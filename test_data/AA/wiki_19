{"url": "https://en.wikipedia.org/wiki?curid=3019", "text": "`Abdu'l-Bahá\n\n`Abdu’l-Bahá' (Persian/‎, 23 May 1844 – 28 November 1921), born ‘Abbás Effendí (), was the eldest son of Bahá'u'lláh, the founder of the Bahá'í Faith. In 1892, `Abdu'l-Bahá was appointed in his father's will to be his successor and head of the Bahá'í Faith. `Abdu'l-Bahá was born in Tehran to an aristocratic family of the realm. At the age of eight his father was imprisoned and the family's possessions were looted, leaving them in virtual poverty. Along with his father, `Abdu'l-Bahá was exiled to Baghdad where the family lived for nine years.\n\nDuring his youth he was faithful to his father and was regarded as an outstanding member of the Bahá’í exile community. As a teenager he was his father’s amanuensis and was regularly seen debating theological issues with the learned men of the area. In 1863, Bahá'u'lláh and his family were banished from Baghdad to Istanbul. During the 1860s the family was further banished from Constantinople to Adrianople, and then finally to the penal-colony of Acre, Palestine.\n\nWith his father's death in 1892, and his appointment as head of the Bahá’í Faith, there was much opposition to him, including virtually all his family members. Notwithstanding this, practically all of the worldwide Bahá’í community accepted his leadership. In 1908, at the age of 64 and after forty years imprisonment, `Abdu’l-Bahá was freed by the Young Turks and he and his family began to live in relative safety. His journeys to the West, and his \"Tablets of the Divine Plan\" spread the Bahá'í message beyond its middle-eastern roots, and his Will and Testament laid the foundation for the current \"Bahá'í administrative order. Many of his writings, prayers and letters are extant, and his discourses with the Western Bahá'ís emphasize the growth of the faith by the late 1890s. `Abdu'l-Bahá's given name was `Abbás, but he preferred the title of `Abdu'l-Bahá (servant of the glory of God). He is commonly referred to in Bahá'í texts as \"The Master\", and received the title of KBE after his personal storage of grain was used to relieve famine in Palestine following World War I, but never used the title.\n\n`Abdu'l-Bahá was born in Tehran, Iran on 23 May 1844 (5th of Jamadiyu'l-Avval, 1260 AH), the eldest son of Bahá'u'lláh and Navváb. He was born on the very same night on which the Báb declared his mission. Born with the given name of `Abbás, he was named after his grandfather Mírzá `Abbás Núrí, a prominent and powerful nobleman. As a child, `Abdu'l-Bahá was shaped by his father's position as a prominent Bábí. He recalled how he met the Bábí Táhirih and how she would take \"me on to her knee, caress me, and talk to me. I admired her most deeply\". `Abdu’l-Bahá had a happy and carefree childhood. The family’s Tehran home and country houses were comfortable and beautifully decorated. `Abdu'l-Bahá enjoyed playing in the gardens with his younger sister with whom he was very close. Along with his younger siblings – a sister, Bahíyyih, and a brother, Mihdí – the three lived in an environment of privilege, happiness and comfort. With his father declining a position as minister of the royal court; during his young boyhood `Abdu’l-Bahá witnessed his parents' various charitable endeavours, which included converting part of the home to a hospital ward for women and children.\n\n`Abdu'l-Bahá received a haphazard education during his childhood. It was customary not to send children of nobility to schools. Most noblemen were educated at home briefly in scripture, rhetoric, calligraphy and basic mathematics. Many were educated to prepare themselves for life in the royal court. Despite a brief spell at a traditional preparatory school at the age of seven for one year, `Abdu'l-Bahá received no formal education. As he grew he was educated by his mother, and uncle. Most of his education however, came from his father. Years later in 1890 Edward Granville Browne described how `Abdu'l-Bahá was \"one more eloquent of speech, more ready of argument, more apt of illustration, more intimately acquainted with the sacred books of the Jews, the Christians, and the Muhammadans...scarcely be found even amongst the eloquent.\"\n\nWhen `Abdu'l-Bahá was seven, he contracted tuberculosis and was expected to die. Though the malady faded away, he would be plagued with bouts of illness for the rest of his life.\n\nOne event that affected `Abdu'l-Bahá greatly during his childhood was the imprisonment of his father when `Abdu'l-Bahá was eight years old; the imprisonment led to his family being reduced to poverty and being attacked in the streets by other children. `Abdu'l-Bahá accompanied his mother to visit Bahá'u'lláh who was then imprisoned in the infamous subterranean dungeon the Síyáh-Chál. He described how \"I saw a dark, steep place. We entered a small, narrow doorway, and went down two steps, but beyond those one could see nothing. In the middle of the stairway, all of a sudden we heard His [Bahá’u’lláh's]…voice: 'Do not bring him in here', and so they took me back\".\n\nBahá'u'lláh was eventually released from prison but ordered into exile, and `Abdu'l-Bahá then eight joined his father on the journey to Baghdad in the winter (January to April) of 1853. During the journey `Abdu'l-Bahá suffered from frost-bite. After a year of difficulties Bahá'u'lláh absented himself rather than continue to face the conflict with Mirza Yahya and secretly secluded himself in the mountains of Sulaymaniyah in April 1854 a month before `Abdu'l-Bahá's tenth birthday. Mutual sorrow resulted in him, his mother and sister becoming constant companions. `Abdu'l-Bahá was particularly close to both, and his mother took active participation in his education and upbringing. During the two-year absence of his father `Abdu'l-Bahá took up the duty of managing the affairs of the family, before his age of maturity (14 in middle-eastern society) and was known to be occupied with reading and, at a time of hand-copied scriptures being the primary means of publishing, was also engaged in copying the writings of the Báb. `Abdu’l-Bahá also took an interest in the art of horse riding and, as he grew, became a renowned rider.\n\nIn 1856, news of an ascetic carrying on discourses with local Súfí leaders that seemed to possibly be Bahá'u'lláh reached the family and friends. Immediately, family members and friends went to search for the elusive dervish – and in March brought Bahá'u'lláh back to Baghdad. On seeing his father, `Abdu'l-Bahá fell to his knees and wept loudly \"Why did you leave us?\", and this followed with his mother and sister doing the same. `Abdu'l-Bahá soon became his father's secretary and shield. During the sojourn in the city `Abdu’l-Bahá grew from a boy into a young man. He was noted as a \"remarkably fine looking youth\", and remembered for his charity and amiableness. Having passed the age of maturity `Abdu'l-Bahá was regularly seen in the mosques of Baghdad discussing religious topics and the scripture as a young man. Whilst in Baghdad, `Abdu'l-Bahá composed a commentary at the request of his father on the Muslim tradition of \"I was a Hidden Treasure\" for a Súfí leader named `Alí Shawkat Páshá. `Abdu'l-Bahá was fifteen or sixteen at the time and `Alí Shawkat Páshá regarded the more than 11000 word essay as a remarkable feat for somebody of his age. In 1863 in what became known as the Garden of Ridván Bahá'u'lláh announced to a few that he was the manifestation of God and He whom God shall make manifest whose coming had been foretold by the Báb. On day eight of the twelve days, it is believed `Abdu'l-Baha was the first person Baha'u'llah revealed his claim to.\n\nIn 1863 Bahá'u'lláh was summoned to Constantinople (Istanbul), and thus his whole family including `Abdu'l-Bahá, then nineteen, accompanied him on his 110-day journey. The journey to Constantinople was another wearisome journey, and `Abdu'l-Bahá helped feed the exiles. It was here that his position became more prominent amongst the Bahá’ís. This was further solidified by Bahá’u’lláh’s tablet of the Branch in which he constantly exalts his son's virtues and station. The family were soon exiled to Adrianople and `Abdu'l-Bahá went with the family. `Abdu’l-Bahá again suffered from frostbite.\n\nIn Adrianople `Abdu’l-Bahá was regarded as the sole comforter of his family – in particular to his mother. At this point `Abdu'l-Bahá was known by the Bahá'ís as \"the Master\", and by non-Bahá'ís as `Abbás Effendi (\"Effendi\" signifies \"Sir\"). It was in Adrianople that Bahá’u’lláh referred to his son as \"the Mystery of God\". The title of \"Mystery of God\" symbolises, according to Bahá'ís, that `Abdu'l-Bahá is not a manifestation of God but how a \"person of `Abdu'l-Bahá the incompatible characteristics of a human nature and superhuman knowledge and perfection have been blended and are completely harmonized\". `Abdu'l-Bahá was at this point noted for having black hair which flowed to his shoulders, large blue eyes, rose-through-alabaster coloured skin and a fine nose. Bahá'u'lláh gave his son many other titles such as \"the Most Mighty Branch\" the \"Branch of Holiness\", \"the Center of the Covenant\" and the apple of his eye. `Abdu'l-Bahá (\"the Master\") was devastated when hearing the news that he and his family were to be exiled separately from Bahá'u'lláh. It was, according to Bahá'ís, through his intercession that the idea was reverted and the family were allowed to be exiled together.\n\nAt the age of 24, `Abdu'l-Bahá was clearly chief-steward to his father and an outstanding member of the Bahá’í community. Bahá’u’lláh and his family were – in 1868 – exiled to the penal colony of Acre, Palestine where it was expected that the family would perish. Arrival in Acre was distressing for the family and exiles. They were greeted in a hostile manner by the surrounding population and his sister and father fell dangerously ill. When told that the women were to sit on the shoulders of the men to reach the shore, `Abdu'l-Bahá took a chair and carried the women to the bay of Acre. `Abdu'l-Bahá was able to procure some anesthetic and nursed the sick. The Bahá’ís were imprisoned under horrendous conditions in a cluster of cells covered in excrement and dirt. `Abdu'l-Bahá himself fell dangerously ill with dysentery, however a sympathetic soldier permitted a physician to help cure him. The population shunned them, the soldiers treated them the same, and the behaviour of Siyyid Muhammad-i-Isfahani (an Azali) did not help matters. Morale was further destroyed with the accidental death of `Abdu'l-Bahá’s youngest brother Mírzá Mihdí at the age of 22. His death devastated the family – particularly his mother and father – and the grieving `Abdu'l-Bahá kept a night-long vigil beside his brother’s body.\n\nOver time, he gradually took over responsibility for the relationships between the small Bahá'i exile community and the outside world. It was through his interaction with the people of Acre that, according to the Bahá'ís, they recognized the innocence of the Bahá'ís, and thus the conditions of imprisonment were eased. Four months after the death of Mihdí the family moved from the prison to the House of `Abbúd. The people of Acre started to respect the Bahá'ís and in particular, `Abdu'l-Bahá. `Abdu'l-Bahá was able to arrange for houses to be rented for the family, the family later moved to the Mansion of Bahjí around 1879 when an epidemic caused the inhabitants to flee.\n\n`Abdu'l-Bahá soon became very popular in the penal colony and Myron Henry Phelps a wealthy New York lawyer described how \"a crowd of human beings...Syrians, Arabs, Ethiopians, and many others\", all waited to talk and receive `Abdu'l-Bahá. He undertook a history of the Bábí religion through publication of A Traveller's Narrative (Makála-i-Shakhsí Sayyáh) in 1886, later translated and published in translation in 1891 through Cambridge University by the agency of Edward Granville Browne who described `Abdu'l-Bahá as: \n\nAs a young man speculation was rife amongst the Bahá’ís to whom `Abdu'l-Bahá would marry. Several young girls were seen as marriage prospects but `Abdu’l-Bahá seemed disinclined to marriage. On 8 March 1873, at the urging of his father, the twenty-eight-year-old `Abdu’l-Bahá married Fátimih Nahrí of Isfahán (1847–1938) a twenty-five-year-old from an upper-class family of the city. Her father was Mírzá Muḥammad `Alí Nahrí of Isfahan an eminent Bahá’í with prominent connections. Fátimih was brought from Persia to Acre, Palestine after both Bahá’u’lláh and his wife Navváb expressed an interest in her to marry `Abdu’l-Bahá. After a wearisome journey from Isfahán to Akka she finally arrived accompanied by her brother in 1872. The young couple were betrothed for about five months before the marriage itself commenced. In the meantime, Fátimih lived in the home of `Abdu'l-Bahá’s uncle Mírzá Músá. According to her later memoirs, Fátimih fell in love with `Abdu'l-Bahá on seeing him. `Abdu'l-Bahá himself had showed little inkling to marriage until meeting Fátimih; who was entitled Munírih by Bahá’u’lláh. Munírih is a title meaning \"Luminous\".\n\nThe marriage resulted in nine children. The first born was a son Mihdí Effendi who died aged about 3. He was followed by Ḍiyá'iyyih Khánum, Fu’ádíyyih Khánum (d. few years old), Rúhangíz Khánum (d. 1893), Túbá Khánum, Husayn Effendi (d.1887 aged 5), Túbá Khánum, Rúhá Khánum and Munnavar Khánum. The death of his children caused `Abdu’l-Bahá immense grief – in particular the death of his son Husayn Effendi came at a difficult time following the death of his mother and uncle. The surviving children (all daughters) were; Ḍiyá'iyyih Khánum (mother of Shoghi Effendi) (d. 1951) Túbá Khánum (1880–1959) Rúḥá Khánum and Munavvar Khánum (d. 1971). Bahá'u'lláh wished that the Bahá'ís follow the example of `Abdu'l-Bahá and gradually move away from polygamy. The marriage of `Abdu’l-Bahá to one woman and his choice to remain monogamous, from advice of his father and his own wish, legitimised the practice of monogamy to a people whom hitherto had regarded polygamy as a righteous way of life.\n\nAfter Bahá'u'lláh died on 29 May 1892, the Will and Testament of Bahá'u'lláh named `Abdu'l-Bahá as Centre of the Covenant, successor and interpreter of Bahá'u'lláh's writings. In the Will and Testament `Abdu'l-Bahá's half-brother, Muhammad `Alí, was mentioned by name as being subordinate to `Abdu'l-Bahá. Muhammad `Alí became jealous of his half-brother and set out to establish authority for himself as an alternative leader with the support of his brothers Badi'u'llah and Diya'u'llah. He began correspondence with Bahá'ís in Iran, initially in secret, casting doubts in others' minds about `Abdu'l-Bahá. While most Bahá'ís followed `Abdu'l-Bahá, a handful followed Muhammad `Alí including such leaders as Mirza Javad and Ibrahim George Kheiralla, an early Bahá'í missionary to America.\n\nMuhammad `Alí and Mirza Javad began to openly accuse `Abdu'l-Bahá of taking on too much authority, suggesting that he believed himself to be a Manifestation of God, equal in status to Bahá'u'lláh. It was at this time that `Abdu'l-Bahá, in order to provide proof of the falsity of the accusations leveled against him, in tablets to the West, stated that he was to be known as \"`Abdu'l-Bahá\" an Arabic phrase meaning the Servant of Bahá to make it clear that he was not a Manifestation of God, and that his station was only servitude. `Abdu'l-Bahá left a Will and Testament that set up the framework of administration. The two highest institutions were the Universal House of Justice, and the Guardianship, for which he appointed Shoghi Effendi as the Guardian. With the exception of `Abdu'l-Bahá and Shoghi Effendi, Muhammad `Alí was supported by all of the remaining male relatives of Bahá'u'lláh, including Shoghi Effendi's father, Mírzá Hádí Shírází. However Muhammad `Alí's and his families statements had very little effect on the Bahá'ís in general - in the `Akká area, the followers of Muhammad `Alí represented six families at most, they had no common religious activities, and were almost wholly assimilated into Muslim society.\n\nBy the end of 1898, Western pilgrims started coming to Akka on pilgrimage to visit `Abdu'l-Bahá; this group of pilgrims, including Phoebe Hearst, was the first time that Bahá'ís raised up in the West had met `Abdu'l-Bahá. The first group arrived in 1898 and throughout late 1898 to early 1899 Western Bahá’ís sporadically visited `Abdu'l-Bahá. The group was relatively young containing mainly women from high American society in their 20s. The group of Westerners aroused suspicion for the authorities, and consequently `Abdu'l-Bahá’s confinement was tightened. During the next decade `Abdu'l-Bahá would be in constant communication with Bahá'ís around the world, helping them to teach the religion; the group included May Ellis Bolles in Paris, Englishman Thomas Breakwell, American Herbert Hopper, French , Susan Moody, Lua Getsinger, and American Laura Clifford Barney. It was Laura Clifford Barney who, by asking questions of `Abdu'l-Bahá over many years and many visits to Haifa, compiled what later became the book Some Answered Questions.\n\nDuring the final years of the 19th century, while `Abdu'l-Bahá was still officially a prisoner and confined to `Akka, he organized the transfer of the remains of the Báb from Iran to Palestine. He then organized the purchase of land on Mount Carmel that Bahá'u'lláh had instructed should be used to lay the remains of the Báb, and organized for the construction of the Shrine of the Báb. This process took another 10 years. With the increase of pilgrims visiting `Abdu'l-Bahá, Muhammad `Alí worked with the Ottoman authorities to re-introduce stricter terms on `Abdu'l-Bahá's imprisonment in August 1901. By 1902, however, due to the Governor of `Akka being supportive of `Abdu'l-Bahá, the situation was greatly eased; while pilgrims were able to once again visit `Abdu'l-Bahá, he was confined to the city. In February 1903, two followers of Muhammad `Alí, including Badi'u'llah and Siyyid `Aliy-i-Afnan, broke with Muhammad `Ali and wrote books and letters giving details of Muhammad `Ali's plots and noting that what was circulating about `Abdu'l-Bahá was fabrication.\n\nFrom 1902 to 1904, in addition to the building of the Shrine of the Báb that `Abdu'l-Bahá was directing, he started to put into execution two different projects; the restoration of the House of the Báb in Shiraz, Iran and the construction of the first Bahá'í House of Worship in Ashgabat, Turkmenistan. `Abdu'l-Bahá asked Aqa Mirza Aqa to coordinate the work so that the house of the Báb would be restored to the state that it was at the time of the Báb's declaration to Mulla Husayn in 1844; he also entrusted the work on the House of Worship to Vakil-u'd-Dawlih.\n\nDuring this period, `Abdu'l-Bahá communicated with a number Young Turks, opposed to the reign of Sultan Abdul Hamid II, including Namık Kemal, Ziya Pasha and Midhat Pasha, in an attempt to disseminate Bahá'í thought into their political ideology. He emphasized Bahá'ís \"seek freedom and love liberty, hope for equality, are well-wishers of humanity and ready to sacrifice their lives to unite humanity\" but on a more broad approach than the Young Turks. Abdullah Cevdet, one of the founders of the Committee of Union and Progress who considered the Bahá'í Faith an intermediary step between Islam and the ultimate abandonment of religious belief, would go on trial for defense of Bahá'ís in a periodical he founded.\n\n‛Abdu'l-Bahá also had contact with military leaders as well, including such individuals as Bursalı Mehmet Tahir Bey and Hasan Bedreddin. The latter, who was involved in the overthrow of Sultan Abdülaziz, is commonly known as Bedri Paşa or Bedri Pasha and is referred to in Persian Bahá'í sources as Bedri Bey (Badri Beg). He was a Bahá'í who translated ‛Abdu’l-Baha's works into French.\n\n`Abdu'l-Bahá also met Muhammad Abduh, one of the key figures of Islamic Modernism and the Salafi movement, in Beirut, at a time when the two men were both opposed to the Ottoman \"ulama\" and shared similar goals of religious reform. Rashid Rida asserts that during his visits to Beirut, `Abdu'l-Bahá would attend Abduh's study sessions. Regarding the meetings of `Abdu'l-Bahá and Muhammad 'Abduh, Shoghi Effendi asserts that \"His several interviews with the well-known Shaykh Muhammad ‘Abdu served to enhance immensely the growing prestige of the community and spread abroad the fame of its most distinguished member.\"\n\nDue to `Abdu'l-Bahá's political activities and alleged accusation against him by Muhammad `Ali, a Commission of Inquiry interviewed `Abdu'l-Bahá in 1905, with the result that he was almost exiled to Fezzan. In response, `Abdu'l-Bahá wrote the sultan a letter protesting that his followers refrain from involvement in partisan politics and that his \"tariqa\" had guided many Americans to Islam. The next few years in `Akka were relatively free of pressures and pilgrims were able to come and visit `Abdu'l-Bahá. By 1909 the mausoleum of the Shrine of the Báb was completed.\n\nThe 1908 Young Turks revolution freed all political prisoners in the Ottoman Empire, and `Abdu'l-Bahá was freed from imprisonment. His first action after his freedom was to visit the Shrine of Bahá'u'lláh in Bahji. While `Abdu'l-Bahá continued to live in `Akka immediately following the revolution, he soon moved to live in Haifa near the Shrine of the Báb. In 1910, with the freedom to leave the country, he embarked on a three-year journey to Egypt, Europe, and North America, spreading the Bahá'í message.\n\nFrom August to December 1911, `Abdu'l-Bahá visited cities in Europe, including London, Bristol, and Paris. The purpose of these trips was to support the Bahá'í communities in the west and to further spread his father's teachings.\n\nIn the following year, he undertook a much more extensive journey to the United States and Canada to once again spread his father's teachings. He arrived in New York City on 11 April 1912, after declining an offer of passage on the RMS Titanic, telling the Bahá'í believers, instead, to \"Donate this to charity.\" He instead travelled on a slower craft, the S.S. Cedric, and cited preference of a longer sea journey as the reason. After hearing of the Titanic's sinking on 16 April he was quoted as saying \"I was asked to sail upon the Titanic, but my heart did not prompt me to do so.\" While he spent most of his time in New York, he visited Chicago, Cleveland, Pittsburgh, Washington, D.C., Boston and Philadelphia. In August of the same year he started a more extensive journey to places including New Hampshire, the Green Acre school in Maine, and Montreal (his only visit to Canada). He then travelled west to Minneapolis, San Francisco, Stanford, and Los Angeles before starting to return east at the end of October. On 5 December 1912 he set sail back to Europe.\n\nDuring his visit to North America he visited many missions, churches, and groups, as well as having scores of meetings in Bahá'ís' homes, and offering innumerable personal meetings with hundreds of people. During his talks he proclaimed Bahá'í principles such as the unity of God, unity of the religions, oneness of humanity, equality of women and men, world peace and economic justice. He also insisted that all his meetings be open to all races.\n\nHis visit and talks were the subject of hundreds of newspaper articles. In Boston newspaper reporters asked `Abdu'l-Bahá why he had come to America, and he stated that he had come to participate in conferences on peace and that just giving warning messages is not enough. `Abdu'l-Bahá's visit to Montreal provided notable newspaper coverage; on the night of his arrival the editor of the \"Montreal Daily Star\" met with him and that newspaper along with The Montreal Gazette, \"Montreal Standard\", Le Devoir and La Presse among others reported on `Abdu'l-Bahá's activities. The headlines in those papers included \"Persian Teacher to Preach Peace\", \"Racialism Wrong, Says Eastern Sage, Strife and War Caused by Religious and National Prejudices\", and \"Apostle of Peace Meets Socialists, Abdul Baha's Novel Scheme for Distribution of Surplus Wealth.\" The \"Montreal Standard\", which was distributed across Canada, took so much interest that it republished the articles a week later; the Gazette published six articles and Montreal's largest French language newspaper published two articles about him. His 1912 visit to Montreal also inspired humourist Stephen Leacock to parody him in his bestselling 1914 book \"Arcadian Adventures with the Idle Rich\". In Chicago one newspaper headline included \"His Holiness Visits Us, Not Pius X but A. Baha,\" and `Abdu'l-Bahá's visit to California was reported in the \"Palo Altan\".\n\nBack in Europe, he visited London, Paris (where he stayed for two months), Stuttgart, Budapest, and Vienna. Finally, on June 12, 1913, he returned to Egypt, where he stayed for six months before returning to Haifa.\n\nOn February 23, 1914, at the eve of World War I, `Abdu'l-Bahá hosted Baron Edmond James de Rothschild, a member of the Rothschild banking family who was a leading advocate and financier of the Zionist movement, during one of his early trips to Palestine.\n\nDuring World War I `Abdu'l-Bahá stayed in Palestine, under the continued threat of Allied bombardment and threats from the Turkish commander. As the war ended, the British Mandate over Palestine brought relative security to `Abdu'l-Bahá. During his final year, a growing number of visitors and pilgrims came to see him in Haifa.\n\nAccording to Harry Charles Luke, an official in the British Colonial Office who served as assistant Governor of Jerusalem, `Abdu'l-Bahá \"was created by King George V a K.B.E.\" on December 4, 1919, being conferred his knighthood \"for valuable services rendered to the British Government in the early days of the Occupation.\" This has been judged to be humanitarian service to people following the privations of war and the chaos in its immediate aftermath by averting a famine in Northern Palestine. He was ceremonially knighted on April 27, 1920, an event which was prominently reported in the \"Star of the West\" as \" a most wonderful celebration.\"\n\nSubsequent to the British occupation of Palestine, during the arrival of Jews under the Palestine Jewish Colonization Association, `Abdu'l-Bahá praised the Zionist movement, proclaiming that \"There is too much talk today of what the Zionists are going to do here. There is no need of it. Let them come and do more and say less\" and that \"A Jewish government might come later.\"\n\n`Abdu'l-Bahá died on November 28, 1921 (27th of Rabi'u'l-Avval, 1340 AH.) On his funeral, Esslemont notes:\n\nHe is buried in the front room of the Shrine of the Báb on Mount Carmel. Plans are in place to one day build a Shrine of `Abdu'l-Bahá. In his Will and Testament he appointed his grandson Shoghi Effendi Rabbani as the Guardian of the Bahá'í Faith.\n\nThe total estimated number of tablets that `Abdu'l-Bahá wrote are over 27,000, of which only a fraction have been translated into English. His works fall into two groups including first his direct writings and second his lectures and speeches as noted by others. The first group includes \"The Secret of Divine Civilization\" written before 1875, \"A Traveller's Narrative\" written around 1886, the Resāla-ye sīāsīya or \"Sermon on the Art of Governance\" written in 1893, the \"Memorials of the Faithful\", and a large number of tablets written to various people; including various Western intellectuals such as August Forel which has been translated and published as the Tablet to Auguste-Henri Forel. The \"Secret of Divine Civilization\" and the \"Sermon on the Art of Governance\" were widely circulated anonymously.\n\nThe second group includes Some Answered Questions, which is an English translation of a series of table talks with Laura Barney, and Paris Talks, \"`Abdu'l-Baha in London\" and \"Promulgation of Universal Peace\" which are respectively addresses given by `Abdu'l-Bahá in Paris, London and the United States.\n\nThe following is a list of some of `Abdu'l-Bahá's many books, tablets, and talks:\n\n\n\n\n", "id": "3019", "title": "`Abdu'l-Bahá"}
{"url": "https://en.wikipedia.org/wiki?curid=3020", "text": "Ambrose of Alexandria\n\nAmbrose of Alexandria (before 212 – c. 250) was a friend of the Christian theologian Origen. Ambrose was attracted by Origen's fame as a teacher, and visited the Catechetical School of Alexandria in 212. At first a gnostic Valentinian and Marcionist, Ambrose, through Origen's teaching, eventually rejected this theology and became Origen's constant companion, and was ordained deacon. He plied Origen with questions, and urged him to write his Commentaries () on the books of the Bible, and, as a wealthy nobleman and courtier, he provided his teacher with books for his studies and secretaries to lighten the labor of composition.\n\nHe suffered during the persecution under the Roman emperor Maximinus Thrax in 235. He was later released and died a confessor. The last mention of Ambrose in the historical record is in Origen's \"Contra Celsum,\" which the latter wrote at the solicitation of Ambrose.\n\nOrigen often speaks of Ambrose in affectionately as a man of education with excellent literary and scholarly tastes. All of Origen's works written after 218 are dedicated to Ambrose, including his \"On Martyrdom\", \"Contra Celsum\", \"Commentary on St. John's Gospel\", and \"On Prayer\". Ambrose's letters to Origen (praised by Jerome) are lost, although part of one exists.\n\nAmbrose is venerated as a saint by some branches of Christianity. His feast day in the Roman Catholic Church falls on 17 March.\n", "id": "3020", "title": "Ambrose of Alexandria"}
{"url": "https://en.wikipedia.org/wiki?curid=3022", "text": "Autonomous building\n\nAn autonomous building is a building designed to be operated independently from infrastructural support services such as the electric power grid, gas grid, municipal water systems, sewage treatment systems, storm drains, communication services, and in some cases, public roads.\n\nAdvocates of autonomous building describe advantages that include reduced environmental impacts, increased security, and lower costs of ownership. Some cited advantages satisfy tenets of green building, not independence per se (see below). Off-grid buildings often rely very little on civil services and are therefore safer and more comfortable during civil disaster or military attacks. (Off-grid buildings would not lose power or water if public supplies were compromised for some reason.)\n\nMost of the research and published articles concerning autonomous building focus on residential homes.\n\nBritish architects Brenda and Robert Vale have said that, as of 2002, \"It is quite possible in all parts of Australia to construct a 'house with no bills', which would be comfortable without heating and cooling, which would make its own electricity, collect its own water and deal with its own waste...These houses can be built now, using off-the-shelf techniques. It is possible to build a \"house with no bills\" for the same price as a conventional house, but it would be (25%) smaller.\"\n\nIn the 1970s, a group of activists and engineers calling themselves the New Alchemists believed the warnings of imminent resource depletion and starvation. The New Alchemists were famous for the depth of research effort placed in their projects. Using conventional construction techniques, they designed a series of \"bioshelter\" projects, the most famous of which was the Ark Bioshelter community for Prince Edward Island. They published the plans for all of these, with detailed design calculations and blueprints. The Ark used wind based water pumping and electricity, and was self-contained in food production. It had living quarters for people, fish tanks raising tilapia for protein, a greenhouse watered with fish water and a closed loop sewage reclamation system that recycled human waste into sanitized fertilizer for the fish tanks. As of January 2010, the successor organization to the New Alchemists has a web page up as the \"New Alchemy Institute\". The PEI Ark has been abandoned and partially renovated several times.\n\nThe 1990s saw the development of Earthships, similar in intent to the Ark project, but organized as a for-profit venture, with construction details published in a series of 3 books by Mike Reynolds. The building material is tires filled with earth. This makes a wall that has large amounts of thermal mass (see earth sheltering). Berms are placed on exposed surfaces to further increase the house's temperature stability. The water system starts with rain water, processed for drinking, then washing, then plant watering, then toilet flushing, and finally black water is recycled again for more plant watering. The cisterns are placed and used as thermal masses. Power, including electricity, heat and water heating, is from solar power.\n\n1990s architects such as William McDonough and Ken Yeang applied environmentally responsible building design to large commercial buildings, such as office buildings, making them largely self-sufficient in energy production. One major bank building (ING's Amsterdam headquarters) in the Netherlands was constructed to be autonomous and artistic as well.\n\nAs an architect or engineer becomes more concerned with the disadvantages of transportation networks, and dependence on distant resources, their designs tend to include more autonomous elements. The historic path to autonomy was a concern for secure sources of heat, power, water and food. A nearly parallel path toward autonomy has been to start with a concern for environmental impacts, which cause disadvantages.\n\nAutonomous buildings can increase security and reduce environmental impacts by using on-site resources (such as sunlight and rain) that would otherwise be wasted. Autonomy often dramatically reduces the costs and impacts of networks that serve the building, because autonomy short-circuits the multiplying inefficiencies of collecting and transporting resources. Other impacted resources, such as oil reserves and the retention of the local watershed, can often be cheaply conserved by thoughtful designs.\n\nAutonomous buildings are usually energy-efficient in operation, and therefore cost-efficient, for the obvious reason that smaller energy needs are easier to satisfy off-grid. But they may substitute energy production or other techniques to avoid diminishing returns in extreme conservation.\n\nAn autonomous structure is not always environmentally friendly. The goal of independence from support systems is associated with, but not identical to, other goals of environmentally responsible green building. However, autonomous buildings also usually include some degree of sustainability through the use of renewable energy and other renewable resources, producing no more greenhouse gases than they consume, and other measures.\n\nFirst and fundamentally, independence is a matter of degree. Self sustainable living, for example, is eliminating dependence on the electrical grid is in fact relatively simple however, obtaining an efficient and reliable food source is a more demanding and time-consuming proposition.\n\nLiving within an autonomous shelter may also require that party to make sacrifices with lifestyle choices, personal behavior, and social expectations to name a few. Even the most comfortable and technologically advanced autonomous homes could require some alterations upon the residents psychological behavior(s); while others may adjust easily, others may not. Others describe their experience as inconvenient, irritating, isolating, or even as an unwanted full-time job. A well-designed building can reduce this issue, but usually at the expense of reduced autonomy.\n\nAn autonomous house must be custom-built (or extensively retrofitted) to suit the climate and location. Passive solar techniques, alternative toilet and sewage systems, thermal massing designs, basement battery systems, efficient windowing, and the array of other design tactics require some degree of non-standard construction, added expense, ongoing experimentation and maintenance, and also have an effect on the psychology of the space.\n\nThe Vales, among others, have shown that living off-grid can be a practical, logical lifestyle choice—under certain conditions.\n\nThis section includes some minimal descriptions of methods, to give some feel for such a building's practicality, provide indexes to further information, and give a sense of modern trends.\n\nThere are many methods of collecting and conserving water. Use reduction is cost-effective.\n\nGreywater systems reuse drained wash water to flush toilets or to water lawns and gardens. Greywater systems can halve the water use of most residential buildings; however, they require the purchase of a sump, greywater pressurization pump, and secondary plumbing. Some builders are installing waterless urinals and even composting toilets that completely eliminate water usage in sewage disposal.\n\nThe classic solution with minimal life-style changes is using a well. Once drilled, a well-foot requires substantial power. However, advanced well-foots can reduce power usage by twofold or more from older models. Well water can be contaminated in some areas. The sono arsenic filter eliminates unhealthy arsenic in well water.\n\nHowever drilling a well is an uncertain activity, with aquifers depleted in some areas. It can also be expensive.\n\nIn regions with sufficient rainfall, it is often more economical to design a building to use rain, with supplementary water deliveries in a drought. Rain water makes excellent soft washwater, but needs antibacterial treatment. If used for drinking, mineral supplements or mineralization is necessary.\n\nMost desert and temperate climates get at least of rain per year. This means that a typical one-story house with a greywater system can supply its year-round water needs from its roof alone. In the driest areas, it might require a cistern of . Many areas average of rain per week, and these can use a cistern as small as .\n\nIn many areas, it is difficult to keep a roof clean enough for drinking. To reduce dirt and bad tastes, systems use a metal collecting-roof and a \"roof cleaner\" tank that diverts the first 40 liters. Cistern water is usually chlorinated, though reverse osmosis systems provide even better quality drinking water.\n\nModern cisterns are usually large plastic tanks. Gravity tanks on short towers are reliable, so pump repairs are less urgent. The least expensive bulk cistern is a fenced pond or pool at ground level.\n\nReducing autonomy reduces the size and expense of cisterns. Many autonomous homes can reduce water use below per person per day, so that in a drought a month of water can be delivered inexpensively via truck. Self-delivery is often possible by installing fabric water tanks that fit the bed of a pick-up truck.\n\nIt can be convenient to use the cistern as a heat sink or trap for a heat pump or air conditioning system; however this can make cold drinking water warm, and in drier years may decrease the efficiency of the HVAC system.\n\nSolar stills can efficiently produce drinking water from ditch water or cistern water, especially high-efficiency multiple effect humidification designs, which separate the evaporator(s) and condenser(s).\n\nNew technologies, like reverse osmosis can create unlimited amounts of pure water from polluted water, ocean water, and even from humid air. Water makers are available for yachts that convert seawater and electricity into potable water and brine. Atmospheric water generators extract moisture from dry desert air and filter it to pure water.\n\nThe approaches below treat human excrement as a waste rather than a resource. Composting toilets use bacteria to decompose human feces into useful, odourless, sanitary compost. The process is sanitary because soil bacteria eat the human pathogens as well as most of the mass of the waste. Nevertheless, most health authorities forbid direct use of \"humanure\" for growing food. The risk is microbial and viral contamination. In a dry composting toilet, the waste is evaporated or digested to gas (mostly carbon dioxide) and vented, so a toilet produces only a few pounds of compost every six months. To control the odor, modern toilets use a small fan to keep the toilet under negative pressure, and exhaust the gasses to a vent pipe.\n\nSome home sewage treatment systems use biological treatment, usually beds of plants and aquaria, that absorb nutrients and bacteria and convert greywater and sewage to clear water. This odor- and color-free reclaimed water can be used to flush toilets and water outside plants. When tested, it approaches standards for potable water. In climates that freeze, the plants and aquaria need to be kept in a small greenhouse space. Good systems need about as much care as a large aquarium.\n\nElectric incinerating toilets turn excrement into a small amount of ash. They are cool to the touch, have no water and no pipes, and require an air vent in a wall. They are used in remote areas where use of septic tanks is limited, usually to reduce nutrient loads in lakes.\n\nNASA's bioreactor is an extremely advanced biological sewage system. It can turn sewage into air and water through microbial action. NASA plans to use it in the manned Mars mission.\n\nA big disadvantage of complex biological sewage treatment systems is that if the house is empty, the sewage system biota may starve to death.\n\nAnother method is NASA's urine-to-water distillation system.\n\nSewage handling is essential for public health. Many diseases are transmitted by poorly functioning sewage systems.\n\nThe standard system is a tiled leach field combined with a septic tank. The basic idea is to provide a small system with primary sewage treatment. Sludge settles to the bottom of the septic tank, is partially reduced by anaerobic digestion, and fluid is dispersed in the leach field. The leach field is usually under a yard growing grass. Septic tanks can operate entirely by gravity, and if well managed, are reasonably safe.\n\nSeptic tanks have to be pumped periodically by a vacuum truck to eliminate non reducing solids. Failure to pump a septic tank can cause overflow that damages the leach field, and contaminates ground water. Septic tanks may also require some lifestyle changes, such as not using garbage disposals, minimizing fluids flushed into the tank, and minimizing nondigestible solids flushed into the tank. For example, septic safe toilet paper is recommended.\n\nHowever, septic tanks remain popular because they permit standard plumbing fixtures, and require few or no lifestyle sacrifices.\n\nComposting or packaging toilets make it economical and sanitary to throw away sewage as part of the normal garbage collection service. They also reduce water use by half, and eliminate the difficulty and expense of septic tanks. However, they require the local landfill to use sanitary practices.\n\nIncinerator systems are quite practical. The ashes are biologically safe, and less than 1/10 the volume of the original waste, but like all incinerator waste, are usually classified as hazardous waste.\n\nSome of the oldest pre-system sewage types are pit toilets, latrines, and outhouses. These are still used in many developing countries.\n\nDrainage systems are a crucial compromise between human habitability and a secure, sustainable watershed. Paved areas and lawns or turf do not allow much precipitation to filter through the ground to recharge aquifers. They can cause flooding and damage in neighbourhoods, as the water flows over the surface towards a low point.\n\nTypically, elaborate, capital-intensive storm sewer networks are engineered to deal with stormwater. In some cities, such as the Victorian era London sewers or much of the old City of Toronto, the storm water system is combined with the sanitary sewer system. In the event of heavy precipitation, the load on the sewage treatment plant at the end of the pipe becomes too great to handle and raw sewage is dumped into holding tanks, and sometimes into surface water.\n\nAutonomous buildings can address precipitation in a number of ways:\n\nIf a water absorbing swale for each yard is combined with permeable concrete streets, storm drains can be omitted from the neighbourhood. This can save more than $800 per house (1970s) by eliminating storm drains. One way to use the savings is to purchase larger lots, which permits more amenities at the same cost. Permeable concrete is an established product in warm climates, and in development for freezing climates. In freezing climates, the elimination of storm drains can often still pay for enough land to construct swales (shallow water collecting ditches) or water impeding berms instead. This plan provides more land for homeowners and can offer more interesting topography for landscaping.\n\nA green roof captures precipitation and uses the water to grow plants. It can be built into a new building or used to replace an existing roof.\n\nSince electricity is an expensive utility, the first step towards conservation is to design a house and lifestyle to reduce demand. Fluorescent lights, laptop computers and gas-powered refrigerators save electricity, although gas-powered refrigerators are not very efficient. There are also superefficient electric refrigerators, such as those produced by the Sun Frost company, some of which use only about half as much electricity as a mass-market energy star-rated refrigerator.\n\nUsing a solar roof, solar cells can provide electric power. Solar roofs have the potential to be more cost-effective than retrofitted solar power, because buildings need roofs anyway. Modern solar cells last about 40 years, which makes them a reasonable investment in some areas. At a sufficient angle, solar cells are cleaned by run-off rain water and therefore have almost no life-style impact.\n\nHowever, there are some areas where there is not a sufficient amount of solar radiation to justify using solar power. A common alternative or supplement is using wind turbines. To generate power, the average autonomous house needs only one small wind generator, 5 metres or less in diameter. On a 30-metre (100 foot) tower, this turbine can provide enough power to supplement solar power on cloudy days. Commercially available wind turbines use sealed, one-moving-part AC generators and passive, self-feathering blades for years of operation without service.\n\nThe main advantage of wind power is that larger wind turbines have a lower per-watt cost than solar cells, provided there is wind. However, location is critical. Just as some locations lack sun for solar cells, there are many areas that lack sufficient wind to justify a turbine installation. In the Great Plains of the United States, a 10-metre (33 foot) turbine can supply enough energy to heat and cool a well-built all-electric house. Economic use in other areas requires research, and possibly a site-survey.\n\nDuring times of low demand, excess power can be stored in batteries for future use. However, batteries need to be replaced every few years. In many areas, battery expenses can be eliminated by attaching the building to the electric power grid and operating the power system with net metering. Utility permission is required, but such cooperative generation is legally mandated in some areas (for example, California).\n\nA grid-based building is less autonomous, but more economical and sustainable with fewer lifestyle sacrifices. In rural areas the grid's cost and impacts can be reduced by using single-wire earth return systems (for example, the MALT-system).\n\nIn areas that lack access to the grid, battery size can be reduced by including a generator to recharge the batteries during extended fogs or other low-power conditions. Auxiliary generators are usually run from propane, natural gas, or sometimes diesel. An hour of charging usually provides a day of operation. Modern residential chargers permit the user to set the charging times, so the generator is quiet at night. Some generators automatically test themselves once per week.\n\nRecent advances in passively stable magnetic bearings may someday permit inexpensive storage of power in a flywheel in a vacuum. Research groups like Canada's Ballard Power Systems are also working to develop a \"regenerative fuel cell\", a device that can generate hydrogen and oxygen when power is available, and combine these efficiently when power is needed.\n\nEarth batteries tap electric currents in the earth called telluric current. They can be installed anywhere in the ground. They provide only low voltages and current. They were used to power telegraphs in the 19th century. As appliance efficiencies increase, they may become practical.\n\nMicrobial fuel cells finally allow the generation of electricity from biomass. The plant can be chopped and converted as a whole, or it can be left alive so that waste saps from the plant can be converted by bacteria.\n\nMost autonomous buildings are designed to use insulation, thermal mass and passive solar heating and cooling. Examples of these are trombe walls and other technologies as skylights.\n\nPassive solar heating can heat most buildings in even the mild and chilly climates. In colder climates, extra construction costs can be as little as 15% more than new, conventional buildings. In warm climates, those having less than two weeks of frosty nights per year, there is no cost impact.\n\nThe basic requirement for passive solar heating is that the solar collectors must face the prevailing sunlight (south in the Northern Hemisphere, north in the Southern Hemisphere), and the building must incorporate thermal mass to keep it warm in the night.\n\nA recent, somewhat experimental solar heating system \"Annualized geo solar heating\" is practical even in regions that get little or no sunlight in winter. It uses the ground beneath a building for thermal mass. Precipitation can carry away the heat, so the ground is shielded with skirts of plastic insulation. The thermal mass of this system is sufficiently inexpensive and large that it can store enough summer heat to warm a building for the whole winter, and enough winter cold to cool the building in summer.\n\nIn annualized geo solar systems, the solar collector is often separate from (and hotter or colder than) the living space. The building may actually be constructed from insulation, for example, straw-bale construction. Some buildings have been aerodynamically designed so that convection via ducts and interior spaces eliminates any need for electric fans.\n\nA more modest \"daily solar\" design is very practical. For example, for about a 15% premium in building costs, the Passivhaus building codes in Europe use high performance insulating windows, R-30 insulation, HRV ventilation, and a small thermal mass. With modest changes in the building's position, modern krypton- or argon-insulated windows permit normal-looking windows to provide passive solar heat without compromising insulation or structural strength. If a small heater is available for the coldest nights, a slab or basement cistern can inexpensively provide the required thermal mass. Passivhaus building codes in particular bring unusually good interior air quality, because the buildings change the air several times per hour, passing it though a heat exchanger to keep heat inside.\n\nIn all systems, a small supplementary heater increases personal security and reduces lifestyle impacts for a small reduction of autonomy. The two most popular heaters for ultra-high-efficiency houses are a small heat pump, which also provides air conditioning, or a central hydronic (radiator) air heater with water recirculating from the water heater. Passivhaus designs usually integrate the heater with the ventilation system.\n\nEarth sheltering and windbreaks can also reduce the absolute amount of heat needed by a building. Several feet below the earth, temperature ranges from in North Dakota to , in Southern Florida. Wind breaks reduce the amount of heat carried away from a building.\n\nRounded, aerodynamic buildings also lose less heat.\n\nAn increasing number of commercial buildings use a combined cycle with cogeneration to provide heating, often water heating, from the output of a natural gas reciprocating engine, gas turbine or stirling electric generator.\n\nHouses designed to cope with interruptions in civil services generally incorporate a wood stove, or heat and power from diesel fuel or bottled gas, regardless of their other heating mechanisms.\n\nElectric heaters and electric stoves may provide pollution-free heat (depending on the power source), but use large amounts of electricity. If enough electricity is provided by solar panels, wind turbines, or other means, then electric heaters and stoves become a practical autonomous design.\n\nHot water heat recycling units recover heat from water drain lines. They increase a building's autonomy by decreasing the heat or fuel used to heat water. They are attractive because they have no lifestyle changes.\n\nCurrent practical, comfortable domestic water-heating systems combine a solar preheating system with a thermostatic gas-powered flow-through heater, so that the temperature of the water is consistent, and the amount is unlimited. This reduces life-style impacts at some cost in autonomy.\n\nSolar water heaters can save large amounts of fuel. Also, small changes in lifestyle, such as doing laundry, dishes and bathing on sunny days, can greatly increase their efficiency. Pure solar heaters are especially useful for laundries, swimming pools and external baths, because these can be scheduled for use on sunny days.\n\nThe basic trick in a solar water heating system is to use a well-insulated holding tank. Some systems are vacuum- insulated, acting something like large thermos bottles. The tank is filled with hot water on sunny days, and made available at all times. Unlike a conventional tank water heater, the tank is filled only when there is sunlight. Good storage makes a smaller, higher-technology collector feasible. Such collectors can use relatively exotic technologies, such as vacuum insulation, and reflective concentration of sunlight.\n\ncogeneration systems produce hot water from waste heat. They usually get the heat from the exhaust of a generator or fuel cell.\n\nHeat recycling, cogeneration and solar pre-heating can save 50-75% of the gas otherwise used. Also, some combinations provide redundant reliability by having several sources of heat.\nSome authorities advocate replacing bottled gas or natural gas with biogas. However, this is usually impractical unless live-stock are on-site. The wastes of a single family are usually insufficient to produce enough methane for anything more than small amounts of cooking.\n\nAnnualized geo solar buildings often have buried, sloped water-tight skirts of insulation that extend from the foundations, to prevent heat leakage between the earth used as thermal mass, and the surface.\n\nLess dramatic improvements are possible. Windows can be shaded in summer. Eaves can be overhung to provide the necessary shade. These also shade the walls of the house, reducing cooling costs.\n\nAnother trick is to cool the building's thermal mass at night, and then cool the building from the thermal mass during the day. It helps to be able to route cold air from a sky-facing radiator (perhaps an air heating solar collector with an alternate purpose) or evaporative cooler directly through the thermal mass. On clear nights, even in tropical areas, sky facing radiators can cool below freezing.\n\nIf a circular building is aerodynamically smooth, and cooler than the ground, it can be passively cooled by the \"dome effect.\" Many installations have reported that a reflective or light colored dome induces a local vertical heat driven vortex that sucks cooler overhead air downward into a dome if the dome is vented properly (a single overhead vent, and peripheral vents). Some people have reported a temperature differential as high as () between the inside of the dome and the outside. Buckminster Fuller discovered this effect with a simple house design adapted from a grain silo, and adapted his Dymaxion house and geodesic domes to use it.\n\nRefrigerators and air conditioners operating from the waste heat of a diesel engine exhaust, heater flue or solar collector are entering use. These use the same principles as a gas refrigerator. Normally, the heat from a flue powers an \"absorptive chiller\". The cold water or brine from the chiller is used to cool air or a refrigerated space.\n\nCogeneration is popular in new commercial buildings. In current cogeneration systems small gas turbines or stirling engines powered from natural gas produce electricity and their exhaust drives an absorptive chiller.\n\nA truck trailer refrigerator operating from the waste heat of a tractor's diesel exhaust was demonstrated by NRG Solutions, Inc. NRG developed a hydronic ammonia gas heat exchanger and vaporizer, the two essential new, not commercially available components of a waste heat driven refrigerator.\n\nA similar scheme (multiphase cooling) can be by a multistage evaporative cooler. The air is passed through a spray of salt solution to dehumidify it, then through a spray of water solution to cool it, then another salt solution to dehumidify it again. The brine has to be regenerated, and that can be done economically with a low temperature solar still. Multiphase evaporative coolers can lower the air's temperature by 50 °F (28 °C), and still control humidity. If the brine regenerator uses high heat, they also partially sterilise the air.\n\nIf enough electric power is available, cooling can be provided by conventional air conditioning using a heat pump.\n\nFood production has often been included in historic autonomous projects to provide security.\nSkilled, intensive gardening can support an adult from as little as 100 square meters of land per person,\npossibly requiring the use of organic farming and aeroponics. Some proven intensive, low-effort food-production systems include urban gardening (indoors and outdoors). Indoor cultivation may be set up using hydroponics, while outdoor cultivation may be done using permaculture, forest gardening, no-till farming, and do nothing farming.\n\nGreenhouses are also sometimes included. Sometimes they are also outfitted with irrigation systems or heat sink-systems which can respectively irrigate the plants or help to store energy from the sun and redistribute it at night (when the greenhouses starts to cool down).\n\n", "id": "3022", "title": "Autonomous building"}
{"url": "https://en.wikipedia.org/wiki?curid=3027", "text": "Anubis\n\nAnubis ( or ; ) or Anpu is the Greek name of a god associated with mummification and the afterlife in ancient Egyptian religion, usually depicted as a canine or a man with a canine head. Archeologists identified the sacred animal of Anubis as an Egyptian canid, that at the time was called the golden jackal, but recent genetic testing has caused the Egyptian animal to be reclassified as the African golden wolf.\n\nLike many ancient Egyptian deities, Anubis assumed different roles in various contexts. Depicted as a protector of graves as early as the First Dynasty (c. 3100 – c. 2890 BC), Anubis was also an embalmer. By the Middle Kingdom (c. 2055 – 1650 BC) he was replaced by Osiris in his role as lord of the underworld. One of his prominent roles was as a god who ushered souls into the afterlife. He attended the weighing scale during the \"Weighing of the Heart,\" in which it was determined whether a soul would be allowed to enter the realm of the dead. Despite being one of the most ancient and \"one of the most frequently depicted and mentioned gods\" in the Egyptian pantheon, Anubis played almost no role in Egyptian myths.\n\nAnubis was depicted in black, a color that symbolized both rebirth and the discoloration of the corpse after embalming. Anubis is associated with Wepwawet (also called Upuaut), another Egyptian god portrayed with a dog's head or in canine form, but with grey or white fur. Historians assume that the two figures were eventually combined. Anubis' female counterpart is Anput. His daughter is the serpent goddess Kebechet.\n\n\"Anubis\" is a Greek rendering of this god's Egyptian name. In the Old Kingdom (c. 2686 BC – c. 2181 BC), the standard way of writing his name in hieroglyphs was composed of the sound ı͗npw followed by a \"jackal\" over a \"ḥtp\" sign:\ni-n:p-w-C6\nA new form with the \"jackal\" on a tall stand appeared in the late Old Kingdom and became common thereafter:\ni-n:p-w-E16\n\nAccording to the Akkadian transcription in the Amarna letters, Anubis' name (\"ı͗npw\") was vocalized in Egyptian as Anapa.\n\nIn Egypt's Early Dynastic period (c. 3100 – c. 2686 BC), Anubis was portrayed in full animal form, with a \"jackal\" head and body. A \"jackal\" god, probably Anubis, is depicted in stone inscriptions from the reigns of Hor-Aha, Djer, and other pharaohs of the First Dynasty. Since Predynastic Egypt, when the dead were buried in shallow graves, \"jackals\" had been strongly associated with cemeteries because they were scavengers which uncovered human bodies and ate their flesh. In the spirit of \"fighting like with like,\" a \"jackal\" was chosen to protect the dead, because \"a common problem (and cause of concern) must have been the digging up of bodies, shortly after burial, by jackals and other wild dogs which lived on the margins of the cultivation.\"\n\nThe oldest known textual mention of Anubis is in the Pyramid Texts of the Old Kingdom (c. 2686 – c. 2181 BC), where he is associated with the burial of the pharaoh.\n\nIn the Old Kingdom, Anubis was the most important god of the dead. He was replaced in that role by Osiris during the Middle Kingdom (2000–1700 BC). In the Roman era, which started in 30 BC, tomb paintings depict him holding the hand of deceased persons to guide them to Osiris.\n\nThe parentage of Anubis varied between myths, times and sources. In early mythology, he was portrayed as a son of Ra. In the Coffin Texts, which were written in the First Intermediate Period (c. 2181–2055 BC), Anubis is the son of either the cow goddess Hesat or the cat-headed Bastet. Another tradition depicted him as the son of his father Ra and mother Nephthys. The Greek Plutarch (c. 40–120 AD) stated that Anubis was the illegitimate son of Nephthys and Osiris, but that he was adopted by Osiris's wife Isis:\n\nGeorge Hart sees this story as an \"attempt to incorporate the independent deity Anubis into the Osirian pantheon.\" An Egyptian papyrus from the Roman period (30–380 AD) simply called Anubis the \"son of Isis.\"\n\nIn the Ptolemaic period (350–30 BC), when Egypt became a Hellenistic kingdom ruled by Greek pharaohs, Anubis was merged with the Greek god Hermes, becoming Hermanubis. The two gods were considered similar because they both guided souls to the afterlife. The center of this cult was in \"uten-ha\"/\"Sa-ka\"/ Cynopolis, a place whose Greek name means \"city of dogs.\" In Book XI of \"The Golden Ass\" by Apuleius, there is evidence that the worship of this god was continued in Rome through at least the 2nd century. Indeed, Hermanubis also appears in the alchemical and hermetical literature of the Middle Ages and the Renaissance.\n\nAlthough the Greeks and Romans typically scorned Egypt's animal-headed gods as bizarre and primitive (Anubis was mockingly called \"Barker\" by the Greeks), Anubis was sometimes associated with Sirius in the heavens and Cerberus and Hades in the underworld. In his dialogues, Plato often has Socrates utter oaths \"by the dog\" (\"kai me ton kuna\"), \"by the dog of Egypt\", and \"by the dog, the god of the Egyptians\", both for emphasis and to appeal to Anubis as an arbiter of truth in the underworld.\n\nIn contrast to real wolves, Anubis was a protector of graves and cemeteries. Several epithets attached to his name in Egyptian texts and inscriptions referred to that role. \"Khenty-imentiu\", which means \"foremost of the westerners\" and later became the name of a different wolf god, alluded to his protecting function because the dead were usually buried on the west bank of the Nile. He took other names in connection with his funerary role, such as \"He who is upon his mountain\" (\"tepy-dju-ef\") – keeping guard over tombs from above – and \"Lord of the sacred land\" (\"neb-ta-djeser\"), which designates him as a god of the desert necropolis.\n\nThe Jumilhac papyrus recounts another tale where Anubis protected the body of Osiris from Set. Set attempted to attack the body of Osiris by transforming himself into a leopard. Anubis stopped and subdued Set, however, and he branded Set's skin with a hot iron rod. Anubis then flayed Set and wore his skin as a warning against evil-doers who would desecrate the tombs of the dead. Priests who attended to the dead wore leopard skin in order to commemorate Anubis' victory over Set. The legend of Anubis branding the hide of Set in leopard form was used to explain how the leopard got its spots.\n\nMost ancient tombs had prayers to Anubis carved on them.\n\nAs \"He who is in the place of embalming\" (\"imy-ut\"), Anubis was associated with mummification. He was also called \"He who presides over the god's pavilion\" (\"khanty-she-netjer\"), in which \"pavilion\" could refer either to the place where embalming was carried out or the pharaoh's burial chamber.\n\nIn the Osiris myth, Anubis helped Isis to embalm Osiris. Indeed, when the Osiris myth emerged, it was said that after Osiris had been killed by Set, Osiris's organs were given to Anubis as a gift. With this connection, Anubis became the patron god of embalmers; during the rites of mummification, illustrations from the \"Book of the Dead\" often show a wolf-mask-wearing priest supporting the upright mummy.\n\nBy the late pharaonic era (664–332 BC), Anubis was often depicted as guiding individuals across the threshold from the world of the living to the afterlife. Though a similar role was sometimes performed by the cow-headed Hathor, Anubis was more commonly chosen to fulfill that function. Greek writers from the Roman period of Egyptian history designated that role as that of \"psychopomp\", a Greek term meaning \"guide of souls\" that they used to refer to their own god Hermes, who also played that role in Greek religion. Funerary art from that period represents Anubis guiding either men or women dressed in Greek clothes into the presence of Osiris, who by then had long replaced Anubis as ruler of the underworld.\n\nOne of the roles of Anubis was as the \"Guardian of the Scales.\" The critical scene depicting the weighing of the heart, in the \"Book of the Dead\", shows Anubis performing a measurement that determined whether the person was worthy of entering the realm of the dead (the underworld, known as \"Duat\"). By weighing the heart of a deceased person against Ma'at (or \"truth\"), who was often represented as an ostrich feather, Anubis dictated the fate of souls. Souls heavier than a feather would be devoured by Ammit, and souls lighter than a feather would ascend to a heavenly existence.\n\nAnubis was one of the most frequently represented gods in ancient Egyptian art. In the early dynastic period, he was depicted in animal form, as a black wolf. Anubis's distinctive black color did not represent the coat of real wolves, but it had several symbolic meanings. First it represented \"the discolouration of the corpse after its treatment with natron and the smearing of the wrappings with a resinous substance during mummification\". Being the color of the fertile silt of the River Nile, to Egyptians black also symbolized fertility and the possibility of rebirth in the afterlife.\n\nLater in the Middle Kingdom Anubis was often portrayed as a wolf-headed human. An extremely rare depiction of him in fully human form was found in the tomb of Ramesses II in Abydos.\n\nAnubis is often depicted wearing a ribbon and holding a \"nekhakha\" \"flail\" in the crook of his arm. Another of Anubis's attributes was the Imiut fetish.\n\nIn funerary contexts, Anubis is shown either attending to a deceased person's mummy or sitting atop a tomb protecting it. New Kingdom tomb-seals also depict Anubis sitting atop the nine bows that symbolize his domination over the enemies of Egypt.\n\n\n\n", "id": "3027", "title": "Anubis"}
{"url": "https://en.wikipedia.org/wiki?curid=3029", "text": "Arthur Jensen\n\nArthur Robert Jensen (August 24, 1923 – October 22, 2012) was a professor of educational psychology at the University of California, Berkeley. Jensen was known for his work in psychometrics and differential psychology, which is concerned with how and why individuals differ behaviorally from one another.\n\nHe was a major proponent of the hereditarian position in the nature and nurture debate, the position that genetics play a significant role in behavioral traits, such as intelligence and personality. He was the author of over 400 scientific papers published in refereed journals and sat on the editorial boards of the scientific journals \"Intelligence\" and \"Personality and Individual Differences\".\n\nHe was rated as one of the 50 most eminent psychologists of the 20th century. He was also a controversial figure, largely for his conclusions regarding the causes of race-based differences in intelligence.\n\nJensen was born August 24, 1923, in San Diego, California, the son of Linda Mary (née Schachtmayer) and Arthur Alfred Jensen, who operated and owned a lumber and building materials company. His paternal grandparents were Danish immigrants and his mother was of half Polish Jewish and half German descent. He studied at University of California, Berkeley (B.A. 1945), San Diego State College (M.A., 1952) and Columbia University (Ph.D., 1956), and did his doctoral thesis with Percival Symonds on the Thematic Apperception Test: He published this work. From 1956 through 1958, he did postdoctoral research at the University of London, Institute of Psychiatry with Hans Eysenck.\n\nUpon returning to the United States, he became a researcher and professor at the University of California, Berkeley, where he focused on individual differences in learning, especially the influences of culture, development, and genetics on intelligence and learning. He received tenure at Berkeley in 1962 and was given his first sabbatical in 1964. He concentrated much of his work on the learning difficulties of culturally disadvantaged students. In 2003, he was awarded the Kistler Prize for original contributions to the understanding of the connection between the human genome and human society. In 2006, the International Society for Intelligence Research awarded Jensen its Lifetime Achievement Award.\n\nJensen has had a lifelong interest in classical music and was, early in his life, attracted by the idea of becoming a conductor himself. At 14, he conducted a band that won a nationwide contest held in San Francisco. Later, he conducted orchestras and attended a seminar given by Nikolai Sokoloff. Soon after graduating from Berkeley, he moved to New York, mainly to be near the conductor Arturo Toscanini. He was also deeply interested in the life and example of Gandhi, producing an unpublished book-length manuscript on his life. During Jensen's period in San Diego he spent time working as a social worker with the San Diego Department of Public Welfare.\n\nJensen's interest in learning differences directed him to the extensive testing of school children. The results led him to distinguish between two separate types of learning ability. \"Level I\", or associative learning, may be defined as retention of input and rote memorization of simple facts and skills. \"Level II\", or conceptual learning, is roughly equivalent to the ability to manipulate and transform inputs, that is, the ability to solve problems.\n\nLater, Jensen was an important advocate in the mainstream acceptance of the general factor of intelligence, a concept which was essentially synonymous with his \"Level II\" conceptual learning. The general factor, or \"g\", is an abstraction that stems from the observation that scores on all forms of cognitive tests correlate positively with one another.\n\nJensen claimed, on the basis of his research, that general cognitive ability is essentially an inherited trait, determined predominantly by genetic factors rather than by environmental conditions. He also contended that while associative learning, or memorizing ability, is equally distributed among the races, conceptual learning, or synthesizing ability, occurs with significantly greater frequency in whites than in non-whites.\n\nJensen's most controversial work, published in February 1969 in the \"Harvard Educational Review\", was titled \"How Much Can We Boost IQ and Scholastic Achievement?\" It concluded, among other things, that Head Start programs designed to boost African-American IQ scores had failed, and that this was likely never to be remedied, largely because, in Jensen's estimation, 80% of the variance in IQ in the population studied was the result of genetic factors and the remainder was due to environmental influences.\n\nThe work became one of—if not the most—cited papers in the history of psychological testing and intelligence research.\n\nAfter the paper was released, students and faculty staged large protests outside Jensen's U.C. Berkeley office. Jensen was denied reprints of his work by his publisher and was not permitted to reply in response to letters of criticism—both extremely unusual policies for their day.\nIn a later article, Jensen argued that his claims had been misunderstood:\n...nowhere have I \"claimed\" an \"innate deficiency\" of intelligence in blacks. My position on this question is clearly spelled out in my most recent book: \"The plain fact is that at present there exists no scientifically satisfactory explanation for the differences between the IQ distributions in the black and white populations. The only genuine consensus among well-informed scientists on this topic is that the cause of the difference remains an open question.\" (Jensen, 1981a, p. 213).\nAlthough a critic of Jensen's thesis, economist Thomas Sowell, criticizing the taboo against research on race and intelligence, wrote:\nProfessor Jensen pointed out back in 1969 that black children's IQ scores rose by 8 to 10 points after he met with them informally in a play room and then tested them again after they were more relaxed around him. He did this because \"I felt these children were really brighter than their IQ would indicate.\" What a shame that others seem to have less confidence in black children than Professor Jensen has had.\n\nHowever, Jensen's 1998 \"\" gives his position suggesting a genetic component is implicated in the white-black difference in IQ. In Chapter 12: Population Differences in \"g\": Causal Hypotheses, Jensen writes:\n\nThe relationship of the g factor to a number of biological variables and its relationship to the size of the white-black differences on various cognitive tests (i.e., Spearman's hypothesis) suggests that the average white-black difference in \"g\" has a biological component. Human races are viewed not as discrete, or Platonic, categories, but rather as breeding populations that, as a result of natural selection, have come to differ statistically in the relative frequencies of many polymorphic genes. The genetic distances between various populations form a continuous variable that can be measured in terms of differences in gene frequencies. Racial populations differ in many genetic characteristics, some of which, such as brain size, have behavioral and psychometric correlates, particularly \"g\".\nIn 1994 he was one of 52 signatories on \"Mainstream Science on Intelligence, \" an editorial written by Linda Gottfredson and published in the \"Wall Street Journal\", which declared the consensus of the signing scholars on the meaning and significance of IQ following the publication of the book \"The Bell Curve\".\n\nIn 2005, Jensen's article, co-written with J. Philippe Rushton, named \"Thirty Years of Research on Race Differences in Cognitive Ability\", was published in the APA journal \"Psychology, Public Policy and Law\". Jensen and Rushton present ten categories of evidence in support of the notion that IQ differences between whites and blacks are partly genetic in origin.\n\nHe died on October 22, 2012 at his home in Kelseyville, California at age 89.\n\nMelvin Konner wrote in the notes to his book \"The Tangled Wing: Biological Constraints on the Human Spirit\":\n\nStatements made by Arthur Jensen, William Shockley, and other investigators in the late 1960s and early 1970s about race and IQ or social class and IQ rapidly passed into currency in policy discussions. Many of these statements were proved wrong, but they had already influenced some policymakers, and that influence is very difficult to recant.\nMany studies that purport to be both science-based and attempt to influence public policy have been accused of scientific racism. Konner wrote:\nWhat of the latest currents of thought? Are they likely to lead to, or at least encourage, further distortions of social policy? The indications are not all encouraging. Richard Herrnstein and Charles Murray published a book in 1994 clearly directed at policy, just as Jensen and others had in the 1960s and 1970s. \"The Bell Curve: Intelligence and Class Structure in American Life\" (New York: Free Press 1994) teamed a psychologist with a conservative policy advocate to try to prove that both the class structure and the racial divide in the United States result from genetically determined differences in intelligence and ability.\n\nTheir general assertions about genes and IQ were not very controversial, but their speculations on race were something else again.\n\nBy 1994, the time of \"The Bell Curve\"'s publishing, Jensen had received $1.1 million from the Pioneer Fund,\nan organization frequently described as racist and \"white supremacist\" in nature.\nThe fund contributed a total of $3.5 million to researchers cited in The Bell Curve's most controversial chapter \"that suggests some races are naturally smarter than others\" with Jensen's works being cited twenty-three times in the book's bibliography.\n\nLisa Suzuki and Joshua Aronson of New York University claimed in 2005 that, unwaveringly for over 30 years, Jensen has largely ignored evidence that fails to support his position that IQ test score gaps represent a genetic racial hierarchy.\n\nPaleontologist and evolutionary biologist Stephen Jay Gould attacked Jensen's work in his 1981 book \"The Mismeasure of Man\". Gould writes that Jensen misapplies the concept of \"heritability\", which is defined as a measure of the variation of a trait due to inheritance \"within\" a population (Gould 1981: 127; 156-157). According to Gould, Jensen uses heritability to measure differences \"between\" populations. Gould also disagrees with Jensen's belief that IQ tests measure a real variable, \"g\", or \"the general factor common to a large number of cognitive abilities\" which can be measured along a unilinear scale.\n\nThis is a claim most closely identified with Charles Spearman. According to Gould, Jensen misunderstood the research of L. L. Thurstone to ultimately support this claim; Gould, however, argues that Thurstone's factor analysis of intelligence revealed \"g\" to be an illusion (1981: 159; 13-314). Gould criticizes Jensen's sources including his use of Catharine Cox's 1926 \"Genetic Studies of Genius\", which examines historiometrically the IQs of historic intellectuals after their deaths (Gould 1981: 153-154).\n\nIn 1980 Jensen published a detailed book in defense of the tests used to measure mental abilities, entitled \"Bias in Mental Testing\". Reviewing this book, psychologist Kenneth Kaye endorsed Jensen's distinction between bias and discrimination. The purpose of tests is to discriminate (that is, reveal actual differences) on the basis of ability; bias constitutes error. Jensen defined any test as biased for a particular group if that group differs significantly from the majority group in the slopes, intercepts, or standard error of the estimates of their regression lines. Most studies found no difference in the regression lines between black and white groups, but those differences that had been found to be biased had overpredicted rather than underpredicted the minority group's performance (for example, grades in Officer Candidate courses). Jensen's conclusion:\nUntil we find out what the relevant psychological predictors are for which racial classification per se is merely a 'stand-in' variable, we have no choice but to include race (or other group membership) as a predictive variable along with the test scores or other predictive measures. On the other hand, if the overprediction of the minority group's criterion performance is not too extreme, it may seem reasonable to many to leave it uncorrected, thereby giving the benefit of the slight predictive bias to the presumably disadvantaged group.\nPointing out that \"many of Jensen's opponents allowed their scientific conclusions to be far more biased by their political views than he did, Kaye quoted 18th-century David Hume: \"There is no Method of Reasoning more Common, and yet none more blameable, than in philosophical Debates, to endeavor the Refutation of any Hypothesis, by a Pretext of its dangerous Consequences to Religion and Morality.\"\n\nIn a 1982 review of \"The Mismeasure of Man\", Jensen gives point-by-point rebuttals to much of Gould's critique, including Gould's treatment of heritability, the \"reification\" of \"g\", and the use of Thurstone's analysis.\n\nIn Arthur Jensen's response to Gould's criticisms, in the paper titled \"The Debunking of Scientific Fossils and Straw Persons\"., Jensen begins his paper with this observation\nStephen Jay Gould is a paleontologist at Harvard's Museum of Comparative Zoology and offers a course at Harvard entitled, \"Biology as a Social Weapon.\" Apparently the course covers much the same content as does the present book. Having had some personal cause for interest in ideologically motivated attacks on biologically oriented behavioral scientists, I first took notice of Gould when he played a prominent role in a group called Science for the People and in that group's attack on the theories of Harvard zoologist Edward O. Wilson, a leader in the development of sociobiology...\nWhile Jensen recognizes the validity of some of Gould's claims, in many places, he criticizes Gould's general approach\nThis charge of a social, value-laden science undoubtedly contains an element of truth. In recent years, however, we recognize this charge as the keystone of the Marxist interpretation of the history of science.\nJensen adds that Gould made a number of misrepresentations, whether intentional or unintentional, while purporting to present Jensen's own positions\nIn his references to my own work, Gould includes at least nine citations that involve more than just an expression of Gould's opinion; in these citations Gould purportedly paraphrases my views. Yet in eight of the nine cases, Gould's representation of these views is false, misleading, or grossly caricatured. Nonspecialists could have no way of knowing any of this without reading the cited sources. While an author can occasionally make an inadvertent mistake in paraphrasing another, it appears Gould's paraphrases are consistently slanted to serve his own message.\nJensen expressed considerably greater praise of his frequent intellectual sparring partner, James R. Flynn:\nNow and then I am asked by colleagues, students, and journalists: who, in my opinion, are the most respectable critics of my position on the race-IQ issue? The name James R. Flynn is by far the first that comes to mind. His book, \"Race, IQ and Jensen\" (1980), is a distinguished contribution to the literature on this topic, and, among the critiques I have seen of my position, is virtually in a class by itself for objectivity, thoroughness, and scholarly integrity.\n\n\"\" (1998) is a book on the general intelligence factor (\"g\"). The book deals with the intellectual history of g and various models of how to conceptualize intelligence, and with the biological correlates of g, its heritability, and its practical predictive power.\n\n\"Clocking the Mind : Mental Chronometry and Individual Differences\" (2006) deals with mental chronometry (MC), and covers a variety of techniques for measuring the speed with which the brain processes information. Whereas IQ merely represents an interval (ranking) scale and thus possesses no true ratio scale properties, Jensen argues mental chronometry represents a true natural science of mental ability.\n\n\n\n\n", "id": "3029", "title": "Arthur Jensen"}
{"url": "https://en.wikipedia.org/wiki?curid=3032", "text": "A Funny Thing Happened on the Way to the Forum\n\nA Funny Thing Happened on the Way to the Forum is a musical with music and lyrics by Stephen Sondheim and book by Burt Shevelove and Larry Gelbart.\n\nInspired by the farces of the ancient Roman playwright Plautus (251–183 BC), specifically \"Pseudolus\", \"Miles Gloriosus\", and \"Mostellaria\", the musical tells the bawdy story of a slave named Pseudolus and his attempts to win his freedom by helping his young master woo the girl next door. The plot displays many classic elements of farce, including puns, the slamming of doors, cases of mistaken identity (frequently involving characters disguising themselves as one another), and satirical comments on social class. The title derives from a line often used by vaudeville comedians to begin a story: \"A funny thing happened on the way to the theater\".\n\nThe musical's original 1962 Broadway run won several Tony Awards, including Best Musical and Best Author (Musical). \"A Funny Thing\" has enjoyed several Broadway and West End revivals and was made into a successful film starring the original lead of the musical, Zero Mostel.\n\n\"A Funny Thing Happened on the Way to the Forum\" opened on Broadway on May 8, 1962, at the Alvin Theatre, and then transferred to the Mark Hellinger Theatre and the Majestic Theatre, where the show closed on August 29, 1964, after 964 performances and 8 previews.\n\nThe show's creators originally wanted Phil Silvers in the lead role of Pseudolus, but he turned them down, allegedly because he would have to perform onstage without his glasses, and his vision was so poor that he feared tripping into the orchestra pit. He is also quoted as turning down the role for being \"Sgt. Bilko in a toga\". (Silvers eventually played the role — wearing his glasses — in a 1972 revival. In the film, he played Marcus Lycus.) Milton Berle also passed on the role. Eventually, Zero Mostel was cast.\n\nDuring the out of town pre-Broadway tryouts the show was attracting little business and not playing well. Jerome Robbins was called in to give advice and make changes. The biggest change Robbins made was a new opening number to replace \"Love Is in the Air\" and introduce the show as a bawdy, wild comedy. Stephen Sondheim wrote the song \"Comedy Tonight\" for this new opening. From that point on, the show was a success.\n\nIt was directed by George Abbott and produced by Hal Prince, with choreography by Jack Cole and uncredited staging and choreography by Robbins. The scenic and costume design was by Tony Walton. This wardrobe is on display at the Costume World Broadway Collection in Pompano Beach, Florida. The lighting design was by Jean Rosenthal. Along with Mostel, the musical featured a cast of seasoned performers, including Jack Gilford (Mostel's friend and fellow blacklist member), David Burns, John Carradine, Ruth Kobart, and Raymond Walburn. The young lovers were played by Brian Davies and Preshy Marker. Karen Black, originally cast as the ingenue, was replaced out of town.\n\nThe show won several Tony Awards: Best Musical, Best Actor, Best Supporting Actor (Burns), Best Book, and Best Director. The score, however, was coolly received; it was Sondheim's first musical on Broadway in which he wrote both the music and lyrics, and did not earn a nomination for Best Original Score.\n\nThe show was presented two times in London's West End. The 1963 production and its 1986 revival were staged at the Strand Theatre and the Piccadilly Theatre respectively, and featured Frankie Howerd starring as Pseudolus, Kenneth Connor as Hysterium, 'Monsewer' Eddie Gray as Senex, Jon Pertwee as Marcus Lycus, and Leon Greene as Miles Gloriosus.\n\nIn 2004 there was a limited-run revival at the Royal National Theatre Olivier Theatre, starring Desmond Barrit as Pseudolus, Philip Quast as Miles Gloriosus, Hamish McColl as Hysterium and Isla Blair as Domina (who had previously played Philia in the 1963 production). This production was nominated for the 2005 Olivier Award, Outstanding Musical Production.\n\n\"A Funny Thing Happened on the Way to the Forum\" was made into a musical film in 1966, directed by Richard Lester, with Mostel and Gilford re-creating their Broadway stage roles, Leon Greene reprising his West End stage role, and Phil Silvers in an expanded role as \"Marcus Lycus\". David Burns did not return for the film role of Senex, which was played in the film by Michael Hordern. Buster Keaton made his final film appearance in the role of Erronius.\n\nA revival opened on Broadway at the Lunt-Fontanne Theatre on April 4, 1972 and closed on August 12, 1972 after 156 performances. Directed by co-author Burt Shevelove the cast starred Phil Silvers as Pseudolus (later replaced by Tom Poston), Lew Parker as Senex, Carl Ballantine as Lycus and Reginald Owen as Erronius. Larry Blyden, who played Hysterium, the role created by Jack Gilford, also co-produced. \"Pretty Little Picture\" and \"That'll Show Him\" were dropped from the show, and were replaced with \"Echo Song\" (sung by Hero and Philia), and \"Farewell\" (added for Nancy Walker as Domina, as she and Senex depart for the country). \"Echo Song\" and \"Farewell\" had been added to a production staged in Los Angeles the previous year and were composed by Sondheim. They had to close soon after Phil Silvers suffered a stroke. The show won two Tony Awards, Best Leading Actor in a Musical for Silvers, and Best Featured Actor in a Musical for Blyden.\n\nThe musical was revived again with great success in 1996, opening at the St. James Theatre on April 18, 1996 and closing on January 4, 1998 after 715 performances. The cast starred Nathan Lane as Pseudolus (replaced by Whoopi Goldberg and later by David Alan Grier), Mark Linn-Baker as Hysterium, Ernie Sabella as Lycus, Jim Stanek as Hero, Lewis J. Stadlen as Senex, and Cris Groenendaal as Miles Gloriosus. The production was directed by Jerry Zaks, with choreography by Rob Marshall. Lane won the 1996 Tony Award for Best Leading Actor and the Dramas Desk Award, Outstanding Actor in a Musical; the production was nominated for the 1996 Tony Award and Drama Desk Award, Revival of a Musical.\n\nEvery actor who has opened in the role of Pseudolus on Broadway (Zero Mostel, Phil Silvers, and Nathan Lane) has won a Best Leading Actor Tony Award for his performance. In addition, Jason Alexander, who performed as Pseudolus in one scene in \"Jerome Robbins' Broadway\", also won a Tony for Best Actor in a Musical.\n\nThe Stephen Sondheim Center for the Performing Arts produced a limited-run revival of the musical from January 11 to 27, 2008. The production was directed by Randal K. West, with Justin Hill as musical director and Adam Cates as choreographer. The cast featured Richard Kind as Pseudolus, Joel Blum as Senex, Stephen DeRosa as Marcus Lycus, Sean McCall as Hysterium, and Steve Wilson as Miles Gloriosus. It also featured Diana Upton-Hill, Ryan Gaffney, Stephen Mark Crisp, Jack Kloppenborg, and Margret Clair.\n\nThe Chung Ying Theatre Company in Hong Kong staged a Cantonese version of the musical at Kwai Tsing Theatre, to celebrate the company's 30th anniversary. It was directed by Chung King Fai and Ko Tin Lung and ran from 14 to 21 March 2009.\n\nThe Stratford Shakespeare Festival in Stratford, Ontario, Canada production ran from June 11 to November 7, 2009, with Des McAnuff directing and Wayne Cilento as choreographer. Bruce Dow originally performed the role of Pseudolus, but was forced to withdraw from the entire 2009 season due to an injury, and the role was then performed by Seán Cullen as of September 5, 2009. Stephen Ouimette played Hysterium. Mirvish Productions presented the earlier Stratford production at the Canon Theatre, Toronto, in December 2010 through January 2011. Bruce Dow and Sean Cullen were alternates in the lead role.\n\nIn October 2012 the play opened at Her Majesty's Theatre, Melbourne, Australia, with Geoffrey Rush as Pseudolus, Magda Szubanski as Domina and Shane Bourne as Senex. Stephen Sondheim came to Melbourne specifically to watch the show.\n\n\"A Funny Thing Happened on the Way to the Forum\" was produced at Two River Theater in Red Bank, New Jersey from November 14, 2015 to December 13, 2015. The production was performed by an all male cast (Paul Castree, Eddie Cooper, Kevin Isola, David Josefsberg, Max Kumangai, Graham Rowat, Manny Stark, Bobby Conte Thornton, David Turner, Michael Urie, Tom Deckman, and Christopher Fitzgerald).\n\nIn ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates).\n\nOne day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin). Pseudolus promises to help him win Philia's love in exchange for his own freedom. Unfortunately (as the two find out when they pay a visit on Lycus), Philia has been sold to the renowned warrior Miles Gloriosus, who is expected to claim her very soon. Pseudolus, an excellent liar, uses Philia's cheery disposition to convince Lycus that she has picked up a plague from Crete, which causes its victims to smile endlessly in its terminal stages. By offering to isolate her in Senex's house, he is able to give Philia and Hero some time alone together, and the two fall in love. But Philia insists that, even though she is in love with Hero, she must honor her contract with the Captain, for \"that is the way of a courtesan.\" To appease her, he tells her to wait (\"that's what virgins do best, isn't it?\") inside, and that he will have the captain knock three times when he arrives. Pseudolus comes up with a plan to slip Philia a sleeping potion that will render her unconscious. He will then tell Lycus that she has died of the Cretan plague, and will offer to remove the body. Hero will come along, and they will stow away on a ship headed for Greece. Satisfied with his plan, Pseudolus steals Hysterium's book of potions and has Hero read him the recipe for the sleeping potion; the only ingredient he lacks is \"mare's sweat\", and Pseudolus goes off in search of some.\n\nUnexpectedly, Senex returns home early from his trip, and knocks three times on his own door. Philia comes out of the house, and, thinking that Senex is the Captain, offers herself up to him. Surprised but game, Senex instructs Philia to wait in the house for him, and she does. Hysterium arrives to this confusion, and tells Senex that Philia is the new maid that he has hired. Pseudolus returns, having procured the necessary mare's sweat; seeing that Senex has returned unexpectedly and grasping the need to keep him out of the way, Pseudolus discreetly sprinkles some of the horse-sweat onto him, then suggests that the road trip has left Senex in dire need of a bath. Taking the bait, Senex instructs Hysterium to draw him a bath in the long-abandoned house of Erronius. But while this is happening, Erronius returns home, finally having given up the search for his long-lost children. Hysterium, desperate to keep him out of the house where his master is bathing, tells the old man that his house has become haunted – a story seemingly confirmed by the sound of Senex singing in his bath. Erronius immediately determines to have a soothsayer come and banish the spirit from his house, and Pseudolus obligingly poses as one, telling Erronius that, in order to banish the spirit, he must travel seven times around the seven hills of Rome (thus keeping the old man occupied and out of the way for quite a while).\n\nWhen Miles Gloriosus arrives to claim his courtesan-bride, Pseudolus hides Philia on the roof of Senex's house; told that she has \"escaped,\" Lycus is terrified to face the Captain's wrath. Pseudolus offers to impersonate Lycus and talk his way out of the mess but, his ingenuity flagging, he ends up merely telling the Captain that Philia has disappeared, and that he, \"Lycus\", will search for her. Displeased and suspicious, Miles insists that his soldiers accompany Pseudolus, but the wily slave loses them in Rome's winding streets.\n\nComplicating matters further, Domina returns from her trip early, suspicious that her husband Senex is \"up to something low.\" She disguises herself in virginal white robes and a veil (much like Philia's) to try to catch Senex being unfaithful. Pseudolus convinces Hysterium to help him by dressing in drag and pretending to be Philia, \"dead\" from the plague. Unfortunately, it turns out that Miles Gloriosus has just returned from Crete, where there is of course no actual plague. With the ruse thus revealed, the main characters run for their lives, resulting in a madcap chase across the stage with both Miles and Senex pursuing all three \"Philia\"s (Domina, Hysterium, and the actual Philia – all wearing identical white robes and veils). Meanwhile, the courtesans from the house of Marcus Lycus – who had been recruited as mourners at \"Philia\"'s ersatz funeral – have escaped, and Lycus sends his eunuchs out to bring them all back, adding to the general pandemonium.\n\nFinally, the Captain's troops are able to round everyone up. His plot thoroughly unraveled, Pseudolus appears to be in deep trouble – but Erronius, completing his third circuit of the Roman hills, shows up fortuitously to discover that Miles Gloriosus and Philia are wearing matching rings which mark them as his long-lost children. Philia's betrothal to the Captain is obviously nullified by the unexpected revelation that he's her brother. Philia weds Hero; Pseudolus gets his freedom and the lovely courtesan Gymnasia; Gloriosus receives twin courtesans to replace Philia; and Erronius is reunited with his children. A happy ending prevails for all – except for poor Senex, stuck with his shrewish wife Domina.\n\n\nAct I\n\nAct II\nNotes: \n\n\nNotes\nBibliography\n\n", "id": "3032", "title": "A Funny Thing Happened on the Way to the Forum"}
{"url": "https://en.wikipedia.org/wiki?curid=3034", "text": "Aleut\n\nThe Aleuts () (\"Aleut'y\"), who are usually known in the Aleut language by the endonym Unangax Унаңан (lit. \"people\", Unangan, singular), are the indigenous people of the Aleutian Islands.\n\nBoth the Unangax and the islands are divided between the US state of Alaska and the Russian administrative division of Kamchatka Krai.\n\nWhile English and Russian are the dominant languages used by Aleuts living in the United States and Russia respectively, the Aleut language is still spoken by an estimated 150 people in the United States and 5 people in Russia. The language belongs to the Eskimo-Aleut language family and includes three dialect groupings: Eastern Aleut, spoken on the Eastern Aleutian, Shumagin, Fox and Pribilof Islands; Atkan, spoken on Atka and Bering islands; and the now extinct Attuan dialect. The Pribilof Islands boast the highest number of active speakers of Aleutian. Most of the Native elders speak Aleut, but it is very rare for an everyday person to speak the language fluently.\n\nAleut was written in the Cyrillic script beginning in 1829. From 1870, the language was written in the Latin script. An Aleut dictionary and grammar have been published, and portions of the Bible were translated into Aleut.\n\nThe Aleut (Unangan) dialects and tribes:\n\n\nТhe Aleut (Unangax) people were distributed throughout the Aleutian Islands, the Shumagin Islands, and the far western part of the Alaska Peninsula, with an estimated population of around 25,000 before contact with Europeans. In the 1820s, the Russian-American Company administered a large portion of the North Pacific during a Russian-led expansion of the fur trade. They resettled many Aleut families to the Commander Islands (within the Aleutsky District of the Kamchatka Krai in Russia) and to the Pribilof Islands (in Alaska). These continue to have majority-Aleut communities.\n\nAccording to the 2000 Census, 11,941 people reported Aleut ancestry, while 17,000 said Aleuts were among their ancestors. Before major outside contact, there were approximately 25,000 Aleuts on the archipelago. In other words, this people suffered high fatalities in the 19th and early 20th centuries from Eurasian infectious diseases to which they had no immunity. In addition, the population suffered as traditional lifestyles were disrupted. According to the up-to-date Encyclopædia Britannica Online, \"Early 21st-century population estimates indicated more than 15,000 individuals of Aleut descent.\" Russian traders and later Europeans married Aleut women and had families with them.\n\nAfter the arrival of Russian Orthodox missionaries in the late 18th century, many Aleuts became Christian. Of the numerous Russian Orthodox congregations in Alaska, most are majority Alaska Native in ethnicity. One of the earliest Christian martyrs in North America was Saint Peter the Aleut.\n\nIn the 18th century, Russia \"promyshlenniki\" traders established settlements on the islands and exploited the people. There was a recorded revolt against Russian workers in Amchitka in 1784. It started when supplies ran out which the Russians had provided to local people in trade for their furs.\n\nThere was high demand for the furs that the Aleut provided from hunting. In 1811, in order to obtain more of the commercially valuable otter pelts, a party of Aleut hunters traveled to the coastal island of San Nicolas, near the Alta California-Baja California border. The locally resident Nicoleño nation sought a payment from the Aleut hunters for the large number of otters being killed in the area. Disagreement arose, turning violent; in the ensuing battle, the Aleut killed nearly all the Nicoleño men. Together with high fatalities from European diseases, the Nicoleños suffered so much from the loss of their men that by 1853, only one living Nicoleña person remained. (See Juana Maria, \"The Lone Woman of San Nicolas\", also known as Karana)\nPrior to major influence from outside, there were approximately 25,000 Aleuts on the archipelago. Foreign diseases, harsh treatment and disruption of traditional society soon reduced the population to less than one-tenth this number. The 1910 Census count showed 1,491 Aleuts. In the 2000 Census, 11,941 people identified as being Aleut; nearly 17,000 said Aleuts were among their ancestors. Alaskans generally recognize that the Russian occupation, while the colonists were limited in number, resulted in few full-blooded Aleuts today. Full-blooded Aleuts still exist and are growing in number, and there are also people who may be part Russian or other descent but solely identify as Aleut.\n\nIn 1942, during World War II, Japanese forces occupied Attu and Kiska Islands in the western Aleutians. They later transported captive Attu Islanders to Hokkaidō, where they were held as prisoners of war. The United States government evacuated hundreds more Aleuts from the western chain and the Pribilofs during WWII, placing them in internment camps in southeast Alaska, where many died. The Aleut Restitution Act of 1988 was an attempt by Congress to compensate the survivors.\n\nThe World War II campaign by the United States to retake Attu and Kiska was a significant component of the operations in the Pacific theater.\n\nIn May 1784, local Aleut revolted on Amchitka against the Russian traders. The Russians had a small trading post there. According to what Aleut people said, in an account recorded by Japanese castaways and published in 2004, otters were decreasing year by year. Their share in the return for the furs they made also were decreasing, as Russian ships stopped coming to the island. The Japanese learned that the Aleut felt the situation was at crisis. The leading Aleuts negotiated with the Russians, saying they had failed to deliver enough supplies in return for furs. Nezimov, leader of the Russians ordered two of his men, Stephano (ステッパノ) and Kazhimov (カジモフ) to kill his mistress Oniishin (オニイシン), who was the Aleut chief's daughter, because he doubted that Oniishin had tried to dissuade her father and other leaders from pushing for more goods.\n\nThat evening, hundreds of Aleut men gathered on a mountain and marched to the Russians' houses. When five Russians opened fire, the Aleuts ran away. The next day the Aleut returned, but escaped again when the Russians started firing. While the men attempted another attack the next day, they yelled and moved more quickly towards the house. As Russians opened fire, they started to run away again. After they ran, Russians noticed that all the men had left the village. The Russians took around 40 women and children hostage, forcing the Aleut to surrender. The Russians killed four Aleut leaders.\n\nAfter they had been killed, the Aleut began to move from Amchitka to neighboring islands.\nNevizimov, leader of the Russian group, was jailed after the whole incident was reported to Russian officials. (According to , written by Katsuragawa Hoshū after interviewing Daikokuya Kōdayū.)\n\nThe Aleut constructed partially underground houses called \"barabara\". According to Lillie McGarvey, a 20th-century Aleut leader, \"barabaras\" keep \"occupants dry from the frequent rains, warm at all times, and snugly sheltered from the high winds common to the area\". Aleuts traditionally built houses by digging an oblong square pit in the ground, usually or smaller. The pit was then covered by a roof framed with driftwood, thatched with grass, then covered with earth for insulation. Inside benches were placed along the sides, with a hearth in the middle. The bedrooms were at the back of the lodge, opposite the entrance.\n\nThe Aleut survived by hunting and gathering. They fished for salmon, crabs, shellfish, and cod, as well as harvesting sea mammals such as seal, walrus and whales. The fish and sea animals were processed in a variety of ways: dried, smoked or roasted. Caribou, musk oxen, deer, moose, whale and other types of game were eaten roasted or preserved for later use. Berries were dried. They were also processed as \"alutiqqutigaq\", a mixture of berries, fat and fish. The boiled skin and blubber of a whale was a delicacy, as was walrus.\nToday many Aleut continue to eat their traditional foods, but also buy the processed foods from Outside, which are very expensive in Alaska.\n\nTraditional arts of the Aleut include weapon-making, building of \"baidarkas\" (special hunting boats), weaving, figurines, clothing, carving, and mask making. Men as well as women often carved ivory and wood. 19th-century craftsmen were famed for their ornate wooden hunting hats, which feature elaborate and colorful designs and may be trimmed with sea lion whiskers, feathers, and ivory. Andrew Gronholdt of the Shumagin Islands has played a vital role in reviving the ancient art of building the \"chaguda-x\" or traditional bentwood hats.\n\nAleut women sewed finely stitched waterproof parkas from seal gut, and wove fine baskets from dune wildrye grass or \"Elymus mollis\". Some women continue to make baskets in this way. Aleut arts are practiced and taught throughout the state of Alaska. As many Aleut have moved out of the islands to other parts of the state, they have taken with them the knowledge of their arts. They have also adopted new materials and methods for their art.\n\nThe Aleut carved work, distinct in each region, has attracted traders for centuries, including early Europeans and other Alaska Natives. Historically carving was a male art and leadership attribute; in today’s world it is an art of both sexes. Most commonly the carvings of ivory and wood originated as part of making hunting weapons. Other carvings depicted the animals of their world, which were so important: such as seals and whales. They also depicted humans.\n\nThe Aleut also carve walrus ivory for other uses, such as jewelry and sewing needles. Jewelry is made with designs specific to the region of each people. Each clan would have a specific style to signify their origin. Jewelry ornaments were made for piercing lips (labrum), nose, and ears, as well as for necklaces. Each woman had her own sewing needles, which she made, and that often had detailed end of animal heads.\n\nThe main Aleut method of basketry was false embroidery (overlay). Strands of grasses or reeds were overlaid upon the basic weaving surface, to obtain a plastic effect. Basketry was an art reserved for women. Early Aleut women created baskets and woven mats of exceptional technical quality, using only their thumbnail, grown long and then sharpened, as a tool. Today, Aleut weavers continue to produce woven grass pieces of a remarkable cloth-like texture, works of modern art with roots in ancient tradition. Birch bark, puffin feathers, and baleen are also commonly used by the Aleut in basketry. The Aleut term for grass basket is \"qiigam aygaaxsii\". One Aleut leader recognized by the State of Alaska for her work in teaching and reviving Aleut basketry was Anfesia Shapsnikoff. Her life and accomplishments are portrayed in the book \"Moments Rightly Placed\"(1998).\n\nMasks were created to portray figures of their myths and oral history. The Atka people believed that another people lived in their land before them. They portrayed such ancients in their masks, which show anthropomorphic creatures named in their language. Knut Bergsland says their word means “like those found in caves.” Masks were generally carved from wood and were decorated with paints made from berries or other natural products. Feathers were inserted into holes carved out for extra decoration. These masks were used in ceremonies ranging from dances to praises, each with its own meaning and purpose.\n\nThe tattoos and piercings of the Aleut people demonstrated accomplishments as well as their religious views. They believed their body art would please the spirits of the animals and make any evil go away. The body orifices were believed to be pathways for the entry of evil entities. By piercing their orifices: the nose, the mouth, and ears, they would stop evil entities, \"khoughkh\", from entering their bodies (Osborn, 52). Body art also enhanced their beauty, social status, and spiritual authority.\n\nBefore the 19th century, piercings and tattoos were very common among the Aleut people, especially among women. Piercings, such as the nose pin, were common among both men and women and were usually performed a few days after birth. The ornament was made of various materials, a piece of bark or bone, or an eagle’s feather shaft. From time to time, adult women decorated the nose pins by hanging pieces of amber and coral from strings on it; the semi-precious objects dangled down to their chins.\n\nPiercing ears was also very common. The Aleuts pierced holes around the rim of their ears with dentalium shells (tooth shells or tusk shells), bone, feathers, dried bird wings or skulls and/or amber. Materials associated with birds were important, as birds were considered to defend animals in the spirit world. A male would wear sea lion whiskers in his ears as a trophy of his expertise as a hunter. Worn for decorative reasons, and sometimes to signify social standing, reputation, and the age of the wearer, Aleuts would pierce their lower lips with walrus ivory and wear beads or bones. The individual with the most piercings held the highest respect.\n\nTattooing for women began when they reached physical maturity, or menstruation, at about age 20. Men traditionally received their first tattoo after killing their first animal, another rite of passage. Sometimes tattoos signaled social class. For example, the daughter of a rich, famous ancestor or father would work hard at her tattoos to show the accomplishments of that ancestor or father. They would sew, or prick, different designs on the chin, the side of the face, or under the nose.\n\nThe Russians arrived in the Aleutian Islands in 1786 and were active there, with small trading settlements and religious missions, through the mid-19th century. They often enslaved the natives, forcing them to work for them. Their influence disrupted Aleut life, and many of the traditional customs disappeared.\n\nThe Aleut people developed in one of the harshest climates in the world, and learned to create and protect warmth. Both men and women wore parkas that extended below the knees. The women wore the skin of seal or sea-otter, and the men wore bird skin parkas, the feathers turned in or out depending on the weather. When the men were hunting on the water, they wore waterproof parkas made from seal or sea-lion guts, or the entrails of bear, walrus, or whales. Parkas had a hood that could be cinched, as could the wrist openings, so water could not get in. Men wore breeches made from the esophageal skin of seals. Children wore parkas made of downy eagle skin with tanned bird skin caps. They called these parkas \"kameikas,\" meaning raingear in the English language.(Aleut Corp. Web.).\n\nSea-lions, harbor seals, and the sea otters are the most abundant marine mammals. The men brought home the skins and prepared them by soaking them in urine and stretching them. The women undertook the sewing (\"Enthnohistory:\" Gross & Khera pg. 32). Preparation of the gut for clothing involved several steps. The prepared intestines were turned inside out. A bone knife was used to remove the muscle tissue and fat from the walls of the intestine. The gut was cut and stretched, and fastened to stakes to dry. It was then cut and sewn to make waterproof parkas, bags, and other receptacles (Turner, Ch. 5, pg. 70). On some hunting trips, the men would take several women with them. They would catch birds and prepare the carcasses and feathers for future use. They caught Puffins, Lunda Cirrhata, Fratercula Corniculata, Guillemots, and Cephus & Murres.\n\nIt took 40 skins of tufted puffin and 60 skins of horned puffin to make one parka. A woman would need a year for all the labor to make one parka. Each lasted two years with proper care. All parkas were decorated with bird feathers, beard bristles of seal and sea-lion, beaks of sea parrots, bird claws, sea otter fur, dyed leather, and caribou hair sewn in the seams. (Gross & Khera, pg. 34).\n\nWomen made needles from the wingbones of seabirds. They made thread from the sinews of different animals and fish guts. A thin strip of seal intestine could also be used, twisted to form a thread. The women grew their thumbnail extra long and sharpened it. They could split threads to make them as fine as a hair. They used vermilion paint, hematite, the ink bag of the octopus, and the root of a kind of grass or vine to color the threads.\n\nThe interior regions of the rough, mountainous Aleutian Islands provided little in terms of natural resources for the Aleutian people. They collected stones for weapons, tools, stoves or lamps. They collected and dried grasses for their woven baskets. For everything else, the Aleuts had learned to use the fish and mammals they caught and processed to satisfy their needs.\n\nIn order to hunt sea mammals and to travel between islands, the Aleuts became experts of sailing and navigation. While hunting, they used small watercraft called \"baidarkas.\" For regular travel, they used their large baidaras. \nThe baidara was a large, open, walrus-skin-covered boat. Aleut families used it when traveling among the islands. It was also used to transport goods for trade, and warriors took them to battle.\n\nThe baidarka (small skin boat) was a small boat covered in sea lion skin. It was developed and used for hunting because of its sturdiness and maneuverability. The Aleut baidarka resembles that of a Yup'ik kayak, but it is hydrodynamically sleeker and faster. They made the baidarka for one or two persons only. The deck was made with a sturdy chamber, the sides of the craft were nearly vertical and the bottom was rounded. Most one-man baidarkas were about feet long and wide, whereas a two-man was on average about long and wide. It was from the baidarka that Aleut men would stand on the water to hunt from the sea.\n\nThe Aleuts hunted small sea mammals with barbed darts and harpoons slung from throwing boards. These boards gave precision as well as some extra distance to these weapons.\n\nHarpoons were also called throwing-arrows when the pointed head fit loosely into the socket of the foreshaft and the head was able to detach from the harpoon when it penetrated an animal, and remain in the wound. There were three main kinds of harpoon that the Aleut’s used: a simple harpoon, with a head that kept its original position in the animal after striking, a compound (toggle-head) harpoon in which the head took a horizontal position in the animal after penetration, and the throwing-lance used to kill large animals.\n\nThe simple Aleut harpoon consisted of four main parts: the wooden shaft, the bone foreshaft, and the bonehead (tip) with barbs pointed backward. The barbed head was loosely fitted into the socket of the foreshaft so that when the animal was stabbed, it pulled the head away from the rest of the harpoon. The sharp barbs penetrated with ease, but could not be pulled out. The bone tip is fastened to a length of braided twine meanwhile; the hunter held the other end of the twine in his hand.\n\nThe compound harpoon was the most prevalent weapon of the Aleut people. Also known as the toggle-head spear, it was about the same size as the simple harpoon and used to hunt the same animals, however, this harpoon provided a more efficient and lethal weapon. This harpoon separated into four parts. The longest part was the shaft with the thicker stalk closer to the tip of the harpoon. The shaft was fitted into the socket of the fore shaft and a bone ring was then placed over the joint to hold the two pieces together, as well as, protecting the wooden shaft from splitting. Connected to the fore shaft of the harpoon is the toggle head spear tip. This tip was made of two sub shafts that break apart on impact with an animal. The upper sub shaft held the razor stone head and attached to the lower sub shaft with a small braided twine loop. Once the tip penetrates the animal the upper sub head broke off from the rest of the shaft, however, since it was still connected with the braided loop it rotated the head into a horizontal position inside the animal’s body so that it could not get away from the hunter.\n\nThe throwing lance may be distinguished from a harpoon because of the fact that all its pieces are fixed and immovable. A lance was a weapon of war and it was also used to kill large marine animals after it has already been harpooned. The throwing lance usually consisted of three parts: a wooden shaft, a bone ring or belt, and the compound head that was made with a barbed bonehead and a stone tip. The length of the compound head was equivalent to the distance between the planes of a man’s chest to his back. The lance would penetrate the chest and pass through the chest cavity and exit from the back. The bone ring was designed to break after impact so that the shaft could be used again for another kill.\n\nThey buried their dead ancestors near the village.\nArcheologists have found many different types of burials, dating from a variety of periods, in the Aleutian Islands. The Aleut developed a style of burials that were accommodated to local conditions, and honored the dead. They have had four main types of burials: \"umqan\", cave, above-ground sarcophagi, and burials connected to communal houses.\n\nUmqan burials are the most widely known type of mortuary practice found in the Aleutian Islands. The people created burial mounds, that tend to be located on the edge of a bluff. They placed stone and earth over the mound to protect and mark it. Such mounds were first excavated by archeologists in 1972 on Southwestern Unmak Island, and dated to the early contact period. Researchers have found a prevalence of these umqan burials, and concluded it is a regional mortuary practice. It may be considered a pan-Aleutian mortuary practice.\n\nCave burials have been found throughout the Eastern Aleutian Islands. The human remains are buried in shallow graves at the rear of the cave. These caves tend to be located next to middens and near villages. Some grave goods have been found in the caves associated with such burials. For example, a deconstructed boat was found in a burial cave on Kanaga Island. There were no other major finds of grave goods in the vicinity.\n\nThroughout the Aleutian Islands, gravesites have been found that are above-ground sarcophagi. These sarcophagi are left exposed, with no attempt to bury the dead in the ground. These burials tend to be isolated and limited to the remains of adult males, which may indicate a specific ritual practice. In the Near Islands, isolated graves have also been found with the remains, and not just the sarcophagus, left exposed on the surface. This way of erecting sarcophagi above ground is not as common as umqan and cave burials, but it is still widespread.\n\nAnother type of practice has been to bury remains in areas next to the communal houses of the settlement. Human remains are abundant in such sites. They indicate a pattern of burying the dead within the main activity areas of the settlement. These burials consist of small pits adjacent to the houses and scattered around them. In these instances, mass graves are common for women and children. This type of mortuary practice has been mainly found in the Near Islands.\n\nIn addition to these four main types, other kinds of burials have been found in the Aleutian Islands. These more isolated examples include mummification, private burial houses, abandoned houses, etc. To date, such examples are not considered to be part of a larger, unifying tradition. The findings discussed represent only the sites that have been excavated.\n\nThe variety of mortuary practices mostly did not included the ritual of including extensive grave goods, as has been found in other cultures. The remains so far have been mainly found with other human and faunal remains. The addition of objects to \"accompany\" the dead is rare. Archaeologists have been trying to dissect the absence of a great tradition of grave goods, but findings have been ambiguous and do not really help the academic community to understand these practices more.\n\nNot much information is known about the ritual parts of burying the dead. Archeologists and anthropologists have not found much evidence related to burial rituals. This lack of ritual evidence could hint at either no ritualized ceremony, or one that has not yet been revealed in the archaeological record. As a result, archaeologists cannot decipher the context to understand exactly why a certain type of burial was used in particular cases.\n\n\n", "id": "3034", "title": "Aleut"}
{"url": "https://en.wikipedia.org/wiki?curid=3035", "text": "Alaska Native Claims Settlement Act\n\nThe Alaska Native Claims Settlement Act (ANCSA) was signed into law by President Richard Nixon on December 18, 1971, constituting at the time the largest land claims settlement in United States history. ANCSA was intended to resolve long-standing issues surrounding aboriginal land claims in Alaska, as well as to stimulate economic development throughout Alaska. \n\nThe settlement established Alaska Native claims to the land by transferring titles to twelve Alaska Native regional corporations and over 200 local village corporations. A thirteenth regional corporation was later created for Alaska Natives who no longer resided in Alaska. The act is codified as 43 U.S.C. 1601 et seq.\n\nWhen Alaska became a state in 1959, section 4 of the Alaska Statehood Act provided that any existing Alaska Native land claims would be unaffected by statehood and held in status quo. Yet while section 4 of the act preserved Native land claims until later settlement, section 6 allowed for the state government to claim lands deemed vacant. Section 6 granted the state of Alaska the right to select lands then in the hands of the federal government, with the exception of Native territory. As a result, nearly from the public domain would eventually be transferred to the state. The state government also attempted to acquire lands under section 6 of the Statehood Act that were subject to Native claims under section 4, and that were currently occupied and used by Alaska Natives. The federal Bureau of Land Management began to process the Alaska government's selections without taking into account the Native claims and without informing the affected Native groups.\n\nIt was against this backdrop that the original language for a land claims settlement was developed. \n\nA 9.2-magnitude earthquake struck the state in 1964. Recovery efforts drew the attention of the federal government, which found that Alaska Natives had the poorest living conditions in the country. The Federal Field Committee for Development Planning in Alaska decided that Natives should receive $100 million and the 10% revenue royalty. Nothing was done with this proposal, however, and a freeze on land transfers remained in effect. \n\nIn 1968, Governor Walter Hickel summoned a group of Native leaders to work out a settlement that would be satisfactory to Natives. The group met for ten days and asked for $20 million in exchange for requested lands. They also asked for 10% of federal mineral lease revenue.\n\nIn 1969 President Nixon appointed Hickel as Secretary of the Interior. The Alaska Federation of Natives (AFN) protested against Hickel’s nomination, but he was eventually confirmed.\n\nHickel worked with the AFN, negotiating with Native leaders and state government over the disputed lands. Offers went back and forth, with each rejecting the other’s proposals. The AFN wanted rights to land, while then Governor Keith Miller believed Natives did not have legitimate claims to state land in light of the provisions of the Alaska Statehood Act. \n\nBut a succeeding Alaska state administration under Governor William A. Egan would stake out positions upon which the AFN and other stakeholders could largely agree. Native leaders, in addition to the Alaska's congressional delegation and the state's newly elected Governor William A. Egan, eventually reached the basis for presenting an agreement to Congress. The proposed settlement terms faced challenges in both houses but found a strong ally in Senator Henry M. Jackson from Washington state. The most controversial issues that continued to hold up approval were methods for determining land selection by Alaska Natives and financial distribution.\n\nIn 1968, the Atlantic-Richfield Company discovered oil at Prudhoe Bay on the Arctic coast, catapulting the issue of land ownership into headlines. In order to lessen the difficulty of drilling at such a remote location and transporting the oil to the lower 48 states, the oil companies proposed building a pipeline to carry the oil across Alaska to the port of Valdez At Valdez, the oil would be loaded onto tankers and shipped to the contiguous states. The plan had been approved, but a permit to construct the pipeline, which would cross lands involved in the land claims dispute, could not be granted until the Native claims were settled.\n\nWith major petroleum dollars on the line, pressure mounted to achieve a definitive legislative resolution at the federal level. In 1971, the Alaska Native Claims Settlement Act was signed into law by President Nixon. It abrogated Native claims to aboriginal lands except those that are the subject of the law. In return, Natives received up to of land and were paid $963 million. The land and money were to be divided among regional, urban, and village tribal corporations established under the law, often recognizing existing leadership.\n\nIn 1971, barely one million acres of land in Alaska was in private hands. ANCSA, together with section 6 of Alaska Statehood Act, which the new act allowed to come to fruition, affected ownership to about of land in Alaska once wholly controlled by the federal government. That is larger by than the combined areas of Maine, Vermont, New Hampshire, Massachusetts, Rhode Island, Connecticut, New York, New Jersey, Pennsylvania, Delaware, Maryland and Virginia.\n\nWhen the bill passed in 1971, it included provisions that had never been attempted in United States settlements with Native Americans. The newly passed Alaska Native Claims Settlement Act created twelve Native regional economic development corporations. Each corporation was associated with a specific region of Alaska, and the Natives who had traditionally lived there. This innovative approach to native settlements engaged the tribes in corporate capitalism. \n\nThe idea originated with the AFN, who believed that the Natives would have to become a part of the capitalist system in order to survive. As stockholders in these corporations, the Natives could earn some income and stay in their traditional villages. If the corporations were managed properly, they could make profits that would enable individuals to stay, rather than having to leave Native villages to find better work. This was intended to help preserve Native culture.\n\nAlaska Natives had three years from passage of ANCSA to make land selections of the granted under the act. In some cases Native corporations received outside aid in surveying the land. For instance, Doyon, Limited (one of the 13 regional corporations) was helped by the Geophysical Institute of the University of Alaska. The Institute determined which land contained resources such as minerals and coal. NASA similarly provided satellite imagery to aid in Native corporations finding areas most suited for vegetation and their traditional subsistence culture. The imagery showed locations of caribou and moose, as well as forests with marketable timber. In total about were analyzed for Doyon. Natives were able to choose tens of thousands of acres of land rich with timber while Doyon used mineral analysis to attract businesses.\n\nThe state of Alaska to date has been granted approximately 85% or of the land claims it has made under ANCSA. The state is entitled to a total of under the terms of the Statehood Act. Originally the state had 25 years after passage of the Alaska Statehood Act to file claims under section 6 of the act with the Bureau of Land Management (BLM). Amendments to ANCSA extended that deadline until 1994, with the expectation that BLM would complete processing of land transfers subject to overlapping Native claims by 2009. Nonetheless, some Native and state selections under ANCSA remained unresolved as late as December 2014.\n\nThere was largely positive reaction to ANCSA, although not entirely. The act was supported by Natives as well as non-Natives, and likewise enjoyed bipartisan support. Natives were heavily involved in the legislative process, and the final draft of the act used many AFN ideas. \n\nSome Natives have argued that ANCSA has hastened cultural genocide of Alaska Natives. Some Natives critiqued ANCSA as an illegitimate treaty since only tribal leaders were involved and the provisions of the act were not voted on by indigenous populations. One native described it as a social and political experiment. Critics have also argued that Natives so feared massacre or incarceration that they offered no resistance to the act. \n\nOthers have argued that the settlement was arguably the most generous afforded by the United States to a Native group. They note that some of the largest and most profitable corporations in the state are the twelve created by ANCSA. Other critics attacked the act as \"Native welfare\" and such complaints continue to be expressed. \n\nThe corporation system has been critiqued, as in some cases stockholders have sold land to outside corporations that have leveled forests and extracted minerals. But supporters of the system argue that it has provided economic benefits for indigenous peoples that outweigh these problems.\n\n\nThe following thirteen regional corporations were created under ANCSA:\n\nAdditionally, most regions and some villages have created their own nonprofits providing social services and health care through grant funding and federal compacts. The objectives of these nonprofits are varied, but focus generally on cultural and educational activities. These include scholarships for Native students, sponsorship of cultural and artistic events, preservation efforts for Native languages, and protection of sites with historic or religious importance.\n\nANCSA created about 224 village and urban corporations. Below is a representative list of village and urban corporations created under ANCSA:\n\n\n\n\n", "id": "3035", "title": "Alaska Native Claims Settlement Act"}
{"url": "https://en.wikipedia.org/wiki?curid=3036", "text": "Adoptionism\n\nAdoptionism, sometimes called dynamic monarchianism, is a nontrinitarian theological doctrine which holds that Jesus was adopted as the Son of God at his baptism, his resurrection, or his ascension. According to Epiphanius's account of the Ebionites, the group believed that Jesus was chosen on account of his sinless devotion to the will of God.\n\nAdoptionism was declared heresy at the end of the 2nd century and was rejected by the Synods of Antioch and the First Council of Nicaea, which defined the orthodox doctrine of the Trinity and identified the man Jesus with the eternally begotten Son or Word of God in the Nicene Creed.\n\nIn \"The Orthodox Corruption of Scripture\", Bart D. Ehrman argues that Adoptionist theology may date back almost to the time of Jesus.\n\nDue to recorded predictions of the destruction of the temple, the Gospel of Mark is believed by many critical scholars to have been composed around or shortly after the fall of Jerusalem in AD 70 due to prophecies assumed to be \"ex postfacto\" regarding the destruction of the Second Temple, and critical scholarly consensus maintains that it was the first written gospel, though the earliest traditional consensus puts the Gospel of Matthew as the first of the canonical gospels. The phrase \"Son of God\" is not present in some early manuscripts at . Ehrman uses this omission to support the notion that the title \"Son of God\" is not used for Jesus until his baptism, and that Mark reflects an Adoptionist view. The words, \"Today I have begotten you,\" are omitted from Mark, however, and it is therefore generally believed to have less Adoptionist tendencies than the lost, non-canonical Gospel of the Hebrews.\n\nPaul's writings do not explicitly mention a virgin birth of Christ. Paul wrote that Jesus was \"born of a woman, born under the law\" and \"as to his human nature was a descendant of David\" in the Epistle to the Galatians and the Epistle to the Romans. Many interpreters, however, take his statements in Philippians 2 to imply that Paul believed Jesus to have existed as equal to God before his incarnation. states that God said, \"You are my son. Today I have begotten you\"; the latter phrase that may show Adoptionist tendencies. It is also almost a direct quote from .\n\nThe first known exponent of Adoptionism in the 2nd century is Theodotus of Byzantium. According to Hippolytus of Rome (\"Philosophumena\", VII, xxiii) Theodotus taught that Jesus was a man born of a virgin, according to the Council of Jerusalem, that he lived like other men, and was most pious; but that at his baptism in the Jordan the \"Christ\" came down upon the man Jesus in the likeness of a dove. (Luke 3:22 And the Holy Ghost descended in a bodily shape like a dove upon him, and a voice came from heaven, which said, Thou art my beloved Son; in thee I am well pleased. Luke 4:1 And Jesus being full of the Holy Ghost returned from Jordan, and was led by the Spirit into the wilderness,) Therefore, wonders (Greek \"dynameis\") were not wrought in him until the Spirit (which Theodotus called Christ) came down and was manifested in Him. (\"Philosophumena\", VII, xxiii) The belief was declared heretical by Pope Victor I.\n\nThe 2nd-century work Shepherd of Hermas also taught that Jesus was a virtuous man filled with the Holy Spirit and adopted as the Son. While the Shepherd of Hermas was popular and sometimes bound with the canonical scriptures, it didn't retain canonical status, if it ever had it.\n\nIn the 3rd century, Paul of Samosata, Patriarch of Antioch, promoted Adoptionism. He said Jesus had been a man who kept himself sinless and achieved union with God. His views, however, did not neatly fit in either of the two main forms of Monarchianism.\n\nSpanish Adoptionism was a theological position which was articulated in Umayyad and Christian-held regions of the Iberian peninsula in the 8th and 9th centuries. The issue seems to have begun with the claim of archbishop Elipandus of Toledo that – in respect to his human nature – Christ was \"adoptive\" Son of God. Another leading advocate of this Christology was Felix of Urgel. In Spain, Adoptionism was opposed by Beatus of Liebana, and in the Carolingian territories, the Adoptionist position was condemned by Pope Hadrian I, Alcuin of York, Agobard, and officially in Carolingian territory by the Council of Frankfurt (794).\n\nDespite the shared name of \"Adoptionism\" the Spanish Adoptionist Christology appears to have differed sharply from the Adoptionism of early Christianity. Spanish advocates predicated the term \"adoptivus\" of Christ only in respect to his humanity; once the divine Son \"emptied himself\" of divinity and \"took the form of a servant\" (Philippians 2:7), Christ's human nature was \"adopted\" as divine.\n\nHistorically, many scholars have followed the Adoptionists' Carolingian opponents in labeling Spanish Adoptionism as a minor revival of “Nestorian” Christology. John C. Cavadini has challenged this notion by attempting to take the Spanish Christology in its own Spanish/North African context in his study, \"The Last Christology of the West: Adoptionism in Spain and Gaul, 785–820\".\n\nA third wave was the revived form (\"Neo-Adoptionism\") of Peter Abelard in the 12th century. Later, various modified and qualified Adoptionist tenets emerged from some theologians in the 14th century. Duns Scotus (1300) and Durandus of Saint-Pourçain (1320) admit the term \"Filius adoptivus\" in a qualified sense. In more recent times the Jesuit Gabriel Vásquez, and the Lutheran divines Georgius Calixtus and Johann Ernst Immanuel Walch, have defended Adoptionism as essentially orthodox.\n\nA form of Adoptionism surfaced in Unitarianism during the 18th century as the virgin birth was increasingly denied by Unitarians . In the 19th century the term Psilanthropism, was applied by such as Samuel Taylor Coleridge who so called his own view that Jesus was the son of Joseph.\n\nA similar form of Adoptionism was expressed in the writings of James Strang, a Latter Day Saint leader who founded the Church of Jesus Christ of Latter Day Saints (Strangite) after the death of Joseph Smith in 1844. In his Book of the Law of the Lord, a purported work of ancient scripture found and translated by Strang, he offers an essay entitled \"Note on the Sacrifice of Christ\" in which he explains his unique (for Mormonism as a whole) doctrines on the subject. Jesus Christ, said Strang, was the natural-born son of Mary and Joseph, who was chosen from before all time to be the Savior of mankind, but who had to be born as an ordinary mortal of two human parents (rather than being begotten by the Father or the Holy Spirit) to be able to truly fulfill his Messianic role. Strang claimed that the earthly Christ was in essence \"adopted\" as God's son at birth, and fully revealed as such during the Transfiguration. After proving himself to God by living a perfectly sinless life, he was enabled to provide an acceptable sacrifice for the sins of men, prior to his resurrection and ascension.\n\nAdoptionism is one of two main forms of monarchianism (the other is modalism, which regards \"Father\" and \"Son\" as two historical or soteriological roles of a single divine Person). Adoptionism (also known as dynamic monarchianism) denies the eternal pre-existence of Christ, and although it explicitly affirms his deity subsequent to events in his life, many classical trinitarians claim that the doctrine implicitly denies it by denying the constant hypostatic union of the eternal Logos to the human nature of Jesus. Under Adoptionism Jesus is currently divine and has been since his adoption, although he is not equal to the Father, per \"my Father is greater than I\" (). and as such is a kind of subordinationism.\n\nAdoptionism was one position in a long series of Christian disagreements about the precise nature of Christ (see Christology) in the developing dogma of the Trinity, an attempt to explain the relationship between Jesus of Nazareth, both as man and God, and God the Father while confidently claiming to be uncompromisingly monotheistic. It differs significantly from the doctrine of the Trinity that was later affirmed by the ecumenical councils.\n\nSome scholars see Adoptionist concepts in the Gospel of Mark and in the writings of the Apostle Paul. According to this view, though Mark has Jesus as the Son of God, references occurring at the strategic points in 1:1 (\"The beginning of the gospel about Jesus Christ, the Son of God\", but not in all versions, see Mark 1), 5:7 (\"What do you want with me, Jesus, Son of the Most High God?\") and 15:39 (\"Surely this man was the Son of God!\"), the concept of the Virgin Birth of Jesus had not been developed or elucidated at the time of the writing of this early Christian text. By the time the Gospels of Luke and Matthew were written, Jesus is identified as being the Son of God from the time of birth. Finally, the Gospel of John portrays him as the pre-existent Word () as existing \"in the beginning\".\n\n\n\n", "id": "3036", "title": "Adoptionism"}
{"url": "https://en.wikipedia.org/wiki?curid=3037", "text": "Apollinarism\n\nApollinarism or Apollinarianism was a view proposed by Apollinaris of Laodicea (died 390) that Jesus could not have had a human mind; rather, Jesus had a human body and lower soul (the seat of the emotions) but a divine mind. \n\nThe Trinity had been recognized at the Council of Nicea in 325, but debate about exactly what it meant continued. A rival to the more common belief that Jesus Christ had two natures was monophysitism (\"one nature\"), the doctrine that Christ had only one nature. Apollinarism and Eutychianism were two forms of monophysitism. Apollinaris' rejection that Christ had a human mind was considered an over-reaction to Arianism and its teaching that Christ was not divine.\n\nTheodoret charged Apollinaris with confounding the persons of the Godhead and with giving in to the heretical ways of Sabellius. Basil of Caesarea accused him of abandoning the literal sense of the scripture, and taking up wholly with the allegorical sense. His views were condemned in a Synod at Alexandria, under Athanasius of Alexandria, in 362, and later subdivided into several different heresies, the main ones of which were the Polemians and the Antidicomarianites.\n\nIt was declared to be a heresy in 381 by the First Council of Constantinople, since Christ was officially depicted as fully human and fully God. Followers of Apollinarianism were accused of attempting to create a tertium quid (\"third thing,\" neither God nor man).\n\nApollinaris further taught, following Tertullian, that the souls of men were propagated by other souls, as well as their bodies (see traducianism). \n\nChristian philosopher William Lane Craig has proposed a neo-Apollinarian Christology in which the divine Logos completes the human nature of Christ. Craig says his proposal is tentative and he welcomes critique and interaction from other scholars.\n\n", "id": "3037", "title": "Apollinarism"}
{"url": "https://en.wikipedia.org/wiki?curid=3038", "text": "Acid–base reaction\n\nAn acid–base reaction is a chemical reaction that occurs between an acid and a base. Several theoretical frameworks provide alternative conceptions of the reaction mechanisms and their application in solving related problems; these are called acid–base theories, for example, Brønsted–Lowry acid–base theory. Their importance becomes apparent in analyzing acid–base reactions for gaseous or liquid species, or when acid or base character may be somewhat less apparent. The first of these concepts was provided by the French chemist Antoine Lavoisier, around 1776.\n\nThe first scientific concept of acids and bases was provided by Lavoisier in around 1776. Since Lavoisier's knowledge of strong acids was mainly restricted to oxoacids, such as (nitric acid) and (sulfuric acid), which tend to contain central atoms in high oxidation states surrounded by oxygen, and since he was not aware of the true composition of the hydrohalic acids (HF, HCl, HBr, and HI), he defined acids in terms of their containing \"oxygen\", which in fact he named from Greek words meaning \"acid-former\" (from the Greek οξυς (\"oxys\") meaning \"acid\" or \"sharp\" and γεινομαι (\"geinomai\") meaning \"engender\"). The Lavoisier definition was held as absolute truth for over 30 years, until the 1810 article and subsequent lectures by Sir Humphry Davy in which he proved the lack of oxygen in , HTe, and the hydrohalic acids. However, Davy failed to develop a new theory, concluding that \"acidity does not depend upon any particular elementary substance, but upon peculiar arrangement of various substances\". One notable modification of oxygen theory was provided by Berzelius, who stated that acids are oxides of nonmetals while bases are oxides of metals.\n\nIn 1838, Justus von Liebig proposed that an acid is a hydrogen-containing substance in which the hydrogen could be replaced by a metal. This redefinition was based on his extensive work on the chemical composition of organic acids, finishing the doctrinal shift from oxygen-based acids to hydrogen-based acids started by Davy. Liebig's definition, while completely empirical, remained in use for almost 50 years until the adoption of the Arrhenius definition.\n\nThe first modern definition of acids and bases in molecular terms was devised by Svante Arrhenius. A hydrogen theory of acids, it followed from his 1884 work with Friedrich Wilhelm Ostwald in establishing the presence of ions in aqueous solution and led to Arrhenius receiving the Nobel Prize in Chemistry in 1903.\n\nAs defined by Arrhenius:\n\nThis causes the protonation of water, or the creation of the hydronium (HO) ion. Thus, in modern times, the symbol H is interpreted as a shorthand for HO, because it is now known that a bare proton does not exist as a free species in aqueous solution.\nThe Arrhenius definitions of acidity and alkalinity are restricted to aqueous solutions, and refer to the concentration of the solvent ions. Under this definition, pure HSO and HCl dissolved in toluene are not acidic, and molten NaOH and solutions of calcium amide in liquid ammonia are not alkaline.\n\nOverall, to qualify as an Arrhenius acid, upon the introduction to water, the chemical must either cause, directly or otherwise:\n\nConversely, to qualify as an Arrhenius base, upon the introduction to water, the chemical must either cause, directly or otherwise:\n\nThe reaction of an acid with a base is called a neutralization reaction. The products of this reaction are a salt and water.\n\nIn this traditional representation an acid–base neutralization reaction is formulated as a double-replacement reaction. For example, the reaction of hydrochloric acid, HCl, with sodium hydroxide, NaOH, solutions produces a solution of sodium chloride, NaCl, and some additional water molecules.\n\nThe modifier (aq) in this equation is important. It was implied by Arrhenius, not included explicitly. It indicates that the substances are dissolved in water. In fact though all three substances, HCl, NaOH and NaCl are capable of existing as pure compounds, in aqueous solutions they are fully dissociated into the (aquated) ions H, Cl, Na and OH.\n\nThe Brønsted–Lowry definition, formulated in 1923, independently by Johannes Nicolaus Brønsted in Denmark and Martin Lowry in England, is based upon the idea of protonation of bases through the de-protonation of acids – that is, the ability of acids to \"donate\" hydrogen ions (H)—otherwise known as protons—to bases, which \"accept\" them.\n\nAn acid–base reaction is, thus, the removal of a hydrogen ion from the acid and its addition to the base. The removal of a hydrogen ion from an acid produces its \"conjugate base\", which is the acid with a hydrogen ion removed. The reception of a proton by a base produces its \"conjugate acid\", which is the base with a hydrogen ion added.\n\nUnlike the previous definitions, the Brønsted–Lowry definition does not refer to the formation of salt and solvent, but instead to the formation of \"conjugate acids\" and \"conjugate bases\", produced by the transfer of a proton from the acid to the base. In this approach, acids and bases are fundamentally different in behavior from salts, which are seen as electrolytes, subject to the theories of Debye, Onsager, and others. An acid and a base react not to produce a salt and a solvent, but to form a new acid and a new base. The concept of neutralization is thus absent. Brønsted–Lowry acid–base behavior is formally independent of any solvent, making it more all-encompassing than the Arrhenius model.\n\nThe general formula for acid–base reactions according to the Brønsted–Lowry definition is:\nwhere HA represents the acid, B represents the base, BH represents the conjugate acid of B, and A represents the conjugate base of HA.\n\nFor example, a Brønsted-Lowry model for the dissociation of hydrochloric acid (HCl) in aqueous solution would be the following:\n\nThe removal of H from the HCl produces the chloride ion, Cl, the conjugate base of the acid. The addition of H to the HO (acting as a base) forms the hydronium ion, HO, the conjugate acid of the base.\n\nWater is amphoteric—that is, it can act as both an acid and a base. The Brønsted-Lowry model explains this, showing the dissociation of water into low concentrations of hydronium and hydroxide ions:\n\nThis equation is demonstrated in the image below:\nHere, one molecule of water acts as an acid, donating an H and forming the conjugate base, OH, and a second molecule of water acts as a base, accepting the H ion and forming the conjugate acid, HO.\n\nAs an example of water acting as an acid, consider an aqueous solution of pyridine, CHN.\n\nIn this example, a water molecule is split into a hydrogen ion, which is donated to a pyridine molecule, and an hydroxide ion.\n\nIn the Brønsted-Lowry model, the solvent does not necessarily have to be water. For example, consider what happens when acetic acid, CHCOOH, dissolves in liquid ammonia.\n\nAn H ion is removed from acetic acid, forming its conjugate base, the acetate ion, CHCOO. The addition of an H ion to an ammonia molecule of the solvent creates its conjugate acid, the ammonium ion, NH.\n\nThe Brønsted–Lowry model calls hydrogen-containing substances (like HCl) acids. Thus, some substances, which many chemists considered to be acids, such as SO or BCl, are excluded from this classification due to lack of hydrogen. Gilbert N. Lewis wrote in 1938, \"To restrict the group of acids to those substances that contain hydrogen interferes as seriously with the systematic understanding of chemistry as would the restriction of the term oxidizing agent to substances containing oxygen.\" Furthermore, KOH and KNH are not considered Brønsted bases, but rather salts containing the bases OH and NH.\n\nThe hydrogen requirement of Arrhenius and Brønsted–Lowry was removed by the Lewis definition of acid–base reactions, devised by Gilbert N. Lewis in 1923, in the same year as Brønsted–Lowry, but it was not elaborated by him until 1938. Instead of defining acid–base reactions in terms of protons or other bonded substances, the Lewis definition defines a base (referred to as a \"Lewis base\") to be a compound that can donate an \"electron pair\", and an acid (a \"Lewis acid\") to be a compound that can receive this electron pair.\n\nFor example, boron trifluoride, BF is a typical Lewis acid. It can accept a pair of electrons as it has a vacancy in its octet. The fluoride ion has a full octet and can donate a pair of electrons. Thus\nis a typical Lewis acid, Lewis base reaction. All compounds of group 13 elements with a formula AX can behave as Lewis acids. Similarly, compounds of group 15 elements with a formula DY, such as amines, NR, and phosphines, PR, can behave as Lewis bases. Adducts between them have the formula XA←DY with a dative covalent bond, shown symbolically as ←, between the atoms A (acceptor) and D (donor). Compounds of group 16 with a formula DX may also act as Lewis bases; in this way, a compound like an ether, RO, or a thioether, RS, can act as a Lewis base. The Lewis definition is not limited to these examples. For instance, carbon monoxide acts as a Lewis base when it forms an adduct with boron trifluoride, of formula FB←CO\n\nAdducts involving metal ions are referred to as co-ordination compounds; each ligand donates a pair of electrons to the metal ion. The reaction\ncan be seen as an acid–base reaction in which a stronger base (ammonia) replaces a weaker one (water)\n\nThe Lewis and Brønsted–Lowry definitions are consistent with each other since the reaction\nis an acid–base reaction in both theories.\n\nOne of the limitations of the Arrhenius definition is its reliance on water solutions. Edward Curtis Franklin studied the acid–base reactions in liquid ammonia in 1905 and pointed out the similarities to the water-based Arrhenius theory. Albert F. O. Germann, working with liquid phosgene, , formulated the solvent-based theory in 1925, thereby generalizing the Arrhenius definition to cover aprotic solvents.\n\nGermann pointed out that in many solutions, there are ions in equilibrium with the neutral solvent molecules:\n\nFor example, water and ammonia undergo such dissociation into hydronium and hydroxide, and ammonium and amide, respectively:\n\nSome aprotic systems also undergo such dissociation, such as dinitrogen tetroxide into nitrosonium and nitrate, antimony trichloride into dichloroantimonium and tetrachloroantimonate, and phosgene into chlorocarboxonium and chloride:\n\nA solute that causes an increase in the concentration of the solvonium ions and a decrease in the concentration of solvate ions is defined as an \"acid\". A solute that causes an increase in the concentration of the solvate ions and a decrease in the concentration of the solvonium ions is defined as a \"base\".\n\nThus, in liquid ammonia, (supplying ) is a strong base, and (supplying ) is a strong acid. In liquid sulfur dioxide (), thionyl compounds (supplying ) behave as acids, and sulfites (supplying ) behave as bases.\n\nThe non-aqueous acid–base reactions in liquid ammonia are similar to the reactions in water:\n\nNitric acid can be a base in liquid sulfuric acid:\nThe unique strength of this definition shows in describing the reactions in aprotic solvents; for example, in liquid :\n\nBecause the solvent system definition depends on the solute as well as on the solvent itself, a particular solute can be either an acid or a base depending on the choice of the solvent: is a strong acid in water, a weak acid in acetic acid, and a weak base in fluorosulfonic acid; this characteristic of the theory has been seen as both a strength and a weakness, because some substances (such as and ) have been seen to be acidic or basic on their own right. On the other hand, solvent system theory has been criticized as being too general to be useful. Also, it has been thought that there is something intrinsically acidic about hydrogen compounds, a property not shared by non-hydrogenic solvonium salts.\n\nThis acid–base theory was a revival of oxygen theory of acids and bases, proposed by German chemist Hermann Lux in 1939, further improved by Håkon Flood circa 1947 and is still used in modern geochemistry and electrochemistry of molten salts. This definition describes an acid as an oxide ion () acceptor and a base as an oxide ion donor. For example:\n\nThis theory is also useful in the systematisation of the reactions of noble gas compounds, especially the xenon oxides, fluorides, and oxofluorides.\n\nMikhail Usanovich developed a general theory that does not restrict acidity to hydrogen-containing compounds, but his approach, published in 1938, was even more general than Lewis theory. Usanovich's theory can be summarized as defining an acid as anything that accepts negative species or donates positive ones, and a base as the reverse. This defined the concept of redox (oxidation-reduction) as a special case of acid–base reactions\n\nSome examples of Usanovich acid–base reactions include:\n\nIn 1963, Ralph Pearson proposed a qualitative concept known as Hard Soft Acid Base principle. later made quantitative with help of Robert Parr in 1984. 'Hard' applies to species that are small, have high charge states, and are weakly polarizable. 'Soft' applies to species that are large, have low charge states and are strongly polarizable. Acids and bases interact, and the most stable interactions are hard–hard and soft–soft. This theory has found use in organic and inorganic chemistry.\n\nThe reaction of a strong acid with a strong base is essentially a quantitative reaction. For example,\n\nIn this reaction both the sodium and chloride ions are spectators as the neutralization reaction,\ndoes not involve them. With weak bases addition of acid is not quantitative because a solution of a weak base is a buffer solution. A solution of a weak acid is also a buffer solution. When a weak acid reacts with a weak base an equilibrium mixture is produced. For example, adenine, written as AH can react with a hydrogen phosphate ion, .\n\nThe equilibrium constant for this reaction can be derived from the acid dissociation constants of adenine and of the dihydrogen phosphate ion.\n\nThe notation [X] signifies \"concentration of X\". When these two equations are combined by eliminating the hydrogen ion concentration, an expression for the equilibrium constant, \"K\" is obtained.\n\nAn acid–alkali reaction is a special case of an acid–base reaction, where the base used is also an alkali. When an acid reacts with an alkali salt (a metal hydroxide), the product is a metal salt and water. Acid–alkali reactions are also neutralization reactions.\n\nIn general, acid–alkali reactions can be simplified to\nby omitting spectator ions.\n\nAcids are in general pure substances that contain hydrogen cations () or cause them to be produced in solutions. Hydrochloric acid () and sulfuric acid () are common examples. In water, these break apart into ions:\n\nThe alkali breaks apart in water, yielding dissolved hydroxide ions:\n\n\n", "id": "3038", "title": "Acid–base reaction"}
{"url": "https://en.wikipedia.org/wiki?curid=3040", "text": "Abu al-Faraj al-Isfahani\n\n`Ali ibn al-Husayn ul-Iṣfahānī (), also known as Abu-l-Faraj or, in the West, as Abulfaraj (897–967) was an historian of Arab-Quraysh origin who is noted for collecting and preserving ancient Arabic lyrics and poems in his major work, the \"Kitāb al-Aghānī\".\nAbu al-Faraj al-Iṣfahānī was born in Isfahan, but spent his youth and made his early studies in Baghdad. He was a direct descendant of the last of the Umayyad caliphs, Marwan II, and was thus connected with the Umayyad rulers in al-Andalus, and seems to have kept up a correspondence with them and to have sent them some of his works. He became famous for his knowledge of early Arabian antiquities.\n\nHis later life was spent in various parts of the Islamic world, in Aleppo with its Hamdanid governor Sayf ad-Dawlah (to whom he dedicated the \"Book of Songs\"), in Ray with the Buwayhid vizier Ibn 'Abbad, and elsewhere.\n\nAlthough he wrote poetry, also an anthology of verses on the monasteries of Mesopotamia and Egypt, and a genealogical work, his fame rests upon his \"Book of Songs\" (Kitab al-Aghani).\n\n\"Kitab al-Aghani\" (\"Book of Songs\"), a twenty volumes work that relates the stories of composers, poets, and singers (both men and women), along with some of their anecdotes, from the oldest epoch of Arabic literature down to the 9th century. These stories are related through \"isnad\" channels. The poems were put to music, but the musical signs are no longer readable. Because of the accompanying biographical annotations on the authors and composers, the work is an important historical source. \nIt contains a mass of information as to the life and customs of the early Arabs, and is the most valuable authority we have for their pre-Islamic and early Islamic days.\n\n", "id": "3040", "title": "Abu al-Faraj al-Isfahani"}
{"url": "https://en.wikipedia.org/wiki?curid=3043", "text": "Alcobaça, Portugal\n\nAlcobaça () is a city and a municipality in Oeste Subregion, region Centro in Portugal, formerly included in the Estremadura Province. The city grew along the valleys of the rivers Alcoa and Baça, from which it derives its name. The municipality population in 2011 was 56,693, in an area of 408.14 km². The city proper has a population of 15,800 inhabitants.\n\nThe city of Alcobaça became notable after the first king of Portugal, Afonso Henriques, decided to build a church to commemorate the Conquest of Santarém from the Moors in 1147. The church later evolved into the Monastery of Alcobaça, one of the most magnificent gothic monuments in the country. In the church are the tombs of Pedro I of Portugal and his murdered mistress Inês de Castro. Over the centuries this monastery played an important role in shaping Portuguese culture.\n\nA few kilometers to the north of Alcobaça is the Monastery of Batalha, another gothic building constructed in memory of a different important battle, that of Aljubarrota. To the west of Alcobaça is the fishing village of Nazaré, now a popular resort town. To the south is the city of Caldas da Rainha and the medieval town of Óbidos. Also to the northeast is the town of Porto de Mós with its rebuilt castle.\n\nA town that only became notable in the 12th century when it was chosen as the future site of Portugal's largest church. In March 1147, the fledgling King Dom Afonso Henriques, defeated the Moors by capturing the city of Santarém. As a tribute to his victory he vowed to build a magnificent home for the Order of Cistercians. It took another 76 years before this task was completed. The monarchy continued to carry out further construction and 60 years later King Dinis built the main cloister. The Monastery was consecrated in 1262.\n\nThe church contains the tombs of Pedro I of Portugal and his murdered mistress Inês de Castro and with it the story of the tragic liaison between Pedro and Inês. Forced at an early age as a royal duty, he was to marry Constanza, the \"Infanta\" (Princess) of Castile, but died shortly after the marriage. Dom Pedro escape with his true love and later lived in the city of Coimbra. His father, King Afonso IV, believing that the family of Inês was a threat to his own kingdom had her murdered. Shortly after the death of his father Dom Pedro declared that he had married Inês in a prior secret ceremony in Bragança, and promptly took a gruesome revenge on the killers and exhumed her body. He presented the embalmed corpse at the court with a crown on her head and demanded that all his courtiers kneel and individually pay homage to her decomposed hand. Today, their ornate tombs face each other so that on Judgment Day his first sight would be of his beloved Inês.\n\nDuring the following centuries the monks from this monastery had a major influence on the development of Portuguese culture. Notably, in 1269 they were the first to give public lessons to their flock, and later they produced the first authoritative history on Portugal in a series of books. In 1810 the invading French pillaged the Abbey taking with them most of its most important treasures, including the noteworthy library. The items that remained were later stolen in 1834 during an anti-clerical riot and the banning of the religious Orders in Portugal.\n\nAdministratively, the municipality is divided into 13 civil parishes (\"freguesias\"):\n\nThe main feature of the city is essentially the monastery that proudly presents a long and sombre façade with 18th-century embellishments. This austerity is further emphasized in the cloisters with its apt name of \"Cloister of Silence\". In contrast within the Abbey is the massive kitchen with a running stream specially diverted to pass through as a supply of fresh water. The open area of the kitchen chimney is large enough to take a whole ox for roasting. The surround to the sacristy doorway is an outstanding example of Manueline decoration. In 1794, Lord Beckford visited the Abbey and commented that he found some 300 monks \"living in a very splendid manner\"!\n\nA few kilometers to the north of Alcobaça is another wondrous building constructed in memory of a different important battle, that of Aljubarrota in 1385, when Dom João I of Portugal defeated the Castilians and ensuring two hundred years of independence from the Castilian invaders. The construction of the Abbey at Batalha commenced in 1388 and was added to by various Portuguese Kings over these next two centuries. To the east of Batalha is the world-famous location of Fátima and a point of pilgrimage for the Roman Catholic religion due to the vision of the Virgin Mary in 1917 by three young children whilst tending their flock. To the west of Alcobaça is the well-known fishing village of Nazaré. Today, the village is now a small town and a popular holiday resort with most of its past and traditions having rapidly evaporated in the course of time. A very successful Portuguese feature film was made in the early 20th century that dramatically captured the primitive and dangerous life of these fishermen. Stoutly Catholic, the inhabitants have retained some of their past as can be still seen in their own particular style of costume. To the south is Caldas da Rainha and the quaint medieval town of Óbidos that is an attraction for any tourists that enjoys a true glimpse of the past. Also to the south is the town of Porto de Mós with its fanciful rebuilt castle. This town borders the Nature Reserve Parque Natural das Serras de Aire e Candeeiros. These 390 square kilometres of limestone-covered landscape is also known for its underground caverns. The best known being the Grutas de Mira de Aire can be visited and consists of tunnels, caverns with stalactites, stalagmites, lakes, and a music and light finale.\n\n\nAlcobaça is twinned with:\n\n\n", "id": "3043", "title": "Alcobaça, Portugal"}
{"url": "https://en.wikipedia.org/wiki?curid=3044", "text": "Amphisbaena\n\nThe amphisbaena (, plural: amphisbaenae) is a mythological, ant-eating serpent with a head at each end. The creature is alternatively called the amphisbaina, amphisbene, amphisboena, amphisbona, amphista, amfivena, amphivena, or anphivena (the last two being feminine), and is also known as the \"Mother of Ants\". Its name comes from the Greek words \"amphis\", meaning \"both ways\", and \"bainein\", meaning \"to go\". According to Greek mythology, the amphisbaena was spawned from the blood that dripped from the Gorgon Medusa's head as Perseus flew over the Libyan Desert with it in his hand, after which Cato's army then encountered it along with other serpents on the march. Amphisbaena fed off of the corpses left behind. The amphisbaena has been referred to by various poets such as Nicander, John Milton, Alexander Pope, Percy Bysshe Shelley, Alfred, Lord Tennyson, A. E. Housman and Allen Mandelbaum; as a mythological and legendary creature, it has been referenced by Lucan, Pliny the Elder, Isidore of Seville, and Thomas Browne, the last of whom debunked its existence.\n\nThis early description of the amphisbaena depicts a venomous, dual-headed snakelike creature. However, Medieval and later drawings often show it with two or more scaled feet, particularly chicken feet, and feathered wings. Some even depict it as a horned, dragon-like creature with a serpent-headed tail and small, round ears, while others have both \"necks\" of equal size so that it cannot be determined which is the rear head. Many descriptions of the amphisbaena say its eyes glow like candles or lightning, but the poet Nicander seems to contradict this by describing it as \"always dull of eye\". He also says: \"From either end protrudes a blunt chin; each is far from each other.\" Nicander's account seems to be referring to what is indeed called the Amphisbaenia.\n\nThe amphisbaena is said to make its home in the desert.\n\nIn ancient times, the supposedly dangerous amphisbaena had many uses in the art of folk medicine and other such remedies. It was said that expecting women wearing a live amphisbaena around their necks would have safe pregnancies; however, if one's goal was to cure ailments such as arthritis or the common cold, one should wear only its skin. By eating the meat of the amphisbaena, one could supposedly attract many lovers of the opposite sex, and slaying one during the full moon could give power to one who is pure of heart and mind. Lumberjacks suffering from cold weather on the job could nail its carcass or skin to a tree to keep warm, while in the process allowing the tree to be felled more easily.\n\nIn \"The Book of Beasts\", T.H. White suggests that the creature derives from sightings of the worm lizards of the same name. These creatures are found in the Mediterranean countries where many of these legends originated.\n\nIn John Milton's Paradise Lost, after the Fall and the return of Satan to Hell, some of the fallen angelic host are transformed into the amphisbaena, to represent the animal by which the Fall was caused, i.e. a snake. \n\n\n\n", "id": "3044", "title": "Amphisbaena"}
{"url": "https://en.wikipedia.org/wiki?curid=3045", "text": "Amyl alcohol\n\nAn amyl alcohol is any of 8 alcohols with the formula CHOH. A mixture of amyl alcohols (also called amyl alcohol) can be obtained from fusel alcohol. Amyl alcohol is used as a solvent and in esterfication, by which is produced amyl acetate and other important products. The name \"amyl alcohol\" without further specification applies to the normal (straight-chain) form, 1-pentanol.\n\nThese are the 8 structural isomers of alcohols with molecular formula CHO:\n\nThree of these alcohols, active amyl alcohol (2-methylbutan-1-ol), methyl (n) propyl carbinol (pentan-2-ol), and methyl isopropyl carbinol (3-methylbutan-2-ol), contain an asymmetric carbon atom and are therefore optically active.\n\nThe most important is isobutyl carbinol, the chief constituent of fermentation amyl alcohol and a constituent of fusel oil. It can be separated from fusel oil by either of two methods: shaking with strong brine solution and separating the oily layer from the brine layer; distilling it and collecting the fraction that boils between 125 and 140 °C.\n\nFurther purification is possible with this procedure: shaking the product with hot limewater, separating the oily layer, drying the product with calcium chloride, and distilling it, collecting the fraction boiling between 128 and 132 °C.\n\nIsobutyl carbinol can be synthesized from isobutanol by conversion into isovaleraldehyde, which is subsequently reduced to isobutyl carbinol by means of sodium amalgam. It is a colourless liquid of density 0.8247 g/cm³ (0 °C), boiling at 131.6 °C, slightly soluble in water, and easily dissolved in organic solvents. It has a characteristic strong smell and a sharp burning taste. Amyl alcohol has an oral LD50 of 200 mg/kg in mice, suggesting that it is significantly more toxic than ethanol. On passing the vapour through a red-hot tube, it decomposes into acetylene, ethylene, propylene, and other compounds. It is oxidized by chromic acid to isovaleraldehyde, and it forms addition compounds crystals with calcium chloride and tin(IV) chloride.\n\nThe other amyl alcohols may be obtained synthetically. Of these, tertiary butyl carbinol has been the most difficult to obtain, with the first reported synthesis in 1891 by L. Tissier using the reduction of a mixture of trimethyl acetic acid and trimethylacetyl chloride with sodium amalgam. It is a solid that melts at 48 to 50 °C and boils at 112.3 °C.\n", "id": "3045", "title": "Amyl alcohol"}
{"url": "https://en.wikipedia.org/wiki?curid=3046", "text": "Amyl nitrite\n\nAmyl nitrite is a chemical compound with the formula CHONO. A variety of isomers are known, but they all feature an amyl group attached to the nitrite functional group. The alkyl group is unreactive and the chemical and biological properties are mainly due to the nitrite group. Like other alkyl nitrites, amyl nitrite is bioactive in mammals, being a vasodilator, which is the basis of its use as a prescription medicine. As an inhalant, it also has a psychoactive effect, which has led to its recreational use with its smell being described as that of old socks or dirty feet. It is also referred to as banapple gas.\n\n\nThe term \"amyl nitrite\" encompasses several isomers. For example, a common form of amyl nitrite with the formula (CH)CHCHCHONO may be more specifically referred to as isoamyl nitrite. When the amyl group is a linear or normal (n) alkyl group, the resulting amyl nitrite would have the structural formula CH(CH)ONO.\n\nDespite a very similar name to amyl nitrite, amyl nitrate has a different chemical composition and different properties. Vast numbers of people confuse the two drugs, especially those wishing to purchase \"poppers\" (amyl nitrite) for recreational purposes.\n\nAlkyl nitrites are prepared by the reaction of alcohols with nitrous acid:\n\nThe reaction is called esterification. Synthesis of alkyl nitrites is, in general, straightforward and can be accomplished in home laboratories. A common procedure includes the dropwise addition of concentrated sulfuric acid to a cooled mixture of an aqueous sodium nitrite solution and an alcohol. The intermediately-formed stoichiometric mixture of nitrous and nitric oxide then converts the alcohol to the alkyl nitrite, which, due to its low density, will form an upper layer that can be easily decanted from the reaction mixture.\n\nIsoamyl nitrite decomposes in the presence of base to give nitrite salts and the isoamyl alcohol:\n\nAmyl nitrite, like other alkyl nitrites, reacts with carbanions to give oximes.\n\nAmyl nitrites are also useful as reagents in a modification of the Sandmeyer reaction. The reaction of the alkyl nitrite with an aromatic amine in a halogenated solvent produces a radical aromatic species, this then frees a halogen atom from the solvent. For the synthesis of aryl iodides diiodomethane is used, whereas bromoform is the solvent of choice for the synthesis of aryl bromides.\n\nAmyl nitrite, in common with other alkyl nitrites, is a potent vasodilator; it expands blood vessels, resulting in lowering of the blood pressure. Alkyl nitrites are a source of nitric oxide, which signals for relaxation of the involuntary muscles. Physical effects include decrease in blood pressure, headache, flushing of the face, increased heart rate, dizziness, and relaxation of involuntary muscles, especially the blood vessel walls and the internal and external anal sphincter. There are no withdrawal symptoms. Overdose symptoms include nausea, vomiting, hypotension, hypoventilation, shortness of breath, and fainting. The effects set in very quickly, typically within a few seconds and disappear within a few minutes. Amyl nitrite may also intensify the experience of synesthesia.\n\n", "id": "3046", "title": "Amyl nitrite"}
{"url": "https://en.wikipedia.org/wiki?curid=3049", "text": "Autumn\n\nAutumn (British English) or fall (American English), is one of the four temperate seasons. Autumn marks the transition from summer to winter, in September (Northern Hemisphere) or March (Southern Hemisphere), when the arrival of night becomes noticeably earlier and the arrival of day becomes noticeably later, and the temperature cools down considerably. One of its main features is the shedding of leaves from deciduous trees.\n\nSome cultures regard the autumnal equinox as \"mid-autumn\", while others with a longer temperature lag treat it as the start of autumn. Meteorologists (and most of the temperate countries in the southern hemisphere) use a definition based on months, with autumn being September, October and November in the northern hemisphere, and March, April and May in the southern hemisphere.\n\nIn North America, autumn is usually considered to start with the September equinox (21 to 24 September) and end with the winter solstice (21 or 22 December). Popular culture in North America associates Labor Day, the first Monday in September, as the end of summer and the start of autumn; certain summer traditions, such as wearing white, are discouraged after that date. As daytime and nighttime temperatures decrease, trees shed their leaves. In traditional East Asian solar term, autumn starts on or around 8 August and ends on or about 7 November. In Ireland, the autumn months according to the national meteorological service, Met Éireann, are September, October and November. However, according to the Irish Calendar, which is based on ancient Gaelic traditions, autumn lasts throughout the months of August, September and October, or possibly a few days later, depending on tradition. In Australia and New Zealand, autumn officially begins on 1 March and ends on 31 May.\n\nThe word \"autumn\" comes from the ancient Etruscan root \"autu-\" and has within it connotations of the passing of the year. It was borrowed by the neighbouring Romans, and became the Latin word \"autumnus\". After the Roman era, the word continued to be used as the Old French word \"autompne\" (\"automne\" in modern French) or \"autumpne\" in Middle English, and was later normalized to the original Latin. In the Medieval period, there are rare examples of its use as early as the 12th century, but by the 16th century, it was in common use.\n\nBefore the 16th century, \"harvest\" was the term usually used to refer to the season, as it is common in other West Germanic languages to this day (cf. Dutch \"herfst\", German \"Herbst\" and Scots \"hairst\"). However, as more people gradually moved from working the land to living in towns, the word \"harvest\" lost its reference to the time of year and came to refer only to the actual activity of reaping, and \"autumn\", as well as \"fall\", began to replace it as a reference to the season.\n\nThe alternative word \"fall\" for the season traces its origins to old Germanic languages. The exact derivation is unclear, with the Old English \"fiæll\" or \"feallan\" and the Old Norse \"fall\" all being possible candidates. However, these words all have the meaning \"to fall from a height\" and are clearly derived either from a common root or from each other. The term came to denote the season in 16th century England, a contraction of Middle English expressions like \"fall of the leaf\" and \"fall of the year\".\n\nDuring the 17th century, English emigration to the British colonies in North America was at its peak, and the new settlers took the English language with them. While the term \"fall\" gradually became obsolete in Britain, it became the more common term in North America.\n\nThe name \"backend,\" a once common name for the season in Northern England, has today been largely replaced by the name autumn.\n\nAssociation with the transition from warm to cold weather, and its related status as the season of the primary harvest, has dominated its themes and popular images. In Western cultures, personifications of autumn are usually pretty, well-fed females adorned with fruits, vegetables and grains that ripen at this time. Many cultures feature autumnal harvest festivals, often the most important on their calendars. Still extant echoes of these celebrations are found in the autumn Thanksgiving holiday of the United States and Canada, and the Jewish Sukkot holiday with its roots as a full-moon harvest festival of \"tabernacles\" (living in outdoor huts around the time of harvest). There are also the many North American Indian festivals tied to harvest of ripe foods gathered in the wild, the Chinese Mid-Autumn or Moon festival, and many others. The predominant mood of these autumnal celebrations is a gladness for the fruits of the earth mixed with a certain melancholy linked to the imminent arrival of harsh weather.\n\nThis view is presented in English poet John Keats' poem \"To Autumn\", where he describes the season as a time of bounteous fecundity, a time of 'mellow fruitfulness'.\n\nWhile most foods are harvested during the autumn, foods particularly associated with the season include pumpkins (which are integral parts of both Thanksgiving and Halloween) and apples, which are used to make the seasonal beverage apple cider.\n\nAutumn, especially in poetry, has often been associated with melancholia. The possibilities of summer are gone, and the chill of winter is on the horizon. Skies turn grey, the amount of usable daylight drops rapidly, and many people turn inward, both physically and mentally. It has been referred to as an unhealthy season.\n\nSimilar examples may be found in Irish poet William Butler Yeats' poem \"The Wild Swans at Coole\" where the maturing season that the poet observes symbolically represents his own aging self. Like the natural world that he observes, he too has reached his prime and now must look forward to the inevitability of old age and death. French poet Paul Verlaine's \"\"Chanson d'automne\"\" (\"Autumn Song\") is likewise characterized by strong, painful feelings of sorrow. Keats' \"To Autumn\", written in September 1819, echoes this sense of melancholic reflection, but also emphasizes the lush abundance of the season.\n\nAutumn is associated with Halloween (influenced by Samhain, a Celtic autumn festival), and with it a widespread marketing campaign that promotes it. Halloween is in autumn in the northern hemisphere. The television, film, book, costume, home decoration, and confectionery industries use this time of year to promote products closely associated with such a holiday, with promotions going from early September to 31 October, since their themes rapidly lose strength once the holiday ends, and advertising starts concentrating on Christmas.\n\nAutumn also has a strong association with the end of summer holiday and the start of a new school year, particularly for children in primary and secondary education. \"Back to School\" advertising and preparations usually occurs in the weeks leading to the beginning of autumn.\n\nEaster is in autumn in the southern hemisphere.\n\nTelevision stations and networks, particularly in North America, traditionally begin their regular seasons in autumn, with new series and new episodes of existing series debuting mostly during late September or early October (series that debut outside the fall season are usually known as mid-season replacements). A sweeps period takes place in November to measure Nielsen Ratings.\n\nAmerican football is played almost exclusively in the autumn months; at the high school level, seasons run through September and October, with some playoff games and holiday rivalry contests being played as late as Thanksgiving. College football's regular season runs from September through November, while the main professional circuit, the National Football League, plays from September through December. Summer sports, such as stock car racing and Major League Baseball, wrap up their seasons in early autumn; MLB's championship World Series is known popularly as the \"Fall Classic.\" (Amateur baseball is usually finished by August.) Likewise, professional winter sports, such as professional ice hockey, basketball and most leagues of soccer football in Europe, are in the early stages of their seasons during autumn; American college basketball and college ice hockey play teams outside their athletic conferences during the late autumn before their in-conference schedules begin in winter.\n\nSince 1997, Autumn has been one of the top 100 names for girls in the United States.\n\nIn Indian mythology, autumn is considered to be the preferred season for the goddess of learning Saraswati, who is also known by the name of \"goddess of autumn\" (Sharada).\n\nIn Asian mysticism, Autumn is associated with the element of metal, and subsequently with the colour white, the White Tiger of the West, and death and mourning.\n\nAlthough colour change in leaves occurs wherever deciduous trees are found, coloured autumn foliage is noted in various regions of the world: most of North America, Eastern Asia (including China, Korea, and Japan), Europe, the forest of Patagonia, eastern Australia and New Zealand's South Island.\n\nEastern Canada and New England are famous for their autumnal foliage, and this attracts major tourism (worth billions of U.S. dollars) for the regions.\n\n\n", "id": "3049", "title": "Autumn"}
{"url": "https://en.wikipedia.org/wiki?curid=3052", "text": "Alameda, California\n\nAlameda ( ; Spanish: ) is a city in Alameda County, California, United States. It is located on Alameda Island and Bay Farm Island, and is adjacent to and south of Oakland and east of San Francisco across the San Francisco Bay. Bay Farm Island, a portion of which is also known as \"Harbor Bay Isle\", is not actually an island, and is part of the mainland adjacent to the Oakland International Airport. The city's estimated 2016 population was 79,277. Alameda is a charter city, rather than a general law city, allowing the city to provide for any form of government. Alameda became a charter city and adopted a council–manager government in 1916, which it retains to the present.\n\nThe island Alameda occupies what was originally a peninsula connected to Oakland. Much of it was low-lying and marshy, but on higher ground than the peninsula and adjacent parts of what is now downtown Oakland were home to one of the largest coastal oak forests in the world. The area was therefore called \"Encinal\", Spanish for \"forest of evergreen oak\". \"Alameda\" is Spanish for \"grove of poplar trees\" or \"tree-lined avenue\", and was chosen in 1853 by popular vote.\n\nThe inhabitants at the time of the arrival of the Spanish in the late 18th century were a local band of the Ohlone tribe. The peninsula became part of the vast Rancho San Antonio granted in 1820 to Luis Peralta by the Spanish king who claimed California. The grant was later confirmed by the new Republic of Mexico upon its independence from Spain.\n\nOver time, the place became known as Bolsa de Encinal or Encinal de San Antonio.\n\nThe city was founded on June 6, 1853, and the town originally contained three small settlements. \"Alameda\" referred to the village at Encinal and High Streets, Hibbardsville was at the North Shore ferry and shipping terminal, and Woodstock was on the west near the ferry piers of the South Pacific Coast Railroad and the Central Pacific. Eventually, the Central Pacific's ferry pier became the Alameda Mole, featuring transit connections between San Francisco ferries, local trollies and Southern Pacific (formerly Central Pacific) commuter lines.\n\nThe first post office opened in 1854. The first school, Schmermerhorn School, was opened in 1855 (and eventually became Lincoln School), Encinal School was opened in 1860 (and closed in 1980). The San Francisco and Alameda Railroad opened the Encinal station in 1864. The Encinal area was also known as Fasskings Station in honor of Frederick Louis Fassking. Encinal's own post office opened in 1876, was renamed West End in 1877, and closed in 1891. The West End area was originally called Bowman's Point in honor of Charles G. Bowman, an early settler.\n\nThe Alameda Terminal was the site of the arrival of the first train via the First Transcontinental Railroad into the San Francisco Bay Area on September 6, 1869. The transcontinental terminus was switched to the Oakland Mole two months later, on November 8, 1869.\n\nThe borders of Alameda were made coextensive with the island in 1872, incorporating Woodstock into Alameda.\nMark Twain described Alameda as being \"The Garden of California.\" \n\nIn 1917, an attraction called Neptune Beach was built in the area now known as Crab Cove. Often compared to Coney Island, the park was a major attraction in the 1920s and 1930s. The original owners of the facility, the Strehlow family, partnered with a local confectioner to create tastes unique to Neptune Beach. Both the American snow cone and the popsicle were first sold at Neptune Beach. The Kewpie doll, hand-painted and dressed in unique hand-sewn dresses, became the original prize for winning games at the beach – another Neptune Beach invention. The Strehlows owned and operated the beach on their own, even filling in a section of the bay to add an additional Olympic-size swimming pool and an exceptional roller coaster which must have given riders a tremendous view of the bay. The \"Cottage Baths\" were available for rent.\n\nNeptune Beach's two huge outdoor pools hosted swimming races and exhibitions by such famous swimmers as Olympian Johnny Weissmuller, who later starred as the original Tarzan, and Jack LaLanne, who started a chain of health clubs. The park closed down in 1939 because of the Great Depression, the completion of the San Francisco–Oakland Bay Bridge, people circumventing paying the admission price, and the rise of car culture. Once the Bay Bridge was complete, the rail lines, which ran right past the entrance to Neptune Beach on the way to the Alameda Mole and the Ferry, lost riders in droves. People began using their cars to escape the city and the immediate suburbs like Alameda and traveling further afield in California. Alameda lost its resort status as more distant locations became more attractive to cash-rich San Francisco tourists. Youngsters in town became aware of ways to avoid paying the dime for admission to the park. Strong swimmers or even waders could sneak in on the bay side just by swimming around the fence.\n\nSome of the resort homes and buildings from the Neptune beach era still exist in present-day Alameda. The Croll Building, on the corner of Webster Street and Central Avenue, was the site of Croll's Gardens and Hotel, famous as training quarters for some of the greatest fighters in boxing history from 1883 to 1914. James J. Corbett, Bob Fitzsimmons, Jim Jefferies, Jack Johnson, and many other champions all stayed and trained here. Today this beautifully preserved building is home to Croll's Pizza and the 1400 Bar & Grill Restaurant. Neptune Court, just a block away on the corner of Central Ave. and McKay Ave., provides another glimpse of what resort life was like in Alameda in the 1920s. A short walk near Crab Cove will reveal many more historic gems.\n\nThe vast majority of the Neptune Beach structures – the hand-carved carousel from the world-famed Dentzel Company, the Ferris wheel, the roller coaster, and other rides – were auctioned off in 1940 for mere pennies on the dollar of their original cost. Today, A consequence of the Neptune Beach closing around 1940 was a total dearth of quality, clean swimming facilities in town. A grass roots effort to create swimming pools at two high schools and two city parks would continue into the early 1960s.\n\nWhen the railroad came to town in the 1860s Park Street developed into the major thoroughfare of the city and the location of the main Alameda train station, residents of Old Alameda pulled up stakes and moved across town to the new downtown. The street's location was chosen by two landowners who wished to attract tenants and development to their land. As a result, they designated their mutual property line as Park Street.\n\nIn 1902, the need for expanded shipping facilities led to the dredging of a canal through the marshland between Oakland and Alameda, turning Alameda into an island. Most of the soil from the canal was used to fill in nearby marshland. The area of Alameda called Bay Farm Island is no longer an island, but is attached by fill to Oakland. In his youth, author Jack London was known to take part in oyster pirating in the highly productive oyster beds near Bay Farm Island, today long gone. The Alameda Works Shipyard was one of the largest and best equipped shipyards in the country. In the 1950s, Alameda's industrial and ship building industries thrived along the Alameda Estuary, where the world's first-ever, land-based, containerized shipping crane was used. Today, the Port of Oakland across the estuary serves as one of the largest ports on the West Coast, using the shipping technologies originally experimented with in Alameda. As of March 21, 2006, Alameda is a \"Coast Guard City\", one of seven in the country.\n\nIn addition to the regular trains running to the Alameda Mole, Alameda was also served by local steam commuter lines of the Southern Pacific (initially, the Central Pacific) which were later transformed into the East Bay Electric Lines. Southern Pacific's electrified trains were not streetcars, but full-sized railroad cars which connected to the mainland by bridges at Webster Street and Fruitvale (only the latter bridge survives today). The trains ran to both the Oakland Mole and the Alameda Mole. In fact, one line which ran between the two moles was dubbed the \"Horseshoe Line\" for the shape of the route on a map. Soon after the completion of the Bay Bridge, Alameda trains ran directly to San Francisco on the lower deck of the bridge, the ferries having been rendered unnecessary. Alameda was the site of the Southern Pacific's West Alameda Shops where all the electric trains were maintained and repaired.\n\nIn the 1930s Pan American Airways established a seaplane port along the fill that led to the Alameda Mole. This was the original home base for the famous China Clipper flying boat.\nIn 1929, the University of California established the San Francisco Airdrome located near the current Webster Street tube as a public airport. The Bay Airdrome had its gala christening party in 1930. The airfield was a busy place, as an early home base for Coastal Air Freight, Varney Air Lines, West Coast Air Transport, Western Air Express, the transbay Air Ferries, and Boeing's Pacific Air Transport. The Airdrome was closed in 1941 when its air traffic interfered with the newly built Naval Air Station Alameda (NAS Alameda). With the advent of World War II, a vast stretch of the marshy area southwest of the Alameda Mole was filled and the NAS Alameda established. This major Naval facility included a large airfield, as well as docks for several aircraft carriers. It closed in 1997.\n\nIn the late 1950s the Utah Construction Company began a landfill beyond the \"Old Sea Wall\" and created \"South Shore\".\n\nOn February 7, 1973, a USN Vought A-7E Corsair II fighter jet on a routine training mission from Lemoore Naval Air Station, suddenly caught fire, 28,000 feet over the San Francisco Bay and crashed into the Tahoe Apartments in Alameda. Eleven people, including pilot Lieutenant Robert Lee Ward died in the crash and fire.\n\nAccording to the United States Census Bureau, the city has a total area of , of which is land and (53.79%) is water.\n\nAlthough Alameda's nickname is \"The Island City\" (or simply \"the island\"), the current city occupies two islands as well as a small section of the mainland. Today, the city consists of the main original section, with the former Naval Air Station Alameda (NAS Alameda) at the west end of Alameda Island, Southshore along the southern side of Alameda Island, and Bay Farm Island, which is part of the mainland proper. The area of the former NAS is now known as \"Alameda Point.\" The Southshore area is separated from the main part of Alameda Island by a lagoon; the north shore of the lagoon is located approximately where the original south shore of the island was. Alameda Point and Southshore are built on bay fill.\n\nNot all of Alameda Island is part of the City of Alameda. Although nearly all of the island is in Alameda city limits, a small portion of a dump site west of the former runways at Alameda Point extends far enough into San Francisco Bay that it is over the county line and part of the City and County of San Francisco. \n\nCoast Guard Island, a small island between Alameda Island and Oakland, is also part of Alameda and is the home of Integrated Support Command Alameda\n\nThis region experiences warm (but not hot) and dry summers, with no average monthly temperatures above 71.6 °F. According to the Köppen climate classification system, Alameda has a warm-summer Mediterranean climate, abbreviated \"Csb\" on climate maps. Annual precipitation is about 20 inches, all rain (snow is extremely rare at sea level in the San Francisco Bay area).\n\nThe 2010 United States Census reported that Alameda had a population of 73,812. The population density was 3,214.9 people per square mile (1,241.3/km²). The racial makeup of Alameda was 37,460 (50.8%) White, 23,058 (31.2%) Asian, 4,759 (6.4%) African American, 426 (0.6%) Native American, 381 (0.5%) Pacific Islander, 2,463 (3.3%) from other races, and 5,265 (7.1%) from two or more races. Hispanic or Latino of any race were 8,092 persons (11.0%).\n\nThe Census reported that 72,316 people (98.0% of the population) lived in households, 857 (1.2%) lived in non-institutionalized group quarters, and 639 (0.9%) were institutionalized.\n\nThere were 30,123 households, out of which 9,144 (30.4%) had children under the age of 18 living in them, 13,440 (44.6%) were opposite-sex married couples living together, 3,623 (12.0%) had a female householder with no husband present, 1,228 (4.1%) had a male householder with no wife present. There were 1,681 (5.6%) unmarried opposite-sex partnerships, and 459 (1.5%) same-sex married couples or same-sex partnerships. 9,347 households (31.0%) were made up of individuals and 2,874 (9.5%) had someone living alone who was 65 years of age or older. The average household size was 2.40. There were 18,291 families (60.7% of all households); the average family size was 3.06.\n\nThe age distribution of the population shows 15,304 people (20.7%) under the age of 18, 5,489 people (7.4%) aged 18 to 24, 21,000 people (28.5%) aged 25 to 44, 22,044 people (29.9%) aged 45 to 64, and 9,975 people (13.5%) who were 65 years of age or older. The median age was 40.7 years. For every 100 females there were 91.7 males. For every 100 females age 18 and over, there were 88.5 males.\n\nPer capita money income in past 12 months (2013 dollars), 2009 – 2013 was $41,340.00 per US Census. Median household income, 2009 – 2013 was $74,606.00 per US Census.\n\nThere were 32,351 housing units at an average density of 1,409.0 per square mile (544.0/km²), of which 14,488 (48.1%) were owner-occupied, and 15,635 (51.9%) were occupied by renters. The homeowner vacancy rate was 1.1%; the rental vacancy rate was 5.7%. 37,042 people (50.2% of the population) lived in owner-occupied housing units and 35,274 people (47.8%) lived in rental housing units.\nAs of the census of 2000, there were 72,259 people, 30,226 households, and 17,863 families residing in the city. The population density was 2,583.3/km² (6,693.4/mi²). There were 31,644 housing units at an average density of 1,131.3/km² (2,931.2/mi²). The racial makeup of the city was 56.95% White, 6.21% Black or African American, 0.67% Native American, 26.15% Asian, 0.60% Pacific Islander, 3.29% from other races, and 6.13% from two or more races. 9.31% of the population were Hispanic or Latino of any race.\n\nThere were 30,226 households out of which 27.7% had children under the age of 18 living with them, 43.7% were married couples living together, 11.4% had a female householder with no husband present, and 40.9% were non-families. 32.2% of all households were made up of individuals and 9.4% had someone living alone who was 65 years of age or older. The average household size was 2.35 and the average family size was 3.04.\n\nIn the city, the age distribution of the population shows 21.5% under the age of 18, 7.0% from 18 to 24, 33.6% from 25 to 44, 24.6% from 45 to 64, and 13.3% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 92.3 males. For every 100 females age 18 and over, there were 89.5 males.\n\nThe median income for a household in the city was $56,285, and the median income for a family was $68,625. Males had a median income of $49,174 versus $40,165 for females. The per capita income for the city was $30,982. About 6.0% of families and 8.2% of the population were below the poverty line, including 11.4% of those under age 18 and 6.1% of those age 65 or over.\n\nThere is a large Filipino community; and also a major Portuguese community, from which Tom Hanks' mother came and where Lyndsy Fonseca was raised for some time. Alameda also has a historic Japanese American community and had a small Japanese business district on a portion of Park Street prior to World War II, when the city's Japanese population was interned. A Japanese Buddhist church is one of the few remaining buildings left of Alameda's pre-war Japanese American community.\n\nLike much of the heavily Democratic Alameda County, the City of Alameda is considered a liberal city. In addition to voting solidly for Democratic candidates in statewide elections, voters in the city have approved a number of progressive ballot initiatives.\n\nVehicle access to Alameda Island is via three bridges from Oakland (Park Street, Fruitvale Avenue, and High Street Bridges), as well as the two one-way Posey and Webster Street Tubes leading into Oakland's Chinatown. Connections from Alameda to Bay Farm Island is provided via the Bay Farm Island Bridge for vehicular traffic as well as the Bay Farm Island Bicycle Bridge (the only pedestrian/bicycle-only drawbridge in the United States). California State Route 61 runs down city streets from the Posey and Webster Street Tubes, across the Bay Farm Island Bridge, and south to the Oakland Airport.\n\nPublic transportation includes the AC Transit buses (which include express buses to San Francisco) and two ferry services — the Alameda/Oakland Ferry and the Alameda Harbor Bay Ferry. AC Transit buses also cover 3 bus times in the morning and afternoon to Lincoln Middle School, located in Alameda. Both ferry services may soon be transferred to the Water Transit Authority. The closest BART stations are Lake Merritt and 12th Street, near the exit to the Posey Tube, and Fruitvale, near the Fruitvale Bridge.\n\nEven though the island is just minutes off Interstate 880 in Oakland, the speed limit for the city is 25 mph (40 km/h) on almost every road. Many unaware drivers fail to slow down after exiting the highway. Groups like Pedestrian Friendly Alameda and BikeAlameda advocate stronger enforcement of speeding laws.\n\nAlameda has also featured prominently on automotive blog Jalopnik, with their \"Down on The Street\" segment consisting of cars found on the streets of Alameda. Jalopnik has nicknamed it \"The Island That Rust Forgot\".\n\nDue to its proximity to the Bay, wind surfers and kite surfers can often be seen at Robert W. Crown Memorial State Beach. From the beach there are also views of the San Francisco skyline and the San Francisco–Oakland Bay Bridge.\n\nThe aircraft carrier \"USS \"Hornet\", a museum ship, has been moored at the former Naval Air Station as the USS \"Hornet\" Museum since 1998. This ship was originally named the \"USS Kearsarge\", but was renamed in honor of the previous Hornet CV-8 (famous for the Doolittle raid), which was lost in October 1942.\n\nAlameda is known for its Victorian houses; 9% of all single-family houses (1500) in Alameda are Victorian, and many more have been divided into two to four-unit dwellings. It is said that Alameda has more pre-1906 earthquake era homes in the Gold Coast section than any other city in the Bay Area.\n\nAlameda is home to the official offices and training facility of the Oakland Raiders American football team, which is located on Bay Farm Island. The facility is also home to The Raider Image, the merchandise arm of the franchise, which the public can visit.\n\nAt the turn of the 19th century, the city of Alameda took a large chunk of Charles Froling's land away to build a street. Froling had planned to build his dream house on the plot of land he received through inheritance. To spite the city and an unsympathetic neighbor, Froling built a house wide, long and high on the tiny strip of land left to him. The Froling spite house is still standing and occupied.\n\nAlameda is also known for its Fourth of July parade, which is advertised as the second oldest and second longest Fourth of July parade in the United States. It features homemade floats, classic cars, motorized living room furniture, fire-breathing dragons, marching bands, and large crowds. The parade route is about 3 miles (5 km) long.\n\nThe Historic Park Street Business District is known for its many buildings that date back to the 1800s and is a designated Historic Commercial District on the National Register. This main thoroughfare of downtown Alameda Is filled with local shops, restaurants, drinking establishments, and services. The renovated 1932 Alameda Theatre & Cineplex is the cultural centerpiece of the commercial district. In addition, popular attractions include High Scores Arcade Museum (a retro video game arcade) and Subpar Miniature Golf (an indoor miniature golf complex that features Bay Area landmarks such as the Golden Gate Bridge and Coit Tower at each hole).\n\nAfter two previous failures, voters in the city passed a ballot measure in 2000 authorizing a bond measure for construction of a new library to replace the city's Carnegie library, damaged during the 1989 Loma Prieta earthquake. The city also received state funds for the new library and opened the doors to the new facility in November 2006.\n\nNaval Air Station Alameda (NAS), at Alameda Point, was decommissioned in 1997, and is in process of being turned over to the City of Alameda for civilian development. The area of the former NAS is now known as Alameda Point. In late July 2006, the City of Alameda announced a deal with the Navy that would turn the land over to the city for $108M. The transfer process was initially slowed down by disputes between the Navy and the city regarding payment for environmental cleanup of the land.\n\nIn September 2010 the US Veterans Administration proposed construction of a $209 million state-of-the-art facility at Alameda Point that would provide primary care, specialty care, and mental health, substance abuse and other services. The VA received Congressional $17.33 million in budget authority for the project in 2011. But concerns over the proximity to a nesting site for an endangered bird, the California least tern, have led to delays in moving the project forward. The VA's 2012 and 2013 budget requests to Congress contain no funding requests for Alameda Point. \n\nIn September 2011 Alameda and the Navy reached an agreement on the terms of a no-cost conveyance for the entire 918 acres at Alameda Point.\n\nThe 33rd America's Cup Race was won by Golden Gate Yacht Club racing team BMW Oracle, founded by Larry Ellison. One possible use of the air station would be an alternate or partnered site with San Francisco for 34th America's Cup.\nWithin 2 weeks of the Golden Gate Yacht Club winning the America's Cup, Alameda city council with local support sent a unanimous letter of support to hold AC 34 in San Francisco Bay Area.\nIn early 2011, the City Council created an ad hoc America's Cup Citizens Advisory Committee to look for ways that Alameda could draw interest from teams and potential spectators. Through those efforts, in mid-2012, the Swedish Artemis Racing team announced that they would create their team base in one of the former air station hangars on Alameda Point.\n\nRosenblum Cellars Winery, Rock Wall Winery, and St. George Spirits are located at Alameda Point. In 1978, Alameda veterinarian Kent Rosenblum and his wife Kathy founded Rosenblum Cellars. In 2008, the company was purchased by Diageo Estates. Shauna Rosenblum, daughter of Kent and Kathy, is the wine maker for Rock Wall Winery. In December, 2007, St. George Absinthe Verte, produced by St. George Spirits became the first brand of American-made absinthe to be legally produced in the United States since a ban was enacted in 1912.\n\nThe city restored the historic Art Deco city landmark Alameda Theatre, expanding it to include a theater multiplex. The public opening was May 21, 2008.\n\nThe South Shore Mall Twin Cinema opened in 1969 and served as a prominent theater on the island until its closure in 1998. In 2002, the building was demolished and its former site is now a parking lot.\n\nAlameda also hosts the Altarena Playhouse, which since 1957 has been home to the Bay Area's oldest continuously operating community theater organization.\n\nAccording to the City's 2014 Comprehensive Annual Financial Report, the top employers in the city are:\n\nAlameda's first newspaper, the \"Encinal\", appeared in the early 1850s and the paper's editor was instrumental in the movement to incorporate the city. Following the \"Encinal\", several other papers appeared along geographic lines, and the \"Daily Argus\" eventually rose to prominence. A young Alameda native, Joseph R. Knowland, wrote political and historical articles for the Alameda papers. Later, Knowland owned the powerful \"Oakland Tribune\". Around 1900, the \"Daily Argus\" began to fade in importance and east and west papers \"The Times\" and \"The Star\" combined to take the leading role as the \"Alameda Times-Star\" in the 1930s. The \"Times-Star\" was sold to the Alameda Newspaper Group in the 1970s.\n\nIn 1997, the Hills Newspaper chain was bought by Knight Ridder, at the time, the second-largest newspaper chain in the U.S. Following the buyout, former Hills Newspapers employees recognized the lack of a local community voice in Alameda, and again formed a new locally based newspaper, the \"Alameda Sun\", in 2001. In 2006, Knight Ridder announced its impending sale to McClatchy Corp., a Sacramento-based publishing firm. McClatchy Corp. has put the \"Contra Costa Times\", which under the Knight Ridder reorganization included all five of the original Hills Newspapers, up for sale. The current owners of the \"Alameda Times-Star\", MediaNews, Inc., based in Colorado, have announced a strong interest in buying both the \"Contra Costa Times\" chain and the \"San Jose Mercury News\", consolidating the daily newspaper market of the East Bay, effectively under one owner. MediaNews closed the \"Times-Star\" in 2011.\n\nThe Alameda community is currently served by two weekly newspapers, the Alameda Journal, owned by the MediaNews Group, and the Alameda Sun, along with a news website, The Alamedan.\n\nAlameda Hospital is located there.\n\nUnlike surrounding communities, Alameda has a municipal power service, Alameda Municipal Power (AMP), that delivers services directly to consumers. AMP sold the majority of its telecommunications business to Comcast in 2008 but continues to provide telecommunication service at Alameda Point.\n\nDuring the California electricity crisis of 2000 and 2001, Alameda Municipal Power did not raise electricity rates, while residents in most of the state endured significant price increases.\n\nThe Alameda Arts Council (AAC) serves as the local Alameda City arts council. The Alameda Civic Ballet is the ballet troupe of the city. The Alameda Museum features displays on the history of Alameda. The Alameda Art Association has about 80 members as of January 2011, and has a gallery space at South Shore Center mall. The Association began in 1944. An annual benefit, Circus for Arts in the Schools, was started by clown artist Jeff Raz in 2004. Photo-realist Robert Bechtle has painted numerous Alameda subjects, including \"Alameda Gran Torino\", which was acquired by SFMOMA in 1974 and remains one of Bechtle's most famous works.\n\nAlameda has been home to many movie sets. Some of the movies filmed on the island have included \"Bicentennial Man\", \"The Net\", \"The Matrix Reloaded\", \"\", \"Bee Season\", the original 1968 \"Your, Mine and Ours\" and the movie musical \"Rent\". Parts of Alameda High School were animated for the \"Animatrix\" episode \"Kid's Story\". A massive hangar at the former Naval Air Station Alameda was used to film special scenes requiring computer-generated imagery for movies such as \"Bicentennial Man\", \"Flubber\", \"What Dreams May Come\", \"\" and many scenes from the \"Matrix\" trilogy, including the signature bullet time scene. The open space of the decommissioned naval base often hosts \"MythBusters\"' more dangerous experiments. The movie \"Spirit Of '76\" was filmed all throughout Alameda.\n\nThe USS Hornet Museum, permanently moored at Alameda Point, has been the site for scenes used in major theatrical releases: \"\", \"Rescue Dawn\", and \"The Master\". In addition, the aircraft carrier has been used for television shows such as \"JAG\", \"Carrier\", \"Looking\", \"The Great Escape\", and the special military episode of \"Fear Factor\"; plus a number of television commercials.\n\nThe Altarena Playhouse, which performs comedies, dramas and musicals, was founded in 1938 and is the longest continuously operating community theater in the San Francisco Bay Area.\n\nRhythmix Cultural Works (RCW) brings people of all ages together to experience and explore music, dance, visual art and educational opportunities. RCW's programs are housed in a restored industrial waterfront building that speaks to Alameda’s history while creating an inclusive venue that reflects the Bay Area’s rich diversity. The organization offers an array of arts programming to the community including Island Arts, Island City Waterways, Round the World Festival and its Performance Art and Learning program (PAL) that serves more than 2000 youth with free cultural arts assemblies each year.\n\nWebster Street in Alameda has long been the host of many arts, crafts and holiday festivals. During some of these festivals, the Chamber of Commerce along with the West Alameda Business Association (WABA) will block of a portion of Webster St. for the entertainment of festival goers. Festivals such as The JAM at Neptune Beach formerly known as the Peanut Butter Jam Festival brings a lot of local and outside visitors. Other event on the \"West-End\" include Trick-or-Treat on Webster Street where merchants supply goodies for local children and culminates with a parade and costume contest; in December \"Santa Claus Meet-n-Greet on Webster Street\" happens with elves, and a photo with the big guy.\n\nThere are three major events when the street in Alameda's historic downtown district is closed to vehicular traffic. The \"Park Street Spring Festival\" takes place every May during the weekend of Mother's Day and attracts over 50,000 visitors. The \"Park Street Art & Wine Faire\" takes place the last weekend of every July and attracts over 100,000 visitors. Both street fairs feature over 150 arts & crafts vendors, food vendors, beer and wine pouring, a children's area, and two stages with regional entertainment. The \"Park Street Classic Car Show\" is held on the second Saturday every October and displays over 400 vintage vehicles.\n\n\nPublic primary and secondary education in Alameda is the responsibility of the Alameda Unified School District, which is legally separate from the City government (as is common throughout California). The College of Alameda, a two-year community college in the West End is part of the Peralta Community College District. The city has numerous private primary schools, and one private high school, St. Joseph Notre Dame High School, a Catholic school.\n\nAlameda's relationships with Wuxi and Jiangyin were initiated in 2005, in part, by Stewart Chen, who then served on the City of Alameda Social Service and Human Relations board, and who went on to be elected to Alameda City Council in November, 2012.\n\nWuxi, China, is a so-called friendship city, because the diplomacy organization Sister Cities International does not recognize the relationship.\n\n\n\nIn September, 2013, a Tibetan rights group initiated a social media and e-mail campaign targeting the Mayor of Alameda, complaining that City of Alameda's participation in, and association with, a flag-raising ceremony to recognize National Day of the People's Republic of China on October 1 was tantamount to endorsing the communist regime in China, its human rights abuses, and the occupation of Tibet. The City of Alameda responded that the ceremony was a function of the Alameda Sister City Association and the Alameda Wuxi Friendship Committee, not a function of the City of Alameda. The Tibetan rights group responded that on September 26, the City of Alameda Social Service and Human Relations board appointed a member, Michael Robles-Wong, as a representative to the Sister City Association.\n\nOn October 1, 2013, the Tibetan rights groupsTibetTruth and Bay Area Friends of Tibet sent roughly 75 protesters to Alameda City Hall to protest the ceremony, which organizers ultimately canceled before it began. Former City of Alameda Councilmember Frank Matarrese announced the cancellation. Then-city councilmember Stewart Chen subsequently defended the ceremony, as a diplomatic, not political, exercise.\n\n\n", "id": "3052", "title": "Alameda, California"}
{"url": "https://en.wikipedia.org/wiki?curid=3054", "text": "Alpha helix\n\nThe alpha helix (α-helix) is a common motif in the secondary structure of proteins and is a righthand-coiled or spiral conformation (helix) in which every backbone N-H group donates a hydrogen bond to the backbone C=O group of the amino acid located three or four residues earlier along the protein sequence. This secondary structure is also sometimes called a classic Pauling–Corey–Branson α-helix (see below). The name 3.6-helix is also used for this type of helix, denoting the average number of residues per helical turn, with 13 atoms being involved in the ring formed by the hydrogen bond. Among types of local structure in proteins, the α-helix is the most regular and the most predictable from sequence, as well as the most prevalent.\n\nIn the early 1930s, William Astbury showed that there were drastic changes in the X-ray fiber diffraction of moist wool or hair fibers upon significant stretching. The data suggested that the unstretched fibers had a coiled molecular structure with a characteristic repeat of ~.\n\nAstbury initially proposed a kinked-chain structure for the fibers. He later joined other researchers (notably the American chemist Maurice Huggins) in proposing that:\n\nAlthough incorrect in their details, Astbury's models of these forms were correct in essence and correspond to modern elements of secondary structure, the α-helix and the β-strand (Astbury's nomenclature was kept), which were developed by Linus Pauling, Robert Corey and Herman Branson in 1951 (see below); that paper showed both right- and left-handed helixes, although in 1960 the crystal structure of myoglobin showed that the right-handed form is the common one. Hans Neurath was the first to show that Astbury's models could not be correct in detail, because they involved clashes of atoms. Neurath's paper and Astbury's data inspired H. S. Taylor, Maurice Huggins and Bragg and collaborators to propose models of keratin that somewhat resemble the modern α-helix.\n\nTwo key developments in the modeling of the modern α-helix were (1) the correct bond geometry, thanks to the crystal structure determinations of amino acids and peptides and Pauling's prediction of \"planar\" peptide bonds; and (2) his relinquishing of the assumption of an integral number of residues per turn of the helix. The pivotal moment came in the early spring of 1948, when Pauling caught a cold and went to bed. Being bored, he drew a polypeptide chain of roughly correct dimensions on a strip of paper and folded it into a helix, being careful to maintain the planar peptide bonds. After a few attempts, he produced a model with physically plausible hydrogen bonds. Pauling then worked with Corey and Branson to confirm his model before publication. In 1954, Pauling was awarded his first Nobel Prize \"for his research into the nature of the chemical bond and its application to the elucidation of the structure of complex substances\" (such as proteins), prominently including the structure of the α-helix.\n\nThe amino acids in an α-helix are arranged in a right-handed helical structure where each amino acid residue corresponds to a 100° turn in the helix (i.e., the helix has 3.6 residues per turn), and a translation of along the helical axis. Dunitz describes how Pauling's first article on the theme in fact shows a left-handed helix, the enantiomer of the true structure. Short pieces of left-handed helix sometimes occur with a large content of achiral glycine amino acids, but are unfavorable for the other normal, biological L-amino acids. The pitch of the alpha-helix (the vertical distance between consecutive turns of the helix) is , which is the product of 1.5 and 3.6. What is most important is that the N-H group of an amino acid forms a hydrogen bond with the C=O group of the amino acid \"four\" residues earlier; this repeated formula_1 hydrogen bonding is the most prominent characteristic of an α-helix. Official international nomenclature specifies two ways of defining α-helices, rule 6.2 in terms of repeating φ,ψ torsion angles (see below) and rule 6.3 in terms of the combined pattern of pitch and hydrogen bonding. The alpha-helices can be identified in protein structure using several computational methods, one of which being DSSP (Dictionary of Protein Secondary Structure).\nSimilar structures include the 3 helix (formula_2 hydrogen bonding) and the π-helix (formula_3 hydrogen bonding). The α-helix can be described as a 3.6 helix, since the i + 4 spacing adds 3 more atoms to the H-bonded loop compared to the tighter 3 helix, and on average, 3.6 amino acids are involved in one ring of α-helix. The subscripts refer to the number of atoms (including the hydrogen) in the closed loop formed by the hydrogen bond.\nResidues in α-helices typically adopt backbone (φ, ψ) dihedral angles around (-60°, -45°), as shown in the image at right. In more general terms, they adopt dihedral angles such that the ψ dihedral angle of one residue and the φ dihedral angle of the \"next\" residue sum to roughly -105°. As a consequence, α-helical dihedral angles, in general, fall on a diagonal stripe on the Ramachandran diagram (of slope -1), ranging from (-90°, -15°) to (-35°, -70°). For comparison, the sum of the dihedral angles for a 3 helix is roughly -75°, whereas that for the π-helix is roughly -130°. The general formula for the rotation angle Ω per residue of any polypeptide helix with \"trans\" isomers is given by the equation\n\nThe α-helix is tightly packed; there is almost no free space within the helix. The amino-acid side-chains are on the outside of the helix, and point roughly \"downward\" (i.e., toward the N-terminus), like the branches of an evergreen tree (Christmas tree effect). This directionality is sometimes used in preliminary, low-resolution electron-density maps to determine the direction of the protein backbone.\n\nThree differently arranged styles of 2D diagrams are used to represent different aspects of the sequence and structure relationships that confer specific physical and interaction properties on individual α-helices. Two of these emphasize circular placement around the cylindrical cross-section: The first-developed such diagram is called the \"helical wheel\", and a more recent version is called the \"wenxiang diagram\". The latter name came from the fact that it resembles a coil-like incense used in China to repel mosquitos; Chinese 蚊香 (pronounced \"wenxiang\").\n\nThe helical wheel represents a helix by a projection of the Cα backbone structure down the helix axis, while the wenxiang diagram represents it more abstractly as a smooth spiral coiled on the plane of the page. Both label the sequence with one-letter amino-acid code (see amino acid) at each Cα position, using different colors or symbols to code the amino-acid properties. Hydrophobic vs hydrophilic amino acids are always distinguished, as the most important property governing helix interactions. Sometimes positively vs negatively charged hydrophilics are distinguished, and sometimes ambiguous amino acids such as glycine (G) are distinguished. Color-coding conventions are various. The helical wheel does not change representation along the helix, while the wenxiang diagram is able to show the relative locations of the amino acids in an α-helix regardless of how long it is.\n\nEither circular style of diagram can provide an intuitive and easily visualizable 2D picture that characterizes the disposition of hydrophobic and hydrophilic residues in α-helices, and can be used to study helix-helix interactions, helix-membrane interactions as quantified by the helical hydrophobic moment, or protein-protein interactions.\n\nVarious utilities and web sites are available to generate helical wheels, such as the page by Kael Fischer.\n\nThe third style of 2D diagram is called a \"helical net\". It is generated by opening the cylindrical surface of each helix along a line parallel to the axis and laying the result out vertically. The helix net is not suitable for studying helix-helix packing interactions, but it has become the dominant means of representing the sequence arrangement for integral membrane proteins because it shows important relationships of the helical sequence to vertical positioning within the membrane even without knowledge of how the helices are arranged in 3D.\n\nHelices observed in proteins can range from four to over forty residues long, but a typical helix contains about ten amino acids (about three turns). In general, short polypeptides do not exhibit much α-helical structure in solution, since the entropic cost associated with the folding of the polypeptide chain is not compensated for by a sufficient amount of stabilizing interactions. In general, the backbone hydrogen bonds of α-helices are considered slightly weaker than those found in β-sheets, and are readily attacked by the ambient water molecules. However, in more hydrophobic environments such as the plasma membrane, or in the presence of co-solvents such as trifluoroethanol (TFE), or isolated from solvent in the gas phase, oligopeptides readily adopt stable α-helical structure. Furthermore, crosslinks can be incorporated into peptides to conformationally stabilize helical folds. Crosslinks stabilize the helical state by entropically destabilizing the unfolded state and by removing enthalpically stabilized \"decoy\" folds that compete with the fully helical state.\n\nSince the α-helix is defined by its hydrogen bonds and backbone conformation, the most detailed experimental evidence for α-helical structure comes from atomic-resolution X-ray crystallography such as the example shown at right. It is clear that all the backbone carbonyl oxygens point downward (toward the C-terminus) but splay out slightly, and the H-bonds are approximately parallel to the helix axis. Protein structures from NMR spectroscopy also show helices well, with characteristic observations of nuclear Overhauser effect (NOE) couplings between atoms on adjacent helical turns. In some cases, the individual hydrogen bonds can be observed directly as a small scalar coupling in NMR.\n\nThere are several lower-resolution methods for assigning general helical structure. The NMR chemical shifts (in particular of the formula_5, formula_6 and formula_7 atoms) and residual dipolar couplings are often characteristic of helices. The far-UV (170-250 nm) circular dichroism spectrum of helices is also idiosyncratic, exhibiting a pronounced double minimum at ~208 nm and ~222 nm. Infrared spectroscopy is rarely used, since the α-helical spectrum resembles that of a random coil (although these might be discerned by, e.g., hydrogen-deuterium exchange). Finally, cryo electron microscopy is now capable of discerning individual α-helices within a protein, although their assignment to residues is still an active area of research.\n\nLong homopolymers of amino acids often form helices if soluble. Such long, isolated helices can also be detected by other methods, such as dielectric relaxation, flow birefringence, and measurements of the diffusion constant. In stricter terms, these methods detect only the characteristic prolate (long cigar-like) hydrodynamic shape of a helix, or its large dipole moment.\n\nDifferent amino-acid sequences have different propensities for forming α-helical structure. Methionine, alanine, leucine, glutamate, and lysine uncharged (\"MALEK\" in the amino-acid 1-letter codes) all have especially high helix-forming propensities, whereas proline and glycine have poor helix-forming propensities. Proline either breaks or kinks a helix, both because it cannot donate an amide hydrogen bond (having no amide hydrogen), and also because its sidechain interferes sterically with the backbone of the preceding turn - inside a helix, this forces a bend of about 30° in the helix axis. However, proline is often seen as the \"first\" residue of a helix, it is presumed due to its structural rigidity. At the other extreme, glycine also tends to disrupt helices because its high conformational flexibility makes it entropically expensive to adopt the relatively constrained α-helical structure.\n\nEstimated differences in free energy, formula_8, estimated in kcal/mol per residue in an alpha-helical configuration, relative to Alanine arbitrarily set as zero. Higher numbers (more positive free energies) are less favoured. Significant deviations from these average numbers are possible, depending on the identities of the neighbouring residues.\n\nA helix has an overall dipole moment due to the aggregate effect of the individual microdipoles from the carbonyl groups of the peptide bond pointing along the helix axis. The effects of this macrodipole are a matter of some controversy. α-helices often occur with the N-terminal end bound by a negatively charged group, sometimes an amino acid side chain such as glutamate or aspartate, or sometimes a phosphate ion. Some regard the helix macrodipole as interacting electrostatically with such groups. Others feel that this is misleading and it is more realistic to say that the hydrogen bond potential of the free NH groups at the N-terminus of an α-helix can be satisfied by hydrogen bonding; this can also be regarded as set of interactions between local microdipoles such as C=O...H-N.\n\nCoiled-coil α helices are highly stable forms in which two or more helices wrap around each other in a \"supercoil\" structure. Coiled coils contain a highly characteristic sequence motif known as a heptad repeat, in which the motif repeats itself every seven residues along the sequence (\"amino acid\" residues, not DNA base-pairs). The first and especially the fourth residues (known as the \"a\" and \"d\" positions) are almost always hydrophobic; the fourth residue is typically leucine - this gives rise to the name of the structural motif called a \"leucine zipper\", which is a type of coiled-coil. These hydrophobic residues and pack together in the interior of the helix bundle. In general, the fifth and seventh residues (the \"e\" and \"g\" positions) have opposing charges and form a salt bridge stabilized by electrostatic interactions. Fibrous proteins such as keratin or the \"stalks\" of myosin or kinesin often adopt coiled-coil structures, as do several dimerizing proteins. A pair of coiled-coils - a four-helix bundle - is a very common structural motif in proteins. For example, it occurs in human growth hormone and several varieties of cytochrome. The Rop protein, which promotes plasmid replication in bacteria, is an interesting case in which a single polypeptide forms a coiled-coil and two monomers assemble to form a four-helix bundle.\n\nThe amino acids that make up a particular helix can be plotted on a helical wheel, a representation that illustrates the orientations of the constituent amino acids (see the article for leucine zipper for such a diagram). Often in globular proteins, as well as in specialized structures such as coiled-coils and leucine zippers, an α-helix will exhibit two \"faces\" - one containing predominantly hydrophobic amino acids oriented toward the interior of the protein, in the hydrophobic core, and one containing predominantly polar amino acids oriented toward the solvent-exposed surface of the protein.\n\nMyoglobin and hemoglobin, the first two proteins whose structures were solved by X-ray crystallography, have very similar folds made up of about 70% α-helix, with the rest being non-repetitive regions, or \"loops\" that connect the helices. In classifying proteins by their dominant fold, the Structural Classification of Proteins database maintains a large category specifically for all-α proteins.\n\nHemoglobin then has an even larger-scale quaternary structure, in which the functional oxygen-binding molecule is made up of four subunits.\n\nα-Helices have particular significance in DNA binding motifs, including helix-turn-helix motifs, leucine zipper motifs and zinc finger motifs. This is because of the convenient structural fact that the diameter of an α-helix is about 12Å (1.2 nm) including an average set of sidechains, about the same as the width of the major groove in B-form DNA, and also because coiled-coil (or leucine zipper) dimers of helices can readily position a pair of interaction surfaces to contact the sort of symmetrical repeat common in double-helical DNA (see Branden & Tooze, chapter 10). An example of both aspects is the transcription factor Max (see image at left), which uses a helical coiled-coil to dimerize, positioning another pair of helices for interaction in two successive turns of the DNA major groove.\n\nα-Helices are also the most common protein structure element that crosses biological membranes (transmembrane protein) it is presumed because the helical structure can satisfy all backbone hydrogen-bonds internally, leaving no polar groups exposed to the membrane if the sidechains are hydrophobic. Proteins are sometimes anchored by a single membrane-spanning helix, sometimes by a pair, and sometimes by a helix bundle, most classically consisting of seven helices arranged up-and-down in a ring such as for rhodopsins (see image at right) or for [G protein–coupled receptor]s (GPCRs).\n\nα-Helices under axial tensile deformation, a characteristic loading condition that appears in many alpha-helix-rich filaments and tissues, results in a characteristic three-phase behavior of stiff-soft-stiff tangent modulus. Phase I corresponds to the small-deformation regime during which the helix is stretched homogeneously, followed by phase II, in which alpha-helical turns break mediated by the rupture of groups of H-bonds. Phase III is typically associated with large-deformation covalent bond stretching.\n\nAlpha-helices in proteins may have low-frequency accordion-like motion as observed by the Raman spectroscopy and analyzed via the quasi-continuum model. Helices not stabilized by tertiary interactions show dynamic behavior, which can be mainly attributed to helix fraying from the ends.\n\nHomopolymers of amino-acids (such as poly-lysine) can adopt α-helical structure at low temperature that is \"melted out\" at high temperatures. This helix-coil transition was once thought to be analogous to protein denaturation. The statistical mechanics of this transition can be modeled using an elegant transfer matrix method, characterized by two parameters: the propensity to initiate a helix and the propensity to extend a helix.\n\nAt least five artists have made explicit reference to the α-helix in their work: Julie Newdoll in painting and Julian Voss-Andreae, Bathsheba Grossman, Byron Rubin, and Mike Tyka in sculpture.\n\nSan Francisco area artist Julie Newdoll, who holds a degree in Microbiology with a minor in art, has specialized in paintings inspired by microscopic images and molecules since 1990. Her painting \"Rise of the Alpha Helix\" (2003) features human figures arranged in an α helical arrangement. According to the artist, \"the flowers reflect the various types of sidechains that each amino acid holds out to the world\". It is interesting to note that this same metaphor is also echoed from the scientist's side: \"β sheets do not show a stiff repetitious regularity but flow in graceful, twisting curves, and even the α-helix is regular more in the manner of a flower stem, whose branching nodes show the influence of environment, developmental history, and the evolution of each part to match its own idiosyncratic function.\"\n\nJulian Voss-Andreae is a German-born sculptor with degrees in experimental physics and sculpture. Since 2001 Voss-Andreae creates \"protein sculptures\" based on protein structure with the α-helix being one of his preferred objects. Voss-Andreae has made α-helix sculptures from diverse materials including bamboo and whole trees. A monument Voss-Andreae created in 2004 to celebrate the memory of Linus Pauling, the discoverer of the α-helix, is fashioned from a large steel beam rearranged in the structure of the α-helix. The tall, bright-red sculpture stands in front of Pauling's childhood home in Portland, Oregon.\n\nRibbon diagrams of α-helices are a prominent element in the laser-etched crystal sculptures of protein structures created by artist Bathsheba Grossman, such as those of insulin, hemoglobin, and DNA polymerase. Byron Rubin is a former protein crystallographer now professional sculptor in metal of proteins, nucleic acids, and drug molecules - many of which featuring α-helices, such as subtilisin, human growth hormone, and phospholipase A2.\n\nMike Tyka is a computational biochemist at the University of Washington working with David Baker. Tyka has been making sculptures of protein molecules since 2010 from copper and steel, including ubiquitin and a potassium channel tetramer.\n\n\n", "id": "3054", "title": "Alpha helix"}
{"url": "https://en.wikipedia.org/wiki?curid=3055", "text": "Accrington\n\nAccrington is a town in the Hyndburn borough of Lancashire, England. It lies about east of Blackburn, west of Burnley, east of Preston, north of Manchester city centre and is situated on the mostly culverted River Hyndburn. Commonly abbreviated by locals to \"Accy\", the town has a population of 54,800 according to the 2001 census and the urban area has a population of over 85,000.\n\nAccrington is a former centre of the cotton and textile machinery industries. The town is famed for manufacturing the hardest and densest building bricks in the world, \"The Accrington NORI\" (iron), which were used in the construction of the Empire State Building and for the foundations of Blackpool Tower; famous for Accrington Stanley F.C. and the Haworth Art Gallery which holds Europe's largest collection of Tiffany glass.\n\nThe name Accrington appears to be Anglo-Saxon in origin. In the records it variously appears as \"Akarinton\" in 1194; \"Akerunton\", \"Akerinton\" and \"Akerynton\" in 1258; \"Acrinton\" in 1292; \"Ackryngton\" in 1311 and \"Acryngton\" in 1324.\n\nThe name may mean \"acorn farmstead\" from Anglo-Saxon \"æcern\" meaning \"acorn\" and \"tun\" meaning \"farmstead\" or \"village\". The southern part of Accrington, the township of New Accrington, was formerly in the Forest of Blackburnshire and the presence of oak trees may be inferred from local place names like Broad Oak and Oak Hill. The products of oak trees were once an important food for swine and a farmstead may have been named for such produce. Anglo-Saxon \"ᴁcerntun\" might become Middle English \"Akerenton\", \"Akerinton\" and the like. Also worth considering is that in the Lancashire dialect \"acorn\" was \"akran\".\n\nThere is no known Old English personal name from which the first element can be derived. But if the Frisian names \"Akkrum\", \"Akkeringa\" and Dutch name \"Akkerghem\", are derived from the personal name \"Akker\" there may be a corresponding Old English name from which \"Accrington\" may be derived.\n\nAccrington covers two townships which were established in 1507 following disafforestation; those of Old Accrington and New Accrington which were merged in 1878 with the incorporation of the borough council. There have been settlements there since the medieval period, likely in the Grange Lane and Black Abbey area, and the King's Highway which passes above the town was at one time used by the kings and queens of England when they used the area for hunting when the Forest of Accrington was one of the four forests of the hundred of Blackburnshire.\n\nRobert de Lacy gave the manor of Accrington to the monks of Kirkstall in the 12th century. The monks built a grange there; removing the inhabitants to make room for it. The locals got their revenge by setting fire to the new building, destroying its contents and in the process killing the three lay brothers who occupied it. An area of the town is named 'Black Abbey', a possible reference to the murders. Regardless of whatever happened, Accrington did not remain under monastic control for long before reverting to the de Lacys.\n\nIt is thought the monks of Kirkstall may have built a small chapel there during their tenure for the convenience of those in charge residing there and their tenants, but the records are uncertain. What is known is that there was a chapel in Accrington prior to 1553 where the vicar of Whalley was responsible for the maintenance of divine worship. However it did not have its own minister and it was served, when at all, by the curate of one of the adjacent chapels. In 1717 Accrington was served by the curate of Church, who preached there only once a month. St. James's Church was built in 1763, replacing the old chapel however it did not achieve parochial status until as late as 1870.\n\nUntil around 1830 visitors considered Accrington to be just a \"considerable village\". The Industrial Revolution, however, resulted in large changes and Accrington’s location on the confluence of a number of streams made it attractive to industry and a number of mills were built in the town in the mid-eighteenth century. Further industrialisation then followed in the late eighteenth century and local landowners began building mansions in the area on the outskirts of the settlement where their mills were located while their employees lived in overcrowded unsanitary conditions in the centre.\n\nIndustrialisation resulted in rapid population growth during the nineteenth century, as people moved from over north-west England to Accrington, with the population increasing from 3,266 in 1811 to 10,376 in 1851 to 43,211 in 1901 to its peak in 1911 at 45,029.\n\nThis fast population growth and slow response from the established church allowed non-conformism to flourish in the town. By the mid-nineteenth century there were Wesleyan, Primitive Methodist, United Free Methodist, Congregationalist, Baptist, Swedenborgian, Unitarian, Roman Catholic and Catholic Apostolic churches in the town. The Swedenborgian church was so grand that it was considered to be the ‘Cathedral’ of that denomination.\n\nFor many decades the textiles industry, the engineering industry and coal mining were the central activities of the town. Cotton mills and dye works provided work for the inhabitants, but often in very difficult conditions. There was regular conflict with employers over wages and working conditions. On 24 April 1826 over 1,000 men and women, many armed, gathered at Whinney Hill in Clayton-le-Moors to listen to a speaker from where they marched on Sykes’s Mill at Higher Grange Lane, near the site of the modern police station and Magistrate’s Courts, and smashed over 60 looms. These riots spread from Accrington through Oswaldtwistle, Blackburn, Darwen, Rossendale, Bury and Chorley. In the end after three days of riots 1,139 looms were destroyed, 4 rioters and 2 bystanders shot dead by the authorities in Rossendale and 41 rioters sentenced to death (all of whose sentences were commuted).\n\nIn the 1842 'plug riots' a general strike spread from town to town due to conditions in the town. In a population of 9,000 people as few as 100 were fully employed. From 15 August 1842 the situation boiled over and bands of men entered the mills which were running and stopped the machinery by knocking out the boiler plugs. This allowed the water and steam to escape shutting down the mill machinery. Thousands of strikers walked over the hills from one town to another to persuade people to join the strike in civil disturbances that lasted about a week. The strike was associated with the Chartist movement but eventually proved unsuccessful in its aims.\n\nIn the early 1860s the Lancashire cotton famine badly affected Accrington, although less so than the wider area due to its more diverse economy, with as many as half of the town's mill employees out of work at one time.\n\nConditions were such that a Local Board of Health was constituted in 1853 and the town itself incorporated in 1878 allowing the enforcement of local laws to improve the town.\n\nOne well-known association the town has is with the 'Accrington Pals', the nickname given to the smallest home town battalion of volunteers formed to fight in the First World War. The Pals battalions were a peculiarity of the 1914-18 war: Lord Kitchener, the Secretary of State for War, believed that it would help recruitment if friends and work-mates from the same town were able to join up and fight together. Strictly speaking, the 'Accrington Pals' battalion is properly known as the '11th East Lancashire Regiment': the nickname is a little misleading, since of the four 250-strong companies that made up the original battalion only one was composed of men from Accrington. The rest volunteered from other east Lancashire towns such as Burnley, Blackburn and Chorley.\n\nThe Pals' first day of action, 1 July 1916, took place in Serre, near Montauban in the north of France. It was part of the 'Big Push' (later known as the Battle of the Somme) that was intended to force the German Army into a retreat from the Western Front, a line they had held since late 1914. The German defences in Serre were supposed to have been obliterated by sustained, heavy, British shelling during the preceding week; however, as the battalion advanced it met with fierce resistance. 235 men were killed and a further 350 wounded — more than half of the battalion — within half an hour. Similarly desperate losses were suffered elsewhere on the front, in a disastrous day for the British Army (approximately 19,000 British soldiers were killed in a single day).\n\nLater in the year, the East Lancashire Regiment was rebuilt with new volunteers — in all, 865 Accrington men were killed during World War I. All of these names are recorded on a war memorial, an imposing white stone cenotaph, which stands in Oak Hill Park in the south of the town. The cenotaph also lists the names of 173 local fatalities from World War II. The trenches from which the Accrington Pals advanced on 1 July 1916 are still visible in John Copse west of the village of Serre, and there is a memorial there made of Accrington brick.\n\nAfter the war and until 1986, Accrington Corporation buses were painted in the regimental colours of red and blue with gold lining. The mudguards were painted black as a sign of mourning.\n\nThe 2001 census gave the population of Accrington town as 45,600. The figure for the urban area was 78,224, increased from 70,442 in 1991. This total includes Accrington, Church, Clayton-le-Moors, Great Harwood and Oswaldtwistle. For comparison purposes that is approximately the same size as Aylesbury, Carlisle, Guildford or Scunthorpe urban areas.\n\nThe borough of Hyndburn as a whole has a population of 88,996. This includes Accrington Urban Area and other outlying towns and villages such as; Altham, Baxenden, part of Belthorn, Huncoat, Rishton and Stanhill.\n\nFormerly cotton and textile machinery were important industries in the town. NORIs, a type of iron hard engineering brick, were produced nearby in Huncoat was closed in 2013, but later reopened in 2015. Mills and factories are Accrington's past but there a few factories and garages now occupy the old building.\n\nThe council has a regeneration plan in place, which will, according to the council, boost the local economy. The plan is to upgrade many old shops, and build a bus station. A memorial for the Accrington Pals may be built outside the town hall.\n\nThe Hyndburn Borough Council plans to spend £10 million to refurbish the town centre, which includes:\n\n\nHalf of Blackburn Road is being refurbished and is now being made into a more attractive shopping street, upgrading shops, adding more trees, and repaving the pavements.\n\nTwo new phases are being built, the first one called the Acorn Park, where new houses are being built with balconies and greener spaces, and Phoenix Place, which will also include new housing and the building of a new mosque to help the overcrowding of nearby mosques. The wood nook area has the highest amount of abandoned housing in Hyndburn, which is also being refurbished and extended for sale to new families.\n\nAccrington is a hill town located at the western edge of the Pennines within a bowl and largely encircled by surrounding hills to heights of 300-400m. The Hyndburn or Accrington Brook flows through the centre of the town. Hill settlements origins were as the economic foci of the district engaging in the spinning and weaving of woolen cloth. Wool, lead and coal were other local industries.\nGeographical coordinates: 53° 46' 0\" North, 2° 21' 0\" West. Height above sea level: there is a spot height outside the Market Hall which is 133.5m; the bench mark on the side of the neighbouring Town Hall is 441.10 feet. The highest height in the town is 320m which is in Baxenden and the lowest is the town hall which is at 132.5m. most of the town is around 200m.\n\nThe town has strong local travel links as Accrington railway station lies on the East Lancashire Line serving trains running locally and trains running from Blackpool to York. However, recent changes to the train timetables have been a disservice to Accrington, increasing the journey time to Preston (a vital link to London or Scotland) by up to 1.5 hours. However, there are still buses to Manchester every thirty minutes as well as more frequent services to other towns in east Lancashire. The main road running through the town centre is the A680 running from Rochdale to Whalley. The town is served by junction seven of the M65 and is linked from the A680 and the A56 dual carriageway which briefly merge; linking to the M66 motorway heading towards Manchester. The closest airports are Manchester Airport at , Blackpool Airport at and Leeds Bradford Airport at .\n\nThere was once a rail link south to Manchester via Haslingden and Bury, but this was closed in the 1960s as part of cuts following the Beeching Report. The trackbed from Accrington to Baxenden is now a linear treelined cycleway/footpath. A train service to Manchester via the Todmorden Curve opened in 2015. A new bus station is being built in Accrington too.\n\nBus operators Pilkington Bus and M&M Coaches are based in Accrington, and Holmeswood Coaches, Rosso and Transdev Blazefield subsidiaries Transdev in Burnley & Pendle and Blackburn Bus Company also provide bus services in the town; routes serve places such as Blackburn, Oswaldtwistle, Rishton, Burnley and Clitheroe. However M&M Coaches ceased business suddenly on the 21st September \n\nAccrington Library, on St James Street, is a Carnegie library that opened in 1908. It is noted for its stained glass window designed by Gustav Hiller and as a place of inspiration for the young Jeanette Winterson.\n\nNear the Tesco supermarket, there is Accrington Skate Park which is popular during the school holidays. On Broadway, Accrington Police Station serves the Borough of Hyndburn. In April 2003, Hyndburn Community Fire Station opened, also serving the Borough of Hyndburn.\n\nThe town is served by the Lancashire Constabulary Police station on Manchester Road. The police station is now moving into town as an effort to save money due to rising expenses and decreasing funding by the government. Crime is very low in Accrington compared to nearby towns.\n\nAccrington is represented in parliament as a part of the constituency of Hyndburn. The constituency boundaries do not align exactly with those of the district of the same name.\n\nAccrington was first represented nationally after the Redistribution of Seats Act 1885 after the 1885 general election by Accrington (UK Parliament constituency). This seat was abolished in the 1983 general election and replaced with the present constituency of Hyndburn (UK Parliament constituency).\n\nAccrington became incorporated as a municipal borough in 1878. Under the Local Government Act 1972, since 1974, the town has formed part of the larger Borough of Hyndburn including the former Urban Districts of Oswaldtwistle, Church, Clayton-le-Moors, Great Harwood and Rishton.\n\nHyndburn consists of 16 wards, electing a total of 35 councillors. Due to its size Accrington is represented by a number of wards in the Borough of Hyndburn. The town largely consists of the Milnshaw, Peel, Central, Barnfield and Spring Hill wards, although some parts of those wards are in other towns in the borough.\n\nThe local hospital is Accrington Victoria Hospital however, as it only deals with minor issues, Accident and Emergency is provided by the Royal Blackburn Hospital. Other services are provided at the Accrington Pals Primary Health Care Centre and the Accrington Acorn Primary Health Care Centre.\n\nThe chief publications in the area are the weekly \"Accrington Observer\", part of MEN media, and the \"Lancashire Telegraph\". Accrington Observer is currently stationed within the Market Hall.\n\nA Ron Hill 10K marathon happens every year at the end of March or start of April and is named for the local Olympic runner for Britain Ron Hill. The marathon goes around town and through the local countrysides, and is organised by the council and local businesses. There is also an annual 1K family run which began in 2014. In 2015 more than five hundred runners ran in the race. Their also a race held by the local rotary around August time.\n\nAccrington Stanley F.C., entered the Football League in 1921 with the formation of the old Third Division (North); after haunting the lower reaches of English football for forty years, they eventually resigned from the League in 1962, due to financial problems, and folded in 1965. The club was reformed three years later and then worked its way through the non-league divisions to reach the Nationwide Conference in 2003. In the 2005–06 season, Stanley, after winning against Woking with three matches to spare, secured a place back in the Football League and the town celebrated with a small parade and honours placed on senior executives of the team. One of the teams relegated—and thus being replaced by Stanley—were Oxford United, who were voted into the Football League to replace the previous Accrington Stanley. The football stadium is called the Crown Ground. Until the 2012-13 season, when Fleetwood Town entered the league, Accrington was the smallest town in England and Wales with a Football League club.\n\nAccrington Stanley Football Club has had its own pub in the town, the Crown, since July 2007.\n\nAn earlier club, Accrington F.C., were one of the twelve founder members of the Football League in 1888. However, their time in league football was even less successful and considerably briefer than that of Accrington Stanley: they dropped out of the league in 1893 and folded shortly afterwards due to financial problems. The town of Accrington thus has the unique \"distinction\" of having lost two separate clubs from league football. They are currently placed in League 2 alongside local club [Blackpool]\n\nAccrington has a cricket ground. Cricket is also played in parks.Schools nearby have shown major interest in cricket and have held cricket training and tournaments.\n\nAccrington has a golf course.\n\nThere are many gyms in the town and the council has held fitness classes for the women and old people. There are two sports centres, the main on being the Hyndburn Sports Centre, Which is currently renovating their swimming pool area. near Lidl.\n\nList of primary schools in Accrington;\n\nSecondary schools serving Accrington are:\n\nAll the secondary schools compete each other to achieve better results which resulted in the Hollins Technology College winning an award from SSAT for fantastic progress. The Hollins is also within the top 3% In the country and well known for its development.\nThe college in the town centre is Accrington and Rossendale College; nearby universities include University Centre at Blackburn College, and the University of Central Lancashire in Preston. There is also a library near the town centre where books and internet are available.\n\nThe Haworth Art Gallery was previously a mansion named as Hollins Hill Mansion. The museum houses a collection of Tiffany glassware presented to the town by Joseph Briggs, an Accrington man who had joined Tiffany’s in the late 19th century and eventually became art director and assistant manager.It is situated in Haworth Park on Manchester Road.\nThe Viaduct is a bridge which has a railway line on it, it goes through the town and has many storage units and shop on sale buy the National Rail. The Viaduct ends at the Accrington Eco Station.\nThe Accrington Town Hall was built in the 19th century and is also listed. It has a reception rooms where pantomimes and fitness clubs are held. Weddings could also be held there. The town hall is on Blackburn Road near The Arcade.\nThe Arcade is a Victorian shopping Centre with about 10-15 outlets and has many restaurants there. It is on Church street near the town hall. The arcade has hardware shops and shops like Argos. There are some restaurants in there too. Sadly most outlets are closing since the year 2013. In 2016, there was a revamp of the Arcade which saw specialist shops such as Darts, Vinyl and Knitted Wear added into the Arcade. \nOakhill Park is a large and old park with a sceneric view of Accrington. It has won many awards such as the best park in Lancashire It has also been awarded an Eco Award. The Haworth Art Gallery is in the park. It is on Manchester Road.\nPeel Park is a park in Accrington which was opened by William Peel on 29 September 1909. The Coppice is a hill within the park, and provides a 2.2 mile scenic walk around the park. There was a centenary celebration marking 100 years from the Coppice being handed over to the people of Accrington on 26 September 2009. There was also a refurbishment of the paths and monument at the top of the Coppice at this time. Since then there has been several revamps to the Playground area of the park.\n\n\nThe centre of Accrington is located around a pedestrianised street called Broadway with shops on both sides, which connects Blackburn Road to Whalley Road. On one side of Broadway forms part of a shopping centre called the Accrington Arndale, which consists of 52 retail units, and opened in October 1987. There are two retail parks, the main one which consists of four high street chains. The markets, with indoor and outdoor stalls, are on Blackburn Road next to the Town Hall.\n\nThe indoor market was opened in 1869 and the Market Hall is now a listed building; in 2010 it was refurbished and the following year it was named as best indoor market in a National Association of British Market Authorities competition. The outdoor market, with 37 stalls, is next to it and opens most days\n\nThe town centre is home to a number of high street multiples, including: Fulton's Foods, Greggs, Argos, EE, Specsavers, cex, Wilko, Shoe Zone, Superdrug, Costa Coffee, Sports Direct, Cash Generator, GAME, Santander, Poundland, Timpson, Vodafone, Coral, Althams Travel, Ladbrokes, Paddy Power, Grainger Games, Carphone Warehouse, Wilko, O2, Halifax, British Heart Foundation, Post Office, Thomas Cook, Thomson, Peacocks, Burton, Holland & Barrett, NatWest, Dorothy Perkins, WHSmith, Nationwide, Iceland, Blue Inc, Boots Opticians, Sense, Card Factory, Subway, Boots, Store Twenty One, Poundworld, Peacocks, B&M Bargains, Wetherspoons, and a mix of other shops.\n\nIn March 2015, Subway announced plans to open a second store in Accrington. In September 2016, Papa John's Pizza announced plans to open within the Accrington Arndale.\n\nFast-food restaurants include; McDonald's, Burger King, [Subway] and KFC. Real Cafe is also set to return to the Streak Food Court. A BT Call Centre is also in town, employing many local people. A Viaduct VUE cinema is located in the town, having opened in October 2002, part of an entertainment complex which also had bowling alley, Accrington Super Bowl, which closed in 2013. Farmfoods and Domino's Pizza announced that they would open stores in the former Accrington Super Bowl. In July 2016, Farmfoods opened, with Domino's Pizza to follow shortly afterwards.\n\nNear the town centre, there is a small retail park which includes a Home Bargains, Pets at Home, Iceland and Poundstretcher, in a shopping development known as Eastgate Retail Park, which opened in 1998. In June 2015, Iceland announced plans to open on the retail park. It opened in September 2015.\n\nA Tesco Extra is on Eagle Street, which opened in 2010, and an Asda on Hyndburn Road, which opened in 1985, being the main supermarkets with discount retailers, such as Aldi, Lidl, which reopened following an rebuild. A Homebase was located in the town, but it closed in February 2015, and was converted into an B&M Homestore. A Halfords Autocentre is located in the town, as are Kwik Fit, ATS Euromaster, and National Tyres. \"Fountain Retail Park\", which opened in 1998, in honour of the aforementioned works, includes a Matalan.\n\nIn Whitebirk, a retail park, the Peel Centre, includes an Currys, PC World, Onit Furniture, Dreams, Smyths Toys Superstore, B&M Bargains, ScS Sofas, Sofaworks, Harveys Furniture & Bensons for Beds. In January 2015, Smyths Toys Superstore announced plans to open in the park, and opened in October 2015. B&M Bargains also has presence in the centre. The Range has an store in Whitebirk, located where B&Q used to be in Blackburn, before it relocated in September 2004 to the Nova Scotia Retail Park, in the Grimshaw Park area. In December 2015, Aldi announced plans to open in the park. In April 2016, the plans were approved, although the application saw opposition.\n\nThe Dunkenhalgh Hotel is owned by Mercure Hotels. In May 2012, Queen Elizabeth II stayed at the hotel, during her visit to Lancashire.\n\nThe Peel Group, the site's owner, have repetitively have had planning permission denied for a controversial expansion of the park, first in May 2005, then June 2007, and most recently August 2014, by the High Court, after an appeal was lodged. They wanted the use of the site to be changed, by adding ASDA Living, Boots, and Next, trying to make a \"copy\" of Preston's Deepdale, as well as relocating other stores. In June 2007, then–Blackburn MP Jack Straw announced that it would be the \"death knell\" for Blackburn, as did then–Hyndburn MP Greg Pope, saying that it would be the \"death knell\" for Accrington.\n\nAs well as motor dealerships from Ford (Peoples), Vauxhall & Chevrolet (Accrington Garages), the town was home to an Arnold Clark (previously Bowker BMWMini) car dealer, which closed down in 2010, and was demolished in January 2015. This was in order to make way for Brickworks, which opens in July 2015. BP, Esso (which includes a Tesco Express), and Texaco operate garages in the town. An out of town business park, Accrington Trade Park, which opened in 2004, includes an Screwfix, Eurocell, James Hargreaves, and Howdens.\n\n\n\n", "id": "3055", "title": "Accrington"}
{"url": "https://en.wikipedia.org/wiki?curid=3058", "text": "Armageddon\n\nAccording to the Book of Revelation, Armageddon (, from \"Harmagedōn\", Late Latin: ) is the prophesied location of a gathering of armies for a battle during the end times, variously interpreted as either a literal or a symbolic location. The term is also used in a generic sense to refer to any end of the world scenario.\n\n\"Mount\" Tel Megiddo is not actually a mountain, but a tell (a hill created by many generations of people living and rebuilding on the same spot) on which ancient forts were built to guard the Via Maris, an ancient trade route linking Egypt with the northern empires of Syria, Anatolia and Mesopotamia. Megiddo was the location of various ancient battles, including one in the 15th century BC and one in 609 BC. Modern Megiddo is a town approximately west-southwest of the southern tip of the Sea of Galilee in the Kishon River area in Palestine.\n\nThe word \"Armageddon\" appears only once in the Greek New Testament, in . The word is translated to Greek from Hebrew \"har məgiddô\" (), \"har\" (Strong H2022) meaning \"a mountain or range of hills (sometimes used figuratively): - hill (country), mount (-ain), X promotion.\" This is a shortened form of \"Harar\" (Strong H2042) \"to loom up; a mountain; -hill, mount\". \"Megiddo\" (Strong מְגִדּוֹן H4023) /meg-id-do'/ \"Megiddon or Megiddo, a place of crowds.\") The name refers to a fortification made by King Ahab (869-50 BC) that dominated the Plain of Jezreel.\n\nMegiddo is mentioned twelve times in the Old Testament, ten times in reference to the ancient city of Megiddo, and twice with reference to \"the plain of Megiddo\", most probably simply meaning \"the plain next to the city\".\nNone of these Old Testament passages describes the city of Megiddo as being associated with any particular prophetic beliefs. The one New Testament reference to the city of Armageddon found in in fact also makes no specific mention of any armies being predicted to one day gather in this city, but instead seems to predict only that \"they (will gather) the kings together to ... Armageddon\". \nThe text does however seem to imply, based on the text from the earlier passage of Revelation 16:14, that the purpose of this gathering of kings in the \"place called Armageddon\" is \"for the war of the great day of God, the Almighty\".  Because of the seemingly highly symbolic and even cryptic language of this one New Testament passage, some Christian scholars conclude that Mount Armageddon must be an idealized location. Rushdoony says, \"There are no mountains of Megiddo, only the Plains of Megiddo. This is a deliberate destruction of the vision of any literal reference to the place.\" \nOther scholars, including C. C. Torrey, Kline and Jordan argue that the word is derived from the Hebrew \"moed\" (), meaning \"assembly\".  Thus, \"Armageddon\" would mean \"Mountain of Assembly,\" which Jordan says is \"a reference to the assembly at Mount Sinai, and to its replacement, Mount Zion.\"\n\nThe traditional viewpoint interprets this Bible prophecy to be symbolic of the progression of the world toward the \"great day of God, the Almighty\" in which the great looming mountain of God's just and holy wrath is poured out against unrepentant sinners, led by Satan, in a literal end-of-the-world final confrontation. Armageddon is the symbolic name given to this event based on scripture references regarding divine obliteration of God's enemies. The hermeneutical method supports this position by referencing Judges 4 and 5 where God miraculously destroys the enemy of His elect, Israel, at Megiddo, also called the Valley of Josaphat.\n\nChristian scholar William Hendriksen says:\nThe Dispensational viewpoint interprets biblical prophecy literally and expects that the fulfillment of prophecy will also be literal, depending upon the context of scripture.  In his discussion of Armageddon, J. Dwight Pentecost has devoted an entire chapter to the subject, titled \"The Campaign of Armageddon\", in which he discusses Armageddon as a campaign and not a specific battle, which will be fought in the Middle East. Pentecost writes:\nPentecost then discusses the location of this campaign, and mentions the \"hill of Megiddo\" and other geographic locations such as \"the valley of Jehoshaphat\" and \"the valley of the passengers\", \"Lord coming from Edom or Idumea, south of Jerusalem, when He returns from the judgment\"; and Jerusalem itself.\n\nPentecost further describes the area involved:\nPentecost then outlines the biblical time period for this campaign to occur and with further arguments concludes that it must take place with the 70th week of Daniel. The invasion of Israel by the Northern Confederacy \"will bring the Beast and his armies to the defense of Israel as her protector\". He then uses Daniel to further clarify his thinking: (Dan. 11:40b-45).\n\nAgain, events are listed by Pentecost in his book:\n\nAfter the destruction of the Beast at the Second Coming of Jesus, the promised Kingdom is set up, in which Jesus and the Saints will rule for a thousand years. Satan is then loosed \"for a season\" and goes out to deceive the nations, specifically, Gog and Magog. The army mentioned attacks the Saints in the New Jerusalem, they are defeated by a judgment of fire coming down from Heaven, and then comes the Great White Throne judgment, which includes all of those through the ages and these are cast into the Lake of Fire, which event is also known as the \"second death\" and Gehenna, not to be confused with Hell, which is Satan's domain. Pentecost describes this as follows:\n\nJehovah's Witnesses believe that Armageddon is the means by which God will fulfill his purpose for the Earth to be populated with happy healthy humans free of sin and death. They teach that the armies of heaven will eradicate all who oppose the Kingdom of God, wiping out all wicked humans on Earth, leaving only righteous mankind.\n\nThey believe that the gathering of all the nations of the earth refers to the uniting of the world's political powers, as a gradual process beginning in 1914 and seen later in manifestations such as the League of Nations and the United Nations following the First and Second World Wars. These political powers are said to be influenced by Satan and his demons in opposition to God's kingdom. Babylon the Great is interpreted as the world empire of false religion, and that it will be destroyed by the beast just prior to Armageddon. Witnesses believe that after all other religions have been destroyed, the governments will turn to persecute them, and that God will then intervene, precipitating Armageddon.\nJehovah's Witnesses teach that the armies of heaven, led by Jesus, will then destroy all forms of human government and then Jesus, along with a selected 144,000 humans, will rule Earth for 1,000 years. They believe that Satan and his demons will be bound for that period, unable to influence mankind. After the 1,000 years are ended, and the second resurrection has taken place, Satan is released and allowed to tempt the perfect human race one last time. Those who follow Satan are destroyed, along with him, leaving the earth, and humankind at peace with God forever, free of sin and death.\n\nThe religion's current teaching on Armageddon originated in 1925 with former Watch Tower Society president J. F. Rutherford, who based his interpretations on the books of Exodus, Jeremiah, Ezekiel and Psalms as well as additional material from the books of Samuel, Kings and Chronicles. The doctrine marked a further break from the teachings of Watch Tower Society founder Charles Taze Russell, who for decades had taught that the final war would be an anarchistic struggle for domination on earth. Tony Wills, author of a historical study of Jehovah's Witnesses, claimed that Rutherford seemed to relish his descriptions of how completely the wicked would be destroyed at Armageddon, dwelling at great length on prophecies of destruction. He stated that towards the close of his ministry Rutherford allocated about half the space available in \"The Watchtower\" magazines to discussion of Armageddon.\n\nThe teachings of the Seventh-day Adventist Church state that the terms \"Armageddon\", \"Day of the Lord\" and \"The Second Coming of Christ\" all describe the same event. Seventh-day Adventists further teach that the current religious movements taking place in the world are setting the stage for Armageddon, and they are concerned by an anticipated unity between spiritualism, American Protestantism and Roman Catholicism. A further significant difference in Seventh-day Adventist theology is the teaching that the events of Armageddon will leave the earth desolate for the duration of the millennium. They teach that the righteous will be taken to heaven while the rest of humanity will be destroyed, leaving Satan with no one to tempt and effectively \"bound.\" The final re-creation of a \"new heaven and a new earth.\" then follows the millennium.\n\nFor Christadelphians, Armageddon marks the \"great climax of history when the nations would be gathered together 'into a place called in the Hebrew tongue Armageddon', and the judgment on them would herald the setting up of the Kingdom of God.\" \n\nIn Ahmadiyya, Armageddon is viewed as a spiritual battle or struggle in the present age between the forces of good, i.e. righteousness, purity and virtue, and the forces of evil. The final struggle between the two comes as satanic influence is let loose with the emergence of Gog and Magog. Satan gathers all his powers, and uses all his methods to mislead people, introducing an age where iniquity, promiscuity, atheism, and materialism abound.\n\nAhmadiyya believe that God appointed Promised Messiah and Mahdi for the spiritual reformation and moral direction of mankind. This age continues for approximately one thousand years as per Judeo-Christian and Islamic prophecies of the Apocalypse; it is characterised by the assembling of mankind under one faith, Islam in Ahmadiyya belief.\n\nFrom Bahá'í literature a number of interpretations of the expectations surrounding the Battle of Armageddon may be inferred, three of them being associated with events surrounding the World Wars.\n\nThe first interpretation deals with a series of tablets written by Bahá'u'lláh, founder of the Bahá'í Faith, to be sent to various kings and rulers. The second, and best-known one, relates to events near the end of World War I involving General Allenby and the Battle of Megiddo (1918) wherein World Powers are said to have drawn soldiers from many parts of the world to engage in battle at Megiddo. In winning this battle Allenby also prevented the Turks from killing 'Abdu'l-Baha, then head of the Baha'i Faith, whom they had intended to crucify. A third interpretation reviews the overall progress of the World Wars, and the situation in the world before and after.\n\nThe idea that a final Battle of Armageddon will be fought at Tel Megiddo has had a wide influence, especially in the US. According to Donald E. Wagner, Professor of Religion and Director of the Center for Middle Eastern Studies at North Park University, Ronald Reagan was an adherent of \"Armageddon theology,\" and \"seemed to blend his political analysis with his Armageddon theology quite naturally.\"\n\nAn American militia group called Hutaree, based on the idea that it will soon defend itself from the Antichrist's armies, received wide attention in 2010, when several members were indicted for plotting to kill a police officer and plant roadside bombs along the funeral procession. The charges were dismissed.\n\n", "id": "3058", "title": "Armageddon"}
{"url": "https://en.wikipedia.org/wiki?curid=3060", "text": "Athlon\n\nAthlon is the brand name applied to a series of x86-compatible microprocessors designed and manufactured by Advanced Micro Devices (AMD). The original Athlon (now called \"Athlon Classic\") was the first seventh-generation x86 processor. The original Athlon was the first desktop processor to reach speeds of one gigahertz (GHz). AMD has continued using the \"Athlon\" name with the Athlon 64, an eighth-generation processor featuring x86-64 (later renamed AMD64) architecture, and the Athlon II. AMD also uses the \"Athlon\" name for some of its series of APUs targeting the Socket AM1 desktop SoC architecture.\n\nThe Athlon made its debut on June 23, 1999. Athlon comes from the Greek άθλος (\"athlos\") meaning ″contest″.\n\nAMD founder (and then-CEO) Jerry Sanders aggressively pursued strategic partnerships and engineering talent in the late 1990s, desiring to leverage the success AMD had gained in the PC market with the preceding AMD K6 line of processors. One major partnership announced in 1998 paired AMD with semiconductor giant Motorola to co-develop copper-based semiconductor technology, and resulted with the K7 project being the first commercial processor to utilize copper fabrication technology. In the announcement, Sanders referred to the partnership as creating a \"virtual gorilla\" that would enable AMD to compete with Intel on fabrication capacity while limiting AMD's financial outlay for new facilities.\n\nThe K7 design team was led by Dirk Meyer, who had worked as a lead engineer at DEC on multiple Alpha microprocessors during his employment at DEC. When DEC was sold to Compaq in 1998, the company discontinued Alpha processor development. Sanders approached many of the Alpha engineering staff as Compaq/DEC wound down their semiconductor business, and was able to bring in nearly all of the Alpha design team. The K7 engineering design team was thus now consisted of both the previously acquired NexGen K6 team (already including engineers such as Vinod Dham) and the nearly complete Alpha design team.\n\nIn August 1999, AMD released the Athlon (K7) processor.\n\nBy working with Motorola, AMD was able to refine copper interconnect manufacturing to the production stage about one year before Intel. The revised process permitted 180-nanometer processor production. The accompanying die-shrink resulted in lower power consumption, permitting AMD to increase Athlon clock speeds to the 1 GHz range. Yields on the new process exceeded expectations, permitting AMD to deliver high speed chips in volume in March 2000.\n\nThe Athlon architecture also used the EV6 bus licensed from DEC as its main system bus. Intel required licensing to use the GTL+ bus used by its Slot 1 Pentium II and later processors. By licensing the EV6 bus used by the Alpha line of processors from DEC, AMD was able to develop its own chipsets and motherboards, and avoid being dependent on licensing from its direct competitor.\n\nInternally, the Athlon is a fully seventh generation x86 processor, the first of its kind. Like the AMD K5 and K6, the Athlon dynamically buffers internal micro-instructions at runtime resulting from parallel x86 instruction decoding. The CPU is an out-of-order design, again like previous post-5x86 AMD CPUs. The Athlon utilizes the Alpha 21264's EV6 bus architecture with double data rate (DDR) technology. This means that at 100 MHz, the Athlon front side bus actually transfers at a rate similar to a 200 MHz single data rate bus (referred to as 200 MT/s), which was superior to the method used on Intel's Pentium III (with SDR bus speeds of 100 MHz and 133 MHz).\n\nAMD designed the CPU with more robust x86 instruction decoding capabilities than that of K6, to enhance its ability to keep more data in-flight at once. The Athlon's three decoders could potentially decode three x86 instructions to six microinstructions per clock, although this was somewhat unlikely in real-world use. The critical branch predictor unit, essential to keeping the pipeline busy, was enhanced compared to what was on board the K6. Deeper pipelining with more stages allowed higher clock speeds to be attained. Whereas the AMD K6-III+ topped out at 570 MHz due to its short pipeline, even when built on the 180 nm process, the Athlon was capable of clocking much higher.\n\nAMD ended its long-time handicap with floating point x87 performance by designing a super-pipelined, out-of-order, triple-issue floating point unit. Each of its three units was tailored to be able to calculate an optimal type of instructions with some redundancy. By having separate units, it was possible to operate on more than one floating point instruction at once. This FPU was a huge step forward for AMD. While the K6 FPU had looked anemic compared to the Intel P6 FPU, with Athlon this was no longer the case.\n\nThe 3DNow! floating point SIMD technology, again present, received some revisions and a name change to \"Enhanced 3DNow!\". Additions included DSP instructions and an implementation of the extended MMX subset of Intel SSE.\n\nThe Athlon's CPU cache consisted of the typical two levels. Athlon was the first x86 processor with a 128 kB split level 1 cache; a 2-way associative cache separated into 2×64 kB for data and instructions (a concept from Harvard architecture). This cache was double the size of K6's already large 2×32 kB cache, and quadruple the size of Pentium II and III's 2×16 kB L1 cache. The initial Athlon (Slot A, later called Athlon Classic) used 512 kB of level 2 cache separate from the CPU, on the processor cartridge board, running at 50% to 33% of core speed. This was done because the 250 nm manufacturing process was too large to allow for on-die cache while maintaining cost-effective die size. Later Athlon CPUs, afforded greater transistor budgets by smaller 180 nm and 130 nm process nodes, moved to on-die L2 cache at full CPU clock speed.\n\nThe AMD Athlon processor launched on June 23, 1999, with general availability by August '99. It launched at 500 MHz and was, on average, 10% faster than the Pentium III at the same clock for Business applications, and even faster (~20%) for gaming workloads.\n\nThe Athlon Classic is a cartridge-based processor, named Slot A and similar to Intel's cartridge Slot 1 used for Pentium II and Pentium III. It used the same, commonly available, physical 242 pin connector used by Intel Slot 1 processors but rotated by 180 degrees to connect the processor to the motherboard. The reversal served to make the slot keyed to prevent installation of the wrong CPU, as the Athlon and Intel processors used fundamentally different (and incompatible) signaling standards for their front-side bus. The cartridge assembly allowed the use of higher speed cache memory modules than could be put on (or reasonably bundled with) motherboards at the time. Similar to the Pentium II and the Katmai-based Pentium III, the Athlon Classic contained 512 kB of L2 cache. This high-speed SRAM cache was run at a divisor of the processor clock and was accessed via its own 64-bit bus, known as a \"back-side bus\" allowing the processor to both service system front side bus requests (the rest of the system) and cache accesses simultaneously versus the traditional approach of pushing \"everything\" through the front-side bus.\n\nOne limitation (also afflicting the Intel Pentium III) is that SRAM cache designs at the time were incapable of keeping up with the Athlon's clock scalability, due both to manufacturing limitations of the cache chips and the difficulty of routing electrical connections to the cache chips themselves. It became increasingly difficult to reliably run an external processor cache to match the processor speeds being released—and in fact it became impossible. Thus initially the Level 2 cache ran at half of the CPU clock speed up to 700 MHz (350 MHz cache). Faster Slot-A processors had to compromise further and run at 2/5 (up to 850 MHz, 340 MHz cache) or 1/3 (up to 1 GHz, 333 MHz cache). This later race to 1 GHz (1000 MHz) by AMD and Intel further exacerbated this bottleneck as ever higher speed processors demonstrated decreasing gains in overall performance—stagnant SRAM cache memory speeds choked further improvements in overall speed. This directly lead to the development of integrating L2 cache onto the processor itself and remove the dependence on external cache chips. AMD's integration of the cache onto the Athlon processor itself would later result in the Athlon Thunderbird.\n\nThe Slot-A Athlons were the first multiplier-locked CPUs from AMD. This was partly done to hinder CPU remarking being done by questionable resellers around the globe. AMD's older CPUs could simply be set to run at whatever clock speed the user chose on the motherboard, making it trivial to relabel a CPU and sell it as a faster grade than it was originally intended. These relabeled CPUs were not always stable, being overclocked and not tested properly, and this was damaging to AMD's reputation. Although the Athlon was multiplier locked, crafty enthusiasts eventually discovered that a connector on the PCB of the cartridge could control the multiplier. Eventually a product called the \"Goldfingers device\" was created by inventors Ryan Petersen and Micheal Franz Schuete that could unlock the CPU, named after the gold connector pads on the processor board that it attached to.\n\nIn commercial terms, the Athlon \"Classic\" was an enormous success—not just because of its own merits, but also because Intel endured a series of major production, design, and quality control issues at this time. In particular, Intel's transition to the 180 nm production process, starting in late 1999 and running through to mid-2000, suffered delays. There was a shortage of Pentium III parts. In contrast, AMD enjoyed a remarkably smooth process transition and had ample supplies available, causing Athlon sales to become quite strong.\n\nThe Argon-based Athlon contained 22 million transistors and measured 184 mm. It was fabricated by AMD in a slightly modified version of their CS44E process, a 0.25 µm complementary metal–oxide–semiconductor (CMOS) process with six levels of aluminium interconnect. \"Pluto\" and \"Orion\" Athlons were fabricated in a 0.18 µm process.\n\n\nThe second generation Athlon, the \"Thunderbird\", debuted on June 5, 2000. This version of the Athlon shipped in a more traditional pin-grid array (PGA) format that plugged into a socket (\"Socket A\") on the motherboard (it also shipped in the slot A package). It was sold at speeds ranging from 600 MHz to 1.4 GHz (Athlon Classics using the Slot A package could clock up to 1 GHz). The major difference, however, was cache design. Just as Intel had done when they replaced the old Katmai-based Pentium III with the much faster Coppermine-based Pentium III, AMD replaced the 512 kB external reduced-speed cache of the Athlon Classic with 256 kB of on-chip, full-speed exclusive cache. As a general rule, more cache improves performance, but faster cache improves it further still.\n\nAMD changed cache design significantly with the Thunderbird core. With the older Athlon CPUs, the CPU caching was of an inclusive design where data from the L1 is duplicated in the L2 cache. Thunderbird moved to an exclusive design where the L1 cache's contents are not duplicated in the L2. This increases total cache size of the processor and effectively makes caching behave as if there is a very large L1 cache with a slower region (the L2) and a very fast region (the L1). Because of Athlon's very large L1 cache and the exclusive design, which turns the L2 cache into basically a \"victim cache\", the need for high L2 performance and size was lessened. AMD kept the 64-bit L2 cache data bus from the older Athlons, as a result, and allowed it to have a relatively high latency. A simpler L2 cache reduced the possibility of the L2 cache causing clock scaling and yield issues. Still, instead of the 2-way associative scheme used in older Athlons, Thunderbird did move to a more efficient 16-way associative layout.\n\nThe Thunderbird was AMD's most successful product since the Am386DX-40 ten years earlier. Mainboard designs had improved considerably by this time, and the initial trickle of Athlon mainboard makers had swollen to include every major manufacturer. AMD's new fab in Dresden came online, allowing further production increases, and the process technology was improved by a switch to copper interconnects. In October 2000, the Athlon \"C\" was introduced, raising the mainboard front-side bus speed from 100 MHz to 133 MHz (266 MT/s) and providing roughly 10% extra performance per clock over the \"B\" model Thunderbird.\n\n\nAMD released the third-generation Athlon, code-named \"Palomino\", on October 9, 2001 as the \"Athlon XP\". The \"XP\" suffix is interpreted to mean \"extended performance\" and also as an unofficial reference to Microsoft Windows XP. The \"Athlon XP\" was marketed using a PR system, which compared its relative performance to an Athlon utilizing the earlier \"Thunderbird\" core. \"Athlon XP\" launched at speeds between 1.33 GHz (PR1500+) and 1.53 GHz (PR1800+), giving AMD the x86 performance lead with the 1800+ model. Less than a month later, it enhanced that lead with the release of the 1600 MHz 1900+, and subsequent 1.67 GHz Athlon XP 2000+ in January 2002.\n\nPalomino was the first K7 core to include the full SSE instruction set from the Intel Pentium III, as well as AMD's 3DNow! Professional. It is roughly 10% faster than Thunderbird at the same clock speed, thanks in part to the new SIMD functionality and to several additional improvements. The core has enhancements to the K7's TLB architecture and added a hardware data prefetch mechanism to take better advantage of available memory bandwidth. Palomino was also the first socketed Athlon officially supporting dual processing, with chips certified for that purpose branded as the Athlon MP. According to articles posted on HardwareZone, it was possible to mod the Athlon XP to function as an MP by connecting some fuses on the OPGA, although results varied with the motherboard used.\n\nChanges in core layout also resulted in Palomino being more frugal with its electrical demands, consuming approximately 20% less power than its predecessor, and thus reducing heat output comparatively as well. While the preceding Athlon \"Thunderbird\" was capable of clock speeds exceeding 1400 MHz, the power and thermal considerations required to reach those speeds would have made it increasingly impractical as a marketable product. Thus, Palomino's goals of lowered power consumption (and resultant heat produced) allowed AMD to increase performance within a reasonable power envelope. Palomino's design also allowed AMD to continue using the same 180 nm manufacturing process node and core voltages as Thunderbird.\n\nInterestingly, the Palomino core actually debuted earlier in the mobile market—branded as Mobile Athlon 4 with the codename \"Corvette\". It distinctively used a ceramic interposer much like the Thunderbird instead of the organic pin grid array package used on all later Palomino processors.\n\n\nThe fourth-generation Athlon \"Thoroughbred\" was released on June 10, 2002 at 1.8 GHz (Athlon XP PR2200+). The \"Thoroughbred\" core marked AMD's first production 130 nm silicon, resulting in a significant reduction in die size compared to its 180 nm predecessor.\n\nThere came to be two steppings (revisions) of this core commonly referred to as Tbred-A (cpuid:6 8 0) and Tbred-B (cpuid:6 8 1). The initial version (later known as A) was simply a direct die shrink of the Palomino, and demonstrated that AMD had successfully transitioned to a 130 nm process. While successful in reducing the production cost per processor, the unmodified Palomino design did not demonstrate the expected reduction in heat and clock scalability usually seen when a design is shrunk to a smaller process. As a result, AMD was not able to increase Thoroughbred-A clock speeds much above those of the Palomino it was to replace. Tbred-A was only sold in versions from 1333 MHz to 1800 MHz, and was only able to displace the more production-costly Palomino from AMD's lineup.\n\nAMD thus reworked the Thoroughbred's design to better match the process node on which it was produced, in turn creating the Thoroughbred-B. A significant aspect of this redesign was the addition of another ninth \"metal layer\" to the already quite complex eight-layered Thoroughbred-A. For comparison, the competing Pentium 4 Northwood only utilized six, and its successor Prescott seven layers. While the addition of more layers itself does not improve performance, it gives more flexibility for chip designers routing electrical pathways within a chip, and importantly for the Thoroughbred core, more flexibility in working around electrical bottlenecks that prevented the processor from attaining higher clock speeds. The Tbred-B offered a startling improvement in headroom over the Tbred-A, which made it very popular for overclocking. The Tbred-A often struggled to reach clock speeds above 1.9 GHz, while the Tbred-B often could easily reach 2.3 GHz and above.\n\nThe Thoroughbred line received an increased front side bus clock during its lifetime, from 133 MHz (266 MT/s) to 166 MHz (333 MT/s) improving the processor's ability to access memory and I/O efficiency, and resulted in improved per-clock performance. AMD shifted their PR rating scheme accordingly, making lower clock speeds equate to higher PR ratings.\n\nThe Thoroughbred-B was the \"direct\" basis for its successor—the Tbred-B with an \"additional\" 256 kB of L2 cache (for 512 kB total) became the Barton core.\n\n\nFifth-generation Athlon \"Barton\"-core processors released in early 2003 with PR of 2500+, 2600+, 2800+, 3000+, and 3200+. While not operating at higher clock rates than \"Thoroughbred\"-core processors, they were marked with higher PR by featuring an increased 512 kB L2 cache; later models additionally supported an increased 200 MHz (400 MT/s) front side bus. The \"Thorton\" core was a later variant of the \"Barton\" with half of the L2 cache disabled, and thus was functionally identical to the \"Thoroughbred-B\" core. The name \"Thorton\" is a portmanteau of \"Thoroughbred\" and \"Barton\".\n\nBy the time of Barton's release, the \"Northwood\"-based Pentium 4 had become more than competitive with AMD's processors. Unfortunately for AMD, a simple increase in size of the L2 cache to 512 kB did not have nearly the same impact as it did for Intel's Pentium 4 line, as the Athlon architecture was not nearly as cache-constrained as the Pentium 4. The Athlon's exclusive-cache architecture and shorter pipeline made it less sensitive to L2 cache size, and the Barton only saw an increase of several percent gained in per-clock performance over the Thoroughbred-B it was derived from. While the increased performance was welcome, it was not sufficient to overtake the Pentium 4 line in overall performance. The PR also became somewhat inaccurate because some Barton models with lower clock rates were being given higher PR than higher-clocked Thoroughbred processors. Instances where a computational task did not benefit more from the additional cache to make up for the loss in raw clock speed created situations where a lower rated (but faster clocked) Thoroughbred would outperform a higher-rated (but lower clocked) Barton.\n\nThe Barton was also used to officially introduce a higher 400 MT/s bus clock for the Socket A platform, which was used to gain some Barton models more efficiency (and increased PR). However, it was clear by this time that Intel's quad-pumped bus was scaling well above AMD's double-pumped EV6 bus. The 800 MT/s bus used by many later Pentium 4 processors was well out of the Athlon XP's reach. In order to reach the same bandwidth levels, the Athlon XP's bus would have to be clocked at levels simply unreachable.\n\nBy this point, the four-year-old Athlon EV6 bus architecture had scaled to its limit. To maintain or exceed the performance of Intel's newer processors would require a significant redesign. The K7 derived Athlons were replaced in March 2003 by the Athlon 64 family, which featured an on-chip memory controller and a completely new HyperTransport bus to replace EV6.\n\n\"Barton (130 nm)\"\n\n\"Thorton (130 nm)\"\n\nA Mobile Athlon XPs (\"Athlon XP-M\") using a given core is physically identical to the equivalent desktop Athlon XPs counterpart, only differing by the configuration used to achieve a given performance level. Processors are usually binned and selected to become a mobile processor by their ability run a given processor speed while supplied with a lower (than desktop) voltage. This results in lower power consumption, longer battery life, and reduced heat over using a normal desktop part. Additionally Mobile XPs feature not being multiplier-locked and generally higher-rated maximum operating temperatures, requirements intended for better operation within the tight thermal constraints within a notebook PC—but also making them attractive for overclocking.\n\nThe Athlon XP-M replaced the older Mobile Athlon 4 based on the \"Palomino\" core, with the Athlon XP-M using the newer \"Thoroughbred\" and \"Barton\" cores. The Athlon XP-M was also offered in a compact microPGA socket 563 version for space constrained applications as an alternative to the larger Socket A.\n\nLike their mobile K6-2+/III+ predecessors, the CPUs were capable of dynamic clock adjustment for power optimization, and also was the reason for the unlocked multiplier. When the system is idle, the CPU clocks itself down via lower bus multiplier and selects a lower voltage. When a program demands more computational resources, the CPU quickly (there is some latency) returns to an intermediate or maximum speed with appropriate voltage to meet the demand. This technology was marketed as \"PowerNow!\" and was similar to Intel's SpeedStep power saving technique. The feature was controlled by the CPU, motherboard BIOS, and operating system. AMD later renamed the technology to Cool'n'Quiet on their K8-based CPUs (Athlon 64, etc.), and introduced it for use on desktop PCs as well.\n\nAthlon XP-Ms were popular with desktop overclockers, as well as underclockers. The lower voltage requirement and higher heat rating selected CPUs that were essentially \"cherry picked\" from the manufacturing line. Being some of the best cores \"off the line\", these CPUs typically overclocked more reliably than their desktop-headed counterparts. Also, the fact that they were not locked to a single multiplier was a significant simplification in the overclocking process. Some \"Barton\" core Athlon XP-Ms have been successfully overclocked as high as 3.1 GHz.\n\nThe chips were also liked for their undervolting ability. Undervolting is a process of determining the lowest voltage at which a CPU can remain stable at a given clock speed. As Athlon XP-M CPUs were already rated running lower voltages than their desktop siblings, it was a better starting point for lowering voltage even further. A popular application was use in home theater PC systems due to high performance and low heat output resultant from low Vcore settings.\n\nBesides not being multiplier locked, XP-Ms curiously were not disabled from multi processor operation. Thus they could be used in place of the more expensive Athlon MP in dual socket A motherboards. Since those boards generally lacked multiplier and voltage adjustment, and normally only supported 133 MHz FSB, adjustments would still be needed for full speed operation. One method of modification known as wire-modding involves connecting the appropriate CPU pins on the CPU socket with small lengths of wire to select the appropriate multiplier. A typical overclock of a mobile 2500+ CPU to 2.26 GHz with 17x multiplier would result in being faster than highest official 2800+ MP CPU running at 2.13 GHz.\n\n\nThe fastest supercomputers based on AthlonMP:\n\n\n", "id": "3060", "title": "Athlon"}
{"url": "https://en.wikipedia.org/wiki?curid=3065", "text": "Amnon\n\nAccording to the Bible, Amnon (, \"faithful\") was the oldest son of David, King of Israel, with his wife, Ahinoam, who is described as \"the Jezreelitess\". (, )\n\nAlthough he was the heir-apparent to David's throne, Amnon is best remembered for the rape of his half-sister Tamar, daughter of David with Maachah. \n\nDespite the biblical prohibition on sexual relations between half-brothers and sisters, () Amnon had an overwhelming desire for her. He acted on advice from his cousin, Jonadab the son of Shimeah, David's brother, to lure Tamar into his quarters by pretending to be sick and desiring her to cook a special meal for him. While in his quarters, and ignoring her protests, he raped her, then had her expelled from his house. King David was angry about the incident, but could not bring himself to punish his eldest son, while Absalom, Amnon's half-brother and Tamar's full brother, nursed a bitter grudge against Amnon for the rape of his sister.\n\nTwo years later, to avenge Tamar, Absalom invited all of David's sons to a feast, then had his servants kill Amnon after he had become drunk with wine. ()\n\n", "id": "3065", "title": "Amnon"}
{"url": "https://en.wikipedia.org/wiki?curid=3067", "text": "Amu Darya\n\nThe Amu Darya (, '; /; //; ; , '), also called the Amu River and historically known by its Latin name, , is a major river in Central Asia. It is formed by the junction of the Vakhsh and Panj rivers, at Qal`eh-ye Panjeh in Afghanistan, and flows from there north-westwards into the southern remnants of the Aral Sea. In ancient times, the river was regarded as the boundary between Greater Iran and Turan.\n\nIn classical antiquity, the river was known as the \"Ōxus\" in Latin and Ὦξος \"Ôxos\" in Greek—a clear derivative of Vakhsh, the name of the largest tributary of the river. In Vedic Sanskrit, the river is also referred to as Vakṣu (वक्षु). The Avestan texts too refer to the River as Yakhsha/Vakhsha (and Yakhsha Arta (\"upper Yakhsha\") referring to the Jaxartes/Syr Darya twin river to Amu Darya).\n\nIn Middle Persian sources of the Sassanid period the river is known as \"Wehrōd\" (lit. \"good river\").\n\nThe name \"Amu\" is said to have come from the medieval city of \"Āmul\", (later, Chahar Joy/Charjunow, and now known as Türkmenabat), in modern Turkmenistan, with \"Darya\" being the Persian word for \"river\".\n\nMedieval Arabic and Muslim sources call the river \"Jayhoun\" (جيحون) which is derived from \"Gihon\", the biblical name for one of the four rivers of the Garden of Eden.\n\nWestern travelers in the 19th century mention that one of the names by which the river was known in Afghanistan was Gozan, and that this name was used by Greek, Mongol, Chinese, Persian, Jewish, and Afghan historians. However, this name is no longer used.\n\nThe river's total length is and its drainage basin totals in area, providing a mean discharge of around of water per year. The river is navigable for over . All of the water comes from the high mountains in the south where annual precipitation can be over . Even before large-scale irrigation began, high summer evaporation meant that not all of this discharge reached the Aral Sea – though there is some evidence the large Pamir glaciers provided enough melt water for the Aral to overflow during the 13th and 14th centuries.\n\nSince the end of the 19th century there have been four different claimants as the true source of the Oxus:\n\nA glacier turns into the Wakhan River and joins the Pamir River about downstream.\nBill Colegrave's expedition to Wakhan in 2007 found that both claimants 2 and 3 had the same source, the Chelab stream, which bifurcates on the watershed of the Little Pamir, half flowing into Lake Chamaktin and half into the parent stream of the Little Pamir/Sarhad River. Therefore, the Chelab stream may be properly considered the true source or parent stream of the Oxus.\nThe Panj River forms the border of Afghanistan and Tajikistan. It flows west to Ishkashim where it turns north and then north-west through the Pamirs passing the Tajikistan–Afghanistan Friendship Bridge. It subsequently forms the border of Afghanistan and Uzbekistan for about , passing Termez and the Afghanistan–Uzbekistan Friendship Bridge. It delineates the border of Afghanistan and Turkmenistan for another before it flows into Turkmenistan at Atamurat. As the \"Amudarya\", it flows across Turkmenistan south to north, passing Türkmenabat, and forms the border of Turkmenistan and Uzbekistan from Halkabat. It is then split by the Tuyamuyun Hydro Complex into many waterways that used to form the river delta joining the Aral Sea, passing Urgench, Daşoguz, and other cities, but it does not reach what is left of the sea any more and is lost in the desert.\n\nUse of water from the Amu Darya for irrigation has been a major contributing factor to the shrinking of the Aral Sea since the late 1950s.\n\nHistorical records state that in different periods, the river flowed into the Aral Sea (from the south), into the Caspian Sea (from the east), or both, similar to the Syr Darya (Jaxartes, in Ancient Greek).\n\nAbout of land is drained by the Amu Darya into the Aral Sea endorheic basin. This includes most of Tajikistan, the southwest corner of Kyrgyzstan, the northeast corner of Afghanistan, a long narrow portion of eastern Turkmenistan and about half of Uzbekistan. Part of the Amu Darya's drainage divide in Tajikistan forms that country's border with China (in the east) and Pakistan (to the south). About 61% of the drainage lies within Tajikistan, Uzbekistan and Turkmenistan, while 39% is in Afghanistan.\nOf the area drained by the Amu Darya, only about actively contribute water to the river.\nThis is because many of the river's major tributaries (especially the Zeravshan River) have been diverted, and much of the river's drainage is dominated by outlying desert and steppe.\n\nThe abundant water flowing in the Amu Darya comes almost entirely from glaciers in the Pamir Mountains and Tian Shan,\nwhich, standing above the surrounding arid plain, collect atmospheric moisture which otherwise would probably escape somewhere else. Without its mountain water sources, the Amu Darya would not contain any water—would not exist—because it rarely rains in the lowlands through which most of the river flows. Throughout most of the steppe, the annual rainfall is about .\n\nThe ancient Greeks called the Amu Darya the \"Oxus\". In ancient times, the river was regarded as the boundary between Greater Iran and Tūrān. The river's drainage lies in the area between the former empires of Genghis Khan and Alexander the Great, although they occurred at very different times. When the Mongols came to the area, they used the water of the Amu Darya to flood Konye-Urgench. One southern route of the Silk Road ran along part of the Amu Darya northwestward from Termez before going westwards to the Caspian Sea.\n\nIt is believed that the Amu Darya's course across the Kara-Kum Desert has gone through several major shifts in the past few thousand years. Much of the time – most recently from the 13th century to the late 16th century – the Amu Darya emptied into both the Aral and the Caspian Seas, reaching the latter via a large distributary called the Uzboy River. The Uzboy splits off from the main channel just south of the Amudarya Delta. Sometimes the flow through the two branches was more or less equal, but often most of the Amu Darya's flow split to the west and flowed into the Caspian.\n\nPeople began to settle along the lower Amu Darya and the Uzboy in the 5th century, establishing a thriving chain of agricultural lands, towns, and cities. In about 985 AD the massive Gurganj Dam at the bifurcation of the forks started to divert water to the Aral. Genghis Khan's troops destroyed the dam in 1221, and the Amu Darya shifted to distributing its flow more or less equally between the main stem and the Uzboy. But in the 18th century, the river again turned north, flowing into the Aral Sea, a path it has taken since. Less and less water flowed down the Uzboy. When Russian explorer, Bekovich—Cherkasski suveyed the region in 1720, Amu Darya did not flow into the Caspian Sea anymore.\n\nThe first Englishman to reach the Oxus, William Moorcroft visited about 1824. Another to reach the region in the Great Game period, a naval officer called John Wood, came with an expedition to find the source of the river in 1839. He found modern-day Lake Zorkul, called it Lake Victoria, and proclaimed he had found the source. Then, the French explorer and geographer Thibaut Viné collected a lot of information about this area during five expeditions between 1856 and 1862.\n\nThe question of finding a route between the Oxus valley and India has been of concern historically. A direct route crosses extremely high mountain passes in the Hindu Kush and isolated areas like Kafiristan. Some in Britain feared that the Empire of Russia, which at the time wielded great influence over the Oxus area, would overcome these obstacles and find a suitable route through which to invade British India – but this never came to pass. The area was taken over by Russian during the Russian conquest of Turkestan.\n\nThe Soviet Union became the ruling power in the early 1920s and expelled Mohammed Alim Khan. It later put down the Basmachi movement and killed Ibrahim Bek. A large refugee population of Central Asians, including Turkmen, Tajiks and Uzbeks, fled to northern Afghanistan. In the 1960s and 1970s the Soviets started using the Amu Darya and the Syr Darya to irrigate extensive cotton fields in the Central Asian plain. Before this time, water from the rivers was already being used for agriculture, but not on this massive scale. The Qaraqum Canal, Karshi Canal, and Bukhara Canal were among the larger of the irrigation diversions built. The 1970s, in the course of the Soviet war in Afghanistan, Soviet forces used the valley to invade Afghanistan through Termez. The Soviet Union fell in the 1990s and Central Asia split up into the many smaller countries that lie within or partially within the Amu Darya basin. The Main Turkmen Canal, a proposed project that would have diverted water along the dry Uzboy River bed into central Turkmenistan, was never built.\n\nDuring the Soviet era a resource-sharing system was instated in which Kyrgyzstan and Tajikistan shared water originating from the Amu Darya and Syr Darya rivers with Kazakhstan, Turkmenistan, and Uzbekistan in summer. In return, Kyrgyzstan and Tajikistan received Kazakh, Turkmen, and Uzbek coal, gas, and electricity in winter. After the fall of the Soviet Union this system disintegrated and the Central Asian nations have failed to reinstate it. Inadequate infrastructure, poor water-management, and outdated irrigation methods all exacerbate the issue.\n\nThe Amu-Darya's delta was suggested as a potential site. A feasibility study was initiated to investigate if the area is suitable and if such an initiative would receive support from relevant decision makers. A viable tiger population of about 100 animals would require at least of large tracts of contiguous habitat with rich prey populations. Such habitat is not available at this stage and cannot be provided in the short term. The proposed region is therefore unsuitable for the reintroduction, at least at this stage.\n\nThe Oxus river, and Arnold's poem, fire the imaginations of the children who adventure with ponies over the moors of the West Country in the 1930s children's book \"The Far-Distant Oxus\". There were two sequels, \"Escape to Persia\" and \"Oxus in Summer\".\n\nRobert Byron's 1937 travelogue, \"The Road to Oxiana\", describes its author's journey from the Levant through Persia to Afghanistan, with the Oxus as his stated goal.\n\nGeorge MacDonald Fraser's \"Flashman at the Charge\", (1973), places Flashman on the Amu Darya and the Arral Sea during the (fictitious) Russian advance on India during The Great Game period.\n\n\n\n", "id": "3067", "title": "Amu Darya"}
{"url": "https://en.wikipedia.org/wiki?curid=3068", "text": "Islamic conquest of Afghanistan\n\nThe Islamic conquest of Afghanistan (642–870) began in the middle of the 7th century after the Islamic conquest of Persia was completed, when Arab Muslims defeated the Sassanid Empire at the battles of Walaja, al-Qādisiyyah and Nahavand. The Muslim Arabs then began to move towards the lands east of Persia and in 652 captured the city, Herat. By 667, the Afghan area was under invasion by the Arabs but in 683 Kabul and other parts of Afghanistan fought with resistance and completely routed the invading army which was led by the Governor of Seistan. The near-complete conversion of Afghans to Islam was during the period of the Ghaznavids in the 10th century with Kafiristan holding out until Emir Abdur Rahman Khan conquered and forcibly converted them in the 1890s. Ethnic Arabs who have settled in Afghanistan, came to form the first community of Afghan Arabs.\n\nThe invasion of Persia was completed five years after the death of the Islamic prophet Muhammad, and all of the Persian territories came under Arab control, though pockets of tribal resistance continued for centuries in the Afghan territories. During the 7th century, Arab armies made their way into the region of Afghanistan from Khorasan with the new religion of Islam. \n\nThe area had been under the rule of the Buddhist and then Hindu dynasty called the Kabul Shahis since the 5th century. Muslims missionaries converted many people to Islam; however, the entire population did not convert, with repetitive revolts from the mountain tribes in the Afghan area taking place. The Hindu Shahi were defeated in the early part of the 10th century by Mahmud of Ghazna, who ruled between 998 and 1030. He also expelled the Hindu Shahi from Gandhara.\n\nIn 870, Ya'qub bin Laith as-Saffar, a local ruler from the Saffarid dynasty of Zaranj, Afghanistan, conquered most of present-day Afghanistan in the name of Islam. In many cases, the people he conquered had rebelled against their Islamic overlords and reverted to prior forms of worship.\n\nFrom the 8th century to the 9th century, many inhabitants of what is present-day Afghanistan and Pakistan were converted to Sunni Islam. It is surmised from the writings of Al Biruni that some Pashtuns living in Pakhtunkhwa (present-day western Pakistan) had not been completely converted. Al Biruni, writing in Tarikh al Hind, also alludes to the Pashtun tribes of Pakhtunkhwa as Hindus. \n\nVarious historical sources such as Martin Ewans, E.J. Brill and Farishta have recorded the introduction of Islam to Kabul and other parts of Afghanistan to the invasions of Mahmud of Ghazna \n\nAl-Idirisi (1100-1165/1166) testifies that until as late as the 12th century, a contract of investiture for every Hindu Shahi king was performed at Kabul and that here he was obliged to agree to certain ancient conditions which completed the contract. \n\nDuring the end of the 9th century, the Samanids extended its rule from Bukhara to as far south as the Indus River and west into parts of Persia. Although Arab Muslim intellectual life was still centered in Baghdad, Sunni Islam, predominated in the Samanid areas at this time. This period of time was considered an era of great cultural, intellectual, and artistic flourishing under the patronage of the Muslim Samanids. By the mid-10th century, the Samanid Dynasty had crumbled in the face of attacks from Turkish tribes to the north and from the Ghaznavids, a rising Turkic dynasty in Afghanistan.\n\nThe region was ruled by Hindu and Buddhist dynasty called the Kabul Shahis since the 5th century. Mountain tribe revolts hindered the process of converting the tribes. In 870, Ya'qub-i Laith Saffari, a local Persian ruler from the Saffarid dynasty of Zaranj, Afghanistan, conquered most of the cities of present-day Afghanistan in the name of Islam. \n\nDuring the 8th through the 9th centuries, many inhabitants of what is present-day Afghanistan and western Pakistan were converted to Sunni Islam. In some cases, however, people that were conquered by the Muslims would rebel and revert to prior forms of worship. The mountain areas were still not completely converted and remained largely by people of non-Muslim faiths. In a book called Hudud-al-Alam, written in 982, it mentions a village near Jalalabad, Afghanistan, where the local king used to have many Hindu, Muslim and Afghan wives. \n\nOut of the Samanid dynasty came the Ghaznavids, whose warriors forged the first great Islamic empire from Ghazni (Afghanistan) that spanned much of the Iranian plateau, Central Asia and conducted many successful raids into India. During the end of the 9th century, the Samanids extended its rule from Bukhara to as far south as the Indus River and west into most of Persia. By the mid-10th century, the Samanid dynasty had crumble in the face of attacks from Turkish tribes to the north and from the Ghaznavids, a rising Turkic Muslim dynasty in Afghanistan. Besides Turkic people, large part of the Ghaznavid Empire was made up of local Muslim Afghans from what is now Afghanistan and western parts of Pakistan.\n\nIt is surmised from the writings of Al Biruni that some Afghans who lived in west of India (modern-day Afghanistan) had not been completely converted to Islam.\n\nVarious historical sources such as Martin Ewans, E.J. Brill and Farishta have recorded that the complete conversion of Afghanistan, Pakistan to Islam was during the rule of Sultan Mahmud of Ghazni. \n\nAl-Idirisi testifies that until as late as the 12th century, a contract of investiture for every Shahi king was performed at Kabul and that here he was obliged to agree to certain ancient conditions which completed the contract. The Ghaznavid military incursions assured the domination of Sunni Islam in what is now Afghanistan and western Pakistan. The most renowned of the dynasty's rulers was Mahmud of Ghazni, who consolidated control over the areas south of the Amu Darya then carried out devastating raids into India. With his booty from India, Mahmud built a great capital at Ghazni, founded universities, and patronized scholars. By the time of his death, Mahmud ruled a vast empire that stretched from Kurdistan to the entire Hindu Kush region as far east as the Punjab as well as territories far north of the Amu Darya. However, as occurred so often in this region, the demise in 1030 of this military genius who had expanded the empire to its farthest reaches was the death knell of the dynasty itself. The rulers of the Ghurids of Ghor in modern-day Afghanistan, captured and burned Ghazni in 1149, just as the Ghaznavids had once conquered Ghor. Not until 1186, however, was the last representative of the Ghaznavids uprooted by the Ghorids from his holdout in Lahore, in the Punjab.\n\n\n\n", "id": "3068", "title": "Islamic conquest of Afghanistan"}
{"url": "https://en.wikipedia.org/wiki?curid=3070", "text": "Durrani Empire\n\nThe Durrani Empire, Durrani Tulukamani, Durrani Wakmani, Durrani Emirate (), also called the Sadozai Kingdom and the Last Afghan Empire, was founded in 1747 by Ahmad Shah Durrani with its capital at Kandahar, in present-day Afghanistan. The Durrani Empire at its maximum extent encompassed present-day Afghanistan, northeastern Iran, eastern Turkmenistan (including the Panjdeh oasis), most of Pakistan, and northwestern India, including the Kashmir region. With the support of various tribal leaders, Ahmad Shah Durrani with his Baloch allies extended Afghan control from Khorasan in the west to Kashmir and Delhi in the east, and from the Amu Darya in the north to the Arabian Sea in the south.\n\nThe Afghan army began their conquests by capturing Ghazni and Kabul from the local rulers. In 1749 the Mughal ruler had ceded sovereignty over what is now Pakistan and northwestern Punjab to the Afghans. Ahmad Shah then set out westward to take possession of Herat, which was ruled by Shahrukh Afshar. He next sent an army to subdue the areas north of the Hindu Kush and in short order all the different tribes began joining his cause. Ahmad Shah and his forces invaded India four times, taking control of the Kashmir and the Punjab region. Early in 1757, he sacked Delhi, but permitted the Mughal dynasty to remain in nominal control as long as the ruler acknowledged Ahmad Shah's suzerainty over the Punjab, Sindh, and Kashmir. Additionally, among the Durranis' other military conquests, the Pashtun also instigated the Vaḍḍā Ghallūghārā when they killed thousands of Sikhs in the Punjab.\n\nAfter the death of Ahmad Shah in about 1772, his son Timur Shah became the next ruler of the Durrani dynasty who decided to make Kabul the new capital of the empire, and used Peshawar as the winter capital. The Durrani Empire is considered the foundation of the modern state of Afghanistan, with Ahmad Shah Durrani being credited as \"Father of the Nation\".\n\nIn 1709 Mir Wais Hotak, chief of the Ghilji tribe of Kandahar Province, gained independence from the Safavid Persians. From 1722 to 1725, his son Mahmud Hotak briefly ruled large parts of Iran and declared himself as \"Shah of Persia\". However, the Hotak dynasty came to a complete end in 1738 after being toppled and banished by the Afsharids who were led by Nader Shah Afshar of Persia.\n\nThe year 1747 marks the definitive appearance of an Afghan political entity independent of both the Persian and Mughal empires. In October 1747 a loya jirga (grand council) concluded near the city of Kandahar with Ahmad Shah Durrani being selected as the new leader of the Afghans, thus the Durrani dynasty was founded. Despite being younger than the other contenders, Ahmad Shah had several overriding factors in his favor. He belonged to a respectable family of political background, especially since his father served as Governor of Herat who died in a battle defending the Afghans. He also had a well-trained larger army and possessed a substantial part of Nadir Shah's treasury, including the Koh-i-Noor diamond, the world's largest.\n\nOne of Ahmad Shah's first military action was the capture Ghazni from the Ghiljis, and then wresting Kabul from the local ruler. In 1749, the Mughal ruler was induced to cede Sindh, the Punjab region and the important trans Indus River to Ahmad Shah in order to save his capital from Afghan attack. Having thus gained substantial territories to the east without a fight, Ahmad Shah turned westward to take possession of Herat, which was ruled by Nader Shah Afshar's grandson, Shahrukh Afshar. Ahmad Shah next sent an army to subdue the areas north of the Hindu Kush mountains. In short order, the powerful army brought under its control the Tajik, Hazara, Uzbek, Turkmen, and other tribes of northern Afghanistan. Ahmad Shah invaded the remnants of the Mughal Empire a third time, and then a fourth, consolidating control over the Kashmir and Punjab regions, with Lahore being governed by Afghans. He sacked Delhi in 1757 but permitted the Mughal dynasty to remain in nominal control of the city as long as the ruler acknowledged Ahmad Shah's suzerainty over Punjab, Sindh, and Kashmir. Leaving his second son Timur Shah to safeguard his interests, Ahmad Shah left India to return to Afghanistan.\n\nAlarmed by the expansion of China's Qing Dynasty up to the western border of Kazakhstan, Ahmad Shah attempted to rally neighboring Muslim khanates and the Kazakhs to unite and attack China, ostensibly to liberate its western Muslim subjects. Ahmad Shah halted trade with Qing China and dispatched troops to Kokand. However, with his campaigns in India exhausting the state treasury, and with his troops stretched thin throughout Central Asia, Ahmad Shah lacked sufficient resources to do anything except to send envoys to Beijing for unsuccessful talks.\n\nThe Mughal power in northern India had been declining since the reign of Aurangzeb, who died in 1707; In 1751-52, \"Ahamdiya\" treaty was signed between the Marathas and Mughals, when Balaji Bajirao was the Peshwa. Through this treaty, the Marathas controlled virtually the whole of India from their capital at Pune and the Mughal rule was restricted only to Delhi (the Mughals remained the nominal heads of Delhi). Marathas were now straining to expand their area of control towards the Northwest of India. Ahmad Shah sacked the Mughal capital and withdrew with the booty he coveted. To counter the Afghans, Peshwa Balaji Bajirao sent Raghunathrao. He defeated the Rohillas and Afghan garrisons in Punjab and succeeded in ousting Timur Shah and his court from India and brought Lahore, Multan, Kashmir and other subahs on the Indian side of Attock under Maratha rule. Thus, upon his return to Kandahar in 1757, Ahmad was forced to return to India and face the formidable attacks of the Maratha Confederacy.\n\nAhmad Shah declared a jihad (or Islamic holy war) against the Marathas, and warriors from various Pashtun tribes, and 25,000 Baloch warriors from various Baloch tribes joined his army under the command of Khan of Kalat Mir Noori Naseer Khan Baloch. Early skirmishes were followed by victory for the Afghans and Baloch against the smaller Maratha garrisons in Northwest India and by 1759 Ahmad and his army had reached Lahore and were poised to confront the Marathas. By 1760, the Maratha groups had coalesced into a big enough army under the command of Sadashivrao Bhau. Once again, Panipat was the scene of a confrontation between two warring contenders for control of northern India. The Third Battle of Panipat (14 January 1761), fought between largely Muslim and largely Hindu armies was waged along a twelve-kilometer front. Despite decisively defeating the Marathas, what might have been Ahmad Shah's peaceful control of his domains was disrupted by many challenges. As far as losses are concerned, Afghans too suffered heavily in the Third Battle of Panipat. This weakened his grasp over Punjab which fell to the rising Sikh misls. There were rebellions in the north in the region of Bukhara.\n\nThe victory at Panipat was the high point of Ahmad Shah's—and Afghan—power. However, even prior to his death, the empire began to unravel. In 1762, Ahmad Shah crossed the passes from Afghanistan for the sixth time to subdue the Sikhs. From this time and on, the domination and control of the Empire began to loosen. He assaulted Lahore and, after taking their holy city of Amritsar, massacred thousands of Sikh inhabitants, destroying their revered Golden Temple. Within two years, the Sikhs rebelled again and rebuilt their holy city of Amritsar. Ahmad Shah tried several more times to subjugate the Sikhs permanently, but failed. Ahmad Shah also faced other rebellions in the north, and eventually he and the Uzbek Emir of Bukhara agreed that the Amu Darya would mark the division of their lands. A decade after the third Battle of Panipat, Marathas under the leadership of Mahadji Scindia entered and recaptured Delhi in 1771, cutting off Rohillas from the Durranis forever. Ahmad Shah retired to his home in the mountains east of Kandahar, where he died on April 14, 1773. He had succeeded to a remarkable degree in balancing tribal alliances and hostilities, and in directing tribal energies away from rebellion. He earned recognition as Ahmad Shah Baba, or \"Father\" of Afghanistan.\n\nAhmad Shah's successors governed so ineptly during a period of profound unrest that within fifty years of his death, the Durrani empire \"per se\" was at an end, and Afghanistan was embroiled in civil war. Much of the territory conquered by Ahmad Shah fell to others in this half century. By 1818, the Sadozai rulers who succeeded Ahmad Shah controlled little more than Kabul and the surrounding territory within a 160-kilometer radius. They not only lost the outlying territories but also alienated other tribes and lineages among the Durrani Pashtuns.\n\nAhmad Shah was succeeded by his son, Timur Shah, who had been deputed to administer his father's conquests in Northern India, but had been driven out by the Marathas. Upon Ahmad Shah's death, the Durrani chieftains only reluctantly accepted Timur's accession. Most of his reign was spent fighting a civil war and resisting rebellion; Timur was even forced to move his capital from Kandahar to Kabul due to the insurgency. Timur Shah proved an ineffectual ruler, during whose reign the Durrani empire began to crumble. He is notable for having had 24 sons, several of whom became rulers of the Durrani territories. Timur died in 1793 and was then succeeded by his fifth son Zaman Shah\n\nAfter the death of Timur Shah, three of his sons, the governors of Kandahar, Herat and Kabul, contended for the succession. Zaman Shah, governor of Kabul, held the field by virtue of being in control of the capital, and became shah at the age of twenty-three. Many of his half-brothers were imprisoned on their arrival in the capital for the purpose, ironically, of electing a new shah. The quarrels among Timur's descendants that through Afghanistan into turmoil also provided the pretext for the interventions of outside forces.\n\nThe efforts of the Sadozai heirs of Timur to impose a true monarchy on the truculent Pashtun tribes, and their efforts to rule absolutely and without the advice of the other major Pashtun tribal leaders, were ultimately unsuccessful. The Sikhs started rising to power in defense of the years of invasions of Punjab by the Afghanis. Zaman Shah was unsuccessful in subduing them. A young Sikh chief, Ranjit Singh, then succeeded in wresting power from Zaman's forces. Later when Zaman was blinded by his brother, it was Ranjit Singh who gave him asylum in Punjab.\n\nZaman's downfall was triggered by his attempts to consolidate power. Although it had been through the support of the Barakzai chief, Painda Khan Barakzai, that he had come to the throne, Zaman soon began to remove prominent Barakzai leaders from positions of power and replace them with men of his own lineage, the Sadozai. This upset the delicate balance of Durrani tribal politics that Ahmad Shah had established and may have prompted Painda Khan and other Durrani chiefs to plot against the shah. Painda Khan and the chiefs of the Nurzai and the Alizai Durrani clans were executed, as was the chief of the Qizilbash clan. Painda Khan's son fled to Iran and pledged the substantial support of his Barakzai followers to a rival claimant to the throne, Zaman's older brother, Mahmud Shah. The clans of the chiefs Zaman had executed joined forces with the rebels, and they took Kandahar without bloodshed.\n\nZeman Shah's overthrow in 1801 was not the end of civil strife in Afghanistan, but the beginning of even greater violence. Mahmud Shah's first reign lasted for only two years before he was replaced by Shuja Shah.\n\nYet another of Timur Shah's sons, Shuja Shah (or Shah Shuja), ruled for only six years. On June 7, 1809, Shuja Shah signed a treaty with the British, which included a clause stating that he would oppose the passage of foreign troops through his territories. This agreement, the first Afghan pact with a Europea power, stipulated joint action in case of Franco-Persian aggression against Afghan or British dominions. Only a few weeks after signing the agreement, Shuja was deposed by his predecessor, Mahmud. Much later, he was reinstated by the British, ruling during 1839–1842. Two of his sons also ruled for a brief period in 1842.\n\nMahmud's second reign lasted nine years. Mahmud alienated the Barakzai, especially Fateh Khan, the son of Painda Khan, who was eventually seized and blinded. Revenge would later be sought and obtained by Fateh Khan's youngest brother, Dost Mohammad Khan.\n\nAli Shah was another son of Timur Shah. He seized power for a brief period in 1818-19.\n\nAyub Shah was another son of Timur Shah, who deposed Sultan Ali Shah. He was himself later deposed, and presumably killed in 1823. The loss of Kashmir during his reign opened a new chapter in South Asian history.\n\n\n\n", "id": "3070", "title": "Durrani Empire"}
{"url": "https://en.wikipedia.org/wiki?curid=3071", "text": "Aimaq people\n\nThe Aimaq (), also transliterated as \"Aimak\" or \"Aymaq\", are a collection of Persian-speaking nomadic and semi-nomadic tribes. Aimaqs are found mostly throughout Pakistan in the Kyber and Balochistan region and in the West Central highlands of Afghanistan, immediately to the north of Herat, and also to a much lesser amount in the Khorasan Province of Iran. They speak a number of subdialects of the Aimaq dialect of Persian, however some southern groups of Taymani and Maleki Aymaqs have adopted Pashto.\n\nAimaks were originally known as \"chahar\" (\"four\") Aymaqs: the Taimani (the main element in the population of Ghor), the Firozkohi, the Temuri, and the Jamshidi. Other sources state that the Aimaq Hazara are one of the \"Chahar\", with the Temuri instead being of the \"lesser Aimaqs\" or \"Aimaq-e digar\" (\"other Aimaqs\") along with the Tahiri, Zuri, Maleki, and Mishmast.\n\nAymāq is a Turkic and Mongolic word that means \"tribe\" or \"grazing territory\". Aimaq Hazara and Taimuri are most Mongoloid of the Aimaqs. The Temuri and Aimaq Hazaras live in yurts, whereas other Aimaqs live in traditional Afghan black tents.\n\nEstimates of the Aimaq population vary between 250,000 and 500,000. They are largely Sunni Muslims, in contrast to the Hazara, who are mostly Shia Muslims. The Temuri Aimaqs are of Mongolian origin, apparent in their physical appearance and their housing (Mongolian-style yurts). However, the Taimanis, Ferozkohis, and Jamshidis are of Iranian origin, and refer to themselves as Tajik; the majority of the Aimaqs in Afghanistan are of these latter three sub-groups.\n\n\n\n", "id": "3071", "title": "Aimaq people"}
{"url": "https://en.wikipedia.org/wiki?curid=3072", "text": "Arcturus\n\nArcturus (), also designated Alpha Boötis (α Boötis, abbreviated Alpha Boo, α Boo) , is the brightest star in the constellation of Boötes, the fourth-brightest in the night sky, and the brightest in the northern celestial hemisphere. Together with Spica and Denebola (or Regulus, depending on the source), Arcturus is part of the Spring Triangle asterism and, by extension, also of the Great Diamond along with the star Cor Caroli.\n\nRelatively close at 36.7 light-years from the Sun, Arcturus is a red giant of spectral type K0III—an ageing star around 7.1 billion years old that has used up its core hydrogen and moved off the main sequence. It is 1.08 ± 0.06 times as massive as the Sun, but has expanded to 25.4 ± 0.2 times its diameter and is around 170 times as luminous.\n\n\"α Boötis\" (Latinised to \"Alpha Boötis\") is the star's Bayer designation.\n\nThe traditional name \"Arcturus\" derives from Ancient Greek Ἀρκτοῦρος (\"Arktouros\") and means \"Guardian of the Bear\", ultimately from ἄρκτος (\"arktos\"), \"bear\" and οὖρος (\"ouros\"), \"watcher, guardian\". It has been known by this name since at least the time of Hesiod. This is a reference to its being the brightest star in the constellation of Boötes (of which it forms the left foot), which is next to the constellations of Ursa Major and Ursa Minor, the Greater and Lesser Bears.\n\nIn 2016, the International Astronomical Union organized a Working Group on Star Names (WGSN) to catalog and standardize proper names for stars. The WGSN's first bulletin of July 2016 included a table of the first two batches of names approved by the WGSN; which included \"Arcturus\" for this star. It is now so entered in the IAU Catalog of Star Names.\n\nWith an apparent visual magnitude of −0.05, Arcturus is the brightest star in the Northern celestial hemisphere and the fourth-brightest star in the night sky, after Sirius (−1.46  apparent magnitude), Canopus (−0.72) and Alpha Centauri (−0.27). However, Alpha Centauri is a binary star, whose unresolved components to the naked eye are both fainter than Arcturus. This makes Arcturus the third-brightest individual star, just ahead of Alpha Centauri A, whose apparent magnitude is −0.01. The French mathematician and astronomer Jean-Baptiste Morin observed Arcturus in the daytime with a telescope (a first for any star other than the Sun and supernovae) in 1635, and Arcturus has been seen at or just before sunset with the naked eye.\n\nArcturus is visible from both Earth's hemispheres as it is located 19° north of the celestial equator. The star culminates at midnight on 27 April, and at 9PM on June 10 being visible during the late northern spring or the southern autumn. From the northern hemisphere, an easy way to find Arcturus is to follow the arc of the handle of the Big Dipper (Plough). By continuing in this path, one can find Spica, \"Arc to Arcturus, then spike to Spica\".\n\nPtolemy described Arcturus as \"subrufa\" (\"slightly red\"): it has a B-V color index of +1.23, roughly midway between Pollux (B-V +1.00) and Aldebaran (B-V +1.54).\n\nEta Boötis, or Muphrid, is only 3.3 light-years distant from Arcturus, and would have a visual magnitude −2.5, whereas an observer on the former system would find Arcturus as bright as Venus as seen from Earth.\n\nBased upon an annual parallax shift of 88.83 milliarcseconds as measured by the Hipparcos satellite, Arcturus is from the Sun (the margin of error is 0.54 milliarcseconds, translating to a margin of error of ±).\n\nArcturus is a type K0 III red giant star. With an absolute magnitude of −0.30 it is, together with Vega and Sirius, one of the most luminous stars in the Sun's neighborhood. It is about 110 times brighter than the Sun in visible light wavelengths, but this underestimates its strength as much of the light it gives off is in the infrared; total (bolometric) power output is about 180 times that of the Sun. The lower output in visible light is due to a lower efficacy as the star has a lower surface temperature than the Sun. With a near-infrared J band magnitude of −2.2, only Betelgeuse (−2.9) and R Doradus (−2.6) are brighter.\n\nAs the brightest K-type giant in the sky, it was the subject of an atlas of its visible spectrum, made from photographic spectra taken with the coudé spectrograph of the Mt. Wilson 2.5m telescope published in 1968, a key reference work for stellar spectroscopy. Subsequent spectral atlases\n\nAs a single star, the mass of Arcturus cannot be measured directly, but models suggest it is slightly larger than that of the Sun. Evolutionary matching to the observed physical parameters gives a mass of , while the oxygen isotope ratio for a first Dredge-up star gives a mass of .\n\nArcturus has been estimated to be around 6 billion to 8.5 billion years old, and is ascending the red giant branch until it accumulates a large enough degenerate helium core to ignite the helium flash. It has likely exhausted the hydrogen from its core and is now in its active hydrogen shell burning phase. It will continue to expand before entering horizontal branch stage of its life cycle.\n\nAs one of the brightest stars in the sky, Arcturus has been the subject of a number of studies in the emerging field of asteroseismology. Belmonte and colleagues carried out a radial velocity (Doppler shift of spectral lines) study of the star in April and May 1988, which showed variability with a frequency of the order of a few microhertz, the highest peak corresponding to 4.3 μHz (2.7 days) with an amplitude of 60 ms, with a frequency separation of c. 5 μHz. They suggested that the most plausible explanation for the variability of Arcturus is stellar oscillations.\n\nAsteroseismological measurements allow direct calculation of the mass and radius, giving values of and . This form of modelling is still relatively inaccurate, but a useful check on other models.\n\nAstronomers term \"metals\" those elements with higher atomic numbers than helium. Arcturus has an enrichment of alpha elements relative to iron but only about a third of solar metallicity, Arcturus is possibly a Population II star.\n\nArcturus has a high proper motion, two arcseconds a year, greater than any first magnitude star other than α Centauri. It is moving rapidly () relative to the Solar System, and is now almost at its closest point to the Sun. Closest approach will happen in about 4,000 years, when the star will be a few hundredths of a light-year closer to Earth than it is today. Arcturus is thought to be an old disk star, and appears to be moving with a group of 52 other such stars, known as the Arcturus stream.\n\nIn antiquity, Arcturus was closer to the centre of the constellation.\n\n\"Hipparcos\" also suggested that Arcturus is a binary star, with the companion about twenty times dimmer than the primary and orbiting close enough to be at the very limits of humans' current ability to make it out. Recent results remain inconclusive, but do support the marginal \"Hipparcos\" detection of a binary companion.\n\nIn 1993, radial velocity measurements of Aldebaran, Arcturus and Pollux showed that Arcturus exhibited a long-period radial velocity oscillation, which could be interpreted as a \"substellar companion\". This substellar object would be nearly 12 times the mass of Jupiter and be located roughly at the same orbital distance from Arcturus as the Earth is from the Sun, at 1.1 Astronomical Units. However, all three stars surveyed showed similar oscillations yielding similar companion masses, and the authors concluded that the variation was likely to be intrinsic to the star rather than due to the gravitational effect of a companion. So far no substellar companion has been confirmed.\n\nIn Arabic, Arcturus is one of two stars called \"al-simāk\" \"the uplifted one\" (the other is Spica). Arcturus is specified as السماك الرامح \"as-simāk ar-rāmiħ\" \"the uplifted one of the lancer\". The term \"Al Simak Al Ramih\" has appeared in Al Achsasi Al Mouakket catalogue (translated into Latin as \"Al Simak Lanceator\").\n\nThis has been variously romanized in the past, leading to obsolete variants such as \"Aramec\" and \"Azimech\". For example, the name \"Alramih\" is used in Geoffrey Chaucer's \"Treatise on the Astrolabe\" (1391). Another Arabic name is \"Haris-el-sema\", from \"حارس السماء\" \"ħāris al-samā’\" \"the keeper of heaven\". or \" حارس الشمال\" \"ħāris al-shamāl’\" \"the keeper of north\".\n\nArcturus was once again called by its classical name from the Renaissance onwards.\n\nIn Chinese astronomy, Arcturus is called \"Da Jiao\" (), because it is the brightest star in the Chinese constellation called \"Jiao Xiu\" (). Later it become a part of another constellation \"Kang Xiu\" ().\n\nIn Indian Astrology or Vedic Astrology or Sidereal Astrology, Arcturus is called \"Swati\" which is a word meaning \"very beneficent\" derived from the language Sanskrit. It is the eponymous star of one of the nakshatras (lunar mansions) of Hindu astrology.\n\nIn Indonesia, Arcturus is called \"Bintang Biduk\" (star of boat).\n\nIn Japan, Arcturus is called \"Mugi-boshi\" (麦星), meaning \"star of wheat\".\n\nThe Wotjobaluk Koori people of southeastern Australia knew Arcturus as \"Marpean-kurrk\", mother of \"Djuit\" (Antares) and another star in Bootes, \"Weet-kurrk\" (Muphrid). Its appearance in the north signified the arrival of the larvae of the wood ant (a food item) in spring. The beginning of summer was marked by the star's setting with the Sun in the west and the disappearance of the larvae. The people of Milingimbi Island in Arnhem Land saw Arcturus and Muphrid as man and woman, and took the appearance of Arcturus at sunrise as a sign to go and harvest \"rakia\" or spikerush. The Wailwun of northern New South Wales knew Arcturus as \"Guembila\" \"red\".\n\nIn Inuit astronomy, Arcturus is called the Old Man (\"Uttuqalualuk\" in Inuit) and The First Ones (\"Sivulliik\" in Inuit).\n\nThe Mi'kmaq of eastern Canada saw Arcturus as \"Kookoogwéss\", the owl.\n\nArcturus had several names that described its significance to indigenous Polynesians. In the Society Islands, Arcturus, called \"Ana-tahua-taata-metua-te-tupu-mavae\" (\"a pillar to stand by\"), was one of the ten \"pillars of the sky\", bright stars that represented the ten heavens of the Tahitian afterlife. In Hawaii, the pattern of Boötes was called \"Hoku-iwa\", meaning \"stars of the frigate bird\". This constellation marked the path for Hawaiiloa on his return to Hawaii from the South Pacific Ocean. The Hawaiians called Arcturus \"Hoku-leʻa\". It was equated to the Tuamotuan constellation \"Te Kiva\", meaning \"frigate-bird\", which could either represent the figure of Boötes or just Arcturus. However, Arcturus may instead be the Tuamotuan star called \"Turu\". The Hawaiian name for Arcturus as a single star was likely \"Hoku-leʻa\", which means \"star of gladness\", or \"clear star\". In the Marquesas Islands, Arcturus was probably called \"Tau-tou\" and was the star that ruled the month approximating January. The Maori and Moriori called it \"Tautoru\", a variant of the Marquesan name and a name shared with Orion's Belt.\n\nAs one of the brightest stars in the sky, Arcturus has been significant to observers since antiquity.\n\nPrehistoric Polynesian navigators knew Arcturus as \"Hōkūleʻa\", the \"Star of Joy\". Arcturus is the zenith star of the Hawaiian Islands. Using Hōkūleʻa and other stars, the Polynesians launched their double-hulled canoes from Tahiti and the Marquesas Islands. Traveling east and north they eventually crossed the equator and reached the latitude at which Arcturus would appear directly overhead in the summer night sky. Knowing they had arrived at the exact latitude of the island chain, they sailed due west on the trade winds to landfall. If Hōkūleʻa could be kept directly overhead, they landed on the southeastern shores of the Big Island of Hawaiʻi. For a return trip to Tahiti the navigators could use Sirius, the zenith star of that island. Since 1976, the Polynesian Voyaging Society's \"Hōkūle‘a\" has crossed the Pacific Ocean many times under navigators who have incorporated this wayfinding technique in their non-instrument navigation.\n\nIn ancient Mesopotamia, it was linked to the god Enlil, and also known as Shudun, \"yoke\", or SHU-PA of unknown derivation in the \"Three Stars Each\" Babylonian star catalogues and later MUL.APIN around 1100 BC.\n\nIn Ancient Rome, the star's celestial activity was supposed to portend tempestuous weather, and a personification of the star acts as narrator of the prologue to Plautus' comedy \"Rudens\" (circa 211 BC).\n\nIn the Hebrew scriptures Arcturus is referred to in Job 38:32.\n\nIn the Middle Ages, Arcturus was considered a Behenian fixed star and attributed to the stone Jasper and the plantain herb. Cornelius Agrippa listed its kabbalistic sign under the alternate name \"Alchameth\".\n\nThe Karandavyuha sutra, compiled at the end of the 4th century or beginning of the 5th century C.E., names one of Avalokiteshvara's meditative absorptions as \"The face of Arcturus\".\n\nArcturus achieved fame when its light was rumored to be the mechanism used to open the 1933 Chicago World's Fair. The star was chosen as it was thought that light from Arcturus had started its journey at about the time of the previous Chicago World's Fair in 1893 (at 36.7 light-years away, and the light actually started in 1896.\n\nThe star is featured in the 1977 documentary film \"Powers of Ten\", in which it is seen when a camera zooms from Earth to the whole of the known universe.\n\n\n", "id": "3072", "title": "Arcturus"}
{"url": "https://en.wikipedia.org/wiki?curid=3074", "text": "Androphagi\n\nAndrophagi (Ancient Greek : \"Ἀνδροφάγοι\" for \"man-eaters\") was an ancient nation of cannibals north of Scythia (according to Herodotus), probably in the forests between the upper waters of the Dnepr and Don. These people may have assisted the Scythians when King Darius the Great led a Persian invasion into what is now Southern Russia to punish the Scythians for their raids into the Achaemenid Empire.\n\nHerodotus first wrote of \"andropophagi\" in his \"Histories\", where he described them as one of several tribes near Scythia. An extra note indicates that the \"andropophagi\" are cannibals, as reflected in their name:\n\nPliny the Elder later wrote in his \"Naturalis Historia\" that the same cannibals near Scythia wore the scalps of men on their chest.\n\nHistorian Marija Gimbutas has hypothesized that \"Androphagoi\" is a Greek translation of *mard-xwaar \"man-eater\" in the old North Iranian language of the Scythians. From *mard-xwaar one can derive \"Mordva\" or \"Mordvin\", the Russian name of the Finno-Ugrian Erzya and Moksha peoples of east-central European Russia. From Herodotus we can deduce a location for the Androphagoi that is approximately the same as that occupied by the modern Mordvins.\n\n\n", "id": "3074", "title": "Androphagi"}
{"url": "https://en.wikipedia.org/wiki?curid=3075", "text": "Albert Brooks\n\nAlbert Lawrence Brooks (born Albert Lawrence Einstein; July 22, 1947) is an American actor, filmmaker, author and comedian. He received an Academy Award nomination for Best Supporting Actor for 1987's \"Broadcast News\" and was widely praised for his performance in the 2011 film \"Drive\". His voice acting credits include Marlin in \"Finding Nemo\" (2003) and \"Finding Dory\" (2016), and recurring guest voices for \"The Simpsons\", including Russ Cargill in \"The Simpsons Movie\" (2007). He has directed, written, and starred in several comedy films, such as \"Modern Romance\" (1981), \"Lost in America\" (1985), and \"Defending Your Life\" (1991). He is also the author of \"2030: The Real Story of What Happens to America\" (2011).\n\nBrooks was born in Beverly Hills, California, the son of Thelma Leeds (née Goodman), a singer and actress, and Harry Einstein, a radio comedian who performed on Eddie Cantor's radio program and was known as Parkyakarkus. His brothers are comedic actor Bob Einstein, better known as a character he created named \"Super Dave Osborne\", and for a recurring role in \"Curb Your Enthusiasm\"; and Cliff Einstein, a partner and longtime chief creative officer at Los Angeles advertising agency Dailey & Associates. His half-brother was Charles Einstein (1926–2007), a writer for such television programs as \"Playhouse 90\" and \"Lou Grant\". Brooks is Jewish; his grandparents emigrated from Austria and Russia. He grew up among show business families in southern California, attending Beverly Hills High School with Richard Dreyfuss and Rob Reiner.\n\nBrooks attended Carnegie Mellon University in Pittsburgh, but dropped out after one year to focus on his comedy career. By the age of 19, he had changed his professional name to Albert Brooks, joking that \"the real Albert Einstein changed his name to sound more intelligent\". He began a comedy career that quickly made him a regular on variety and talk shows during the late 1960s and early 1970s. Brooks led a new generation of self-reflective baby-boomer comics appearing on NBC's \"The Tonight Show Starring Johnny Carson\". His onstage persona, that of an egotistical, narcissistic, nervous comic, an ironic showbiz insider who punctured himself before an audience by disassembling his mastery of comedic stagecraft, influenced other '70s post-modern comedians, including Steve Martin, Martin Mull, and Andy Kaufman.\n\nAfter two successful comedy albums, \"Comedy Minus One\" (1973) and the Grammy Award–nominated \"A Star Is Bought\" (1975), Brooks left the stand-up circuit to try his hand as a filmmaker. He had already made his first short film, \"The Famous Comedians School\", a satiric short and an early example of the mockumentary subgenre that appeared on the PBS show The Great American Dream Machine in 1972.\n\nIn 1975, he directed six short films for the first season of NBC's \"Saturday Night Live\":\n\n\nIn 1976 he appeared in his first mainstream film role, in Martin Scorsese's landmark \"Taxi Driver\"; Scorsese allowed Brooks to improvise much of his dialogue. The role reflected Brooks's decision to move to Los Angeles to enter the film business. In an interview, Brooks mentioned a conversation he'd had with \"Taxi Driver\" screenwriter Paul Schrader, in which Schrader said that Brooks's character was the only one in the movie that he could not \"understand\" – a remark that Brooks found amusing, as the movie's antihero was a psychotic loner.\n\nBrooks directed his first feature film, \"Real Life\", in 1979. The film, in which Brooks (playing a version of himself) obnoxiously films a typical suburban family in an effort to win both an Oscar and a Nobel Prize, was a sendup of PBS's \"An American Family\" documentary. It has also been viewed as foretelling the future emergence of reality television. Brooks also made a cameo appearance in the film \"Private Benjamin\" (1980), starring Goldie Hawn. (He also got starring credits in the film, even though his character dies within roughly the first half-hour of the film.)\n\nThrough the 1980s and 1990s, Brooks co-wrote (with longtime collaborator Monica Johnson), directed and starred in a series of well-received comedies, playing variants on his standard neurotic and self-obsessed character. These include 1981's \"Modern Romance\", where Brooks played a film editor desperate to win back his ex-girlfriend (Kathryn Harrold). The film received a limited release and ultimately grossed under $3 million domestically, but was well received by critics, with one reviewer commenting that the film was \"not Brooks at his best, but still amusing\". His best-received film, \"Lost in America\" (1985), featured Brooks and Julie Hagerty as a couple who leave their yuppie lifestyle and drop out of society to live in a motor home as they have always dreamed of doing, meeting disappointment.\n\nBrooks's \"Defending Your Life\" (1991) placed his lead character in the afterlife, put on trial to justify his human fears and determine his cosmic fate. Critics responded to the offbeat premise and the chemistry between Brooks and Meryl Streep, as his post-death love interest. His later efforts did not find large audiences, but still retained Brooks's touch as a filmmaker. He garnered positive reviews for \"Mother\" (1996), which starred Brooks as a middle-aged writer moving back home to resolve tensions between himself and his mother (Debbie Reynolds). 1999's \"The Muse\" featured Brooks as a down-and-out Hollywood screenwriter using the services of an authentic muse (Sharon Stone) for inspiration. In an interview with Brooks with regards to \"The Muse\", Gavin Smith wrote, \"Brooks's distinctive filmmaking style is remarkably discreet and unemphatic; he has a light, deft touch, with a classical precision and economy, shooting and cutting his scenes in smooth, seamless successions of medium shots, with clean, high-key lighting.\"\n\nBrooks has appeared as a guest voice on \"The Simpsons\" five times during its run (always under the name \"A. Brooks\"), and is described as the best guest star in the show's history by IGN, particularly for his role as supervillain Hank Scorpio in the episode \"You Only Move Twice\".\n\nBrooks also acted in other writers' and directors' films during the 1980s and 1990s. He had a cameo in the opening scene of \"\", playing a driver whose passenger (Dan Aykroyd) has a shocking secret. In James L. Brooks's hit \"Broadcast News\" (1987), Albert Brooks was nominated for an Academy Award for Best Supporting Actor for playing an insecure, supremely ethical network TV reporter, who offers the rhetorical question, \"Wouldn't this be a great world if insecurity and desperation made us more attractive?\" He also won positive notices for his role in 1998's \"Out of Sight\", playing an untrustworthy banker and ex-convict.\n\nBrooks received positive reviews for his portrayal of a dying retail store owner who befriends disillusioned teen Leelee Sobieski in \"My First Mister\" (2001). Brooks continued his voiceover work in Pixar's \"Finding Nemo\" (2003), as the voice of Marlin, one of the film's protagonists; \"Nemo\" is Brooks's largest grossing film to date.\n\nIn 2005, his film \"Looking for Comedy in the Muslim World\" was dropped by Sony Pictures due to their desire to change the title. Warner Independent Pictures purchased the film and gave it a limited release in January 2006; the film received mixed reviews and a low box office gross. The movie goes back to the days of Brooks's \"Real Life\", as Brooks once again plays himself, a filmmaker commissioned by the U.S. government to see what makes the Muslim people laugh, thus sending him on a tour of India and Pakistan.\n\nIn 2006 he appeared in the documentary film \"Wanderlust\" as David Howard from \"Lost in America\". The documentary included many other well known people. In 2007, he continued his long term collaboration with \"The Simpsons\" by voicing Russ Cargill, the central antagonist of \"The Simpsons Movie\".\n\nHe has played Lenny Botwin, Nancy Botwin's estranged father-in-law, on Showtime's television series \"Weeds\". St. Martin's Press published his first novel, \"2030: The Real Story of What Happens to America\", on May 10, 2011.\n\nIn 2011, Brooks co-starred as the vicious gangster Bernie Rose, the main antagonist in the motion picture \"Drive\", alongside Ryan Gosling and Carey Mulligan, a role that has been given much critical praise and positive reviews, with several critics proclaiming Brooks' performance as one of the film's best aspects. After receiving awards and nominations from several film festivals and critic groups, but not an Academy Award nomination, Brooks responded humorously on Twitter, \"And to the Academy: ‘You don't like me. You really don't like me’.\"\n\nIn 2016, Brooks reprised the role of Marlin from Finding Nemo in the 2016 sequel \"Finding Dory\" and voiced Tiberius, a curmudgeonly red-tailed hawk in \"The Secret Life of Pets\".\n\nIn 1997, Brooks married website designer Kimberly Shlain, daughter of surgeon and writer Leonard Shlain. They have two children, Jacob and Claire, and reside in Santa Monica, California.\n\n", "id": "3075", "title": "Albert Brooks"}
{"url": "https://en.wikipedia.org/wiki?curid=3076", "text": "Antares\n\nAntares (), also designated Alpha Scorpii (α Scorpii, abbreviated Alpha Sco, α Sco), is on average the fifteenth-brightest star in the night sky, the brightest star in the constellation of Scorpius. Distinctly reddish when viewed with the unaided eye, Antares is a slow irregular variable star that ranges in brightness from apparent magnitude to +0.6 to +1.6. Often referred to as \"the heart of the scorpion\", Antares is flanked by Sigma and Tau Scorpii in the centre of the constellation.\n\nClassified as a red supergiant of spectral type M1.5Iab, Antares is one of the largest known stars. It is the brightest, most massive, and most evolved stellar member of the nearest OB association (the Scorpius–Centaurus Association). Antares is a member of the Upper Scorpius subgroup of the Scorpius–Centaurus Association, which contains thousands of stars with mean age 11 million years at a distance of approximately . It is thought to be between 15 and 18 times as massive as the Sun, and have around 883 times its radius. Hence, if placed in the center of the Solar System, its outer surface would lie between the orbits of Mars and Jupiter.\n\n\"α Scorpii\" (Latinised to \"Alpha Scorpii\") is the star's Bayer designation. It also has the Flamsteed designation 21 Scorpii, as well as catalogue designations such as HR 6134 in the Bright Star Catalogue and HD 148478 in the Henry Draper Catalogue. As a prominent infrared source, it appears in the Two Micron All-Sky Survey catalogue as 2MASS J16292443-2625549 and the Two Micron All-Sky Survey catalogue as IRAS 16262-2619. It is also catalogued as a double star WDS J16294-2626 and CCDM J16294-2626.\n\nThe traditional name \"Antares\" derives from the Ancient Greek , meaning \"equal to-Ares\" (\"equal to-Mars\"), due to the similarity of its reddish hue to the appearance of the planet Mars. The comparison of Antares with Mars may have originated with early Mesopotamian astronomers. However, some scholars have speculated that the star may have been named after Antar, or Antarah ibn Shaddad, the Arab warrior-hero celebrated in the pre-Islamic poems Mu'allaqat. In 2016, the International Astronomical Union organised a Working Group on Star Names (WGSN) to catalog and standardise proper names for stars. The WGSN's first bulletin of July 2016 included a table of the first two batches of names approved by the WGSN; which included \"Antares\" for this star. It is now so entered in the IAU Catalog of Star Names.\n\nAntares is a variable star and is listed in the General Catalogue of Variable Stars but as a Bayer-designated star it does not have a separate variable star designation.\n\nAntares is a supergiant star with a stellar classification of M1.5Iab. With a radius that is approximately 883 times that of the Sun, it is one of largest stars, if placed in the center of the Solar System, its outer surface would lie between the orbits of Mars and Jupiter. Based upon parallax measurements, Antares is approximately from the Sun. Its visual luminosity is about 10,000 times that of the Sun, but because the star radiates a considerable part of its energy in the infrared part of the spectrum, the bolometric luminosity equals roughly 65,000 times that of the Sun. The mass of the star has been calculated to be in the range of 15 to 18 solar masses. A 2012 analysis by Pecaut and colleagues comparing the effective temperature and luminosity of Antares to theoretical evolutionary tracks for massive stars which include rotation and mass loss yielded a mass of approximately 17 solar masses and an age of 12 million years.\n\nThe size of Antares may be calculated using its parallax and angular diameter. The parallax angle is given in the adjacent box, and the angular diameter is known from lunar occultation measurements (41.3 ± 0.1 milliarcseconds). This implies a radius of 890 ± 150 solar radii at this distance. By analysing its radial velocity from its spectrum, Pugh and colleagues calculated a period of 5.93 ± 0.01 years and considered whether this change was orbital or pulsational. If the latter, then the radius of the star changes by 165 ± 22 solar radii (19% ± 4%). However, if this were the case, Antares' brightness would vary by a greater amount.\n\nAntares is a type \"LC\" slow irregular variable star, whose apparent magnitude slowly varies from +0.6 to +1.6.\n\nAntares is visible in the sky all night around May 31 of each year, when the star is at opposition to the Sun. At this time, Antares rises at dusk and sets at dawn as seen at the equator. For approximately two to three weeks on either side of November 30, Antares is not visible in the night sky, because it is near conjunction with the Sun; this period of invisibility is longer in the Northern Hemisphere than in the Southern Hemisphere, since the star's declination is significantly south of the celestial equator.\n\nAntares is one of the four first magnitude stars that lies within 5° of the ecliptic (like Spica, Regulus and Aldebaran) and therefore can be occulted by the Moon and, though rarely, by Venus. The last occultation of Antares by Venus took place on September 17, 525 BC; the next one will take place on November 17, 2400. Other planets have not occulted Antares in the last millennium nor will they do so in the next millennium, as they pass as a result of their actual node position and inclination always northward of Antares. On 31 July 2009, Antares was occulted by the Moon. The event was visible in much of southern Asia and the Middle East. Every year around December 2 the Sun passes 5° north of Antares.\n\nAntares has a magnitude 5.5 companion star, Antares B, that changed from an angular separation (from its primary, Antares A) of 3.3 arcseconds in 1854 to 2.86 arcseconds in 1990. It was first observed by Scottish astronomer James William Grant FRSE while in India on 23 July 1844. The last is equal to a projected separation of about 529 astronomical units (au) at the estimated distance of Antares, giving a minimum value for the separation of the pair. Spectroscopic examination of the energy states in the outflow of matter from the companion star suggests that it is about 224 au beyond the primary. Antares B is a blue-white main-sequence star of spectral type B2.5V; it also has numerous unusual spectral lines suggesting it has been polluted by matter ejected by Antares A.\n\nThe companion star is normally difficult to see in small telescopes due to glare from Antares A, but can sometimes be seen in apertures over . The companion is often described as green, but this is probably either a contrast effect, or the result of the mixing of light from the two stars when they are seen together through a telescope and are too close to be completely resolved. Antares B can sometimes be observed with a small telescope for a few seconds during lunar occultations while Antares A is hidden by the Moon. It was discovered by Johann Tobias Bürg during one such occultation on April 13, 1819, but until its existence was confirmed in 1846 it was thought by some to be merely the light of Antares viewed through the Moon's atmosphere (which at the time was theorised to exist). When observed by itself during such an occultation, the companion appears a profound blue or bluish-green color.\n\nThe orbit of the companion star is poorly known, as attempts to analyse the radial velocity of Antares need to be unravelled from the star's own pulsations. Orbital periods are possible within a range of 1,200 to 2,562 years.\n\nAntares, like the similarly-sized red giant Betelgeuse in the constellation Orion, will almost certainly explode as a supernova, probably within the next few hundred thousand years. For a few months, the Antares supernova could be as bright as the full moon and be visible in daytime.\n\nIn the Babylonian star catalogues dating from at least 1100 BCE, Antares was called GABA GIR.TAB, \"the Breast of the Scorpion\". In MUL.APIN, which dates between 1100 and 700 BC, it is one of the stars of Ea in the southern sky and marks breast of the Scorpion goddess Ishhara. Later names that translate as \"the Heart of Scorpion\" include ' from the Arabic '. This had been directly translated from the Ancient Greek '. ' translated above Greek name into Latin.\"\n\nIn ancient Mesopotamia, Antares may have been known by the following names: Urbat, Bilu-sha-ziri (\"the Lord of the Seed\"), Kak-shisa (\"the Creator of Prosperity\"), Dar Lugal (\"The King\"), Masu Sar (\"the Hero and the King\"), and Kakkab Bir (\"the Vermilion Star\"). In ancient Egypt, Antares represented the scorpion goddess Serket (and was the symbol of Isis in the pyramidal ceremonies).\n\nIn Persia, Antares was known as \"Satevis\", one of the four \"royal stars\". In India, it with Sigma and Tau Scorpii were Jyeshthā (the eldest or biggest), one of the \"nakshatra\" (Hindu lunar mansions). The ancient Chinese called Antares \"()\", because it was the second-brightest star of the mansion \"Xin\" (心). It was the national star of the Shang Dynasty, and it was sometimes referred to as () because of its reddish appearance.\n\nThe Māori people of New Zealand call Antares \"Rehua\", and regard it as the chief of all the stars. Rehua is father of \"Puanga/Puaka\" (Rigel), an important star in the calculation of the Māori calendar. The Wotjobaluk Koori people of Victoria, Australia, knew Antares as \"Djuit\", son of \"Marpean-kurrk\" (Arcturus); the stars on each side represented his wives. The Kulin Kooris saw Antares (\"Balayang\") as the brother of \"Bunjil\" (Altair).\n\n\n", "id": "3076", "title": "Antares"}
{"url": "https://en.wikipedia.org/wiki?curid=3077", "text": "Aldebaran\n\nAldebaran, designated Alpha Tauri (α Tauri, abbreviated Alpha Tau, α Tau), is an orange giant star located about 65 light years from the Sun in the zodiac constellation of Taurus. It is the brightest star in its constellation and usually the fourteenth-brightest star in the nighttime sky, though it varies slowly in brightness between magnitude 0.75 and 0.95. It is likely that Aldebaran hosts a planet several times the size of Jupiter.\n\nThe planetary exploration probe Pioneer 10 is currently heading in the general direction of the star and should make its closest approach in about two million years.\n\n\"Alpha Tauri\" is the star's Bayer designation. The name \"Aldebaran\" is Arabic (' ') and means \"the Follower\", presumably because it rises near and soon after the Pleiades. In 2016, the International Astronomical Union organized a Working Group on Star Names (WGSN) to catalog and standardize proper names for stars. The WGSN's first bulletin of July 2016 included a table of the first two batches of names approved by the WGSN; which included \"Aldebaran\" for this star. It is now so entered in the IAU Catalog of Star Names.\n\nIn Persia it was known as Tascheter.\n\nThe Romans called it \".\n\nIn the Middle Ages it was sometimes called Cor Tauri (the Heart of the Bull/Taurus).\n\nJohn Gower refers to it as Aldeboran.\n\nIn Chinese it is known as (\", the Fifth Star of the Net).\n\nIn Hindu astronomy it is identified as the lunar mansion Rohini (\"the red one\") and as one of the twenty-seven daughters of Daksha and the wife of the god Chandra (moon).\n\nThis easily seen and striking star in its suggestive asterism is a popular subject for ancient and modern myths.\n\nOn March 11, of 509 AD, a lunar occultation of Aldebaran was observed in Athens, Greece. English astronomer Edmund Halley studied the timing of this event, and in 1718 concluded that Aldebaran must have changed position since that time, moving several minutes of arc further to the north. This, as well as observations of the changing positions of stars Sirius and Arcturus, led to the discovery of proper motion. Based on present day observations, the position of Aldebaran has shifted 7′ in the last 2000 years; roughly a quarter the diameter of the full Moon. Note that 5,000 years ago the vernal equinox was close to Aldebaran.\n\nEnglish astronomer William Herschel discovered a faint companion to Aldebaran in 1782; an 11th magnitude star at an angular separation of 117″. This star was shown to be itself a close double star by S. W. Burnham in 1888, and he discovered an additional 14th magnitude companion at an angular separation of 31″. Follow on measurements of proper motion showed that Herschel's companion was diverging from Aldebaran, and hence they were not physically connected. However, the companion discovered by Burnham had almost exactly the same proper motion as Aldebaran, suggesting that the two formed a wide binary star system.\n\nWorking at his private observatory in Tulse Hill, England, in 1864 William Huggins performed the first studies of the spectrum of Aldebaran, where he was able to identify the lines of nine elements, including iron, sodium, calcium, and magnesium. In 1886, Edward C. Pickering at the Harvard College Observatory used a photographic plate to capture fifty absorption lines in the spectrum of Aldebaran. This became part of the Draper Catalogue, published in 1890. By 1887, the photographic technique had improved to the point that it was possible to measure a star's radial velocity from the amount of Doppler shift in the spectrum. By this means, the recession velocity of Aldebaran was estimated as (48 km/s), using measurements performed at Potsdam Observatory by Hermann C. Vogel and his assistant Julius Scheiner.\n\nThe angular diameter of this star was measured for the first time in 1921 using an interferometer attached to the Hooker Telescope at the Mount Wilson Observatory. The result was 0.0237″, which was in close agreement with the estimated values of the time.\n\nAldebaran is classified as a type K5 III star, which indicates it is an orange-hued giant star that has evolved off the main sequence band of the Hertzsprung–Russell diagram after exhausting the hydrogen at its core. The collapse of the centre of the star into a degenerate helium core has ignited a shell of hydrogen outside the core and Aldebaran is now a red giant. This has caused it to expand to 44.2 times the diameter of the Sun, equivalent to approximately 61 million kilometres (see 10 gigametres for similar sizes).\n\nMeasurements by the Hipparcos satellite and other sources put Aldebaran around away. Stellar models predict it only has about 50% more mass than the Sun, yet it shines with 425 times the Sun's luminosity due to the expanded radius. Aldebaran is a slightly variable star, of the slow irregular variable type \"LB\". It varies by about 0.2 in apparent magnitude from 0.75 to 0.95. With a near-infrared J band magnitude of −2.1, only Betelgeuse (−2.9), R Doradus (−2.6), and Arcturus (−2.2) are brighter.\n\nThe photosphere shows abundances of carbon, oxygen, and nitrogen that suggest the giant has gone through its first dredge-up stage—a normal step in the evolution of a star into a red giant during which material from deep within the star is brought up to the surface by convection. With its slow rotation, Aldebaran lacks a dynamo needed to generate a corona and hence is not a source of hard X-ray emission. However, small scale magnetic fields may still be present in the lower atmosphere, resulting from convection turbulence near the surface. (The measured strength of the magnetic field on Aldebaran is 0.22 G.) Any resulting soft X-ray emissions from this region may be attenuated by the chromosphere, although ultraviolet emission has been detected in the spectrum. The star is currently losing mass at a rate of with a velocity of . This stellar wind may be generated by the weak magnetic fields in the lower atmosphere.\n\nBeyond the chromosphere of Aldebaran is an extended molecular outer atmosphere (MOLsphere) where the temperature is cool enough for molecules of gas to form. This region lies between 1.2 and 2.8 times the radius of the star, with temperatures of 1,000−2,000 K. The spectrum reveals lines of carbon monoxide, water, and titanium oxide. Past this radius, the modest outflow of the stellar wind itself declines in temperature to about 7,500 K at a distance of 1 Astronomical Unit (AU)−the distance of the Earth from the Sun. The wind continues to expand until it reaches the termination shock boundary with the hot, ionized interstellar medium that dominates the Local Bubble, forming a roughly spherical astrosphere with a radius of around 1,000 AU, centered on Aldebaran.\n\nAldebaran is one of the easiest stars to find in the night sky, partly due to its brightness and partly due to its spatial relation to one of the more noticeable asterisms in the sky. If one follows the three stars of Orion's belt from left to right (in the Northern Hemisphere) or right to left (in the Southern), the first bright star found by continuing that line is Aldebaran.\n\nSince the star is located (by chance) in the line of sight between the Earth and the Hyades, it has the appearance of being the brightest member of the more scattered Hyades open star cluster that makes up the bull's-head-shaped asterism; however, the star cluster is actually more than twice as far away, at about 150 light years.\n\nAldebaran is close enough to the ecliptic to be occulted by the Moon. Such occultations occur when the Moon's ascending node is near the autumnal equinox. A series of 49 occultations occur starting at 29 Jan 2015 and ending at 3 Sep 2018. Each event is visible from a different location on Earth, but always in the northern hemisphere or close to the equator. That means that people in e.g. Australia or South Africa can never observe an Aldebaran occultation. This is due to the fact that Aldebaran is slightly too far south of the ecliptic. A reasonably accurate estimate for the diameter of Aldebaran was obtained during the September 22, 1978 occultation. Aldebaran is in conjunction with the Sun around June 1 of each year.\n\nOccultations by planets are not possible at present, as each planet passes Aldebaran north. The closest conjunction of a planet with Aldebaran in the 21st century occurred on July 9, 2012, when Venus passed Aldebaran 56' northward. However, in the far future and far past occultations of Aldebaran by Mercury and Venus occurred as result of wandering nodes. The next occultation of Aldebaran by a planet, Venus, will occur on 5366 August 27.\n\nFive faint stars are positioned so that they appear close to Aldebaran. These double stars were given alphabetic secondary star designations more or less in the order of their discovery, with the letter A reserved for the primary star. Some of the characteristics of these components, including their position relative to Aldebaran, are listed in the table at right.\n\nSome surveys have indicated that Alpha Tauri B may have about the same proper motion and parallax as Aldebaran and thus may be a physical binary system. However these measurements are difficult to make because the dim B component appears so close to the bright primary star. The resulting margin of error is too large to positively establish (or exclude) a physical relationship between the two stars. So far neither the B component, nor anything else, has been unambiguously shown to be physically associated with Aldebaran.\n\nAlpha Tauri CD is a binary system with the C and D component stars gravitationally bound to and co-orbiting each other. These co-orbiting stars have been shown to be located far beyond Aldebaran and are members of the Hyades star cluster. As with the rest of the stars in the cluster they do not physically interact with Aldebaran in any way.\n\nIn 1993, radial velocity measurements of Aldebaran, Arcturus and Pollux showed that Aldebaran exhibited a long-period radial velocity oscillation, which could be interpreted as a \"substellar companion\". The measurements for Aldebaran implied a companion with a minimum mass 11.4 times that of Jupiter in a 643-day orbit at a separation of in a mildly eccentric orbit. However, all three stars surveyed showed similar oscillations yielding similar companion masses, and the authors concluded that the variation was likely to be intrinsic to the star rather than due to the gravitational effect of a companion. In 2015 a study showed stable longterm evidence for both a planetary companion and stellar activity.\n\n", "id": "3077", "title": "Aldebaran"}
{"url": "https://en.wikipedia.org/wiki?curid=3078", "text": "Altair\n\nAltair (), also designated Alpha Aquilae (α Aquilae, abbreviated Alpha Aql, α Aql), is the brightest star in the constellation of Aquila and the twelfth brightest star in the night sky. It is currently in the G-cloud—a nearby accumulation of gas and dust known as an interstellar cloud. Altair is an A-type main sequence star with an apparent visual magnitude of 0.77 and is one of the vertices of the asterism known as the Summer Triangle (the other two vertices are marked by Deneb and Vega). It is 16.7 light-years (5.13 parsecs) from the Sun and is one of the closest stars visible to the naked eye.\n\nAltair rotates rapidly, with a velocity at the equator of approximately 286 km/s. This is a significant fraction of the star's estimated breakup speed of 400 km/s. A study with the Palomar Testbed Interferometer revealed that Altair is not spherical, but is flattened at the poles due to its high rate of rotation. Other interferometric studies with multiple telescopes, operating in the infrared, have imaged and confirmed this phenomenon.\n\n\"α Aquilae\" (Latinised to \"Alpha Aquilae\") is the star's Bayer designation. The traditional name \"Altair\" has been used since medieval times. It is an abbreviation of the Arabic phrase , \"al-nesr al-ṭā’ir\" (\"\"). In 2016, the International Astronomical Union organized a Working Group on Star Names (WGSN) to catalog and standardize proper names for stars. The WGSN's first bulletin of July 2016 included a table of the first two batches of names approved by the WGSN; which included \"Altair\" for this star. It is now so entered in the IAU Catalog of Star Names.\n\nAlong with Beta Aquilae and Gamma Aquilae, Altair forms the well-known line of stars sometimes referred to as the \"Family of Aquila\" or \"Shaft of Aquila\".\n\nAltair is a type-A main sequence star with approximately 1.8 times the mass of the Sun and 11 times its luminosity. Altair possesses an extremely rapid rate of rotation; it has a rotational period of approximately 9 hours. For comparison, the equator of the Sun requires a little more than 25 days for a complete rotation. This rapid rotation forces Altair to be oblate; its equatorial diameter is over 20 percent greater than its polar diameter.\n\nSatellite measurements made in 1999 with the Wide Field Infrared Explorer showed that the brightness of Altair fluctuates slightly, varying by just a few thousandths of a magnitude with several different periods less than 2 hours. As a result, it was identified in 2005 as a Delta Scuti variable star. Its light curve can be approximated by adding together a number of sine waves, with periods that range between 0.8 and 1.5 hours. It is a weak source of coronal X-ray emission, with the most active sources of emission being located near the star's equator. This activity may be due to convection cells forming at the cooler equator.\n\nThe angular diameter of Altair was measured interferometrically by R. Hanbury Brown and his co-workers at Narrabri Observatory in the 1960s. They found a diameter of 3milliarcseconds. Although Hanbury Brown et al. realized that Altair would be rotationally flattened, they had insufficient data to experimentally observe its oblateness. Altair was later observed to be flattened by infrared interferometric measurements made by the Palomar Testbed Interferometer in 1999 and 2000. This work was published by G. T. van Belle, David R. Ciardi and their co-authors in 2001.\n\nTheory predicts that, owing to Altair's rapid rotation, its surface gravity and effective temperature should be lower at the equator, making the equator less luminous than the poles. This phenomenon, known as gravity darkening or the von Zeipel effect, was confirmed for Altair by measurements made by the Navy Prototype Optical Interferometer in 2001, and analyzed by Ohishi et al. (2004) and Peterson et al. (2006). Also, A. Domiciano de Souza et al. (2005) verified gravity darkening using the measurements made by the Palomar and Navy interferometers, together with new measurements made by the VINCI instrument at the VLTI.\n\nAltair is one of the few stars for which a direct image has been obtained. In 2006 and 2007, J. D. Monnier and his coworkers produced an image of Altair's surface from 2006 infrared observations made with the MIRC instrument on the CHARA array interferometer; this was the first time the surface of any main-sequence star, apart from the Sun, had been imaged. The false-color image was published in 2007. The equatorial radius of the star was estimated to be 2.03 solar radii, and the polar radius 1.63 solar radii—a 25% increase of the stellar radius from pole to equator. The polar axis is inclined by about 60° to the line of sight from the Earth.\n\nThe term \"Al Nesr Al Tair\" appeared in Al Achsasi al Mouakket's catalogue, which was translated into Latin as \"Vultur Volans\". This name was applied by the Arabs to the asterism of α, β, and γ Aquilae and probably goes back to the ancient Babylonians and Sumerians, who called α Aquilae the eagle star. The spelling \"Atair\" has also been used. Medieval astrolabes of England and Western Europe depicted Altair and Vega as birds.\n\nThe Koori people of Victoria also knew Altair as \"Bunjil\", the wedge-tailed eagle, and β and γ Aquilae are his two wives the black swans. The people of the Murray River knew the star as \"Totyerguil\". The Murray River was formed when \"Totyerguil\" the hunter speared \"Otjout\", a giant Murray cod, who, when wounded, churned a channel across southern Australia before entering the sky as the constellation Delphinus.\n\nIn Chinese, the asterism consisting of α, β, and γ Aquilae is known as \"Hé Gǔ\" (; lit. \"river drum\"). Altair is thus known as \"Hé Gǔ èr\" (; lit. \"river drum two\", meaning the \"second star of the drum at the river\"). However, Altair is better known by its other names: \"Qiān Niú Xīng\" () or \"Niú Láng Xīng\" (), translated as the \"cowherd star\". These names are an allusion to a love story, \"The Weaver Girl and the Cowherd\", in which Niulang (represented by Altair) and his two children (represented by β and γ Aquilae) are separated from respectively their wife and mother Zhinu (represented by Vega) by the Milky Way. They are only permitted to meet once a year, when magpies form a bridge to allow them to cross the Milky Way.\n\nThe people of Micronesia called Altair as \"Mai-lapa\", \"big/old breadfruit\", while the Māori people called this star as \"Poutu-te-rangi\", \"pillar of heaven\".\n\nIn Western astrology, the star Altair was ill-omened, portending danger from reptiles.\n\nJapan Airlines's Starjet 777-200 JA8983 was named Altair.\n\nAltair Airlines was a regional airline that operated out of Philadelphia from 1966 to 1982.\n\nThe NASA Constellation Program announced \"Altair\" as the name of the Lunar Surface Access Module (LSAM) on December 13, 2007. The Russian-made Beriev Be-200 Altair seaplane is also named after the star.\n\nThe Altair 8800 was one of the first microcomputers intended for home use.\n\nAltair is the name of three United States navy ships: , and USNS Altair (T-AKR-291).\n\n\"Altair\" is the name of a 1919 poem by Karle Wilson Baker. \nThe bright primary star has the multiple star designation WDS 19508+0852A and has three faint visual companion stars, WDS 19508+0852B, C, and D. Component B is not physically close to A but merely appears close to it in the sky.\n\n", "id": "3078", "title": "Altair"}
{"url": "https://en.wikipedia.org/wiki?curid=3079", "text": "Australian Broadcasting Corporation\n\nThe Australian Broadcasting Corporation (ABC) is Australia's national public broadcaster, owned and funded by the government. The ABC plays a leading role in the history of broadcasting in Australia. With a total annual budget of A$1.22 billion, the corporation provides television, radio, online and mobile services throughout metropolitan and regional Australia, as well as overseas through the Australia Network and Radio Australia.\n\nFounded in 1929 as the Australian Broadcasting Company, it was subsequently made a state-owned corporation on 1 July 1932 as the Australian Broadcasting Commission. The \"Australian Broadcasting Corporation Act 1983\" changed the name of the organisation to the Australian Broadcasting Corporation, effective 1 July 1983. Although funded and owned by the government, the ABC remains editorially independent as ensured through the \"Australian Broadcasting Corporation Act 1983\".\n\nThe ABC is sometimes informally referred to as \"Aunty\", originally in imitation of the British Broadcasting Corporation's nickname.\n\nThe first public radio station in Australia opened in Sydney on 23 November 1923 under the call sign 2SB with other stations in Melbourne, Brisbane, Adelaide, Perth and Hobart following. A licensing scheme, administered by the Postmaster-General's Department, was soon established allowing certain stations government funding, albeit with restrictions placed on their advertising content.\n\nFollowing a 1927 royal commission inquiry into radio licensing issues, the government established the National Broadcasting Service which subsequently took over a number of the larger funded stations. It also nationalised the Australian Broadcasting Company which had been created by entertainment interests to supply programs to various radio stations. On 1 July 1932, the Australian Broadcasting Commission was established, taking over the operations of the National Broadcasting Service and eventually establishing offices in each of Australia's capital cities.\nOver the next four years the stations were reformed into a cohesive broadcasting organisation through regular program relays, coordinated by a centralised bureaucracy. The Australian broadcast radio spectrum was constituted of the ABC and the commercial sector.\n\nIn 1942 \"The Australian Broadcasting Act\" was passed, giving the ABC the power to decide when, and in what circumstances, political speeches should be broadcast. Directions from the Minister about whether or not to broadcast any matter now had to be made in writing, and any exercise of the power had to be mentioned in the Commission's Annual Report. It was used only once, in 1963. In the same year, \"Kindergarten of the Air\" began on ABC Radio in Perth, and was later broadcast nationally.\n\nCater argues that reform was urgently needed in 1945:\n\nThe ABC commenced television broadcasting in 1956, and followed the earlier radio practice of naming the station after the first letter of the base state. ABN-2 (New South Wales) Sydney was inaugurated by Prime Minister Robert Menzies on 5 November 1956, with the first broadcast presented by Michael Charlton, and James Dibble reading the first television news bulletin. ABV-2 (Melbourne, Victoria) followed two weeks later, on 18 November 1956. Stations in other capital cities followed: ABQ-2 (Brisbane, Queensland) (1959), ABS-2 (Adelaide, South Australia) (1960), ABW-2 (Perth, Western Australia) (1960), and ABT-2 (Hobart, Tasmania) (1960). ABC-3 Canberra opened in 1961, and ABD-6 (Darwin, Northern Territories) started broadcasting in 1971, both named after the base city.\n\nAlthough radio programs could be distributed nationally by landline, television relay facilities were not in place until the early 1960s. This meant that news bulletins had to be sent to each capital city by teleprinter, to be prepared and presented separately in each city, with filmed materials copied manually and sent to each state. Other television programs at the time included the popular \"Six O'Clock Rock\" hosted by Johnny O'Keefe, \"Mr. Squiggle\", as well as operas and plays.\n\nIn 1973 New South Wales Rugby League boss Kevin Humphreys negotiated rugby league's first television deal with the ABC.\nIn 1975, colour television was introduced into Australia, and within a decade the ABC had moved into satellite broadcasting, greatly enhancing its ability to distribute content nationally. In the same year, the ABC introduced a 24-hour-a-day AM rock station in Sydney, 2JJ (Double Jay), which was eventually expanded into the national Triple J FM network. A year later, a national classical music network was established on the FM band, broadcasting from Adelaide. It was initially known as ABC-FM (now called ABC Classic FM) – referring both to its 'fine music' programming and radio frequency.\n\nABC budget cuts began in 1976 and continued until 1985. In 1978 the ABC NSW Staff Association organised a strike against budget cuts and political interference. Sydney ABC was off air for four days. A packed free concert in support was held at the Regent Theatre and compered by Bob Hudson. It featured Fred Dagg and Robyn Archer. In 1991, Tom Molomby wrote:\n\nThe \"Australian Broadcasting Corporation Act 1983\" changed the name of the organisation from the \"Australian Broadcasting Commission\" to the \"Australian Broadcasting Corporation\", effective 1 July 1983. At the same time, the newly formed Corporation underwent significant restructuring. The ABC was split into separate television and radio divisions, with an overhaul of management, finance, property and engineering. Geoffrey Whitehead was the initial managing director; however, following his resignation in 1986, David Hill (at the time chair of the ABC Board) took over his position.\n\nProgram production in indigenous affairs, comedy, social history and current affairs was significantly expanded, while the Corporation's output of drama was boosted. Local production trebled from 1986–91 with the assistance of co-production, co-financing, and pre-sales arrangements.\n\nA new Concert Music Department was formed in 1985 to co-ordinate the corporation's six symphony orchestras, which in turn received a greater level of autonomy to better respond to local needs. Open-air free concerts and tours, educational activities, and joint ventures with other music groups were undertaken at the time to expand the orchestras' audience reach.\n\nABC Radio was restructured significantly again in 1985 – Radio One became the Metropolitan network, while Radio 2 became known as Radio National (callsigns, however, were not standardised until 1990). New programs such as \"The World Today\", \"Australia All Over\", and \"The Coodabeen Champions\" were introduced, while ABC-FM established an Australian Music Unit in 1989. Radio Australia began to focus on the Asia-Pacific region, with coverage targeted at the south west and central Pacific, south-east Asia, and north Asia. Radio Australia also carried more news coverage, with special broadcasts during the 1987 Fijian coup, Tiananmen Square massacre, and the First Gulf War.\nIn 1991, the Corporation's Sydney radio and orchestral operations moved to a new building built by Leighton Holdings on a single site in the inner-city suburb of Ultimo. In Melbourne, the ABC Southbank Centre was completed in 1994, and now houses the radio division in Victoria as well as the Melbourne Symphony Orchestra.\n\nThe ABC Multimedia Unit was established in July 1995, to manage the new ABC website (launched in August). Funding was allocated later that year specifically for online content, as opposed to reliance on funding for television and radio content. The first online election coverage was put together in 1996, and included news, electorate maps, candidate information and live results.\n\nBy the early 1990s, all major ABC broadcasting outlets moved to 24-hour-a-day operation, while regional radio coverage in Australia was extended with 80 new transmitters. Live television broadcasts of selected parliamentary sessions started in 1990. ABC NewsRadio, a continuous news network broadcast on the Parliamentary and News Network when parliament is not sitting, was launched on 5 October 1994.\n\nInternational television service Australia Television International was established in 1993, while at the same time Radio Australia increased its international reach. Reduced funding in 1997 for Radio Australia resulted in staff and programming cuts.\n\n\"Australia Television\" was sold to the Seven Network in 1998, however the service continued to show ABC news and current affairs programming up until its closure in 2001. The ABC's television operation joined its radio and online divisions at the corporation's Ultimo headquarters in 2000.\n\nIn 2001, digital television commenced after four years of preparation. In readiness, the ABC had fully digitised its production, post-production and transmission facilities – heralded at the time as \"the greatest advance in television technology since the introduction of colour\". The first programmes to be produced in widescreen were drama series \"Something in the Air\", \"Grass Roots\" and \"In the Mind of the Architect\".\n\nAt the same time, the ABC's Multimedia division was renamed \"ABC New Media\", becoming an output division of the ABC alongside Television and Radio. Legislation allowed the ABC to provide 'multichannels' – additional, digital-only, television services managed by the New Media Division. Soon after the introduction of digital television in 2001, Fly TV and the ABC Kids channel launched, showing a mix of programming aimed at teenagers and children.\n\nIn 2002, the ABC launched ABC Asia Pacific – the replacement for the defunct Australia Television International operated previously by the Seven Network. Much like its predecessor, and companion radio network Radio Australia, the service provided a mix of programming targeted at audiences throughout the Asia-Pacific region. Funding cuts in 2003 led to the closure of Fly TV and the ABC Kids channel.\n\nThe ABC launched a digital radio service, ABC DiG, in November 2002, available though the internet and digital television, but not available through any other terrestrial broadcast until DAB+ became available in 2009.\nABC2, a second attempt at a digital-only television channel, launched on 7 March 2005. Unlike its predecessors the new service was not dependent on government funding, instead running on a budget of A$3 million per year. Minister for Communications Helen Coonan inaugurated the channel at Parliament House three days later. Genre restrictions limiting the types of programming the channel could carry were lifted in October 2006 – ABC2 was henceforth able to carry programming classified as comedy, drama, national news, sport and entertainment.\n\nA high incidence of breast cancer in female staff working at the ABC's offices in Brisbane led to the closure of the site, based in Toowong, on 21 December 2006. Sixteen women were diagnosed with the disease in a period spanning 1994 to 2007. A progress report released in March 2007 by an independent panel formed to investigate the occurrences found that the rate of occurrence for breast cancer rate at the offices was eleven times higher than elsewhere – after the closure of the site, the ABC's Brisbane-based television and radio operations were moved to alternate locations around the city, including Ten Brisbane's studios at Mt Coot-tha. The ABC's managing director, Mark Scott, announced in August 2007 that new studios would be built on the site, following the final release of the Review and Scientific Investigation Panel's report. In January 2012 the ABC in Brisbane moved into purpose-built accommodation in South Bank.\n\nOn 8 February 2008, ABC TV was rebranded as ABC1, complementing the existing ABC2 digital-only channel which was launched on 7 March 2005. Branding was also added for a new kids' channel that had been announced throughout the Howard Government based on their winning the 2007 election but left to the 2009 Rudd Government Budget where ABC3 was funded and announced in June. A new online video-on-demand service launched in July of the same year, titled ABC iview, and the ABC launched digital radio broadcasts in the same month.\n\nABC News 24 launched on 22 July 2010, and brought with it both new programming content as well as a collaboration of existing news and current affair productions and resources. The ABC launched the 24-hour news channel to both complement its existing 24-hour ABC News Radio service and compete with commercial offerings on cable TV. It became the ABC's fifth domestic TV channel and the fourth launched within the past 10 years.\n\nOn 20 July 2014, ABC1 was renamed back to its original name of ABC.\n\nIn 2014 the ABC ran its first \"Mental As\" week focusing on improving awareness of mental health issues, as part of Mental Health Week.\n\nIn December 2015 it was announced that former Google executive Michelle Guthrie would take over from managing director Mark Scott, who was to retire in April 2016.\n\nBelow is a diagram of the ABC's divisional structure.\n\nThe operations of the ABC are governed by a board of directors, consisting of a managing director, five to seven directors, and until 2006, a staff-elected director. The managing director is appointed by the board for a period of up to five years, but is eligible for renewal. The authority and guidelines for the appointment of directors is provided for in the \"Australian Broadcasting Corporation Act 1983\".\n\nAppointments to the ABC Board made by successive governments have often resulted in criticism of the appointees' political affiliation, background, and relative merit. Past appointments have associated directly with political parties – five of fourteen appointed chairmen have been accused of political affiliation or friendship, include Richard Downing and Ken Myer (both of whom publicly endorsed the Australian Labor Party at the 1972 election), as well as Sir Henry Bland. David Hill was close to Neville Wran, while Donald McDonald was considered to be a close friend of John Howard.\n\nFrom 2003 the Howard Government made several controversial appointments to the ABC Board, including prominent ABC critic Janet Albrechtsen, Ron Brunton, and Keith Windschuttle.\n\nDuring their 2007 federal election campaign, Labor announced plans to introduce a new system, similar to that of the BBC, for appointing members to the board. Under the new system, candidates for the ABC Board would be considered by an independent panel established \"at arm's length\" from the Communications Minister. If the Minister chose someone not on the panel's shortlist, they would be required to justify this to parliament. The ABC chairman would be nominated by the Prime Minister and endorsed by the Leader of the Opposition.\n\nThe new merit-based appointment system was announced on 16 October, in advance of the new triennial funding period starting in 2009.\n\nCurrent Board members are:\nThe ABC is funded mainly by the Australian government, in addition to some revenue received from its retail outlets. In the 2006–07 federal budget, the ABC received A$823 million of government funding, increased to $840 million in 2008–09. In the 2009–10 federal budget, the ABC received funding of $929.9 million.\n\nUntil 1948, the ABC was funded directly by radio licence fees; amendments were also made to the \"Australian Broadcasting Act\" that meant the ABC would receive its funding directly from the federal government. Licence fees remained until 1973 when they were abolished by the Whitlam Labor government, on the basis that the near-universality of television and radio services meant that public funding was a fairer method of providing revenue for government-owned radio and television broadcasters.\n\nThe term \"where your 8 cents a day goes\", coined in the late 1980s during funding negotiations, is often used in reference to the services provided by the ABC. It is estimated that the cost of the ABC per head of population per day was 7.1 cents a day, based on the Corporation's 2007–08 'base funding' of $543 million. Budget figures above show the ABC costs over 14 cents per day today.\n\nThe Australian Communications Minister, Senator Stephen Conroy indicated strong support from the Government for the ABC's funding submission for the 2009/10 budget, saying the organisation had been underfunded for many years.\n\nUnder the \"Australian Broadcasting Corporation Act 1983\", the ABC Board is bound to \"maintain the independence and integrity of the Corporation\" and to ensure that \"the gathering and presentation by the Corporation of news and information is accurate and impartial according to the recognized standards of objective journalism.\"\n\nIn relation to impartiality and diversity of perspectives, the current ABC editorial policy requires of the broadcaster that:\n\nAs a publicly funded broadcaster, the ABC is expected not to take editorial stances on political issues, and is required to present a range of views with impartiality. Over the decades, accusations of \"bias\" at the ABC have arisen at different times, and various inquiries undertaken.\n\nReviews of the ABC are regularly commissioned and sometimes not released. A 2004 Roy Morgan media credibility survey found that media professionals regarded ABC Radio as the most accurate news source in the country. In mid 2013 the University of the Sunshine Coast released a study of the professional views of journalists. Slightly over half of respondents expected to vote for either Labor or The Greens whereas just under a third planned to vote Coalition. In contrast over 40% of ABC journalists would vote for The Greens and almost a third Labor. \nDr Rhonda Jolly's 2014 ABC Overview noted that \"many commentators have argued consistently that there is a left wing bias which dominates ABC news and programming\" and cited a 2005 piece by Paul Gray that the broadcaster was overly influenced by the \"narrow middle-class values of the Australian secular Left\" and said that \"while the national broadcaster had at times offended governments of all persuasions, it had always adopted a 'from the Left' perspective.\" Jolly also noted however that supporters of the ABC \"deny claims that the broadcaster is either intentionally or inadvertently biased\" and that \"Speaking from opposition, politicians have praised the ABC for its scrutiny of government.\" The paper noted that, in December 2013, ABC chairman James Spigelman called four independent audits a year in response to the frequent allegations of lack of impartiality in news and current affairs.\n\nThe conservative Liberal Party governments in the 1960s and 1970s attempted to influence the ABC's political coverage by threatening to reduce funding for its news and current affairs division,\n\nThe Hawke Labor government unsuccessfully proposed to merge it with the Special Broadcasting Service (SBS).\n\nBob Hawke criticised some of the 7.30 Report's coverage of the 1991 Gulf War to which he committed naval forces as being \"loaded\", \"biased\" and \"disgraceful\".\n\nFor much of the Howard Government years, ABC TV's masthead political programs were anchored by Labor affiliated journalists Kerry O'Brien, Barrie Cassidy and Maxine McKew. \"7.30 Report\" and \"Insiders\" were hosted by former Labor staffers Kerry O'Brien and Barrie Cassidy respectively, while the 2007 election saw \"Lateline\" host McKew defeat Liberal Prime Minister John Howard as the Labor candidate for the seat of Bennelong. At that same election, Liberal front bencher Joe Hockey was challenged unsuccessfully by ABC Sydney News weatherman turned Labor candidate Mike Bailey in the Seat of North Sydney.\n\nOf the 1996 prime ministerial Election debates between Opposition Leader John Howard and Labor Prime Minister Paul Keating, Howard later wrote: \"I flatly refused to have Kerry O'Brien of the ABC [moderate the debates] because of the way he had handled the second Keating-Hewson debate in 1993\" in which O'Brien \"went in to bat\" for Keating. Howard went on to win that election. A decade later, the ABC Media Watch program reported that NSW Liberal Senator Concetta Fierravanti-Wells had written to her constituents to say that the ABC had \"a collective loathing\" of John Howard. At the end of the Howard Government's term in 2007, left-wing political commentator Robert Manne wrote in \"The Monthly\" that the Howard Government had viewed the broadcaster as being run by \"left-wing ideologues\" who had \"supposedly pushed the agenda of the Left on issues like refugees, the republic, multiculturalism, reconciliation, radical feminism, extreme environmentalism, anti-Americanism, gay rights and so on.\"\n\nSoon after coming to office in 1996, the Howard Government reduced the ABC's operating grants by 10%. Its appointment of Jonathan Shier to the position of managing director was controversial, for his program of budget cuts, restructuring and the loss of several high-profile personalities and shows. Shier left the position early, on 31 October 2001. \"7.30 Report\" anchor Kerry O'Brien opposed Howard's budget cuts to the ABC, and describes the appointment of Shier as its Managing Director as a manifestation of the \"conservative obsession with the ABC as a kind of biased, left-wing culture\".\n\nIn Howard's last election, he was defeated in the Seat of Bennelong by Labor candidate Maxine McKew, who had hosted \"Lateline\" during the Howard era. Peter Mares reported for Radio National that \"some wags described it as an 'internal promotion', while others said she'd simply moved from the 'media wing' to the 'political wing' of the ALP\". Mares consulted ABC journalist turned NSW Liberal MLA Pru Goward who said: \" I have no doubt there was left-wing bias, I certainly thought it when I was there\", while McKew said there was no left wing bias, though \"what I detected years ago in the ABC, much more of a collectivist philosophy\".\n\nConservative commentators such as Andrew Bolt, Tim Blair and Gerard Henderson accused the ABC of a left-wing bias.\n\nLiberal Prime Minister Tony Abbott perceived the ABC to be left wing and hostile to his government, while his successor Malcolm Turnbull enjoyed better relations with the National Broadcaster. When the ABC co-operated with \"The Guardian\" to publish stolen documents purporting to reveal monitoring of Indonesian officials by Australian spy agencies under the Rudd Government, Abbott told 2GB radio: \"A lot of people feel at the moment that the ABC instinctively takes everyone's side but Australia's\". Abbott reportedly called the \"Q&A\" program a \"Lefty Lynch Mob\". When it invited a man convicted of threatening Commonwealth officials to participate in questioning one of his ministers amid a heightened terrorism alert in June 2015, Abbott asks the makers of the program: \"whose side are you on?\". The ABC found that there had been an \"error of judgement', but repeated the program later in the week, prompting Abbott to say that \"heads should roll\" over the affair. Abbott initiated a brief ministerial boycott of the \"Q&A\" program following the affair. \n\nThe broadcaster was critical of Abbott when he broke an election-eve promise not to make cuts to the ABC, and required 4.6% cuts over five years as part of his \"Budget repair\" program. In early 2015, an internal ABC review of its coverage of Joe Hockey's first Budget criticised the post-budget interviews by \"7:30\" and \"Lateline\", finding that the interviewers had given the impression of bias. \n\nWhen Abbott lost the leadership to Turnbull in the September 2015 Liberal leadership spill, the hosts of the ABC's political programs spoke in favour of Abbott's demise. Kerry O'Brien and Barrie Cassidy, hosts respectively of the ABC's flagship weekly current affairs programs \"Four Corners\" and \"Insiders\", welcomed the replacement of Abbott by Turnbull, as did ABC radio commentators Fran Kelly Paul Bongiorno and Amanda Vanstone. Fairfax and News Limited reported that Leigh Sales, the host of \"7.30\" gave Turnbull an unusually warm first interview following his toppling of Abbott.\n\nIn a March 2016 interview with ABC Managing Director Mark Scott, \"Media Watch\" host Paul Barry examined the question of perceptions of left wing bias at the ABC. Scott noted that while perhaps the ABC was more concerned about gay marriage than about electricity prices, he did not accept the criticism of bias because \"a lot of that criticism comes from right wing commentators and they wonder where are the strong right wing commentators on the ABC. We don’t do that kind of journalism. We don’t ask questions about our journalists’ voting pattern and where their ideology are. We look at the journalism that they put to air and we have strong editorial standards...\" Following the interview, conservative ABC critic Andrew Bolt wrote \"How can the man heading our biggest media organisation be so blind to the ABC's unlawful and dangerous Leftist bias?\" while former \"Media Watch\" host Jonathan Holmes wrote for \"The Age\" that this interview indicated that ABC management had failed to recognise a clear problem of left wing bias among some capital city radio presenters.\n\nA number of former journalists and presenters have moved from positions at the ABC to politics.\n\nState Labor premiers and chief ministers Bob Carr,\nAlan Carpenter,\nand Clare Martin are all former ABC journalists. Other ABC Labor politicians include Mary Delahunty, Maxine McKew, Mike Bailey, Ian Baker, Leon Bignell, John Bowler, Bob Debus, Malarndirri McCarthy, Frank McGuire, Neville Oliver and Diana Warnock. Senior ABC political reporter Kerry O'Brien was press secretary to Labor prime minister Gough Whitlam and Labor deputy leader Lionel Bowen and Barrie Cassidy was press secretary to Labor prime minister Bob Hawke. Radio National's Phillip Adams is a former member of the Communist Party of Australia and the Labor Party, and Melbourne ABC radio's Jon Faine is a former member of the Labor Party.\n\nOn the Coalition side of politics, Pru Goward has served as a Minister in the NSW state Liberal Government, Rob Messenger, Peter Collins, Eoin Cameron, Scott Emerson and Sarah Henderson all held, or hold, positions at the ABC. Radio National's \"Counterpoint\" program is hosted by former Liberal minister Amanda Vanstone, who describes herself as \"liberal\" rather than \"conservative\".\n\nResearch undertaken by the broadcaster in 2007 indicated that out of a total of 19 former employees moving into party political positions, 10 have joined the Labor Party and nine the Liberal Party.\n\nThe ABC operates 54 local radio stations, in addition to four national networks and international service Radio Australia. In addition, DiG Radio launched on digital platforms in 2002, currently offering three separate stations.\n\nABC Local Radio is the Corporation's flagship radio station in each broadcast area. There are 54 individual stations, each with a similar format consisting of locally presented light entertainment, news, talk back, music, sport and interviews, in addition to some national programming such as \"AM\", \"PM\", \"The World Today\", sporting events and \"Nightlife\".\n\nABC Radio National broadcasts more than 60 special interest programmes per week covering a range of topics including music, comedy, book readings, radio dramas, poetry, science, health, the arts, religion, social history and current affairs.\n\nABC NewsRadio is a rolling news service, previously known as the Parliamentary and News Network. The service was established to broadcast federal parliamentary sittings, to relieve the local ABC radio network from this intermittent task, and to provide a news service at other times. The network broadcasts news on a 24/7 format with updates on the quarter-hour. Much of its news content is produced by the ABC itself, however many programmes are relayed from the BBC World Service, NPR, Deutsche Welle, Radio Netherlands and CNN Radio.\n\nABC Classic FM was the ABC's first FM radio service. It was originally known simply as \"ABC FM\", and for a short time \"ABC Fine Music\". Its format borrowed heavily from community stations that eventually founded the Fine Music Network, as well as BBC Radio 3.\n\nTriple J is the national youth radio network, and broadcasts contemporary alternative and independent music; it is targeted at people aged 18–35. While the network plays music from around the world, it has a strong focus on local artists. Triple J was formerly known as \"Double Jay\" when it launched in Sydney on 19 January 1975.\n\nABC Radio broadcasts regular news bulletins across most of its radio stations. Many of these bulletins are heralded by the \"Majestic Fanfare\", written by British composer Charles Williams in 1935.\n\nWithin Australia, the ABC operates four channels. ABC, the Corporation's original television service, receives the bulk of funding for television and shows first-run comedy, drama, documentaries, and news and current affairs. In each state and territory a local news bulletin is shown at 7.00 p.m. nightly.\n\nIn 2001 ABC TV launched its digital service.\n\nABC2, launched in 2005, is a digital-only channel that shows repeated programmes from ABC, as well as some original content including news programmes, children's shows, animation, and music shows.\n\nIn September 2007, the Australian government announced a proposal to launch a new digital-only children's channel, to be named ABC3. An ABC3 channel appeared on television receivers in 2008, as a place holder for the future ABC3 channel. ABC3 was considered by the Australia 2020 Summit and given as one of the recommendations to the Government. In April 2009, the Government's official response to the Summit approved the idea, and in the 2009–10 Commonwealth Budget $67 million was allocated towards ABC3 as part of the Government's $167 million funding increase to the ABC. The channel launched in December 2009. In September 2016 ABC3 was rebranded ABC Me. The rebranded channel is reported to be \"designed to reflect and celebrate the lives, interests and diversity of young Australians\" and will increase its focus to primary school children.\n\nIn January 2010, the ABC announced its intention to launch Australia's first free-to-air news dedicated channel. ABC News 24 replaced the former ABC High Definition simulcast of ABC1 and commenced broadcasting at 7:30 pm (AEST) 5:30 (AWST) on Thursday, 22 July 2010.\n\nOn 6 December 2016, ABC upgraded its HD format from 720p to 1080i.\n\nAn experimental Multimedia Unit was established in 1995, charged with developing policy for the ABC's work in web publishing. This unit continued until 2000, when the New Media division was formed, bringing together the ABC's online output as a division similar to Television or Radio. The division had over a million pages of material published by late 2003.\n\nIn 2001 the New Media division became New Media and Digital Services, reflecting the broader remit to develop content for digital platforms such as digital television. In addition to ABC Online, the division also had responsibility over the ABC's two digital television services, Fly TV and the ABC Kids channel, until their closure in 2003. In March 2005 the division oversaw the launch of ABC2, a free-to-air digital television channel, in effect a replacement for ABC Kids and Fly.\n\nIn conjunction with the ABC's radio division, New Media and Digital Services implemented the ABC's first podcasts in December 2004. By mid-2006 the ABC had become an international leader in podcasting with over fifty podcast programmes delivering hundreds of thousands of downloads per week, including trial video podcasts of The Chaser's War on Everything and jtv.\n\nIn February 2007, the New Media & Digital Services division was dissolved and divided up amongst other areas of the ABC. It was replaced by a new Innovation division, to manage ABC Online and investigate new technologies for the ABC.\nIn 2015 the Innovation division was replaced with the Digital Network division.\n\nAustralia Network, formerly ABC Asia Pacific, is an international satellite television service operated by the Australian Broadcasting Corporation, funded by advertising and grants from the Department of Foreign Affairs and Trade. Aimed at the Asia-Pacific region, the service broadcasts a mixture of English language programming, including general entertainment, sport, and current affairs.\n\nABC Radio Australia is an international shortwave, satellite and internet radio service with transmissions aimed at East Asia and the Pacific Islands, although its signals are also audible in many other parts of the world. It features programmes in various languages spoken in these regions, including Mandarin, Indonesian, Vietnamese, Khmer and Tok Pisin.\n\nRadio Australia bulletins are also carried on WRN Broadcast, available via satellite in Europe and North America.\n\nABC Commercial is the division of the ABC responsible for pursuing new sources of revenue for the Corporation. It is composed of ABC Retail, ABC Consumer Publishing and Content Sales, as well as ABC Resource Hire. ABC retail outlets were established in 1974. All profits from the sale of consumer product and production services return to the Corporation to reinvest in programme-making.\n\nUp until the installation of disc recording equipment in 1935, all content broadcast on the ABC was produced live, including music. For this purpose, the ABC established broadcasting orchestras in each state, and in some centres also employed choruses and dance bands. This became known as the ABC Concert Music Division, which was controlled by the Federal Director of Music – the first of whom was W. G. James.\n\nThere are currently six state symphony orchestras:\n\nThe orchestras were corporatised in the 1990s, and were divested into independent companies on 1 January 2007.\n\nThe ABC logo is one of the most recognisable logos in Australia. In the early years of television, the ABC had been using Lissajous curves as fillers between programmes. In July 1963, the ABC conducted a staff competition to create a new logo for use on television, stationery, publications, microphone badges and ABC vehicles. In 1965, ABC graphics designer Bill Kennard, who had been experimenting with telerecording of the cathode ray oscilloscope displays, submitted a design which was part of the waveform from an oscilloscope. The letters \"ABC\" were added to the design and it was adopted as the ABC's official logo. Kennard was presented with £25 for his design.\n\nSince its original introduction in 1965, it has been updated several times, including with the introduction of colour television in 1975. The line was thickened to feature colour in the logo. The 1975 logo is the longest-running logo, with a lifespan of 27 years. In 2001, with the introduction of digital television in Australia, ABC Television adopted a modified version of the logo, featuring a silver 3D look and losing the \"over and under\" design. However, despite the launch of this logo, the 1975 logo is still used by the corporation. In July 2002, to celebrate the ABC's 70th anniversary, the corporation adopted a new logo across all media. This new logo still used the silver 3D colour but reverted to its \"over and under\" design. In 2014, as part of ABC1's renaming back into \"ABC TV\", the 1975 logo was brought back to on-air presentation. Despite this, the 2002 silver logo remains in usage by the corporation.\n\n\n\n", "id": "3079", "title": "Australian Broadcasting Corporation"}
{"url": "https://en.wikipedia.org/wiki?curid=3080", "text": "Alexandria\n\nAlexandria ( or ; Arabic: '; '; \"\") is the second largest city and a major economic centre in Egypt, extending about along the coast of the Mediterranean Sea in the north central part of the country. Its low elevation on the Nile delta makes it highly vulnerable to rising sea levels. Alexandria is Egypt's largest seaport, serving approximately 80% of Egypt's imports and exports. It is an important industrial center because of its natural gas and oil pipelines from Suez. Alexandria is also an important tourist destination.\n\nAlexandria was founded around a small Ancient Egyptian town \"c.\" 331 BC by Alexander the Great. It became an important center of the Hellenistic civilization and remained the capital of Hellenistic and Roman and Byzantine Egypt for almost 1000 years until the Muslim conquest of Egypt in AD 641, when a new capital was founded at Fustat (later absorbed into Cairo). Hellenistic Alexandria was best known for the Lighthouse of Alexandria (\"Pharos\"), one of the Seven Wonders of the Ancient World; its Great Library (the largest in the ancient world; now replaced by a modern one); and the Necropolis, one of the Seven Wonders of the Middle Ages. Alexandria was the second most powerful city of the ancient world after Rome. Ongoing maritime archaeology in the harbor of Alexandria, which began in 1994, is revealing details of Alexandria both before the arrival of Alexander, when a city named Rhacotis existed there, and during the Ptolemaic dynasty.\n\nFrom the late 18th century, Alexandria became a major center of the international shipping industry and one of the most important trading centers in the world, both because it profited from the easy overland connection between the Mediterranean Sea and the Red Sea, and the lucrative trade in Egyptian cotton.\n\nAlexandria is believed to have been founded by Alexander the Great in April 331 BC as (\"Alexandria\"). Alexander's chief architect for the project was Dinocrates. Alexandria was intended to supersede Naucratis as a Hellenistic center in Egypt, and to be the link between Greece and the rich Nile valley. However, more recent radiocarbon dating of seashell fragments and lead contamination predate this claim by two millennia \n\nAlexandria was the intellectual and cultural center of the ancient world for some time. The city and its museum attracted many of the greatest scholars, including Greeks, Jews and Syrians. The city was later plundered and lost its significance.\n\nJust east of Alexandria (where Abu Qir Bay is now), there was in ancient times marshland and several islands. As early as the 7th century BC, there existed important port cities of Canopus and Heracleion. The latter was recently rediscovered under water.\n\nAn Egyptian city, Rhakotis, already existed on the shore also, and later gave its name to Alexandria in the Egyptian language (Egyptian *Raˁ-Ḳāṭit, written \"rˁ-ḳṭy.t\", 'That which is built up'). It continued to exist as the Egyptian quarter of the city. A few months after the foundation, Alexander left Egypt and never returned to his city. After Alexander's departure, his viceroy, Cleomenes, continued the expansion. Following a struggle with the other successors of Alexander, his general Ptolemy succeeded in bringing Alexander's body to Alexandria, though it was eventually lost after being separated from its burial site there.\n\nAlthough Cleomenes was mainly in charge of overseeing Alexandria's continuous development, the \"Heptastadion\" and the mainland quarters seem to have been primarily Ptolemaic work. Inheriting the trade of ruined Tyre and becoming the center of the new commerce between Europe and the Arabian and Indian East, the city grew in less than a generation to be larger than Carthage. In a century, Alexandria had become the largest city in the world and, for some centuries more, was second only to Rome. It became Egypt's main Greek city, with Greek people from diverse backgrounds.\n\nAlexandria was not only a center of Hellenism, but was also home to the largest urban Jewish community in the world. The Septuagint, a Greek version of the Tanakh, was produced there. The early Ptolemies kept it in order and fostered the development of its museum into the leading Hellenistic center of learning (Library of Alexandria), but were careful to maintain the distinction of its population's three largest ethnicities: Greek, Jewish, and Egyptian.\n\nIn AD 115, large parts of Alexandria were destroyed during the Kitos War, which gave Hadrian and his architect, Decriannus, an opportunity to rebuild it. In 215, the emperor Caracalla visited the city and, because of some insulting satires that the inhabitants had directed at him, abruptly commanded his troops to put to death all youths capable of bearing arms. On 21 July 365, Alexandria was devastated by a tsunami (365 Crete earthquake), an event annually commemorated years later as a \"day of horror.\"\n\nThe Islamic prophet, Muhammad's first interaction with the people of Egypt occurred in 628, during the Expedition of Zaid ibn Haritha (Hisma). He sent Hatib bin Abi Baltaeh with a letter to the king of Egypt (in reality Emperor Heraclius) and Alexandria called Muqawqis In the letter Muhammad said: \"I invite you to accept Islam, Allah the sublime, shall reward you doubly. But if you refuse to do so, you will bear the burden of the transgression of all the Copts\". During this expedition one of Muhammad's envoys Dihyah bin Khalifa Kalbi was attacked, Muhammad sent Zayd ibn Haritha to help him. Dihya approached the Banu Dubayb (a tribe which converted to Islam and had good relations with Muslims) for help. When the news reached Muhammad, he immediately dispatched Zayd ibn Haritha with 500 men to battle. The Muslim army fought with Banu Judham, killed several of them (inflicting heavy casualties), including their chief, Al-Hunayd ibn Arid and his son, and captured 1000 camels, 5000 of their cattle and 100 women and boys. The new chief of the Banu Judham who had embraced Islam appealed to Muhammad to release his fellow tribesmen, and Muhammad released them.\n\nIn 619, Alexandria fell to the Sassanid Persians. Although the Byzantine Emperor Heraclius recovered it in 629, in 641 the Arabs under the general 'Amr ibn al-'As captured it during the Muslim conquest of Egypt, after a siege that lasted 14 months.\n\nAfter the Battle of Ridaniya in 1517, the city was conquered by the Ottoman Turks and remained under Ottoman rule until 1798. Alexandria lost much of its former importance to the Egyptian port city of Rosetta during the 9th to 18th centuries, and only regained its former prominence with the construction of the Mahmoudiyah Canal in 1807.\n\nAlexandria figured prominently in the military operations of Napoleon's expedition to Egypt in 1798. French troops stormed the city on 2 July 1798, and it remained in their hands until the arrival of a British expedition in 1801. The British won a considerable victory over the French at the Battle of Alexandria on 21 March 1801, following which they besieged the city, which fell to them on 2 September 1801. Muhammad Ali, the Ottoman governor of Egypt, began rebuilding and redevelopment around 1810, and by 1850, Alexandria had returned to something akin to its former glory. Egypt turned to Europe in their effort to modernize the country. Greeks, followed by other Europeans and others, began moving to the city. In the early 20th century, the city became a home for novelists and poets.\n\nIn July 1882, the city came under bombardment from British naval forces and was occupied.\n\nIn July 1954, the city was a target of an Israeli bombing campaign that later became known as the Lavon Affair. On 26 October 1954, Alexandria's Mansheya Square was the site of a failed assassination attempt on Gamal Abdel Nasser.\n\nEuropeans began leaving Alexandria following the 1956 Suez Crisis that led to an outburst of Arab nationalism. The nationalization of property by Nasser, which reached its highest point in 1961, drove out nearly all the rest.\n\nThe most important battles and sieges of Alexandria include:\n\nGreek Alexandria was divided into three regions:\nTwo main streets, lined with colonnades and said to have been each about wide, intersected in the center of the city, close to the point where the Sema (or Soma) of Alexander (his Mausoleum) rose. This point is very near the present mosque of Nebi Daniel; and the line of the great East–West \"Canopic\" street, only slightly diverged from that of the modern Boulevard de Rosette (now Sharia Fouad). Traces of its pavement and canal have been found near the Rosetta Gate, but remnants of streets and canals were exposed in 1899 by German excavators outside the east fortifications, which lie well within the area of the ancient city.\n\nAlexandria consisted originally of little more than the island of Pharos, which was joined to the mainland by a mole and called the \"Heptastadion\" (\"seven stadia\"—a \"stadium\" was a Greek unit of length measuring approximately ). The end of this abutted on the land at the head of the present Grand Square, where the \"Moon Gate\" rose. All that now lies between that point and the modern \"Ras al-Tin\" quarter is built on the silt which gradually widened and obliterated this mole. The Ras al-Tin quarter represents all that is left of the island of Pharos, the site of the actual lighthouse having been weathered away by the sea. On the east of the mole was the Great Harbor, now an open bay; on the west lay the port of Eunostos, with its inner basin Kibotos, now vastly enlarged to form the modern harbor.\n\nIn Strabo's time, (latter half of the 1st century BC) the principal buildings were as follows, enumerated as they were to be seen from a ship entering the Great Harbor.\n\n\nThe names of a few other public buildings on the mainland are known, but there is little information as to their actual position. None, however, are as famous as the building that stood on the eastern point of Pharos island. There, The Great Lighthouse, one of the Seven Wonders of the World, reputed to be high, was situated. The first Ptolemy began the project, and the second Ptolemy (Ptolemy II Philadelphus) completed it, at a total cost of 800 talents. It took 12 years to complete and served as a prototype for all later lighthouses in the world. The light was produced by a furnace at the top and the tower was built mostly with solid blocks of limestone. The Pharos lighthouse was destroyed by an earthquake in the 14th century, making it the second longest surviving ancient wonder, after the Great Pyramid of Giza. A temple of Hephaestus also stood on Pharos at the head of the mole.\n\nIn the 1st century, the population of Alexandria contained over 180,000 adult male citizens, according to a census dated from 32 CE, in addition to a large number of freedmen, women, children and slaves. Estimates of the total population range from 216,000 to 500,000 to over 1,000,000, making it one of the largest cities ever built before the Industrial Revolution and the largest pre-industrial city that was not an imperial capital.\n\nAlexandria is located in the country of Egypt, on the southern coast of the Mediterranean.\n\nAlexandria has a borderline hot desert climate (Köppen climate classification: BWh), approaching a hot semi-arid climate (BSh). As the rest of Egypt's northern coast, the prevailing north wind, blowing across the Mediterranean, gives the city a less severe climate from the desert hinterland. Rafah and Alexandria are the wettest places in Egypt, the other wettest places are Rosetta, Baltim, Kafr el-Dawwar and Mersa Matruh. The city's climate is influenced by the Mediterranean Sea, moderating its temperatures, causing variable rainy winters and moderately hot summers that, at times, can be very humid; January and February are the coolest months, with daily maximum temperatures typically ranging from and minimum temperatures that could reach . Alexandria experiences violent storms, rain and sometimes snow, sleet and hail during the cooler months; these events, combined with a poor drainage system, have been responsible for occasional flooding in the city. July and August are the hottest and driest months of the year, with an average daily maximum temperature of .\nThe average annual rainfall is around but has been as high as \n\nPort Said, Kosseir, Baltim, Damietta and Alexandria have the least temperature variation in Egypt.\n\nThe highest recorded temperature was on May 30, 1961 and the coldest recorded temperature was on January 31, 1994.\n\nDue to the constant presence of war in Alexandria in ancient times, very little of the ancient city has survived into the present day. Much of the royal and civic quarters sank beneath the harbour due to earthquake subsidence in AD 365, and the rest has been built over in modern times.\n\"Pompey's Pillar\", a Roman triumphal column, is one of the best-known ancient monuments still standing in Alexandria today. It is located on Alexandria's ancient acropolis—a modest hill located adjacent to the city's Arab cemetery—and was originally part of a temple colonnade. Including its pedestal, it is 30 m (99 ft) high; the shaft is of polished red granite, in diameter at the base, tapering to at the top. The shaft is high, and made out of a single piece of granite. Its volume is and weight approximately 396 tons. Pompey's Pillar may have been erected using the same methods that were used to erect the ancient obelisks. The Romans had cranes but they were not strong enough to lift something this heavy. Roger Hopkins and Mark Lehrner conducted several obelisk erecting experiments including a successful attempt to erect a 25-ton obelisk in 1999. This followed two experiments to erect smaller obelisks and two failed attempts to erect a 25-ton obelisk. The structure was plundered and demolished in the 4th century when a bishop decreed that Paganism must be eradicated. \"Pompey's Pillar\" is a misnomer, as it has nothing to do with Pompey, having been erected in 293 for Diocletian, possibly in memory of the rebellion of Domitius Domitianus. Beneath the acropolis itself are the subterranean remains of the Serapeum, where the mysteries of the god Serapis were enacted, and whose carved wall niches are believed to have provided overflow storage space for the ancient Library. In more recent years, many ancient artifacts have been discovered from the surrounding sea, mostly pieces of old pottery.\n\nAlexandria's catacombs, known as \"Kom El Shoqafa\", are a short distance southwest of the pillar, consist of a multi-level labyrinth, reached via a large spiral staircase, and featuring dozens of chambers adorned with sculpted pillars, statues, and other syncretic Romano-Egyptian religious symbols, burial niches, and sarcophagi, as well as a large Roman-style banquet room, where memorial meals were conducted by relatives of the deceased. The catacombs were long forgotten by the citizens until they were discovered by accident in 1900.\n\nThe most extensive ancient excavation currently being conducted in Alexandria is known as Kom El Deka. It has revealed the ancient city's well-preserved theater, and the remains of its Roman-era baths.\n\nPersistent efforts have been made to explore the antiquities of Alexandria. Encouragement and help have been given by the local Archaeological Society, and by many individuals, notably Greeks proud of a city which is one of the glories of their national history. Excavations were performed in the city by Greeks seeking the tomb of Alexander the Great without success.\nThe past and present directors of the museum have been enabled from time to time to carry out systematic excavations whenever opportunity is offered; D. G. Hogarth made tentative researches on behalf of the Egypt Exploration Fund and the Society for the Promotion of Hellenic Studies in 1895; and a German expedition worked for two years (1898–1899). But two difficulties face the would-be excavator in Alexandria: lack of space for excavation and the underwater location of some areas of interest.\nSince the great and growing modern city stands immediately over the ancient one, it is almost impossible to find any considerable space in which to dig, except at enormous cost. Cleopatra VII's royal quarters were inundated by earthquakes and tsunami, leading to gradual subsidence in the 4th century AD. This underwater section, containing many of the most interesting sections of the Hellenistic city, including the palace quarter, was explored in 1992 and is still being extensively investigated by the French underwater archaeologist Franck Goddio and his team. It raised a noted head of Caesarion. These are being opened up to tourists, to some controversy. The spaces that are most open are the low grounds to northeast and southwest, where it is practically impossible to get below the Roman strata.\n\nThe most important results were those achieved by Dr. G. Botti, late director of the museum, in the neighborhood of “Pompey's Pillar”, where there is a good deal of open ground. Here, substructures of a large building or group of buildings have been exposed, which are perhaps part of the Serapeum. Nearby, immense catacombs and \"columbaria\" have been opened which may have been appendages of the temple. These contain one very remarkable vault with curious painted reliefs, now artificially lit and open to visitors.\n\nThe objects found in these researches are in the museum, the most notable being a great basalt bull, probably once an object of cult in the Serapeum. Other catacombs and tombs have been opened in Kom El Shoqafa (Roman) and Ras El Tin (painted).\n\nThe German excavation team found remains of a Ptolemaic colonnade and streets in the north-east of the city, but little else. Hogarth explored part of an immense brick structure under the mound of Kom El Deka, which may have been part of the Paneum, the Mausolea, or a Roman fortress.\n\nThe making of the new foreshore led to the dredging up of remains of the Patriarchal Church; and the foundations of modern buildings are seldom laid without some objects of antiquity being discovered. The wealth underground is doubtlessly immense; but despite all efforts, there is not much for antiquarians to see in Alexandria outside the museum and the neighborhood of “Pompey's Pillar”.\n\nThe temple was built in the Ptolemy era and dedicated to Osiris, which finished the construction of Alexandria. It is located in Abusir, the western suburb of Alexandria in Borg el Arab city. Only the outer wall and the pylons remain from the temple. There is evidence to prove that sacred animals were worshiped there. Archaeologists found an animal necropolis near the temple. Remains of a Christian church show that the temple was used as a church in later centuries. Also found in the same area are remains of public baths built by the emperor Justinian, a seawall, quays and a bridge. Near the beach side of the area, there are the remains of a tower built by Ptolemy II Philadelphus. The tower was an exact scale replica of the destroyed Alexandrine Pharos Lighthouse.\n\nThe most famous mosque in Alexandria is El-Mursi Abul Abbas Mosque in Bahary. Other notable mosques in the city include Ali ibn Abi Talib mosque in Somouha, Bilal mosque, al-Gamaa al-Bahari in Mandara, Hatem mosque in Somouha, Hoda el-Islam mosque in Sidi Bishr, al-Mowasah mosque in Hadara, Sharq al-Madina mosque in Miami, al-Shohadaa mosque in Mostafa Kamel, Al Qa'ed Ibrahim Mosque, Yehia mosque in Zizinia, Sidi Gaber mosque in Sidi Gaber, and Sultan mosque.\n\nAlexandria is the base of the Salafi movement's in Egypt. Al-Nour Party, which is based in the city and overwhelmingly won most of the Salafi votes in the 2011–12 parliamentary election, supports the president Abdel Fattah el-Sisi.\n\nAfter Rome and Constantinople, Alexandria was considered the third-most important seat of Christianity in the world. The Pope of Alexandria was second only to the bishop of Rome, the capital of the Roman Empire until 430. The Church of Alexandria had jurisdiction over most of the continent of Africa. After the Council of Chalcedon in AD 451, the Church of Alexandria was split between the Miaphysites and the Melkites. The Miaphysites went on to constitute what is known today as the Coptic Orthodox Church of Alexandria. The Melkites went on to constitute what is known today as the Greek Orthodox Church of Alexandria. In the 19th century, Catholic and Protestant missionaries converted some of the adherents of the Orthodox churches to their respective faiths.\n\nToday, the Patriarchal seat of the Pope of the Coptic Orthodox Church is Saint Mark Cathedral in Ramleh. The most important Coptic Orthodox churches in Alexandria include Pope Cyril I Church in Cleopatra, Saint Georges Church in Sporting, Saint Mark & Pope Peter I Church in Sidi Bishr, Saint Mary Church in Assafra, Saint Mary Church in Gianaclis, Saint Mina Church in Fleming, Saint Mina Church in Mandara and Saint Takla Haymanot's Church in Ibrahimeya.\n\nThe most important Eastern Orthodox churches in Alexandria are Agioi Anárgyroi Church, Church of the Annunciation, Saint Anthony Church, Archangels Gabriel & Michael Church, Taxiarchon Church, Saint Catherine Church, Cathedral of the Dormition in Mansheya, Church of the Dormition, Prophet Elijah Church, Saint George Church, Church of the Immaculate Conception in Ibrahemeya, Saint Joseph Church in Fleming, Saint Joseph of Arimathea Church, Saint Mark & Saint Nektarios Chapel in Ramleh, Saint Nicholas Church, Saint Paraskevi Church, Saint Sava Cathedral in Ramleh, Saint Theodore Chapel and the Russian church of Saint Alexander Nevsky in Alexandria, which serves the Russian speaking community in the city.\n\nThe Apostolic Vicariate of Alexandria in Egypt-Heliopolis-Port Said has jurisdiction over all Latin Church Catholics in Egypt. Member churches include Saint Catherine Church in Mansheya and Church of the Jesuits in Cleopatra. The city is also the nominal see of the Melkite Greek Catholic titular Patriarchate of Alexandria (generally vested in its leading Patriarch of Antioch) and the actual cathedral see of its Patriarchal territory of Egypt, Sudan and South Sudan, which uses the Byzantine Rite, and the nominal see of the Armenian Catholic diocese of Iskandkeriya (for all Egypt and Sudan, whose actual cathedral is in Cairo), a suffragan of the Armenian Catholic Patriarch of Cilicia, using the Armenian Rite.\n\nThe Saint Mark Church in Shatby, founded as part of Collège Saint Marc, is multi-denominational and holds liturgies according to Latin Catholic, Coptic Catholic and Coptic Orthodox rites.\n\nIn antiquity, Alexandria was a major center of the cosmopolitan religious movement called Gnosticism (today mainly remembered as a Christian heresy).\n\nAlexandria's once-flourishing Jewish community declined rapidly following the 1948 Arab–Israeli War, after which negative reactions towards Zionism among Egyptians led to Jewish residents in the city, and elsewhere in Egypt, being perceived as Zionist collaborators. Most Jewish residents of Egypt fled to the newly established Israel, France, Brazil and other countries in the 1950s and 1960s. The community once numbered 50,000 but is now estimated at below 50. The most important synagogue in Alexandria is the Eliyahu Hanavi Synagogue.\n\nAlexandria has a number of higher education institutions. Alexandria University is a public university that follows the Egyptian system of higher education. Many of its faculties are internationally renowned, most notably its Faculty of Medicine & Faculty of Engineering. In addition, Egypt-Japan University of Science and Technology in New Borg El Arab city, its is a research university set up in collaboration between the Japanese and Egyptian governments in 2010, the Arab Academy for Science and Technology and Maritime Transport is a semi-private educational institution that offers courses for high school, undergraduate level, and postgraduate students. It is considered the most reputable university in Egypt after the AUC American University in Cairo because of its worldwide recognition from (board of engineers at UK & ABET in US). Université Senghor is a private French university that focuses on the teaching of humanities, politics and international relations, which mainly targets students from the African continent. Other institutions of higher education in Alexandria include Alexandria Institute of Technology (AIT) and Pharos University in Alexandria.\n\nAlexandria has a long history of foreign educational institutions. The first foreign schools date to the early 19th century, when French missionaries began establishing French charitable schools to educate the Egyptians. Today, the most important French schools in Alexandria run by Catholic missionaries include Collège de la Mère de Dieu, Collège Notre Dame de Sion, Collège Saint Marc, Ecoles des Soeurs Franciscaines (four different schools), École Girard, École Saint Gabriel, École Saint-Vincent de Paul, École Saint Joseph, École Sainte Catherine, and Institution Sainte Jeanne-Antide. As a reaction to the establishment of French religious institutions, a secular (laic) mission established Lycée el-Horreya, which initially followed a French system of education, but is currently a public school run by the Egyptian government. The only school in Alexandria that completely follows the French educational system is Lycée Français d'Alexandrie (École Champollion). It is usually frequented by the children of French expatriates and diplomats in Alexandria. The Italian school is the Istituto \"Don Bosco\".\n\nEnglish schools in Alexandria are becoming the most popular schools. English language schools in the city include: Riada Language School, Alexandria Language School, Future Language School, Future International Schools (Future IGCSE, Future American School and Future German school), Alexandria American School, British School of Alexandria, Egyptian American School, Pioneers Language School, Princesses Girls' School, Sidi Gaber Language School, Riada American School, Taymour English School, Sacred Heart Girls' School, Schutz American School, Victoria College, El Manar Language School for Girls (previously called Scottish School for Girls), Kawmeya Language School, El Nasr Boys' School (previously called British Boys' School), and El Nasr Girls' College. Most of these schools were nationalized during the rule of Gamal Abdel Nasser, and are currently Egyptian public schools run by the Egyptian Ministry of Education.\n\nThere are only two German schools in Alexandria which are Deutsche Schule der Borromärinnen (DSB of Saint Charles Borromé) and Future Deutsche Schule.\n\nThe Montessori educational system was first introduced in Alexandria in 2009 at Alexandria Montessori.\n\nThe most notable public schools in Alexandria include El Abbassia High School and Gamal Abdel Nasser High School.\n\nAlexandria is served by Alexandria International Airport and Borg al Arab Airport which is located about away from city center.\n\nFrom late 2011, Alexandria International was to be closed to commercial operations for two years as it underwent expansion, with all airlines operating out of Borg al Arab Airport from then onwards, where a brand new terminal was completed in February 2010.\n\n\nAlexandria's intracity commuter rail system extends from Misr Station (Alexandria's primary intercity railway station) to Abu Qir, parallel to the tram line. The commuter line's locomotives operate on diesel, as opposed to the overhead-electric tram.\n\nAlexandria plays host to two intercity railway stations: the aforementioned Misr Station (in the older Manshia district in the western part of the city) and Sidi Gaber railway station (in the district of Sidi Gaber in the center of the eastern expansion in which most Alexandrines reside), both of which also serve the commuter rail line. Intercity passenger service is operated by Egyptian National Railways.\n\nAn extensive tramway network was built in 1860 and is the oldest in Africa. The network begins at the El Raml district in the west and ends in the Victoria district in the east. Most of the vehicles are blue in color. Some smaller yellow-colored vehicles have further routes beyond the two main endpoints. The tram routes have one of four numbers: 1, 2, 5, and 6. All four start at El Raml, but only two (1 and 2) reach Victoria. There are two converging and diverging points. The first starts at Bolkly (Isis) and ends at San Stefano. The other begins at Sporting and ends at Mostafa Kamel. Route 5 starts at San Stefano and takes the inner route to Bolkly. Route 6 starts at Sidi Gaber El Sheikh in the outer route between Sporting and Mustafa Kamel. Route 1 takes the inner route between San Stefano and Bolkly and the outer route between Sporting and Mustafa Kamel. Route 2 takes the route opposite to Route 1 in both these areas. The tram fares are 25 piastres (0.25 pounds) during most of the day, and 50 piastres (0.50 pounds) after 9pm. Some trams (that date back the 30s) charge a pound. The tram is considered the cheapest method of public transport.\n\nTaxis in Alexandria sport a yellow-and-black livery and are widely available. While Egyptian law requires all cabs to carry meters, these generally do not work and fares must be negotiated with the driver on either departure or arrival.\n\nThe minibus share taxi system, or \"mashrū`\" operates along well-known traffic arteries. The routes can be identified by both their endpoints and the route between them:\n\nThe route is generally written in Arabic on the side of the vehicle, although some drivers change their route without changing the paint. Some drivers also drive only a segment of a route rather than the whole path; such drivers generally stop at a point known as a major hub of the transportation system (for example, Victoria) to allow riders to transfer to another car or to another mode of transport.\n\nFare is generally L.E. 2.00 to travel the whole route. Shorter trips may have a lower fare, depending on the driver and the length of the trip.\n\nAlexandria has four ports; namely the Western Port, which is the main port of the country that handles about 60% of the country’s exports and imports, Dekhela Port west of the Western Port, the Eastern Port which is a yachting harbor, and Abu Qir Port at the northern east of the governorate. It is commercial port for general cargo and phosphates.\n\nThe Royal Library of Alexandria, in Alexandria, Egypt, was once the largest library in the world. It is generally thought to have been founded at the beginning of the 3rd century BC, during the reign of Ptolemy II of Egypt. It was likely created after his father had built what would become the first part of the library complex, the temple of the Muses—the Museion, Greek \"Μουσείον\" (from which the Modern English word \"museum\" is derived).\n\nIt has been reasonably established that the library, or parts of the collection, were destroyed by fire on a number of occasions (library fires were common and replacement of handwritten manuscripts was very difficult, expensive, and time-consuming). To this day the details of the destruction (or destructions) remain a lively source of controversy.\n\nThe Bibliotheca Alexandrina was inaugurated in 2002, near the site of the old Library.\n\n\nThe main sport that interests Alexandrians is football, as is the case in the rest of Egypt and Africa. Alexandria Stadium is a multi-purpose stadium in Alexandria, Egypt. It is currently used mostly for football matches, and was used for the 2006 African Cup of Nations. The stadium is the oldest stadium in Egypt and Africa, being built in 1929. The stadium holds 20,000 people. Alexandria was one of three cities that participated in hosting the African Cup of Nations in January 2006, which Egypt won. Sea sports such as surfing, jet-skiing and water polo are practiced on a lower scale. The Skateboarding culture in Egypt started in this city. The city is also home to the Alexandria Sporting Club, which is especially known for its basketball team, which traditionally provides the country's national team with key players. The city hosted the AfroBasket, the continent's most prestigious basketball tournament, on four occasions (1970, 1975, 1983, 2003).\n\nAlexandria has four stadiums:\n\nOther less popular sports like tennis and squash are usually played in private social and sports clubs, like:\n\n\nAlexandria is a main summer resort and tourist attraction, due to its public and private beaches and ancient history and Museums, especially the Bibliotheca Alexandrina, based on reviving the ancient Library of Alexandria.\n\nOne of the main tourism attractions that start every year from the city is Cross Egypt Challenge. Started in 2011, Cross Egypt Challenge is an international cross-country motorcycle and scooter rally conducted throughout the most difficult tracks and roads of Egypt. Alexandria is known as the yearly starting point of Cross Egypt Challenge and a huge celebration is conducted the night before the rally starts after all the international participants arrive to the city.\n\nAlexandria is twinned with:\n\n\n\n", "id": "3080", "title": "Alexandria"}
{"url": "https://en.wikipedia.org/wiki?curid=3082", "text": "Alexandria, Indiana\n\nAlexandria is a city in Monroe Township, Madison County, Indiana, United States. It is about northeast of Indianapolis. According to the 2010 census, its population was 5,145, a decrease of 17.8% from 6,260 in 2000.\n\nAlexandria was platted in 1836 when it was certain that the Indiana Central Canal would be extended to that point. It was incorporated as a town in 1898.\n\nAlexandria is located at . According to the 2010 census, Alexandria has a total area of , all land.\n\nAlexandria is part of the Anderson, Indiana Metropolitan Statistical Area. \n\nAs of the census of 2010, there were 5,145 people, 2,113 households, and 1,362 families residing in the city. The population density was . There were 2,507 housing units at an average density of . The racial makeup of the city was 97.4% White, 0.3% African American, 0.1% Native American, 0.2% Asian, 0.8% from other races, and 1.1% from two or more races. Hispanic or Latino of any race were 1.7% of the population.\n\nThere were 2,113 households of which 33.6% had children under the age of 18 living with them, 42.2% were married couples living together, 15.7% had a female householder with no husband present, 6.6% had a male householder with no wife present, and 35.5% were non-families. 30.1% of all households were made up of individuals and 12.8% had someone living alone who was 65 years of age or older. The average household size was 2.41 and the average family size was 2.95.\n\nThe median age in the city was 38.2 years. 25.6% of residents were under the age of 18; 8.8% were between the ages of 18 and 24; 24.8% were from 25 to 44; 25.1% were from 45 to 64; and 15.6% were 65 years of age or older. The gender makeup of the city was 47.8% male and 52.2% female.\n\nAs of the census of 2000, there were 6,260 people, 2,481 households, and 1,654 families residing in the city. The population density was 2,308.6 people per square mile (891.9/km²). There were 2,704 housing units at an average density of 997.2 per square mile (385.2/km²). The racial makeup of the city was 98.10% White, 0.46% Black or African American, 0.08% Native American, 0.11% Asian, 0.02% Pacific Islander, 0.43% from other races, and 0.80% from two or more races. 0.99% of the population were Hispanic or Latino of any race.\n\nThere were 2,481 households out of which 33.9% had children under the age of 18 living with them, 49.0% were married couples living together, 12.7% had a female householder with no husband present, and 33.3% were non-families. 28.9% of all households were made up of individuals and 13.1% had someone living alone who was 65 years of age or older. The average household size was 2.48 and the average family size was 3.04.\n\nIn the city, the population was spread out with 27.8% under the age of 18, 8.9% from 18 to 24, 28.0% from 25 to 44, 19.5% from 45 to 64, and 15.9% who were 65 years of age or older. The median age was 35 years. For every 100 females there were 91.4 males. For every 100 females age 18 and over, there were 87.4 males.\n\nThe median income for a household in the city was $35,359, and the median income for a family was $42,731. Males had a median income of $30,529 versus $23,384 for females. The per capita income for the city was $15,578. About 4.2% of families and 7.0% of the population were below the poverty line, including 4.1% of those under age 18 and 15.0% of those age 65 or over.\n\nThe city council consists of seven members. Five members are elected from individual districts and two are elected at-large. The city is governed by a \"strong\" mayor system who appoints two council members and/or city residents to serve at the mayor's pleasure on the board of public works and safety. The chief financial officer is the clerk-treasurer. The clerk-treasure and mayor are full-time elected officials. The Alexandria City Court has a part-time locally elected judge.\n\nAlexandria Airport is a public use airport located southeast of the central business district of Alexandria.\n\n\n", "id": "3082", "title": "Alexandria, Indiana"}
{"url": "https://en.wikipedia.org/wiki?curid=3083", "text": "Alexandria, Louisiana\n\nAlexandria is the ninth-largest city in the state of Louisiana and is the parish seat of Rapides Parish, Louisiana, United States. It lies on the south bank of the Red River in almost the exact geographic center of the state. It is the principal city of the Alexandria metropolitan area (population 153,922) which encompasses all of Rapides and Grant parishes. Its neighboring city is Pineville. In 2010, the population was 47,723, an increase of 3 percent from the 2000 census.\n\nLocated along the Red River, the city of Alexandria was originally home to a community which supported activities of the adjacent Spanish outpost of Post du Rapides. The area developed as an assemblage of traders and merchants in the agricultural lands bordering the mostly unsettled areas to the north and providing a link from the south to the El Camino Real and then larger settlement of Natchitoches, the oldest permanent settlement in the Louisiana Purchase.\n\nAlexander Fulton, a businessman from Washington County, near Pittsburgh, Pennsylvania, received a land grant from Spain in 1785, and the first organized settlement was made at some point in the 1790s. In 1805, Fulton and business partner Thomas Harris Maddox laid out the town plan and named the town in Fulton's honor. The earliest deed that survives, for an Alexandria resident is from June 24, 1805 when a William Cochren who identifies himself as a \"of the Town of Alexandria\" sold a tract of land across the Red River to a William Murrey.[Louisiana State Land Office, Historical Records, Sales Documents, South Western District, Sales Letters, 39].\n\nThat same year Fulton was appointed coroner in Rapides Parish by territorial Governor William C.C. Claiborne. Alexandria was incorporated as a town in 1819 and received a city charter in 1832.\n\nIn the spring of 1863, Alexandria was occupied by Union forces under the command of Admiral David Dixon Porter and General Nathaniel P. Banks. Porter arrived with his gunboats on May 7. Later in the day Banks reached Alexandria with his cavalry, whose members had marched twenty-five miles to reach the city that day. According to the historian John D. Winters of Louisiana Tech University, Porter disliked Banks but nevertheless turned over Alexandria to him and then departed to rejoin General U.S. Grant at the ongoing siege of Vicksburg, Mississippi. Banks posted guards and declared martial law. Porter left behind the gunboat \"USS Lafayette\" in Alexandria and posted the \"USS Pittsburg\" on the Black River to the northeast.\n\nIn 1864, Admiral Porter, back in the area, and General Banks quarreled over possession of cotton supplies. Porter seized three hundred bales of Confederate cotton from various warehouses in Alexandria and stamped it \"U.S.N. prize\", referring to the United States Navy. Porter sent his sailors into the country to search for unginned cotton. After the crop was located, it was brought to Alexandria to be ginned and baled. The sailors also seized molasses and wool. Winters writes that Porter \"took all cotton wherever he found it, cotton belonging to the Confederate government, cotton belonging to the 'rebels,' and cotton belonging to 'loyal' citizens.\"\n\nWinters continues: \"Banks was furious with Porter when he learned that the admiral was scouring the interior for cotton. Since he had no authority to stop Porter's speculative activities, Banks could only try to beat him to the remaining cotton. Army wagons were sent out in large numbers to collect the cotton. Thousands of bales were brought in by the troops and stored for future shipment. Jealous of the abundant transportation facilities of the army, unprincipled navy men stole army wagons and teams at night, repainted the wagons, and branded the mules with navy initials, and dove deep in the country in search of cotton. . . . \"\n\nThe federal army made itself as comfortable as possible during its long stay in Alexandria. Winters writes that \"lumber and tools were foraged, and the men busied themselves by building wooden tent floors, benches, and furniture. . . . Alexandria [was enclosed] with a zigzag line of fortifications.\" While Banks remained in Alexandria in the spring of 1864, Porter was temporarily trapped north of the city because of the low level of the Red River, four feet instead of the needed seven feet to accommodate gunboats.\n\nConfederate citizens as a whole were most fearful of the Union. According to Winters, \"most [Confederates] had never before seen a Yankee soldier [and] expected the worse from the invader. . . . 'Some cried, some cursed, some whined; and some overcome with fear, hid themselves in the woods, leaving everything to the tender mercies of the army.' Negroes were responsible for much of the plunder and pillage. Negro camp followers and officers' servants roamed the plantations and small farms without hindrance, bringing in their booty to camps each afternoon. . . . \"\n\nOn May 13, 1864, when the Union decided to abandon Alexandria, the city was set afire despite General Banks' order to the contrary. Winters reports that \"burning and plundering\" by two Union corps, who set fire to a store on Front Street. Then \"a strong wind spread the flames rapidly from one building to the next.\" Banks later claimed that the fire \"broke out in the attic of one of the buildings on the levee inhabited by either soldiers or refugees.\" Winters reports that \"pandemonium reigned; frightened cows bellowed and charged through the flaming streets; squawking chickens with scorched wings tried to fly out of danger. Hundreds of women, children, and old people ran through the streets, trying to carry a few of their belongings to safety. When the heat became unbearable, they dropped their loads and fled to the levee. Thieves ran from house to house and even along the levee taking whatever they wanted from the shocked people. By noon the most congested parts of town were destroyed. An attempt to blow up a church in the path of the fire only succeeded in helping to spread the flames. . . . \"\n\nAlexandria faced the overwhelming task of rebuilding with a year of the war remaining. Prices became exorbitant; butter cost $10 a pound, bacon $5 a pound, flour $3 a pound, and a bushel of meal $10. Many of the helpless lived in the forest without food, shelter, or clothing, subsisting on blackberries. All clothing was homespun, and shoes were mostly made of cloth. While Admiral Porter expressed sympathy for the suffering Alexandria residents, he declared the \"burning of Alexandria a fit termination of the unfortunate Red River expedition.\"\n\nAlexandria is located at and has an elevation of .\n\nAccording to the United States Census Bureau, the city has a total area of . 26.4 square miles (68.4 km²) of it is land and 0.6 square miles (1.5 km²) of it (2.15%) is water.\n\nAlexandria is on a level plain in the center of the Louisiana Longleaf Pine forests, in which pine is interspersed with various hardwoods. A number of small bayous, such as Bayou Rapides, Bayou Robert, and Hynson Bayou, meander throughout the city. In the immediate vicinity of the city, cotton, sugar, alfalfa, and garden vegetables are cultivated.\n\nThe climate is humid subtropical with some continental influence in the winter. Summers are consistently hot and humid, whereas winters are mild, with occasional cold snaps. On average, the first freeze occurs in early to mid November and the last freeze occurs in early to mid March. The area receives plentiful rainfall year-round, with thunderstorms possible throughout the year. Some storms can be severe, especially during the spring months. According to 'Cities Ranked and Rated' (Bert Sperling and Peter Sander), Alexandria reports an average of 69 days per year with thunder reported. This is nearly double the national average. Snowfall is rare, with measurable snow having occurred 27 times since 1895. The heaviest snowfall event took place February 12–13, 1960 when 9.1\" of snow fell.\n\nTropical storms and hurricanes do impact Alexandria from time to time, but rarely cause severe damage, unlike areas closer to the coast. In September 2005 Hurricane Rita affected Alexandria and surrounding areas, causing widespread power outages and damaging the roofs of some structures. The most recent hurricane, Gustav, caused widespread flooding, knocked over trees and power lines leading to power outages, and damaged structures. Some low-lying Alexandria neighborhoods experienced substantial flooding from Gustav with several feet of water in houses.\n\nAs of the census of 2010, there were 47,723 people, 17,816 households, and 11,722 families residing in the city. The population density was 1,754.6/sq mi (677.5/km²). There were 19,806 housing units at an average density of 749.9 per square mile (289.6/km²). The racial makeup of the city was 50.75% White, 40.60% Black, 1.25% Native American, 1.85% Asian, 0.14% Pacific Islander, 1.03% from other races, and 1.09% from two or more races. 6.98% of the population were Hispanic or Latino of any race.\n\nThere were 17,816 households out of which 31.9% had children under the age of 18 living with them, 38.5% were married couples living together, 23.2% had a female householder with no husband present, and 34.2% were non-families. 30.4% of all households were made up of individuals and 12.1% had someone living alone who was 65 years of age or older. The average household size was 2.50 and the average family size was 3.13.\n\nIn the city, the population was spread out with 28.1% under the age of 18, 9.2% from 18 to 24, 26.2% from 25 to 44, 21.4% from 45 to 64, and 15.1% who were 65 years of age or older. The median age was 36 years. For every 100 females there were 83.5 males. For every 100 females age 18 and over, there were 77.7 males.\n\nThe median income for a household in the city was $26,097, and the median income for a family was $31,978. Males had a median income of $29,456 versus $20,154 for females. The per capita income for the city was $16,242. About 23.2% of families and 27.4% of the population were below the poverty line, including 37.7% of those under age 18 and 18.5% of those age 65 or over.\n\nLike many other southern cities, the largest single church denomination in the Alexandria area is Southern Baptist. Large congregations include Emmanuel Baptist Church downtown on Jackson Street and Calvary Baptist off Jackson Street Extension. Alexandria is headquarters too of the Louisiana Baptist Convention. A significant Roman Catholic population is also present, a result of the large Catholic Acadian French population which resides in and around Alexandria, many from neighboring Avoyelles Parish. Alexandria is the headquarters for the Diocese of Alexandria, Louisiana, which is headed by Bishop Ronald Herzog\n\nAlexandria also has a significant number of Methodists, Presbyterians, and Episcopalians. There is a large number of Pentecostals too. Alexandria has a small, though active Jewish community which dates back to the mid-19th century. Jews have consistently been leaders in government, civic organizations, education, and medicine. The long-time Alexandria City Council member, Harry B. Silver, is Jewish. From 1973 to 1977, another Jew, Arnold Jack Rosenthal, was the last commissioner of finance and utilities under the previous commission form of municipal government. At one time, many large businesses in the downtown werer Jewish-owned, with stores including: Wellan's, Caplan's, Bialy's, Weiss & Goldring, and Schwartzberg's. The Jewish community in Alexandria maintains two synagogues, which are approximately two blocks apart: Congregation Gemiluth Chassodim (Reform) and B'nai Israel Traditional Synagogue (Conservative).\n\nAs Alexandria is at the cusp of Cajun culture's extension to the north, the city recognizes Mardi Gras as an official holiday. The annual Mardi Gras Krewes Parade – occurring on the Sunday before Mardi Gras – on Texas Avenue is a major cultural festivity in the area. Boasted as a true family oriented event, parade goers can enjoy over 20 New Orleans style floats, high school and college marching bands, as well as appearances by local celebrities. In addition to the main Sunday parade, the College Cheerleaders & Classic Cars Parade, which recently was established in 2008, takes place downtown on the Friday before Mardi Gras, the Children's Parade as well takes place downtown on the Saturday before Mardi Gras, and the Krewe of Provine Parade which occurs on Fat Tuesday itself down Coliseum Boulevard. All the events are organized by the Alexandria Mardi Gras Association (AMGA). The Krewe Parade can attract from 120,000 to 150,000; the Children's parade, up to 40,000 to 50,000, and the College Cheerleaders & Classic Cars, about 5,000 to 15,000 people.\n\nBegun in the late 1980s, Cenlabration\nwas one of the largest festivals in Central Louisiana (Cenla). The name comes from Central Louisiana (\"LA\") Celebration, and reflects local culture and heritage, as well as serving as a means of celebrating Labor Day as the end of summer.\n\nAs many as three stages support a particular type of music, including Cajun and zydeco, blues and jazz, and Country music. In addition there are arts and crafts booths for local artists to sell their wares. In the Children's Village, children can participate in arts and crafts, listen to storytellers, play games with clowns, or watch a play. The festival has plenty of carnival rides available as well. Cenlabration ends with a large fireworks display.\n\nIn 2002, representatives of local government, businesses, organizations, and community formed the nonprofit organization River Cities Cultural Alliance, Inc. to promote tourism and the arts through a celebration of Central Louisiana’s diverse cultural heritage. The nonprofit served to organize and put on RiverFest: Heritage and Arts on the Red. More than ten thousand festival-goers attending the event.\n\nRiverFest was held in downtown Alexandria and on the Alexandria and Pineville levees. The festival features the work of visual artists from across the South, food booths exemplifying southern cuisine, a variety of children’s activities, three outdoor stages with a wide range of music, dance, and theatrical performances, and a literary component with readings and panel discussions by Louisiana authors and scholars.\n\nRiverFest was canceled in 2007.\n\nThe Alexandria Museum of Art was founded in 1977 and occupies an historic Rapides Bank Building on the banks of the Red River. The building was constructed built c. 1898 and is listed on the National Historic Register. It opened to the public in March 1998. In 1998, the Alexandria Museum of Art expanded and constructed its grand foyer and offices as an annex to the Rapides Bank Building. In 1999, the Alexandria Museum of Art was honored as an Outstanding Arts Organization in the Louisiana Governor's Arts Awards. In 2007, the Alexandria Museum of Art entered into a collaborative endeavor agreement with Louisiana State University of Alexandria (LSUA). The Alexandria Museum of Art now also serves as a downtown campus for LSUA classes, and is host to multidisciplinary community events, including concerts and recitals, lectures, yoga classes, Second Saturday Markets, and Museum Afterhours.\n\nThe Louisiana History Museum is located downtown on the bottom floor of the former library. A small facility, it showcases the history of all Louisiana, with emphasis on the central portion of the state, Rapides Parish, and Alexandria. Major exhibit areas concern Native Americans, Louisiana geography, politics, health care, farming, and the impact of war.\n\nThe T.R.E.E. House Children's Museum and Arna Bontemps African American Museum are located within the Cultural Arts District.\n\nThe Kent Plantation House in Alexandria, completed by 1800, was located on a Spanish land grant. It is the oldest standing structure in Central Louisiana, one of only two buildings in the city to survive the burning of 1864 by Union troops fleeing after having been defeated at the Battle of Mansfield in DeSoto Parish. The house has been moved from its original location but still stands on part of the first land grant. It is open for tours daily except Sundays at 9, 10, and 11 a.m. and 1, 2, and 3 p.m. The tour is led by costumed docents and includes the house furnished in period pieces, some belonging to the original family, and all nine outbuildings, including an 1840-50s sugar mill, blacksmith shop, barn, two slave cabins, open-hearth kitchen, and milk house.\n\nThe performing arts are centered in the Alexandria Cultural Arts District in the downtowna. Located within a few blocks of each other are three performance venues: Coughlin-Saunders Performing Arts Center, the Hearn Stage, and the Riverfront Amphitheater.\n\nThe Coughlin-Saunders Performing Arts Center is the home of the Rapides Symphony Orchestra, which has performed in Alexandria since 1968. The center hosts the Performing Arts Series of the Arts Council of Central Louisiana, the Red River Chorale (an auditioned community chorus), and presentations of numerous local theater groups. The land for the center was donated by \"The Alexandria Town Talk\" newspaper, owned by the Gannett Company of McLean, Virginia.\n\nBusinesswoman Jacqueline Seagall Caplan (1935-2016) was the president of the Arts Council of Central Louisiana and the chairman of the group's executive committee when the Coughlin-Saunders Performing Arts Center opened in 2004. She predicted that Coughlin-Saunders would in time \"provide a place people can point to and say it's theirs. ... [Until now], we've never had a performing arts center where every type of performing art can come.\"\n\nThe Hearn Stage is a black box theater for smaller productions. The Arts Council provides day-to-day management of both the Coughlin-Saunders Center and the Hearn Stage.\n\nThe Riverfront Aamphitheater hosts each April a \"azz on the River\"music festival, sponsored by the Arna Bontemps African American Museum. The Rapides Symphony holds an annual fall Pops concert in the amphitheater. In recent years, the amphitheater has welcomed musical guests in conjunction with the springtime Dragonboat Races sponsored by the Alexandria Museum of Art.\n\nThe spring and fall seasons also feature Downtown Rocks, a free outdoor concert series in nearby Fulton Park.\n\nAlexandria is home to the Alexandria Aces, a summer college league team. The Aces were champions in various leagues in 1997, 1998, 2006, and 2007. They play their home games at Bringhurst Field. The remaining games of the 2013 season were cancelled in mid-July because of low attendance, which averaged fewer than two hundred per game.\n\nAlexandria is also home to the Cenla Derby Dames, a roller derby team that operates under the Women's Flat Track Derby Association. The Dames play their home games at the Rapides Parish Coliseum.\n\nNearby is Bringhurst Golf Course, popularly known as \"the nation's oldest par three course.\" A full-scale renovation was completed in mid-2010. In addition to Bringhurst, named for the late industrialist R.W. Bringhurst, Alexandria is home to four other golf courses: Oak Wing, The Links on the Bayou, at LSUA, and Alexandria Golf and Country Club.\n\nAlexandria once had a minor league ice hockey team, the Alexandria Warthogs. They played their home games at the Rapides Parish Coliseum.\n\nThere was also a semi-pro football team, the Louisiana Rapides Rangers, who played their home games at the Rapides Parish Coliseum. They played in the Central District of the Southern American Football League, and the Southern Conference of the National Indoor Football League (NIFL). The team was owned by a Lafayette business group before moving in 2003 to Beaumont, Texas.\n\nIn 1974, a Little League team from Alexandria won the Louisiana state championship.\n\nAlexandria is also home to the U-14 Crossroads Pride soccer team. They won the 2012 Louisiana Soccer Association State Cup.\n\n\nhttp://www.legacy.com/obituaries/thetowntalk/obituary.aspx?n=patrick-mccauley&pid=174641302&fhid=5535#sthash.LF5SOogF.dpuf|title=Patrick McCauley|date=April 16, 2015|publisher=\"Alexandria Town Talk\"|accessdate=May 17, 2015}}</ref>\n\nEstablished March 17, 1883, The Alexandria Town Talk is a daily newspaper for Alexandria-Pineville and the thirteen parishes which comprise central Louisiana. The newspaper was owned by the family of the late Jane Wilson Smith and Joe D. Smith, Jr., until March 1996, when it was sold to Central Newspapers. In August 2000, the Gannett Company acquired the Central Newspapers properties, including \"The Town Talk\". The name of the paper on its inaugural issue was the \"Alexandria Daily Town Talk\". Although it has since been shorted to the current \"The Town Talk\", it is still frequently referred to by long-time residents as the \"Daily Town Talk\".\n\nKey officers include: Publisher William \"Ed\" Humphrey; Executive Editor Paul V. Carty; Advertising Director William \"Bill\" Heirtzler; and Assistant Managing Editors John Marcase and Richard Powell Sharkey.\n\nAlexandria is served by local television stations KALB-TV (NBC / CBS), WNTZ (Fox), KLAX-TV (ABC), KLPA (PBS/LPB), and KBCA (The CW). KALB is the oldest television station in central Louisiana.\n\nAlexandria is the location of the pawn shop in the show Cajun Pawn Stars on the History Channel.\n\nLocal radio stations\n\n\n\n\n\n\nThe Alexandria Zoological Park is a zoo first opened to the public in 1926. Owned by the City of Alexandria and operated by the Division of Public Works, it is home to about 500 animals and includes an award-winning Louisiana Habitat exhibit. Much of the credit for the quality of the zoo has been given to Robert Leslie Whitt (1951–2008), who served as director for 34 years prior to his death. Whitt was hired in 1974 by then Streets and Parks Commissioner Malcolm Hebert. The zoo is accredited by the Association of Zoos and Aquariums (AZA) and takes part in about 20 Species Survival Plans (SSP) as part of its conservation efforts.\n\nCotile Lake is a man-made impoundment located in the uplands approximately west-northwest of Alexandria, Louisiana. The lake is approximately in size and was completed in October 1965. The Louisiana Wild Life and Fisheries Commission stocked this impoundment with the proper species and number of game fish in 1965–66 shortly after its completion date. The recreational facilities include a large area cleared and zoned for swimming with complete bath house facilities nearby. There is a water skiing area that is cleared and snagged for safety of the skiers. The picnic and camping areas are modern and complete. There is also space available for campers.\n\nEncompasses a lake, of developed recreation facilities and a primitive camping area all within the Alexander State Forest. The lake, located in central Louisiana, was constructed as a joint venture of the Louisiana Forestry Commission, the Rapides Parish Police Jury, and the Lower West Red River Soil and Water Conservation District as a reservoir for agricultural irrigation in times of need and for recreation purposes.\n\nThe recreation area camping area contains 109 campsites with conventional full utility hookups, 3 beaches for swimming, bath houses, a boat launch, and 75 picnic sites. A covered pavilion within the developed area provides for groups up to 100 people. The recreation area is open year-round and operates on user fees.\n\nAlexandria sits in the middle of the Kisatchie National Forest. Ranger districts are north, northwest, west and southwest of the city. An abundance of large timberlands and forest nurseries, as well as lake and recreation areas, are within a short driving distance.\n\n\nAlexandria is home to both Headquarters and Company B of the 199th Brigade Support Battalion (BSB). The 199th BSB is the logistical component of the 256th Infantry Brigade that served in Operation Iraqi Freedom from October 2004 until September 2005. The 199th BSB provides supply and transportation (Company A), medical (Company C) and maintenance (Company B) support and services that keep the 256th Brigade operational. The battalion also has units located in Jonesboro, Winnfield, Colfax, and St. Martinville, Louisiana.\n\nAlexandria served as the home of England Air Force Base from its origins as an emergency airstrip for Esler Regional Airport until its closure. England AFB was officially closed on December 15, 1992, pursuant to the Defense Base Closure and Realignment Act (Public Law 101-510) and recommendations of the Defense Secretary's Commission on Base Realignment and Closure. The base now serves as Alexandria International Airport (see below).\nAt the time of the 2000 census, the per capita income in Alexandria was $16,242, compared with $21,587 nationally. The Alexandria workforce consists of about 55,000 residents. Union Tank Car Company has recently located a plant northwest of Alexandria near the airport creating hundreds of jobs. Expansions at the Procter & Gamble plant and the construction of a PlastiPak plant in nearby Pineville have also created a number of new jobs for the area. Sundrop Fuels Inc., a Colorado-based biofuels start-up, plans to construct an over 1,200 acre plant just northwest of Alexandria in Rapides Station area. The facility will serve as the headquarters for the company because aside from the plant itself, Sundrop has also bought Cowboy Town, an abandon entertainment venue that sits inside the surrounding land that was purchased, to house their offices and their maintenance and fabrication operations.\n\nIn 2007, Inc. Magazine rated Alexandria as the 77th best place in which to conduct business out of the 393 U.S. cities ranked, a significant increase from its ranking as No. 276 in 2006. Among other Louisiana cities, Alexandria ranked second, following only Baton Rouge, which ranked 59th nationally.\n\nAlexandria is home to two major hospitals: Rapides Regional Medical Center, a former Baptist hospital is located downtown. Christus St. Frances Cabrini Hospital was opened in 1950 and is located at the corner of Masonic Drive and Texas Avenue. Both hospitals have undergone expansion.\n\nAdditionally, located just across the Red River in Pineville, the Veteran's Affairs Medical Center at Alexandria serves central Louisiana and surrounding areas.\n\nMeanwhile, in 2013, the state allocated $15 million to move the medical services long provided at no or minimal charge at the Huey P. Long Medical Center in Pineville to the former hospital at England Park at the site of the closed England Air Force Base.\n\nIn the early 19th century, the Port of Alexandria brought goods to the area and shipped cotton and other local products to the rest of the country. A ferry connected the cities of Alexandria and Pineville until a bridge was built across the Red in 1900.\n\nToday, Port facilities include: a 40-ton crane for off-loading, a warehouse, 13,600-ton bulk fertilizer warehouse, a 3,400-ton bulk fertilizer dome structure and a 5,000-ton dome which was added in January 2005.\n\nThe petroleum off-loading facility includes two tanks, one tank capable of handling two barges and five truck off-loading simultaneously. There is also a general cargo dock with access to rail and a hopper barge unloading dock with conveyor system.\n\nToday's modern facilities and the Port's central location with its connection to the Mississippi River provide excellent opportunities for importers and exporters.\n\nAlexandria International Airport (AEX) is a regional airport, providing flights to Atlanta,Dallas/Ft. Worth, and Houston. In 2006 a new-state-of-the-art passenger terminal was dedicated. Alexandria is served by American, United, and Delta.\n\nFormerly known as England AFB until 1992, Alexandria International Airport additionally has numerous international charter airlines use the airport in the transport of military personnel attached to the United States Army base at Fort Polk. A new military personnel terminal opened in 2007.\n\nDowntown Alexandria, including the Alexandria Cultural Arts District, is currently in the process of revitalization. It is home to five museums, three performance venues, and several galleries. In recent years, several bars, cafes, and restaurants have opened.\n\nAcross the street from the venues is the Hotel Bentley. The Bentley was built in 1908 by lumberman and local eccentric Joseph A. Bentley. The Bentley's heyday was during the 1940s and 1950s, when senior military officials, including General Dwight D. Eisenhower, stayed for extended periods. The Bentley, which was closed on December 12, 2004, was once one of only two four-star hotels in Louisiana. The hotel was set to reopen in August 2007, in time for the 100th anniversary of its construction, but was prevented by funding issues. The current owner, Michael Jenkins, purchased the Bentley for $3.4 million. His plan is to keep the older portion of the building to remain a hotel and turn the 7-storey tower portion into luxury condominiums, and also to reopen Bentley's restaurant and Mirror Room lounge. The hotel and all of its components were to have been opened by the summer of 2013, but the hotel remained unfinished as of November 2014.\n\nCentral Alexandria is bounded by MacArthur Drive, Masonic Drive, Mason Street, the Alexandria-Pineville Expressway, and the Red River.\n\nNorthwestern Alexandria comprises the area north of Louisiana Highway 28 West and MacArthur Drive and south of the Red River.\n\nWestern Alexandria is the area south of Highway 28 West, west of MacArthur Drive, and north of Versailles Boulevard and Metro Drive\n\nAlexandria real estate broker Robert Andrew Wolf, Jr. (1930-2016), designed The Centre and other local and regional developments, including the Walmart SuperCenter on Louisiana Highway 28 West, the Melrose Plantation in Natchitoches Parish with partner John Wasson, at which once lived the author Francois Mignon and the painter Clementine Hunter, and the site of what became the Union Tank Car Company near England Airpark, formerly part of England Air Force Base. In 1967, he and Wasson designed the Wedgewood subdivision in Alexandria; in 1970, they sold Melrose. Wolf was a past president of the Alexandria-Pineville Board of Realtors and in 1984 was named \"Realtor of the Year\".\n\nSouthwestern Alexandria comprises the area west of Masonic Drive and south of Versailles Boulevard and Metro Drive.\n\nSouthern Alexandria is located east of Masonic Drive and south of MacArthur Drive\n\nSoutheastern Alexandria contains the area northeast of MacArthur Drive, south of Masonic Drive, Mason Street, and Alexandria-Pineville Expressway, and bordered by the Red River.\n\nRapides Parish\n\n\nGrant Parish\n\nFollowing the Civil War, all public records in Alexandria had been destroyed. On September 29, 1868, the city was granted a new charter with a government consisting of a Mayor, Treasurer, and Justice of the Peace. Nine aldermen represented the four wards of the city – two from each ward and one elected at-large.\n\nIn 1912, the Lawrason Act established Alexandria municipal government in a strong mayor format, where the mayor was also the Commissioner of Public Health and Safety (Police, Fire, Sanitation). There were separate Commissioners of Streets and Parks and Finance and Utilities, elected citywide. The last to hold those positions, which ended in 1977, were Mayor John K. Snyder (1922–1993), Malcolm P. Hebert, Sr. (1926–2006), and Arnold Jack Rosenthal (1923–2010), respectively.\n\nAlexandria has a mayoral-council system of government. The Mayor serves as the executive branch of the local government. The current Mayor – Jacques Roy – was elected to office in November 2006, succeeding long-time mayor Edward Gordon \"Ned\" Randolph, Jr. Randolph had succeeded John K. Snyder.\n\nThe City Council serves as the legislative branch. The five districts of the city are represented on the Council; in addition there are two council members elected to serve as at-large representatives of the city.\n\nThe Alexandria Court has a limited jurisdiction, consisting of the citizens of Wards 1, 2 and 8 in Rapides Parish. Within those boundaries the court has the power to hear and decide both criminal and civil cases, rule in civil cases and hand down judgment for punishment in criminal cases.\n\nOverall, the people of the Alexandria area tend to be conservative. Even though the majority typically elects Republicans in national elections, they vote for Democrats in local elections, many of which are not contested by the GOP.\n\nFrom 1913 to 1993, Alexandria served as the seat of Louisiana's Eighth Congressional district. A Democratic seat, it was held by the Long family for nearly half of its existence, from 1953 to 1987, broken only by the two terms of Harold B. McSween and three terms of Republican Clyde Holloway of Forest Hill. The seat was removed after the 1990 census indicated Louisiana no longer had the population to support it. The district was split among the Fourth, Fifth and Sixth Congressional districts. Alexandria is now in the Fifth district and was represented from 2003 to 2013 by Rodney Alexander, a Democrat-turned-Republican. From November 2013 to January 2015 the representative is Vance McAllister of Ouachita Parish.\n\nSituated south of the city, Louisiana State University at Alexandria (or LSUA) is a regional campus of the state's flagship university system, Louisiana State University. From its establishment in 1959, the campus offered only two-year degrees; students seeking baccalaureate degrees had to commute or move to the main campus in Baton Rouge in order to gain a four-year degree. After 1976, students could either commute or telecommute in order to attend upper level courses, including graduate classes. In 2002, following approval by the Louisiana State University Board of Supervisors and the Louisiana Board of Regents the Louisiana Legislature passed legislation allowing LSUA to offer baccalaureate degrees.\n\nA four-year degree is also attainable through Southern Baptist-affiliated Louisiana College in Pineville, founded in 1906.\n\nAlexandria also has one of the Region 6 Louisiana Technical College campuses.\n\nRapides Parish School Board operates public schools.\n\nAlexandria has three public high schools: Bolton High School, Alexandria Senior High School, and Peabody Magnet High School. In addition, there are two private high schools: the Roman Catholic Holy Savior Menard Central High School, and Grace Christian.\n\nThe Renaissance Home for Youth west of Alexandria is a haven for youthful offenders who live in a group-home setting as an alternative to reform school or adult jail. Since the facility opened in 1973, nearly 12 thousand young people have lived at the home in search of rehabilitation.\n\nAlfred Booker Junior Academy proudly follows faith- centered education for all students Pre-Kindergarten through eighth grade.\n\nAlexandria serves as the crossroads of Louisiana. To reach either Shreveport or Monroe from the southern portion of the state, the easiest method of travel takes the driver through Alexandria. Likewise, if a visitor is to head from the northern portion of the state to the Cajun portions of the state (Lake Charles and Lafayette), or the greater metropolitan areas of either Baton Rouge or New Orleans, the easiest method of travel involves driving down Interstate 49 through Alexandria.\n\nIn addition to I-49, travelers can follow Louisiana 1 up to Alexandria from Baton Rouge and points south. Also, Highway 167 could be taken from Opelousas north to Monroe, crossing through Alexandria at one of the few bridges over the Red River in central Louisiana. Highways 165 and 71 also link Alexandria and points south with the northern portion of the state via the OK Allen bridge.\n\nThere are possible plans for a 50-mile, 4 lane beltway to encircle Alexandria and Pineville. As of now, it is only in the planning stages of development.\n\nThree road bridges cross the Red River in the Alexandria area. They are:\n\nFormer bridges include:\n\nThere are two railroad bridges over the Red River in Alexandria. One is located near the Buhlow area north of the OK Allen bridge. The other is south of the Purple Heart Memorial Bridge.\n\nRegional mass transit is handled by ATRANS (Alexandria Transportation Authority).\n\nFor those leaving or arriving at the city by bus, Greyhound Lines has a terminal downtown.\n\nAlexandria is served by the Alexandria International Airport and the Esler Regional Airport in Pineville.\n\nAlexandria does not have Amtrak service, nor a commuter rail system. The Kansas City Southern and the Missouri Pacific (since absorbed by Union Pacific) operated train stations in the area in the early part of the 20th century but these have since closed.\n\n", "id": "3083", "title": "Alexandria, Louisiana"}
{"url": "https://en.wikipedia.org/wiki?curid=3085", "text": "Alexandria Troas\n\nAlexandria Troas (\"Alexandria of the Troad\"; ; ) is the site of an ancient Greek city situated on the Aegean Sea near the northern tip of Turkey's western coast, a little south of Tenedos (modern Bozcaada). It is located southeast of modern Dalyan, a village in the Ezine district of Çanakkale Province. The site sprawls over an estimated ; among the few structures remaining today are a ruined bath, an odeon, a theatre, gymnasium complex and a recently uncovered stadion. The circuit of the old walls can still be traced.\n\nAccording to Strabo, this site was first called Sigeia; around 306 BC Antigonus refounded the city as the much-expanded Antigonia Troas by settling the people of five other towns in Sigeia, including the once influential city of Neandreia. It did not receive its name until its name was changed by Lysimachus to Alexandria Troas, in 301 BC, in memory of Alexander III of Macedon (Pliny merely states that the name changed from Antigonia to Alexandria). As the chief port of north-west Asia Minor, the place prospered greatly in Roman times, becoming a \"free and autonomous city\" as early as 188 BC, and the existing remains sufficiently attest its former importance. In its heyday the city may have had a population of about 100,000. Strabo mentions that a Roman colony was created at the location in the reign of Augustus, named Colonia Alexandria Augusta Troas (called simply Troas during this period). Augustus, Hadrian and the rich grammarian Herodes Atticus contributed greatly to its embellishment; the aqueduct still preserved is due to the latter. Constantine considered making Troas the capital of the Roman Empire.\n\nIn Roman times, it was a significant port for travelling between Anatolia and Europe. Paul of Tarsus sailed for Europe for the first time from Alexandria Troas and returned there from Europe (it was there that the episode of the raising of Eutychus later occurred). Ignatius of Antioch also paused at this city before continuing to his martyrdom at Rome.\n\nSeveral of its later bishops are known: Marinus in 325; Niconius in 344; Sylvanus at the beginning of the 5th century; Pionius in 451; Leo in 787; Peter, friend of the Patriarch Ignatius, and adversary to Michael, in the ninth century. In the 10th century Troas is given as a suffragan of Cyzicus and distinct from the famous Troy (Heinrich Gelzer, \"Ungedruckte ... Texte der Notitiae episcopatuum\", 552; \"Georgii Cyprii descriptio orbis romani\", 64); it is not known when the city was destroyed and the diocese disappeared. The bishopric remains a titular see of the Catholic Church under the name Troas, vacant since 1971.\n\nTroas is also a titular see of the Orthodox Church under the Ecumenical Patriarchate. Bishop Savas (Zembillas) of Troas served as hierarch from 2002 to 2011, and then became Metropolitan Savas (Zembillas) of Pittsburgh in the Greek Orthodox Archdiocese of America.\n\nKarasid Turkomans settled in the area of the Troad in the 14th century. Their \"beylik\" was conquered by the Ottomans in 1336. The ruins of Alexandria Troas came to be known among the Turks as \"Eski Stambul\", the \"Old City\". The site's stones were much plundered for building material (for example Mehmed IV took columns to adorn his Yeni Valide Mosque in Istanbul). As of the mid-18th century the site served as \"a lurking place for bandetti\".\n\nBy 1911, the site had been overgrown with vallonea oaks and much plundered, but the circuit of the old walls could still be traced, and in several places they were fairly well preserved. \nThey had a circumference of about ten kilometres, and were fortified with towers at regular intervals.\nRemains of an ancient bath and gymnasium complex can be found within this area; this building is locally known as \"Bal Saray\" (Honey Palace) and was originally endowed by Herodes Atticus in the year 135. Trajan built an aqueduct which can still be traced. \nThe harbour had two large basins, now almost choked with sand. \nIt is the subject of an early twenty-first century study by German archaeologists digging and surveying at the site. \nTheir excavation uncovered the remains of a large stadium dating to about 100 BC.\n\n", "id": "3085", "title": "Alexandria Troas"}
{"url": "https://en.wikipedia.org/wiki?curid=3087", "text": "Alexandria, West Dunbartonshire\n\nAlexandria (, ) is a town in West Dunbartonshire, Scotland. The town is situated on the River Leven, four miles (6 km) north-west of Dumbarton.\n\nIn 2001, the population of the town was 13,444. It is the largest town in the Vale of Leven, the others being Balloch, Bonhill, Jamestown and Renton; their combined population is over 20,000.\n\nThe town's traditional industries, most importantly cotton manufacturing, bleaching and printing, have been phased out. The town was redeveloped in the 1970s with a new town centre layout and traffic system. Local landmarks include Christie Park, and the Fountain in the town centre. Lomond Galleries on North Main Street is a former car factory with an impressive dome and an even more impressive marble entrance hall and staircase. It was originally built in 1906 as the Argyll Motor Works, for Argyll Motors Ltd. A carving above the entrance shows one of the company's cars. After the car production ceased in 1914 it was used by the Admiralty for the manufacture of torpedoes, which were test-fired in Loch Long, and in the early 1970s was the scene of the Plessey sit-in. \n\nAlexandria sits on the former A82 main road between Glasgow and Loch Lomond. There are regular bus services on the route and the town has a railway station on the rail line between Balloch and Glasgow Queen Street.\n\nThe town is reputed to be the only UK town with a railway station and a pub in the middle of a roundabout. A. J. Cronin's uncle owned a pub in Bridge Street. Alexandria Library is located on Gilmour Street. \n\nThe town is home to Vale of Leven football club, who play at Millburn Park. The club were a dominant force in early Scottish football history, winning the Scottish Cup in 1877, 1878 and 1879, and were founder members of the Scottish Football League.\n", "id": "3087", "title": "Alexandria, West Dunbartonshire"}
{"url": "https://en.wikipedia.org/wiki?curid=3088", "text": "Alexandria, Romania\n\nAlexandria () is the capital city of the Teleorman County, Romania. It is located south-west of Bucharest, towards the Bulgarian border. The city is situated on the Vedea River and has 45,434 inhabitants.\n\nAlexandria was named after its founder, Alexandru II Ghica, prince of Wallachia from 1834 to 1842.\nIts population in 1900 was 1,675. Its chief trade then was in grain, dispatched by rail to the Danubian port of Zimnicea, or by river to Giurgiu.\nIn 1989, the city had over 63,000 people and more than six large factories.\n\n", "id": "3088", "title": "Alexandria, Romania"}
{"url": "https://en.wikipedia.org/wiki?curid=3089", "text": "Angela Vincent\n\nAngela Vincent (born 1942) is a professor at Somerville College of Oxford University. She is the head of a research group, which is located in the West Wing within the John Radcliffe Hospital, and works on a wide range of biological disciplines encompassing molecular biology, biochemistry, cellular immunology and intracellular neurophysiology. The group's research is focused on autoimmune and genetic disorders of the neuromuscular junction, peripheral nerves and more recently the exciting field of central nervous system diseases. The principal autoimmune diseases studied are myasthenia gravis, the Lambert-Eaton myasthenic syndrome, limbic encephalitis, other types of autoimmune encephalitis and acquired neuromyotonia.\n\nHer contributions are mainly on the roles of antibodies directed against ion channels, proteins complexed to ion channels, such as LGI1, CASPR2 and Contactin-2, within neurons, glia and the nerve-muscle junction in the pathogenesis of above-mentioned diseases.\n\nShe has demonstrated that transfer of these antibodies across the placenta from the pregnant woman to the fetus in utero can cause developmental abnormalities. She has also worked on the principal gene mutations causing neuromuscular diseases.\n\nIn 2009 she presented the Leslie Oliver Oration at Queen's Hospital. In 2011, she was made a FRS.\n\n", "id": "3089", "title": "Angela Vincent"}
{"url": "https://en.wikipedia.org/wiki?curid=3090", "text": "Arithmetic–geometric mean\n\nIn mathematics, the arithmetic–geometric mean (AGM) of two positive real numbers and is defined as follows:\n\nFirst, compute the arithmetic and geometric means of and , calling them and respectively (the latter is the principal square root of the product ):\n\nThen, use iteration, with taking the place of and taking the place of . In this way, two sequences and are defined:\n\nThese two sequences converge to the same number, which is the arithmetic–geometric mean of and ; it is denoted by , or sometimes by .\n\nThis can be used for algorithmic purposes as in the AGM method, which makes it possible to construct fast algorithms for calculating exponential and trigonometric functions, as well as some mathematical constants, in particular, to quickly compute formula_3.\n\nTo find the arithmetic–geometric mean of and , first calculate their arithmetic and geometric means, thus:\n\nand then iterate as follows:\n\nThe first five iterations give the following values:\n\nAs can be seen, the number of digits in agreement (underlined) approximately doubles with each iteration. The arithmetic–geometric mean of 24 and 6 is the common limit of these two sequences, which is approximately 13.4581714817256154207668131569743992430538388544.\n\nThe first algorithm based on this sequence pair appeared in the works of Lagrange. Its properties were further analyzed by Gauss.\n\nThe geometric mean of two positive numbers is never bigger than the arithmetic mean (see inequality of arithmetic and geometric means); as a consequence, is an increasing sequence, is a decreasing sequence, and . These are strict inequalities if .\n\nIf , then .\n\nThere is an integral-form expression for :\n\nwhere is the complete elliptic integral of the first kind:\n\nIndeed, since the arithmetic–geometric process converges so quickly, it provides an efficient way to compute elliptic integrals via this formula. In engineering, it is used for instance in elliptic filter design.\n\nThe reciprocal of the arithmetic–geometric mean of 1 and the square root of 2 is called Gauss's constant, after Carl Friedrich Gauss.\n\nThe geometric–harmonic mean can be calculated by an analogous method, using sequences of geometric and harmonic means. The arithmetic–harmonic mean can be similarly defined, but takes the same value as the geometric mean.\n\nThe arithmetic–geometric mean can be used to compute – among others – logarithms, complete and incomplete elliptic integrals of the first and second kind, and Jacobi elliptic functions.\n\nFrom the inequality of arithmetic and geometric means we can conclude that:\n\nand thus\n\nthat is, the sequence is nondecreasing.\n\nFurthermore, it is easy to see that it is also bounded above by the larger of and (which follows from the fact that both the arithmetic and geometric means of two numbers lie between them). Thus, by the monotone convergence theorem, the sequence is convergent, so there exists a such that:\n\nHowever, we can also see that:\n\nand so:\n\nQ.E.D.\n\nThis proof is given by Gauss.\nLet\n\nChanging the variable of integration to formula_15, where\n\ngives\n\nThus, we have\n\nThe last equality comes from observing that formula_19.\n\nFinally, we obtain the desired result\n\nGauss noticed that the sequences\n\nas\n\nhave the same limit:\nthe arithmetic–geometric mean, \"agm\".\n\nIt is possible to use this fact to construct fast algorithms for calculating elementary transcendental functions and some classical constants, in particular, the constant .\n\nFor example, according to the Gauss–Salamin formula:\n\nwhere\n\nwhich can be computed without loss of precision using\n\nTaking formula_27 , yields the \"agm\",\nwhere is a complete elliptic integral of the first kind,\nThat is to say that this quarter period may be efficiently computed through the \"agm\",\n\nUsing this property of the AGM along with the ascending transformations of Landen, Richard Brent suggested the first AGM algorithms for the fast evaluation of elementary transcendental functions (\"e\", cos \"x\", sin \"x\"). Subsequently, many authors went on to study the use of the AGM algorithms.\n\n\n\n", "id": "3090", "title": "Arithmetic–geometric mean"}
{"url": "https://en.wikipedia.org/wiki?curid=3092", "text": "Akira Toriyama\n\nHe earned the 1981 Shogakukan Manga Award for best \"shōnen\" or \"shōjo\" manga with \"Dr. Slump\", and it went on to sell over 35 million copies in Japan. It was adapted into a successful anime series, with a second anime created in 1997, 13 years after the manga ended. His next series, \"Dragon Ball\", would become one of the most popular and successful manga in the world. Having sold more than 240 million copies worldwide, it is the third best-selling manga of all time and is considered to be one of the main reasons for the period when manga circulation was at its highest in the mid-1980s and mid-1990s. Overseas, \"Dragon Ball\"s anime adaptations have been more successful than the manga and are credited with boosting anime's popularity in the Western world.\n\nAkira Toriyama was born in Nagoya, Aichi, Japan. He has recalled that when he was in elementary school all of his classmates drew, imitating anime and manga, as a result of not having many forms of entertainment. He believes that he began to advance above everyone else when he started drawing pictures of his friends, and after winning a prize at the local art studio for a picture of \"One Hundred and One Dalmatians\", began to think \"art was fun\". Toriyama has a love of cars and motorcycles, something he inherited from his father who used to race motorbikes and operated an auto repair business for a brief time.\n\nBefore becoming a manga artist, he worked at an advertising agency in Nagoya designing posters for three years. After quitting his previous job, Toriyama entered the manga industry by submitting a work to an amateur contest in a \"Jump\" magazine in order to win the prize money. While it did not win, Kazuhiko Torishima, who would later become his editor, contacted him and gave him encouragement. His debut came later in 1978 with the story \"Wonder Island\", which was published in \"Weekly Shōnen Jump\". However, he did not rise to popularity until the comedy series \"Dr. Slump\", which was serialized in \"Weekly Shōnen Jump\" from 1980 to 1984. It follows the adventures of a perverted professor and his small but super-strong robot Arale. He began the series at age 25 while living at home with his parents, but when the series ended in 1984 he was a \"manga superstar\". In 1981, \"Dr. Slump\" earned him the Shogakukan Manga Award for best \"shōnen\" or \"shōjo\" manga series of the year. A very successful anime adaptation aired on TV from 1981 to 1986, with a remake series airing from 1997 to 1999. By 2008, the manga had sold over 35 million copies in Japan.\n\nIn 1984, \"Weekly Shōnen Jump\" began serializing Toriyama's \"Dragon Ball\", which became an instant hit. To date it has sold over 156 million copies in Japan alone, making it Shueisha's second best-selling manga of all time. It began as an adventure/gag manga but later turned into a martial arts fighting series, considered by many to be the \"most influential \"shōnen\" manga\". \"Dragon Ball\" was one of the main reasons for the magazine's circulation hitting a record high of 6.53 million copies (1995). The series' success encouraged Toriyama to continue working on it from 1984 to 1995. At the series' end, Toriyama said that he asked everyone involved to let him end the manga, so he could \"take some new steps in life\". During that 11-year period, he produced 519 chapters that were collected into 42 volumes. Moreover, the success of the manga led to five anime adaptations, several animated movies, numerous video games, and mega-merchandising. The third anime adaptation, \"Dragon Ball GT\", was not based on his manga; however, Toriyama was still involved in coming up with the name and designing the main cast. Although the fifth, \"Dragon Ball Super\", is also not based on the manga, Toriyama is credited with its story and character designs. Aside from its popularity in Japan, \"Dragon Ball\" was successful internationally as well, including in Europe and North America, with a total of 240 million copies of the manga sold worldwide.\n\nToriyama's design sense led to a position designing characters for the popular \"Dragon Quest\" series of role-playing video games (formerly called \"Dragon Warrior\" in North America). He has also served as the character designer for the Super Famicom RPG \"Chrono Trigger\" and for the fighting games \"Tobal No. 1\" and \"Tobal 2\" for the PlayStation.\n\nToriyama's own home studio in Kiyosu is called Bird Studio, which is a play on his name; meaning \"bird\". Toriyama does nearly all of the work at Bird Studio himself, and even when he employed an assistant (until 1995, and only one at a time, which is itself rare for manga artists), the assistant did mostly backgrounds. The studio founded in 1983 has produced occasional one-shots, or stand-alone manga that are not serialized, and some other design work. Toriyama's manga after \"Dragon Ball\" tend to be short (100–200-page) stories, including \"Cowa!\", \"Kajika\", and \"Sand Land\".\n\nOn December 6, 2002, Toriyama made his only promotional appearance in the United States at the launch of \"Weekly Shōnen Jump\"'s North American counterpart, \"Shonen Jump\", in New York City. Toriyama's \"Dragon Ball\" and \"Sand Land\" were published in the magazine in the first issue, which also included an in-depth interview with him.\n\nOn March 27, 2005, CQ Motors began selling an electric car designed by Toriyama. The one-person QVOLT is part of the company's Choro-Q series of small electric cars, with only 9 being produced. It costs 1,990,000 yen (about $19,000 US), has a top speed of and is available in 5 colors. Designed to look like an American street rod, the QVOLT has a top and a door that are both opened by pulling a cord. Toriyama stated that the car took over a year to design, \"but due to my genius mini-model construction skills, I finally arrived at the end of what was a very emotional journey.\"\n\nHe worked on a 2006 one-shot called \"Cross Epoch\", in cooperation with \"One Piece\" creator Eiichiro Oda. The story is a short crossover that presents characters from both \"Dragon Ball\" and \"One Piece\". Toriyama was the character designer and artist for the 2006 Mistwalker Xbox 360 exclusive RPG \"Blue Dragon\", working with Hironobu Sakaguchi and Nobuo Uematsu, both of whom he had previously worked with on \"Chrono Trigger\". He announced that his help with the making of the \"Blue Dragon\" anime might very well be his final work in anime. In his own words, he said:\nIn 2008, he collaborated with Masakazu Katsura, his good friend and creator of \"I\"s\" and \"Zetman\", for the \"Jump SQ\" one-shot \"Sachie-chan Good!!\". It was published in North America in the free SJ Alpha Yearbook 2013, which was mailed out to annual subscribers of the digital manga magazine \"Shonen Jump Alpha\" in December 2012. The two worked together again in 2009, for the three-chapter one-shot \"Jiya\" in \"Weekly Young Jump\".\n\nAvex Trax commissioned Toriyama to draw a portrait of pop singer Ayumi Hamasaki; it was printed on the CD of her 2009 single \"Rule/Sparkle\", which was used as the theme song to the American live-action \"Dragonball Evolution\" film. Also in 2009, Toriyama drew a manga titled \"Delicious Island's Mr. U\" for Anjō's Rural Society Project, a nonprofit environmental organization that teaches the importance of agriculture and nature to young children. They originally asked him to do the illustrations for a pamphlet, but Toriyama liked the project and decided to expand it into a story. It is included in a booklet about environmental awareness that is distributed by the Anjō city government.\n\nHe collaborated with \"Shōnen Jump\" to create a video to raise awareness and support for those affected by the 2011 Tōhoku earthquake and tsunami on March 11, 2011. \"\", the series' first theatrical film in 17 years, opened on March 30, 2013 and marks the first time Toriyama has been deeply involved in an animation, in this case as early as the screenwriting stages. A special \"dual ticket\" that can be used to see both \"Battle of Gods\" and \"\" was created with new art by both Toriyama and Eiichiro Oda, creator of \"One Piece\".\n\nHis one-shot \"Kintoki\", originally published in 2010, was released in North America's online manga anthology \"Weekly Shonen Jump\" on January 28, 2013. On March 27, the \"Akira Toriyama: The World of \"Dragon Ball\"\" exhibit opened at the Takashimaya department store in Nihonbashi, garnering 72,000 visitors in its first nineteen days. The exhibit is separated into seven areas. The first provides a look at the series' history, the second shows the 400-plus characters from the series, the third displays Toriyama's manga manuscripts from memorable scenes, the fourth shows special color illustrations, the fifth displays rare \"Dragon Ball\"-related materials, the sixth includes design sketches and animation cels from the anime, and the seventh screens \"Dragon Ball\"-related videos. It was there until April 15, when it moved to Osaka from April 17 to 23, and ended in Toriyama's native Nagoya from July 27 to September 1. To celebrate the 45th anniversary of \"Weekly Shōnen Jump\", Toriyama launched a new series in its July 13 issue titled \"Jaco the Galactic Patrolman\". Viz Media began serializing it in English in their digital \"Weekly Shonen Jump\" magazine, beginning just two days later.\n\nThe follow-up film to \"Battle of Gods\", \"\" released on April 18, 2015, features even more contributions from Toriyama. As of June 2015, he currently contributes to \"Dragon Ball Super\".\n\nToriyama admires Osamu Tezuka's \"Astro Boy\" and was impressed by Walt Disney's \"One Hundred and One Dalmatians\", which he remembers for its high-quality animation. Jackie Chan's early movies also had a noticeable influence on his stories, particularly Chan's martial arts comedy film \"Drunken Master\". Toriyama stated he was influenced by animator Toyoo Ashida and the anime television series adaptation of his own \"Dragon Ball\"; from which he learned that separating colors instead of blending them makes the art cleaner and coloring illustrations easier. It was Toriyama's sound effects in \"Mysterious Rain Jack\" that caught the eye of Kazuhiko Torishima, who explained that usually they are written in \"katakana\", but Toriyama used the alphabet which he found refreshing. In his opinion, Torishima stated that Toriyama excels in black and white, utilizing black areas, as a result of not having had the money to buy screentone when he started drawing manga.\n\n\"Dr. Slump\" is mainly a comedy series, filled with puns, toilet humor and sexual innuendos. But it also contained many science fiction elements; aliens, anthropomorphic characters, time travel, and parodies of works such as Godzilla, \"Star Wars\" and \"Star Trek\". Toriyama also included many real-life people in the series, such as his assistants, wife and colleagues (such as Masakazu Katsura), but most notably his editor Kazuhiko Torishima as the series' main antagonist, Dr. Mashirito.\n\nWhen \"Dragon Ball\" began, it was loosely based on the classic Chinese novel \"Journey to the West\", with Goku being Sun Wukong and Bulma as Xuanzang. Toriyama continued to use his characteristic comedic style in the beginning, but over the course of time this slowly changed, with him turning the series into a \"nearly-pure fighting manga\" later on. He did not plan out in advance what would happen in the series, instead choosing to draw as he went. This, coupled with him simply forgetting things he had already drawn, caused him to find himself in situations that he had to write himself out of. In a rare 2013 interview, commenting on \"Dragon Ball\"'s global success, Toriyama admitted, \"Frankly, I don't quite understand why it happened. While the manga was being serialized, the only thing I wanted as I kept drawing was to make Japanese boys happy.\" Speaking of his manga in general, he said, \"The role of my manga is to be a work of entertainment through and through. I dare say I don't care even if [my works] have left nothing behind, as long as they have entertained their readers.\"\n\nToriyama was commissioned to illustrate the characters and monsters for the first \"Dragon Quest\" video game (1986) in order to separate it from other role-playing games of the time. He has since worked on every title in the series. For each game Yuji Horii first sends rough sketches of the characters with their background information to Toriyama, who then re-draws them. Lastly, Horii approves the finished work. Toriyama explained that for video games, because the sprites are so small, as long as they have a distinguishing feature so people can tell which character it is, he can make complex designs without concern of having to reproduce it like he usually would in manga. Besides the character and monster designs, Toriyama also does the games' packaging art and, for \"\", the boats and ships. The series' Slime character, which has become a sort of mascot for the franchise, is considered to be one of the most recognizable figures in gaming.\n\nManga critic Jason Thompson declared Toriyama's art influential, saying that his \"extremely personal and recognizable style\" was a reason for \"Dragon Ball\"'s popularity. He points out that the popular \"shōnen\" manga of the late 1980s and early 1990s had \"manly\" heroes, such as \"City Hunter\" and \"Fist of the North Star\", whereas \"Dragon Ball\" starred the cartoonish and small Goku, thus starting a trend that Thompson says continues to this day. Toriyama himself said he went against the normal convention that the strongest characters should be the largest in terms of physical size, designing many of the series' most powerful characters with small statures. Thompson concluded his analysis by saying that only Akira Toriyama drew like this at the time and that \"Dragon Ball\" is \"an action manga drawn by a gag manga artist.\" However, James S. Yadao, author of \"The Rough Guide to Manga\", points out that an art shift does occur in the series, as the characters gradually \"lose the rounded, innocent look that [Toriyama] established in \"Dr. Slump\" and gain sharper angles that leap off the page with their energy and intensity.\"\n\nMany manga artists have named Toriyama and \"Dragon Ball\" as influences, including \"One Piece\" author Eiichiro Oda, \"Naruto\" creator Masashi Kishimoto, \"Fairy Tail\" and \"Rave\" author Hiro Mashima, \"Venus Versus Virus\" author Atsushi Suzumi, \"Bleach\" creator Tite Kubo, \"Black Cat\" author Kentaro Yabuki, and \"Mr. Fullswing\" author Shinya Suzuki. In 2008, Oricon conducted a poll of people's favorite manga artists, with Toriyama coming in second, only behind \"Nana\" author Ai Yazawa. However, he was number one among male respondents and among those over 30 years of age. They held a poll on the Mangaka that Changed the History of Manga in 2010, \"mangaka\" being the Japanese word for a manga artist. Toriyama came in second, after only Osamu Tezuka, due to his works being highly influential and popular worldwide. Toriyama won the Special 40th Anniversary Festival Award at the 2013 Angoulême International Comics Festival, honoring his years in cartooning. He actually received the most votes for the festival's Grand Prix de la ville d'Angoulême award that year; however, the selection committee chose Willem as the recipient. Due to his video game design work, IGN named Toriyama number 74 on their list of the Top 100 Game Creators of All Time.\n\n\n\n\n\n", "id": "3092", "title": "Akira Toriyama"}
{"url": "https://en.wikipedia.org/wiki?curid=3093", "text": "Epsilon Ursae Majoris\n\nEpsilon Ursae Majoris (ε Ursae Majoris, abbreviated Epsilon UMa, ε UMa), also named Alioth, is (despite being designated 'epsilon') the brightest star in the constellation of Ursa Major, and at magnitude 1.76 is the thirty-first-brightest star in the sky.\n\nIt is the star in the tail of the bear closest to its body, and thus the star in the handle of the Big Dipper (Plough) closest to the bowl. It is also a member of the large and diffuse Ursa Major moving group. Historically, the star was frequently used in celestial navigation in the maritime trade, because it is listed as one of the 57 navigational stars.\n\nAccording to \"Hipparcos\", Alioth is from the Sun. Its spectral type is A1p; the \"p\" stands for \"peculiar\", as the spectrum of its light is characteristic of an Alpha2 Canum Venaticorum variable. Alioth, as a representative of this type, may harbor two interacting processes. First, the star's strong magnetic field separating different elements in the star's hydrogen 'fuel'. In addition, a rotation axis at an angle to the magnetic axis may be spinning different bands of magnetically sorted elements into the line of sight between Alioth and the Earth. The intervening elements react differently at different frequencies of light as they whip in and out of view, causing Alioth to have very strange spectral lines that fluctuate over a period of 5.1 days. The \"kB9\" suffix to the spectral type indicates that the calcium K line is present and representative of a B9 spectral type even though the rest of the spectrum indicates A1.\n\nWith Alioth, the rotational and magnetic axes are at almost 90 degrees to one another. Darker (denser) regions of chromium form a band at right angles to the equator.\n\nA recent study suggests Alioth's 5.1-day variation may be due to a substellar object of about 14.7 Jupiter masses in an eccentric orbit (e=0.5) with an average separation of 0.055 astronomical units.\n\nAlioth has a relatively weak magnetic field, 15 times weaker than α CVn, but it is still 100 times stronger than that of the Earth.\n\n\"ε Ursae Majoris\" (Latinised to \"Epsilon Ursae Majoris\") is the star's Bayer designation. \n\nThe traditional name \"Alioth\" comes from the Arabic \"alyat\" (fat tail of a sheep). In 2016, the International Astronomical Union organized a Working Group on Star Names (WGSN) to catalog and standardize proper names for stars. The WGSN's first bulletin of July 2016 included a table of the first two batches of names approved by the WGSN; which included \"Alioth\" for this star.\n\nThis star was known to the Hindus as \"Añgiras\", one of the Seven Rishis.\n\nIn Chinese, (), meaning \"Northern Dipper\", refers to an asterism consisting of Epsilon Ursae Majoris, Alpha Ursae Majoris, Beta Ursae Majoris, Gamma Ursae Majoris, Delta Ursae Majoris, Zeta Ursae Majoris and Eta Ursae Majoris. Consequently, Epsilon Ursae Majoris itself is known as (, ) and (, ).\n\nUSS Allioth (AK-109) was a United States Navy Crater class cargo ship named after the star.\n\n", "id": "3093", "title": "Epsilon Ursae Majoris"}
{"url": "https://en.wikipedia.org/wiki?curid=3095", "text": "Amiga 500\n\nThe Amiga 500, also known as the A500 (or its code name \"Rock Lobster\"), is the first low-end Commodore Amiga 16/32-bit multimedia home/personal computer. It was announced at the winter Consumer Electronics Show in January 1987 - at the same time as the high-end Amiga 2000 - and competed directly against the Atari 520ST. Before Amiga 500 was shipped, Commodore suggested that the list price of the Amiga 500 was without a monitor. At delivery in October 1987, Commodore announced that the Amiga 500 would carry a list price. In Europe, the Amiga 500 was released in May 1987. In the Netherlands, the A500 was available from April 1987 for a list price of 1499 HFL (730 USD in 1987).\n\nThe Amiga 500 represents a return to Commodore's roots by being sold in the same mass retail outlets as the Commodore 64 - to which it was a spiritual successor - as opposed to the computer-store-only Amiga 1000, as well as being another computer whose keyboard is included just above in the same case.\n\nThe original Amiga 500 proved to be Commodore’s best-selling Amiga model, enjoying particular success in Europe. Although popular with hobbyists, arguably its most widespread use was as a gaming machine, where its advanced graphics and sound were of significant benefit. Amiga 500 eventually sold 6 million units worldwide.\n\nIn October 1989, the Amiga 500 dropped its price from £499 GBP to £399 and was bundled with the \"Batman Pack\" in the United Kingdom. This price drop helped Commodore to sell more than 1 million Amiga 500s in 1989.\n\nIn late 1991, an enhanced model known as the Amiga 500+ replaced the original 500 in some markets, it was bundled with the \"Cartoon Classics\" pack in the United Kingdom at 399 GBP.\n\nThe Amiga 500 series was discontinued in mid-1992 and replaced by the similarly specified and priced Amiga 600, although this new machine had originally been intended as a much cheaper model, which would have been the A300. In late 1992, Commodore released the “next-generation” Amiga 1200, a machine closer in concept to the original Amiga 500, but featuring significant technical improvements. Despite this, neither the A1200 nor the A600 replicated the commercial success of its predecessor, as by this time, the popular market was definitively shifting from the home computer platforms of the past to commodity Wintel PCs and the new \"low-cost\" Macintosh Classic, LC and IIsi models.\n\nOutwardly resembling the Commodore 128, the Amiga 500 houses the keyboard and CPU in one shell, unlike the Amiga 1000. It utilizes a Motorola 68000 microprocessor running at (NTSC) or (PAL). The CPU is 32-bit internally, but uses a 16-bit data bus and 24-bit address bus, providing a maximum of 16 MB of address space.\n\nThe earliest Amiga 500 models use nearly the same Original Amiga chipset as the Amiga 1000. So graphics can be displayed in multiple resolutions and color depths, even on the same screen. Resolutions vary from 320×200 (up to 32 colors) to 640×200 (up to 16 colors) for NTSC (704×484 overscan) and 320×256 to 640×256 for PAL (704×576 overscan.) The system uses planar graphics, with up to five bitplanes (four in high resolution) allowing 2-, 4-, 8-, 16-, and 32-color screens, from a palette of 4096 colors. Two special graphics modes are also available: Extra HalfBrite, which uses a 6th bitplane as a mask to cut the brightness of any pixel in half (resulting in 32 arbitrary colors plus 32 more colors set at half the value of the first 32), and which allows all 4096 colors to be used on screen simultaneously. Later revisions of the chipset are PAL/NTSC switchable in software.\n\nThe sound chip produces four hardware-mixed channels, two to the left and two to the right, of 8-bit PCM at a sampling frequency of up to . Each hardware channel has its own independent volume level and sampling rate, and can be designated to another channel where it can modulate both volume and frequency using its own output. With DMA disabled it's possible to output with a sampling frequency up to . There's a common trick to output sound with 14-bit precision that can be combined to output 14-bit sound.\n\nThe stock system comes with AmigaOS version 1.2 or 1.3 and of chip RAM (150 ns access time), one built-in double-density standard floppy disk drive that is completely programmable and can read IBM PC disks, standard Amiga disks, and up to using custom-formatting drivers.\n\nDespite the lack of Amiga 2000-compatible internal expansion slots, there are many ports and expansion options. There are two DE9M Atari joystick ports for joysticks or mice, stereo audio (RCA connectors 1 V p-p). There is a floppy drive port for daisy-chaining up to three extra floppy disk drives via an DB23F connector. The then-standard RS-232 serial port (DB25M) and Centronics parallel port (DB25F) are also included. The power supply is (, ). \nThe system displays video in analog RGB PAL or NTSC through a proprietary DB23M connector and in NTSC mode the line frequency is HSync for standard video modes, which is compatible with NTSC television and CVBS/RGB video, but out of range for most VGA-compatible monitors, while a multisync monitor is required for some of the higher resolutions. This connection can also be genlocked to an external video signal. The system was bundled with an RF adapter to provide output on televisions with a coaxial RF input, while monochrome composite video is available via an RCA connector (also coaxial). There is also a Zorro II bus expansion on the left side (behind a plastic cover). Peripherals such as a hard disk drive can be added via the expansion slot and are configured automatically by the Amiga's AutoConfig standard, so that multiple devices do not conflict with each other. Up to of “fast RAM\" can be added using the side expansion slot.\n\nThe Amiga 500 has a \"trap-door\" slot on the underside for an upgrade of of RAM. The extra RAM is classified as \"fast\" RAM, but is sometimes referred to as \"slow\" RAM since due to the design of the expansion bus it is actually on the chipset bus. Such upgrades usually include a battery-backed real-time clock. All versions of the A500 can have the additional RAM configured as chip RAM by a simple hardware modification, which involves fitting a later model (8372A) Agnus chip. Likewise, all versions of the A500 can be upgraded to chip RAM by fitting the chip and adding additional memory.\n\nThe Amiga 500 also sports an unusual feature for a budget machine, socketed chips, which allow easy replacement of defective chips. The CPU can be directly upgraded to a 68010 or to a 68020, 68030, or 68040 via the side expansion slot, or by removing the CPU and plugging a CPU expansion card in the CPU socket. (Though the latter required opening the computer and voiding any remaining warranty). In fact, all the custom chips can be upgraded to the Amiga Enhanced Chip Set (ECS) versions.\n\nThe case is made from ABS plastics which may become brown with time. This may be reversed by using the public domain chemical mix \"Retr0bright\", though without a clearcoat to block oxygen, the brown colouring will return.\n\nWhenever the computer is powered on a self diagnostic test is run that will show any failure with a specific colour where Green means no chip RAM found or is damaged, Red means bad kickstart-ROM, Yellow means the CPU has crashed (no trap routine or trying to run bad code) or a bad Zorro expansion card.\nThe keyboard LED uses blink codes: one blink means the keyboard ROM has a checksum error, two blinks means RAM failure, three blinks means watchdog timer failure. Using Caps Lock key and getting a response means CIA and the CPU works. Note in EVERY case of colours or blinking LEDs there is NO guarantee that ANY of it is accurate. Remember when the diagnostic codes are triggered it means the computer has some kind of fault and it can easily mis-interpret the fault and give false readings. For example, if the screen flashes green it can mean the Agnus is bad, the Agnus socket is bad, the logic connected to the Agnus is bad, the logic connected to the CPU is bad, the logic connected to the RAM is bad, a connection between CPU and/or logic and/or Agnus and/or Chip RAM is bad and/or some/all of the chip RAM is faulty etc. etc. Many of the issues with Amigas are caused by damage from corrosion or poor repair skills, especially the A500+ which has a Ni-Cad battery fitted and is always corroded if the battery has not been removed. Likewise a corroded battery on an A501 can cause faults on the A500 motherboard if the corrosion is very bad and has spread to the motherboard. The self-test Chip RAM check is *very* brief and simplistic and all the other tests are minimalistic to minimize the start-up time (as documented in the Amiga Hardware Manual and many other official Commodore technical documents) so there is no guarantee that any of the diagnostic colours are 100% accurate.\n\n\nMax 6 bpp. The Amiga could show multiple resolution modes at the same time, splitting the screen vertically. An additional mode called Hold-And-Modify (HAM) makes it possible to utilize over a wide span. This works by letting each pixel position use the previous RGB value and modify one of the red, green or blue values to a new 4-bit value. This will cause some negligible colour artifacts however.\n\n\n\nA popular expansion for the Amiga 500 was the Amiga 501 circuit board that can be installed underneath the computer behind a plastic cover. It contains RAM configured by default as \"Slow RAM\" or \"trap-door RAM\" and a battery-backed real-time clock (RTC). However, the RAM is pseudo-fast RAM, only accessible by the processor, but still as slow as chip RAM. The motherboard can be modified to relocate the trap-door RAM to the chip memory pool, provided a compatible Agnus chip is fitted on the motherboard.\n\n\n", "id": "3095", "title": "Amiga 500"}
{"url": "https://en.wikipedia.org/wiki?curid=3100", "text": "Aga\n\nAga or AGA may refer to:\n\nIn general, \"Aga\" has historically been used in the Middle East as a term of respect for dignitaries or wealthy people.\n\n\n\n\n\n\n\n\n", "id": "3100", "title": "Aga"}
{"url": "https://en.wikipedia.org/wiki?curid=3104", "text": "Amiga 1000\n\nThe Commodore Amiga 1000, also known as the A1000 and originally simply as the Amiga, is the first personal computer released by Commodore International in the Amiga line. It combines the 16/32-bit Motorola 68000 CPU which was powerful by 1985 standards with one of the most advanced graphics and sound systems in its class, and runs a preemptive multitasking operating system that fits into of read-only memory and shipped with 256 kB of DRAM. The primary memory can be expanded internally with a manufacturer supplied 256 kB module for a total of 512 kB of DRAM. Using the external slot the primary memory can be expanded up to \n\nThe A1000 has a number of characteristics that distinguish it from later Amiga models: It is the only model to feature the short-lived Amiga check-mark logo on its case, the majority of the case is elevated slightly to give a storage area for the keyboard when not in use (a \"keyboard garage\"), and the inside of the case is engraved with the signatures of the Amiga designers (similar to the Macintosh); including Jay Miner and the paw print of his dog Mitchy. The A1000's case was designed by Howard Stolz. As Senior Industrial Designer at Commodore, Stolz was the mechanical lead and primary interface with Sanyo in Japan, the contract manufacturer for the A1000 casing.\n\nThe Amiga 1000 was manufactured in two variations: One uses the NTSC television standard and the other uses the PAL television standard. The NTSC variant was the initial model manufactured and sold in North America. The later PAL model was manufactured in Germany and sold in countries using the PAL television standard. The first NTSC systems lacks the EHB video mode which is present in all later Amiga models.\n\nBecause AmigaOS was rather buggy at the time of the A1000's release, the OS was not placed in ROM then. Instead, the A1000 includes a daughterboard with 256 kB of RAM, dubbed the \"writable control store\" (WCS), into which the core of the operating system is loaded from floppy disk (this portion of the operating system is known as the \"Kickstart\"). The WCS is write-protected after loading, and system resets do not require a reload of the WCS. In Europe, the WCS was often referred to as WOM (Write Once Memory), a play on the more conventional term \"ROM\" (read-only memory).\n\nThe preproduction Amiga (which was codenamed \"Velvet\") released to developers in early 1985 contained of RAM with an option to expand it to Commodore later increased the system memory to due to objections by the Amiga development team. The names of the custom chips were different; Denise and Paula were called Daphne and Portia respectively. The casing of the preproduction Amiga was almost identical to the production version: the main difference being an embossed Commodore logo in the top left corner. It did not have the developer signatures or the carry handle. \n\nThe Amiga 1000 has a Motorola 68000 CPU running at 7.15909 MHz (on NTSC systems) or 7.09379 MHz (PAL systems), precisely double the video color carrier frequency for NTSC or 1.6 times the color carrier frequency for PAL. The system clock timings are derived from the video frequency, which simplifies glue logic and allows the Amiga 1000 to make do with a single crystal. In keeping with its video game heritage, the chipset was designed to synchronize CPU memory access and chipset DMA so the hardware runs in real time without wait-state delays.\n\nThough most units were sold with an analog RGB monitor, the A1000 also has a built-in composite video output which allows the computer to be connected directly to some monitors other than their standard RGB monitor. The A1000 also has a \"TV MOD\" output, into which an RF Modulator can be plugged, allowing connection to a TV that was old enough not to even have a composite video input.\n\nThe original 68000 CPU can be directly replaced with a Motorola 68010, which can execute instructions slightly faster than the 68000 but also introduces a small degree of software incompatibility. Third-party CPU upgrades, which mostly fit in the CPU socket, use faster 68020/68881 or 68030/68882 microprocessors and integrated memory. Such upgrades often have the option to revert to 68000 mode for full compatibility. Some boards have a socket to seat the original 68000, whereas the 68030 cards typically come with an on-board 68000.\n\nThe original Amiga 1000 is the only model to have 256 kB of Amiga Chip RAM, which can be expanded to 512 kB with the addition of a daughterboard under a cover in the centre front of the machine. RAM may also be upgraded via official and third-party upgrades, with a practical upper limit of about 9 MB of \"fast RAM\" due to the 68000's 24-bit address bus. This memory is accessible only by the CPU permitting faster code execution as DMA cycles are not shared with the chipset.\n\nThe Amiga 1000 features an 86-pin expansion port (electrically identical to the later Amiga 500 expansion port, though the A500's connector is inverted). This port is utilized by third-party expansions such as memory upgrades and SCSI adaptors. These resources are handled by the Amiga Autoconfig standard. Other expansion options are available including a bus expander which provides two Zorro-II slots.\n\nIntroduced on July 23, 1985 during a star-studded gala featuring Andy Warhol and Debbie Harry held at the Vivian Beaumont Theater at Lincoln Center in New York City, machines began shipping in September with a base configuration of 256 kB of RAM at the retail price of . A analog RGB monitor was available for around , bringing the price of a complete Amiga system to 1,595 USD. Before the release of the Amiga 500 and Amiga 2000 models in 1987, the A1000 was simply called \"Amiga\".\n\nIn the US, the A1000 was marketed as \"The Amiga from Commodore\", with the Commodore logo omitted from the case. The Commodore branding was retained for the international versions. \n\nAdditionally, the Amiga 1000 was sold exclusively in computer stores in the US rather than the various non computer-dedicated department and toy stores through which the VIC-20 and Commodore 64 were retailed. These measures were an effort to avoid Commodore's \"toy-store\" computer image created during the Tramiel era. \n\nAlong with the operating system, the machine came bundled with a version of AmigaBASIC developed by Microsoft and a speech synthesis library developed by Softvoice, Inc.\n\nMany A1000 owners remained attached to their machines long after newer models rendered the units technically obsolete, and it attracted numerous aftermarket upgrades. Many CPU upgrades that plugged into the Motorola 68000 socket functioned in the A1000. Additionally, a line of products called the \"Rejuvenator\" series allowed the use of newer chipsets in the A1000, and an Australian-designed replacement A1000 motherboard called \"The Phoenix\" utilized the same chipset as the A3000 and added an A2000-compatible video slot and on-board SCSI controller.\n\nIn 1994, as Commodore filed for bankruptcy, \"Byte\" magazine called the Amiga 1000 \"the first multimedia computer... so far ahead of its time that almost nobody—including Commodore's marketing department—could fully articulate what it was all about\".\n\nIn 2006, PC World rated the Amiga 1000 as the 7th greatest PC of all time. In 2007, it was rated by the same magazine as the 37th best tech product of all time.\n\n\n", "id": "3104", "title": "Amiga 1000"}
{"url": "https://en.wikipedia.org/wiki?curid=3107", "text": "Asymptote\n\nIn analytic geometry, an asymptote () of a curve is a line such that the distance between the curve and the line approaches zero as they tend to infinity. Some sources include the requirement that the curve may not cross the line infinitely often, but this is unusual for modern authors. In some contexts, such as algebraic geometry, an asymptote is defined as a line which is tangent to a curve at infinity.\n\nThe word asymptote is derived from the Greek ἀσύμπτωτος (\"asumptōtos\") which means \"not falling together\", from ἀ priv. + σύν \"together\" + πτωτ-ός \"fallen\". The term was introduced by Apollonius of Perga in his work on conic sections, but in contrast to its modern meaning, he used it to mean any line that does not intersect the given curve.\n\nThere are potentially three kinds of asymptotes: \"horizontal\", \"vertical\" and \"oblique\" asymptotes. For curves given by the graph of a function , horizontal asymptotes are horizontal lines that the graph of the function approaches as \"x\" tends to Vertical asymptotes are vertical lines near which the function grows without bound.\n\nMore generally, one curve is a \"curvilinear asymptote\" of another (as opposed to a \"linear asymptote\") if the distance between the two curves tends to zero as they tend to infinity, although the term \"asymptote\" by itself is usually reserved for linear asymptotes.\n\nAsymptotes convey information about the behavior of curves \"in the large\", and determining the asymptotes of a function is an important step in sketching its graph. The study of asymptotes of functions, construed in a broad sense, forms a part of the subject of asymptotic analysis.\n\nThe idea that a curve may come arbitrarily close to a line without actually becoming the same may seem to counter everyday experience. The representations of a line and a curve as marks on a piece of paper or as pixels on a computer screen have a positive width. So if they were to be extended far enough they would seem to merge, at least as far as the eye could discern. But these are physical representations of the corresponding mathematical entities; the line and the curve are idealized concepts whose width is 0 (see Line). Therefore, the understanding of the idea of an asymptote requires an effort of reason rather than experience.\n\nConsider the graph of the function formula_1 shown to the right. The coordinates of the points on the curve are of the form formula_2 where x is a number other than 0. For example, the graph contains the points (1, 1), (2, 0.5), (5, 0.2), (10, 0.1), … As the values of formula_3 become larger and larger, say 100, 1000, 10,000 …, putting them far to the right of the illustration, the corresponding values of formula_4, .01, .001, .0001, …, become infinitesimal relative to the scale shown. But no matter how large formula_3 becomes, its reciprocal formula_6 is never 0, so the curve never actually touches the \"x\"-axis. Similarly, as the values of formula_3 become smaller and smaller, say .01, .001, .0001, …, making them infinitesimal relative to the scale shown, the corresponding values of formula_4, 100, 1000, 10,000 …, become larger and larger. So the curve extends farther and farther upward as it comes closer and closer to the \"y\"-axis. Thus, both the \"x\" and \"y\"-axes are asymptotes of the curve. These ideas are part of the basis of concept of a limit in mathematics, and this connection is explained more fully below.\n\nThe asymptotes most commonly encountered in the study of calculus are of curves of the form . These can be computed using limits and classified into \"horizontal\", \"vertical\" and \"oblique\" asymptotes depending on its orientation. Horizontal asymptotes are horizontal lines that the graph of the function approaches as \"x\" tends to +∞ or −∞. As the name indicate they are parallel to the \"x\"-axis. Vertical asymptotes are vertical lines (perpendicular to the \"x\"-axis) near which the function grows without bound. Oblique asymptotes are diagonal lines so that the difference between the curve and the line approaches 0 as \"x\" tends to +∞ or −∞. More general type of asymptotes can be defined in this case. Only open curves that have some infinite branch, can have an asymptote. No closed curve can have an asymptote.\n\nThe line \"x\" = \"a\" is a \"vertical asymptote\" of the graph of the function if at least one of the following statements is true:\n\nThe function \"ƒ\"(\"x\") may or may not be defined at \"a\", and its precise value at the point \"x\" = \"a\" does not affect the asymptote. For example, for the function\n\nhas a limit of +∞ as , \"ƒ\"(\"x\") has the vertical asymptote , even though \"ƒ\"(0) = 5. The graph of this function does intersect the vertical asymptote once, at (0,5). It is impossible for the graph of a function to intersect a vertical asymptote (or a vertical line in general) in more than one point. Moreover, if a function is continuous at each point where it is defined, it is impossible that its graph does intersect any vertical asymptote.\n\nA common example of a vertical asymptote is the case of a rational function at a point x such that the denominator is zero and the numerator is non-zero.\n\n\"Horizontal asymptotes\" are horizontal lines that the graph of the function approaches as . The horizontal line \"y\" = \"c\" is a horizontal asymptote of the function \"y\" = \"ƒ\"(\"x\") if\nIn the first case, \"ƒ\"(\"x\") has \"y\" = \"c\" as asymptote when \"x\" tends to −∞, and in the second that \"ƒ\"(\"x\") has \"y\" = \"c\" as an asymptote as \"x\" tends to +∞\n\nFor example, the arctangent function satisfies\n\nSo the line is a horizontal tangent for the arctangent when \"x\" tends to −∞, and is a horizontal tangent for the arctangent when \"x\" tends to +∞.\n\nFunctions may lack horizontal asymptotes on either or both sides, or may have one horizontal asymptote that is the same in both directions. For example, the function has a horizontal asymptote at \"y\" = 0 when \"x\" tends both to −∞ and +∞ because, respectively,\n\nWhen a linear asymptote is not parallel to the \"x\"- and \"y\"-axis, it is called an \"oblique asymptote\" or \"slant asymptote\". A function \"f\"(\"x\") is asymptotic to the straight line (\"m\" ≠ 0) if\n\nformula_17\n\nIn the first case the line is an oblique asymptote of \"ƒ\"(\"x\") when \"x\" tends to +∞, and in the second case the line is an oblique asymptote of \"ƒ(x)\" when \"x\" tends to −∞\n\nAn example is ƒ(\"x\") = \"x\" + 1/\"x\", which has the oblique asymptote \"y\" = \"x\" (that is \"m\" = 1, \"n\" = 0) as seen in the limits\n\nThe asymptotes of many elementary functions can be found without the explicit use of limits (although the derivations of such methods typically use limits).\n\nThe oblique asymptote, for the function \"f\"(\"x\"), will be given by the equation \"y\"=\"mx\"+\"n\". The value for \"m\" is computed first and is given by\n\nwhere \"a\" is either formula_22 or formula_23 depending on the case being studied. It is good practice to treat the two cases separately. If this limit doesn't exist then there is no oblique asymptote in that direction.\n\nHaving \"m\" then the value for \"n\" can be computed by\n\nwhere \"a\" should be the same value used before. If this limit fails to exist then there is no oblique asymptote in that direction, even should the limit defining \"m\" exist. Otherwise is the oblique asymptote of \"ƒ\"(\"x\") as \"x\" tends to \"a\".\n\nFor example, the function has\n\nso that is the asymptote of \"ƒ\"(\"x\") when \"x\" tends to +∞.\n\nThe function has\n\nSo does not have an asymptote when \"x\" tends to +∞.\n\nA rational function has at most one horizontal asymptote or oblique (slant) asymptote, and possibly many vertical asymptotes.\n\nThe degree of the numerator and degree of the denominator determine whether or not there are any horizontal or oblique asymptotes. The cases are tabulated below, where deg(numerator) is the degree of the numerator, and deg(denominator) is the degree of the denominator.\n\nThe vertical asymptotes occur only when the denominator is zero (If both the numerator and denominator are zero, the multiplicities of the zero are compared). For example, the following function has vertical asymptotes at \"x\" = 0, and \"x\" = 1, but not at \"x\" = 2.\n\nWhen the numerator of a rational function has degree exactly one greater than the denominator, the function has an oblique (slant) asymptote. The asymptote is the polynomial term after dividing the numerator and denominator. This phenomenon occurs because when dividing the fraction, there will be a linear term, and a remainder. For example, consider the function\nshown to the right. As the value of \"x\" increases, \"f\" approaches the asymptote \"y\" = \"x\". This is because the other term, \"y\" = 1/(\"x\"+1) becomes smaller.\n\nIf the degree of the numerator is more than 1 larger than the degree of the denominator, and the denominator does not divide the numerator, there will be a nonzero remainder that goes to zero as \"x\" increases, but the quotient will not be linear, and the function does not have an oblique asymptote.\n\nIf a known function has an asymptote (such as \"y\"=0 for \"f\"(x)=\"e\"), then the translations of it also have an asymptote.\n\nIf a known function has an asymptote, then the scaling of the function also have an asymptote.\n\nFor example, \"f\"(\"x\")=\"e\"+2 has horizontal asymptote \"y\"=0+2=2, and no vertical or oblique asymptotes.\n\nLet be a parametric plane curve, in coordinates \"A\"(\"t\") = (\"x\"(\"t\"),\"y\"(\"t\")). Suppose that the curve tends to infinity, that is:\nA line ℓ is an asymptote of \"A\" if the distance from the point \"A\"(\"t\") to ℓ tends to zero as \"t\" → \"b\".\n\nFor example, the upper right branch of the curve \"y\" = 1/\"x\" can be defined parametrically as \"x\" = \"t\", \"y\" = 1/\"t\" (where \"t\">0). First, \"x\" → ∞ as \"t\" → ∞ and the distance from the curve to the \"x\"-axis is 1/\"t\" which approaches 0 as \"t\" → ∞. Therefore, the \"x\"-axis is an asymptote of the curve. Also, \"y\" → ∞ as \"t\" → 0 from the right, and the distance between the curve and the \"y\"-axis is \"t\" which approaches 0 as \"t\" → 0. So the \"y\"-axis is also an asymptote. A similar argument shows that the lower left branch of the curve also has the same two lines as asymptotes.\n\nAlthough the definition here uses a parameterization of the curve, the notion of asymptote does not depend on the parameterization. In fact, if the equation of the line is formula_32 then the distance from the point \"A\"(\"t\") = (\"x\"(\"t\"),\"y\"(\"t\")) to the line is given by\nif γ(\"t\") is a change of parameterization then the distance becomes\nwhich tends to zero simultaneously as the previous expression.\n\nAn important case is when the curve is the graph of a real function (a function of one real variable and returning real values). The graph of the function \"y\" = \"ƒ\"(\"x\") is the set of points of the plane with coordinates (\"x\",\"ƒ\"(\"x\")). For this, a parameterization is\nThis parameterization is to be considered over the open intervals (\"a\",\"b\"), where \"a\" can be −∞ and \"b\" can be +∞.\n\nAn asymptote can be either vertical or non-vertical (oblique or horizontal). In the first case its equation is \"x\" = \"c\", for some real number \"c\". The non-vertical case has equation , where \"m\" and formula_36 are real numbers. All three types of asymptotes can be present at the same time in specific examples. Unlike asymptotes for curves that are graphs of functions, a general curve may have more than two non-vertical asymptotes, and may cross its vertical asymptotes more than once.\n\nLet be a parametric plane curve, in coordinates \"A\"(\"t\") = (\"x\"(\"t\"),\"y\"(\"t\")), and \"B\" be another (unparameterized) curve. Suppose, as before, that the curve \"A\" tends to infinity. The curve \"B\" is a curvilinear asymptote of \"A\" if the shortest of the distance from the point \"A\"(\"t\") to a point on \"B\" tends to zero as \"t\" → \"b\". Sometimes \"B\" is simply referred to as an asymptote of \"A\", when there is no risk of confusion with linear asymptotes.\n\nFor example, the function\nhas a curvilinear asymptote , which is known as a \"parabolic asymptote\" because it is a parabola rather than a straight line.\n\nAsymptotes are used in procedures of curve sketching. An asymptote serves as a guide line to show the behavior of the curve towards infinity. In order to get better approximations of the curve, curvilinear asymptotes have also been used although the term asymptotic curve seems to be preferred.\n\nThe asymptotes of an algebraic curve in the affine plane are the lines that are tangent to the projectivized curve through a point at infinity. For example, one may identify the asymptotes to the unit hyperbola in this manner. Asymptotes are often considered only for real curves, although they also make sense when defined in this way for curves over an arbitrary field.\n\nA plane curve of degree \"n\" intersects its asymptote at most at \"n\"−2 other points, by Bézout's theorem, as the intersection at infinity is of multiplicity at least two. For a conic, there are a pair of lines that do not intersect the conic at any complex point: these are the two asymptotes of the conic.\n\nA plane algebraic curve is defined by an equation of the form \"P\"(\"x\",\"y\") = 0 where \"P\" is a polynomial of degree \"n\"\nwhere \"P\" is homogeneous of degree \"k\". Vanishing of the linear factors of the highest degree term \"P\" defines the asymptotes of the curve: setting , if , then the line\nis an asymptote if formula_40 and formula_41 are not both zero. If formula_42 and formula_43, there is no asymptote, but the curve has a branch that looks like a branch of parabola. Such a branch is called a , even when it does not have any parabola that is a curvilinear asymptote. If formula_44 the curve has a singular point at infinity which may have several asymptotes or parabolic branches.\n\nOver the complex numbers, \"P\" splits into linear factors, each of which defines an asymptote (or several for multiple factors). 0ver the reals, \"P\" splits in factors that are linear or quadratic factors. Only the linear factors correspond to infinite (real) branches of the curve, but if a linear factor has multiplicity greater than one, the curve may have several asymptotes or parabolic branches. It may also occur that such a multiple linear factor corresponds to two complex conjugate branches, and does not corresponds to any infinite branch of the real curve. For example, the curve has no real points outside the square formula_45, but its highest order term gives the linear factor \"x\" with multiplicity 4, leading to the unique asymptote \"x\"=0.\n\nThe hyperbola\nhas the two asymptotes\nThe equation for the union of these two lines is\nSimilarly, the hyperboloid\nis said to have the asymptotic cone\n\nThe distance between the hyperboloid and cone approaches 0 as the distance from the origin approaches infinity.\nMore generally, let us consider a surface that has an implicit equation\nformula_51\nwhere the formula_52 are homogeneous polynomials of degree formula_53 and formula_54. Then the equation formula_55 defines a cone which is centered at the origin. It is called an asymptotic cone, because the distance to the cone of a point of the surface tends to zero when the point on the surface tends to infinity.\n\n\n\n", "id": "3107", "title": "Asymptote"}
{"url": "https://en.wikipedia.org/wiki?curid=3110", "text": "Andrew S. Tanenbaum\n\nAndrew Stuart \"Andy\" Tanenbaum (sometimes referred to by the handle ast) (born March 16, 1944) is an American computer scientist and professor emeritus of computer science at the Vrije Universiteit Amsterdam in the Netherlands.\n\nHe is best known as the author of MINIX, a free Unix-like operating system for teaching purposes, and for his computer science textbooks, regarded as standard texts in the field. He regards his teaching job as his most important work. Since 2004 he has operated Electoral-vote.com, a website dedicated to analysis of polling data in federal elections in the United States.\n\nTanenbaum was born in New York City and grew up in suburban White Plains, New York.\n\nHe received his bachelor of Science degree in Physics from MIT in 1965 and his Ph.D. degree in astrophysics from the University of California, Berkeley in 1971. Tanenbaum also served as a lobbyist for the Sierra Club.\n\nHe moved to the Netherlands to live with his wife, who is Dutch, but he retains his United States citizenship. He teaches courses about Computer Organization and Operating Systems and supervises the work of Ph.D. candidates at the VU University Amsterdam. On , he announced his retirement.\n\nTanenbaum is well recognized for his textbooks on computer science. They include:\n\nHis book, \"Operating Systems: Design and Implementation\" and MINIX were Linus Torvalds' inspiration for the Linux kernel. In his autobiography \"Just for Fun\", Torvalds describes it as \"the book that launched me to new heights\".\n\nHis books have been translated into many languages including Arabic, Basque, Bulgarian, Chinese, Dutch, French, German, Greek, Hebrew, Hungarian, Italian, Japanese, Korean, Macedonian, Mexican Spanish, Persian, Polish, Portuguese, Romanian, Russian, Serbian, and Spanish. They have appeared in over 175 editions and are used at universities around the world.\n\nTanenbaum has had a number of Ph.D. students who themselves have gone on to become widely known computer science researchers.\nThese include:\n\nIn the early 1990s, the Dutch government began setting up a number of thematically oriented research schools that spanned multiple universities. These schools were intended to bring professors and Ph.D. students from different Dutch (and later, foreign) universities together to help them cooperate and enhance their research.\n\nTanenbaum was one of the cofounders and first Dean of the Advanced School for Computing and Imaging (ASCI). This school initially consisted of nearly 200 faculty members and Ph.D. students from the Vrije Universiteit, University of Amsterdam, Delft University of Technology, and Leiden University. They were especially working on problems in advanced computer systems such as parallel computing and image analysis and processing.\n\nTanenbaum remained dean for 12 years, until 2005, when he was awarded an Academy Professorship by the Royal Netherlands Academy of Arts and Sciences, at which time he became a full-time research professor. ASCI has since grown to include researchers from nearly a dozen universities in The Netherlands, Belgium, and France. ASCI offers Ph.D. level courses, has an annual conference, and runs various workshops every year.\n\nThe Amsterdam Compiler Kit is a toolkit for producing portable compilers. It was started sometime before 1981 and Andrew Tanenbaum was the architect from the start until version 5.5.\n\nIn 1987, Tanenbaum wrote a clone of UNIX, called MINIX (MINi-unIX), for the IBM PC. It was targeted at students and others who wanted to learn how an operating system worked. Consequently, he wrote a book that listed the source code in an appendix and described it in detail in the text. The source code itself was available on a set of floppy disks. Within three months, a Usenet newsgroup, comp.os.minix, had sprung up with over 40,000 subscribers discussing and improving the system. One of these subscribers was a Finnish student named Linus Torvalds who began adding new features to MINIX and tailoring it to his own needs. On October 5, 1991, Torvalds announced his own (POSIX like) kernel, called Linux, which originally used the MINIX file system, but it is not based on MINIX code.\n\nAlthough MINIX and Linux have diverged, MINIX continues to be developed, now as a production system as well as an educational one. The focus is on building a highly modular, reliable, and secure, operating system. The system is based on a microkernel, with only 5000 lines of code running in kernel mode. The rest of the operating system runs as a number of independent processes in user mode, including processes for the file system, process manager, and each device driver. The system continuously monitors each of these processes, and when a failure is detected is often capable of automatically replacing the failed process without a reboot, without disturbing running programs, and without the user even noticing. MINIX 3, as the current version is called, is available under the BSD license for free.\n\nTanenbaum has also been involved in numerous other research projects in the areas of operating systems, distributed systems, and ubiquitous computing, often as supervisor of Ph.D. students or a postdoctoral researcher. These projects include:\n\nIn 2004, Tanenbaum created Electoral-vote.com, a web site analyzing opinion polls for the 2004 U.S. Presidential Election, using them to project the outcome in the Electoral College. He stated that he created the site as an American who \"knows first hand what the world thinks of America and it is not a pretty picture at the moment. I want people to think of America as the land of freedom and democracy, not the land of arrogance and blind revenge. I want to be proud of America again.\" The site provided a color-coded map, updated each day with projections for each state's electoral votes. Through most of the campaign period Tanenbaum kept his identity secret, referring to himself as \"the Votemaster\" and acknowledging only that he personally preferred John Kerry. A libertarian who supports the Democrats, he revealed his identity on November 1, 2004, the day before the election, also stating his reasons and qualifications for running the website.\n\nThrough the site he also covered the 2006 midterm elections, correctly predicting the winner of all 33 Senate races that year.\n\nFor the 2008 elections, he got every state right except for Indiana, which he said McCain would win by 2% (Obama won by 1%) and Missouri, which he said was too close to call (McCain won by 0.1%). He correctly predicted all the winners in the Senate except for Minnesota, where he predicted a 1% win by Norm Coleman over Al Franken. After 7 months of legal battling and recounts, Franken won by 312 votes (0.01%).\n\nIn 2010, he correctly projected 35 out of 37 Senate races in the Midterm elections on the website. The exceptions were Colorado and Nevada.\n\nThe Tanenbaum–Torvalds debate was a famous debate between Tanenbaum and Linus Torvalds regarding kernel design on Usenet in 1992.\n\n\n\nTanenbaum has been keynote speaker at numerous conferences, most recently\n\n", "id": "3110", "title": "Andrew S. Tanenbaum"}
{"url": "https://en.wikipedia.org/wiki?curid=3111", "text": "Ariane 5\n\nAriane 5 is a European heavy lift launch vehicle that is part of the Ariane rocket family, an expendable launch system used to deliver payloads into geostationary transfer orbit (GTO) or low Earth orbit (LEO). \n\nAriane 5 rockets are manufactured under the authority of the European Space Agency (ESA) and the Centre National d'Etudes Spatiales. Airbus Defence and Space is the prime contractor for the vehicles, leading a consortium of other European contractors. \n\nAriane 5 is operated and marketed by Arianespace as part of the \"Ariane\" programme. The rockets are launched by Arianespace from the Guiana Space Centre in French Guiana.\n\nAriane 5 succeeded Ariane 4, but was not derived from it directly. Ariane 5 has been refined since the first launch in successive versions, \"G\", \"G+\", \"GS\", \"ECA\", and most recently, \"ES\". ESA originally designed Ariane 5 to launch the Hermes spaceplane, and thus intended it to be human rated from the beginning.\n\nTwo satellites can be mounted using a SYLDA carrier (\"SYstème de Lancement Double Ariane\"). Three main satellites are possible depending on size using SPELTRA (\"Structure Porteuse Externe Lancement TRiple Ariane\"). Up to eight secondary payloads, usually small experiment packages or minisatellites, can be carried with an ASAP (\"Ariane Structure for Auxiliary Payloads\") platform.\n\nOn 14 February 2017, Ariane 5 performed its 77th consecutive successful mission since 2003.\n\nAriane 5’s cryogenic H173 main stage (H158 for Ariane 5 G, G+, and GS) is called the EPC (\"Étage Principal Cryotechnique\"—Cryotechnic Main Stage). It consists of a large tank 30.5 metres high with two compartments, one for liquid oxygen and one for liquid hydrogen, and a Vulcain 2 engine at the base with a vacuum thrust of . The H173 EPC weighs about 189 tonnes, including 175 tonnes of propellant. After the main cryogenic stage runs out of fuel, it can re-enter the atmosphere for an ocean splashdown.\n\nAttached to the sides are two P241 (P238 for Ariane 5 G and G+) solid rocket boosters (SRBs or EAPs from the French \"Étages d’Accélération à Poudre\"), each weighing about 277 tonnes full and delivering a thrust of about . They are fueled by a mix of ammonium perchlorate (68%) and aluminum fuel (18%) and HTPB (14%). They each burn for 130 seconds before being dropped into the ocean. The SRBs are usually allowed to sink to the bottom of the ocean, but like the Space Shuttle Solid Rocket Boosters they can be recovered with parachutes, and this has occasionally been done for post-flight analysis. (Unlike Space Shuttle SRBs Ariane 5 boosters are not reused.) The most recent attempt was for the first Ariane 5 ECA mission. One of the two boosters was successfully recovered and returned to the Guiana Space Center for analysis. Prior to that mission, the last such recovery and testing was done in 2003.\n\nThe French M51 SLBM shares a substantial amount of technology with these boosters.\n\nIn February 2000 the suspected nose cone of an Ariane 5 booster washed ashore on the South Texas coast, and was recovered by beachcombers before the government could get to it.\n\nThe second stage is on top of the main stage and below the payload. The Ariane 5 G used the EPS (\"Étage à Propergols Stockables\"—Storable Propellant Stage), which is fueled by monomethylhydrazine (MMH) and nitrogen tetroxide. It also has 10 tonnes of storable propellants. The EPS was improved for use on the Ariane 5 G+, GS, and ES. Ariane 5 ECA uses the ESC (\"Étage Supérieur Cryotechnique\"—Cryogenic Upper Stage), which is fueled by liquid hydrogen and liquid oxygen.\n\nThe EPS upper stage is capable of multiple ignitions, first demonstrated during flight V26 which was launched on 5 October 2007. This was purely to test the engine, and occurred after the payloads had been deployed. The first operational use of restart capability as part of a mission came on 9 March 2008, when two burns were made to deploy the first Automated Transfer Vehicle into a circular parking orbit, followed by a third burn after ATV deployment to de-orbit the stage. This procedure was repeated for all subsequent ATV flights.\n\nThe payload and all upper stages are covered at launch by a fairing, which is jettisoned once sufficient altitude has been reached (typically above 100 km). The Fairing is also used for aerodynamic stability and protection from heating during supersonic flight and acoustic loads.\n\n, the Ariane 5 commercial launch price for launching a \"midsize satellite in the lower position\" is approximately , competing for commercial launches in an increasingly competitive market, mainly due to SpaceX.\n\nThe heavier satellite launched in the upper position on a typical dual-satellite Ariane 5 launch is priced higher, on the order of .\n\nTotal launch price of an Ariane 5—which can transport up to two satellites to space, one in the \"upper\" and one in the \"lower\" positions—is around 150 million Euro as of January 2015.\n\nThe Ariane 5 ME (Mid-life Evolution) was in development until 2015 and seen as a stopgap between / and the new Ariane 6. With first flight planned for 2018, it would have become ESA's principal launcher until the arrival of the new Ariane 6 version.\n\nThe Ariane 5 ME uses a new upper stage, with increased propellant volume, powered by the new Vinci engine. Unlike the HM-7B engine, it can restart several times, allowing for complex orbital maneuvers such as insertion of two satellites into different orbits, direct insertion into geosynchronous orbit, planetary exploration missions, and guaranteed upper stage deorbiting or insertion into graveyard orbit.\n\nThe new launcher also includes a lengthened fairing up to 20m and a new dual launch system to accommodate larger satellites. Compared to an Ariane 5 ECA model, the payload to GTO increases by 15% to 11.5 tonnes and the cost-per-kilogram of each launch is projected to decline by 20%.\n\nOriginally known as the Ariane 5 ECB, was to have its first flight in 2006. However, the failure of the first ECA flight in 2002, combined with a deteriorating satellite industry, caused ESA to cancel development in 2003. Development of the Vinci engine continued, though at a lower pace. The ESA Council of Ministers agreed to fund development of the new upper stage in November 2008.\nIn 2009, EADS Astrium was awarded a €200 million contract, and on April 10, 2012 received another €112 million contract to continue development of the Ariane 5 ME with total development effort expected to cost €1 billion.\n\nOn 21 November 2012, ESA agreed to continue with the Ariane 5 ME to meet the challenge of lower priced competitors. It was agreed the Vinci upper stage would also be used as the second stage of a new Ariane 6, and further commonality would be sought. Ariane 5 ME qualification flight is scheduled for mid-2018, followed by gradual introduction into service.\n\nOn 2 December 2014, ESA decided to stop funding the development of Ariane 5 ME and instead focus on Ariane 6 which should have a lower cost per launch and allow more flexibility in the payloads (using two or four P120C solid boosters depending on total payload mass).\n\nWork on the Ariane 5 EAP motors have been continued in the Vega programme. The Vega 1st stage engine—the P80 engine—is a shorter derivation of the EAP. The P80 booster casing is made of filament wound graphite epoxy, much lighter than the current stainless steel casing. A new composite steerable nozzle has been developed while new thermal insulation material and a narrower throat improve the expansion ratio and subsequently the overall performance. Additionally, the nozzle now has electromechanical actuators which have replaced the heavier hydraulic ones used for thrust vector control.\n\nThese developments will probably later make their way back into the Ariane programme. The incorporation of the ESC-B with the improvements to the solid motor casing and an uprated Vulcain engine would deliver to LEO. This would be developed for any lunar missions but the performance of such a design may not be possible if the higher Max-Q for the launch of this rocket poses a constraint on the mass delivered to orbit.\n\nThe design brief of the next generation rocket called for a lower-cost and smaller rocket capable of launching a single satellite of up to 6.5 tonnes to GTO. However, after several permutations the finalized design was nearly identical in performance to the Ariane 5, even though a lower per-launch price is projected.\n\nDevelopment is projected to cost €4 billion. Its first test launch is set for 2021. , Ariane 6 is projected to be launched for about €70 million per flight or about half of the Ariane 5 rocket's current price.\n\nAriane 5's first test flight (Ariane 5 Flight 501) on 4 June 1996 failed, with the rocket self-destructing 37 seconds after launch because of a malfunction in the control software. A data conversion from 64-bit floating point value to 16-bit signed integer value to be stored in a variable representing horizontal bias caused a processor trap (operand error) because the floating point value was too large to be represented by a 16-bit signed integer. The software was originally written for the Ariane 4 where efficiency considerations (the computer running the software had an 80% maximum workload requirement) led to four variables being protected with a handler while three others, including the horizontal bias variable, were left unprotected because it was thought that they were \"physically limited or that there was a large margin of error\". The software, written in Ada, was included in the Ariane 5 through the reuse of an entire Ariane 4 subsystem despite the fact that the particular software containing the bug, which was just a part of the subsystem, was not required by the Ariane 5 because it has a different preparation sequence than the Ariane 4.\n\nThe second test flight (L502, on 30 October 1997) was a partial failure. The Vulcain nozzle caused a roll problem, leading to premature shutdown of the core stage. The upper stage operated successfully, but it could not reach the intended orbit.\n\nA subsequent test flight (L503, on 21 October 1998) proved successful and the first commercial launch (L504) occurred on 10 December 1999 with the launch of the XMM-Newton X-ray observatory satellite.\n\nAnother partial failure occurred on 12 July 2001, with the delivery of two satellites into an incorrect orbit, at only half the height of the intended GTO. The ESA Artemis telecommunications satellite was able to reach its intended orbit on 31 January 2003, through the use of its experimental ion propulsion system.\n\nThe next launch did not occur until 1 March 2002, when the Envisat environmental satellite successfully reached an orbit above the Earth in the 11th launch. At , it was the heaviest single payload until the launch of the first ATV on 9 March 2008 (19,360 kg).\n\nThe first launch of the ECA variant on 11 December 2002 ended in failure when a main booster problem caused the rocket to veer off-course, forcing its self-destruction three minutes into the flight. Its payload of two communications satellites (Stentor and Hot Bird 7), valued at about EUR 630 million, was lost in the ocean. The fault was determined to have been caused by a leak in coolant pipes allowing the nozzle to overheat. After this failure, Arianespace SA delayed the expected January 2003 launch for the Rosetta mission to 26 February 2004, but this was again delayed to early March 2004 due to a minor fault in the foam that protects the cryogenic tanks on the Ariane 5. As of April 2014, the failure of the first ECA launch was the last failure of an Ariane 5; since then, all subsequent launches have been successful, with 69 consecutive successes that stretch back to 9 April 2003 with the launch of INSAT-3A and Galaxy 12 satellites.\n\nOn 27 September 2003 the last Ariane 5 G boosted three satellites (including the first European lunar probe, SMART-1), in Flight 162. On 18 July 2004 an Ariane 5 G+ boosted what was at the time the heaviest telecommunication satellite ever, Anik F2, weighing almost .\n\nThe first successful launch of the Ariane 5 ECA took place on 12 February 2005. The payload consisted of the XTAR-EUR military communications satellite, a 'SLOSHSAT' small scientific satellite and a MaqSat B2 payload simulator. The launch had been originally scheduled for October 2004, but additional testing and the military requiring a launch at that time (of a Helios 2A observation satellite) delayed the attempt.\n\nOn 11 August 2005, the first Ariane 5 GS (featuring the Ariane 5 ECA's improved solid motors) boosted Thaïcom-4/iPStar-1, the heaviest telecommunications satellite to date at , into orbit.\n\nOn 16 November 2005, the third Ariane 5 ECA launch (the second successful ECA launch) took place. It carried a dual payload consisting of Spaceway-F2 for DirecTV and Telkom-2 for PT Telekomunikasi of Indonesia. This was the rocket's heaviest dual payload to date, at more than .\n\nOn 27 May 2006, an Ariane 5 ECA rocket set a new commercial payload lifting record of 8.2 tonnes. The dual-payload consisted of the Thaicom 5 and Satmex 6 satellites.\n\nOn 4 May 2007 the Ariane 5 ECA set another new commercial record, lifting into transfer orbit the Astra 1L and Galaxy 17 communication satellites with a combined weight of 8.6 tonnes, and a total payload weight of 9.4 tonnes. This record was again broken by another Ariane 5 ECA, launching the Skynet 5B and Star One C1 satellites, on 11 November 2007. The total payload weight for this launch was .\n\nOn 9 March 2008, the first Ariane 5 ES-ATV was launched to deliver the first ATV called \"Jules Verne\" to the International Space Station. The ATV was the heaviest payload ever launched by a European rocket, providing supplies to the space station with necessary propellant, water, air and dry cargo. This was the first operational Ariane mission which involved an engine restart in the upper stage. (The ES-ATV Aestus EPS upper stage was restartable while the ECA HM7-B engine was not.)\n\nOn 1 July 2009, an Ariane 5 ECA launched TerreStar-1, the largest commercial telecommunication satellite ever built.\n\nOn 28 October 2010, an Ariane 5 ECA launched Eutelsat's W3B (part of its W Series of satellites) and Broadcasting Satellite System Corporation (B-SAT)'s BSAT-3b satellites into orbit. However, the W3B satellite failed to operate shortly after the successful launch and was written off as a total loss due to an oxidizer leak in the satellite's main propulsion system. The BSAT-3b satellite, however, is operating normally.\n\nOn 22 April 2011, the Ariane 5 ECA flight VA-201 broke a commercial record, lifting Yahsat 1A and Intelsat New Dawn with a total payload weight of 10,064 kg to transfer orbit. This record was later broken again during the launch of Ariane 5 ECA flight VA-208 on 2 August 2012, lifting a total of 10,182 kg into the planned geosynchronous transfer orbit, which was broken again 6 months later on flight VA-212 with 10,317 kg sent towards geosynchronous transfer orbit. In June 2016 the GTO record was raised to 10,730 kg, on the first rocket in history that carried a satellite dedicated to financial institutions. The payload record was pushed a further 5 kg to on 24 August with the launch of Intelsat 33e and Intelsat 36.\n\nAriane 5 rockets have accumulated 91 launches since 1996, 87 of which were successful, yielding a success rate. Between April 2003 and February 2017, Ariane 5 has flown 77 consecutive missions without failure.\n\n Ariane 5 had 20 missions on its launch manifest. Up to seven launches are planned for the year 2017: six with dual communications satellites due to geosynchronous orbit, and one with 4 Galileo satellites. A flight in March 2017 was cancelled due to transportation to the launch site being restricted by a blockade erected by striking workers.\n\n", "id": "3111", "title": "Ariane 5"}
{"url": "https://en.wikipedia.org/wiki?curid=3112", "text": "Arianespace\n\nArianespace SA is a French multinational company founded in 1980 as the world's first commercial launch service provider. It undertakes the production, operation, and marketing of the Ariane programme. The main launch vehicles offered by the company are the Ariane 5, the Soyuz-2 as a medium-lift alternative, and the Vega as a lighter one.\n\n, more than 240 commercial launches have occurred since May 22, 1984. Arianespace states that the total number of launch contracts signed since Ariane launches commenced operations in 1984 is 285. Arianespace uses the Centre Spatial Guyanais in French Guiana as a launch site. It has its headquarters in Courcouronnes, Essonne, France, near Évry.\n\nOn 21 October 2011 Arianespace launched the first Soyuz rocket ever from outside former Soviet territory. The payload was two Galileo navigation satellites.\n\nArianespace primary shareholders are its suppliers, in the various nations of the European Union. \nArianespace currently has 18 shareholders:\n\nArianespace shareholding has been restructured with the creation of an Airbus Safran Launchers company that will develop and manufacture the Ariane 6 launcher. Airbus and Safran shareholdings were pooled along with the purchase of the French governments CNES stake to form a partnership company holding just under 74% of Arianespace shares while the remaining 26% is spread across companies in ten countries including further Airbus subsidiaries.\n\n\nIn 2004, Arianespace held more than 50 percent of the world market for boosting satellites to geostationary transfer orbit (GTO).\n\nThe disruptive force represented by new sector entrant SpaceX forced Arianespace to cut workforce and focus on cost-cutting to decrease costs to remain competitive against the new low-cost entrant in the launch sector. According to an Arianespace managing director, \"It's quite clear there's a very significant challenge coming from SpaceX,\" he said. \"Therefore things have to change … and the whole European industry is being restructured, consolidated, rationalised and streamlined.\"\n\nIn the midst of pricing pressure from U.S. company SpaceX, Arianespace made a November 2013 announcement of pricing flexibility for the \"lighter satellites\" it carries to Geostationary orbits aboard its Ariane 5.\nIn early 2014, Arianespace requested additional subsidies from European governments to face the competition from SpaceX and unfavorable changes in the Euro-Dollar exchange rate. Reducing pricing allowed Arianespace to sign four additional contracts in September 2014 for a lower slots on an Ariane 5 SYLDA dispenser for the satellites that otherwise could be flown on SpaceX launch vehicle. Overall Arianespace signed 11 contracts in 2014 until September, with two additional being in a late stage of negotiations. Arianespace has a backlog of launches worth billion with 38 satellites to be launched on Ariane 5, 7 on Soyuz and 9 on Vega, claiming 60% of the global satellite launch market.\nBy November 2014, SpaceX had \"already begun to take market share\" from Arianespace, and Eutelsat CEO Michel de Rosen—a major customer of Arianespace—said that \"Each year that passes will see SpaceX advance, gain market share and further reduce its costs through economies of scale.\"\n\nCurrently Arianespace operates 3 launch vehicles, including two versions of Ariane 5:\n\nAdditionally Arianespace offers optional back-up launch service on H-IIA through Launch Services Alliance.\n\nSince the first launch in 1979, there have been several versions of the Ariane launch vehicle:\n\nNew Ariane 6 vehicle is in development. It would be payload wise in league of Ariane 5 and has tentatively its first test flight in 2020 as of 2016.\n\nThe Ariane's Cup is a sailing competition organized on behalf of the Industrials participating in the Ariane programme.\n\n\nComparable Launch Provider Company\n", "id": "3112", "title": "Arianespace"}
{"url": "https://en.wikipedia.org/wiki?curid=3114", "text": "Amiga 500 Plus\n\nThe Commodore Amiga 500 Plus (often A500 Plus or simply A500+) is an enhanced version of the original Amiga 500 computer. It was notable for introducing new versions of Kickstart and Workbench, and for some minor improvements in the custom chips, known as the Enhanced Chip Set (or ECS).\n\nThe A500+ was released in several markets (including many European countries), but was never sold officially in the U.S.\n\nAlthough officially introduced in 1992, some Amiga 500 Plus units had already been sold (masquerading as Amiga 500 models, and with no prior announcement) during late 1991. It has been speculated that Commodore had already sold out the remaining stocks of Amiga 500s, before the run up to the profitable Christmas sales period. In order to make enough A500s before Christmas, Commodore used stocks of the new 8A revision motherboards destined for the A500+. Many users were unaware that they were purchasing anything other than a standard Amiga 500. Although the Amiga 500+ was an improvement to the Amiga 500, it was minor. It was discontinued and replaced by the Amiga 600 in summer 1992, making it the shortest lived Amiga model.\n\nCommodore created the A500+ for a couple of reasons. The first was cost reduction; minor changes were made to the motherboard to make it cheaper to produce. It was also so that Commodore could introduce the new version of the Amiga Operating system, 2.04.\n\nDue to the new Kickstart, quite a few popular games (such as Treasure Island Dizzy, SWIV, and Lotus Esprit Turbo Challenge) failed to work on the Amiga 500+, and some people took them back to dealers demanding an original Kickstart 1.3 Amiga 500. This problem was solved by third parties who produced Kickstart ROM switching boards, that could allow the Amiga 500+ to be downgraded to Kickstart 1.2 or 1.3. It also encouraged game developers to use better programming habits, which was important since Commodore already had plans for the introduction of the next-generation Amiga 1200 computer. A program, Relokick, was also released (and included with an issue of CU Amiga) which loaded a Kickstart 1.3 ROM image into memory and booted the machine into Kickstart 1.3, allowing incompatible software to run. In some cases, updated compatible versions of games were later released, such as budget versions of Lotus 1 and SWIV.\n\n\n", "id": "3114", "title": "Amiga 500 Plus"}
{"url": "https://en.wikipedia.org/wiki?curid=3116", "text": "Accumulator (computing)\n\nIn a computer's central processing unit (CPU), an accumulator is a register in which intermediate arithmetic and logic results are stored. \n\nWithout a register like an accumulator, it would be necessary to write the result of each calculation (addition, multiplication, shift, etc.) to main memory, perhaps only to be read right back again for use in the next operation. Access to main memory is slower than access to a register like the accumulator because the technology used for the large main memory is slower (but cheaper) than that used for a register. Early electronic computer systems were often split into two groups, those with accumulators and those without.\n\nModern computer systems often have multiple general purpose registers that operate as accumulators, and the term is no longer as common as it once was. However, a number of special-purpose processors still use a single accumulator for their work, in order to simplify their design.\n\nMathematical operations often take place in a stepwise fashion, using the results from one operation as the input to the next. For instance, a manual calculation of a worker's weekly payroll might look something like:\n\nA computer program carrying out the same task would follow the same basic sequence of operations, although the values being looked up would all be stored in computer memory. In early computers the number of hours would likely be held on a punch card and the pay rate in some other form of memory, perhaps a magnetic drum. Once the multiplication is complete, the result needs to be placed somewhere. On a \"drum machine\" this would likely be back to the drum, an operation that takes considerable time. And then the very next operation has to read that value back in, which introduces another considerable delay.\n\nAccumulators dramatically improve performance in systems like these by providing a scratchpad area where the results of one operation can be fed to the next one for little or no performance penalty. In the example above, the basic weekly pay would be calculated and placed in the accumulator, which could then immediately be used by the income tax calculation. This removes one save and one read operation from the sequence, operations that generally took tens to hundreds of times as long as the multiplication itself.\n\nAn accumulator machine, also called a 1-operand machine, or a CPU with \"accumulator-based architecture\", is a kind of CPU where, although it may have several registers, the CPU mostly stores the results of calculations in one special register, typically called \"the accumulator\". Almost all early computers were accumulator machines with only the high-performance \"supercomputers\" having multiple registers. Then as mainframe systems gave way to microcomputers, accumulator architectures were again popular with the MOS 6502 being a notable example. Many 8-bit microcontrollers that are still popular as of 2014, such as the PICmicro and 8051, are accumulator-based machines.\n\nModern CPUs are typically 2-operand or 3-operand machines. The additional operands specify which one of many general purpose registers (also called \"general purpose accumulators\") are used as the source and destination for calculations. These CPUs are not considered \"accumulator machines\".\n\nThe characteristic which distinguishes one register as being the accumulator of a computer architecture is that the accumulator (if the architecture were to have one) would be used as an \"implicit\" operand for arithmetic instructions. For instance, a CPU might have an instruction like: codice_1 that adds the value read from memory location \"memaddress\" to the value in the accumulator, placing the result back in the accumulator. The accumulator is not identified in the instruction by a register number; it is implicit in the instruction and no other register can be specified in the instruction. Some architectures use a particular register as an accumulator in some instructions, but other instructions use register numbers for explicit operand specification.\n\nAny system that uses a single \"memory\" to store the result of multiple operations can be considered an accumulator. J. Presper Eckert refers to even the earliest adding machines of Gottfried Leibniz and Blaise Pascal as accumulator-based systems.\n\nHistorical convention dedicates a register to \"the accumulator\", an \"arithmetic organ\" that literally accumulates its number during a sequence of arithmetic operations:\n\nJust a few of the instructions are, for example (with some modern interpretation):\n\nNo convention exists regarding the names for operations from registers to accumulator and from accumulator to registers. Tradition (e.g. Donald Knuth's (1973) hypothetical MIX computer), for example, uses two instructions called \"load accumulator\" from register/memory (e.g. \"LDA r\") and \"store accumulator\" to register/memory (e.g. \"STA r\"). Knuth's model has many other instructions as well.\n\nThe 1945 configuration of ENIAC had 20 accumulators, which could operate in parallel. Each one could store an eight decimal digit number and add to it (or subtract from it) a number it received. Most of IBM's early binary \"scientific\" computers, beginning with the vacuum tube IBM 701 in 1952, used a single 36-bit accumulator, along with a separate multiplier/quotient register to handle operations with longer results. The IBM 650, a decimal machine, had one 10 digit accumulator; the IBM 7070, a later, transistorized decimal machine had three accumulators.\n\nThe 12-bit PDP-8 was one of the first minicomputers to use accumulators, and inspired many later machines. The PDP-8 had but one accumulator. The HP 2100 and Data General Nova had 2 and 4 accumulators. The Nova was created when this follow-on to the PDP-8 was rejected in favor of what would become the PDP-11. The Nova provided four accumulators, AC0-AC3, although AC2 and AC3 could also be used to provide offset addresses, tending towards more generality of usage for the registers. The PDP-11 introduced a more contemporary model of general registers, numbered R0-R7 or more, adopted by most later CISC and RISC machines.\nEarly 4-bit and 8-bit microprocessors such as the 4004, 8008 and numerous others, typically had single accumulators. The 8051 microcontroller has two, a primary accumulator and a secondary accumulator, where the second is used by instructions only when multiplying (MUL AB) or dividing (DIV AB); the former splits the 16-bit result between the two 8-bit accumulators, whereas the latter stores the quotient on the primary accumulator A and the remainder in the secondary accumulator B. As a direct descendent of the 8008, the 8080, and the 8086, the modern ubiquitous Intel x86 processors still uses the primary accumulator EAX and the secondary accumulator EDX for multiplication and division of large numbers. For instance, MUL ECX will multiply the 32-bit registers ECX and EAX and split the 64-bit result between EAX and EDX. However, MUL and DIV are special cases, other arithmetic-logical instructions (ADD, SUB, CMP, AND, OR, XOR, TEST) may specify any of the eight registers EAX, ECX, EDX, EBX, ESP, EBP, ESI, EDI as the accumulator (i.e. left operand and destination); this is also supported for multiply if the upper half of the result is not required. x86 is thus a fairly general register architecture, despite being based on an accumulator model. The 64-bit extension of x86, x86-64, has been further generalized to 16 instead of 8 general registers.\n\n", "id": "3116", "title": "Accumulator (computing)"}
{"url": "https://en.wikipedia.org/wiki?curid=3117", "text": "Abu Zubaydah\n\nAbu Zubaydah ( ; , \"Abū Zubaydah\"; born March 12, 1971 as Zayn al-Abidin Muhammad Husayn) is a Saudi Arabian citizen currently held by the U.S. in the Guantanamo Bay detention camp in Cuba. He is held under the authority of Authorization for Use of Military Force Against Terrorists (AUMF).\n\nZubaydah was arrested in Pakistan in March 2002 and has been in United States custody ever since, including four-and-a-half years in the secret prison network of the Central Intelligence Agency (CIA). He was transferred among prisons in various countries as part of a United States rendition program. During his time in CIA custody, Zubaydah was extensively interrogated; he was water-boarded 83 times and subjected to numerous other torture techniques including forced nudity, sleep deprivation, confinement in small dark boxes, deprivation of solid food, stress positions, and physical assaults. While in CIA custody, Zubaydah lost his left eye. Videotapes of some of Zubaydah's interrogations are amongst those destroyed by the CIA in 2005.\n\nZubaydah and ten other \"high-value detainees\" were transferred to Guantanamo in September 2006. He and other former CIA detainees are held in Camp 7, where conditions are the most isolating. At his Combatant Status Review Tribunal in 2007, Zubaydah said he was told that the CIA realized he was not significant. \n\nOn July 24, 2014 the European Court of Human Rights (ECHR) ordered the Polish government to pay Zubaydah €100,000 in damages. It also awarded him €30,000 to cover his costs. Poland cooperated with the US, allowing the CIA to hold and torture Zubaydah on its territory in 2002–2003. Zubaydah said through his US lawyer that he would be donating the full €100,000 in damages to victims of torture. Joseph Margulies was a lawyer for Zubaydah.\n\nAccording to his younger brother Hesham, they had eight siblings. Hesham remembers his older brother \"as a happy-go-lucky guy, and something of a womanizer.\" Born in Saudi Arabia, Zubaydah moved to the West Bank as a teenager, where he joined in Palestinian demonstrations against the Israelis. Zubaydah is reported to have studied computer science in Pune, India prior to his travel to Afghanistan/Pakistan at the age of 20 in 1991. He joined the mujahideen in the Afghan civil war, perhaps serving under Mohamad Kamal Elzahabi. In 1992, Zubaydah was injured in a mortar shell blast, which left shrapnel in his head and caused severe memory loss, as well as the loss of the ability to speak for over one year.\n\nZubaydah eventually became involved in the jihad training site known as the Khalden training camp, where he oversaw the flow of recruits and obtained passports and paperwork for men transferring out of Khalden. He may also have worked as an instructor there. Although originally described as an Al Qaeda training camp, this alleged connection, which has been used as justification for holding Zubaydah and others as enemy combatants, has come under scrutiny from multiple sources,<ref name=\"9/11CommissionReport\">\"9/11 Commission Report: Final Report of the National Commission on Terrorist Attacks Upon the United States\", July 22, 2006</ref> and the camp may have shuttered its doors in 2001 in response to an ideological division with Al Qaeda.\n\nBy 1999, the United States government was attempting to surveil Zubaydah. By March 2000, United States officials were reporting that Zubaydah was a \"senior Bin Laden official,\" the \"former head of Egypt-based Islamic Jihad,\" a \"trusted aide\" to Bin Laden with \"growing power,\" who had \"played a key role in the East Africa embassy attacks.\" Zubaydah was convicted \"in absentia\" in Jordan and sentenced to death by a Jordanian court for his role in plots to bomb U.S. and Israeli targets there. A senior Middle East security official said Zubaydah had directed the Jordanian cell and was part of \"Bin Laden's inner circle.\"\n\nIn August 2001, the classified FBI report, \"Bin Laden Determined To Strike in US\", said that the foiled millennium bomber, Ahmed Ressam, had confessed that Zubaydah had encouraged him to blow up the Los Angeles airport and facilitated his mission. The report said that Zubaydah was also planning his own attack on the U.S. However, when Ressam was tried in December 2001, federal prosecutors did not try to connect him to Zubaydah or refer to any of this supposed evidence in its case. After the trial, Ressam recanted his confession, saying he had been coerced into giving it.\n\nAccording to a psychological evaluation conducted upon his capture, Zubaydah allegedly served as Osama Bin Laden's senior lieutenant and counter-intelligence officer (i.e. third or fourth highest-ranking member of al Qaeda), managed a network of training camps, was involved in every major terrorist operation carried out by al Qaeda (including the planning of 9/11), and was engaged in planning future terrorist attacks against U.S. interests. These statements were widely echoed by members of the Bush administration and other US officials. Zubaydah's perceived \"value\" as a detainee would later be used by President Bush to justify the use of \"enhanced interrogation techniques\" and Zubaydah's detention in secret CIA prisons around the world. However, Zubaydah's connection to Al Qaeda is now often said to have been overstated, and in response to his habeas corpus petition, the U.S. Government stated in 2009 that they did not contend that Zubaydah had any involvement with the 9/11 attacks or that he had even been a member of Al Qaeda.\n\nOn March 28, 2002, CIA and FBI agents, in conjunction with Pakistani intelligence services, raided several safe houses in Pakistan searching for Zubaydah. Zubaydah was apprehended from one of the targeted safe houses in Faisalabad, Pakistan. The Pakistani intelligence service had paid a small amount for a tip on his whereabouts. The United States paid far more to Pakistan for its assistance; a CIA source later said, \"We paid $10 million for Zubaydah.\" The Pakistan ISI built a new headquarters on 35 acres outside Islamabad with the money and also bought a helicopter.\n\nDuring the raid, Zubaydah was shot in the thigh, the testicle, and the stomach with rounds from an AK-47 assault rifle. Not recognised at first, he was piled into a pick-up truck along with other prisoners by the Pakistani forces, until a senior FBI agent identified him. He was taken by the FBI to a Pakistani hospital nearby and treated for his wounds. The attending doctor told John Kiriakou, the co-leader of the CIA group which apprehended Zubaydah, that he had never before seen a patient survive such severe wounds. The FBI and CIA flew in a doctor from Johns Hopkins University to ensure Zubaydah would survive during transit out of Pakistan.\n\nHis pocket litter supposedly contained two bank cards which showed he had access to Saudi and Kuwaiti bank accounts; most al-Qaeda members used the preferred, untraceable hawala banking. According to James Risen, \"It is not clear whether an investigation of the cards simply fell through the cracks, or whether they were ignored because no one wanted to know the answers about connections between al Qaeda and important figures in the Middle East – particularly in Saudi Arabia.\" One of Risen's sources chalks up the failure to investigate the cards to incompetence rather than foul play: \"The cards were sent back to Washington and were never fully exploited. I think nobody ever looked at them because of incompetence.\"\n\nWhen Americans investigated the cards, they worked with \"a Muslim financier with a questionable past, and with connections to the Afghan Taliban, al Qaeda, and Saudi intelligence.\" Risen wrote, \"Saudi intelligence officials had seized all of the records related to the card from the Saudi financial institution in question; the records then disappeared. There was no longer any way to trace the money that had gone into the account.\"\n\nA search of the safehouse turned up Zubaydah's personal 10,000-page diaries, in which he recorded his thoughts as a young boy, old man, and at his current age. What appears to be split personalities is how Zubaydah was piecing his memories together after his 1992 shrapnel head wound. As part of his therapy to regain his memories, he began recording the diary that detailed his life, emotions, and what people were telling him. He split information into categories, such as what he knew about himself and what people told him, and listed them under different names to distinguish one set from the other. This was later incorrectly interpreted by some analysts reviewing the diary as symptoms of split personality disorder.\n\nZubaydah was turned over to the CIA. Reports later alleged that he was transferred to secret CIA-operated prisons, known as black sites, in Pakistan, Thailand, Afghanistan, Poland, Northern Africa, and Diego Garcia. Historically, renditions of prisoners to countries which commit torture have been illegal. A memo written by John Yoo and signed by Jay Bybee of the Office of the Legal Counsel, DOJ, days before Zubaydah's capture, provided a legal opinion providing for CIA renditions of detainees to places such as Thailand. In March 2009, the U.S. Senate Intelligence Committee launched a year-long study on how the CIA operated the secret prisons, or black sites, around the world.\n\nIn the spring of 2002, immediately following the capture of Zubaydah, top Bush administration officials, Vice President Dick Cheney, Secretary of State Colin Powell, CIA Director George Tenet, National Security Adviser Condoleezza Rice, Secretary of Defense Donald Rumsfeld, and US Attorney General John Ashcroft discussed at length whether or not the CIA could legally use harsh techniques against him. Condoleezza Rice specifically mentioned the SERE program during the meeting, saying, \"I recall being told that U.S. military personnel were subjected to training to certain physical and psychological interrogation techniques...\"\n\nIn addition, in 2002 and 2003, the administration briefed several Democratic Congressional leaders on the proposed \"enhanced interrogation techniques.\" These congressional leaders included Nancy Pelosi, the future Speaker of the House, and Representative Jane Harman. Congressional officials have stated that the attitude in the briefings ranged from \"quiet acquiescence, if not downright support.\" The documents show that top U.S. Officials were intimately involved in the discussion and approval of the harsher interrogation techniques used on Zubaydah. Condoleezza Rice ultimately told the CIA the harsher interrogation tactics were acceptable, and Dick Cheney stated, \"I signed off on it; so did others.\" During the discussions, US Attorney General John Ashcroft is reported as saying, \"Why are we talking about this in the White House? History will not judge this kindly.\"\n\nZubaydah was interrogated by two separate interrogation teams: the first from the FBI and one from the CIA. Ali Soufan, one of the FBI interrogators, later testified in 2009 on these issues to the Senate Committee that was investigating detainee treatment. Soufan, who witnessed part of the CIA interrogation of Zubaydah, described his treatment under the CIA as torture. The International Committee of the Red Cross and others later reached the same conclusion. While in CIA custody, Zubaydah lost his left eye.\n\nBecause of the urgency felt about the interrogation of Zubaydah, the CIA had consulted with the president about how to proceed. The General Counsel of the CIA asked for a legal opinion from the Office of Legal Counsel, Department of Justice about what was permissible during interrogation.\n\nIn early July 2002 the Associate General Council CTC/Legal Group started drafting a memo to the Attorney General requesting the approval of \"aggressive\" interrogation methods, which otherwise would be prohibited under the provisions of Section 2340-2340B, Title 18, United States Code, on Abu Zubaydah. This memo, drafted by Office of Legal Counsel, Jay Bybee and his assistant John Yoo, is also referred to as the first Torture Memo. Addressed to CIA acting General Counsel John A. Rizzo at his request, the purpose of the memo was to describe and authorize specific enhanced interrogation techniques to be used on Zubaydah. On July 26, 2002 Deputy Assistant Attorney General John Yoo informed the CIA that Attorney General John Ashcroft had approved waterboarding of Abu Zubaydah.\n\nJournalists including Jane Mayer, Joby Warrick and Peter Finn, and Alex Koppelman have reported the CIA was already using these harsh tactics before the memo authorizing their use was written, and that it was used to provide after-the-fact legal support for harsh interrogation techniques. A Department of Justice 2009 report regarding prisoner abuses reportedly stated the memos were prepared one month after Zubaydah had already been subjected to the specific techniques authorized in August 1, 2002, memo. John Kiriakou stated in July 2009 that Zubaydah was waterboarded in the early summer of 2002, months before August 1, 2002 memo was written.\n\nThe memo described ten techniques which the interrogators wanted to use: \"(1) attention grasp, (2) walling, (3) facial hold, (4) facial slap (insult slap), (5) cramped confinement, (6) wall standing, (7) stress positions, (8) sleep deprivation, (9) insects placed in a confinement box, and (10) the waterboard.\" Many of the techniques were, until then, generally considered illegal. Many other techniques developed by the CIA were held to constitute inhumane and degrading treatment and torture under the United Nations Convention against Torture and Article 3 of the European Convention on Human Rights.\n\nAs reported later, many of these interrogation techniques were previously considered illegal under U.S. and international law and treaties at the time of Zubaydah's capture. For instance, the United States had prosecuted Japanese military officials after World War II and American soldiers after the Vietnam War for waterboarding. Since 1930, the United States had defined sleep deprivation as an illegal form of torture. Many other techniques developed by the CIA constitute inhuman and degrading treatment and torture under the United Nations Convention against Torture, and Article 3 of the European Convention on Human Rights.\n\nThe CIA subjected Zubaydah to various forms of increasingly harsh interrogation techniques, including temperature extremes, music played at debilitating volumes, and sexual humiliation. Zubaydah was also subjected to beatings, isolation, waterboarding, long-time standing, continuous cramped confinement, and sleep deprivation.\n\nDuring Zubaydah's interrogation, President Bush learned he was on painkillers for his wounds and was proving resistant. He said to the CIA director George Tenet, \"Who authorized putting him on pain medication?\" It was later reported that Zubaydah was denied painkillers during his interrogation.\n\nZubaydah was one of three or more high-value detainees to be waterboarded. The Bush administration in 2007 said that Zubaydah had been waterboarded once. John Kiriakou, a CIA officer who had seen the cables regarding Zubaydah's interrogation, publicly said in 2009 that Zubaydah was waterboarded once for 35 seconds before he started talking.\n\nIntelligence sources claimed as early as 2008 that Zubaydah had been waterboarded no less than ten times in the span of one week. Zubaydah was waterboarded 83 times within the month of August 2002, the month the CIA was authorized to use this enhanced interrogation techniques for him. In January 2010, Kiriakou, in a memoir, said, \"Now we know that Zubaydah was waterboarded eighty-three times in a single month, raising questions about how much useful information he actually supplied.\"\n\nIn August 2010 the Associated Press reported that the CIA, having concluded its agents had gotten most of the information from Zubaydah, in September 2003 transferred him and three other high-value detainees to Guantanamo. They were held at what was informally known as \"Strawberry Fields,\" a secret camp within the complex built especially for former CIA detainees. Concerned that a pending Supreme Court decision, \"Rasul v. Bush\" (2004), might go against the Bush administration and require providing the prisoners with counsel and having to reveal data about them, on March 27, 2004 the CIA took the four men back into custody and transported them out of Guantanamo to one of their secret sites. At the time, the moves were all kept secret.\n\nIn February 2007, the International Committee of the Red Cross concluded a report on the treatment of \"14 high-value detainees,\" who had been held by the CIA and, after September 2006, by the military at Guantanamo. The ICRC described the twelve enhanced interrogation techniques covered in the OLC memos to the CIA: suffocation by water (which is described as \"torture\" by numerous US officials), prolonged stress standing position, beatings by use of a collar, beating and kicking, confinement in a box, prolonged nudity, sleep deprivation, exposure to cold temperature, prolonged shackling, threats of ill-treatment, forced shaving, and deprivation/restricted provision of solid food. Zubaydah was the only detainee of the 14 interviewed who had been subjected to all 12 of these interrogation techniques. He was also the only one of the 14 detainees to be put into close confinement.\n\nThe final memo mentioned Zubaydah several times. It claimed that due to the enhanced interrogation techniques, Zubaydah \"provided significant information on two operatives, [including] José Padilla[,] who planned to build and detonate a 'dirty bomb' in the Washington DC area.\" This claim is strongly disputed by Ali Soufan, the FBI interrogator who first interrogated Zubaydah following his capture, by traditional means. He said the most valuable information was gained before torture was used. Other intelligence officers have also disputed that claim. Soufan, when asked in 2009 by Senator Sheldon Whitehouse during a Congressional hearing if the memo was incorrect, testified that it was. The memo noted that not all of the waterboarding sessions were necessary for Zubaydah, since the on-scene interrogation team determined he had stopped producing actionable intelligence. The memo reads:\nThis is not to say that the interrogation program has worked perfectly. According to the IG Report, the CIA, at least initially, could not always distinguish detainees who had information but were successfully resisting interrogation from those who did not actually have the information. See IG Report at 83–85. On at least one occasion, this may have resulted in what might be deemed in retrospect to have been the unnecessary use of enhanced techniques. On that occasion, although the on-scene interrogation team judged Zubaydah to be compliant, elements within CIA Headquarters still believed he was withholding information. See id at 84. At the direction of CIA Headquarters, interrogators therefore used the waterboard one more time on Zubaydah.\nJohn McLaughlin, former acting CIA director, stated in 2006, \"I totally disagree with the view that the capture of Zubaydah was unimportant. Zubaydah was woven through all of the intelligence prior to 9/11 that signaled a major attack was coming, and his capture yielded a great deal of important information.\"\n\nIn his 2007 memoir, former CIA Director George Tenet writes:\nA published report in 2006 contended that Zubaydah was mentally unstable and that the administration had overstated his importance. Baloney. Zubaydah had been at the crossroads of many al-Qa'ida operations and was in position to – and did – share critical information with his interrogators. Apparently, the source of the rumor that Zubaydah was unbalanced was his personal diary, in which he adopted various personas. From that shaky perch, some junior Freudians leapt to the conclusion that Zubaydah had multiple personalities. In fact, Agency psychiatrists eventually determined that in his diary he was using a sophisticated literary device to express himself. And, boy, did he express himself.\n\nZubaydah's capture was touted as the biggest of the War on Terror until that of Khalid Sheikh Mohammed.<ref name=\"9/11MastermindNabbed\">\"Alleged 9-11 Mastermind Nabbed\" CBS News, March 1, 2003</ref> The director of the FBI stated Zubaydah's capture would help deter future attacks.\n\nIn a speech in 2006, President Bush claimed that Zubaydah revealed useful intelligence when enhanced interrogation was used, including identification of two important suspects and information that allegedly helped foil a terrorist attack on American soil. These claims directly conflict with the reports of the F.B.I. agents who first interrogated Zubaydah. He gave them the names before torture was used, and the third piece of information came from other sources who had been receiving crucial pieces of information from him without the use of harsher techniques, as well as other government officials.\n\nThe Bush administration relied on some of Zubaydah's claims in justifying the invasion of Iraq. U.S. officials stated that the allegations that Iraq and al-Qaeda were linked in the training of people on chemical weapons came from Zubaydah. The officials noted there was no independent verification of his claims.\n\nThe U.S. Government included statements made by Zubaydah in regards to al Qaeda's ability to obtain a dirty bomb to show a link between Iraq and al Qaeda. According to a Senate Intelligence Committee report of 2004, Zubaydah said that \"he had heard that an important al Qaeda associate, Abu Musab al Zarqawi, and others had good relationships with Iraqi intelligence.\" But the year before in June 2003, Zubaydah and Khalid Sheikh Mohammed were reported as saying there was no link between Saddam Hussein and al Qaeda.\n\nIn the Senate Armed Services Committee 2008 report on the abuses of detainees, the Bush administration was described as having applied pressure to interrogators to find a link between Iraq and Al-Qaeda prior to the Iraq War. Major Paul Burney, a psychiatrist with the United States Army, said to the committee, \"while we were [at Guantanamo] a large part of the time we were focused on trying to establish a link between Al Qaeda and Iraq and we were not being successful.\" He said that higher-ups were \"frustrated\" and applied \"more and more pressure to resort to measures that might produce more immediate results.\"\n\nColonel Lawrence B. Wilkerson, the former chief of staff for former Secretary of State Colin Powell said:\nLikewise, what I have learned is that as the administration authorized harsh interrogation in April and May of 2002—well before the Justice Department had rendered any legal opinion—its principal priority for intelligence was not aimed at pre-empting another terrorist attack on the U.S. but discovering a smoking gun linking Iraq and al-Qa'ida.\n\nSo furious was this effort that on one particular detainee, even when the interrogation team had reported to Cheney's office that their detainee \"was compliant\" (meaning the team recommended no more torture), the VP's office ordered them to continue the enhanced methods. The detainee had not revealed any al-Qa'ida-Baghdad contacts yet. This ceased only after Ibn al-Shaykh al-Libi, under waterboarding in Egypt, \"revealed\" such contacts. Of course, later we learned that al-Libi revealed these contacts only to get the torture to stop.\n\nIn 2004 media coverage of Abu Zubaydah began listing him as a \"disappeared\" prisoner,\" claiming he had no access to the International Red Cross. In February 2005, the CIA was reported as uncomfortable keeping Zubaydah in indefinite custody. Less than 18 months later, Zubaydah and the thirteen other high-value detainees who had been in secret CIA custody were transferred to the Guantanamo Bay detention camp.\n\nAfter his transfer, the CIA denied access to Zubaydah. In 2008, the Office of the Inspector General, Department of Justice, complained that it had been prevented from seeing him, although it was conducting a study of the US treatment of its detainees.\n\nSome people are concerned about Zubaydah's mental stability and how that has affected information he has given to interrogators. Ron Suskind noted in his book, \"The One Percent Doctrine: Deep Inside America's Pursuit of Its Enemies Since 9/11\" (2006), that Zubaydah was mentally ill or disabled due to a severe head injury. He described Zubaydah as keeping a diary \"in the voice of three people: Hani 1, Hani 2, and Hani 3\"—a boy, a young man and a middle-aged alter ego. Zubaydah's diaries spanned ten years and recorded in numbing detail \"what he ate, or wore, or trifling things [people] said.\" Dan Coleman, then the FBI's top al-Qaeda analyst, told a senior bureau official, \"This guy is insane, certifiable, split personality.\" According to Suskind, this judgment was \"echoed at the top of CIA and was briefed to the President and Vice President.\" Coleman stated Zubaydah was a \"safehouse keeper\" with mental problems, who \"claimed to know more about al-Qaeda and its inner workings than he really did.\"\n\nJoseph Margulies, Zubaydah's co-counsel, wrote in an OpEd in the \"Los Angeles Times\":\nPartly as a result of injuries he suffered while he was fighting the communists in Afghanistan, partly as a result of how those injuries were exacerbated by the CIA and partly as a result of his extended isolation, Zubaydah's mental grasp is slipping away. Today, he suffers blinding headaches and has permanent brain damage. He has an excruciating sensitivity to sounds, hearing what others do not. The slightest noise drives him nearly insane. In the last two years alone, he has experienced about 200 seizures. Already, he cannot picture his mother's face or recall his father's name. Gradually, his past, like his future, eludes him.\n\nPresident Bush referred to Zubaydah in a speech to Congress September 2006 requesting a bill to authorize military commissions, following the US Supreme Court ruling in \"Hamdan v. Rumsfeld\" (2006) that held the tribunals as formulated by the executive branch were unconstitutional. Congress rapidly passed legislation that was signed by the president.\n\nLess than one month after Zubaydah's capture, Justice Department officials said Zubaydah was \"a near-ideal candidate for a tribunal trial.\" Several months later in 2002, US officials said there was \"no rush\" to try Zubaydah via military commission.\n\nAt his Combatant Status Review Tribunal in 2007, Zubaydah said he was told that the CIA realized he was not significant.\n\"They told me, 'Sorry, we discover that you are not Number 3, not a partner, not even a fighter,' \"said Zubaydah, speaking in broken English, according to the new transcript of a Combatant Status Review Tribunal held at the U.S. military prison in Guantanamo Bay, Cuba.\"\n\nAbu Zubaydah's lawyers filed a lawsuit in July 2008 challenging his detention at Guantanamo Bay detention camps after the \"Boumediene v. Bush\" ruling. As of 2015, the judge overseeing the case, Richard W. Roberts, has failed to rule on any motions related to the case, even the preliminary ones. This has led Zubaydah's lawyers to file motion asking Judge Roberts to recuse himself for nonfeasance in January 2015.\n\nThe judge's failure to act for nearly seven years may be related to the revelation in the Senate Intelligence Committee report on CIA torture that Zubaydah's CIA interrogators wanted him to \"remain in isolation and incommunicado for the remainder of his life.\"\n\nThe U.S. Government has not officially charged Zubaydah with any crimes.\n\nWhen he assumed office in January 2009 President Barack Obama made a number of promises about the future of Guantanamo.\nHe promised the use of torture would cease at the camp. He promised to institute a new review system. That new review system was composed of officials from six departments, where the OARDEC reviews were conducted entirely by the Department of Defense. When it reported back, a year later, the Joint Review Task Force classified some individuals as too dangerous to be transferred from Guantanamo, even though there was no evidence to justify laying charges against them. On April 9, 2013, that document was made public after a Freedom of Information Act request.\nZayn al-lbidin Muhammed Husayn was one of the 71 individuals deemed too innocent to charge but too dangerous to release. Although Obama promised that those deemed too innocent to charge but too dangerous to release would start to receive reviews from a Periodic Review Board less than a quarter of men have received a review.\n\nOn July 24, 2014 the European Court of Human Rights (ECHR) ruled that Poland had violated the European Convention on Human Rights when it cooperated with US allowing the CIA to hold and torture Zubaydah and Abd al-Rahim al-Nashiri on its territory in 2002–2003. The court ordered the Polish government to pay each of the men 100,000 euros in damages. It also awarded Zubaydah 30,000 euros to cover his costs.\n\n\n", "id": "3117", "title": "Abu Zubaydah"}
{"url": "https://en.wikipedia.org/wiki?curid=3118", "text": "Arithmetic\n\nArithmetic (from the Greek ἀριθμός \"arithmos\", \"number\") is a branch of mathematics that consists of the study of numbers, especially the properties of the traditional operations between them—addition, subtraction, multiplication and division. Arithmetic is an elementary part of number theory, and number theory is considered to be one of the top-level divisions of modern mathematics, along with algebra, geometry, and analysis. The terms \"arithmetic\" and \"higher arithmetic\" were used until the beginning of the 20th century as synonyms for \"number theory\" and are sometimes still used to refer to a wider part of number theory.\n\nThe prehistory of arithmetic is limited to a small number of artifacts which may indicate the conception of addition and subtraction, the best-known being the Ishango bone from central Africa, dating from somewhere between 20,000 and 18,000 BC, although its interpretation is disputed.\n\nThe earliest written records indicate the Egyptians and Babylonians used all the elementary arithmetic operations as early as 2000 BC. These artifacts do not always reveal the specific process used for solving problems, but the characteristics of the particular numeral system strongly influence the complexity of the methods. The hieroglyphic system for Egyptian numerals, like the later Roman numerals, descended from tally marks used for counting. In both cases, this origin resulted in values that used a decimal base but did not include positional notation. Complex calculations with Roman numerals required the assistance of a counting board or the Roman abacus to obtain the results.\n\nEarly number systems that included positional notation were not decimal, including the sexagesimal (base 60) system for Babylonian numerals and the vigesimal (base 20) system that defined Maya numerals. Because of this place-value concept, the ability to reuse the same digits for different values contributed to simpler and more efficient methods of calculation.\n\nThe continuous historical development of modern arithmetic starts with the Hellenistic civilization of ancient Greece, although it originated much later than the Babylonian and Egyptian examples. Prior to the works of Euclid around 300 BC, Greek studies in mathematics overlapped with philosophical and mystical beliefs. For example, Nicomachus summarized the viewpoint of the earlier Pythagorean approach to numbers, and their relationships to each other, in his \"Introduction to Arithmetic\".\n\nGreek numerals were used by Archimedes, Diophantus and others in a positional notation not very different from ours. Because the ancient Greeks lacked a symbol for zero (until the Hellenistic period), they used three separate sets of symbols. One set for the unit's place, one for the ten's place, and one for the hundred's. Then for the thousand's place they would reuse the symbols for the unit's place, and so on. Their addition algorithm was identical to ours, and their multiplication algorithm was only very slightly different. Their long division algorithm was the same, and the square root algorithm that was once taught in school was known to Archimedes, who may have invented it. He preferred it to Hero's method of successive approximation because, once computed, a digit doesn't change, and the square roots of perfect squares, such as 7485696, terminate immediately as 2736. For numbers with a fractional part, such as 546.934, they used negative powers of 60 instead of negative powers of 10 for the fractional part 0.934. The ancient Chinese used a similar positional notation. Because they also lacked a symbol for zero, they had one set of symbols for the unit's place, and a second set for the ten's place. For the hundred's place they then reused the symbols for the unit's place, and so on. Their symbols were based on the ancient counting rods. It is a complicated question to determine exactly when the Chinese started calculating with positional representation, but it was definitely before 400 BC. The Bishop of Syria, Severus Sebokht (650 AD), \"Indians possess a method of calculation that no word can praise enough. Their rational system of mathematics, or of their method of calculation. I mean the system using nine symbols.\"\n\nLeonardo of Pisa (Fibonacci) in 1200 AD wrote in \"Liber Abaci\" \"The method of the Indians (Modus Indoram) surpasses any known method to compute. It's a marvelous method. They do their computations using nine figures and symbol zero\".\n\nThe gradual development of Hindu–Arabic numerals independently devised the place-value concept and positional notation, which combined the simpler methods for computations with a decimal base and the use of a digit representing 0. This allowed the system to consistently represent both large and small integers. This approach eventually replaced all other systems. In the early the Indian mathematician Aryabhata incorporated an existing version of this system in his work, and experimented with different notations. In the 7th century, Brahmagupta established the use of 0 as a separate number and determined the results for multiplication, division, addition and subtraction of zero and all other numbers, except for the result of division by 0. His contemporary, the Syriac bishop Severus Sebokht described the excellence of this system as \"... valuable methods of calculation which surpass description\". The Arabs also learned this new method and called it \"hesab\".\nAlthough the Codex Vigilanus described an early form of Arabic numerals (omitting 0) by 976 AD, Fibonacci was primarily responsible for spreading their use throughout Europe after the publication of his book \"Liber Abaci\" in 1202. He considered the significance of this \"new\" representation of numbers, which he styled the \"Method of the Indians\" (Latin \"Modus Indorum\"), so fundamental that all related mathematical foundations, including the results of Pythagoras and the algorism describing the methods for performing actual calculations, were \"almost a mistake\" in comparison.\n\nIn the Middle Ages, arithmetic was one of the seven liberal arts taught in universities.\n\nThe flourishing of algebra in the medieval Islamic world and in Renaissance Europe was an outgrowth of the enormous simplification of computation through decimal notation.\n\nVarious types of tools have been invented and widely used to assist in numeric calculations. Before Renaissance, they were various types of abaci. More recent examples include slide rules, nomograms and mechanical calculators, such as Pascal's calculator. At present, they have been supplanted by electronic calculators and computers.\n\nThe basic arithmetic operations are addition, subtraction, multiplication and division, although this subject also includes more advanced operations, such as manipulations of percentages, square roots, exponentiation, and logarithmic functions. Arithmetic is performed according to an order of operations. Any set of objects upon which all four arithmetic operations (except division by 0) can be performed, and where these four operations obey the usual laws, is called a field.\n\nAddition is the basic operation of arithmetic. In its simplest form, addition combines two numbers, the \"addends\" or \"terms\", into a single number, the \"sum\" of the numbers (Such as or ).\n\nAdding more than two numbers can be viewed as repeated addition; this procedure is known as summation and includes ways to add infinitely many numbers in an infinite series; repeated addition of the number 1 is the most basic form of counting.\n\nAddition is commutative and associative so the order the terms are added in does not matter. The identity element of addition (the additive identity) is 0, that is, adding 0 to any number yields that same number. Also, the inverse element of addition (the additive inverse) is the opposite of any number, that is, adding the opposite of any number to the number itself yields the additive identity, 0. For example, the opposite of 7 is −7, so .\n\nAddition can be given geometrically as in the following example:\n\nSubtraction is the inverse of addition. Subtraction finds the \"difference\" between two numbers, the \"minuend\" minus the \"subtrahend\". If the minuend is larger than the subtrahend, the difference is positive; if the minuend is smaller than the subtrahend, the difference is negative; if they are equal, the difference is 0.\n\nSubtraction is neither commutative nor associative. For that reason, it is often helpful to look at subtraction as addition of the minuend and the opposite of the subtrahend, that is . When written as a sum, all the properties of addition hold.\n\nThere are several methods for calculating results, some of which are particularly advantageous to machine calculation. For example, digital computers employ the method of two's complement. Of great importance is the counting up method by which change is made. Suppose an amount \"P\" is given to pay the required amount \"Q\", with \"P\" greater than \"Q\". Rather than performing the subtraction and counting out that amount in change, money is counted out starting at \"Q\" and continuing until reaching \"P\". Although the amount counted out must equal the result of the subtraction , the subtraction was never really done and the value of might still be unknown to the change-maker.\n\nMultiplication is the second basic operation of arithmetic. Multiplication also combines two numbers into a single number, the \"product\". The two original numbers are called the \"multiplier\" and the \"multiplicand\", sometimes both simply called \"factors\".\n\nMultiplication may be viewed as a scaling operation. If the numbers are imagined as lying in a line, multiplication by a number, say \"x\", greater than 1 is the same as stretching everything away from 0 uniformly, in such a way that the number 1 itself is stretched to where \"x\" was. Similarly, multiplying by a number less than 1 can be imagined as squeezing towards 0. (Again, in such a way that 1 goes to the multiplicand.)\n\nMultiplication is commutative and associative; further it is distributive over addition and subtraction. The multiplicative identity is 1, that is, multiplying any number by 1 yields that same number. Also, the multiplicative inverse is the reciprocal of any number (except 0; 0 is the only number without a multiplicative inverse), that is, multiplying the reciprocal of any number by the number itself yields the multiplicative identity.\n\nThe product of \"a\" and \"b\" is written as or . When \"a\" or \"b\" are expressions not written simply with digits, it is also written by simple juxtaposition: \"ab\". In computer programming languages and software packages in which one can only use characters normally found on a keyboard, it is often written with an asterisk: \n\nDivision is essentially the inverse of multiplication. Division finds the \"quotient\" of two numbers, the \"dividend\" divided by the \"divisor\". Any dividend divided by 0 is undefined. For distinct positive numbers, if the dividend is larger than the divisor, the quotient is greater than 1, otherwise it is less than 1 (a similar rule applies for negative numbers). The quotient multiplied by the divisor always yields the dividend.\n\nDivision is neither commutative nor associative. As it is helpful to look at subtraction as addition, it is helpful to look at division as multiplication of the dividend times the reciprocal of the divisor, that is When written as a product, it obeys all the properties of multiplication.\n\nDecimal representation refers exclusively, in common use, to the written numeral system employing arabic numerals as the digits for a radix 10 (\"decimal\") positional notation; however, any numeral system based on powers of 10, e.g., Greek, Cyrillic, Roman, or Chinese numerals may conceptually be described as \"decimal notation\" or \"decimal representation\".\n\nModern methods for four fundamental operations (addition, subtraction, multiplication and division) were first devised by Brahmagupta of India. This was known during medieval Europe as \"Modus Indoram\" or Method of the Indians. Positional notation (also known as \"place-value notation\") refers to the representation or encoding of numbers using the same symbol for the different orders of magnitude (e.g., the \"ones place\", \"tens place\", \"hundreds place\") and, with a radix point, using those same symbols to represent fractions (e.g., the \"tenths place\", \"hundredths place\"). For example, 507.36 denotes 5 hundreds (10), plus 0 tens (10), plus 7 units (10), plus 3 tenths (10) plus 6 hundredths (10).\n\nThe concept of 0 as a number comparable to the other basic digits is essential to this notation, as is the concept of 0's use as a placeholder, and as is the definition of multiplication and addition with 0. The use of 0 as a placeholder and, therefore, the use of a positional notation is first attested to in the Jain text from India entitled the \"Lokavibhâga\", dated 458 AD and it was only in the early 13th century that these concepts, transmitted via the scholarship of the Arabic world, were introduced into Europe by Fibonacci using the Hindu–Arabic numeral system.\n\nAlgorism comprises all of the rules for performing arithmetic computations using this type of written numeral. For example, addition produces the sum of two arbitrary numbers. The result is calculated by the repeated addition of single digits from each number that occupies the same position, proceeding from right to left. An addition table with ten rows and ten columns displays all possible values for each sum. If an individual sum exceeds the value 9, the result is represented with two digits. The rightmost digit is the value for the current position, and the result for the subsequent addition of the digits to the left increases by the value of the second (leftmost) digit, which is always one. This adjustment is termed a \"carry\" of the value 1.\n\nThe process for multiplying two arbitrary numbers is similar to the process for addition. A multiplication table with ten rows and ten columns lists the results for each pair of digits. If an individual product of a pair of digits exceeds 9, the \"carry\" adjustment increases the result of any subsequent multiplication from digits to the left by a value equal to the second (leftmost) digit, which is any value from (). Additional steps define the final result.\n\nSimilar techniques exist for subtraction and division.\n\nThe creation of a correct process for multiplication relies on the relationship between values of adjacent digits. The value for any single digit in a numeral depends on its position. Also, each position to the left represents a value ten times larger than the position to the right. In mathematical terms, the exponent for the radix (base) of 10 increases by 1 (to the left) or decreases by 1 (to the right). Therefore, the value for any arbitrary digit is multiplied by a value of the form 10 with integer \"n\". The list of values corresponding to all possible positions for a single digit is written \n\nRepeated multiplication of any value in this list by 10 produces another value in the list. In mathematical terminology, this characteristic is defined as closure, and the previous list is described as closed under multiplication. It is the basis for correctly finding the results of multiplication using the previous technique. This outcome is one example of the uses of number theory.\n\nCompound unit arithmetic is the application of arithmetic operations to mixed radix quantities such as feet and inches, gallons and pints, pounds shillings and pence, and so on. Prior to the use of decimal-based systems of money and units of measure, the use of compound unit arithmetic formed a significant part of commerce and industry.\n\nThe techniques used for compound unit arithmetic were developed over many centuries and are well-documented in many textbooks in many different languages. In addition to the basic arithmetic functions encountered in decimal arithmetic, compound unit arithmetic employs three more functions:\n\nKnowledge of the relationship between the various units of measure, their multiples and their submultiples forms an essential part of compound unit arithmetic.\n\nThere are two basic approaches to compound unit arithmetic:\n\nDuring the 19th and 20th centuries various aids were developed to aid the manipulation of compound units, particularly in commercial applications. The most common aids were mechanical tills which were adapted in countries such as the United Kingdom to accommodate pounds, shillings, pennies and farthings and \"Ready Reckoners\" – books aimed at traders that catalogued the results of various routine calculations such as the percentages or multiples of various sums of money. One typical booklet that ran to 150 pages tabulated multiples \"from one to ten thousand at the various prices from one farthing to one pound\".\n\nThe cumbersome nature of compound unit arithmetic has been recognized for many years – in 1586, the Flemish mathematician Simon Stevin published a small pamphlet called \"De Thiende\" (\"the tenth\") in which he declared that the universal introduction of decimal coinage, measures, and weights to be merely a question of time while in the modern era, many conversion programs, such as that embedded in the calculator supplied as a standard part of the Microsoft Windows 7 operating system display compound units in a reduced decimal format rather than using an expanded format (i.e. \"2.5 ft\" is displayed rather than ).\n\nUntil the 19th century, \"number theory\" was a synonym of \"arithmetic\". The addressed problems were directly related to the basic operations and concerned primality, divisibility, and the solution of equations in integers, such as Fermat's last theorem. It appeared that most of these problems, although very elementary to state, are very difficult and may not be solved without very deep mathematics involving concepts and methods from many other branches of mathematics. This led to new branches of number theory such as analytic number theory, algebraic number theory, Diophantine geometry and arithmetic algebraic geometry. Wiles' proof of Fermat's Last Theorem is a typical example of the necessity of sophisticated methods, which go far beyond the classical methods of arithmetic, for solving problems that can be stated in elementary arithmetic.\n\nPrimary education in mathematics often places a strong focus on algorithms for the arithmetic of natural numbers, integers, fractions, and decimals (using the decimal place-value system). This study is sometimes known as algorism.\n\nThe difficulty and unmotivated appearance of these algorithms has long led educators to question this curriculum, advocating the early teaching of more central and intuitive mathematical ideas. One notable movement in this direction was the New Math of the 1960s and 1970s, which attempted to teach arithmetic in the spirit of axiomatic development from set theory, an echo of the prevailing trend in higher mathematics.\n\nAlso, arithmetic was used by Islamic Scholars in order to teach application of the rulings related to Zakat and Irth. This was done in a book entitled \"The Best of Arithmetic\" by Abd-al-Fattah-al-Dumyati.\n\nThe book begins with the foundations of mathematics and proceeds to its application in the later chapters.\n\n\n", "id": "3118", "title": "Arithmetic"}
{"url": "https://en.wikipedia.org/wiki?curid=3120", "text": "Andersonville, Georgia\n\nAndersonville is a city in Sumter County, Georgia, United States. As of the 2010 census, the city had a population of 255. It is located in the southwest part of the state, about southwest of Macon, Georgia on the Central of Georgia railroad. During the American Civil War, it was the site of a prisoner-of-war camp which is now Andersonville National Historic Site.\n\nAndersonville is part of the Americus Micropolitan Statistical Area.\n\nThe little hamlet of Anderson was named for John Anderson, a director of the South Western Railroad in 1853 when it was extended from Oglethorpe to Americus. It was known as Anderson Station until the US post office was established in November 1855. The government changed the name of the station from “Anderson” to “Andersonville” in order to avoid confusion with the post office in Anderson, South Carolina.\n\nDuring the Civil War, the Confederate army established Camp Sumter at Andersonville to house incoming Union prisoners of war. The town served as a supply depot during the war period. It included a post office, a depot, a blacksmith shop and stable, a couple of general stores, two saloons, a school, a Methodist church, and about a dozen houses. (Ben Dykes, who owned the land on which the prison was built, was both depot agent and postmaster.)\n\nUntil the establishment of the prison, the area was entirely dependent on agriculture. After the close of the prison and end of the war, the town continued economically dependent on agriculture, primarily the cultivation of cotton as a commodity crop. The town changed very little over the years.\n\nIt was not until 1968, when the large-scale mining of kaolin, bauxitic kaolin, and bauxite was begun by Mulcoa, Mullite Company of America, that the town was dramatically altered. This operation exploited of scrub oak wilderness into a massive mining and refining operation. The company now ships more than 2000 tons of refined ore from Andersonville each week.\n\nIn 1974, long-time mayor Lewis Easterlin and a group of concerned citizens decided to promote tourism in the town; they stressed its history, redeveloping Main Street to look much as it did during the American Civil War. The city of Andersonville and the Andersonville National Historic Site, location of the prison camp, welcomes tourists from all over the world. They come for the history, museums, and to step back in time.\n\nAs of the census of 2000, there were 331 people, 124 households, and 86 families residing in the city. The population density was 254.1 people per square mile (98.3/km²). There were 142 housing units at an average density of 109.0 per square mile (42.2/km²). The racial makeup of the city was 65.26% White and 34.74% African American. Hispanic or Latino of any race were 1.21% of the population.\n\nThere were 124 households out of which 34.7% had children under the age of 18 living with them, 46.0% were married couples living together, 17.7% had a female householder with no husband present, and 30.6% were non-families. 26.6% of all households were made up of individuals and 10.5% had someone living alone who was 65 years of age or older. The average household size was 2.67 and the average family size was 3.21.\n\nIn the city, the population was spread out with 27.8% under the age of 18, 9.4% from 18 to 24, 31.4% from 25 to 44, 19.3% from 45 to 64, and 12.1% who were 65 years of age or older. The median age was 36 years. For every 100 females there were 105.6 males. For every 100 females age 18 and over, there were 97.5 males.\n\nThe median income for a household in the city was $29,107, and the median income for a family was $30,972. Males had a median income of $26,591 versus $20,000 for females. The per capita income for the city was $15,168. About 19.8% of families and 23.0% of the population were below the poverty line, including 29.3% of those under age 18 and 13.5% of those age 65 or over.\n\n", "id": "3120", "title": "Andersonville, Georgia"}
{"url": "https://en.wikipedia.org/wiki?curid=3121", "text": "Andersonville\n\nAndersonville may refer to:\n\n\n\n\n", "id": "3121", "title": "Andersonville"}
{"url": "https://en.wikipedia.org/wiki?curid=3122", "text": "Agra Canal\n\nThe Agra Canal is an important Indian irrigation work which starts from Okhla in Delhi. The Agra canal originates from Okhla barrage, downstream of Nizamuddin bridge. It opened in 1874.\n\nIn the beginning, it was available for navigation, in Delhi, erstwhile Gurgaon, Mathura and Agra Districts, and Bharatpur State. Later, navigation was stopped in 1904 and the canal has since then, been exclusively used for irrigation purposes only. At present the canal does not flow in district Gurgaon, but only in Faridabad, which was earlier a part of Gurgaon.\n\nThe Canal receives its water from the Yamuna River at Okhla, about 10 km to the south of New Delhi. The weir across the Yamuna was the first attempted in Upper India upon a foundation of fine sand; it is about 800-yard long, and rises seven-feet above the summer level of the river.\n\nFrom Okhla the canal follows the high land between the Khari-Nadi and the Yamuna and finally joins the Banganga river about below Agra. Navigable branches connect the canal with Mathura and Agra.\nthe canal irrigates about 1.5 lakh hectares in Agra, and Mathura in Uttar Pradesh, Faridabad in Haryana, Bharatpur in Rajasthan and also some parts of Delhi\n\nThe Agra Canal also has many places to visit along its coast.\n", "id": "3122", "title": "Agra Canal"}
{"url": "https://en.wikipedia.org/wiki?curid=3123", "text": "Amakusa\n\nAmakusa (天草), which means \"Heaven's Grass,\" is a series of islands off the west coast of Kyushu, the southernmost of the four main islands of Japan.\n\nThe largest island of the Amakusa group is Shimoshima, which is 26.5 miles long and 13.5 miles in extreme width (). It is situated at 32°20'N, 130°E, separated from the rest of Kumamoto Prefecture by the Yatsushiro Sea.\n\nIt has no high mountains, but its surface is very hilly. Four of the peaks rise to a height of over . The population resorts to the terrace system of cultivation to cope with the lack of flat arable land.\n\nAmakusa, along with the neighboring Shimabara Peninsula, became the site of the Shimabara rebellion in the 17th century, led by Christians. Following the rebellion, Kakure Kirishitan, the Christians who had survived, continued to practice their faith in secret, despite massive persecution.\n\nAmakusa produces a little coal and pottery stone, both being used by the potters of Hirado and Satsuma Province. Many kilns remain on the islands today, and pottery and pottery stone are still exported.\n\nAmakusa pottery has been recognised by the government. The retail company Muji brought out its own line of \"Hakuji\" home ware, which is produced out of ground translucent Amakusa stones kneaded into clay, using traditional techniques.\n\nHidenoshin Koyama, who built Thomas Blake Glover's House in Glover Garden, came from this island.\n\nAt present, the islands are organized as Amakusa District, Amakusa City, and Kami-amakusa City, all of which are under the administration of Kumamoto Prefecture.\n\nThe islands are served by Amakusa Airfield, located on the north end of Shimoshima. The islands are connected to the mainland by the Five Bridges of Amakusa and by ferry from Hondo and Matsushima.\n\nThere are also ferries between the islands and the neighboring prefectures of Kagoshima Prefecture and Nagasaki Prefecture. The ferry from Oniike on the north Shimoshima to Kuchinotsu, at the southern tip of the Shimabara Peninsula, is run by the Shimabara Railway and operates hourly each day. The ferry boat from Tomioka Port in Reihoku, sailing north to Mogi in Nagasaki Prefecture, is operated by Yasuda Sangyo Kisen Co. Ltd.\nTwo ferries from Shinwa and Ushibuka, in the south of Shimoshima, connect Amakusa to Nagashima in Kagoshima Prefecture.\n", "id": "3123", "title": "Amakusa"}
{"url": "https://en.wikipedia.org/wiki?curid=3124", "text": "Afterglow\n\nAn afterglow is a broad high arch of whitish or rosy light appearing in the sky due to very fine particles of dust suspended in the high regions of the atmosphere. An afterglow may appear above the highest clouds in the hour of deepening twilight, or reflected from the high snowfields in mountain regions long after sunset. The particles produce a scattering effect upon the component parts of white light. The true alpenglow, which occurs long after sunset or long before sunrise, is caused by the backscattering of red sunlight by aerosols and fine dust particles low in the atmosphere. It is an afterglow caused by direct illumination of atmospheric particles by sunlight as it refracts and gets scattered through the Earth's atmosphere. The high-energy and high-frequency light is scattered out the most and the remaining low-energy, low-frequency reaches the observer in the horizon at twilight. The backscattering of this light further turns it pinkish-red. This period of time is referred to as the blue hour and is widely treasured by photographers and painters as it offers breathtaking imagery.\nThe afterglow persists till the Earth's shadow (terminator line) takes over the sky of the observer as nightfall and the stars appear, with planet Venus being the brightest object (after the moon) visible in the night sky just opposite to the Belt of Venus at the anti-solar point.\n\nAfter the eruption of the volcano Krakatoa in 1883, a remarkable series of red sunsets appeared worldwide. These were due to an enormous amount of exceedingly fine dust blown to a great height by the volcano's explosion, and then globally diffused by the high atmospheric currents. Edvard Munch's painting \"The Scream\" possibly depicts an afterglow during this period.\n\n", "id": "3124", "title": "Afterglow"}
{"url": "https://en.wikipedia.org/wiki?curid=3125", "text": "Ammonius Grammaticus\n\nAmmonius Grammaticus was a 4th-century Egyptian priest who, after the destruction of the pagan temple at Alexandria (389), fled to Constantinople, where he became the tutor of the ecclesiastical historian Socrates.\nAmmonius was formerly identified as the author of a treatise titled \"Peri homoíōn kai diaphórōn léxeōn\" (περὶ ὁμοίων καὶ διαφόρων λέξεων, \"On the Differences of Synonymous Expressions\").\nBut it seems more probable that the real author was Herennius Philo of Byblus, who was born during the reign of Nero and lived till the reign of Hadrian, and that the treatise in its present form is a revision prepared by a later Byzantine editor, whose name may have been Ammonius.\n\n", "id": "3125", "title": "Ammonius Grammaticus"}
{"url": "https://en.wikipedia.org/wiki?curid=3129", "text": "Algebraic closure\n\nIn mathematics, particularly abstract algebra, an algebraic closure of a field \"K\" is an algebraic extension of \"K\" that is algebraically closed. It is one of many closures in mathematics.\n\nUsing Zorn's lemma, it can be shown that every field has an algebraic closure, and that the algebraic closure of a field \"K\" is unique up to an isomorphism that fixes every member of \"K\". Because of this essential uniqueness, we often speak of \"the\" algebraic closure of \"K\", rather than \"an\" algebraic closure of \"K\".\n\nThe algebraic closure of a field \"K\" can be thought of as the largest algebraic extension of \"K\".\nTo see this, note that if \"L\" is any algebraic extension of \"K\", then the algebraic closure of \"L\" is also an algebraic closure of \"K\", and so \"L\" is contained within the algebraic closure of \"K\".\nThe algebraic closure of \"K\" is also the smallest algebraically closed field containing \"K\",\nbecause if \"M\" is any algebraically closed field containing \"K\", then the elements of \"M\" that are algebraic over \"K\" form an algebraic closure of \"K\".\n\nThe algebraic closure of a field \"K\" has the same cardinality as \"K\" if \"K\" is infinite, and is countably infinite if \"K\" is finite.\n\n\nLet formula_1 be the set of all monic irreducible polynomials in \"K\"[\"x\"].\nFor each formula_2, introduce new variables formula_3 where formula_4.\nLet \"R\" be the polynomial ring over \"K\" generated by formula_5 for all formula_6 and all formula_7. Write\n\nwith formula_9.\nLet \"I\" be the ideal in \"R\" generated by the formula_10. Since \"I\" is strictly smaller than \"R\",\nZorn's lemma implies that there exists a maximal ideal \"M\" in \"R\" that contains \"I\".\nThe field \"K\"=\"R\"/\"M\" has the property that every polynomial formula_11 with coefficients in \"K\" splits as the product of formula_12 and hence has all roots in \"K\". In the same way, an extension \"K\" of \"K\" can be constructed, etc. The union of all these extensions is the algebraic closure of \"K\", because any polynomial with coefficients in this new field has its coefficients in some \"K\" with sufficiently large \"n\", and then its roots are in \"K\", and hence in the union itself. \n\nIt can be shown along the same lines that for any subset \"S\" of \"K\"[\"x\"], there exists a splitting field of \"S\" over \"K\".\n\nAn algebraic closure \"K\" of \"K\" contains a unique separable extension \"K\" of \"K\" containing all (algebraic) separable extensions of \"K\" within \"K\". This subextension is called a separable closure of \"K\". Since a separable extension of a separable extension is again separable, there are no finite separable extensions of \"K\", of degree > 1. Saying this another way, \"K\" is contained in a \"separably-closed\" algebraic extension field. It is unique (up to isomorphism).\n\nThe separable closure is the full algebraic closure if and only if \"K\" is a perfect field. For example, if \"K\" is a field of characteristic \"p\" and if \"X\" is transcendental over \"K\", formula_13 is a non-separable algebraic field extension.\n\nIn general, the absolute Galois group of \"K\" is the Galois group of \"K\" over \"K\".\n\n\n", "id": "3129", "title": "Algebraic closure"}
{"url": "https://en.wikipedia.org/wiki?curid=3130", "text": "Advanced Power Management\n\nAdvanced power management (APM) is an API developed by Intel and Microsoft and released in 1992 which enables an operating system running an IBM-compatible personal computer to work with the BIOS (part of the computer's firmware) to achieve power management.\n\nRevision 1.2 was the last version of the APM specification, released in 1996. ACPI is intended as the successor to APM. Microsoft dropped support for APM in Windows Vista. The Linux kernel still mostly supports APM, with the last fully functional APM support shipping in 3.3.\n\nAPM uses a layered approach to manage devices. APM-aware applications (which include device drivers) talk to an OS-specific APM driver. This driver communicates to the APM-aware BIOS, which controls the hardware. There is the ability to opt out of APM control on a device-by-device basis, which can be used if a driver wants to communicate directly with a hardware device.\n\nCommunication occurs both ways; power management events are sent from the BIOS to the APM driver, and the APM driver sends information and requests to the BIOS via function calls. In this way the APM driver is an intermediary between the BIOS and the operating system.\n\nPower management happens in two ways; through the above-mentioned function calls from the APM driver to the BIOS requesting power state changes, and automatically based on device activity.\n\nThere are 12 power events (such as standby, suspend and resume requests, and low battery notifications), plus OEM-defined events, that can be sent from the APM BIOS to the operating system. The APM driver regularly polls for event change notifications.\n\nPower Management Events:\nPower management functions:\nThere are 21 APM function calls defined that the APM driver can use to query power management statuses, or request power state transitions. Example function calls include letting the BIOS know about current CPU usage (the BIOS may respond to such a call by placing the CPU in a low-power state, or returning it to its full-power state), retrieving the current power state of a device, or requesting a power state change.\n\nThe APM specification defines system power states and device power states.\n\nAPM defines five power states for the computer system:\n\nAPM also defines power states that APM-aware hardware can implement. There is no requirement that an APM-aware device implement all states.\n\nThe four states are:\n\nThe CPU core (defined in APM as the CPU clock, cache, system bus and system timers) is treated specially in APM, as it is the last device to be powered down, and the first device to be powered back up. The CPU core is always controlled through the APM BIOS (there is no option to control it through a driver). Drivers can use APM function calls to notify the BIOS about CPU usage, but it is up to the BIOS to act on this information; a driver cannot directly tell the CPU to go into a power saving state.\n\n\n", "id": "3130", "title": "Advanced Power Management"}
{"url": "https://en.wikipedia.org/wiki?curid=3132", "text": "Adolphe Sax\n\nAntoine-Joseph \"Adolphe\" Sax (; 6 November 1814 – c. 7 February 1894) was a Belgian inventor and musician who invented the saxophone in 1846. He played the flute and clarinet, and his other inventions are the saxotromba, saxhorn and saxtuba.\n\nAntoine-Joseph Sax was born on 6 November 1814, in Dinant, Belgium, to Charles-Joseph Sax and his wife. While his first name was Antoine, he was referred to as Adolphe from childhood. His father and mother were instrument designers themselves, who made several changes to the design of the horn. Adolphe began to make his own instruments at an early age, entering two of his flutes and a clarinet into a competition at the age of 15. He subsequently studied performance on those two instruments as well as voice at the Royal Conservatory of Brussels.\n\nAccording to the biography of Adolphe Sax published on the city of Dinant's website, Sax faced many near-death experiences. Over the course of his childhood, he:\n\n\nAlso according to the biography, his mother once said that \"He's a child condemned to misfortune; he won't live\". His neighbors called him \"little Sax, the ghost\".\n\nAfter leaving the Royal Conservatory of Brussels, Sax began to experiment with new instrument designs, while his parents continued to make conventional instruments to bring in money. Adolphe's first important invention was an improvement of the bass clarinet design, which he patented at the age of 24. Sax relocated permanently to Paris in 1841 and began working on a new set of instruments exhibited there in 1844. These were valved bugles, and although he had not invented the instrument itself, his examples were much more successful than those of his rivals and became known as saxhorns. They came in approximately seven different sizes, and paved the path to the creation of the flugelhorn. Today, saxhorns are sometimes used in concert bands and orchestras. The saxhorn also laid the groundwork for the modern euphonium.\n\nSax also developed the \"saxotromba\" family, valved brass instruments with narrower bore than the saxhorns, in 1845, though they survived only briefly.\n\nSaxhorn instruments spread rapidly. The saxhorn valves were accepted as state-of-the-art and are largely unchanged today. The advances made by Adolphe Sax were soon followed by the British brass band movement which exclusively adopted the saxhorn range. The Jedforest Instrumental Band formed in 1854 and The Hawick Saxhorn Band formed in 1855, within the Scottish Borders, a decade after saxhorn models became available.\n\nThe period around 1840 saw Sax inventing the \"clarinette-bourdon\", an early unsuccessful design of contrabass clarinet. Around this time he also developed the instrument for which he is best known, the saxophone, patented on 28 June 1846. The saxophone was invented for use in both orchestras and concert bands. Composer Hector Berlioz wrote approvingly of the new instrument in 1842. By 1846 Sax had designed, on paper, a full range of saxophones (from sopranino to subcontrabass). Although they never became standard orchestral instruments, the saxophones made his reputation and secured him a job, teaching at the Paris Conservatoire in 1857.\n\nSax continued to make instruments later in life and presided over the new saxophone class at the Paris Conservatoire. Rival instrument makers attacked the legitimacy of his patents and mounted a long campaign of litigation against Sax and his company. He was driven into bankruptcy in 1856 and again in 1873.\n\nSax suffered from lip cancer between 1853 and 1858 but made a full recovery. In 1894 Sax died in complete poverty in Paris and was interred in section 5 (Avenue de Montebello) at the Cimetière de Montmartre in Paris.\n\n\n\n", "id": "3132", "title": "Adolphe Sax"}
{"url": "https://en.wikipedia.org/wiki?curid=3134", "text": "Aspirated consonant\n\nIn phonetics, aspiration is the strong burst of breath that accompanies either the release or, in the case of preaspiration, the closure of some obstruents. In English, aspirated consonants are allophones in complementary distribution with their unaspirated counterparts, but in some other languages, notably most Indian and East Asian languages, the difference is contrastive, while in Arabic and Persian, all stops are aspirated.\n\nTo feel or see the difference between aspirated and unaspirated sounds, one can put a hand or a lit candle in front of one's mouth, and say \"spin\" and then \"pin\" . One should either feel a puff of air or see a flicker of the candle flame with \"pin\" that one does not get with \"spin\".\n\nIn the International Phonetic Alphabet (IPA), aspirated consonants are written using the symbols for voiceless consonants followed by the aspiration modifier letter , a superscript form of the symbol for the voiceless glottal fricative . For instance, represents the voiceless bilabial stop, and represents the aspirated bilabial stop.\n\nVoiced consonants are seldom actually aspirated. Symbols for voiced consonants followed by , such as , typically represent consonants with murmured voiced release (see below). In the grammatical tradition of Sanskrit, aspirated consonants are called voiceless aspirated, and breathy-voiced consonants are called voiced aspirated.\n\nThere are no dedicated IPA symbols for degrees of aspiration and typically only two degrees are marked: unaspirated and aspirated . An old symbol for light aspiration was , but this is now obsolete. The aspiration modifier letter may be doubled to indicate especially strong or long aspiration. Hence, the two degrees of aspiration in Korean stops are sometimes transcribed or and , but they are usually transcribed and , with the details of voice-onset time given numerically.\n\nPreaspirated consonants are marked by placing the aspiration modifier letter before the consonant symbol: represents the preaspirated bilabial stop.\n\nUnaspirated or tenuis consonants are occasionally marked with the modifier letter for unaspiration , a superscript equals sign: . Usually, however, unaspirated consonants are left unmarked: .\n\nVoiceless consonants are produced with the vocal folds open (spread) and not vibrating, and voiced consonants are produced when the vocal folds are fractionally closed and vibrating (modal voice). Voiceless aspiration occurs when the vocal cords remain open after a consonant is released. An easy way to measure this is by noting the consonant's voice-onset time, as the voicing of a following vowel cannot begin until the vocal cords close.\n\nPhonetically in some languages, such as Navajo, aspiration of stops tends to be realised as voiceless velar airflow; aspiration of affricates is realised as an extended length of the frication.\n\nAspirated consonants are not always followed by vowels or other voiced sounds. For example, in Eastern Armenian, aspiration is contrastive even word-finally, and aspirated consonants occur in consonant clusters. In Wahgi, consonants are aspirated only in final position.\n\nThe degree of aspiration varies: the voice-onset time of aspirated stops is longer or shorter depending on the language or the place of articulation.\n\nArmenian and Cantonese have aspiration that lasts about as long as English aspirated stops, in addition to unaspirated stops. Korean has lightly aspirated stops that fall between the Armenian and Cantonese unaspirated and aspirated stops as well as strongly aspirated stops whose aspiration lasts longer than that of Armenian or Cantonese. (See voice-onset time.)\n\nAspiration varies with place of articulation. The Spanish voiceless stops have voice-onset times (VOTs) of about 5, 10, and 30 milliseconds, whereas English aspirated have VOTs of about 60, 70, and 80 ms. Voice-onset time in Korean has been measured at 20, 25, and 50 ms for and 90, 95, and 125 for .\n\nWhen aspirated consonants are doubled or geminated, the stop is held longer and then has an aspirated release. An aspirated affricate consists of a stop, fricative, and aspirated release. A doubled aspirated affricate has a longer hold in the stop portion and then has a release consisting of the fricative and aspiration.\n\nIcelandic and Faroese have consonants with preaspiration , and some scholars interpret them as consonant clusters as well. In Icelandic, preaspirated stops contrast with double stops and single stops (see :\n\nPreaspirated stops also occur in most Sami languages. For example, in Northern Sami, the unvoiced stop and affricate phonemes , , , , are pronounced preaspirated (, , , ) in medial or final position.\n\nAlthough most aspirated obstruents in the world's languages are stops and affricates, aspirated fricatives such as , or have been documented in Korean, in a few Tibeto-Burman languages, in some Oto-Manguean languages, and in the Siouan language Ofo. Some languages, such as Choni Tibetan, have up to four contrastive aspirated fricatives , and .\n\nTrue aspirated voiced consonants, as opposed to murmured (breathy-voice) consonants such as the that are common in the languages of India, are extremely rare. They have been documented in Kelabit Taa, and the Kx'a languages. Reported aspirated voiced stops, affricates and clicks are .\n\nAspiration has varying significance in different languages. It is either allophonic or phonemic, and may be analyzed as an underlying consonant cluster.\n\nIn some languages, such as English, aspiration is allophonic. Stops are distinguished primarily by voicing, and voiceless stops are sometimes aspirated, while voiced stops are usually unaspirated.\n\nEnglish voiceless stops are aspirated for most native speakers when they are word-initial or begin a stressed syllable, as in \"pill\", \"till\", \"kill\".\n\nThey are unaspirated for almost all speakers when immediately following word-initial s, as in \"spill\", \"still\", \"skill\". After an \"s\" elsewhere in a word they are normally unaspirated as well, except sometimes in compound words. When the consonants in a cluster like \"st\" are analyzed as belonging to different morphemes (heteromorphemic) the stop is aspirated, but when they are analyzed as belonging to one morpheme the stop is unaspirated. For instance, \"distend\" has unaspirated since it is not analyzed as two morphemes, but \"distaste\" has an aspirated middle because it is analyzed as \"dis-\" + \"taste\" and the word \"taste\" has an aspirated initial \"t\".\n\nWord-final voiceless stops are sometimes aspirated.\n\nVoiceless stops in Pashto are slightly aspirated prevocalically in a stressed syllable.\n\nIn many languages, such as Armenian, Korean, Thai, Indo-Aryan languages, Dravidian languages, Icelandic, Ancient Greek, and the varieties of Chinese, tenuis and aspirated consonants are phonemic. Unaspirated consonants like and aspirated consonants like are separate phonemes, and words are distinguished by whether they have one or the other.\n\nAlemannic German dialects have unaspirated as well as aspirated ; the latter series are usually viewed as consonant clusters.\n\nIn Danish and most southern varieties of German, the \"lenis\" consonants transcribed for historical reasons as are distinguished from their fortis counterparts , mainly in their lack of aspiration.\n\nFrench, Standard Dutch, Tamil, Italian, Russian, Spanish, Modern Greek, and Latvian are languages that do not have aspirated consonants.\n\nStandard Chinese (Mandarin) has stops and affricates distinguished by aspiration: for instance, , . In pinyin, tenuis stops are written with letters that represent voiced consonants in English, and aspirated stops with letters that represent voiceless consonants. Thus \"d\" represents , and \"t\" represents .\n\nWu Chinese and Southern Min has a three-way distinction in stops and affricates: . In addition to aspirated and unaspirated consonants, there is a series of \"muddy consonants\", like . These are pronounced with slack or breathy voice: that is, they are weakly voiced. Muddy consonants as initial cause a syllable to be pronounced with low pitch or \"light\" (陽 \"yáng\") tone.\n\nMany Indo-Aryan languages have aspirated stops. Sanskrit, Hindi, Bengali, Marathi, and Gujarati have a four-way distinction in stops: voiceless, aspirated, voiced, and breathy-voiced or voiced aspirated, such as . Punjabi has lost breathy-voiced consonants, which resulted in a tone system, and therefore has a distinction between voiceless, aspirated, and voiced: .\n\nSome of the Dravidian languages, such as Telugu, Tamil, Malayalam, and Kannada, have a distinction between voiced and voiceless, aspirated and unaspirated only in loanwords from Indo-Aryan languages. In native Dravidian words, there is no distinction between these categories and stops are underspecified for voicing and aspiration.\n\nMost dialects of Armenian have aspirated stops, and some have breathy-voiced stops.\n\nClassical and Eastern Armenian have a three-way distinction between voiceless, aspirated, and voiced, such as .\n\nWestern Armenian has a two-way distinction between aspirated and voiced: . Western Armenian aspirated corresponds to Eastern Armenian aspirated and voiced , and Western voiced corresponds to Eastern voiceless .\n\nSome forms of Greek before the Koine Greek period are reconstructed as having aspirated stops. The Classical Attic dialect of Ancient Greek had a three-way distinction in stops like Eastern Armenian: . These series were called , , (\"psilá, daséa, mésa\") \"smooth, rough, intermediate\", respectively, by Koine Greek grammarians.\n\nThere were aspirated stops at three places of articulation: labial, coronal, and velar . Earlier Greek, represented by Mycenaean Greek, likely had a labialized velar aspirated stop , which later became labial, coronal, or velar depending on dialect and phonetic environment.\n\nThe other Ancient Greek dialects, Ionic, Doric, Aeolic, and Arcadocypriot, likely had the same three-way distinction at one point, but Doric seems to have had a fricative in place of in the Classical period, and the Ionic and Aeolic dialects sometimes lost aspiration (psilosis).\n\nLater, during the Koine Greek period, the aspirated and voiced stops of Attic Greek lenited to voiceless and voiced fricatives, yielding in Medieval and Modern Greek.\n\nThe term \"aspiration\" sometimes refers to the sound change of debuccalization, in which a consonant is lenited (weakened) to become a glottal stop or fricative .\n\nSo-called voiced aspirated consonants are nearly always pronounced instead with breathy voice, a type of phonation or vibration of the vocal folds. The modifier letter after a voiced consonant actually represents a breathy-voiced or murmured dental stop, as with the \"voiced aspirated\" bilabial stop in the Indo-Aryan languages. This consonant is therefore more accurately transcribed as , with the diacritic for breathy voice, or with the modifier letter , a superscript form of the symbol for the voiced glottal fricative .\n\nSome linguists restrict the double-dot subscript to murmured sonorants, such as vowels and nasals, which are murmured throughout their duration, and use the superscript hook-aitch for the breathy-voiced release of obstruents.\n\n", "id": "3134", "title": "Aspirated consonant"}
{"url": "https://en.wikipedia.org/wiki?curid=3135", "text": "Arteriovenous malformation\n\nArteriovenous malformation (AVM) is an abnormal connection between arteries and veins, bypassing the capillary system. This vascular anomaly is widely known because of its occurrence in the central nervous system (usually cerebral AVM), but can appear in any location. Although many AVMs are asymptomatic, they can cause intense pain or bleeding or lead to other serious medical problems.\n\nAVMs are usually congenital and belong to the RASopathies.\nThe genetic transmission patterns of AVM, if any, are unknown. AVM is not generally thought to be an inherited disorder, unless in the context of a specific hereditary syndrome.\n\nSymptoms of AVM vary according to the location of the malformation. Roughly 88% of people with an AVM are asymptomatic; often the malformation is discovered as part of an autopsy or during treatment of an unrelated disorder (called in medicine an \"incidental finding\"); in rare cases, its expansion or a micro-bleed from an AVM in the brain can cause epilepsy, neurological deficit, or pain.\n\nThe most general symptoms of a cerebral AVM include headaches and epileptic seizures, with more specific symptoms occurring that normally depend on the location of the malformation and the individual. Such possible symptoms include:\n\n\nCerebral AVMs may present themselves in a number of different ways:\n\n\nIn the lungs, pulmonary arteriovenous malformations have no symptoms in up to 29% of all cases.\n\nCan occur due to autosomal dominant diseases, such as hereditary hemorrhagic telangiectasia.\n\nArteries and veins are part of the human cardiovascular system. Arteries carry blood away from the heart to the lungs or the rest of the body, where the blood passes through capillaries, and veins return the blood to the heart. An AVM interferes with this process by forming a direct connection of the arteries and veins. AVMs can cause intense pain and lead to serious medical problems. Although AVMs are often associated with the brain and spinal cord, they can develop in any part of the body.\n\nNormally, the arteries in the vascular system carry oxygen-rich blood, except in the case of the pulmonary artery. Structurally, arteries divide and sub-divide repeatedly, eventually forming a sponge-like capillary bed. Blood moves through the capillaries, giving up oxygen and taking up waste products, including , from the surrounding cells. Capillaries in turn successively join together to form veins that carry blood away. The heart acts to pump blood through arteries and uptake the venous blood.\n\nAn AVM lacks the dampening effect of capillaries on the blood flow, which means that the AVM can get progressively larger over time as the amount of blood flowing through it increases, forcing the heart to work harder to keep up with the extra blood flow. It also causes the surrounding area to be deprived of the functions of the capillaries—removal of and delivery of nutrients to the cells. The resulting tangle of blood vessels, often called a \"nidus\" (Latin for \"nest\"), has no capillaries. It can be extremely fragile and prone to bleeding because of the abnormally direct connections between high-pressure arteries and low-pressure veins. The resultant sign, audible via stethoscope, is a rhythmic, whooshing sound caused by excessively rapid blood flow through the arteries and veins. It has been given the term \"bruit\", French for noise. On some occasions, a patient with a brain AVM may become aware of the noise, which can compromise hearing and interfere with sleep in addition to causing psychological distress.\n\nAVMs are diagnosed primarily by the following methods:\n\nAVMs can occur in various parts of the body:\n\nAVMs may occur in isolation or as a part of another disease (for example, Von Hippel-Lindau disease or hereditary hemorrhagic telangiectasia).\n\nAVMs have been shown to be associated with aortic stenosis.\n\nBleeding from an AVM can be relatively mild or devastating. It can cause severe and less often fatal strokes. If a cerebral AVM is detected before a stroke occurs, usually the arteries feeding blood into the nidus can be closed off to avert the danger. However, interventional therapy may also be relatively risky. \nTreatment for brain AVMs can be symptomatic, and patients should be followed by a neurologist for any seizures, headaches, or focal neurologic deficits. AVM-specific treatment may also involve endovascular embolization, neurosurgery or radiosurgery.\nEmbolization, that is, cutting off the blood supply to the AVM with coils, particles, acrylates, or polymers introduced by a radiographically guided catheter, may be used in addition to neurosurgery or radiosurgery, but is rarely successful in isolation except in smaller AVMs. Gamma knife may also be used.\n\nThe estimated detection rate of AVM in the US general population is 1.4/100,000 per year. This is approximately one fifth to one seventh the incidence of intracranial aneurysms. An estimated 300,000 Americans have AVMs, of whom 12% (approximately 36,000) will exhibit symptoms of greatly varying severity.\n\nEmmanuel, Luschka, and Virchow first described arteriovenous malformations in the mid-1800s. Olivecrona performed the first surgical excision of an intracranial AVM in 1932.\n\n\n\nDespite many years of research, the central question of whether to treat AVMs has not been answered. All treatments, whether involving surgery, radiation, or drugs, have risks and side-effects. Therefore, it might be better in some cases to avoid treatment altogether and simply accept a small risk of coming to harm from the AVM itself. This question is currently being addressed in clinical trials.\n\n", "id": "3135", "title": "Arteriovenous malformation"}
{"url": "https://en.wikipedia.org/wiki?curid=3138", "text": "Atlanta\n\nAtlanta is the capital of and the most populous city in the U.S. state of Georgia, with an estimated 2015 population of 463,878. Atlanta is the cultural and economic center of the Atlanta metropolitan area, home to 5,710,795 people and the ninth largest metropolitan area in the United States. Atlanta is the county seat of Fulton County, and a small portion of the city extends eastward into DeKalb County.\n\nIn 1837, Atlanta was founded at the intersection of two railroad lines, and the city rose from the ashes of the American Civil War to become a national center of commerce. In the decades following the Civil Rights Movement, the city earned a reputation as \"too busy to hate\" for the relatively progressive views of its citizens and leaders compared to other cities in the Deep South. Atlanta attained international prominence, and it became the primary transportation hub of the Southeastern United States, via highway, railroad, and air, with Hartsfield–Jackson Atlanta International Airport being the world's busiest airport since 1998.\n\nAtlanta rated an \"alpha -\" world city that exerts a significant impact upon commerce, finance, research, technology, education, media, art, and entertainment.It ranks 40th among world cities and 8th in the nation with a gross domestic product of $270 billion. Atlanta's economy is considered diverse, with dominant sectors that include logistics, professional and business services, media operations, and information technology. Atlanta has topographic features that include rolling hills and dense tree coverage. Revitalization of Atlanta's neighborhoods, initially spurred by the 1996 Olympics in Atlanta, has intensified in the 21st century, altering the city's demographics, politics, and culture.\n\nPrior to the arrival of European settlers in north Georgia, Creek Indians inhabited the area. Standing Peachtree, a Creek village located where Peachtree Creek flows into the Chattahoochee River, was the closest Indian settlement to what is now Atlanta. As part of the systematic removal of Native Americans from northern Georgia from 1802 to 1825, the Creek ceded the area in 1821, and white settlers arrived the following year.\nIn 1836, the Georgia General Assembly voted to build the Western and Atlantic Railroad in order to provide a link between the port of Savannah and the Midwest. The initial route was to run southward from Chattanooga to a terminus east of the Chattahoochee River, which would then be linked to Savannah. After engineers surveyed various possible locations for the terminus, the \"zero milepost\" was driven into the ground in what is now Five Points. A year later, the area around the milepost had developed into a settlement, first known as \"Terminus,\" and later as \"Thrasherville\" after a local merchant who built homes and a general store in the area. By 1842, the town had six buildings and 30 residents and was renamed \"Marthasville\" to honor the Governor's daughter. Later, J. Edgar Thomson, Chief Engineer of the Georgia Railroad, suggested the town be renamed \"Atlantica-Pacifica,\" which was shortened to \"Atlanta\". The residents approved, and the town was incorporated as Atlanta on December 29, 1847.\n\nBy 1860, Atlanta's population had grown to 9,554. During the American Civil War, the nexus of multiple railroads in Atlanta made the city a hub for the distribution of military supplies. In 1864, the Union Army moved southward following the capture of Chattanooga and began its invasion of north Georgia. The region surrounding Atlanta was the location of several major army battles, culminating with the Battle of Atlanta and a four-month-long siege of the city by the Union Army under the command of General William Tecumseh Sherman. On September 1, 1864, Confederate General John Bell Hood made the decision to retreat from Atlanta, and he ordered the destruction of all public buildings and possible assets that could be of use to the Union Army. On the next day, Mayor James Calhoun surrendered Atlanta to the Union Army, and on September 7, Sherman ordered the city's civilian population to evacuate. On November 11, 1864, Sherman prepared for the Union Army's March to the Sea by ordering Atlanta to be burned to the ground, sparing only the city's churches and hospitals.\n\nAfter the Civil War ended in 1865, Atlanta was gradually rebuilt. Due to the city's superior rail transportation network, the state capital was moved from Milledgeville to Atlanta in 1868. In the 1880 Census, Atlanta surpassed Savannah as Georgia's largest city.\nBeginning in the 1880s, Henry W. Grady, the editor of the \"Atlanta Constitution\" newspaper, promoted Atlanta to potential investors as a city of the \"New South\" that would be based upon a modern economy and less reliant on agriculture. By 1885, the founding of the Georgia School of Technology (now Georgia Tech) and the city's black colleges had established Atlanta as a center for higher education. In 1895, Atlanta hosted the Cotton States and International Exposition, which attracted nearly 800,000 attendees and successfully promoted the New South's development to the world.\n\nDuring the first decades of the 20th century, Atlanta experienced a period of unprecedented growth. In three decades' time, Atlanta's population tripled as the city limits expanded to include nearby streetcar suburbs. The city's skyline emerged with the construction of the Equitable, Flatiron, Empire, and Candler buildings; and Sweet Auburn emerged as a center of black commerce. The period was also marked by strife and tragedy. Increased racial tensions led to the Atlanta Race Riot of 1906, which left at least 27 people dead and over 70 injured. In 1915, Leo Frank, a Jewish-American factory superintendent, convicted of murder, was hanged in Marietta by a lynch mob, drawing attention to antisemitism in the United States. On May 21, 1917, the Great Atlanta Fire destroyed 1,938 buildings in what is now the Old Fourth Ward, resulting in one fatality and the displacement of 10,000 people.\n\nOn December 15, 1939, Atlanta hosted the premiere of \"Gone with the Wind\", the epic film based on the best-selling novel by Atlanta's Margaret Mitchell. The gala event at Loew's Grand Theatre was attended by the film's legendary producer, David O. Selznick, and the film's stars Clark Gable, Vivien Leigh, and Olivia de Havilland, but Oscar winner Hattie McDaniel, an African American actress, was barred from the event due to racial segregation laws and policies.\n\nAtlanta played a vital role in the Allied effort during World War II due to the city's war-related manufacturing companies, railroad network, and military bases, leading to rapid population and economic growth. In the 1950s, the city's newly constructed highway system allowed middle class Atlantans the ability to relocate to the suburbs. As a result, the city began to make up an ever-smaller proportion of the metropolitan area's population.\n\nDuring the 1960s, Atlanta was a major organizing center of the Civil Rights Movement, with Dr. Martin Luther King, Jr., Ralph David Abernathy, and students from Atlanta's historically black colleges and universities playing major roles in the movement's leadership. While minimal compared to other cities, Atlanta was not free of racial strife. In 1961, the city attempted to thwart blockbusting by erecting road barriers in Cascade Heights, countering the efforts of civic and business leaders to foster Atlanta as the \"city too busy to hate\". Desegregation of the public sphere came in stages, with public transportation desegregated by 1959, the restaurant at Rich's department store by 1961, movie theaters by 1963, and public schools by 1973.\n\nIn 1960, whites comprised 61.7% of the city's population. By 1970, African Americans were a majority of the city's population and exercised new-found political influence by electing Atlanta's first black mayor, Maynard Jackson, in 1973. Under Mayor Jackson's tenure, Atlanta's airport was modernized, solidifying the city's role as a transportation center. The opening of the Georgia World Congress Center in 1976 heralded Atlanta's rise as a convention city. Construction of the city's subway system began in 1975, with rail service commencing in 1979. Despite these improvements, Atlanta lost over 100,000 residents between 1970 and 1990, over 20% of its population.\n\nAtlanta was selected as the site for the 1996 Summer Olympic Games. Following the announcement, the city government undertook several major construction projects to improve Atlanta's parks, sporting venues, and transportation infrastructure. While the games themselves were marred by numerous organizational inefficiencies as well as the Centennial Olympic Park bombing, the spectacle was a watershed event in Atlanta's history that initiated a fundamental transformation of the city in the decade that followed.\n\nDuring the 2000s, Atlanta underwent a profound physical, cultural, and demographic transformation. Suburbanization, a booming economy, and new migrants decreased the city's black percentage from a high of 67% in 1990 to 54% in 2010. From 2000 to 2010, Atlanta gained 22,763 white residents, 5,142 Asian residents, and 3,095 Hispanic residents, while the city's black population decreased by 31,678. Much of the city's demographic change during the decade was driven by young, college-educated professionals: from 2000 to 2009, the three-mile radius surrounding Downtown Atlanta gained 9,722 residents aged 25 to 34 holding at least a four-year degree, an increase of 61%. Between the mid-1990s and 2010, stimulated by funding from the HOPE VI program, Atlanta demolished nearly all of its public housing, a total of 17,000 units and about 10% of all housing units in the city. In 2005, the $2.8 billion BeltLine project was adopted, with the stated goals of converting a disused 22-mile freight railroad loop that surrounds the central city into an art-filled multi-use trail and increasing the city's park space by 40%. Atlanta's cultural offerings expanded during the 2000s: the High Museum of Art doubled in size; the Alliance Theatre won a Tony Award; and art galleries were established on the once-industrial Westside.\n\nAtlanta encompasses , of which is land and is water. The city is situated among the foothills of the Appalachian Mountains, and at above mean sea level, Atlanta has one of the highest elevations among major cities east of the Mississippi River. Atlanta straddles the Eastern Continental Divide, such that rainwater that falls on the south and east side of the divide flows into the Atlantic Ocean, while rainwater on the north and west side of the divide flows into the Gulf of Mexico. Atlanta sits atop a ridge south of the Chattahoochee River, which is part of the ACF River Basin. Located at the far northwestern edge of the city, much of the river's natural habitat is preserved, in part by the Chattahoochee River National Recreation Area.\n\nMost of Atlanta was burned during the Civil War, depleting the city of a large stock of its historic architecture. Yet architecturally, the city had never been particularly \"southern\"—because Atlanta originated as a railroad town, rather than a patrician southern seaport like Savannah or Charleston, many of the city's landmarks could have easily been erected in the Northeast or Midwest.\n\nDuring the Cold War era, Atlanta embraced global modernist trends, especially regarding commercial and institutional architecture. Examples of modernist architecture include the 1,196,240sq.ft Westin Peachtree Plaza (1976), Georgia-Pacific Tower (1982), the State of Georgia Building (1966), and the Atlanta Marriott Marquis (1985). In the latter half of the 1980s, Atlanta became one of the early adopters of postmodern designs that reintroduced classical elements to the cityscape. Many of Atlanta's tallest skyscrapers were built in the late 1980s and early 1990s, with most displaying tapering spires or otherwise ornamented crowns, such as the 1,187,676 sq.ft One Atlantic Center (1987), 191 Peachtree Tower (1991), and the Four Seasons Hotel Atlanta (1992). Also completed during the era is Atlanta's tallest skyscraper, the Bank of America Plaza (1992), which, at , is the 61st-tallest building in the world and the 9th-tallest building in the United States. The Bank of America Plaza is the tallest building outside of New York City and Chicago, and was the last building built in the United States to be in the top 10 tallest buildings in the world until One World Trade Center was completed externally in May 2013. The city's embrace of modern architecture translated into an ambivalent approach toward historic preservation, leading to the destruction of notable architectural landmarks, including the Equitable Building (1892–1971), Terminal Station (1905–1972), and the Carnegie Library (1902–1977). The Fox Theatre (1929)—Atlanta's cultural icon—would have met the same fate had it not been for a grassroots effort to save it in the mid-1970s.\n\nAtlanta is divided into 242 officially defined neighborhoods. The city contains three major high-rise districts, which form a north-south axis along Peachtree: Downtown, Midtown, and Buckhead. Surrounding these high-density districts are leafy, low-density neighborhoods, most of which are dominated by single-family homes.\n\nDowntown Atlanta contains the most office space in the metro area, much of it occupied by government entities. Downtown is home to the city's sporting venues and many of its tourist attractions. Midtown Atlanta is the city's second-largest business district, containing the offices of many of the region's law firms. Midtown is known for its art institutions, cultural attractions, institutions of higher education, and dense form. Buckhead, the city's uptown district, is eight miles (13 km) north of Downtown and the city's third-largest business district. The district is marked by an urbanized core along Peachtree Road, surrounded by suburban single-family neighborhoods situated among dense forests and rolling hills.\n\nSurrounding Atlanta's three high-rise districts are the city's low- and medium-density neighborhoods, where the craftsman bungalow single-family home is dominant. The eastside is marked by historic streetcar suburbs built from the 1890s-1930s as havens for the upper middle class. These neighborhoods, many of which contain their own villages encircled by shaded, architecturally-distinct residential streets, include the Victorian Inman Park, Bohemian East Atlanta, and eclectic Old Fourth Ward. On the westside, former warehouses and factories have been converted into housing, retail space, and art galleries, transforming the once-industrial West Midtown into a model neighborhood for smart growth, historic rehabilitation, and infill construction. In southwest Atlanta, neighborhoods closer to downtown originated as streetcar suburbs, including the historic West End, while those farther from downtown retain a postwar suburban layout, including Collier Heights and Cascade Heights, home to much of the city's affluent African American population. Northwest Atlanta contains the areas of the city to west of Marietta Boulevard and to the north of Martin Luther King, Jr. Drive, including those neighborhoods remote to downtown, such as Riverside, Bolton and Whittier Mill, which is one of Atlanta's designated Landmark Historical Neighborhoods. Vine City, though technically Northwest, adjoins the city's Downtown area and has recently been the target of community outreach programs and economic development initiatives.\n\nGentrification of the city's neighborhoods is one of the more controversial and transformative forces shaping contemporary Atlanta. The gentrification of Atlanta has its origins in the 1970s, after many of Atlanta's neighborhoods had undergone the urban decay that affected other major American cities in the mid-20th century. When neighborhood opposition successfully prevented two freeways from being built through city's the east side in 1975, the area became the starting point for Atlanta's gentrification. After Atlanta was awarded the Olympic games in 1990, gentrification expanded into other parts of the city, stimulated by infrastructure improvements undertaken in preparation for the games. Gentrification was aided by the Atlanta Housing Authority's eradication of the city's public housing.\n\nUnder the Köppen classification, Atlanta has a humid subtropical climate (\"Cfa\") with four distinct seasons and generous precipitation year-round, typical for the inland South. Summers are hot and humid, with temperatures somewhat moderated by the city's elevation. Winters are cool but variable, with an average of 48 freezing days per year and temperatures dropping to on rare occasions. Warm air from the Gulf of Mexico can bring spring-like highs while strong Arctic air masses can push lows into the teens (≤ −7 °C).\n\nJuly averages , with high temperatures reaching on an average 44 days per year, though readings are not seen most years. January averages , with temperatures in the suburbs slightly cooler due largely to the urban heat island effect. Lows at or below freezing can be expected 40 nights annually, but extended stretches with daily high temperatures below are very rare, with a recent exception in January 2014. Extremes range from on February 13, 1899 to on June 30, 2012. Dewpoints in the summer range from in June to in July.\n\nTypical of the southeastern U.S., Atlanta receives abundant rainfall that is evenly distributed throughout the year, though spring and early fall are markedly drier. The average annual rainfall is , while snowfall is typically light at around per year. The heaviest single snowfall occurred on January 23, 1940, with around of snow. However, ice storms usually cause more problems than snowfall does, the most severe occurring on January 7, 1973. Tornadoes are rare in the city itself, but the March 15, 2008 EF2 tornado damaged prominent structures in downtown Atlanta.\n\nThe 2010 United States Census reported that Atlanta had a population of 420,003. The population density was 3,154 per square mile (1232/km). The racial makeup and population of Atlanta was 54.0% Black or African American, 38.4% White, 3.1% Asian and 0.2% Native American. Those from some other race made up 2.2% of the city's population, while those from two or more races made up 2.0%. Hispanics of any race made up 5.2% of the city's population. The median income for a household in the city was $45,171. The per capita income for the city was $35,453. 22.6% percent of the population was living below the poverty line. Atlanta has one of the highest LGBT populations per capita, ranking third among major American cities, behind San Francisco and slightly behind Seattle, with 12.8% of the city's total population identifying as gay, lesbian, or bisexual. 7.3% of Atlantans were born abroad (86th in the US).\nIn the 2010 Census, Atlanta was recorded as the nation's fourth-largest majority-black city. It has long been known as a center of African-American political power, education, and culture, often called a black mecca. African-American residents of Atlanta have followed whites to newer housing in the suburbs in the early 21st century. From 2000 to 2010, the city's black population decreased by 31,678 people, shrinking from 61.4% of the city's population in 2000 to 54.0% in 2010.\n\nAt the same time, the white population of Atlanta has increased. Between 2000 and 2010, the proportion of whites in the city's population grew faster than that of any other U.S. city. In that decade, Atlanta's white population grew from 31% to 38% of the city's population, an absolute increase of 22,753 people, more than triple the increase that occurred between 1990 and 2000.\n\nOut of the total population five years and older, 83.3% spoke only English at home, while 8.8% spoke Spanish, 3.9% another Indo-European language, and 2.8% an Asian language. Atlanta's dialect has traditionally been a variation of Southern American English. The Chattahoochee River long formed a border between the Coastal Southern and Southern Appalachian dialects. Because of the development of corporate headquarters in the region, attracting migrants from other areas of the country, by 2003, \"Atlanta\" magazine concluded that Atlanta had become significantly \"de-Southernized.\" A Southern accent was considered a handicap in some circumstances. In general, Southern accents are less prevalent among residents of the city and inner suburbs and among younger people; they are more common in the outer suburbs and among older people. At the same time, residents of the city express Southern variations of African American Vernacular English.\n\nReligion in Atlanta, while historically centered on Protestant Christianity, now involves many faiths as a result of the city and metro area's increasingly international population. Protestant Christianity still maintains a strong presence in the city (63%), but in recent decades the Catholic Church has increased in numbers and influence because of new migrants in the region. Metro Atlanta also has numerous ethnic or national Christian congregations, including Korean and Indian churches. The larger non-Christian faiths are Judaism, Islam and Hinduism. Overall, there are over 1,000 places of worship within Atlanta.\n\nWith a GDP of $304 billion, the Metro Atlanta economy is the eighth-largest in the country and 17th-largest in the world. Corporate operations play a major role in the economy, as the city claims the country's third-largest concentration of Fortune 500 companies, and hosts the global headquarters of corporations such as The Coca-Cola Company, The Home Depot, Delta Air Lines, AT&T Mobility, Chick-fil-A, UPS, and Newell-Rubbermaid. Over 75 percent of Fortune 1000 companies conduct business operations in metro Atlanta, and the region hosts offices of over 1,250 multinational corporations. Many corporations are drawn to Atlanta by the city's educated workforce; , 45% of adults 25 or older in the city have at least 4-year college degrees, compared to the national average of 28%.\n\nAtlanta began as a railroad town and logistics has remained a major component of the city's economy to this day. Atlanta is an important rail junction and contains major classification yards for Norfolk Southern and CSX. Since its construction in the 1950s, Hartsfield-Jackson Atlanta International Airport has served as a key engine of Atlanta's economic growth. Delta Air Lines, the city's largest employer and the metro area's third largest, operates the world's largest airline hub at Hartsfield-Jackson and has helped make it the world's busiest airport, both in terms of passenger traffic and aircraft operations. Partly due to the airport, Atlanta has become a hub for diplomatic missions; , the city contains 26 consulates general, the seventh-highest concentration of diplomatic missions in the United States.\n\nMedia is also an important aspect of Atlanta's economy. The city is a major cable television programming center. Ted Turner established the headquarters of both the Cable News Network (CNN) and the Turner Broadcasting System (TBS) in Atlanta. Cox Enterprises, the country's third-largest cable television service and the publisher of over a dozen American newspapers, is headquartered in the city. The Weather Channel is headquartered just outside Atlanta in Cobb County.\n\nInformation technology—a business sector that includes publishing, software development, entertainment and data processing—has garnered a larger percentage of Atlanta's economic output. Indeed, Atlanta has been nicknamed the Silicon peach due to its burgeoning technology sector. , Atlanta contains the fourth-largest concentration of information technology jobs in the United States, numbering 85,000. Atlanta ranks as the sixth fastest-growing city for information technology jobs, with an employment growth of 4.8% in 2012 and a three-year growth near 9%, or 16,000 jobs. Information technology companies are drawn to Atlanta's lower costs and educated workforce.\n\nRecently, Atlanta has become a center for film and television production, largely due to the Georgia Entertainment Industry Investment Act, which awards qualified productions a transferable income tax credit of 20% of all in-state costs for film and television investments of $500,000 or more. Film and television production facilities in Atlanta include Turner Studios, Pinewood Studios (Pinewood Atlanta), Tyler Perry Studios, Williams Street Productions, and the EUE/Screen Gems soundstages. Film and television production injected $6 billion into Georgia's economy in 2015, with Atlanta garnering most of the projects. Atlanta has gained recognition as a center of production of horror and zombie-related productions, with \"Atlanta\" magazine dubbing the city the \"Zombie Capital of the World\".\nCompared to other American cities, Atlanta's economy has been disproportionately affected by the 2008 financial crisis and subsequent recession, with the city's economy earning a ranking of 68 among 100 American cities in a September 2014 report due to an elevated unemployment rate, declining real income levels, and a depressed housing market. From 2010 to 2011, Atlanta saw a 0.9% contraction in employment and only a 0.4% rise in income. Though unemployment had dropped to 7% by late 2014, this was still higher than the national unemployment rate of 5.8% Atlanta's housing market has struggled, with home prices falling by 2.1% in January 2012, reaching levels not seen since 1996. Compared with a year earlier, the average home price in Atlanta fell 17.3% in February 2012, the largest annual drop in the history of the index for any city. The collapse in home prices has led some economists to deem Atlanta the worst housing market in the country. Nevertheless, in August 2013, Atlanta appeared on \"Forbes\" magazine's list of the Best Places for Business and Careers.\n\nAtlanta is a city located in the South that has a culture that is no longer strictly Southern. This is due to a large population of migrants from other parts of the U.S., in addition to many recent immigrants to the U.S. who have made the metropolitan area their home, establishing Atlanta as the cultural and economic hub of an increasingly multi-cultural metropolitan area. Thus, although traditional Southern culture is part of Atlanta's cultural fabric, it is mostly the backdrop to one of the nation's most cosmopolitan cities. This unique cultural combination reveals itself in the arts district of Midtown, the quirky neighborhoods on the city's eastside, and the multi-ethnic enclaves found along Buford Highway.\n\nAtlanta is one of few United States cities with permanent, professional, resident companies in all major performing arts disciplines: opera (Atlanta Opera), ballet (Atlanta Ballet), orchestral music (Atlanta Symphony Orchestra), and theater (the Alliance Theatre). Atlanta attracts many touring Broadway acts, concerts, shows, and exhibitions catering to a variety of interests. Atlanta's performing arts district is concentrated in Midtown Atlanta at the Woodruff Arts Center, which is home to the Atlanta Symphony Orchestra and the Alliance Theatre. The city frequently hosts touring Broadway acts, especially at The Fox Theatre, a historic landmark that is among the highest grossing theatres of its size.\n\nAs a national center for the arts, Atlanta is home to significant art museums and institutions. The renowned High Museum of Art is arguably the South's leading art museum and among the most-visited art museums in the world. The Museum of Design Atlanta (MODA), a design museum, is the only such museum in the Southeast. Contemporary art museums include the Atlanta Contemporary Art Center and the Museum of Contemporary Art of Georgia. Institutions of higher education contribute to Atlanta's art scene, with the Savannah College of Art and Design's Atlanta campus providing the city's arts community with a steady stream of curators, and Emory University's Michael C. Carlos Museum containing the largest collection of ancient art in the Southeast.\n\nAtlanta has played a major or contributing role in the development of various genres of American music at different points in the city's history. Beginning as early as the 1920s, Atlanta emerged as a center for country music, which was brought to the city by migrants from Appalachia. During the countercultural 1960s, Atlanta hosted the Atlanta International Pop Festival, with the 1969 festival taking place more than a month before Woodstock and featuring many of the same bands. The city was also a center for Southern rock during its 1970s heyday: the Allman Brothers Band's hit instrumental \"Hot 'Lanta\" is an ode to the city, while Lynyrd Skynyrd's famous live rendition of \"Free Bird\" was recorded at the Fox Theatre in 1976, with lead singer Ronnie Van Zant directing the band to \"play it pretty for Atlanta\". During the 1980s, Atlanta had an active Punk rock scene that was centered on two of the city's music venues, 688 Club and the Metroplex, and Atlanta famously played host to the Sex Pistols first U.S. show, which was performed at the Great Southeastern Music Hall. The 1990s saw the birth of Atlanta hip hop, a subgenre that gained relevance following the success of home-grown duo OutKast; however, it was not until the 2000s that Atlanta moved \"from the margins to becoming hip-hop's center of gravity, part of a larger shift in hip-hop innovation to the South\". Also in the 2000s, Atlanta was recognized by the Brooklyn-based \"Vice\" magazine for its indie rock scene, which revolves around the various live music venues found on the city's alternative eastside.\n\n, Atlanta is the seventh-most visited city in the United States, with over 35 million visitors per year. Although the most popular attraction among visitors to Atlanta is the Georgia Aquarium, the world's largest indoor aquarium, Atlanta's tourism industry is mostly driven by the city's history museums and outdoor attractions. Atlanta contains a notable amount of historical museums and sites, including the Martin Luther King, Jr. National Historic Site, which includes the preserved childhood home of Dr. Martin Luther King, Jr., as well as his final resting place; the Atlanta Cyclorama & Civil War Museum, which houses a massive painting and diorama in-the-round, with a rotating central audience platform, depicting the Battle of Atlanta in the Civil War; the World of Coca-Cola, featuring the history of the world-famous soft drink brand and its well-known advertising; the College Football Hall of Fame which honors college football and its athletes; the National Center for Civil and Human Rights, which explores the Civil Rights Movement and its connection to contemporary human rights movements throughout the world; the Carter Center and Presidential Library, housing U.S. President Jimmy Carter's papers and other material relating to the Carter administration and the Carter family's life; and the Margaret Mitchell House and Museum, where Mitchell wrote the best-selling novel \"Gone with the Wind\".\n\nAtlanta contains various outdoor attractions. The Atlanta Botanical Garden, adjacent to Piedmont Park, is home to the Kendeda Canopy Walk, a skywalk that allows visitors to tour one of the city's last remaining urban forests from . The Canopy Walk is considered the only canopy-level pathway of its kind in the United States. Zoo Atlanta, located in Grant Park, accommodates over 1,300 animals representing more than 220 species. Home to the nation's largest collections of gorillas and orangutans, the Zoo is one of only four zoos in the U.S. to house giant pandas. Festivals showcasing arts and crafts, film, and music, including the Atlanta Dogwood Festival, the Atlanta Film Festival, and Music Midtown, respectively, are also popular with tourists.\n\nTourists are drawn to the city's culinary scene, which comprises a mix of urban establishments garnering national attention, ethnic restaurants serving cuisine from every corner of the world, and traditional eateries specializing in Southern dining. Since the turn of the 21st century, Atlanta has emerged as a sophisticated restaurant town. Many restaurants opened in the city's gentrifying neighborhoods have received praise at the national level, including Bocado, Bacchanalia, and Miller Union in West Midtown, Empire State South in Midtown, and Two Urban Licks and Rathbun's on the east side. In 2011, the \"New York Times\" characterized Empire State South and Miller Union as reflecting \"a new kind of sophisticated Southern sensibility centered on the farm but experienced in the city.\" Visitors seeking to sample international Atlanta are directed to Buford Highway, the city's international corridor. There, the million-plus immigrants that make Atlanta home have established various authentic ethnic restaurants representing virtually every nationality on the globe. For traditional Southern fare, one of the city's most famous establishments is The Varsity, a long-lived fast food chain and the world's largest drive-in restaurant. Mary Mac's Tea Room and Paschal's are more formal destinations for Southern food.\n\nAtlanta is home to professional franchises for four major team sports: the Atlanta Braves of Major League Baseball, the Atlanta Hawks of the National Basketball Association, the Atlanta Falcons of the National Football League, and Atlanta United FC of Major League Soccer. The Braves, who moved to Atlanta in 1966, were established as the Boston Red Stockings in 1871 and are the oldest continually operating professional sports franchise in the United States. The Braves won the World Series in 1995, and had an unprecedented run of 14 straight divisional championships from 1991 to 2005. The Braves will have a new home in 2017. Moving from Turner Field to Suntrust Park, which is located in the Atlanta Metropolitan area 10 miles (16 km) northwest of downtown Atlanta in Cumberland/Galleria, Georgia.\n\nThe Atlanta Falcons have played in Atlanta since their inception in 1966. The Falcons have won the division title six times (1980, 1998, 2004, 2010, 2012, 2016) and the NFC championship twice in 1998 and 2016. However, they have been unsuccessful in both of their Super Bowl trips so far, losing to the Denver Broncos in Super Bowl XXXIII in 1999 and to the New England Patriots in Super Bowl LI in 2017. The Atlanta Hawks began in 1946 as the Tri-Cities Blackhawks, playing in Moline, Illinois. The team moved to Atlanta in 1968, and they currently play their games in Philips Arena. The Atlanta Dream is the city's Women's National Basketball Association franchise.\n\nAtlanta has had its own professional ice hockey and soccer franchises. The National Hockey League (NHL) has had two Atlanta franchises: the Atlanta Flames began play in 1972 before moving to Calgary in 1980, while the Atlanta Thrashers began play in 1999 before moving to Winnipeg in 2011. The Atlanta Chiefs was the city's professional soccer team from 1967 to 1972, and the team won a national championship in 1968. In 1998 another professional soccer team was formed, the Atlanta Silverbacks of the North American Soccer League. In April 2014, Atlanta United FC, was formed as an expansion team to begin play in 2017.\n\nAtlanta has been the host city for various international, professional and collegiate sporting events. Most famously, Atlanta hosted the Centennial 1996 Summer Olympics. Atlanta hosted Super Bowl XXVIII in 1994 and Super Bowl XXXIV in 2000. In professional golf, The Tour Championship, the final PGA Tour event of the season, is played annually at East Lake Golf Club. In 2001 and 2011, Atlanta hosted the PGA Championship, one of the four major championships in men's professional golf, at the Atlanta Athletic Club. In professional ice hockey, the city hosted the 56th NHL All-Star Game in 2008, three years before the Thrashers moved. In 2011, Atlanta hosted professional wrestling's annual WrestleMania. The city has hosted the NCAA Final Four Men's Basketball Championship four times, most recently in 2013. In college football, Atlanta hosts the Chick-fil-A Kickoff Game, the SEC Championship Game, and the Chick-fil-A Peach Bowl.\n\nAtlanta's 343 parks, nature preserves, and gardens cover , which amounts to only 5.6% of the city's total acreage, compared to the national average of just over 10%. However, 64% of Atlantans live within a 10-minute walk of a park, a percentage equal to the national average. In its 2013 ParkScore ranking, The Trust for Public Land reported that among the park systems of the 50 most populous U.S. cities, Atlanta's park system received a ranking of 31. Piedmont Park, located in Midtown, is Atlanta's most iconic green space. The park, which underwent a major renovation and expansion in recent years, attracts visitors from across the region and hosts cultural events throughout the year. Other notable city parks include Centennial Olympic Park, a legacy of the 1996 Summer Olympics that forms the centerpiece of the city's tourist district; Woodruff Park, which anchors the campus of Georgia State University; Grant Park, home to Zoo Atlanta; and Chastain Park, which houses an amphitheater used for live music concerts. The Chattahoochee River National Recreation Area, located in the northwestern corner of the city, preserves a stretch of the river for public recreation opportunities. The Atlanta Botanical Garden, adjacent to Piedmont Park, contains formal gardens, including a Japanese garden and a rose garden, woodland areas, and a conservatory that includes indoor exhibits of plants from tropical rainforests and deserts. The BeltLine, a former rail corridor that forms a loop around Atlanta's core, has been transformed into a series of parks, connected by a multi-use trail, increasing Atlanta's park space by 40%.\n\nAtlanta offers resources and opportunities for amateur and participatory sports and recreation. Jogging is a popular local sport, and the city hosts the Peachtree Road Race, the world's largest race, annually on Independence Day. The Georgia Marathon, which begins and ends at Centennial Olympic Park, routes through the city's historic east side neighborhoods. Golf and tennis are popular in Atlanta, and the city contains six public golf courses and 182 tennis courts. Facilities located along the Chattahoochee River cater to watersports enthusiasts, providing the opportunity for kayaking, canoeing, fishing, boating, or tubing. The city's only skate park, a facility that offers bowls, curbs, and smooth-rolling concrete mounds, is located at Historic Fourth Ward Park.\n\nAtlanta is governed by a mayor and the Atlanta City Council. The city council consists of 15 representatives—one from each of the city's 12 districts and three at-large positions. The mayor may veto a bill passed by the council, but the council can override the veto with a two-thirds majority. The mayor of Atlanta is Kasim Reed, a Democrat elected on a nonpartisan ballot whose first term in office expired at the end of 2013. Reed was elected to a second term on November 5, 2013.\nEvery mayor elected since 1973 has been black. In 2001, Shirley Franklin became the first woman to be elected Mayor of Atlanta, and the first African-American woman to serve as mayor of a major southern city. Atlanta city politics suffered from a notorious reputation for corruption during the 1990s administration of Mayor Bill Campbell, who was convicted by a federal jury in 2006 on three counts of tax evasion in connection with gambling winnings during trips he took with city contractors.\n\nAs the state capital, Atlanta is the site of most of Georgia's state government. The Georgia State Capitol building, located downtown, houses the offices of the governor, lieutenant governor and secretary of state, as well as the General Assembly. The Governor's Mansion is located in a residential section of Buckhead. Atlanta serves as the regional hub for many arms of the federal bureaucracy, including the Federal Reserve Bank of Atlanta and the Centers for Disease Control and Prevention. Atlanta also plays an important role in federal judiciary system, containing the United States Court of Appeals for the Eleventh Circuit and of the United States District Court for the Northern District of Georgia.\n\nHistorically, Atlanta has been a stronghold for the Democratic Party. Although municipal elections are officially nonpartisan, nearly all of the city's elected officials are registered Democrats. The city is split among 14 state house districts and four state senate districts, all held by Democrats. At the federal level, Atlanta is split between two congressional districts. The northern three-fourths of the city is located in the 5th district, represented by Democrat John Lewis. The southern fourth is in the 13th district, represented by Democrat David Scott.\n\nThe city is served by the Atlanta Police Department, which numbers 2,000 officers and oversaw a 40% decrease in the city's crime rate between 2001 and 2009. Specifically, homicide decreased by 57%, rape by 72%, and violent crime overall by 55%. Crime is down across the country, but Atlanta's improvement has occurred at more than twice the national rate. Nevertheless, Forbes ranked Atlanta as the sixth most dangerous city in the United States in 2012.\n\nDue to the more than 30 colleges and universities located in the city, Atlanta is considered a center for higher education. The Georgia Institute of Technology is one of the most prominent public universities in Atlanta; it is a research university located in Midtown that has been consistently ranked among the nation's top ten public universities for its degree programs in engineering, computing, management, the sciences, architecture, and liberal arts. Georgia State University is a major public research university located in Downtown Atlanta; it is the largest of the 29 public colleges and universities in the University System of Georgia and is a significant contributor to the revitalization of the city's central business district. Atlanta is home to nationally renowned private colleges and universities, most notably Emory University, a leading liberal arts and research institution that ranks among the top 20 schools in the United States and operates Emory Healthcare, the largest health care system in Georgia.\n\nFifty-five thousand students are enrolled in 106 schools in Atlanta Public Schools, some of which are operated as charter schools. The district has been plagued by a widely publicized cheating scandal that was exposed in 2009. Atlanta is served by many private schools, including parochial Roman Catholic schools operated by the Archdiocese of Atlanta.\n\nThe primary network-affiliated television stations in Atlanta are WXIA-TV (NBC), WGCL-TV (CBS), WSB-TV (ABC), and WAGA-TV (FOX). The Atlanta metropolitan area is served by two public television stations and one public radio station. WGTV is the flagship station of the statewide Georgia Public Television network and is a PBS member station, while WPBA is owned by Atlanta Public Schools. Georgia Public Radio is listener-funded and comprises one NPR member station, WABE, a classical music station operated by Atlanta Public Schools.\n\nAtlanta is served by the \"Atlanta Journal-Constitution\", its only major daily newspaper with wide distribution. The \"Atlanta Journal-Constitution\" is the result of a 1950 merger between \"The Atlanta Journal\" and \"The Atlanta Constitution\", with staff consolidation occurring in 1982 and separate publication of the morning \"Constitution\" and afternoon \"Journal\" ceasing in 2001. Alternative weekly newspapers include \"Creative Loafing\", which has a weekly print circulation of 80,000. \"Atlanta\" magazine is an award-winning, monthly general-interest magazine based in and covering Atlanta.\n\nAtlanta's transportation infrastructure comprises a complex network that includes a heavy rail rapid transit system, a light rail streetcar loop, a multi-county bus system, Amtrak service via the Crescent, multiple freight train lines, an Interstate Highway System, several airports, including the world's busiest, and over of bike paths.\n\nAtlanta has a network of freeways that radiate out from the city, and automobiles are the dominant means of transportation in the region. Three major interstate highways converge in Atlanta: I-20 (east-west), I-75 (northwest-southeast), and I-85 (northeast-southwest). The latter two combine in the middle of the city to form the Downtown Connector (I-75/85), which carries more than 340,000 vehicles per day and is one of the most congested segments of interstate highway in the United States. Atlanta is mostly encircled by Interstate 285, a beltway locally known as \"the Perimeter\" that has come to mark the boundary between \"Inside the Perimeter\" (ITP), the city and close-in suburbs, and \"Outside the Perimeter\" (OTP), the outer suburbs and exurbs. The heavy reliance on automobiles for transportation in Atlanta has resulted in traffic, commute, and air pollution rates that rank among the worst in the country.\n\nThe Metropolitan Atlanta Rapid Transit Authority (MARTA) provides public transportation in the form of buses and heavy rail. Notwithstanding heavy automotive usage in Atlanta, the city's subway system is the eighth busiest in the country. MARTA rail lines connect key destinations, such as the airport, Downtown, Midtown, Buckhead, and Perimeter Center. However, significant destinations, such as Emory University and Cumberland, remain unserved. As a result, a 2011 Brookings Institution study placed Atlanta 91st of 100 metro areas for transit accessibility. Emory University operates its Cliff shuttle buses with 200,000 boardings per month, while private minibuses supply Buford Highway. Amtrak, the national rail passenger system, provides service to Atlanta via the \"Crescent train\" (New York–New Orleans), which stops at Peachtree Station. In 2014, the Atlanta Streetcar opened to the public. The streetcar's line, which is also known as the Downtown Loop, runs 2.7 miles around the downtown tourist areas of Peachtree Center, Centennial Olympic Park, the Martin Luther King, Jr. National Historic Site, and Sweet Auburn. The Atlanta Streetcar line is also being expanded on in the coming years to include a wider range of Atlanta's neighborhoods and important places of interest, with a total of over 50 miles of track in the plan.\n\nHartsfield-Jackson Atlanta International Airport is the world's busiest airport as measured by passenger traffic and aircraft traffic. The facility offers air service to over 150 U.S. destinations and more than 75 international destinations in 50 countries, with over 2,500 arrivals and departures daily. Delta Air Lines maintains its largest hub at the airport. Situated () south of downtown, the airport covers most of the land inside a wedge formed by Interstate 75, Interstate 85, and Interstate 285.\n\nCycling is a growing mode of transportation in Atlanta, more than doubling since 2009, when it comprised 1.1% of all commutes (up from 0.3% in 2000). Although Atlanta's lack of bike lanes and hilly topography may deter many residents from cycling, the city's transportation plan calls for the construction of of bike lanes by 2020, with the BeltLine helping to achieve this goal. In 2012, Atlanta's first \"bike track\" was constructed on 10th Street in Midtown. The two lane bike track runs from Monroe Drive west to Charles Allen Drive, with connections to the Beltline and Piedmont Park. Starting in June 2016, Atlanta received a bike sharing program with 100 bikes in Downtown, with 500 more being expected by the end of the year.\n\nAtlanta has a reputation as a \"city in a forest\" due to an abundance of trees that is rare among major cities. The city's main street is named after a tree, and beyond the Downtown, Midtown, and Buckhead business districts, the skyline gives way to a dense canopy of woods that spreads into the suburbs. The city is home to the Atlanta Dogwood Festival, an annual arts and crafts festival held one weekend during early April, when the native dogwoods are in bloom. The nickname is factually accurate, as the city's tree coverage percentage is at 36%, the highest out of all major American cities, and above the national average of 27%. Atlanta's tree coverage does not go unnoticed—it was the main reason cited by \"National Geographic\" in naming Atlanta a \"Place of a Lifetime\".\n\nThe city's lush tree canopy, which filters out pollutants and cools sidewalks and buildings, has increasingly been under assault from man and nature due to heavy rains, drought, aged forests, new pests, and urban construction. A 2001 study found that Atlanta's heavy tree cover declined from 48% in 1974 to 38% in 1996. Community organizations and the city government are addressing the problem. Trees Atlanta, a non-profit organization founded in 1985, has planted and distributed over 75,000 shade trees in the city, and Atlanta's government has awarded $130,000 in grants to neighborhood groups to plant trees.\n\nAtlanta has 17 sister cities, as designated by Sister Cities International, Inc. (SCI):\n\n", "id": "3138", "title": "Atlanta"}
{"url": "https://en.wikipedia.org/wiki?curid=3143", "text": "Axiology\n\nAxiology (from Greek , \"axia\", \"value, worth\"; and , \"-logia\") is the philosophical study of value. It is either the collective term for ethics and aesthetics—philosophical fields that depend crucially on notions of worth—or the foundation for these fields, and thus similar to value theory and meta-ethics. The term was first used by Paul Lapie, in 1902, and Eduard von Hartmann, in 1908.\n\nAxiology studies mainly two kinds of values: ethics and aesthetics. Ethics investigates the concepts of \"right\" and \"good\" in individual and social conduct. Aesthetics studies the concepts of \"beauty\" and \"harmony.\" Formal axiology, the attempt to lay out principles regarding value with mathematical rigor, is exemplified by Robert S. Hartman's science of value.\n\nBetween the 5th and 6th century BC, it was important in Greece to be knowledgeable if you were to be successful. Philosophers began to recognize that differences existed between the laws and morality of society. Socrates held the belief that knowledge had a vital connection to virtue, making morality and democracy closely intertwined. Socrates' student, Plato furthered the belief by establishing virtues which should be followed by all. With the fall of the government, values became individual, causing skeptic schools of thought to flourish, ultimately shaping a pagan philosophy that is thought to have influenced and shaped Christianity. During the medieval times, Thomas Aquinas argued for a separation between natural and religious virtues. This concept led philosophers to distinguish between judgments based on fact and judgments based on values, creating division between science and philosophy.\n\nCommunication theorists seek to contribute to mutual intelligence about the anatomy and operation of human communication. The axiological issues that are significant for the evolution of communication theory are whether research can be truly free of value and whether the end for the administered research should be designed to expand knowledge or to change society. For communication theorists, a primary interest is with the philosophical establishment of the research approach. A continuing value debate occurs between scholars who comply with a conventional scientific approach and those who take an interpretivist approach to communication development.\n\nThose who take a conventional scientific approach believe that research must be free of values in order to be valid. Therefore, it is necessary for the scientist to approach their research in a neutral and objective manner. In contrast, the interpretivists argue that it is impossible for research to be completely free of personal values, as research is always biased towards the values of the researcher. According to interpretivists, these biases are sometimes so entrenched in the researcher's culture that they will most likely go unnoticed during research. Since no one can truly be unbiased, some groups are more knowledgeable about certain things than other groups due to their positions in society, and they can be considered more qualified to perform research on certain topics as a result.\n\n\n\n", "id": "3143", "title": "Axiology"}
{"url": "https://en.wikipedia.org/wiki?curid=3144", "text": "A Doll's House\n\nA Doll's House (; also translated as \"A Doll House\") is a three-act play in prose by Henrik Ibsen. It premiered at the Royal Theatre in Copenhagen, Denmark, on 21 December 1879, having been published earlier that month.\n\nThe play is significant for its critical attitude toward 19th-century marriage norms. It aroused great controversy at the time, as it concludes with the protagonist, Nora, leaving her husband and children because she wants to discover herself. Ibsen was inspired by the belief that \"a woman cannot be herself in modern society,\" since it is \"an exclusively male society, with laws made by men and with prosecutors and judges who assess feminine conduct from a masculine standpoint.\" Its ideas can also be seen as having a wider application: Michael Meyer argued that the play's theme is not women's rights, but rather \"the need of every individual to find out the kind of person he or she really is and to strive to become that person.\" In a speech given to the Norwegian Association for Women's Rights in 1898, Ibsen insisted that he \"must disclaim the honor of having consciously worked for the women's rights movement,\" since he wrote \"without any conscious thought of making propaganda,\" his task having been \"the \"description of humanity\".\"\n\nIn 2006, the centennial of Ibsen's death, \"A Doll's House\" held the distinction of being the world's most performed play for that year. UNESCO has inscribed Ibsen's autographed manuscripts of \"A Doll's House\" on the Memory of the World Register in 2001, in recognition of their historical value.\n\nThe title of the play is most commonly translated as \"A Doll's House\", though some scholars use \"A Doll House\". John Simon argues that the only significance in the alternative translation is the difference in the way the toy is named in Britain and the United States. Egil Törnqvist argues that the alternative \"simply sounds more idiomatic to Americans.\"\n\n\nThe play opens at Christmas time as Nora Helmer enters her home carrying a number of packages. Nora's husband Torvald is working in his study when she arrives. He playfully rebukes her for spending so much money on Christmas gifts, calling her his \"little squirrel\". He teases her about how she spent weeks making gifts and ornaments by hand last year because money was scarce. This year Torvald is due a promotion at the bank where he works, so Nora feels that they can let themselves go a little. The maid announces two visitors: Mrs. Kristine Linde, an old friend of Nora's, who has come seeking employment, and Dr. Rank, a close friend of the family, who is let into the study. Kristine has had a difficult few years, ever since her husband died leaving her with no money or children. Nora explains that things have not been easy for them either: Torvald became sick and they had to travel to Italy so he could recover. Kristine further explains that when her mother was ill, she had to take care of her brothers, but now that they are grown she feels her life is \"unspeakably empty\". Nora promises to talk to Torvald about finding her a job. Kristine gently tells Nora that she is like a child. Nora is offended, so she reveals that she borrowed money from \"some admirer\", so they could travel to Italy to improve Torvald's health. She told Torvald that her father gave her the money, but in fact she managed to illegally borrow it without his knowledge. Over the years, she has been secretly working and saving up to pay it off.\n\nKrogstad, a lower-level employee at Torvald's bank, arrives and goes into the study. Nora is clearly uneasy when she sees him. Dr. Rank leaves the study and mentions that he feels wretched, though, like everyone, he wants to go on living. In contrast to his physical illness, he says that the man in the study, Krogstad, is \"morally diseased\".\n\nAfter the meeting with Krogstad, Torvald comes out of the study. Nora asks him if he can give Kristine a position at the bank and Torvald is very positive, saying that this is a fortunate moment, as a position has just become available. Torvald, Kristine, and Dr. Rank leave the house, leaving Nora alone. The nanny returns with the children and Nora plays with them for a while until Krogstad creeps into the living room and surprises her. Krogstad tells Nora that Torvald intends to fire him at the bank and asks her to intercede with Torvald to allow him to keep his job. She refuses and Krogstad threatens to blackmail her about the loan she took out for the trip to Italy; he knows that she obtained this loan by forging her father's signature. Krogstad leaves and when Torvald returns, she tries to convince him not to fire Krogstad. Torvald refuses to hear her pleas, explaining that Krogstad is a liar and a hypocrite and that he committed a terrible crime: he forged someone's name. Torvald feels physically ill in the presence of a man \"poisoning his own children with lies and dissimulation\".\n\nKristine arrives to help Nora repair a dress for a costume function that Torvald and she plan to attend the next day. Torvald returns from the bank, and Nora pleads with him to reinstate Krogstad, claiming she is worried Krogstad will publish libelous articles about Torvald and ruin his career. Torvald dismisses her fears and explains that, although Krogstad is a good worker and seems to have turned his life around, he must be fired because he is not deferential enough to Torvald in front of other bank personnel. Torvald then retires to his study to work.\n\nDr. Rank, the family friend, arrives. Nora asks him for a favor, but Rank responds by revealing that he has entered the terminal stage of tuberculosis of the spine and that he has always been secretly in love with her. Nora tries to deny the first revelation and make light of it, but is more disturbed by his declaration of love. She tries clumsily to tell him that she is not in love with him, but that she loves him dearly as a friend.\n\nDesperate after being fired by Torvald, Krogstad arrives at the house. Nora convinces Dr. Rank to go into Torvald's study so he will not see Krogstad. When Krogstad confronts Nora, he declares that he no longer cares about the remaining balance of Nora's loan, but that he will instead preserve the associated bond to blackmail Torvald into not only keeping him employed but also promoting him. Nora explains that she has done her best to persuade her husband, but he refuses to change his mind. Krogstad informs Nora that he has written a letter detailing her crime (forging her father's signature of surety on the bond) and put it in Torvald's mailbox, which is locked.\n\nNora tells Kristine of her difficult situation. Having had a relationship in the past before her marriage, Kristine says that Krogstad and she are still in love and promises to try to convince him to relent.\n\nTorvald enters and tries to retrieve his mail, but Nora distracts him by begging him to help her with the dance she has been rehearsing for the costume party, feigning anxiety about performing. She dances so badly and acts so childishly that Torvald agrees to spend the whole evening coaching her. When the others go to dinner, Nora stays behind for a few minutes and contemplates killing herself to save her husband from the shame of the revelation of her crime and to pre-empt any gallant gesture on his part to save her reputation.\n\nKristine tells Krogstad that she only married her husband because she had no other means to support her sick mother and young siblings and that she has returned to offer him her love again. She believes that he would not have stooped to unethical behavior if he had not been devastated by her abandonment and been in dire financial straits. Krogstad is moved and offers to take back his letter to Torvald. However, Kristine decides that Torvald should know the truth for the sake of his and Nora's marriage.\n\nAfter literally dragging Nora home from the party, Torvald goes to check his mail, but is interrupted by Dr. Rank, who has followed them. Dr. Rank chats for a while, conveying obliquely to Nora that this is a final goodbye, as he has determined that his death is near. Dr. Rank leaves, and Torvald retrieves his letters. As he reads them, Nora steels herself to take her life. Torvald confronts her with Krogstad's letter. Enraged, he declares that he is now completely in Krogstad's power – he must yield to Krogstad's demands and keep quiet about the whole affair. He berates Nora, calling her a dishonest and immoral woman and telling her that she is unfit to raise their children. He says that from now on their marriage will be only a matter of appearances.\n\nA maid enters, delivering a letter to Nora. The letter is from Krogstad, yet Torvald demands to read the letter, taking it from Nora. Torvald exults that he is saved, as Krogstad has returned the incriminating bond, which Torvald immediately burns along with Krogstad's letters. He takes back his harsh words to his wife and tells her that he forgives her. Nora realizes that her husband is not the strong and gallant man she thought he was, and that he truly loves himself more than he does her.\n\nTorvald explains that, when a man has forgiven his wife, it makes him love her all the more, since it reminds him that she is totally dependent on him, like a child. He dismisses the fact that Nora had to make the agonizing choice between her conscience and his health, and ignores her years of secret efforts to free them from the ensuing obligations and the danger of loss of reputation. He preserves his peace of mind by thinking of the incident as a mere mistake that she made owing to her dumbness, one of her most endearing feminine traits.\n\nNora tells Torvald that she is leaving him to live alone so that she can find out who she is and what she believes and decide what to do with her life. She says that she has been treated like a doll to play with for her whole life, first by her father and then by him. Concerned for the family reputation, Torvald insists that she fulfill her duty as a wife and mother, but Nora says that her first duties are to herself and that she cannot be a good mother or wife without learning to be more than a plaything. She reveals that she had expected that he would want to sacrifice his reputation for hers and that she had planned to kill herself to prevent him from doing so. She now realizes that Torvald is not at all the kind of person she had believed him to be and that their marriage has been based on mutual fantasies and misunderstanding.\n\nTorvald is unable to comprehend Nora's point of view, since it contradicts all that he has been taught about the female mind throughout his life. Furthermore, he is so narcissistic that it is impossible for him to understand how he appears to her, as selfish, hypocritical, and more concerned with public reputation than with actual morality. Nora leaves her keys and wedding ring, and as Torvald breaks down and begins to cry, baffled by what has happened, Nora leaves the house, slamming the door behind herself. Whether or not she ever comes back is never made clear.\n\nIbsen's German agent felt that the original ending would not play well in German theatres; therefore, for it to be considered acceptable, Ibsen was forced to write an alternative ending for the German premiere. In this ending, Nora is led to her children after having argued with Torvald. Seeing them, she collapses, and the curtain is brought down. Ibsen later called the ending a disgrace to the original play and referred to it as a \"barbaric outrage\". Virtually all productions today use the original ending, as do nearly all of the film versions of the play.\n\n\"A Doll's House\" was based on the life of Laura Kieler (maiden name Laura Smith Petersen), a good friend of Ibsen. Much that happened between Nora and Torvald happened to Laura and her husband, Victor. Much like the play, Laura signed an illegal loan to save her husband. She wanted the money to find a cure for her husband's tuberculosis. She wrote to Ibsen, asking for his recommendation of her work to his publisher, thinking that the sales of her book would repay her debt. At his refusal, she forged a check for the money. At this point she was found out. In real life, when Victor discovered about Laura's secret loan, he divorced her and had her committed to an asylum. Two years later, she returned to her husband and children at his urging, and she went on to become a well-known Danish author, living to the age of 83.\n\nIbsen wrote \"A Doll's House\" at the point when Laura Kieler had been committed to the asylum, and the fate of this friend of the family shook him deeply, perhaps also because Laura had asked him to intervene at a crucial point in the scandal, which he did not feel able or willing to do. Instead, he turned this life situation into an aesthetically shaped, successful drama. In the play, Nora leaves Torvald with head held high, though facing an uncertain future given the limitations single women faced in the society of the time.\n\nKieler eventually rebounded from the shame of the scandal and had her own successful writing career while remaining discontented with sole recognition as \"Ibsen's Nora\" years afterwards.\n\nIbsen started thinking about the play around May 1878, although he did not begin its first draft until a year later, having reflected on the themes and characters in the intervening period (he visualised its protagonist, Nora, for instance, as having approached him one day wearing \"a blue woollen dress\"). He outlined his conception of the play as a \"modern tragedy\" in a note written in Rome on 19 October 1878. \"A woman cannot be herself in modern society,\" he argues, since it is \"an exclusively male society, with laws made by men and with prosecutors and judges who assess feminine conduct from a masculine standpoint.\"\n\nIbsen sent a fair copy of the completed play to his publisher on 15 September 1879. It was first published in Copenhagen on 4 December 1879, in an edition of 8,000 copies that sold out within a month; a second edition of 3,000 copies followed on 4 January 1880, and a third edition of 2,500 was issued on 8 March.\n\n\"A Doll's House\" received its world premiere on 21 December 1879 at the Royal Theatre in Copenhagen, with Betty Hennings as Nora, Emil Poulsen as Torvald, and Peter Jerndorff as Dr. Rank. Writing for the Norwegian newspaper \"Folkets Avis\", the critic Erik Bøgh admired Ibsen's originality and technical mastery: \"Not a single declamatory phrase, no high dramatics, no drop of blood, not even a tear.\" Every performance of its run was sold out. Another production opened at the Royal Theatre in Stockholm, on 8 January 1880, while productions in Christiania (with Johanne Juell as Nora and Arnoldus Reimers as Torvald) and Bergen followed shortly after.\n\nIn Germany, the actress Hedwig Niemann-Raabe refused to perform the play as written, declaring, \"\"I\" would never leave \"my\" children!\" Since the playwright's wishes were not protected by copyright, Ibsen decided to avoid the danger of being rewritten by a lesser dramatist by committing what he called a \"barbaric outrage\" on his play himself and giving it an alternative ending in which Nora did not leave. A production of this version opened in Flensburg in February 1880. This version was also played in Hamburg, Dresden, Hanover, and Berlin, although, in the wake of protests and a lack of success, Niemann-Raabe eventually restored the original ending. Another production of the original version, some rehearsals of which Ibsen attended, opened on 3 March 1880 at the Residenz Theatre in Munich.\n\nIn Great Britain, the only way in which the play was initially allowed to be given in London was in an adaptation by Henry Arthur Jones and Henry Herman called \"Breaking a Butterfly\". This adaptation was produced at the Princess Theatre, 3 March 1884. The first British production of the play in its regular form opened on 7 June 1889 at the Novelty Theatre, starring Janet Achurch as Nora and Charles Charrington as Torvald. Achurch played Nora again for a 7-day run in 1897. Soon after its London premiere, Achurch brought the play to Australia in 1889.\n\nThe play was first seen in America when, during 1883, in Louisville, Kentucky, Helena Modjeska acted Nora. The play made its Broadway premiere at the Palmer's Theatre on 21 December 1889, starring Beatrice Cameron as Nora Helmer. It was first performed in France in 1894.\nOther productions in the United States include one in 1902 starring Minnie Maddern Fiske, a 1937 adaptation with acting script by Thornton Wilder and starring Ruth Gordon, and a 1971 production starring Claire Bloom.\n\nA new translation by Zinnie Harris at the Donmar Warehouse, starring Gillian Anderson, Toby Stephens, Anton Lesser, Tara FitzGerald and Christopher Eccleston opened in May 2009. In August 2013, Young Vic, London, Great Britain, produced a new adaptation of \"A Doll's House\" directed by Carrie Cracknell based on the English language version by Simon Stephens.\nIn September 2014, in partnership with Brisbane Festival, La Boite located in Brisbane, Australia, hosted an adaptation of \"A Doll's House\" written by Lally Katz and directed by Stephen Mitchell Wright.\nIn June 2015, Space Arts Centre in London staged an adaptation of A Doll's House featuring the discarded alternate ending.\n\n\"A Doll's House\" questions the traditional roles of men and women in 19th-century marriage. To many 19th-century Europeans, this was scandalous. The covenant of marriage was considered holy, and to portray it as Ibsen did was controversial; however, the Irish playwright George Bernard Shaw found Ibsen's willingness to examine society without prejudice exhilarating.\n\nThe Swedish playwright August Strindberg criticised the play in his volume of essays and short stories \"Getting Married\" (1884). Strindberg questioned Nora’s walking out and leaving her children behind with a man that she herself disapproved of so much that she would not remain with him. Strindberg also considers that Nora’s involvement with an illegal financial fraud that involved Nora forging a signature, all done behind her husband’s back, and then Nora’s lying to her husband regarding Krogstad’s blackmail, are serious crimes that should raise questions at the end of the play, when Nora is moralistically judging her husband. And Strindberg points out that Nora’s complaint that she and Torvald “have never exchanged one serious word about serious things”, is contradicted by the discussions that occur in act one and two.\n\nBecause of the departure from traditional behavior and theatrical convention involved in Nora's leaving home, her act of slamming the door as she leaves has come to represent the play itself. One critic noted, \"That slammed door reverberated across the roof of the world.\"\n\n\"A Doll's House\" has been adapted for the cinema on many occasions, including:\n\n\n\n\n\n\n", "id": "3144", "title": "A Doll's House"}
{"url": "https://en.wikipedia.org/wiki?curid=3146", "text": "AIM-7 Sparrow\n\nThe AIM-7 Sparrow is an American, medium-range semi-active radar homing air-to-air missile operated by the United States Air Force, United States Navy and United States Marine Corps, as well as other various air forces and navies. Sparrow and its derivatives were the West's principal beyond visual range (BVR) air-to-air missile from the late 1950s until the 1990s. It remains in service, although it is being phased out in aviation applications in favor of the more advanced AIM-120 AMRAAM. The Self-Defence Forces of Japan also employ the Sparrow missile, though it is being phased out and replaced by the Mitsubishi AAM-4. NATO pilots use the brevity code Fox One in radio communication to signal launch of a Semi-Active Radar Homing Missile such as the Sparrow.\n\nThe Sparrow was used as the basis for a surface-to-air missile, the RIM-7 Sea Sparrow, which is used by a number of navies for air defense of their ships. Fired at low altitude and flying directly at its target though the lower atmosphere, the range of the missile in this role is greatly reduced. With the retirement of the Sparrow in the air-to-air role, a new version of the Sea Sparrow was produced to address this concern, producing the much larger and more capable RIM-162 ESSM.\n\n from a late-1940s United States Navy program to develop a guided rocket weapon for air-to-air use. In 1947 the Navy contracted Sperry to build a beam riding version of a standard HVAR, the standard unguided aerial rocket, under Project Hotshot. The weapon was initially dubbed KAS-1, then AAM-2, and, from 1948 on, AAM-N-2. The airframe was developed by Douglas Aircraft Company. The diameter of the HVAR proved to be inadequate for the electronics, leading Douglas to expand the missile's airframe to diameter. The prototype weapon began unpowered flight-tests in 1947, and made its first aerial interception in 1952.\n\nAfter a protracted development cycle the initial AAM-N-2 \"Sparrow\" entered limited operational service in 1954 with specially modified Skyknights all weather carrier night fighters. And in 1956, they were carried by the F3H-2M Demon and F7U Cutlass fighter aircraft. Compared to the modern versions, the Sparrow I was more streamlined and featured a bullet-shaped airframe with a long pointed nose.\n\nSparrow I was a limited and rather primitive weapon. The limitations of beam-riding guidance (which was slaved to an optical sight on single seater fighters and a radar with night fighters) restricted the missile to attacks against targets flying a straight course and made it essentially useless against a maneuvering target. Only about 2,000 rounds were produced to this standard.\n\nAs early as 1950 Douglas examined equipping the Sparrow with an active radar seeker, initially known as XAAM-N-2a \"Sparrow II, the original retroactively becoming Sparrow I\". In 1952 it was given the new code AAM-N-3. The active radar made the Sparrow II a \"fire and forget\" weapon, allowing several to be fired at separate targets at the same time.\n\nBy 1955 Douglas proposed going ahead with development, intending it to be the primary weapon for the F5D Skylancer interceptor. It was later selected, with some controversy, to be the primary weapon for the Canadian Avro Arrow supersonic interceptor, along with the new Astra fire-control system. For Canadian use and as a second source for US missiles, Canadair was selected to build the missiles in Quebec.\n\nThe small size of the missile forebody and the K-band AN/APQ-64-radar limited performance, and it was never able to work in testing. After considerable development and test firings in the U.S. and Canada, Douglas abandoned development in 1956. Canadair continued development until the Arrow was cancelled in 1959.\n\nA subvariant of the Sparrow I armed with the same nuclear warhead as the MB-1 Genie was proposed in 1958, but was cancelled shortly thereafter.\n\nConcurrently with the development of the Sparrow I, in 1951, Raytheon began work on the semi-active radar homing version of Sparrow family of missiles, the AAM-N-6 \"Sparrow III\". The first of these weapons entered United States Navy service in 1958.\n\nThe AAM-N-6a was similar to the -6, but used a new Thiokol liquid-fuel rocket engine for improved performance. It also included changes to the guidance electronics to make it effective at higher closing speeds. The -6a was also selected to arm the Air Force's \"F-110A Spectre\" (F-4 Phantom) fighters in 1962, known to them as the AIM-101. It entered production in 1959, with 7500 being built.\n\nAnother upgrade reverted to a Rocketdyne solid-fuel motor for the AAM-N-6b, which started production in 1963. The new motor significantly increased maximum range to for head-on attacks.\n\nDuring this year the Navy and Air Force agreed on standardized naming conventions for their missiles. The Sparrows became the AIM-7 series. The original Sparrow I and aborted Sparrow II became the AIM-7A and AIM-7B, despite both being out of service. The -6, -6a and -6B became the AIM-7C, AIM-7D and AIM-7E respectively.\n\n25,000 AIM-7Es were produced, and saw extensive use during the Vietnam War, where its performance was generally considered disappointing. The mixed results were a combination of reliability problems (exacerbated by the tropical climate), limited pilot training in fighter-to-fighter combat, and restrictive rules of engagement that generally prohibited BVR (beyond visual range) engagements. The P (kill probability) of the AIM-7E was less than 10%; US fighter pilots shot down 59 aircraft out of the 612 Sparrows fired. Of the 612 AIM-7D/E/E-2 missiles fired, 97 (or 15.8%) hit their targets, resulting in 56 (or 9.2%) kills. Two kills were obtained beyond visual range.\n\nIn 1969 an improved version, the E-2, was introduced with clipped wings and various changes to the fuzing. Considered a \"dogfight Sparrow\", the AIM-7E-2 was intended to be used at shorter ranges where the missile was still travelling at high speeds, and in the head-on aspect, making it much more useful in the visual limitations imposed on the engagements. Even so, its kill rate was only 13% in combat, leading to a practice of ripple-firing all four at once in hopes of increasing kill probability. Its worst tendency was that of detonating prematurely, approximately a thousand feet in front of the launching aircraft, but it also had many motor failures, erratic flights, and fuzing problems. An E-3 version included additional changes to the fuzing, and an E-4 featured a modified seeker for use with the F-14 Tomcat.\n\nImproved versions of the AIM-7 were developed in the 1970s in an attempt to address the weapon's limitations. The AIM-7F, which entered service in 1976, had a dual-stage rocket motor for longer range, solid-state electronics for greatly improved reliability, and a larger warhead. Even this version had room for improvement, leading British Aerospace and the Italian firm Alenia to develop advanced versions of Sparrow with better performance and improved electronics as the BAe Skyflash and Alenia Aspide, respectively.\n\nThe most common version of the Sparrow today, the AIM-7M, entered service in 1982 and featured a new inverse monopulse seeker (matching the capabilities of Skyflash), active radar fuse, digital controls, improved ECM resistance, and better low-altitude performance. It was used to good advantage in the 1991 Gulf War, where it scored many USAF air-to-air kills. Of 44 missiles fired, 30 (68.2%) hit their intended targets resulting in 24/26 (54.5%/59.1%) kills. 19 kills were obtained beyond visual range.\n\nThe AIM-7P is similar in most ways to the M versions, and was primarily an upgrade program for existing M-series missiles. The main changes were to the software, improving low-level performance. A follow-on Block II upgrade added a new rear receiver allowing the missile to receive mid-course correction from the launching aircraft. Plans initially called for all M versions to be upgraded, but currently P's are being issued as required to replace M's lost or removed from the inventory.\n\nThe final version of the missile was to have been the AIM-7R, which added an infrared homing seeker to an otherwise unchanged AIM-7P Block II. A general wind-down of the budget led to it being cancelled in 1997.\n\nSparrow is now being phased out with the availability of the active-radar AIM-120 AMRAAM, but is likely to remain in service for several years.\n\nAs part of the Avro Arrow program, Canadair partnered with Douglas in the development of the Sparrow II (AIM-7B). After Douglas dropped out of this program, Canadair continued on with it until the termination of the Arrow. Canadair had completed five missiles based on airframes from Douglas, and built two models from scratch, when the program was cancelled with the cancellation of the Arrow.\n\nSkyguard I is an anti-aircraft system, utilizing ground based AIM-7 Sparrow launchers.\n\nThe Italian company Finmeccanica (now Leonardo S.p.A.), Alenia Difesa licensed the AIM-7E Sparrow technology from the US, and produced its own improved version called Aspide.\n\nThe LY-60/FD-60/PL-10 is a family of PRC missiles developed by the Shanghai Academy of Science and Technology, largely based on the Italian Aspide missile - a version of the Sparrow. There are four versions of the basic design, three of which are surface-to-air and one air-to-air.\n\nThe Soviet Union acquired an AIM-7 in 1968 and a Vympel team started copying it as the K-25. The missile did not enter production as the R-23 was perceived to have better versatility, range, signal processing logic and immunity from interference. K-25 work ended in 1971, but analysis of the Sparrow was later used to inform the design of the Vympel R-27, particularly the servomechanisms and movable wings.\n\nBritish Aerospace (BAe) licensed the AIM-7E2 technology in the 1970s, producing the Skyflash missile. Skyflash used a Marconi XJ521 monopulse Semi-Active seeker together with improvements to the electronics. It was powered by the Aerojet Mk52 mod 2 rocket engine (later by the Rocketdyne Mk38 mod 4). Skyflash entered service with the Royal Air Force (RAF) on their Phantom FG.1/FGR.2 in 1978, and later on the Tornado F3. Skyflash was also exported to Sweden for use on their Viggen fighters.\n\nAn upgraded version with active radar seeker, called Active Sky Flash was proposed by BAe and Thomson-CSF, but did not receive funding because the RAF opted for other missiles.\n\nThe Sparrow has four major sections: guidance section, warhead, control, and rocket motor (currently the Hercules MK-58 solid-propellant rocket motor). It has a cylindrical body with four wings at mid-body and four tail fins. Although the external dimensions of the Sparrow remained relatively unchanged from model to model, the internal components of newer missiles represent major improvements, with vastly increased capabilities. The warhead is of the continuous-rod type.\n\nAs with other semi-active radar guided missiles, the missile does not generate radar signals, but instead homes in on reflected continuous-wave signals from the launch platform's radar. The receiver also senses the guidance radar to enable comparisons that enhance the missile's resistance to passive jamming.\n\nThe launching aircraft will illuminate the target with its radar. In radars of the 1950s these were single target tracking devices using a nutating horn as part of the antenna. This caused the beam to be swept in a small cone. Signal processing would be applied to determine the direction of maximum illumination and so develop a signal to steer the antenna toward the target. The missile detects the reflected signal from the target with a high gain antenna in a similar fashion and steers the entire missile toward closure with the target. The missile guidance also samples a portion of the illuminating signal via rearward pointing waveguides. The comparison of these two signals enabled logic circuits to determine the true target reflection signal, even if the target were to eject radar-reflecting chaff.\n\n\n\n\n", "id": "3146", "title": "AIM-7 Sparrow"}
{"url": "https://en.wikipedia.org/wiki?curid=3147", "text": "AIM-120 AMRAAM\n\nThe AIM-120 Advanced Medium-Range Air-to-Air Missile, or AMRAAM (pronounced \"am-ram\"), is a modern beyond-visual-range air-to-air missile (BVRAAM) capable of all-weather day-and-night operations. Designed with 7-inch diameter instead of 8-inch diameter form-and-fit factors, and employing active transmit-receive radar guidance instead of semi-active receive-only radar guidance, it is a fire-and-forget upgrade to the previous generation Sparrow missiles. When an AMRAAM missile is being launched, NATO pilots use the brevity code Fox Three.\n\nThe AIM-7 Sparrow medium range missile (MRM) was purchased by the US Navy from original developer Howard Hughes in the 1950s as its first operational air-to-air missile with \"beyond visual range\" (BVR) capability. With an effective range of about , it was introduced as a radar beam-riding missile and then it was improved to a semiactive radar guided missile which would home in on reflections from a target illuminated by the radar of the launching aircraft. It was effective at visual to beyond visual range. The early beam riding versions of the Sparrow missiles were integrated onto the F3H Demon and F7U Cutlass, but the definitive AIM-7 Sparrow was the primary weapon for the all-weather F-4 Phantom II fighter/interceptor, which lacked an internal gun in its U.S. Navy, U.S. Marine Corps, and early U.S. Air Force versions. The F-4 carried up to four AIM-7s in built-in recesses under its belly.\n\nAlthough designed for use against non-maneuvering targets such as bombers, because of poor performance against fighters over North Vietnam, these missiles were progressively improved until they proved highly effective in dogfights. Together with the short-range, infrared-guided AIM-9 Sidewinder, they replaced the AIM-4 Falcon IR and radar guided series for use in air combat by the USAF as well. A disadvantage to semi-active homing was that only one target could be illuminated by the launching fighter plane at a time. Also, the launching aircraft had to remain pointed in the direction of the target (within the azimuth and elevation of its own radar set) which could be difficult or dangerous in air-to-air combat.\n\nAn active-radar variant called the Sparrow II was developed to address these drawbacks, but the U.S. Navy pulled out of the project in 1956. The Royal Canadian Air Force, which took over development in the hopes of using the missile to arm their prospective CF-105 Arrow interceptor, soon followed in 1958. The electronics of the time simply could not be miniaturized enough to make Sparrow II a viable working weapon. It would take decades, and a new generation of digital electronics, to produce an effective active-radar air-to-air missile as compact as the Sparrow.\n\nThe US Navy later developed the AIM-54 Phoenix long-range missile (LRM) for the fleet air defense mission. It was a large , Mach 5 missile designed to counter cruise missiles and the bombers that launched them. Originally intended for the straight-wing Douglas F6D Missileer and then the navalized version of the F-111B, it finally saw service with the Grumman F-14 Tomcat, the only fighter capable of carrying such a heavy missile. Phoenix was the first US fire-and-forget, multiple-launch, radar-guided missile: one which used its own active guidance system to guide itself without help from the launch aircraft when it closed on its target. This, in theory, gave a Tomcat with a six-Phoenix load the unprecedented capability of tracking and destroying up to six targets beyond visual range, as far as away—the only US fighter with such capability.\n\nA full load of six Phoenix missiles and its dedicated launcher exceeded a typical Vietnam-era bomb load. Its service in the US Navy was primarily as a deterrent, as its use was hampered by restrictive rules of engagement in conflicts such as Operations Desert Storm, Southern Watch, and Iraqi Freedom. The US Navy retired the Phoenix in 2004 in light of availability of the AIM-120 AMRAAM on the F/A-18 Hornet and the pending retirement of the F-14 Tomcat from active service in late 2006.\n\nThe Department of Defense conducted an extensive evaluation of air combat tactics and missile technology from 1974 to 1978 at Nellis AFB using the F-14 Tomcat and F-15 Eagle equipped with Sparrow and Sidewinder missiles as the blue force and aggressor F-5E aircraft equipped with AIM-9L all-aspect Sidewinders as the red force. This joint test and evaluation (JT&E) was designated Air Combat Evaluation/Air Intercept Missile Evaluation (ACEVAL/AIMVAL). A principal finding was that the necessity to produce illumination for the Sparrow until impact resulted in the red force's being able to launch their all-aspect Sidewinders before impact, resulting in mutual kills. What was needed was Phoenix-type multiple-launch and terminal active capability in a Sparrow-size airframe. This led to a memorandum of agreement (MOA) with European allies (principally the UK and Germany for development) for the US to develop an advanced, medium-range, air-to-air missile with the USAF as lead service. The MOA also assigned responsibility for development of an advanced, short-range, air-to-air missile to the European team; this would become the British ASRAAM.\n\nBy the 1990s, the reliability of the Sparrow had improved so much from the dismal days of Vietnam that it accounted for the largest number of aerial targets destroyed in Desert Storm. But while the USAF had passed on the Phoenix and their own similar AIM-47/YF-12 to optimize dogfight performance, they still needed a multiple-launch fire-and-forget capability for the F-15 and F-16. AMRAAM would need to be fitted on fighters as small as the F-16, and fit in the same spaces that were designed to fit the Sparrow on the F-4 Phantom. The European partners needed AMRAAM to be integrated on aircraft as small as the Sea Harrier. The US Navy needed AMRAAM to be carried on the F/A-18 Hornet and wanted capability for two to be carried on a launcher that normally carried one Sparrow to allow for more air-to-ground weapons.\n\nThe AMRAAM became one of the primary air-to-air weapons of the new F-22 Raptor fighter, which needed to place all of its weapons into internal weapons bays in order to help achieve an extremely low radar cross-section.\n\nAMRAAM was developed as the result of an agreement (the Family of Weapons MOA, no longer in effect by 1990), among the United States and several other NATO nations to develop air-to-air missiles and to share production technology. Under this agreement the U.S. was to develop the next generation medium range missile (AMRAAM) and Europe would develop the next generation short range missile (ASRAAM). Although Europe initially adopted the AMRAAM, an effort to develop the Meteor (missile), a competitor to AMRAAM, was begun in Great Britain. Eventually the ASRAAM was developed solely by the British, but using another source for its infrared seeker. After protracted development, the deployment of AMRAAM (AIM-120A) began in September 1991 in US Air Force F-15 Eagle fighter squadrons. The US Navy soon followed (in 1993) in its F/A-18 Hornet squadrons.\n\nThe eastern counterpart of AMRAAM is the somewhat similar Russian Air Force AA-12 \"Adder\", sometimes referred to in the West as the \"AMRAAMski.\" Likewise, France began its own air-to-air missile development with the MICA concept that used a common airframe for separate radar-guided and infrared-guided versions.\n\nAMRAAM has an all-weather, beyond-visual-range (BVR) capability. It improves the aerial combat capabilities of US and allied aircraft to meet the threat of enemy air-to-air weapons as they existed in 1991. AMRAAM serves as a follow-on to the AIM-7 Sparrow missile series. The new missile is faster, smaller, and lighter, and has improved capabilities against low-altitude targets. It also incorporates a datalink to guide the missile to a point where its active radar turns on and makes terminal intercept of the target. An inertial reference unit and micro-computer system makes the missile less dependent upon the fire-control system of the aircraft.\n\nOnce the missile closes in on the target, its active radar guides it to intercept. This feature, known as \"fire-and-forget\", frees the aircrew from the need to further provide guidance, enabling the aircrew to aim and fire several missiles simultaneously at multiple targets and perform evasive maneuvers while the missiles guide themselves to the targets.\n\nThe missile also features the ability to \"Home on Jamming,\" giving it the ability to switch over from active radar homing to passive homing – homing on jamming signals from the target aircraft. Software on board the missile allows it to detect if it is being jammed, and guide on its target using the proper guidance system.\n\nAMRAAM uses two-stage guidance when fired at long range. The aircraft passes data to the missile just before launch, giving it information about the location of the target aircraft from the launch point and its direction and speed. The missile uses this information to fly on an interception course to the target using its built-in inertial navigation system (INS). This information is generally obtained using the launching aircraft's radar, although it could come from an Infra-red search and track system, from a data link from another fighter aircraft, or from an AWACS aircraft.\n\nAfter launch, if the firing aircraft or surrogate continues to track the target, periodic updates—such as changes in the target's direction and speed—are sent from the launch aircraft to the missile, allowing the missile to adjust its course, via actuation of the rear fins, so that it is able to close to a self-homing distance where it will be close enough to \"catch\" the target aircraft in the \"basket\" (the missile's radar field of view in which it will be able to lock onto the target aircraft, unassisted by the launch aircraft).\n\nNot all armed services using the AMRAAM have elected to purchase the mid-course update option, which limits AMRAAM's effectiveness in some scenarios. The RAF initially opted not to use mid-course update for its Tornado F3 force, only to discover that without it, testing proved the AMRAAM was less effective in beyond visual range (BVR) engagements than the older semi-active radar homing BAE Skyflash weapon—the AIM-120's own radar is necessarily of limited range and power compared to that of the launch aircraft.\n\nOnce the missile closes to self-homing distance, it turns on its active radar seeker and searches for the target aircraft. If the target is in or near the expected location, the missile will find it and guide itself to the target from this point. If the missile is fired at short range, within visual range (WVR) or the near BVR, it can use its active seeker just after launch, making the missile truly \"fire and forget\". \n\nApart from the slave mode, there is a free guidance mode, called boresight. This mode is radar guidance-free, the missile just fires and locks the first thing it sees. This mode can be used for defensive shot, i.e. when the enemy has numerical superiority.\n\nThe kill probability (P) is determined by several factors, including aspect (head-on interception, side-on or tail-chase), altitude, the speed of the missile and the target, and how hard the target can turn. Typically, if the missile has sufficient energy during the terminal phase, which comes from being launched at close range to the target from an aircraft with an altitude and speed advantage, it will have a good chance of success. This chance drops as the missile is fired at longer ranges as it runs out of overtake speed at long ranges, and if the target can force the missile to turn it might bleed off enough speed that it can no longer chase the target. Operationally, the missile, which was designed for beyond visual range combat, has a P of 59% (17 missiles for 10 kills). The targets included six MiG-29s, a MiG-25, a MiG-23, a Galeb and a US Army Blackhawk that was targeted by mistake.\n\nThere are currently four main variants of AMRAAM, all in service with the United States Air Force, United States Navy, and the United States Marine Corps. The AIM-120A is no longer in production and shares the enlarged wings and fins with the successor AIM-120B. The AIM-120C has smaller \"clipped\" aerosurfaces to enable internal carriage on the USAF F-22 Raptor. AIM-120B deliveries began in 1994.\n\nThe AIM-120C deliveries began in 1996. The C-variant has been steadily upgraded since it was introduced. The AIM-120C-6 contained an improved fuse (Target Detection Device) compared to its predecessor. The AIM-120C-7 development began in 1998 and included improvements in homing and greater range (actual amount of improvement unspecified). It was successfully tested in 2003 and is currently being produced for both domestic and foreign customers. It helped the U.S. Navy replace the F-14 Tomcats with F/A-18E/F Super Hornets – the loss of the F-14's long-range AIM-54 Phoenix missiles (already retired) is offset with a longer-range AMRAAM-D. The lighter weight of the advanced AMRAAM enables an F/A-18E/F pilot greater bring-back weight upon carrier landings.\n\nThe AIM-120D is an upgraded version of the AMRAAM with improvements in almost all areas, including 50% greater range (than the already-extended range AIM-120C-7) and better guidance over its entire flight envelope yielding an improved kill probability (P). Raytheon began testing the D model on August 5, 2008, the company reported that an AIM-120D launched from an F/A-18F Super Hornet passed within lethal distance of a QF-4 target drone at the White Sands Missile Range.\n\nThe AIM-120D (P3I Phase 4, formerly known as AIM-120C-8) is a development of the AIM-120C with a two-way data link, more accurate navigation using a GPS-enhanced IMU, an expanded no-escape envelope, and improved HOBS (High-Angle Off-Boresight) capability. The AIM-120D is a joint USAF/USN project, and is currently in the testing phase. The USN was scheduled to field it from 2014, and AIM-120D will be carried by all Pacific carrier groups by 2020, although the 2013 sequestration cuts could push back this later date to 2022. The Royal Australian Air Force requested 450 AIM-120D missiles, which would make it the first foreign operator of the missile. The procurement, approved by the US Government in April 2016, will cost $1.1 billion and will be integrated for use on the F/A-18F Super Hornet, EA-18G Growler and the F-35 Lightning II aircraft.\n\nThere are also plans for Raytheon to develop a ramjet-powered derivative of the AMRAAM, the Future Medium Range Air-Air Missile (FMRAAM). It is not known whether the FMRAAM will be produced since the target market, the British Ministry of Defence, has chosen the Meteor missile over the FMRAAM for a BVR missile for the Eurofighter Typhoon aircraft.\n\nRaytheon is also working with the Missile Defense Agency to develop the Network Centric Airborne Defense Element (NCADE), an anti-ballistic missile derived from the AIM-120. This weapon will be equipped with a Ramjet engine and an infrared homing seeker derived from the Sidewinder missile. In place of a proximity-fused warhead, the NCADE will use a kinetic energy hit-to-kill vehicle based on the one used in the Navy's RIM-161 Standard Missile 3.\n\nThe −120A and −120B models are currently nearing the end of their service life while the −120D variant has just entered full production. AMRAAM was due to be replaced by the USAF, the U.S. Navy, and the U.S. Marine Corps after 2020 by the Joint Dual Role Air Dominance Missile (Next Generation Missile). This was unexpectedly terminated in the 2013 budget plan, and so the future replacement is uncertain.\n\nRaytheon successfully tested launching AMRAAM missiles from a five-missile carrier on a M1097 Humvee. This system will be known as the SLAMRAAM (Surface Launched (SL) and AMRAAM). They receive their initial guidance information from a radar not mounted on the vehicle. Since the missile is launched without the benefit of an aircraft's speed or high altitude, its range is considerably shorter. Raytheon is currently marketing an SL-AMRAAM EX, purported to be an extended range AMRAAM and bearing a resemblance to the RIM-162 ESSM.\n\nThe Norwegian Advanced Surface-to-Air Missile System (NASAMS), developed by Kongsberg Defence & Aerospace, consists of a number of vehicle-pulled launch batteries (containing six AMRAAMs each) along with separate radar trucks and control station vehicles. A more recent version of the program is the \"High Mobility Launcher\", made in cooperation with Raytheon (Kongsberg Defence & Aerospace was already a subcontractor on the SLAMRAAM system), where the launch-vehicle is a Humvee (M1152A1 HMMWV), containing four AMRAAMs each.\n\nWhile still under evaluation for replacement of current US Army assets, the SL-AMRAAM has been deployed in several nations' military forces. The United Arab Emirates (UAE) has requested the purchasing of SL-AMRAAM as part of a larger 7 billion dollar foreign military sales package. The sale would include 288 AMRAAM C-7 missiles.\n\nThe US Army has test fired the SL-AMRAAM from a HIMARS artillery rocket launcher as a common launcher, as part of a move to switch to a larger and more survivable launch platform.\n\nOn January 6, 2011, Secretary of Defense Robert Gates announced that the U.S. Army has decided to terminate acquisition of the SLAMRAAM as part of a budget-cutting effort.\n\nThe National Guard Association of the United States has sent a letter asking for the United States Senate to stop the Army's plan to drop the SLAMRAAM program because without it there would be no path to modernize the Guard's AN/TWQ-1 Avenger Battalions.\n\nOn February 22, 2015 Raytheon announced an Extended Range upgrade to NASAMS-launched AMRAAM, calling it AMRAAM-ER. This combines the AMRAAM seeker with the ESSM rocket motor.\n\nThe AMRAAM was used for the first time on December 27, 1992, when a USAF F-16D shot down an Iraqi MiG-25 that violated the southern no-fly-zone. Interestingly, this missile had been returned from the flight line as defective a day earlier. AMRAAM gained a second victory in January 1993 when an Iraqi MiG-23 was shot down by a USAF F-16C.\n\nThe third combat use of the AMRAAM was in 1994, when a Republika Srpska Air Force J-21 Jastreb aircraft was shot down by a USAF F-16C that was patrolling the UN-imposed no-fly zone over Bosnia. In that engagement, at least three other Serbian aircraft were shot down by USAF F-16C fighters using AIM-9 missiles (see Banja Luka incident for more details). At that point, three launches in combat had resulted in three kills, resulting in the AMRAAM's being informally named \"slammer\" in the second half of the 1990s.\n\nIn 1998 and 1999 AMRAAMs were again fired by USAF F-15 fighters at Iraqi aircraft violating the No-Fly-Zone, but this time they failed to hit their targets. During the spring of 1999, AMRAAMs saw their main combat action during Operation Allied Force, the Kosovo bombing campaign. Six Serbian MiG-29 were shot down by NATO (4 USAF F-15C, 1 USAF F-16C, 1 Dutch F-16A MLU), all of them using AIM-120 missiles (the kill by the F-16C may have happened due to friendly fire, from SA-7 MANPAD fired by Serbian infantry).\n\nAs of 2016, the AIM-120 AMRAAM has shot down nine aircraft (six MiG-29s, one MiG-25, one MiG-23, and one Soko J-21 Jastreb). An AMRAAM was also involved in a friendly fire incident in 1994 when F-15 fighters patrolling Iraq's Northern No-Fly Zone inadvertently shot down a pair of U.S. Army Black Hawk helicopters.\n\nSince 2007 Raytheon has continued to slip on AMRAAM deliveries, leading the USAF to withhold $621 million in 2012 on account of 193 missiles not delivered.\n\nCanadair, now Bombardier, had largely helped with the development of the AIM-7 Sparrow and Sparrow II, and assisted to a less extent in the AIM-120 development. Canada had placed an order for 256 AIM-120's, but cancelled half of them after engine ignition problems due to cold weather conditions. The AIM-9X & AIM-7 were ordered as replacements.\n\nIn early 1995 South Korea ordered 88 AIM-120A missiles for its KF-16 fleet. In 1997 South Korea ordered additional 737 AIM-120B missiles.\n\nIn 2006 Poland received AIM-120C-5 missiles to arm its new F-16C/D Block 52+ fighters.\n\nIn early 2006, the Pakistan Air Force (PAF) ordered 500 AIM-120C-5 AMRAAM missiles as part of a $650 million F-16 ammunition deal to equip its F-16C/D Block 50/52+ and F-16A/B Block 15 MLU fighters. The PAF got the first three F-16C/D Block 50/52+ aircraft on July 3, 2010 and first batch of AMRAAMs on July 26, 2010.\n\nIn 2007, the United States government agreed to sell 218 AIM-120C-7 missiles to Taiwan as part of a large arms sales package that also included 235 AGM-65G-2 Maverick missiles. Total value of the package, including launchers, maintenance, spare parts, support and training rounds, was estimated at around US$421 million. This supplemented an earlier Taiwanese purchase of 120 AIM-120C-5 missiles a few years ago.\n\n2008 has brought announcements of new or additional sales to Singapore, Finland, Morocco and South Korea; in December 2010 the Swiss government requested 150 AIM-120C-7 missiles. Sales to Finland have stalled, because the manufacturer has not been able to fix a mysterious bug that causes the rocket motors of the missile to fail in cold tests. In May 5, 2015, the State Department has made a determination approving a possible Foreign Military Sale to Royal Malaysian Air Force for AIM-120C7 AMRAAM Missiles and associated equipment, parts and logistical support for an estimated cost of $21 million.\n\nIn March 2016, the US government approved the sales of AIM-120C-7 missiles to the Indonesian Air Force to equip their fleet of F-16 C/D Block 32+.\n\n\n\n\n", "id": "3147", "title": "AIM-120 AMRAAM"}
{"url": "https://en.wikipedia.org/wiki?curid=3149", "text": "AGM-88 HARM\n\nThe AGM-88 High-speed Anti-Radiation Missile (HARM) is a tactical, air-to-surface missile designed to home in on electronic transmissions coming from surface-to-air radar systems. It was originally developed by Texas Instruments as a replacement for the AGM-45 Shrike and AGM-78 Standard ARM system. Production was later taken over by Raytheon Corporation when it purchased the defense production business of Texas Instruments.\n\nThe AGM-88 can detect, attack and destroy a radar antenna or transmitter with minimal aircrew input. The proportional guidance system that hones in on enemy radar emissions has a fixed antenna and seeker head in the missile's nose. A smokeless, solid-propellant, booster-sustainer rocket motor propels the missile at speeds over Mach 2. HARM, a U.S. Navy-led program, was initially integrated onto the A-6E, A-7 and F/A-18 and later onto the EA-6B. RDT&E for use on the F-14 was begun, but not completed. The USAF introduced HARM on the F-4G Wild Weasel and later on specialized F-16s equipped with the HARM Targeting System (HTS).\n\nThe HARM missile was approved for full production in March 1983, obtained initial operating capability (IOC) on the A-7E Corsair II in late 1983 and then deployed in late 1985 with VA-46 aboard the aircraft carrier USS \"America\". In 1986 the first successful firing of the HARM from an EA-6B was performed by VAQ-131. It was soon used in combat—in March 1986 against a Libyan SA-5 site in the Gulf of Sidra, and then Operation Eldorado Canyon in April. HARM was used extensively by the United States Navy and the United States Air Force for Operation Desert Storm during the Gulf War of 1991.\n\nDuring the Gulf War, the HARM was involved in a friendly fire incident when the pilot of an F-4G Wild Weasel escorting a B-52 bomber mistook the latter's tail gun radar for an Iraqi AAA site. (This was after the tail gunner of the B-52 had targeted the F-4G, mistaking it for an Iraqi MiG.) The F-4 pilot launched the missile and then saw that the target was the B-52, which was hit. It survived with shrapnel damage to the tail and no casualties. The B-52 was subsequently renamed \"In HARM's Way\".\n\n\"Magnum\" is spoken over the radio to announce the launch of an AGM-88. During the Gulf War, if an aircraft was illuminated by enemy radar a bogus \"Magnum\" call on the radio was often enough to convince the operators to power down.\nThis technique would also be employed in Serbia during air operations in 1999.\n\nIn 2013 President Obama offered the AGM-88 to Israel for the first time.\n\nThe newest upgrade, the \"AGM-88E Advanced Anti-Radiation Guided Missile (AARGM),\" features the latest software, enhanced capabilities intended to counter radar shutdown and passive radar using an additional active millimeter wave seeker. It was released in November 2010 and is a joint venture by the US Department of Defense and the Italian Ministry of Defense and is produced by Alliant Techsystems.\n\nIn November 2005, the Italian Ministry of Defense and the US Department of Defense signed a Memorandum of Agreement on the joint development of the AGM-88E AARGM missile. Italy was providing $20 million of developmental funding as well as several millions worth of material, equipment and related services. The Italian Air Force was expected to procure up to 250 missiles for its Tornado ECR aircraft. Thus flight test program was set to integrate the AARGM onto Tornado ECR's weapon system.<br>\nThe Navy demonstrated the AARGM's capability during Initial Operational Test and Evaluation (IOT&E) in spring 2012 with live firing of 12 missiles. Aircrew and maintenance training with live missiles was completed in June.\n\nThe Navy authorized Full-Rate Production (FRP) of the AARGM in August 2012, with 72 missiles for the Navy and nine for the Italian Air Force to be delivered in 2013. A U.S. Marine Corps F/A-18 Hornet squadron will be the first forward-deployed unit with the AGM-88E.\n\nIn September 2013, ATK delivered the 100th AARGM to the U.S. Navy. The AGM-88E program is on schedule and on budget, with Full Operational Capability (FOC) planned for September 2014. The AGM-88E was designed to improve the effectiveness of legacy HARM variants against fixed and relocatable radar and communications sites, particularly those that would shut down to throw off anti-radiation missiles, by attaching a new seeker to the existing Mach 2-capable rocket motor and warhead section, adding a passive anti-radiation homing receiver, satellite and inertial navigation system, a millimeter wave radar for terminal guidance, and the ability to beam up images of the target via a satellite link just seconds before impact.\n\nIt will be initially integrated onto the F/A-18C/D, F/A-18E/F, EA-18G, and Tornado ECR aircraft and later on the F-35.\n\nThe Navy's FY 2016 budget included funding for an extended range AARGM-ER that utilizes the existing guidance system and warhead of the AGM-88E with a solid integrated rocket-ramjet for double the range. Development funding will last to 2020.\n\nOn September 2016, Orbital ATK has lifted the veil on its extended-range variant of the AGM-88E or AARGM-ER, which incorporates a redesigned control section and 11.5 in.-dia. rocket motor for twice the range and internal carriage on the Lockheed Martin F-35 Lightning II. \n\nIn September 2015, the AGM-88E successfully hit a mobile ship target in a live-fire test, demonstrating the missile's ability to use anti-radiation homing and millimeter wave radar to detect, identify, locate, and engage moving targets.\n\nAlthough the U.S. chose the Orbital ATK-produced AGM-88E, Raytheon created their own version of the AARGM called the AGM-88F HARM Control Section Modification (HCSM) that incorporates similar upgrade features, which could allow the company to offer their missile for export.\n\n\n\n\n", "id": "3149", "title": "AGM-88 HARM"}
{"url": "https://en.wikipedia.org/wiki?curid=3151", "text": "AGM-65 Maverick\n\nThe AGM-65 Maverick is an air-to-ground tactical missile (AGM) designed for close air support. It is the most widely produced precision-guided missile in the Western world, and is effective against a wide range of tactical targets, including armor, air defenses, ships, ground transportation and fuel storage facilities.\n\nOriginally designed and built by Hughes Missile Systems, development of the AGM-65 spanned from 1966 to 1972, after which it entered service with the United States Air Force in August 1972. Since then, it has been exported to more than 30 countries and is certified on 25 aircraft. The Maverick served during the Vietnam, Yom Kippur, Iran–Iraq, and Persian Gulf Wars, along with other smaller conflicts, destroying enemy forces and installations with varying degrees of success.\n\nSince its introduction into service, numerous Maverick versions had been designed and produced, using electro-optical, laser, charge-coupled device and infra-red guidance systems. The AGM-65 has two types of warhead: one has a contact fuze in the nose, the other has a heavyweight warhead fitted with a delayed-action fuze, which penetrates the target with its kinetic energy before detonating.\n\nThe Maverick shares the same configuration as Hughes's AIM-4 Falcon and AIM-54 Phoenix, and measures more than in length and in diameter.\n\nThe Maverick's development history began in 1965, when the United States Air Force (USAF) began a program to develop a replacement to the AGM-12 Bullpup. With a range of , the radio-guided Bullpup was introduced in 1959 and was considered a \"silver bullet\" by operators. However, the launch aircraft was required to fly straight towards the target during the missile's flight instead of performing evasive maneuvers, thus risking the crew. Even when it hit, the small warhead was only useful against small targets like bunkers, when used against larger targets like the Thanh Hóa Bridge it did little other than char the structure. The USAF began a series of projects to replace Bullpup, both larger versions of Bullpup, models C and D, as well as a series of Bullpup adaptations offering fire-and-forget guidance. Among the later were the AGM-83 Bulldog, AGM-79 Blue Eye. and AGM-80 Viper.\n\nFrom 1966 to 1968, Hughes Missile Systems Division and Rockwell competed for the contract to build an entirely new fire-and-forget missile with far greater range performance than any of the Bullpup versions. Each were allocated $3 million for preliminary design and engineering work of the Maverick in 1966. In 1968, Hughes emerged with the $95 million contract for further development and testing of the missile; at the same time, contract options called for 17,000 missiles to be procured. Hughes conducted a smooth development of the AGM-65 Maverick, with the first unguided test launch from a F-4 on 18 September 1969, with the first guided test on 18 December successfully performing a direct hit on a M41 tank target at the Air Force Missile Development Center at Holloman Air Force Base, New Mexico.\n\nIn July 1971, the USAF and Hughes signed a $69.9 million contract for 2,000 missiles, the first of which was delivered in 1972. Although early operational results were favorable, military planners predicted that the Maverick would fare less successfully in the hazy conditions of Central Europe, where it would have been used against Warsaw Pact forces. As such, development of the AGM-65B began in 1975 before it was delivered during the late 1970s. When production of the AGM-65A/B was ended in 1978, more than 35,000 missiles had been built.\n\nMore versions of the Maverick appeared, among which was the laser-guided AGM-65C/E. Development of the AGM-65C started in 1978 by Rockwell, who built a number of development missiles for the USAF. Due to high cost, the version was not procured by the USAF, and instead entered service with the United States Marine Corps (USMC) as the AGM-65E.\n\nAnother major development was the AGM-65D, which employed an imaging infrared (IIR) seeker. By imaging on radiated heat, the IIR is all-weather operable as well as showing improved performance in acquiring and tracking the hot engines, such as in tanks and trucks, that were to be one of its major missions. The seekerhead mechanically scanned the scene over a nitrogen-cooled 4-by-4 pixel array using a series of mirrored facets machined into the inner surface of the ring-shaped main gyroscope. The five-year development period of the AGM-65D started in 1977 and ended with the first delivery to the USAF in October 1983. The version received initial operating capability in February 1986.\n\nThe AGM-65F is a hybrid Maverick combining the AGM-65D's IIR seeker and warhead and propulsion components of the AGM-65E. Deployed by the United States Navy (USN), the AGM-65F is optimized for maritime strike roles. The first AGM-65F launch from the P-3C took place in 1989, and in 1994, the USN awarded Unisys a contract to integrate the version with the P-3C. Meanwhile, Hughes produced the AGM-65G, which essentially has the same guidance system as the D, with some software modifications that track larger targets, coupled with a shaped-charge warhead.\n\nIn the mid-1990s to early 2000s, there were several ideas of enhancing the Maverick's potential. Among them was the stillborn plan to incorporate the Maverick millimeter wave active radar homing, which can determine the exact shape of a target. Another study called \"Longhorn Project\" was conducted by Hughes, and later Raytheon following the absorption of Hughes into Raytheon, looked a Maverick version equipped with turbojet engines instead of rocket motors. The \"Maverick ER\", as it was dubbed, would have a \"significant increase in range\" compared to the Maverick's current range of . The proposal was abandoned, but if the Maverick ER had entered production, it would have replaced the AGM-119B Penguin carried on the MH-60R.\nThe most modern versions of the Maverick are the AGM-65H/K, which were in production . The AGM-65H was developed by coupling the AGM-65B with a charge-coupled device (CCD) seeker optimized for desert operations and which has three times the range of the original TV-sensor; a parallel USN program aimed at rebuilding AGM-65Fs with newer CCD seekers resulted in the AGM-65J. The AGM-65K, meanwhile, was developed by replacing the AGM-65G's IR guidance system with an electro-optical television guidance system.\n\nThe Maverick has a modular design construction, allowing a different combination of the guidance package and warhead to be attached to the rocket motor section to produce a different weapon. It has long-chord delta wings and a cylindrical body, reminiscent of the AIM-4 Falcon and the AIM-54 Phoenix.\n\nDifferent models of the AGM-65 have used electro-optical, laser, and infra-red guidance systems. The AGM-65 has two types of warheads: one has a contact fuze in the nose, the other has a heavyweight warhead fitted with a delayed-action fuze, which penetrates the target with its kinetic energy before detonating. The latter is most effective against large, hard targets. The propulsion system for both types is a solid-fuel rocket motor behind the warhead.\n\nThe Maverick missile is unable to lock onto targets on its own; it has to be given input by the pilot or weapon systems officer (WSO) after which it follows the path to the target autonomously, allowing the WSO to fire and forget. In an A-10 Thunderbolt IIs, for example, the video fed from the seeker head is relayed to a screen in the cockpit, where the pilot can check the locked target of the missile before launch. A crosshair on the head-up display is shifted by the pilot to set the approximate target while the missile will then automatically recognize and lock on to the target. Once the missile is launched, it requires no further assistance from the launch vehicle and tracks its target automatically. This fire-and-forget property is not shared by the E version that uses semi-active laser homing.\n\n\nThe Maverick was declared operational on 30 August 1972 with the F-4D/Es and A-7s initially cleared for the type; the missile made its combat debut four months later with the USAF in the Vietnam War. During the Yom Kippur War in October 1973, the Israelis used Mavericks to destroy and disable enemy vehicles. Deployment of early versions of the Mavericks in these two wars were successful due to the favorable atmospheric conditions that suited the electro-optical TV seeker. Ninety-nine missiles were fired during the two wars, eighty-four of which were successful.\n\nIn June 1975, during a border confrontation, a formation of Iranian F4E Phantoms destroyed a group of Iraqi tanks by firing 12 Mavericks at them. Five years later, during Operation \"Pearl\" as part of the Iran–Iraq War, Iranian F-4s used Mavericks to sink three OSA II missile boats and four P-6 combat ships.\nDue to weapons embargoes, Iran had to equip its AH-1J SeaCobra helicopters with AGM-65 Maverick missiles and used them with some success in various operations such as Operation \"Undeniable Victory\" whereas Iranian AH-1J's fired 11 Mavericks.\n\nIn August 1990, Iraq invaded Kuwait. In early 1991, the US-led Coalition executed Operation \"Desert Storm\" during which Mavericks played a crucial role in the ousting of Iraqi forces from Kuwait. Employed by F-15E Strike Eagles, F/A-18 Hornets, AV-8B Harriers, F-16 Fighting Falcons and A-10 Thunderbolt IIs, but used mainly by the last two, more than 5,000 Mavericks were deployed to attack armored targets. The most-used variant by the USAF was the IIR-guided AGM-65D. The reported hit rate by USAF Mavericks was 80–90%, while for the USMC it was 60%. The Maverick was used again in Iraq during the 2003 Iraq War, during which 918 were fired.\n\nThe first time the Maverick were fired from a Lockheed P-3 Orion at a hostile vessel was when the USN and coalition units came to the aid of Libyan rebels to engage the Libyan Coast Guard vessel \"Vittoria\" in the port of Misrata, Libya, during the late evening of 28 March 2011. \"Vittoria\" was engaged and fired upon by a USN P-3C Maritime Patrol aircraft with AGM-65 Maverick missiles.\n\nLAU-117 Maverick launchers have been used on USN, USAF, and USMC aircraft:\n\nThe Maverick has been exported to at least 30 countries:\n\n\n", "id": "3151", "title": "AGM-65 Maverick"}
{"url": "https://en.wikipedia.org/wiki?curid=3152", "text": "AIM-54 Phoenix\n\nThe AIM-54 Phoenix is a radar-guided, long-range air-to-air missile (AAM), carried in clusters of up to six missiles on the Grumman F-14 Tomcat, its only operational launch platform. The Phoenix was the United States' only long-range air-to-air missile. The combination of Phoenix missile and the AN/AWG-9 guidance radar was the first aerial weapons system that could simultaneously engage multiple targets. Both the missile and the aircraft were used by the United States Navy and are now retired, the AIM-54 Phoenix in 2004 and the F-14 in 2006. They were replaced by the shorter-range AIM-120 AMRAAM, employed on the F/A-18 Hornet and F/A-18E/F Super Hornet. Following the retirement of the F-14 by the U.S. Navy, the weapon's only current operator is the Islamic Republic of Iran Air Force. Brevity code \"Fox Three\" was used when firing the AIM-54.\n\nSince 1951, the Navy faced the initial threat from the Tupolev Tu-4K 'Bull' carrying anti-ship missiles. Eventually, during the height of the Cold War, the threat would have expanded into regimental-size raids of Tu-16 Badger and Tu-22M Backfire bombers equipped with low-flying, long-range, high-speed, nuclear-armed cruise missiles and considerable electronic countermeasures (ECM) of various types.\n\nThe Navy would require a long-range, long-endurance interceptor aircraft to defend carrier battle groups against this threat. The proposed F6D Missileer was intended to fulfill this mission and oppose the attack far from the fleet it was defending. The weapon needed for interceptor aircraft, the Bendix AAM-N-10 Eagle, was to be an air-to-air missile of unprecedented range when compared to contemporary AIM-7 Sparrow missiles. It would work together with Westinghouse AN/APQ-81 radar. The Missileer project was cancelled in December 1960.\n\nIn the early 1960s, the U.S. Navy made the next interceptor attempt with the F-111B, and they needed a new missile design. At the same time, the USAF canceled the projects for their land-based high-speed interceptor aircraft, the North American XF-108 Rapier and the Lockheed YF-12, and left the capable AIM-47 Falcon missile at a quite advanced stage of development, but with no effective launch platform.\n\nThe AIM-54 Phoenix, developed for the F-111B fleet air defense fighter, had an airframe with four cruciform fins that was a scaled-up version of the AIM-47. One characteristic of the Missileer ancestry was that the radar sent it mid-course corrections, which allowed the fire control system to \"loft\" the missile up over the target into thinner air where it had better range.\n\nThe F-111B was canceled in 1968. Its weapons system, the AIM-54 working with the AWG-9 radar, migrated to the new U.S. Navy fighter project, the VFX, which would later become the F-14 Tomcat.\n\nIn 1977, development of a significantly improved Phoenix version, the AIM-54C, was developed to better counter projected threats from tactical anti-naval aircraft and cruise missiles, and its final upgrade included a re-programmable memory capability to keep pace with emerging ECM.\n\nThe AIM-54/AWG-9 combination had multiple track capability (up to 24 targets) and launch (up to 6 Phoenixes can be launched nearly simultaneously); the large missile is equipped with a conventional warhead.\n\nOn the F-14, four missiles can be carried under the fuselage tunnel attached to special aerodynamic pallets, plus two under glove stations. A full load of 6 Phoenix missiles and the unique launch rails weighs in at over , about twice the weight of Sparrows, so it was more common to carry a mixed load of 4 Phoenix, 2 Sparrow, and 2 Sidewinder missiles.\n\nMost other US aircraft relied on the smaller, semi-active medium-range AIM-7 Sparrow. Semi-active guidance meant the aircraft no longer had a search capability while supporting the launched Sparrow, reducing situational awareness.\n\nThe Tomcat's radar could track up to 24 targets in track-while-scan mode, with the AWG-9 selecting up to 6 potential targets for the missiles. The pilot or radar intercept officer (RIO) could then launch the Phoenix missiles once parameters were met. The large tactical information display (TID) in the RIO's cockpit gave information to the aircrew (the pilot had the ability to monitor the RIO's display) and the radar could continually search and track multiple targets after Phoenix missiles were launched, thereby maintaining situational awareness of the battlespace.\n\nThe Link-4 datalink allowed US Navy Tomcats to share information with the E-2C Hawkeye AEW aircraft. During Desert Shield in 1990, the Link-4A was introduced; this allowed the Tomcats to have a fighter-to-fighter datalink capability, further enhancing overall situational awareness. The F-14D entered service with the JTIDS that brought the even better Link-16 datalink \"picture\" to the cockpit.\n\nThe Phoenix has several guidance modes and achieves its longest range by using mid-course updates from the F-14A/B AWG-9 radar (APG-71 radar in the F-14D) as it climbs to cruise between and at close to Mach 5. Phoenix uses this high altitude to gain gravitational potential energy, which is later converted into kinetic energy as the missile dives at high velocity towards its target. At around from the target, the missile activates its own radar to provide terminal guidance. Minimum engagement range for the Phoenix is around and active homing would initiate upon launch.\n\n\nThe AIM-54 Phoenix was retired from USN service on September 30, 2004. F-14 Tomcats were retired on September 22, 2006. They were replaced by shorter-range AIM-120 AMRAAMs, employed on the F/A-18E/F Super Hornet.\n\nDespite the much-vaunted capabilities, the Phoenix was rarely used in combat, with only two confirmed launches and no confirmed targets destroyed in US Navy service, though a large number of kills were claimed by Iranian F-14s during the Iran–Iraq War. The USAF F-15 Eagle had responsibility for overland combat air patrol duties in Operation Desert Storm in 1991, primarily because of the onboard F-15 IFF capabilities. The Tomcat did not have the requisite IFF capability mandated by the JFACC to satisfy the rules of engagement to utilize the Phoenix capability at beyond visual range. The AIM-54 was not adopted by any foreign nation besides Iran, or any other US armed service, and was not used on any aircraft other than the F-14.\n\nThere is very little information available regarding Iran's use of its 79 F-14A Tomcats (delivered prior to 1979) in most western outlets. The exception is a book released by Osprey Publishing titled \"Iranian F-14 Tomcats in Combat\" by Tom Cooper and Farzad Bishop. Most of the research contained in the book was based on pilot interviews. Reports vary on the use of the 285 missiles supplied to Iran, during the Iran–Iraq War, 1980–88.\n\nAccording to Cooper, the Islamic Republic of Iran Air Force kept its F-14 fighters and AIM-54 missiles in regular use during the entire Iran–Iraq War, though periodic lack of spares grounded large parts of the fleet at times. During late 1987, the stock of AIM-54 missiles was at its lowest, with fewer than 50 operational missiles available. The missiles needed fresh thermal batteries that could only be purchased from the US. Iran found a clandestine buyer that supplied it with batteries—which cost up to US$10,000 each. Iran received spares and parts for both the F-14s and AIM-54s from various sources during the Iran–Iraq War, and has received more spares after the conflict. Iran started a program to build spares for the planes and missiles, and although there are claims that it no longer relies on outside sources to keep its F-14s and AIM-54s operational, there is evidence that Iran continues to procure parts clandestinely.\n\nBoth the F-14 Tomcat and AIM-54 Phoenix missile continue in the service of the Islamic Republic of Iran Air Force. The operational abilities of these aircraft and missiles are questionable, since the US refused to supply spare parts and maintenance after the 1979 revolution, except for a brief period during the Iran-Contra Affair.\n\nIran claimed to be working on building an equivalent missile and in 2013 unveiled the Fakour-90, an upgraded and reverse-engineered version of the Phoenix.\n\n\nThere were also test, evaluation, ground training, and captive air training versions of the missile; designated ATM-54, AEM-54, DATM-54A, and CATM-54. The flight versions had A and C versions. The DATM-54 was not made in a C version as there was no change in the ground handling characteristics.\n\n\n\n\nThe following is a list of AIM-54 Phoenix specifications:\n\n", "id": "3152", "title": "AIM-54 Phoenix"}
{"url": "https://en.wikipedia.org/wiki?curid=3155", "text": "Lockheed AC-130\n\nThe Lockheed AC-130 gunship is a heavily armed, long-endurance ground-attack variant of the C-130 Hercules transport fixed-wing aircraft. It carries a wide array of anti-ground oriented weapons that are integrated with sophisticated sensors, navigation, and fire-control systems. Unlike other military fixed-wing aircraft, the AC-130 relies on visual targeting. Because its large profile and low operating altitudes (around 7,000 ft) make it an easy target, it usually flies close air support missions at night.\n\nThe airframe is manufactured by Lockheed Martin, while Boeing is responsible for the conversion into a gunship and for aircraft support. Developed during the Vietnam War as 'Project Gunship II', the AC-130 replaced the Douglas AC-47 Spooky, or 'Gunship I'. The sole operator is the United States Air Force, which uses the AC-130U Spooky and AC-130W Stinger II variants for close air support, air interdiction, and force protection, with the AC-130J Ghostrider in development. Close air support roles include supporting ground troops, escorting convoys, and urban operations. Air interdiction missions are conducted against planned targets and targets of opportunity. Force protection missions include defending air bases and other facilities. AC-130Us are based at Hurlburt Field, Florida, while AC-130Ws are based at Cannon AFB, New Mexico; gunships can be deployed worldwide. The squadrons are part of the Air Force Special Operations Command (AFSOC), a component of the United States Special Operations Command (SOCOM).\n\nThe AC-130 has an unpressurized cabin, with the weaponry mounted to fire from the port side of the fuselage. During an attack, the gunship performs a pylon turn, flying in a large circle around the target, therefore being able to fire at it for far longer than in a conventional strafing attack. The AC-130H Spectre was armed with two M61 Vulcan cannons, one Bofors 40 mm cannon, and one M102 howitzer; after 1994, the cannons were removed. The upgraded AC-130U Spooky has a single GAU-12 Equalizer cannon in place of the Spectre's two cannons, an improved fire control system, and increased ammunition capacity. New AC-130Js based on the MC-130J Combat Shadow II special operations tanker were planned . The AC-130W is armed with one 30 mm Bushmaster cannon, AGM-176 Griffin missiles, and GBU-39 Small Diameter Bombs (SDBs).\n\nDuring the Vietnam War, the C-130 Hercules was selected to replace the Douglas AC-47 Spooky gunship (Project Gunship I) in order to improve mission endurance and increase capacity to carry munitions. Capable of flying faster than helicopters and at high altitudes with excellent loiter time, the use of the pylon turn allowed the AC-47 to deliver continuous accurate fire to a single point on the ground.\nIn 1967, JC-130A 54-1626 was selected for conversion into the prototype AC-130A gunship (Project Gunship II). The modifications were done at Wright-Patterson Air Force Base by the Aeronautical Systems Division. A direct view night vision telescope was installed in the forward door, an early forward looking infrared device in the forward part of the left wheel well, and Gatling guns fixed facing down and aft along the left side. The analog fire control computer prototype was handcrafted by RAF Wing Commander Tom Pinkerton at the USAF Avionics Laboratory at Wright-Patterson AFB. Flight testing of the prototype was performed primarily at Eglin Air Force Base, followed by further testing and modifications. By September 1967, the aircraft was certified ready for combat testing and was flown to Nha Trang Air Base, South Vietnam for a 90-day test program. The AC-130 was later supplemented by the AC-119 Shadow (Project Gunship III), which later proved to be underpowered.\n\nSeven more warplanes were converted to the \"Plain Jane\" configuration like the AC-130 prototype in 1968, and one aircraft received the \"Surprise Package\" refit in 1969. The Surprise Package upgrade included the latest 20 mm rotary cannons and 40 mm Bofors cannon but no 7.62 mm close support armament. The Surprise Package configuration served as a test bed for the avionic systems and armament for the AC-130E.\n\nIn 1970, ten more AC-130As were acquired under the \"Pave Pronto\" project. In the summer of 1971, Surprise Package AC-130s were converted to the Pave Pronto configuration and assumed the new nickname of 'Thor'. Conversion of C-130Es into AC-130Es for the \"PAVE Spectre\" project followed.\n\nRegardless of their project names the aircraft were more commonly referred to by the squadron's call sign 'Spectre'.\n\nIn 2007, Air Force Special Operations Command (AFSOC) initiated a program to upgrade the armament of AC-130s. The test program planned for the 25 mm GAU-12/U and 40 mm Bofors cannon on the AC-130U gunships to be replaced with two 30 mm Mk 44 Bushmaster II cannons. In 2007, the Air Force modified four AC-130U gunships as test platforms for the Bushmasters. These were referred to as AC-130U Plus 4 or AC-130U+4. AFSOC, however, canceled its plans to install the new cannons on its fleet of AC-130Us. It has since removed the guns and re-installed the original 40 mm and 25 mm cannons and returned the planes to combat duty. Brigadier General Bradley A. Heithold, AFSOC's director of plans, programs, requirements, and assessments, said on 11 August 2008 that the effort was canceled because of problems with the Bushmaster's accuracy in tests \"at the altitude we were employing it\". There were also schedule considerations that drove the decision, he said.\n\nThere were also plans to possibly replace the 105 mm cannon with a breech-loading 120 mm M120 mortar, and to give the AC-130 a standoff capability using either the AGM-114 Hellfire missile, the Advanced Precision Kill Weapon System (based on the Hydra 70 rocket), or the Viper Strike glide bomb.\n\nIn 2010, the Air Force awarded L-3 Communications a $61 million contract to add precision strike packages to eight MC-130W Combat Spear special-mission aircraft to give them a gunship-like attack capability; such-equipped MC-130Ws are known as \"Dragon Spears\". Air Force Special Operations Command is arming these aircraft to relieve the high operational demands on AC-130 gunships until new AC-130Js enter service. The MC-130W Dragon Spear was renamed the AC-130W Stinger II in 2011. The precision strike packages consist of a 30 mm gun and several precision guided munitions (PGMs). Rails are mounted on the out-board pylon of the wing for four Hellfire missiles, SDBs, or SDB IIs under each. 10 Common Launch Tubes (CLTs) are mounted on the rear ramp to fire Griffin A missiles; additional missiles are stored in the aircraft that can be reloaded in flight. CLTs are able to fire other small munitions able to fit inside the -diameter, -long tubes.\n\nThe Air Force launched an initiative in 2011 to acquire 16 new gunships based on new-built MC-130J Combat Shadow II special operations tankers outfitted with a \"precision strike package\" to give them an attack capability, requesting $1.6 billion from Fiscal Years 2011 through 2015. This would increase the size of the gunship fleet to 33 aircraft, a net increase of eight after the planned retirement of eight aging AC-130Hs. The first aircraft would be bought in Fiscal 2012, followed by two in Fiscal 2013, five in Fiscal 2014, and the final eight in Fiscal 2015. The decision to retain the C-130 came after funding for 16 C-27Js was removed from the fiscal 2010 budget. The AC-130J will follow the path of the Dragon Spear program. On 9 January 2013, the Air Force began converting the first MC-130J Combat Shadow II into an AC-130J Ghostrider and delivered it to AFSOC on 29 July 2015. The first AC-130J is to enter service in 2017.\n\nThe Air Force decided to add a 105 mm cannon to the AC-130J in addition to the 30 mm cannon and smart bombs, the shells being more accurate and cheaper than dropping SDBs. AFSOC is interested in adding a directed energy weapon to the AC-130J by 2020, similar to the previous Advanced Tactical Laser program. It is to produce a beam of up to 120 kW, or potentially even 180–200 kW, weigh about , defensively destroy anti-aircraft missiles, and offensively engage communications towers, boats, cars, and aircraft. However, laser armament may only be installed on a few aircraft rather than the entire AC-130J fleet; the laser will be mounted on the side in place of the 30 mm cannon. Other potential additions include an active denial system to perform airborne crowd control, and small unmanned aerial vehicles from the common launch tubes to provide remote video feed and coordinates to weapons operators through cloud cover. Called the Tactical Off-board Sensor (TOBS), the drones would be expendable and fly along a pre-programed orbit to verify targets the aircraft can't see itself because of bad weather or standing off from air defenses. AFSOC will initially utilize the Raytheon Coyote small UAV for the TOBS mission, as it is an off-the-shelf design with a one-hour endurance, but plans to fulfill the role with a new drone capable of a four-hour endurance by 2019.\n\nThe Air Force is also interested in acquiring a glide bomb that can be launched from the common launch tubes capable of hitting ground vehicles traveling as fast as 120 km/h (70 mph) while above . In June 2016, Dynetics was awarded a contract by SOCOM to integrate its tactical munition onto the AC-130. Designated the GBU-69/B Small Glide Munition, the weapon weighs and is armed with a blast-fragmentation warhead that can detonate by direct impact or at a pre-selected height; despite being smaller, being unpowered allows more volume for its warhead to be heavier than those on the Hellfire and Griffin A missiles, and respectively. Guidance is provided by a GPS receiver with anti-spoofing software and four Distributed Aperture Semi-Active Laser Seeker (DASALS) apertures adapted from the WGU-59/B APKWS for terminal guidance. Fielding is planned in 2017.\n\nBy 2018, AC-130 gunships will have been providing close air support for special operators for 50 years. Although the aircraft have been kept relevant through constant upgrades to their weaponry, sensor packages, and countermeasures, they are not expected to be survivable in future non-permissive environments due to their high signatures and low airspeeds. Military analysts, such as the Center for Strategic and Budgetary Assessments, have suggested that AFSOC invest in more advanced technologies to fill the role to operate in future contested combat zones, including a mix of low-cost disposable unmanned and stealthy strike aircraft.\n\nThe AC-130 is a heavily armed long-endurance aircraft carrying an array of anti-ground oriented weapons that are integrated with sophisticated sensors, navigation, and fire-control systems. It is capable of delivering precision firepower or area-saturation fire over a target area over a long period of time, at night or in adverse weather. The sensor suite consists of a television sensor, infrared sensor, and radar. These sensors allow the gunship to visually or electronically identify friendly ground forces and targets in most weather conditions.\n\nThe AC-130U is equipped with the AN/APQ-180, a synthetic aperture radar for long-range target detection and identification. The gunship's navigational devices include inertial navigation systems and a Global Positioning System. The AC-130U employs technologies developed in the 1990s which allow it to attack two targets simultaneously. It has twice the munitions capacity of the AC-130H. Although the AC-130U conducts some operations in daylight, most of its combat missions are conducted at night. The AC-130H's unit cost is US$132.4 million, and the AC-130U's cost is US$190 million (fiscal 2001 dollars).\n\nDuring the Vietnam era, the various AC-130 versions following the Pave Pronto modifications were equipped with a magnetic anomaly detector system called Black Crow (designated AN/ASD-5), a highly sensitive passive device with a phased-array antenna located in the left-front nose radome that could pick up localized deviations in the Earth's magnetic field normally used to detect submerged submarines. The Black Crow system was slaved into the targeting computers of the AC-130A/E/H, enabling the detection of the unshielded ignition coils of North Vietnamese trucks hidden under dense jungle foliage along the Ho Chi Minh trail. It could also detect hand-held transmitter signals of air controllers on the ground to identify and locate targets.\n\nThe PGM-38/U enhanced 25 mm high explosive incendiary round was created to expand the AC-130U gunships' mission in standoff range and survivability for its 25 mm GAU-12/U gun. This round is a combination of the existing PGU-25 HEI and a M758 fuze designated as FMU-151/B to meet the MIL-STD-1316. The FMU-151 has an improved arming delay with multi-sensitive range.\n\nThe AC-130 gunship first arrived in South Vietnam on 21 September 1967 under the Gunship II program and began combat operations over Laos and South Vietnam that year. In June 1968, AC-130s were deployed to Tan Son Nhut AB near Saigon for support against the Tet Offensive. By 30 October 1968, enough AC-130 Gunship IIs arrived to form a squadron, the 16th Special Operations Squadron (SOS) of the 8th Tactical Fighter Wing (TFW), at Ubon Royal Thai Air Force Base, Thailand. It was at this time that the C-130A gunship was designated the AC-130A.\n\nOn 18 August 1968, an AC-130 gunship flying an armed reconnaissance mission in Vietnam's III Corps was diverted to support the Katum Special Forces Camp. The ground commander quickly assessed the accurate fire and capabilities of this weapon system and called for fire on his own perimeter when the Viet Cong attempted to bridge the wire on the west side of his position.\n\nBy December 1968, most AC-130s flew under F-4 Phantom II escort (to protect the gunship against heavy and concentrated AAA fire) from the 497th Tactical Fighter Squadron, normally three Phantoms per Gunship. On 24 May 1969, the first Spectre gunship was lost to enemy fire.\n\nIn late 1969, under code name \"Surprise Package\", 56-0490 arrived with solid-state laser-illuminated low-light-level-TV with a companion YAG laser designator, an improved forward looking infrared (FLIR) sensor, video recording for TV and FLIR, an inertial navigation system, and a prototype digital fire control computer. The remaining AC-130s were refitted with upgraded similar equipment in the summer of 1970, and then redeployed to Ubon RTAFB. On 25 October 1971, the first \"Cadillac\" gunship, the AC-130E arrived in Vietnam. On 17 February 1972, the first 105 mm cannon arrived for service with Spectre and was installed on Gunship 570. It was used from mid-February until the aircraft received battle damage to its right flap. The cannon was switched to Gunship 571 and was used until 30 March when the aircraft was shot down.\n\nOn 28 January 1973, the Vietnam peace accord went into effect, marking the end of Spectre operations in Vietnam. Spectre was still needed and active in the region, supporting operations in Laos and Cambodia. On 22 February 1973, American offensive operations in Laos ended and the gunships became totally committed to operations in the Cambodian conflict.\n\nOn 12 April 1975, the Khmer Rouge were threatening the capital of Phnom Penh and AC-130s were called on to help in Operation Eagle Pull, the final evacuation of American and allied officials from Phnom Penh before it fell to the communists. The AC-130 was also over Saigon on 30 April 1975 to protect the final evacuation in Operation Frequent Wind. Spectres were also called in when the SS Mayaguez was seized, on the open sea, by Khmer Rouge soldiers and sailors on 15 May 1975.\n\nSix AC-130s and 52 air crew members were lost during the war. AC-130s destroyed more than 10,000 trucks and participated in many crucial close air support missions in Vietnam.\n\nWith the conclusion of hostilities in Southeast Asia in the mid-1970s, the AC-130H became the sole gunship in the regular Air Force, home based at Hurlburt Field, Florida, while the AC-130A fleet was transferred to the Air Force Reserve's 919th Tactical Airlift Group (919 TAG) at Eglin AFB Auxiliary Field #3/Duke Field, Florida. With the transition to the AC-130A, the 919 TAG was then redesignated as the 919th Special Operations Group (919 SOG).\n\nIn the late 1970s, when the AC-130H fleet was first being modified for in-flight refueling capability, a demonstration mission was planned and flown from Hurlburt Field, Florida, non-stop, to conduct a 2-hour live-fire mission over Empire Firing Range in the Republic of Panama, then return home. This 13-hour mission with two in-flight refuelings from KC-135 tankers proved the validity of flying long-range missions outside the contiguous United States to attack targets then return to home base without intermediate stops.\n\nAC-130s from both the 4th and 16th Special Operations Squadrons have been deployed in nearly every conflict the United States has been involved in, officially and unofficially, since the end of the Vietnam War.\n\nIn July 1979, AC-130H crews deployed to Howard Air Force Base, Panama, as a precaution against possible hostile actions against American personnel during the Nicaraguan Revolution. New time aloft and non-stop distance records were subsequently set by a 16th SOS 2-ship AC-130H formation flight that departed Hurlburt Field on 13 November 1979 and landed on 15 November at Andersen Air Force Base, Guam, a distance of and 29 hours 43 minutes non-stop, refueling four times in-flight. Refueling support for the Guam deployment was provided by KC-135 crews from the 305th Air Refueling Wing from Grissom AFB, Indiana.\n\nIn November 1979, four AC-130H gunships flew nonstop from Hurlburt Field to Anderson AFB, Guam, because of the hostage situation at the Embassy in Iran. At Guam, AC-130H crews developed communications-out/lights-out refueling procedures for later employment by trial-and-error. This deployment with the 1 SOW/CC as Task Force commander was directed from the office of the CJCS for fear that Iranian militants could begin executing American Embassy personnel who had been taken hostage on 4 November. One early option considered AC-130H retaliatory punitive strikes deep within Iran. Later gunship flights exceeded the 1979 Hurlburt-to-Guam flight. Upon return in March 1980, the four planes soon found themselves in Egypt to support the ill-fated hostage rescue attempt.\nDuring Operation Urgent Fury in Grenada in 1983, AC-130s suppressed enemy air defense systems and attacked ground forces enabling the assault of the Point Salines Airfield via airdrop and air-land of friendly forces. The AC-130 aircrew earned the Lieutenant General William H. Tunner Award for the mission.\n\nThe AC-130Hs of the 16th Special Operations Squadron unit maintained an ongoing rotation to Howard AB, Panama, monitoring activities in El Salvador and other Central American points of interest, with rules of engagement eventually permitting attacks on FMLN targets. This commitment of Maintainers and crews started in 1983 and lasted until 1990. The AC-130 is considered to have hastened the end of the Salvadoran Civil War in the 1980s. Crews flew undercover missions from Honduras and attacked guerrilla camps and concentrations.\n\nAC-130s also had a primary role during the United States invasion of Panama (named Operation Just Cause) in 1989, when they destroyed Panama Defense Force headquarters and numerous command-and-control facilities, and provided close air support for US ground troops. Aircrews earned the Mackay Trophy for the most meritorious flight of the year, and the Tunner Award.\n\nDuring the Gulf War of 1990–91 (Operations Desert Shield and Desert Storm), Regular Air Force and Air Force Reserve AC-130s provided close air support and force protection (air base defense) for ground forces, and battlefield interdiction. The primary interdiction targets were early warning/ground control intercept (EW/GCI) sites along the southern border of Iraq. At its standard altitude of 12,000 feet, the aircraft had a proven ability to engage moving ground targets. The first gunship to enter the Battle of Khafji helped stop a southbound Iraqi armored column on 29 January 1991. One day later, three more gunships provided further aid to Marines participating in the operation. The gunships attacked Iraqi positions and columns moving south to reinforce their positions north of the city.\n\nDespite the threat of surface-to-air missiles (SAMs) and increasing visibility during the early morning hours of 31 January 1991, one AC-130H, AF Serial No. 69-6567, call-sign Spirit 03, opted to stay to continue to protect the Marines. A lone Iraqi with a Strela-2 MANPADS shot Spirit 03 down, and all 14 crew members died.\n\nThe military has used AC-130 gunships during the humanitarian operations in Somalia (Operation Restore Hope and Operation United Shield) in 1992–93, Operation Uphold Democracy in Haiti in 1994. AC-130s took part in Operation Assured Response in Liberia in 1996 and in Operation Silver Wake in 1997, the evacuation of American non-combatants from Albania.\n\nAC-130s took part in the NATO missions in Bosnia and Herzegovina and Kosovo during the 1990s.\n\nThe AC-130U gunship set a new record for the longest sustained flight by any C-130 on 22 and 23 October 1997, when two AC-130U gunships flew 36 hours nonstop from Hurlburt Field, Florida to Taegu Air Base (Daegu), South Korea, being refueled seven times in the air by KC-135 tankers. The two gunships took on 410,000 lb (186,000 kg) of fuel. Gunships also were part of the buildup of U.S. forces in 1998 to compel Iraq to allow UNSCOM weapons inspections.\n\nThe U.S. has used gunships with deployments to the War in Afghanistan (Operation Enduring Freedom - Afghanistan) (2001–2014), and Iraq War (Operation Iraqi Freedom) (2003–11).\n\nAC-130 strikes were directed by special forces on known Taliban locations during the early days of the war in Afghanistan. U.S. Special Operations Forces are using the AC-130 to support its operations. The day after arriving in Afghanistan, the AC-130s attacked Taliban and Al-Qaeda forces near the city of Konduz and were directly responsible for the city's surrender the next day. On 26 November 2001, Spectres were called in to put down a rebellion at the prison fort of Qala-I-Janghi. The 16 SOS flew missions over Mazar-i-Sharif, Kunduz, Kandahar, Shkin, Asadabad, Bagram, Baghran, Tora Bora, and virtually every other part of Afghanistan. The Spectre participated in countless operations within Afghanistan, performing on-call close air support and armed reconnaissance. In March 2002, three AC-130 Spectres provided 39 crucial combat missions in support of Operation Anaconda in Afghanistan. During the intense fighting, the planes expended more than 1,300 40 mm and 1,200 105 mm rounds.\n\nClose air support was the main mission of the AC-130 in Iraq. Night after night, at least one AC-130 was in the air to fulfill one or more air support requests (ASRs). A typical mission had the AC–130 supporting a single brigade’s ASRs followed by aerial refueling and another 2 hours with another brigade or SOF team. The use of AC-130s in places like Fallujah, urban settings where insurgents were among crowded populations of non-combatants, was criticized by human rights groups. AC-130s were also used for intelligence gathering with their sophisticated long-range video, infrared and radar sensors.\n\nIn 2007, US Special Operations forces also used the AC-130 in attacks on suspected Al-Qaeda militants in Somalia.\n\nThere were eight AC-130H and seventeen AC-130U aircraft in active-duty service as of July 2010.\n\nIn March 2011, the U.S. Air Force deployed two AC-130U gunships to take part in Operation Odyssey Dawn, the U.S. military intervention in Libya, which eventually came under NATO as Operation Unified Protector.\nBy September 2013, 14 MC-130W Dragon Spear aircraft have been converted to AC-130W Stinger II gunships. The Stinger gunships have been deployed to Afghanistan to replace the aging AC-130H aircraft and provide an example for the new AC-130J Ghostrider. Modifications began with crews cutting holes in the plane to make room for weapons, and adding kits and bomb bases for laser-guided munitions. Crews added a 105 mm cannon, 20-inch infrared and electro-optical sensors, and the ability to carry 250-pound bombs on the wings.\n\nOn 15 November 2015, two days after the attacks in Paris by ISIL, AC-130s and A-10 Thunderbolt II attack aircraft destroyed a convoy of over 100 ISIL-operated oil tanker trucks in Syria. The attacks were part of an intensification of the U.S.-led Military intervention against ISIL called Operation Tidal Wave II (named after the original Operation Tidal Wave during World War II, a failed attempt to raid German oil fields that resulted in heavy aircraft and aircrew loss) in an attempt to cut off oil smuggling as a source of funding for the group.\n\nThe U.S. has continued to use the aircraft in the War in Afghanistan (2015–present). On 3 October 2015, five attacks on a Doctors Without Borders hospital in Kunduz, Afghanistan were carried out by an AC-130.\n\n\nUnited States Air Force\n\n\n\n\n\n\n\n\nOne of the first seven AC-130A aircraft deployed to Vietnam was AF serial no. 53-3129, named \"First Lady\" in November 1970. This aircraft was a conversion of the first production C-130. On 25 March 1971, it took an anti-aircraft artillery hit in the belly just aft of the nose gear wheel well over the Ho Chi Minh trail in Laos. The 37 mm shell destroyed everything below the crew deck and barely missed striking two crew members. The pilot was able to crash land the aircraft safely. In 1975, after the conclusion of US involvement in the Vietnam war, it was transferred to the Air Force Reserve, where it served with the 711th Special Operations Squadron of the 919th Special Operations Wing. In 1980, the aircraft was upgraded from the original three-bladed propellers to the quieter four-bladed propellers and was eventually retired in late 1995. The retirement also marked an end to the Air Force Reserve Command flying the AC-130A. The aircraft now sits on display in the final Air Force Reserve Command configuration with grey paint, black markings, and the four-bladed Hamilton Sunstrand 54H60-91 props at the Air Force Armament Museum at Eglin Air Force Base, Florida, USA.\n\nA second AC-130A, AF serial no. 56-0509, named the \"Ultimate End\", was accepted by the Air Force on 28 February 1957, and modified to the AC-130A configuration on 27 July 1970. The aircraft participated in the Vietnam War and the rescue of the SS Mayaguez. \"Ultimate End\" demonstrated the durability of the C-130 after surviving hits in five places by 37 mm anti-aircraft artillery on 12 December 1970, extensive left wing leading edge damage on 12 April 1971 and a 57 mm round damaging the belly and injuring one crewman on 4 March 1972. \"Ultimate End\" was reassigned to the Air Force Reserve's 919th Special Operations Wing at Eglin AFB Auxiliary Field No.3 / Duke Field on 17 June 1975, where it continued in service until retired in the fall 1994 and transferred to Air Force Special Operations Command's \"Heritage Air Park\" at Hurlburt Field, Florida. While assigned to the 711th Special Operations Squadron, \"Ultimate End\" served in Operations JUST CAUSE in Panama, DESERT STORM in Kuwait and Iraq, and UPHOLD DEMOCRACY in Haiti. After 36 years and seven months of service, 24 years as a gunship, \"Ultimate End\" retired from active service on 1 October 1994. It made its last flight from Duke Field to Hurlburt Field on 20 October 1994. The Spectre Association dedicated \"Ultimate End\" (which served with the 16 SOS in Vietnam) on 4 May 1995. Lt Col Michael Byers, then 16 SOS commander, represented the active-duty gunship force and Clyde Gowdy of the Spectre Association represented all Spectre personnel past and present for the unveiling of a monument at the aircraft and the dedication as a whole.\n\nA third AC-130A, AF serial no. 54-1630, is on display in the Cold War Gallery at the National Museum of the United States Air Force at Wright-Patterson AFB, Ohio. Named \"Azrael\" for the angel of death in Islam who severs the soul from the body, this aircraft figured prominently in the closing hours of Operation Desert Storm. On 26 February 1991, Coalition ground forces were driving the Iraqi Army out of Kuwait. With an Air Force Reserve crew called to active duty, Azrael was sent to the Al Jahra highway (Highway 80) between Kuwait City and Basra, Iraq, to intercept the convoys of tanks, trucks, buses, and cars fleeing the battle. Facing SA-6 and SA-8 surface-to-air missiles and 37 mm and 57 mm radar-guided anti-aircraft artillery the crew attacked and destroyed or disabled most of the convoys. \"Azrael\" was also assigned to the 919th Special Operations Wing and retired to the museum in October 1995.\n\nAnother AC-130A, AF serial no. 54-1626, the original prototype AC-130 named \"Gunship II\" is on display at the outdoor Air Park at the National Museum of the United States Air Force at Wright-Patterson AFB, Ohio. This aircraft served in Southeast Asia from 1967 to 1972, then served in JC-130A test configuration. It was transferred to the National Museum of the United States Air Force in 1976, and converted back to AC-130A configuration in the late 1990s.\n\nAC-130A serial no. 54-1623, c/n 3010, named \"Ghost Rider\" served in Southeast Asia and later conflicts until being retired in 1997 to Dobbins AFB, Georgia. Ghost Rider eventually was transferred and displayed at the Lockheed Museum at Marietta, Georgia.\n\n\n\n\n(Prior to c. 2000)\n(Current Armament)\n\n\n\n\n\n", "id": "3155", "title": "Lockheed AC-130"}
{"url": "https://en.wikipedia.org/wiki?curid=3158", "text": "Alternative\n\nAlternative may refer to:\n\n\n\n\n\n", "id": "3158", "title": "Alternative"}
{"url": "https://en.wikipedia.org/wiki?curid=3160", "text": "Alternative algebra\n\nIn abstract algebra, an alternative algebra is an algebra in which multiplication need not be associative, only alternative. That is, one must have\nfor all \"x\" and \"y\" in the algebra.\n\nEvery associative algebra is obviously alternative, but so too are some strictly non-associative algebras such as the octonions. The sedenions, on the other hand, are not alternative.\n\nAlternative algebras are so named because they are precisely the algebras for which the associator is alternating. The associator is a trilinear map given by\nBy definition a multilinear map is alternating if it vanishes whenever two of its arguments are equal. The left and right alternative identities for an algebra are equivalent to\nBoth of these identities together imply that the associator is totally skew-symmetric. That is,\nfor any permutation σ. It follows that\nfor all \"x\" and \"y\". This is equivalent to the \"flexible identity\"\nThe associator of an alternative algebra is therefore alternating. Conversely, any algebra whose associator is alternating is clearly alternative. By symmetry, any algebra which satisfies any two of:\nis alternative and therefore satisfies all three identities.\n\nAn alternating associator is always totally skew-symmetric. The converse holds so long as the characteristic of the base field is not 2.\n\n\nArtin's theorem states that in an alternative algebra the subalgebra generated by any two elements is associative. Conversely, any algebra for which this is true is clearly alternative. It follows that expressions involving only two variables can be written unambiguously without parentheses in an alternative algebra. A generalization of Artin's theorem states that whenever three elements formula_12 in an alternative algebra associate (i.e., formula_13), the subalgebra generated by those elements is associative.\n\nA corollary of Artin's theorem is that alternative algebras are power-associative, that is, the subalgebra generated by a single element is associative. The converse need not hold: the sedenions are power-associative but not alternative.\n\nThe Moufang identities\nhold in any alternative algebra.\n\nIn a unital alternative algebra, multiplicative inverses are unique whenever they exist. Moreover, for any invertible element formula_17 and all formula_18 one has\nThis is equivalent to saying the associator formula_20 vanishes for all such formula_17 and formula_18. If formula_17 and formula_18 are invertible then formula_25 is also invertible with inverse formula_26. The set of all invertible elements is therefore closed under multiplication and forms a Moufang loop. This \"loop of units\" in an alternative ring or algebra is analogous to the group of units in an associative ring or algebra.\n\nZorn's theorem states that any finite-dimensional non-associative alternative algebra is a generalised octonion algebra.\n\nThe projective plane over any alternative division ring is a Moufang plane.\n\nThe close relationship of alternative algebras and composition algebras was given by Guy Roos in 2008: He shows (page 162) the relation for an algebra \"A\" with unit element \"e\" and an involutive anti-automorphism formula_27 such that \"a\" + \"a\"* and \"aa\"* are on the line spanned by \"e\" for all \"a\" in \"A\". Use the notation \"n\"(\"a\") = \"aa\"*. Then if \"n\" is a non-singular mapping into the field of \"A\", and \"A\" is alternative, then (\"A,n\") is a composition algebra.\n\n\n", "id": "3160", "title": "Alternative algebra"}
{"url": "https://en.wikipedia.org/wiki?curid=3162", "text": "Arbitrage\n\nIn economics and finance, arbitrage (, , ) is the practice of taking advantage of a price difference between two or more markets: striking a combination of matching deals that capitalize upon the imbalance, the profit being the difference between the market prices. When used by academics, an arbitrage is a (imagined, hypothetical, thought experiment) transaction that involves no negative cash flow at any probabilistic or temporal state and a positive cash flow in at least one state; in simple terms, it is the possibility of a risk-free profit after transaction costs. For instance, an arbitrage is present when there is the opportunity to instantaneously buy low and sell high.\n\nIn principle and in academic use, an arbitrage is risk-free; in common use, as in statistical arbitrage, it may refer to \"expected\" profit, though losses may occur, and in practice, there are always risks in arbitrage, some minor (such as fluctuation of prices decreasing profit margins), some major (such as devaluation of a currency or derivative). In academic use, an arbitrage involves taking advantage of differences in price of a \"single\" asset or \"identical\" cash-flows; in common use, it is also used to refer to differences between \"similar\" assets (relative value or convergence trades), as in merger arbitrage.\n\nPeople who engage in arbitrage are called arbitrageurs —such as a bank or brokerage firm. The term is mainly applied to trading in financial instruments, such as bonds, stocks, derivatives, commodities and currencies.\n\n\"Arbitrage\" is a French word and denotes a decision by an arbitrator or arbitration tribunal. (In modern French, \"\"\"\" usually means referee or umpire.) In the sense used here it is first defined in 1704 by Mathieu de la Porte in his treatise \"\" as a consideration of different exchange rates to recognize the most profitable places of issuance and settlement for a bill of exchange (\"\".)\n\nIf the market prices do not allow for profitable arbitrage, the prices are said to constitute an arbitrage equilibrium, or arbitrage-free market. An arbitrage equilibrium is a precondition for a general economic equilibrium. The \"no arbitrage\" assumption is used in quantitative finance to calculate a unique risk neutral price for derivatives.\n\nThis refers to the method of valuing a coupon-bearing financial instrument by discounting its future cash flows by multiple discount rates. By doing so, a more accurate price can be obtained than if the price is calculated with a present-value pricing approach. Arbitrage-free pricing is used for bond valuation and to detect arbitrage opportunities for investors.\n\nFor the purpose of valuing the price of a bond, its cash flows can each be thought of as packets of incremental cash flows with a large packet upon maturity, being the principal. Since the cash flows are dispersed throughout future periods, they must be discounted back to the present. In the present-value approach, the cash flows are discounted with one discount rate to find the price of the bond. In arbitrage-free pricing, multiple discount rates are used.\n\nThe present-value approach assumes that the yield of the bond will stay the same until maturity. This is a simplified model because interest rates may fluctuate in the future, which in turn affects the yield on the bond. The discount rate may be different for each of the cash flows for this reason. Each cash flow can be considered a zero-coupon instrument that pays one payment upon maturity. The discount rates used should be the rates of multiple zero-coupon bonds with maturity dates the same as each cash flow and similar risk as the instrument being valued. By using multiple discount rates, the arbitrage-free price is the sum of the discounted cash flows. Arbitrage-free price refers to the price at which no price arbitrage is possible.\n\nThe ideas of using multiple discount rates obtained from zero-coupon bonds and discount a similar bonds cash flow to find its price is derived from the yield curve. The yield curve is a curve of the yields of the same bond with different maturities. This curve can be used to view trends in market expectations of how interest rates will move in the future. In arbitrage-free pricing of a bond, a yield curve of similar zero-coupon bonds with different maturities is created. If the curve were to be created with Treasury securities of different maturities, they would be stripped of their coupon payments through bootstrapping. This is to transform the bonds into zero-coupon bonds. The yield of these zero-coupon bonds would then be plotted on a diagram with time on the \"x\"-axis and yield on the \"y\"-axis.\n\nSince the yield curve displays market expectations on how yields and interest rates may move, the arbitrage-free pricing approach is more realistic than using only one discount rate. Investors can use this approach to value bonds and find mismatches in prices, resulting in an arbitrage opportunity. If a bond valued with the arbitrage-free pricing approach turns out to be priced higher in the market, an investor could have such an opportunity:\n\nIf the outcome from the valuation were the reversed case, the opposite positions would be taken in the bonds. This arbitrage opportunity comes from the assumption that the prices of bonds with the same properties will converge upon maturity. This can be explained through market efficiency, which states that arbitrage opportunities will eventually be discovered and corrected accordingly. The prices of the bonds in t move closer together to finally become the same at t.\n\nArbitrage is possible when one of three conditions is met:\n\n\nArbitrage is not simply the act of buying a product in one market and selling it in another for a higher price at some later time. The transactions must occur \"simultaneously\" to avoid exposure to market risk, or the risk that prices may change on one market before both transactions are complete. In practical terms, this is generally possible only with securities and financial products that can be traded electronically, and even then, when each leg of the trade is executed the prices in the market may have moved. Missing one of the legs of the trade (and subsequently having to trade it soon after at a worse price) is called 'execution risk' or more specifically 'leg risk'.\n\nIn the simplest example, any good sold in one market should sell for the same price in another. Traders may, for example, find that the price of wheat is lower in agricultural regions than in cities, purchase the good, and transport it to another region to sell at a higher price. This type of price arbitrage is the most common, but this simple example ignores the cost of transport, storage, risk, and other factors. \"True\" arbitrage requires that there be no market risk involved. Where securities are traded on more than one exchange, arbitrage occurs by simultaneously buying in one and selling on the other.\n\nSee rational pricing, particularly arbitrage mechanics, for further discussion.\n\nMathematically it is defined as follows:\n\nwhere formula_2 and formula_3 denotes the portfolio value at time \"t\".\n\n\nArbitrage has the effect of causing prices in different markets to converge. As a result of arbitrage, the currency exchange rates, the price of commodities, and the price of securities in different markets tend to converge. The speed at which they do so is a measure of market efficiency. Arbitrage tends to reduce price discrimination by encouraging people to buy an item where the price is low and resell it where the price is high (as long as the buyers are not prohibited from reselling and the transaction costs of buying, holding and reselling are small relative to the difference in prices in the different markets).\n\nArbitrage moves different currencies toward purchasing power parity. As an example, assume that a car purchased in the United States is cheaper than the same car in Canada. Canadians would buy their cars across the border to exploit the arbitrage condition. At the same time, Americans would buy US cars, transport them across the border, then sell them in Canada. Canadians would have to buy American dollars to buy the cars and Americans would have to sell the Canadian dollars they received in exchange. Both actions would increase demand for US dollars and supply of Canadian dollars. As a result, there would be an appreciation of the US currency. This would make US cars more expensive and Canadian cars less so until their prices were similar. On a larger scale, international arbitrage opportunities in commodities, goods, securities and currencies tend to change exchange rates until the purchasing power is equal.\n\nIn reality, most assets exhibit some difference between countries. These, transaction costs, taxes, and other costs provide an impediment to this kind of arbitrage. Similarly, arbitrage affects the difference in interest rates paid on government bonds issued by the various countries, given the expected depreciation in the currencies relative to each other (see interest rate parity).\n\nArbitrage transactions in modern securities markets involve fairly low day-to-day risks, but can face extremely high risk in rare situations, particularly financial crises, and can lead to bankruptcy. Formally, arbitrage transactions have negative skew – prices can get a small amount closer (but often no closer than 0), while they can get very far apart. The day-to-day risks are generally small because the transactions involve small differences in price, so an execution failure will generally cause a small loss (unless the trade is very big or the price moves rapidly). The rare case risks are extremely high because these small price differences are converted to large profits via leverage (borrowed money), and in the rare event of a large price move, this may yield a large loss.\n\nThe main day-to-day risk is that part of the transaction fails – execution risk. The main rare risks are counterparty risk and liquidity risk – that a counterparty to a large transaction or many transactions fails to pay, or that one is required to post margin and does not have the money to do so.\n\nIn the academic literature, the idea that seemingly very low risk arbitrage trades might not be fully exploited because of these risk factors and other considerations is often referred to as limits to arbitrage.\n\nGenerally it is impossible to close two or three transactions at the same instant; therefore, there is the possibility that when one part of the deal is closed, a quick shift in prices makes it impossible to close the other at a profitable price. However, this is not necessarily the case. Many exchanges and inter-dealer brokers allow multi legged trades (e.g. basis block trades on LIFFE).\n\nCompetition in the marketplace can also create risks during arbitrage transactions. As an example, if one was trying to profit from a price discrepancy between IBM on the NYSE and IBM on the London Stock Exchange, they may purchase a large number of shares on the NYSE and find that they cannot simultaneously sell on the LSE. This leaves the arbitrageur in an unhedged risk position.\n\nIn the 1980s, risk arbitrage was common. In this form of speculation, one trades a security that is clearly undervalued or overvalued, when it is seen that the wrong valuation is about to be corrected by events. The standard example is the stock of a company, undervalued in the stock market, which is about to be the object of a takeover bid; the price of the takeover will more truly reflect the value of the company, giving a large profit to those who bought at the current price—if the merger goes through as predicted. Traditionally, arbitrage transactions in the securities markets involve high speed, high volume and low risk. At some moment a price difference exists, and the problem is to execute two or three balancing transactions while the difference persists (that is, before the other arbitrageurs act). When the transaction involves a delay of weeks or months, as above, it may entail considerable risk if borrowed money is used to magnify the reward through leverage. One way of reducing the risk is through the illegal use of inside information, and in fact risk arbitrage with regard to leveraged buyouts was associated with some of the famous financial scandals of the 1980s such as those involving Michael Milken and Ivan Boesky.\n\nAnother risk occurs if the items being bought and sold are not identical and the arbitrage is conducted under the assumption that the prices of the items are correlated or predictable; this is more narrowly referred to as a convergence trade. In the extreme case this is merger arbitrage, described below. In comparison to the classical quick arbitrage transaction, such an operation can produce disastrous losses.\n\nAs arbitrages generally involve \"future\" movements of cash, they are subject to counterparty risk: if a counterparty fails to fulfill their side of a transaction. This is a serious problem if one has either a single trade or many related trades with a single counterparty, whose failure thus poses a threat, or in the event of a financial crisis when many counterparties fail. This hazard is serious because of the large quantities one must trade in order to make a profit on small price differences.\n\nFor example, if one purchases many risky bonds, then hedges them with CDSes, profiting from the difference between the bond spread and the CDS premium, in a financial crisis the bonds may default \"and\" the CDS writer/seller may itself fail, due to the stress of the crisis, causing the arbitrageur to face steep losses.\n\nArbitrage trades are necessarily synthetic, \"leveraged\" trades, as they involve a short position. If the assets used are not identical (so a price divergence makes the trade temporarily lose money), or the margin treatment is not identical, and the trader is accordingly required to post margin (faces a margin call), the trader may run out of capital (if they run out of cash and cannot borrow more) and be forced to sell these assets at a loss even though the trades may be expected to ultimately make money. In effect, arbitrage traders synthesize a put option on their ability to finance themselves.\n\nPrices may diverge during a financial crisis, often termed a \"flight to quality\"; these are precisely the times when it is hardest for leveraged investors to raise capital (due to overall capital constraints), and thus they will lack capital precisely when they need it most.\n\nAlso known as Geographical arbitrage, this is the simplest form of arbitrage. In spatial arbitrage, an arbitrageur looks for price differences between geographically separate markets. For example, there may be a bond dealer in Virginia offering a bond at 100-12/23 and a dealer in Washington bidding 100-15/23 for the same bond. For whatever reason, the two dealers have not spotted the difference in the prices, but the arbitrageur does. The arbitrageur immediately buys the bond from the Virginia dealer and sells it to the Washington dealer.\n\nAlso called risk arbitrage, merger arbitrage generally consists of buying/holding the stock of a company that is the target of a takeover while shorting the stock of the acquiring company.\n\nUsually the market price of the target company is less than the price offered by the acquiring company.\nThe spread between these two prices depends mainly on the probability and the timing of the takeover being completed as well as the prevailing level of interest rates.\n\nThe bet in a merger arbitrage is that such a spread will eventually be zero, if and when the takeover is completed. The risk is that the deal \"breaks\" and the spread massively widens.\n\nAlso called \"municipal bond relative value arbitrage\", \"municipal arbitrage\", or just \"muni arb\", this hedge fund strategy involves one of two approaches. It should be noted that the term \"arbitrage\" is also used in the context of the Income Tax Regulations governing the investment of proceeds of municipal bonds; these regulations, aimed at the issuers or beneficiaries of tax-exempt municipal bonds, are different and, instead, attempt to remove the issuer's ability to arbitrage between the low tax-exempt rate and a taxable investment rate.\n\nGenerally, managers seek relative value opportunities by being both long and short municipal bonds with a duration-neutral book. The relative value trades may be between different issuers, different bonds issued by the same entity, or capital structure trades referencing the same asset (in the case of revenue bonds). Managers aim to capture the inefficiencies arising from the heavy participation of non-economic investors (i.e., high income \"buy and hold\" investors seeking tax-exempt income) as well as the \"crossover buying\" arising from corporations' or individuals' changing income tax situations (i.e., insurers switching their munis for corporates after a large loss as they can capture a higher after-tax yield by offsetting the taxable corporate income with underwriting losses). There are additional inefficiencies arising from the highly fragmented nature of the municipal bond market which has two million outstanding issues and 50,000 issuers in contrast to the Treasury market which has 400 issues and a single issuer.\n\nSecond, managers construct leveraged portfolios of AAA- or AA-rated tax-exempt municipal bonds with the duration risk hedged by shorting the appropriate ratio of taxable corporate bonds. These corporate equivalents are typically interest rate swaps referencing Libor or SIFMA . The arbitrage manifests itself in the form of a relatively cheap longer maturity municipal bond, which is a municipal bond that yields significantly more than 65% of a corresponding taxable corporate bond. The steeper slope of the municipal yield curve allows participants to collect more after-tax income from the municipal bond portfolio than is spent on the interest rate swap; the carry is greater than the hedge expense. Positive, tax-free carry from muni arb can reach into the double digits. The bet in this municipal bond arbitrage is that, over a longer period of time, two similar instruments—municipal bonds and interest rate swaps—will correlate with each other; they are both very high quality credits, have the same maturity and are denominated in the same currency. Credit risk and duration risk are largely eliminated in this strategy. However, basis risk arises from use of an imperfect hedge, which results in significant, but range-bound principal volatility. The end goal is to limit this principal volatility, eliminating its relevance over time as the high, consistent, tax-free cash flow accumulates. Since the inefficiency is related to government tax policy, and hence is structural in nature, it has not been arbitraged away.\n\nNote, however, that many municipal bonds are callable, and that this imposes substantial additional risks to the strategy.\n\nA convertible bond is a bond that an investor can return to the issuing company in exchange for a predetermined number of shares in the company.\n\nA convertible bond can be thought of as a corporate bond with a stock call option attached to it.\n\nThe price of a convertible bond is sensitive to three major factors:\n\n\nGiven the complexity of the calculations involved and the convoluted structure that a convertible bond can have, an arbitrageur often relies on sophisticated quantitative models in order to identify bonds that are trading cheap versus their theoretical value.\n\nConvertible arbitrage consists of buying a convertible bond and hedging two of the three factors in order to gain exposure to the third factor at a very attractive price.\n\nFor instance an arbitrageur would first buy a convertible bond, then sell fixed income securities or interest rate futures (to hedge the interest rate exposure) and buy some credit protection (to hedge the risk of credit deterioration).\nEventually what he'd be left with is something similar to a call option on the underlying stock, acquired at a very low price.\nHe could then make money either selling some of the more expensive options that are openly traded in the market or delta hedging his exposure to the underlying shares.\n\nA depositary receipt is a security that is offered as a \"tracking stock\" on another foreign market. For instance a Chinese company wishing to raise more money may issue a depository receipt on the New York Stock Exchange, as the amount of capital on the local exchanges is limited. These securities, known as ADRs (American depositary receipt) or GDRs (global depository receipt) depending on where they are issued, are typically considered \"foreign\" and therefore trade at a lower value when first released. Many ADR's are exchangeable into the original security (known as fungibility) and actually have the same value. In this case there is a spread between the perceived value and real value, which can be extracted. Other ADR's that are not exchangeable often have much larger spreads. Since the ADR is trading at a value lower than what it is worth, one can purchase the ADR and expect to make money as its value converges on the original. However, there is a chance that the original stock will fall in value too, so by shorting it one can hedge that risk.\n\nCross-border arbitrage exploits different prices of the same stock in different countries:\n\nExample: Apple is trading on NASDAQ at US$108.84. The stock is also traded on the German electronic exchange, XETRA. If 1 euro costs US$1.11, a cross-border trader could enter a buy order on the XETRA at €98.03 per Apple share and a sell order at €98.07 per share.\n\nSome brokers in Germany do not offer access to the U.S. exchanges. Hence if a German retail investor wants to buy Apple stock, he needs to buy it on the XETRA. The cross-border trader would sell the Apple shares on XETRA to the investor and buy the shares in the same second on NASDAQ. Afterwards, the cross-border trader would need to transfer the shares bought on NASDAQ to the German XETRA exchange, where he is obliged to deliver the stock.\n\nIn most cases, the quotation on the local exchanges is done electronically by high-frequency traders, taking into consideration the home price of the stock and the exchange rate. This kind of high-frequency trading benefits the public as it reduces the cost to the German investor and enables him to buy U.S. shares.\n\nA dual-listed company (DLC) structure involves two companies incorporated in different countries contractually agreeing to operate their businesses as if they were a single enterprise, while retaining their separate legal identity and existing stock exchange listings. In integrated and efficient financial markets, stock prices of the twin pair should move in lockstep. In practice, DLC share prices exhibit large deviations from theoretical parity. Arbitrage positions in DLCs can be set up by obtaining a long position in the relatively underpriced part of the DLC and a short position in the relatively overpriced part. Such arbitrage strategies start paying off as soon as the relative prices of the two DLC stocks converge toward theoretical parity. However, since there is no identifiable date at which DLC prices will converge, arbitrage positions sometimes have to be kept open for considerable periods of time. In the meantime, the price gap might widen. In these situations, arbitrageurs may receive margin calls, after which they would most likely be forced to liquidate part of the position at a highly unfavorable moment and suffer a loss. Arbitrage in DLCs may be profitable, but is also very risky.\n\nA good illustration of the risk of DLC arbitrage is the position in Royal Dutch Shell—which had a DLC structure until 2005—by the hedge fund Long-Term Capital Management (LTCM, see also the discussion below). Lowenstein (2000) describes that LTCM established an arbitrage position in Royal Dutch Shell in the summer of 1997, when Royal Dutch traded at an 8 to 10 percent premium. In total $2.3 billion was invested, half of which long in Shell and the other half short in Royal Dutch (Lowenstein, p. 99). In the autumn of 1998 large defaults on Russian debt created significant losses for the hedge fund and LTCM had to unwind several positions. Lowenstein reports that the premium of Royal Dutch had increased to about 22 percent and LTCM had to close the position and incur a loss. According to Lowenstein (p. 234), LTCM lost $286 million in equity pairs trading and more than half of this loss is accounted for by the Royal Dutch Shell trade.\n\nThe market prices for privately held companies are typically viewed from a return on investment perspective (such as 25%), whilst publicly held and or exchange listed companies trade on a Price to earnings ratio (P/E) (such as a P/E of 10, which equates to a 10% ROI). Thus, if a publicly traded company specialises in the acquisition of privately held companies, from a per-share perspective there is a gain with every acquisition that falls within these guidelines. E.g., Berkshire Hathaway and Halydean Corporation. Private to public equities arbitrage is a term which can arguably be applied to investment banking in general. Private markets to public markets differences may also help explain the overnight windfall gains enjoyed by principals of companies that just did an initial public offering (IPO).\n\nRegulatory arbitrage is where a regulated institution takes advantage of the difference between its real (or economic) risk and the regulatory position. For example, if a bank, operating under the Basel I accord, has to hold 8% capital against default risk, but the real risk of default is lower, it is profitable to securitise the loan, removing the low risk loan from its portfolio. On the other hand, if the real risk is higher than the regulatory risk then it is profitable to make that loan and hold on to it, provided it is priced appropriately. Regulatory arbitrage can result in parts of entire businesses being unregulated as a result of the arbitrage.\n\nThis process can increase the overall riskiness of institutions under a risk insensitive regulatory regime, as described by Alan Greenspan in his October 1998 speech on The Role of Capital in Optimal Banking Supervision and Regulation.\n\nThe term \"Regulatory Arbitrage\" was used for the first time in 2005 when it was applied by Scott V. Simpson, a partner at law firm Skadden, Arps, to refer to a new defence tactic in hostile mergers and acquisitions where differing takeover regimes in deals involving multi-jurisdictions are exploited to the advantage of a target company under threat.\n\nIn economics, regulatory arbitrage (sometimes, tax arbitrage) may be used to refer to situations when a company can choose a nominal place of business with a regulatory, legal or tax regime with lower costs. For example, an insurance company may choose to locate in Bermuda due to preferential tax rates and policies for insurance companies. This can occur particularly where the business transaction has no obvious physical location: in the case of many financial products, it may be unclear \"where\" the transaction occurs.\n\nRegulatory arbitrage can include restructuring a bank by outsourcing services such as IT. The outsourcing company takes over the installations, buying out the bank's assets and charges a periodic service fee back to the bank. This frees up cashflow usable for new lending by the bank. The bank will have higher IT costs, but counts on the multiplier effect of money creation and the interest rate spread to make it a profitable exercise.\n\nExample:\nSuppose the bank sells its IT installations for 40 million USD. With a reserve ratio of 10%, the bank can create 400 million USD in additional loans (there is a time lag, and the bank has to expect to recover the loaned money back into its books). The bank can often lend (and securitize the loan) to the IT services company to cover the acquisition cost of the IT installations. This can be at preferential rates, as the sole client using the IT installation is the bank. If the bank can generate 5% interest margin on the 400 million of new loans, the bank will increase interest revenues by 20 million. The IT services company is free to leverage their balance sheet as aggressively as they and their banker agree to. This is the reason behind the trend towards outsourcing in the financial sector. Without this money creation benefit, it is actually more expensive to outsource the IT operations as the outsourcing adds a layer of management and increases overhead.\n\nAccording to PBS Frontline's 2012 four-part documentary, \"Money, Power, and Wall Street,\" regulatory arbitrage, along with asymmetric bank lobbying in Washington and abroad, allowed investment banks in the pre- and post-2008 period to continue to skirt laws and engage in the risky proprietary trading of opaque derivatives, swaps, and other credit-based instruments invented to circumvent legal restrictions at the expense of clients, government, and publics.\n\nDue to the Affordable Care Act’s expansion of Medicaid coverage, one form of Regulatory Arbitrage can now be found when businesses engage in “Medicaid Migration”, a maneuver by which qualifying employees who would typically be enrolled in company health plans elect to enroll in Medicaid instead. These programs that have similar characteristics as insurance products to the employee, but have radically different cost structures, resulting in significant expense reductions for employers.\n\nTelecom arbitrage companies allow phone users to make international calls for free through certain access numbers. Such services are offered in the United Kingdom; the telecommunication arbitrage companies get paid an interconnect charge by the UK mobile networks and then buy international routes at a lower cost. The calls are seen as free by the UK contract mobile phone customers since they are using up their allocated monthly minutes rather than paying for additional calls.\n\nSuch services were previously offered in the United States by companies such as FuturePhone.com. These services would operate in rural telephone exchanges, primarily in small towns in the state of Iowa. In these areas, the local telephone carriers are allowed to charge a high \"termination fee\" to the caller's carrier in order to fund the cost of providing service to the small and sparsely populated areas that they serve. However, FuturePhone (as well as other similar services) ceased operations upon legal challenges from AT&T and other service providers.\n\nStatistical arbitrage is an imbalance in expected nominal values. A casino has a statistical arbitrage in every game of chance that it offers—referred to as the house advantage, house edge, vigorish or house vigorish.\n\nLong-Term Capital Management (LTCM) lost 4.6 billion U.S. dollars in fixed income arbitrage in September 1998. LTCM had attempted to make money on the price difference between different bonds. For example, it would sell U.S. Treasury securities and buy Italian bond futures. The concept was that because Italian bond futures had a less liquid market, in the short term Italian bond futures would have a higher return than U.S. bonds, but in the long term, the prices would converge. Because the difference was small, a large amount of money had to be borrowed to make the buying and selling profitable.\n\nThe downfall in this system began on August 17, 1998, when Russia defaulted on its ruble debt and domestic dollar debt. Because the markets were already nervous due to the Asian financial crisis, investors began selling non-U.S. treasury debt and buying U.S. treasuries, which were considered a safe investment. As a result, the price on US treasuries began to increase and the return began decreasing because there were many buyers, and the return (yield) on other bonds began to increase because there were many sellers (i.e. the price of those bonds fell). This caused the difference between the prices of U.S. treasuries and other bonds to increase, rather than to decrease as LTCM was expecting. Eventually this caused LTCM to fold, and their creditors had to arrange a bail-out. More controversially, officials of the Federal Reserve assisted in the negotiations that led to this bail-out, on the grounds that so many companies and deals were intertwined with LTCM that if LTCM actually failed, they would as well, causing a collapse in confidence in the economic system. Thus LTCM failed as a fixed income arbitrage fund, although it is unclear what sort of profit was realized by the banks that bailed LTCM out.\n\n\n\n", "id": "3162", "title": "Arbitrage"}
{"url": "https://en.wikipedia.org/wiki?curid=3165", "text": "ACF Fiorentina\n\nACF Fiorentina, commonly referred to as simply Fiorentina , is a professional Italian football club from Florence, Tuscany. Founded by a merger in 1926, and refounded in 2002 following bankruptcy, Fiorentina have played at the top level of Italian football for the majority of their existence; only four clubs have played in more Serie A seasons.\n\nFiorentina has won two Italian Championships, in 1955–56 and again in 1968–69, as well as six Coppa Italia trophies and one Supercoppa Italiana. On the European stage, Fiorentina won the UEFA Cup Winners' Cup in 1960–61 and lost the final one year later. They finished runners-up in the 1956–57 European Cup, losing against Real Madrid, and also came close to winning the 1989–90 UEFA Cup, finishing as runners-up against Juventus after losing the first leg in Turin and drawing in the second one in Avellino.\n\nSince 1931, the club have played at the Stadio Artemio Franchi, which currently has a capacity of 47,282. The stadium has used several names over the years and has undergone several renovations. Fiorentina are known widely by the nickname \"Viola\", a reference to their distinctive purple colours.\n\nAssociazione Calcio Fiorentina was founded in the autumn of 1926 by local noble and National Fascist Party member Luigi Ridolfi, who initiated the merger of two older Florentine clubs, CS Firenze and PG Libertas. The aim of the merger was to give Florence a strong club to rival those of the more dominant Italian Football Championship sides of the time from Northwest Italy. Also influential was the cultural revival and rediscovery of \"Calcio Fiorentino\", an ancestor of modern football that was played by members of the Medici family.\n\nAfter a rough start and three seasons in lower leagues, Fiorentina reached the Serie A in 1931. That same year saw the opening of the new stadium, originally named after Giovanni Berta, after a prominent fascist, but now known as Stadio Artemio Franchi. At the time, the stadium was a masterpiece of engineering, and its inauguration was monumental. To be able to compete with the best teams in Italy, Fiorentina strengthened their team with some new players, notably the Uruguayan Pedro Petrone, nicknamed \"el Artillero\". Despite enjoying a good season and finishing in fourth place, Fiorentina were relegated the following year, although they would return quickly to Serie A. In 1941, they won their first Coppa Italia, but the team were unable to build on their success during the 1940s because of World War II and other troubles.\n\nIn 1950, Fiorentina started to achieve consistent top-five finishes in the domestic league. The team consisted of great players such as well-known goalkeeper Giuliano Sarti, Sergio Cervato, Francesco Rosella, Guido Gratton, Giuseppe Chiappella and Aldo Scaramucci but above all, the attacking duo of Brazilian Julinho and Argentinian Miguel Montuori. This team won Fiorentina's first \"scudetto\" (Italian championship) in 1955–56, 12 points ahead of second-place Milan. Milan beat Fiorentina to top spot the following year, but more significantly Fiorentina became the first Italian team to play in a European Cup final, when a disputed penalty led to a 2–0 defeat at the hands of Alfredo Di Stéfano's Real Madrid.\nFiorentina were runners-up again in the three subsequent seasons. In the 1960–61 season, the club won the Coppa Italia again and was also successful in Europe, winning the first Cup Winners' Cup against Scottish side Rangers.\n\nAfter several years of runner-up finishes, Fiorentina dropped away slightly in the 1960s, bouncing from fourth to sixth place, although the club won the Coppa Italia and the Mitropa Cup in 1966.\n\nWhile the 1960s did result in some trophies and good Serie A finishes for Fiorentina, nobody believed that the club could challenge for the title. The 1968–69 season started with Milan as frontrunners, but on matchday 7, they lost to Bologna and were overtaken by Gigi Riva's Cagliari. Fiorentina, after an unimpressive start, then moved to the top of the Serie A, but the first half of their season finished with a 2–2 draw against Varese, leaving Cagliari as outright league leader. The second half of the season was a three-way battle between the three contending teams, Milan, Cagliari and Fiorentina. Milan fell away, instead focusing their efforts on the European Cup, and it seemed that Cagliari would retain top spot. After Cagliari lost against Juventus, however, Fiorentina took over at the top. The team then won all of their remaining matches, beating rivals Juve in Turin on the penultimate matchday to seal their second, and last, national title. In the European Cup competition the following year, Fiorentina had some good results, including a win in the Soviet Union against Dynamo Kyiv, but they were eventually knocked out in the quarter-finals after a 3–0 defeat in Glasgow to Celtic.\n\n\"Viola\" players began the 1970s decade with \"Scudetto\" sewed on their breast, but the period was not especially fruitful for the team. After a fifth-place finish in 1971, they finished in mid-table almost every year, even flirting with relegation in 1972 and 1978. The \"Viola\" did win the Anglo-Italian League Cup in 1974 and won the Coppa Italia again in 1975. The team consisted of young talents like Vincenzo Guerini and Moreno Roggi, who had the misfortune to suffer bad injuries, and above all Giancarlo Antognoni, who would later become an idol to Fiorentina's fans. The young average age of the players led to the team being called \"Fiorentina Ye-Ye\".\n\nIn 1980, Fiorentina was bought by Flavio Pontello, who came from a rich house-building family. He quickly changed the team's anthem and logo, leading to some complaints by the fans, but he started to bring in high-quality players such as Francesco Graziani and Eraldo Pecci from Torino; Daniel Bertoni from Sevilla; Daniele Massaro from Monza; and a young Pietro Vierchowod from Sampdoria. The team was built around Giancarlo Antognoni, and in 1982, Fiorentina were involved in an exciting duel with rivals Juventus. After a bad injury to Antognoni, the league title was decided on the final day of the season when Fiorentina were denied a goal against Cagliari and were unable to win. Juventus won the title with a disputed penalty and the rivalry between the two teams erupted.\n\nThe following years were strange for Fiorentina, who vacillated between high finishes and relegation battles. Fiorentina also bought two interesting players, \"El Puntero\" Ramón Díaz and, most significantly, the young Roberto Baggio.\n\nIn 1990, Fiorentina fought to avoid relegation right up until the final day of the season, but did reach the UEFA Cup final, where they again faced Juventus. The Turin team won the trophy, but Fiorentina's \"tifosi\" once again had real cause for complaint: the second leg of the final was played in Avellino (Fiorentina's home ground was suspended), a city with many Juventus fans, and emerging star Roberto Baggio was sold to the rival team on the day of the final. Pontello, suffering from economic difficulties, was selling all the players and was forced to leave the club after serious riots in Florence's streets. The club was then acquired by the famous filmmaker Mario Cecchi Gori.\n\nThe first season under Cecchi Gori's ownership was one of stabilisation, after which the new chairman started to sign some good players like Brian Laudrup, Stefan Effenberg, Francesco Baiano and, most importantly, Gabriel Batistuta, who became an iconic player for the team during the 1990s. In 1993, however, Cecchi Gori died and was succeeded as chairman by his son, Vittorio. Despite a good start to the season, Cecchi Gori fired the coach, Luigi Radice, after a defeat against Atalanta, and replaced him with Aldo Agroppi. The results were dreadful: Fiorentina fell into the bottom half of the standings and were relegated on the last day of the season.\n\nClaudio Ranieri was brought in as coach for the 1993–94 season, and that year, Fiorentina dominated Serie B, Italy's second division. Upon their return to Serie A, Ranieri put together a good team centred around new top scorer Batistuta, signing the young talent Rui Costa from Benfica and the new world champion Brazilian defender Márcio Santos. The former became an idol to Fiorentina fans, while the second disappointed and was sold after only a season. The \"Viola\" finished the season in tenth place.\n\nThe following season, Cecchi Gori bought other important players, namely Swedish midfielder Stefan Schwarz. The club again proved its mettle in cup competitions, winning the Coppa Italia against Atalanta and finishing joint-third in Serie A. In the summer, Fiorentina became the first non-national champions to win the Supercoppa Italiana, defeating Milan 2–1 at the San Siro.\n\nFiorentina's 1995–96 season was disappointing in the league, but they did reach the Cup Winners' Cup semi-final by beating Gloria Bistrița, Sparta Prague and Benfica. The team lost the semi-final to the eventual winner of the competition, Barcelona (away 1–1; home 0–2). The season's main signings were Luís Oliveira and Andrei Kanchelskis, the latter of whom suffered from many injuries.\n\nAt the end of the season, Ranieri left Fiorentina for Valencia in Spain, with Cecchi Gori appointing Alberto Malesani as his replacement. Fiorentina played well but struggled against smaller teams, although they did manage to qualify for the UEFA Cup. Malesani left Fiorentina after only a season and was succeeded by Giovanni Trapattoni. With Trapattoni's expert guidance and Batistuta's goals, Fiorentina challenged for the title in 1998–99 but finished the season in third, earning them qualification for the Champions League. The following year was disappointing in Serie A, but \"Viola\" played some historical matches in the Champions League, beating Arsenal 1–0 at the old Wembley Stadium and Manchester United 2–0 in Florence. They were ultimately eliminated in the second group stage.\n\nAt the end of the season, Trapattoni left the club and was replaced by Turkish coach Fatih Terim. More significantly, however, Batistuta was sold to Roma, who eventually won the title the following year. Fiorentina played well in 2000–01 and stayed in the top half of Serie A, despite the resignation of Terim and the arrival of Roberto Mancini. They also won the Coppa Italia for the sixth and last time.\n\nThe year 2001 heralded major changes for Fiorentina, as the terrible state of the club's finances was revealed: they were unable to pay wages and had debts of around US$50 million. but even this soon proved to be insufficient resources to sustain the club. Fiorentina were relegated at the end of the 2001–02 season and went into judicially-controlled administration in June 2002. This form of bankruptcy (sports companies cannot exactly fail in this way in Italy, but they can suffer a similar procedure) meant that the club was refused a place in Serie B for the 2002–03 season, and as a result effectively ceased to exist.\n\nThe club was promptly re-established in August 2002 as Associazione Calcio Fiorentina e Florentia Viola with shoe and leather entrepreneur Diego Della Valle as new owner and the club was admitted into Serie C2, the fourth tier of Italian football. The only player to remain at the club in its new incarnation was Angelo Di Livio, whose commitment to the club's cause further endeared him to the fans. Helped by Di Livio and 30-goal striker Christian Riganò, the club won its Serie C2 group with considerable ease, which would normally have led to a promotion to Serie C1. Due to the bizarre \"Caso Catania\" (Catania Case), however, the club skipped Serie C1 and was admitted into Serie B, something that was only made possible by the Italian Football Federation (FIGC)'s decision to resolve the Catania situation by increasing the number of teams in Serie B from 20 to 24 and promoting Fiorentina for \"sports merits.\" In the 2003 off-season, the club also bought back the right to use the Fiorentina name and the famous shirt design, and re-incorporated itself as ACF Fiorentina. The club finished the 2003–04 season in sixth place and won the playoff against Perugia to return to top-flight football.\nIn their first season back in Serie A, however, the club struggled to avoid relegation, only securing survival on the last day of the season on head-to-head record against Bologna and Parma. In 2005, Della Valle decided to appoint Pantaleo Corvino as new sports director, followed by the appointment of Cesare Prandelli as head coach in the following season. The club made several signings during the summer transfer market, most notably Luca Toni and Sébastien Frey. This drastic move earned them a fourth-place finish with 74 points and a Champions League qualifying round ticket. Toni scored 31 goals in 38 appearances, the first player to pass the 30-goal mark since Antonio Valentin Angelillo in the 1958–59 season, for which he was awarded the European Golden Boot. On 14 July 2006, however, Fiorentina were relegated to Serie B due to their involvement in the 2006 Serie A match fixing scandal and given a 12-point penalty. The team was reinstated to the Serie A on appeal, but with a 19-point penalty for the 2006–07 season. The team's 2006–07 Champions League place was also revoked. After the start of the season, Fiorentina's penalisation was reduced from 19 points to 15 on appeal to the Italian courts. In spite of this penalty, they managed to secure a place in the UEFA Cup.\n\nDespite Toni's departure to Bayern Munich, Fiorentina had a strong start to the 2007–08 season and were tipped by Italian national team head coach Marcello Lippi, among others, as a surprise challenger for the \"Scudetto\", and although this form tailed off towards the middle of the season, the \"Viola\" managed to qualify for the Champions League. In Europe, the club reached the semi-final of the UEFA Cup, where they were ultimately defeated by Rangers on penalties. The 2008–09 season continued this success, a fourth-place finish assuring Fiorentina's spot in 2010's Champions League playoffs. Their European campaign was also similar to that of the previous run, relegated to the 2008–09 UEFA Cup and were eliminated by Ajax in the end.\n\nIn the 2009–10 season, Fiorentina started their domestic campaign strongly before steadily losing momentum and slipped to mid-table positions at the latter half of the season. In Europe, the team proved to be a surprise dark horse: after losing their first away fixture against Lyon, they staged a comeback with a five-match streak by winning all their remaining matches (including defeating Liverpool home and away). The \"Viola\" qualified as group champions, but eventually succumbed to Bayern Munich due to the away goals rule. This was controversial due to a mistaken refereeing decision by Tom Henning Øvrebø, who allowed a clearly offside goal for Bayern in the first leg. Bayern eventually finished the tournament as runners-up, making a deep run all the way to the final. The incident called into attention the possible implementation of video replays in football. Despite a good European run and reaching the semi-finals in the Coppa Italia, Fiorentina failed to qualify for Europe.\n\nDuring this period, on 24 September 2009, Andrea Della Valle resigned from his position as chairman of Fiorentina, and announced all duties would be temporarily transferred to Mario Cognini, Fiorentina's vice-president until a permanent position could be filled.\n\nIn June 2010, the \"Viola\" bid farewell to long-time manager Cesar Prandelli, by then the longest-serving coach in the team's history, who was departing to coach the Italian national team. Catania manager Siniša Mihajlović was appointed to replace him. The club spent much of the early 2010–11 season in last place, but their form improved and Fiorentina ultimately finished ninth. Following a 1–0 defeat to Chievo in November 2011, Mihajlović was sacked and replaced by Delio Rossi. After a brief period of improvements, the \"Viola\" were again fighting relegation, prompting the sacking of Sporting Director Pantaleo Corvino in early 2012 following a 0–5 home defeat to Juventus. Their bid for survival was kept alive by a number of upset victories away from home, notably at Roma and Milan. During a home game against Novara, trailing 0–2 within half an hour, manager Rossi decided to substitute midfielder Adem Ljajić early. Ljajić sarcastically applauded him in frustration, whereupon Rossi retaliated by physical assaulting his player, an action that ultimately prompted his termination by the club. His replacement, caretaker manager Vincenzo Guerini, then guided the team away from the relegation zone to a 13th-place finish to end the turbulent year.\n\nTo engineer a resurrection of the club after the disappointing season, the Della Valle family invested heavily in the middle of 2012, buying 17 new players and appointing Vincenzo Montella as head coach. The team began the season well, finishing the calendar year in joint third place and eventually finishing the 2012–13 season in fourth, enough for a position in the 2013–14 Europa League.\n\nThe club lost fan favourite Stevan Jovetić during the middle of 2013, selling him to English Premier League club Manchester City for a €30 million transfer fee. They also sold Adem Ljajić to Roma and Alessio Cerci to Torino, using the funds to bring in Mario Gómez, Josip Iličić and Ante Rebić, among others. During the season, Fiorentina topped their Europa League group, moving on to the round of 32 to face Danish side Esbjerg fB, which Fiorentina defeated 4–2 on aggregate. In the following round of 16, however, they then lost to Italian rivals Juventus 2–1 on aggregate, ousting them from the competition. At the end of the season, the team finished fourth again in the league, and also finishing they year as Coppa Italia runners-up after losing 3–1 to Napoli in the final.\n\nIn 2014–15, during the 2015 winter transfer window, the team club sold star winger Juan Cuadrado to Chelsea for €30 million but were able to secure the loan of Mohamed Salah in exchange, who was a revelation in the second half of the season. Their 2014–15 Europa League campaign saw them progress to the semi-finals, where they were knocked-out by Spanish side Sevilla, the eventual champions. In the 2014–15 domestic season, Fiorentina once again finished fourth, thus qualifying for the 2015–16 Europa League. In June 2015, Vincenzo Montella was sacked as manager after the club grew impatient with the coaches inability to prove his commitment to the club, later appointing Paulo Sousa on June 21 as the team's new head coach.\n\nFiorentina have had many managers and head coaches throughout their history. Below is a chronological list from the club's foundation in 1926 to the present day.\n\nThe official emblem of the city of Florence, a red fleur-de-lis on a white field, has been pivotal in the all-round symbolism of the club.\n\nOver the course of the club's history, they have had several badge changes, all of which incorporated Florence's fleur-de-lis in some way. The first one was nothing more than the city's coat of arms, a white shield with the red fleur-de-lis inside. It was soon changed to a very stylised fleur-de-lis, always red, and sometimes even without the white field. The most common symbol, adopted for about 20 years, had been a white lozenge with the flower inside. During the season they were Italian champions, the lozenge disappeared and the flower was overlapped with the \"scudetto\".\n\nThe logo introduced by owner Flavio Pontello in 1980 was particularly distinct, consisting of one-half of the city of Florence's emblem and one-half of the letter \"F\", for Fiorentina. People disliked it when it was introduced, believing it was a commercial decision and, above all, because the symbol bore more of a resemblance to a halberd than a fleur-de-lis.\n\nToday's logo is a kite shaped double lozenge bordered in gold. The outer lozenge has a purple background with the letters \"AC\" in white and the letter \"F\" in red, standing for the club's name. The inner lozenge is white with a gold border and the red fleur-de-lis of Florence. This logo had been in use from 1992 to 2002, but after the financial crisis and resurrection of the club the new one couldn't use the same logo. Florence's \"comune\" instead granted Florentia Viola use of the stylised coat of arms used in other city documents. Diego Della Valle acquired the current logo the following year in a judicial auction for a fee of €2.5 million, making it the most expensive logo in Italian football.\n\nWhen Fiorentina was founded in 1926, the players wore red and white halved shirts derived from the colour of the city emblem. The more well-known and highly distinctive purple kit was adopted in 1928 and has been used ever since, giving rise to the nickname \"La Viola\" (\"The Purple (team)\"). Tradition has it that Fiorentina got their purple kit by mistake after an accident washing the old red and white coloured kits in the river.\n\nThe away kit has always been predominantly white, sometimes with purple and red elements, sometimes all-white. The shorts had been purple when the home kit was with white shorts. Fiorentina's third kit was first one in the 1995–96 season and it was all-red with purple borders and two lilies on the shoulders. The red shirt has been the most worn 3rd shirt by Fiorentina, although they also wore rare yellow shirts ('97–'98, '99–'00 and '10–'11) and a sterling version, mostly in the Coppa Italia, in 2000–01.\n\n\n\nSerie A:\n\nSerie B\n\nSerie C2 (as \"Florentia Viola\")\n\nCoppa Italia:\n\nSupercoppa Italiana:\n\nEuropean Cup:\n\nUEFA Cup:\n\nUEFA Cup Winners' Cup:\n\nCoppa Grasshoppers\n\nMitropa Cup\n\nAnglo-Italian League Cup\n\nCopa EuroAmericana\n\nThis is the UEFA club's coefficient as of 6 January 2017:\nA.C. Fiorentina S.p.A. was unable to register for 2002–03 Serie B due to financial difficulties, and then the sports title was transferred to a new company thanks to Article 52 of N.O.I.F., while the old company was liquidated. At that time the club was heavily rely on windfall profit from selling players, especially in pure player swap or cash plus player swap that potentially increase the cost by the increase in amortization of player contracts (an intangible assets). For example, Marco Rossi joined Fiorentina for 17 billion lire in 2000, but at the same time Lorenzo Collacchioni moved to Salernitana for 1 billion lire, making the club had a player profit of 997 million lire and extra 1 billion lire to be amortize in 5-year. In 1999, Emiliano Bigica also swapped with Giuseppe Taglialatela, which the latter was valued for 10 billion lire. The operating income (excluding windfall profit from players trading) of 2000–01 season was minus 113,271,475,933 Italian lire (minus €58,499,835). It was only boosted by the sales of Francesco Toldo, Rui Costa in June 2001 (a profit of 134.883 billion lire; €69.661 million). However, alleged to Parma for a reported 140 million lire. The two players eventually joined Inter Milan and A.C. Milan in 2001–02 financial year instead, for undisclosed fees. Fail to have financial support from the owner Vittorio Cecchi Gori, the club windup due to its huge imbalance in operating income.\n\nSince re-established in 2002, ACF Fiorentina S.p.A. yet to self-sustain to keep the team in top division as well as in European competitions. In the 2005 financial year, which cover the first Serie A season, the club made a net loss of €9,159,356, followed by a net loss of €19,519,789. In 2006 (2005–06 Serie A and 2006–07 Serie A), Fiorentina heavily invested on players, made the amortisation of intangible asset (the player contract) had increased from €17.7 million to €24 million. However the club suffered from 2006 Italian football scandal, meant the club did not qualify for Europe. In 2007 Fiorentina almost break-even, with a net loss of just €3,704,953. In 2007 financial year the TV revenue increased after qualified to 2007–08 UEFA Cup. Despite qualified to 2008–09 UEFA Champions League, Fiorentina made a net loss of €9,179,484 in 2008 financial year after the increase in TV revenue was outweighed by the increase in wage. In the 2009 financial year, Fiorentina made a net profit of €4,442,803, largely due to the profit on selling players (€33,631,489 from players such as Felipe Melo, Giampaolo Pazzini and Zdravko Kuzmanović; increased from about €3.5 million in 2008). However it also offset by the write-down of selling players (€6,062,545, from players such as Manuel da Costa, Arturo Lupoli and Davide Carcuro).\n\nAfter the club failed to qualify to Europe at the end of 2009–10 Serie A, as well as lack of player profit, Fiorentina turnover was decreased from €140,040,713 in 2009 to just €79,854,928, despite wage bill also fell, \"la Viola\" still made a net loss of €9,604,353. In the 2011 financial year, the turnover slipped to €67,076,953, as the club's lack of capital gains from selling players and 2010 financial year still included the installments from UEFA for participating 2009–10 UEFA Europa League. Furthermore, the gate income had dropped from €11,070,385 to €7,541,260. The wage bill did not fall much and in reverse the amortization of transfer fee had sightly increased due to new signing. \"La Viola\" had saving in other cost but counter-weighted by huge €11,747,668 write-down for departed players, due to D'Agostino, Frey and Mutu, but the former would counter-weight by co-ownership financial income, which all made the operating cost remained high as worse as last year. Moreover, in 2010 the result was boosted by acquiring the asset from subsidiary (related to AC Fiorentina) and the re-valuation of its value in separate balance sheet. If deducting that income (€14,737,855), 2010 financial year was net loss 24,342,208 and 2011 result was worsen €8,131,876 only in separate balance sheet. In 2012, the club benefited from the sales of Matija Nastasić and Valon Behrami, followed by Stevan Jovetić and Adem Ljajić in 2013. In 2014, due to €28.4 million drop from the windfall profit of selling players, the club recorded their worst financial results since re-foundation, despite even the club maintained the same level of windfall profit, the result would still worse than in 2013. Moreover, Fiorentina also revealed that the club had a relevant football net income of minus €19.5 million in the first assessment period of UEFA Financial Fair Play Regulations in 2013–14 season (in May 2014). (aggregate of 2012 and 2013 results), which within the limit of minus €45 million, as well as minus €25.5 million in assessment period 2014–15 (aggregate of 2012, 2013 and 2014 results). However, as the limit was reduced to minus €30 million in assessment period 2015–16, 2016–17 and 2017–18 season, the club had to achieve a relevant net income of positive €5.6 million in 2015 financial year. \"La Viola\" sold Juan Cuadrado to Chelsea in January 2015 for €30 million fee, in order to make the club eligible to 2016–17 edition of UEFA competitions.\n\n", "id": "3165", "title": "ACF Fiorentina"}
{"url": "https://en.wikipedia.org/wiki?curid=3168", "text": "Afrobeat\n\nAfrobeat is a music genre which developed in the 1970s out of a combination of West African musical styles, such as highlife and yoruba, with American funk and jazz, with a focus on chanted vocals and percussion.\n\nThe genre features chants, call-and-response vocals, and complex, interacting rhythms.\n\nA key figure in its development is Nigerian multi-instrumentalist and bandleader Fela Kuti who popularised the style both within and outside Nigeria. It was partially borne out of an attempt to distinguish Kuti's music from the \"soul music\" of American artists such as James Brown. \n\nAfrobeat originated from Fuji, heavy Nigerian drumbeats and Ghanaian highlife. It was later exported to the southern part of Nigeria in the 1970s, by Fela Kuti, who experimented with many different forms of contemporary music of the time. The new sound hailed from a club that he established called the Afrika Shrine. Upon arriving in Nigeria, Kuti also changed the name of his group to Africa '70. The band maintained a five-year residency in the Afrika Shrine from 1970 to 1975 while afrobeat thrived among Nigerian youth.\n\nPrevalent in his and Lagbaja's music are native Nigerian harmonies and rhythms, taking different elements and combining, modernizing, and improvising upon them. Politics are essential to Afrobeat, since founder Kuti used social criticism to pave the way for social change. His message can be described as confrontational and controversial, which can be related to the political climate of most of the African countries in the 1970s, many of which were dealing with political injustice and military corruption while recovering from the transition from colonial governments to self-determination. As the genre spread throughout the African continent many bands took up the style. The recordings of these bands and their songs were rarely heard or exported outside the originating countries but many can now be found on compilation albums and CDs from specialist record shops.\n\nBig band (15 to 30 pieces: Fela-era afrobeat) and energetic performances\n\n\n\nFela Kuti included the traditional Gbedu drum in his ensemble, with a percussionist pounding out a thunderous rhythm from a drum lying on its side.\n\nMany jazz musicians have been attracted to Afrobeat. From Roy Ayers in the 1970s to Randy Weston in the 1990s, there have been collaborations that have resulted in albums such as \"Africa: Centre of the World\" by Roy Ayers, released on the Polydore label in 1981. In 1994 Branford Marsalis, the American jazz saxophonist, included samples of Fela's \"Beast of No Nation\" on his \"Buckshot LeFonque\" album. The new generation of DJs and musicians of the 2000s who have fallen in love with both Kuti's material and other rare releases have made compilations and remixes of these recordings, thus re-introducing the genre to new generations of listeners and fans of afropop and groove (see Afrobeats section below).\n\nAfrobeat has also profoundly influenced important contemporary producers and musicians like Brian Eno and David Byrne, who credit Fela Kuti as an essential influence. Both worked on Talking Heads' highly acclaimed 1980 album \"Remain In Light\", which brought polyrhythmic afrobeat influences to Western music.\n\nThe horn section of Antibalas have been guest musicians on TV On The Radio's highly acclaimed 2008 album \"Dear Science\", as well as on British band Foals' 2008 album, \"Antidotes\". Some Afrobeat influence can also be found in the music of Vampire Weekend and Paul Simon.\n\nAccording to David Drake, the eclectic genre “reimagines diasporic influences and—more often than not—completely reinvents them.” However, some caution against equating Afrobeats to contemporary pan-African music, in order to prevent the erasure of local musical contributions.\n\nAfrobeats is primarily produced between Lagos, Accra, and London. Paul Gilroy, of \"The Black Atlantic\", reflects on the changing London music scene as a result of shifting demographics:\"We are moving towards an African majority which is diverse both in its cultural habits and in its relationship to colonial and postcolonial governance, so the shift away from Caribbean dominance needs to be placed in that setting. Most of the grime folks are African kids, either the children of migrants or migrants themselves. It's not clear what Africa might mean to them\"Many first and second generation African immigrants follow - and produce - Afrobeats music. Fuse ODG, a UK artist of Ghanaian descent, coins #TINA or This is New Africa as a means to change perceptions of Africa:\"This movement will shed light on Africa in a positive way and focus on how we can improve Africa. It’s not about just plying your talents in the Western world; it’s about going back home and helping Africa.\"\n\nIn recent years, afrobeat has become more prominent on the international popular music scene. This was seen in Drake's 2016 single \"One Dance\" which featured the Nigerian afrobeat artist Wizkid, and was infused with afrobeat sounds. The single became one of the best selling tracks of 2016, topping the charts in 15 different countries, including the U.S., the UK and Canada.\n\n\nThere are several active afrobeat bands worldwide today. Afrobeat today is often mixed with other genres, such as hip hop, makossa, azonto, gospel, skelewu, shoki, shakitibobo. dancehall and galala.\n\nModern afrobeat bands/artists include:\n\n\n", "id": "3168", "title": "Afrobeat"}
{"url": "https://en.wikipedia.org/wiki?curid=3170", "text": "Arithmetic function\n\nIn number theory, an arithmetic, arithmetical, or number-theoretic function is a real or complex valued function \"f\"(\"n\") defined on the set of natural numbers (i.e., positive integers) that \"expresses some arithmetical property of \"n\"\".\n\nAn example of an arithmetic function is the divisor function whose value at a positive integer \"n\" is equal to the number of divisors of \"n\".\n\nThere is a larger class of number-theoretic functions that do not fit the above definition, e.g. the prime-counting functions. This article provides links to functions of both classes.\n\nformula_1   and   formula_2   mean that the sum or product is over all prime numbers:\n\nSimilarly,   formula_5   and   formula_6   mean that the sum or product is over all prime powers with strictly positive exponent (so 1 is not included):\n\nformula_8   and   formula_9   mean that the sum or product is over all positive divisors of \"n\", including 1 and \"n\". E.g., if \"n\" = 12,\n\nThe notations can be combined:   formula_11   and   formula_12   mean that the sum or product is over all prime divisors of \"n\". E.g., if \"n\" = 18,\n\nand similarly   formula_14   and   formula_15   mean that the sum or product is over all prime powers dividing \"n\". E.g., if \"n\" = 24,\n\nAn arithmetic function \"a\" is\n\nTwo whole numbers \"m\" and \"n\" are called coprime if their greatest common divisor is 1; i.e., if there is no prime number that divides both of them.\n\nThen an arithmetic function \"a\" is\n\nThe fundamental theorem of arithmetic states that any positive integer \"n\" can be represented uniquely as a product of powers of primes:   formula_17   where \"p\" < \"p\" < ... < \"p\" are primes and the \"a\" are positive integers. (1 is given by the empty product.)\n\nIt is often convenient to write this as an infinite product over all the primes, where all but a finite number have a zero exponent. Define ν(\"n\") as the exponent of the highest power of the prime \"p\" that divides \"n\". I.e. if \"p\" is one of the \"p\" then ν(\"n\") = \"a\", otherwise it is zero. Then\n\nIn terms of the above the functions ω and Ω are defined by\n\nTo avoid repetition, whenever possible formulas for the functions listed in this article are given in terms of \"n\" and the corresponding \"p\", \"a\", ω, and Ω.\n\nσ(\"n\") is the sum of the \"k\"th powers of the positive divisors of \"n\", including 1 and \"n\", where \"k\" is a complex number.\n\nσ(\"n\"), the sum of the (positive) divisors of \"n\", is usually denoted by σ(\"n\").\n\nSince a positive number to the zero power is one, σ(\"n\") is therefore the number of (positive) divisors of \"n\"; it is usually denoted by \"d\"(\"n\") or τ(\"n\") (for the German \"Teiler\" = divisors).\n\nSetting \"k\" = 0 in the second product gives\n\nφ(\"n\"), the Euler totient function, is the number of positive integers not greater than \"n\" that are coprime to \"n\".\n\nJ(\"n\"), the Jordan totient function, is the number of \"k\"-tuples of positive integers all less than or equal to \"n\" that form a coprime (\"k\" + 1)-tuple together with \"n\". It is a generalization of Euler's totient, .\n\nμ(\"n\"), the Möbius function, is important because of the Möbius inversion formula. See Dirichlet convolution, below.\n\nThis implies that μ(1) = 1. (Because Ω(1) = ω(1) = 0.)\n\nτ(\"n\"), the Ramanujan tau function, is defined by its generating function identity:\n\nAlthough it is hard to say exactly what \"arithmetical property of \"n\"\" it \"expresses\", (τ(\"n\") is (2π) times the \"n\"th Fourier coefficient in the q-expansion of the modular discriminant function) it is included among the arithmetical functions because it is multiplicative and it occurs in identities involving certain σ(\"n\") and \"r\"(\"n\") functions (because these are also coefficients in the expansion of modular forms).\n\n\"c\"(\"n\"), Ramanujan's sum, is the sum of the \"n\"th powers of the primitive \"q\"th roots of unity:\n\nEven though it is defined as a sum of complex numbers (irrational for most values of \"q\"), it is an integer. For a fixed value of \"n\" it is multiplicative in \"q\":\n\nMany of the functions mentioned in this article have expansions as series involving these sums; see the article Ramanujan's sum for examples.\n\nλ(\"n\"), the Liouville function, is defined by\n\nAll Dirichlet characters χ(\"n\") are completely multiplicative. An example is the non-principal character (mod 4) defined in the introduction. Two characters have special notations:\n\nThe principal character (mod \"n\") is denoted by χ(\"a\") (or χ(\"a\")). It is defined as\n\nThe quadratic character (mod \"n\") is denoted by the Jacobi symbol for odd \"n\" (it is not defined for even \"n\".):\n\nIn this formula formula_30 is the Legendre symbol, defined for all integers \"a\" and all odd primes \"p\" by\n\nFollowing the normal convention for the empty product, formula_32\n\nω(\"n\"), defined above as the number of distinct primes dividing \"n\", is additive.\n\nΩ(\"n\"), defined above as the number of prime factors of \"n\" counted with multiplicities, is completely additive.\n\nFor a fixed prime \"p\", ν(\"n\"), defined above as the exponent of the largest power of \"p\" dividing \"n\", is completely additive.\n\nThese important functions (which are not arithmetic functions) are defined for non-negative real arguments, and are used in the various statements and proofs of the prime number theorem. They are summation functions (see the main section just below) of arithmetic functions which are neither multiplicative nor additive.\n\nπ(\"x\"), the prime counting function, is the number of primes not exceeding \"x\". It is the summation function of the characteristic function of the prime numbers.\n\nA related function counts prime powers with weight 1 for primes, 1/2 for their squares, 1/3 for cubes, … It is the summation function of the arithmetic function which takes the value 1/\"k\" on integers which are the k-th power of some prime number, and the value 0 on other integers.\n\n\"θ\"(\"x\") and \"ψ\"(\"x\"), the Chebyshev functions,\nare defined as sums of the natural logarithms of the primes not exceeding \"x\".\n\nThe Chebyshev function \"ψ\"(\"x\") is the summation function of the von Mangoldt function just below.\n\nΛ(\"n\"), the von Mangoldt function, is 0 unless the argument is a prime power, in which case it is the natural log of the prime:\n\n\"p\"(\"n\"), the partition function, is the number of ways of representing \"n\" as a sum of positive integers, where two representations with the same summands in a different order are not counted as being different:\n\nλ(\"n\"), the Carmichael function, is the smallest positive number such that formula_39   for all \"a\" coprime to \"n\". Equivalently, it is the least common multiple of the orders of the elements of the multiplicative group of integers modulo \"n\".\n\nFor powers of odd primes and for 2 and 4, λ(\"n\") is equal to the Euler totient function of \"n\"; for powers of 2 greater than 4 it is equal to one half of the Euler totient function of \"n\":\n\nand for general \"n\" it is the least common multiple of λ of each of the prime power factors of \"n\":\n\n\"h\"(\"n\"), the class number function, is the order of the ideal class group of an algebraic extension of the rationals with discriminant \"n\". The notation is ambiguous, as there are in general many extensions with the same discriminant. See quadratic field and cyclotomic field for classical examples.\n\n\"r\"(\"n\") is the number of ways \"n\" can be represented as the sum of \"k\" squares, where representations that differ only in the order of the summands or in the signs of the square roots are counted as different.\n\nGiven an arithmetic function \"a(n)\", its summation function \"A(x)\" is defined by\n\"A\" can be regarded as a function of a real variable. Given a positive integer \"m\", \"A\" is constant along open intervals \"m\" < \"x\" < \"m\" + 1, and has a jump discontinuity at each integer for which \"a(m)\" ≠ 0.\n\nSince such functions are often represented by series and integrals, to achieve pointwise convergence it is usual to define the value at the discontinuities as the average of the values to the left and right:\n\nIndividual values of arithmetic functions may fluctuate wildly – as in most of the above examples. Summation functions \"smooth out\" these fluctuations. In some cases it may be possible to find asymptotic behaviour for the summation function for large \"x\".\n\nA classical example of this phenomenon is given by the divisor summatory function, the summation function of \"d\"(\"n\"), the number of divisors of \"n\":\n\nAn average order of an arithmetic function is some simpler or better-understood function which has the same summation function asymptotically, and hence takes the same values \"on average\". We say that \"g\" is an \"average order\" of \"f\" if\n\nas \"x\" tends to infinity. The example above shows that \"d\"(\"n\") has the average order log(\"n\").\n\nGiven an arithmetic function \"a(n)\", let \"F(s)\", for complex \"s\", be the function defined by the corresponding Dirichlet series (where it converges):\n\"F(s)\" is called a generating function of \"a(n)\". The simplest such series, corresponding to the constant function \"a\"(\"n\") = 1 for all \"n\", is ς(\"s\") the Riemann zeta function.\n\nThe generating function of the Möbius function is the inverse of the zeta function:\n\nConsider two arithmetic functions \"a\" and \"b\" and their respective generating functions \"F\"(\"s\") and \"F\"(\"s\"). The product \"F\"(\"s\")\"F\"(\"s\") can be computed as follows:\n\nIt is a straightforward exercise to show that if \"c\"(\"n\") is defined by\n\nthen\n\nThis function \"c\" is called the Dirichlet convolution of \"a\" and \"b\", and is denoted by formula_54.\n\nA particularly important case is convolution with the constant function \"a\"(\"n\") = 1 for all \"n\", corresponding to multiplying the generating function by the zeta function:\n\nMultiplying by the inverse of the zeta function gives the Möbius inversion formula:\n\nIf \"f\" is multiplicative, then so is \"g\". If \"f\" is completely multiplicative, then \"g\" is multiplicative, but may or may not be completely multiplicative.\n\nThere are a great many formulas connecting arithmetical functions with each other and with the functions of analysis, especially powers, roots, and the exponential and log functions.\n\nHere are a few examples:\n\nThere is a formula for r in the section on class numbers below.\n\nDefine the function σ(\"n\") as\n\nThat is, if \"n\" is odd, σ(\"n\") is the sum of the \"k\"th powers of the divisors of \"n\", i.e. σ(\"n\"), and if \"n\" is even it is the sum of the \"k\"th powers of the even divisors of \"n\" minus the sum of the \"k\"th powers of the odd divisors of \"n\".\n\nAdopt the convention that Ramanujan's τ(\"x\") = 0 if \"x\" is not an integer.\n\nHere \"convolution\" does not mean \"Dirichlet convolution\" but instead refers to the formula for the coefficients of the product of two power series:\n\nThe sequence formula_82 is called the convolution or the Cauchy product of the sequences \"a\" and \"b\".\n<br>See Eisenstein series for a discussion of the series and functional identities involved in these formulas.\n\nSince σ(\"n\") (for natural number \"k\") and τ(\"n\") are integers, the above formulas can be used to prove congruences for the functions. See Tau-function for some examples.\n\nExtend the domain of the partition function by setting \"p\"(0) = 1.\n\nPeter Gustav Lejeune Dirichlet discovered formulas that relate the class number \"h\" of quadratic number fields to the Jacobi symbol.\n\nAn integer \"D\" is called a fundamental discriminant if it is the discriminant of a quadratic number field. This is equivalent to \"D\" ≠ 1 and either a) \"D\" is squarefree and \"D\" ≡ 1 (mod 4) or b) \"D\" ≡ 0 (mod 4), \"D\"/4 is squarefree, and \"D\"/4 ≡ 2 or 3 (mod 4).\n\nExtend the Jacobi symbol to accept even numbers in the \"denominator\" by defining the Kronecker symbol:\n\nThen if \"D\" < −4 is a fundamental discriminant\n\nThere is also a formula relating \"r\" and \"h\". Again, let \"D\" be a fundamental discriminant, \"D\" < −4. Then\n\nLet formula_92   be the \"n\"th harmonic number.   Then\n\nThe Riemann hypothesis is also equivalent to the statement that, for all \"n\" > 5040,\n\nIn 1965 P. Kesava Menon proved\n\nThis has been generalized by a number of mathematicians, e.g.:\n\nB. Sury\n\nN. Rao\nwhere \"a\", \"a\", ..., \"a\" are integers, gcd(\"a\", \"a\", ..., \"a\", \"n\") = 1.\n\nL. Tóth\nwhere \"m\" and \"m\" are odd, \"m\" = lcm(\"m\", \"m\").\n\nIn fact, if \"f\" is any arithmetical function\nwhere * stands for Dirichlet convolution.\n\nLet \"m\" and \"n\" be distinct, odd, and positive. Then the Jacobi symbol satisfies the law of quadratic reciprocity:\n\nLet λ(\"n\") be Liouville's function. Then\n\nLet λ(\"n\") be Carmichael's function. Then\n\n\n", "id": "3170", "title": "Arithmetic function"}
{"url": "https://en.wikipedia.org/wiki?curid=3172", "text": "ANSI C\n\nANSI C, ISO C and Standard C refer to the successive standards for the C programming language published by the American National Standards Institute (ANSI) and the International Organization for Standardization (ISO). Historically, the names referred specifically to the original and best-supported version of the standard (known as C89 or C90). Software developers writing in C are encouraged to conform to the standards, as doing so aids portability between compilers.\n\nThe first standard for C was published by ANSI. Although this document was subsequently adopted by International Organization for Standardization (ISO) and subsequent revisions published by ISO have been adopted by ANSI, the name ANSI C (rather than ISO C) is still more widely used. While some software developers use the term ISO C, others are standards body–neutral and use Standard C.\n\nIn 1983, the American National Standards Institute formed a committee, X3J11, to establish a standard specification of C. The standard was completed in 1989 and ratified as ANSI X3.159-1989 \"Programming Language C.\" This version of the language is often referred to as \"ANSI C\". Later on sometimes the label \"C89\" is used to distinguish it from C99 but using the same labelling method.\n\nThe same standard as C89 was ratified by the International Organization for Standardization as ISO/IEC 9899:1990, with only formatting changes, which is sometimes referred to as C90. Therefore, the terms \"C89\" and \"C90\" refer to essentially the same language.\n\nThis standard has been withdrawn by both ANSI/INCITS and ISO/IEC.\n\nIn 1995, the ISO published an extension, called Amendment 1, for the ANSI-C standard. Its full name finally was \"ISO/IEC 9899/AMD1:1995\" or nicknamed \"C95\". Aside from error correction there were further changes to the language capabilities, such as:\n\n\nIn addition to the amendment, two technical corrigenda were published by ISO for C90:\n\n\nIn March 2000, ANSI adopted the ISO/IEC 9899:1999 standard. This standard is commonly referred to as C99. Some notable additions to the previous standard include:\n\n\nThree technical corrigenda were published by ISO for C99:\n\n\nThis standard has been withdrawn by both ANSI/INCITS and ISO/IEC in favour of C11.\n\n\"C11\" is the current standard for the C programming language. Notable features introduced over the previous revision include improved Unicode support, type-generic expressions using the new codice_16 keyword, a cross-platform multi-threading API (codice_17) and atomic types support in both core language and the library (codice_18).\n\nOne technical corrigendum has been published by ISO for C11:\n\n\nAs part of the standardization process, ISO also publishes technical reports and specifications:\n\nMore technical specifications are in development and pending approval, including the fifth and final part of TS 18661, a software transactional memory specification, and parallel library extensions.\n\nANSI C is now supported by almost all the widely used compilers. Most of the C code being written nowadays is based on ANSI C. Any program written \"only\" in standard C and without any hardware dependent assumptions is virtually guaranteed to compile correctly on any platform with a conforming C implementation. Without such precautions, most programs may compile only on a certain platform or with a particular compiler, due, for example, to the use of non-standard libraries, such as GUI libraries, or to the reliance on compiler- or platform-specific attributes such as the exact size of certain data types and byte endianness.\n\nTo mitigate the differences between K&R C and the ANSI C standard, the codice_19 (\"standard c\") macro can be used to split code into ANSI and K&R sections.\nIn the above example, a prototype is used in a function declaration for ANSI compliant implementations, while an obsolescent non-prototype declaration is used otherwise. Those are still ANSI-compliant as of C99. Note how this code checks both definition and evaluation: this is because some implementations may set codice_19 to zero to indicate non-ANSI compliance.\n\n\n\n", "id": "3172", "title": "ANSI C"}
{"url": "https://en.wikipedia.org/wiki?curid=3173", "text": "Alien and Sedition Acts\n\nThe Alien and Sedition Acts were four bills passed by the Federalist-dominated 5th United States Congress and signed into law by President John Adams in 1798. They made it harder for an immigrant to become a citizen (Naturalization Act), allowed the president to imprison and deport non-citizens who were deemed dangerous (Alien Friends Act of 1798) or who were from a hostile nation (Alien Enemy Act of 1798), and criminalized making false statements that were critical of the federal government (Sedition Act of 1798).\n\nThe Federalists argued that the bills strengthened national security during an undeclared naval war with France. Critics argued that they were primarily an attempt to suppress voters who disagreed with the Federalist party, and violated the right of freedom of speech in the First Amendment. Three of the acts were repealed after the Democratic-Republican party of Thomas Jefferson came to power. But the Alien Enemies Act remained in effect, was revised and codified in 1918 for use in World War I, and was used by President Franklin Delano Roosevelt to imprison Japanese, German, and Italian aliens during World War II. Following cessation of hostilities, the act was used by President Harry S. Truman to continue to imprison, then deport, aliens of the formerly hostile nations. In 1948 the Supreme Court determined that presidential powers under the acts continued after cessation of hostilities until there was a peace treaty with the hostile nation. The revised Alien Enemies Act remains in effect today.\n\nThe Naturalization Act increased the residency requirement for American citizenship from five to fourteen years. At the time, the majority of immigrants supported Thomas Jefferson and the Democratic-Republicans, the political opponents of the Federalists. The Alien Friends Act allowed the president to imprison or deport aliens considered \"dangerous to the peace and safety of the United States\" at any time, while the Alien Enemies Act authorized the president to do the same to any male citizen of a hostile nation above the age of fourteen during times of war. Lastly, the controversial Sedition Act restricted speech that was critical of the federal government. Under the Sedition Act, the Federalists allowed people who were accused of violating the sedition laws to use truth as a defense. The Sedition Act resulted in the prosecution and conviction of many Jeffersonian newspaper owners who disagreed with the government.\n\nThe acts were denounced by Democratic-Republicans and ultimately helped them to victory in the 1800 election, when Thomas Jefferson defeated the incumbent, President Adams. The Sedition Act and the Alien Friends Act were allowed to expire in 1800 and 1801, respectively. The Alien Enemies Act, however, remains in effect as Sections 21–24 of Title 50 of the United States Code.\n\nOpposition to the Federalists, spurred by Democratic-Republicans, reached new heights with the Democratic-Republicans' support of France, which was still in the midst of the French Revolution. Some appeared to desire in the United States an event similar to the French Revolution, in order to overthrow the government. When Democratic-Republicans in some states refused to enforce federal laws such as the 1791 whiskey tax, the first tax levied by the national government, and threatened to rebel, Federalists warned that they would send in the army to force them to capitulate. As the unrest sweeping Europe spread to the United States, calls for secession reached unparalleled heights, and the fledgling nation seemed ready to tear itself apart. Some of this agitation was seen by Federalists as having been caused by French and French-sympathizing immigrants. The Alien Act and the Sedition Act were meant to guard against this perceived threat of anarchy.\n\nThey were a major political issue in the elections of 1798 and 1800, controversial then, and remaining so today. Opposition to them resulted in the highly controversial Virginia and Kentucky Resolutions, authored by James Madison and Thomas Jefferson. Prominent prosecutions under the Sedition Act include:\n\n\nThe Democratic-Republicans made the Alien and Sedition Acts an important issue in the 1800 election campaign. Upon assuming the Presidency, Thomas Jefferson pardoned those still serving sentences under the Sedition Act, and Congress soon repaid their fines. It has been said that the Alien Acts were aimed at Albert Gallatin, and the Sedition Act aimed at Benjamin Bache's \"Aurora\". While government authorities prepared lists of aliens for deportation, many aliens fled the country during the debate over the Alien and Sedition Acts, and Adams never signed a deportation order.\n\nThe Alien and Sedition Acts were never appealed to the Supreme Court, whose right of judicial review was not clearly established until \"Marbury v. Madison\" in 1803. Subsequent mentions in Supreme Court opinions beginning in the mid-20th century have assumed that the Sedition Act would today be found unconstitutional.\n\nThomas Jefferson and James Madison also secretly drafted the Kentucky and Virginia Resolutions denouncing the federal legislation, though many other state legislatures strongly opposed these resolutions. Though the resolutions followed Madison's \"interposition\" approach, Jefferson advocated nullification and at one point drafted a threat for Kentucky to secede. Jefferson's biographer Dumas Malone argued that this might have gotten Jefferson impeached for treason, had his actions become known at the time. In writing the Kentucky Resolutions, Jefferson warned that, \"unless arrested at the threshold,\" the Alien and Sedition Acts would \"necessarily drive these states into revolution and blood.\" Historian Ron Chernow says of this \"he wasn't calling for peaceful protests or civil disobedience: he was calling for outright rebellion, if needed, against the federal government of which he was vice president.\" Jefferson \"thus set forth a radical doctrine of states' rights that effectively undermined the constitution.\" Chernow argues that neither Jefferson nor Madison sensed that they had sponsored measures as inimical as the Alien and Sedition Acts themselves. Historian Garry Wills argued, \"Their nullification effort, if others had picked it up, would have been a greater threat to freedom than the misguided [alien and sedition] laws, which were soon rendered feckless by ridicule and electoral pressure\" The theoretical damage of the Kentucky and Virginia resolutions was \"deep and lasting, and was a recipe for disunion\". George Washington was so appalled by them that he told Patrick Henry that if \"systematically and pertinaciously pursued\", they would \"dissolve the union or produce coercion\". The influence of Jefferson's doctrine of states' rights reverberated right up to the Civil War and beyond. At the close of the Civil War, future president James Garfield said that Jefferson's Kentucky Resolution \"contained the germ of nullification and secession, and we are today reaping the fruits\".\n\nThe Alien Enemies Acts remained in effect at the outset of World War I. It was recodified to be part of the US war and national defense statutes (50 USC 21–24).\n\nOn December 7, 1941, responding to the bombing of Pearl Harbor, President Franklin Delano Roosevelt used the authority of the revised Alien Enemies Act to issue presidential proclamations 2525 (Alien Enemies – Japanese), 2526 (Alien Enemies – German), and 2527 (Alien Enemies – Italian), to apprehend, restrain, secure and remove Japanese, German, and Italian non-citizens. On February 19, 1942, citing authority of the wartime powers of the president and commander in chief, Roosevelt made Executive Order 9066, authorizing the Secretary of War to prescribe military areas and giving him authority that superseded the authority of other executives under Proclamations 2525-7. EO 9066 led to the internment of Japanese Americans, whereby over 110,000 people of Japanese ancestry living on the Pacific coast were forcibly relocated and forced to live in camps in the interior of the country, 62% of whom were United States citizens, not aliens.\n\nHostilities with Germany and Italy ended in May 1945, and with Japan in August. Alien enemies, and US citizens, continued to be interned. On July 14, 1945, President Harry S. Truman issued Presidential Proclamation 2655, titled “Removal of Alien Enemies”. The proclamation gave the Attorney General authority regarding aliens enemies within the continental United States, to decide whether they are \"dangerous to the public peace and safety of the United States\", to order them removed, and to create regulations governing their removal. The proclamation cited the revised Alien Enemies Act (50 U.S.C. 21–24) as to powers of the President to make public proclamation regarding \"subjects of the hostile nation\" more than fourteen years old and living inside the United States but not naturalized, to remove them as alien enemies, and to determine the means of removal.\n\nOn September 8, 1945, Truman issued Presidential Proclamation 2662, titled \"Removal of Alien Enemies\". The revised Alien Enemies Act (50 U.S.C. 21–24) was cited as to removal of alien enemies in the interest of the public safety. The United States had agreed, at a conference in Rio de Janeiro in 1942, to assume responsibility for the restraint and repatriation of dangerous alien enemies to be sent to the United States from Latin American republics. In another inter-American conference in Mexico City on March 8, 1945, North and South American governments resolved to recommended adoption of measures to prevent aliens of hostile nations who were deemed to be security threats or threats to welfare from remaining in North or South America. Truman gave authority to the Secretary of State to determine if alien enemies in the United States who were sent to the United States from Latin America, or who were in the United States illegally, endangered the welfare or security of the country. The Secretary of State was given power to remove them \"to destinations outside the limits of the Western Hemisphere\", to the former enemy territory of the governments to whose \"principles of which (the alien enemies) have adhered\". The Department of Justice was directed to assist the Secretary of State in their prompt removal.\n\nOn April 10, 1946, Truman issued Presidential Proclamation 2685, titled “Removal of Alien Enemies”, citing the revised Alien Enemies Act (50 U.S.C. 21–24) as to its provision for the “removal from the United States of alien enemies in the interest of the public safety”. Truman proclaimed regulations that were in addition to and supplemented other \"regulations affecting the restraint and removal of alien enemies\". As to alien enemies who had been brought into the continental United States from Latin America after December 1941, the proclamation gave the Secretary of State authority to decide if their presence was \"prejudicial to the future security or welfare of the Americas\", and to make regulations for their removal. 30 days was set as the reasonable time for them to \"effect the recovery, disposal, and removal of (their) goods and effects, and for (their) departure.\"\n\nIn 1947 New York's Ellis Island continued to incarcerate hundreds of ethnic Germans. Fort Lincoln was a large internment camp still holding internees in North Dakota. North Dakota was represented by controversial Senator William \"Wild Bill\" Langer. Langer introduced a bill (S. 1749) \"for the relief of all persons detained as enemy aliens\", and directing the US Attorney General to cancel \"outstanding warrants of arrest, removal, or deportation\" for many German aliens still interned, listing many by name, and all of those detained by the Immigration and Naturalization Service (INS), which was under the Department of Justice (DOJ). It directed the INS not to issue any more warrants or orders, if their only basis was the original warrants of arrest. The bill never passed. The Attorney General gave up plenary jurisdiction over the last internee on Ellis Island late in 1948.\n\nIn Ludecke v. Watkins (1948), the Supreme Court interpreted the time of release under the Alien Enemies Act. German alien Kurt G. W. Ludecke was detained in 1941, under Proclamation 2526. and continued to be held after cessation of hostilities. In 1947, Ludecke petitioned for a writ of habeas corpus to order his release, after the Attorney General ordered him deported. The court ruled 5–4 to release Ludecke, but also found that the Alien Enemies Act allowed for detainment beyond the time hostilities ceased, until an actual treaty was signed with the hostile nation or government.\n\nIn 1988, President Reagan and the 100th Congress introduced the Civil Liberties Act of 1988, whose purpose amongst others was to acknowledge and apologize for actions of the US against individuals of Japanese ancestry during World War II. The statement from Congress agreed with the Commission on Wartime Relocation and Internment of Civilians, that \"a grave injustice was done to both citizens and permanent resident aliens of Japanese... without adequate security reasons and without any acts of espionage or sabotage documented by the Commission, and were motivated largely by racial prejudice, wartime hysteria, and a failure of political leadership.\"\n\nIn 2015, presidential candidate Donald Trump made a proposal to ban all Muslims from entering the United States (as part of the War on Terror); Roosevelt's application of the Alien Enemies Act was cited as a possible justification. The proposal created international controversy, drawing criticism from foreign heads of state that have historically remained uninvolved in United States presidential elections. A former Reagan Administration aide noted that, despite criticism of Trump's proposal to invoke the law, \"the Alien Enemies Act... is still on the books... (and people) in Congress for many decades (haven’t) repealed the law... (nor has) Barack Obama\". Other critics claimed that the proposal violated founding principles, and was unconstitutional for singling out a religion, and not a hostile nation. They included the Pentagon and others, who argued that the proposal (and its citation of the Alien Enemies proclamations as authority) played into the ISIL narrative that the United States was at war with the entire Muslim religion (not just with ISIL and other terrorist entities).\n\n\n\n\n", "id": "3173", "title": "Alien and Sedition Acts"}
{"url": "https://en.wikipedia.org/wiki?curid=3175", "text": "Antinomy\n\nAntinomy (Greek ἀντί, \"antí\", \"against, in opposition to,\" and νόμος, \"nómos\", \"law\") refers to a real or apparent mutual incompatibility of two laws. It is a term used in logic and epistemology, particularly in the philosophy of Kant and Roberto Unger.\n\nThere are many examples of antinomy. A self-contradictory phrase such as \"There is no absolute truth\" can be considered an antinomy because this statement is suggesting in itself to be an absolute truth, and therefore denies itself any truth in its statement. A paradox such as \"this sentence is false\" can also be considered to be an antinomy; for the sentence to be true, it must be false, and vice versa.\n\nThe term acquired a special significance in the philosophy of Immanuel Kant (1724–1804), who used it to describe the equally rational but contradictory results of applying to the universe of pure thought the categories or criteria of reason that are proper to the universe of sensible perception or experience (phenomena). Empirical reason cannot here play the role of establishing rational truths because it goes beyond possible experience and is applied to the sphere of that which transcends it.\n\nFor Kant there are four antinomies, connected with:\n\nIn each antinomy, a thesis is contradicted by an antithesis. For example: in the First Antinomy, Kant proves the thesis that time must have a beginning by showing that if time had no beginning, then an infinity would have elapsed up until the present moment. This is a manifest contradiction because infinity cannot, by definition, be completed by \"successive synthesis\"—yet just such a finalizing synthesis would be required by the view that time is infinite; so the thesis is proven. Then he proves the antithesis, that time has no beginning, by showing that if time had a beginning, then there must have been \"empty time\" out of which time arose. This is incoherent (for Kant) for the following reason: Since, necessarily, no time elapses in this pretemporal void, then there could be no alteration, and therefore nothing (including time) would ever come to be: so the antithesis is proven. Reason makes equal claim to each proof, since they are both correct, so the question of the limits of time must be regarded as meaningless.\n\nThis was part of Kant's critical program of determining limits to science and philosophical inquiry. These contradictions are inherent in reason when it is applied to the world as it is in itself, independently of our perceptions of it (this has to do with the distinction between phenomena and noumena). Kant's goal in his critical philosophy was to identify what claims we are and are not justified in making, and the antinomies are a particularly illustrative example of his larger project.\n\n\n\n", "id": "3175", "title": "Antinomy"}
{"url": "https://en.wikipedia.org/wiki?curid=3189", "text": "Ascending chain condition\n\nIn mathematics, the ascending chain condition (ACC) and descending chain condition (DCC) are finiteness properties satisfied by some algebraic structures, most importantly ideals in certain commutative rings. These conditions played an important role in the development of the structure theory of commutative rings in the works of David Hilbert, Emmy Noether, and Emil Artin.\nThe conditions themselves can be stated in an abstract form, so that they make sense for any partially ordered set. This point of view is useful in abstract algebraic dimension theory due to Gabriel and Rentschler.\n\nA partially ordered set (poset) \"P\" is said to satisfy the ascending chain condition (ACC) if every strictly ascending sequence of elements eventually terminates. Equivalently, given any sequence\nthere exists a positive integer \"n\" such that\nSimilarly, \"P\" is said to satisfy the descending chain condition (DCC) if every strictly descending sequence of elements eventually terminates, that is, there is no infinite descending chain. Equivalently every descending sequence\nof elements of \"P\", eventually stabilizes.\n\n\n\n", "id": "3189", "title": "Ascending chain condition"}
{"url": "https://en.wikipedia.org/wiki?curid=3192", "text": "Adin Steinsaltz\n\nRabbi Adin Steinsaltz (Hebrew: עדין שטיינזלץ) or Adin Even Yisrael (Hebrew: עדין אבן ישראל) (born 1937) is a teacher, philosopher, social critic, and spiritual mentor, who has been hailed by \"Time\" magazine as a \"once-in-a-millennium scholar\". He has devoted his life to making the Talmud accessible to all Jews. Originally published in modern Hebrew, with a running commentary to facilitate learning, his \"Steinsaltz edition of the Talmud\" has also been translated into English, French, Russian and Spanish. Beginning in 1989, Steinsaltz published several tractates in Hebrew and English of the Babylonian (Bavli) Talmud in an English-Hebrew edition. The first volume of a new English-Hebrew edition, the Koren Talmud Bavli, was released in May, 2012, with thirteenth tractates in print by July 2014. New volumes are being released following the Daf Yomi cycle.\n\nBorn in Jerusalem in 1937 to secular parents, Steinsaltz studied mathematics, physics, and chemistry at the Hebrew University, in addition to rabbinical studies. Following graduation, he established several experimental schools after an unsuccessful attempt to start a neo-Hassidic community in the Negev desert, and, at the age of 23, became Israel’s youngest school principal.\n\nIn 1965, he founded the Israel Institute for Talmudic Publications and began his monumental work on the Talmud, including translation into Hebrew, English, Russian, and various other languages. The Steinsaltz editions of the Talmud include translation from the original Aramaic and a comprehensive commentary. Steinsaltz completed his Hebrew edition of the entire Babylonian Talmud in November 2010, at which time Koren Publishers Jerusalem became the publisher of all of his works, including the Talmud. While not without criticism (such as by Jacob Neusner, 1998), the Steinsaltz edition is widely used throughout Israel, the United States and the world. Over two million volumes of the Steinsaltz Talmud have been distributed to date. The out-of-print Random House publication of \"\" is widely regarded as the most accurate and least redacted of any English language edition and is sought after on that basis by scholars and collectors. Controversial Talmud passages previously obscured, omitted entirely or confined to footnotes in English translations like the Soncino Talmud, receive full exposition in the Steinsaltz Talmud. Random House halted publication of the Steinsaltz Talmud after less than one-third of the English translation had been published.\n\nThe Steinsaltz editions of the Talmud have opened up the world of Talmud study to thousands of people outside the walls of the traditional yeshiva, including women, who traditionally were not taught Talmud. Regarding the access that his work provides, Rabbi Steinsaltz says: “I never thought that spreading ignorance has any advantage, except for those who are in a position of power and want to deprive others of their rights and spread ignorance in order to keep them underlings.”\n\nRabbi Steinsaltz's classic work of Kabbalah, \"The Thirteen Petalled Rose\", was first published in 1980 and now appears in eight languages. In all, Steinsaltz has authored some 60 books and hundreds of articles on subjects including Talmud, Jewish mysticism, Jewish philosophy, sociology, historical biography, and philosophy. Many of these works have been translated into English by his close personal friend, now deceased, Yehuda Hanegbi. His latest book is a memoir-biography on the Lubavitcher Rebbe, Rabbi Menachem Mendel Schneerson, published by Maggid Books (2014).\n\nIn the summer of 1989, a group of rabbis including Elazar Shach placed a ban on three of Steinsaltz's books.\n\nContinuing his work as a teacher and spiritual mentor, Steinsaltz established a network of schools and educational institutions in Israel and the former Soviet Union. He has served as scholar in residence at the Woodrow Wilson International Center for Scholars in Washington, D.C. and the Institute for Advanced Study in Princeton. His honorary degrees include doctorates from Yeshiva University, Ben Gurion University of the Negev, Bar Ilan University, Brandeis University, and Florida International University. Steinsaltz is also Rosh Yeshiva of Yeshivat Hesder Tekoa.\n\nBeing a follower of Rabbi Menachem Mendel Schneerson of Chabad-Lubavitch, he went to help Jews in the Soviet Union assisting Chabad's \"shluchim\" (propagators) network. Deeply involved in the future of the Jews in the former Soviet Union, Steinsaltz serves as the region's \"Duchovny Ravin\" (Spiritual Rabbi), a historic Russian title which indicates that he is the spiritual mentor of Russian Jewry. In this capacity, Steinsaltz travelled to Russia and the Republics once each month from his home in Jerusalem. During his time in the former Soviet Union he founded the Jewish University, both in Moscow and Saint Petersburg. The Jewish University is the first degree-granting institution of Jewish studies in the former Soviet Union.\n\nSteinsaltz has taken a cautious approach to interfaith dialogues. During a visit of a delegation of Roman Catholic cardinals in Manhattan in January 2004, he said that “you do not have to raise over-expectations of a meeting as it doesn't signify in itself a breakthrough, however, the opportunity for cardinals and rabbis to speak face to face is valuable. It's part of a process in which we can talk to each other in a friendly way”, and called for “a theological dialogue that asks the tough questions, such as whether Catholicism allows for Jews to enter eternal paradise.”\n\nSteinsaltz and his wife live in Jerusalem, and have three children and more than ten grandchildren. His son, Rabbi Menachem Even-Israel, is the Executive Director of Shefa - Rabbi Steinsaltz's umbrella organization, located in the Steinsaltz Center in the Nachlaot neighborhood of Jerusalem.\n\nRabbi Steinsaltz accepted the position as Nasi (President) of the 2004 attempt to revive the Sanhedrin. In 2008 he resigned from this position due to differences of opinion.\n\nSteinsaltz is a popular University and radio commentator. He has been invited to speak at the Aspen Institute for Humanistic Studies at Yale University in 1979. In Jerusalem, he gives evening seminars, which according to Newsweek usually last till 2 in the morning, and have attracted prominent politicians as the former Prime Minister Levi Eshkol and former Finance Minister Pinhas Sapir.\n\nRabbi Steinsaltz has received many awards and prizes, among them the Israel Prize for Jewish studies in 1988.\n\nOn 9 February 2012, Steinsaltz was honored by Israeli President Shimon Peres with Israel's first President's Prize for his scholarship in Talmud.\n\nThe Jewish Book Council named the Koren Talmud Bavli with commentary, translation and notes by Rabbi Adin Steinsaltz, a 2012 National Jewish Book Award winner in the category of Modern Jewish Thought and Experience.\n\nJacob Neusner's \"How Adin Steinsaltz Misrepresents the Talmud. Four False Propositions from his \"Reference Guide\"\" (1998) displays strong disagreement. \n\nTalmudic researcher and lecturer Aharon Feldman penned a lengthy critical review of the Steinsaltz Talmud. Among many criticisms, he writes \"Specifically, the work is marred by an extraordinary number of inaccuracies stemming primarily from misreadings of the sources; it fails to explain those difficult passages which the reader would expect it to explain; and it confuses him with notes which are often irrelevant, incomprehensible and contradictory.\" Feldman says he fears that \"An intelligent student utilizing the Steinsaltz Talmud as his personal instructor might in fact conclude that Talmud in general is not supposed to make sense.\" Furthermore, writes Feldman, the Steinsaltz Talmud gives off the impression that the Talmud is intellectually flabby, inconsistent, and often trivial.\n\nSteinsaltzs' works aroused fierce opposition in much of the Orthodox world, with many leading rabbis such as Elazar Shach, Yosef Shalom Eliashiv, and Eliezer Waldenberg harshly condemning his Talmud and other books. Waldenberg wrote that that when the Steinsaltz Talmud was brought before him, he was \"shocked\" to see the way in which the Steinsaltz Talmud described the Patriarchs and Talmudic sages, as well as it's approach to the Oral Torah. Waldenberg further wrote that the Steinsaltz Talmud had the power to \"poision the souls\" of those who read it. Mordechai Gifter delivered a pointed lecture on the subject, criticizing Steinsaltz and his defenders in strong terms.\n\n\n", "id": "3192", "title": "Adin Steinsaltz"}
{"url": "https://en.wikipedia.org/wiki?curid=3198", "text": "A. E. Housman\n\nAlfred Edward Housman (; 26 March 1859 – 30 April 1936), usually known as A. E. Housman, was an English classical scholar and poet, best known to the general public for his cycle of poems \"A Shropshire Lad\". Lyrical and almost epigrammatic in form, the poems wistfully evoke the dooms and disappointments of youth in the English countryside. Their beauty, simplicity and distinctive imagery appealed strongly to late Victorian and Edwardian taste, and to many early 20th-century English composers both before and after the First World War. Through their song-settings, the poems became closely associated with that era, and with Shropshire itself.\n\nHousman was one of the foremost classicists of his age and has been ranked as one of the greatest scholars who ever lived. He established his reputation publishing as a private scholar and, on the strength and quality of his work, was appointed Professor of Latin at University College London and then at Cambridge. His editions of Juvenal, Manilius and Lucan are still considered authoritative.\n\nThe eldest of seven children, Housman was born at Valley House in Fockbury, a hamlet on the outskirts of Bromsgrove in Worcestershire, to Sarah Jane (née Williams, married 17 June 1858 in Woodchester, Gloucester) and Edward Housman (whose family came from Lancaster), and was baptised on 24 April 1859 at Christ Church, in Catshill. His mother died on his twelfth birthday, and his father, a country solicitor, remarried, to an elder cousin, Lucy, in 1873. Housman's brother Laurence Housman and their sister Clemence Housman also became writers.\n\nHousman was educated at King Edward's School in Birmingham and later Bromsgrove School, where he revealed his academic promise and won prizes for his poems. In 1877 he won an open scholarship to St John's College, Oxford, where he studied classics. Although introverted by nature, Housman formed strong friendships with two roommates, Moses Jackson and A. W. Pollard. Jackson became the great love of Housman's life, but he was heterosexual and did not reciprocate Housman's feelings. Housman became an atheist while attending Oxford. Housman obtained a first in classical Moderations in 1879, but his dedication to textual analysis, particularly of Propertius, led him to neglect the ancient history and philosophy that formed part of the Greats curriculum. Accordingly, he failed to obtain a degree. Though some attribute Housman's unexpected failure in his final exams directly to his rejection by Jackson, most biographers adduce more obvious causes. Housman was indifferent to philosophy and overconfident in his exceptional gifts; he felt contempt for inexact scholarship; and he enjoyed idling away his time with Jackson and others. He may also have been distracted by news of his father's desperate illness. He felt deeply humiliated by his failure and became determined to vindicate his genius.\nAfter Oxford, Jackson got a job as a clerk in the Patent Office in London and arranged a job there for Housman too. The two shared a flat with Jackson's brother Adalbert until 1885, when Housman moved to lodgings of his own, probably after Jackson responded to a declaration of love by telling Housman that he could not reciprocate his feelings. Moses Jackson moved to India in 1887, placing more distance between himself and Housman. When Jackson returned briefly to England in 1889, to marry, Housman was not invited to the wedding and knew nothing about it until the couple had left the country. Adalbert Jackson died in 1892 and Housman commemorated him in a poem published as \"XLII – A.J.J.\" of \"More Poems\" (1936).\n\nMeanwhile, Housman pursued his classical studies independently, and published scholarly articles on such authors as Horace, Propertius, Ovid, Aeschylus, Euripides and Sophocles. He gradually acquired such a high reputation that in 1892 he was offered and accepted the professorship of Latin at University College London (UCL).\n\nWhen R. W. Chambers discovered an immensely rare original Coverdale Bible of 1535 in the UCL library he presented it to the Library Committee, where Housman remarked that it would be better to sell it to \"buy some really useful books with the proceeds\". Many years later UCL's academic common room was dedicated to his memory as the Housman Room.\n\nIn his private life Housman enjoyed gastronomy, flying in aeroplanes and making frequent visits to France, where he read \"books which were banned in Britain as pornographic\". A. C. Benson, a fellow don, described him as being \"descended from a long line of maiden aunts\".\n\nAlthough Housman's early work and his responsibilities as a professor included both Latin and Greek, he began to specialise in Latin poetry. When asked later why he had stopped writing about Greek verse, he responded, \"I found that I could not attain to excellence in both.\"\n\nIn 1911 he took the Kennedy Professorship of Latin at Trinity College, Cambridge, where he remained for the rest of his life. G. P. Goold, Classics Professor at University College, wrote of Housman's accomplishments: \"The legacy of Housman's scholarship is a thing of permanent value; and that value consists less in obvious results, the establishment of general propositions about Latin and the removal of scribal mistakes, than in the shining example he provides of a wonderful mind at work. … He was and may remain the last great textual critic.\" Between 1903 and 1930 Housman published his critical edition of Manilius's \"Astronomicon\" in five volumes. He also edited works by Juvenal (1905) and Lucan (1926). Many colleagues were unnerved by his scathing attacks on those he thought guilty of shoddy scholarship. In his paper \"The Application of Thought to Textual Criticism\" (1921) Housman wrote: \"A textual critic engaged upon his business is not at all like Newton investigating the motion of the planets: he is much more like a dog hunting for fleas.\" He declared many of his contemporary scholars to be stupid, lazy, vain, or all three, saying: \"Knowledge is good, method is good, but one thing beyond all others is necessary; and that is to have a head, not a pumpkin, on your shoulders, and brains, not pudding, in your head.\" \n\nHis younger colleague A. S. F. Gow quoted examples of these attacks, noting that they \"were often savage in the extreme\". Gow also related how Housman intimidated his students, sometimes reducing them to tears. According to Gow, Housman could never remember his students' names, maintaining that \"had he burdened his memory by the distinction between Miss Jones and Miss Robinson, he might have forgotten that between the second and fourth declension\". One notable pupil was Enoch Powell. Housman found his true vocation in classical studies and treated his poems as secondary. He did not speak about his poetry in public until 1933 when he gave a lecture, \"The Name and Nature of Poetry\", in which he argued that poetry should appeal to emotions rather than to the intellect.\n\nHousman died, aged 77, in Cambridge. His ashes are buried just outside St Laurence's Church, Ludlow, Shropshire.\n\nDuring his years in London, A. E. Housman completed \"A Shropshire Lad\", a cycle of 63 poems. After one publisher had turned it down, he helped subsidise its publication in 1896. At first selling slowly, it rapidly became a lasting success. Its appeal to English musicians had helped to make it widely known before World War I, when its themes struck a powerful chord with English readers. The book has been in print continuously since May 1896.\n\nThe poems are marked by pessimism and preoccupation with death, without religious consolation. Housman wrote many of them while living in Highgate, London, before ever visiting Shropshire, which he presented in an idealised pastoral light as his 'land of lost content'. Housman himself acknowledged that \"No doubt I have been unconsciously influenced by the Greeks and Latins, but [the] chief sources of which I am conscious are Shakespeare’s songs, the Scottish Border ballads, and Heine.”\n\nHousman began writing a new set of poems after the First World War. He was an influence on many British poets who became famous by their writing about the war, and wrote several poems as occasional verse to commemorate the war dead. This included his \"Epitaph on an Army of Mercenaries\", honouring the British Expeditionary Force, an elite but small force of professional soldiers, 'a rapier amongst scythes' sent to Belgium at the start of the war. Fighting a well-equipped and much larger German army, they suffered heavy losses.\n\nIn the early 1920s, when Moses Jackson was dying in Canada, Housman wanted to assemble his best unpublished poems so that Jackson could read them before his death. These later poems, mostly written before 1910, show a greater variety of subject and form than those in \"A Shropshire Lad\" but lack the consistency of his previously published work. He published them as \"Last Poems\" (1922), feeling that his inspiration was exhausted and that he should not publish more in his lifetime. After his death Housman's brother, Laurence, published further poems in \"More Poems\" (1936), \"A. E .H.: Some Poems, Some Letters and a Personal Memoir by his Brother\" (1937), and \"Collected Poems\" (1939). \"A. E. H.\" includes humorous verse such as a parody of Longfellow's poem \"Excelsior\". Housman also wrote a parodic \"Fragment of a Greek Tragedy\", in English, published posthumously with humorous poems under the title \"Unkind to Unicorns\".\n\nJohn Sparrow quoted a letter written late in Housman's life that described the genesis of his poems:\nSparrow himself adds, \"How difficult it is to achieve a satisfactory analysis may be judged by considering the last poem in \"A Shropshire Lad\". Of its four stanzas, Housman tells us that two were 'given' him ready made; one was coaxed forth from his subconsciousness an hour or two later; the remaining one took months of conscious composition. No one can tell for certain which was which.\"\n\nIn 1942 Laurence Housman also deposited an essay entitled \"A. E. Housman's 'De Amicitia'\" in the British Library, with the proviso that it was not to be published for 25 years. The essay discussed A. E. Housman's homosexuality and his love for Moses Jackson. Despite the conservative nature of the times and his own caution in public life, Housman was quite open in his poetry, and especially in \"A Shropshire Lad\", about his deeper sympathies. Poem XXX of that sequence, for instance, speaks of how \"Fear contended with desire\": \"Others, I am not the first, / Have willed more mischief than they durst\". In \"More Poems\", he buries his love for Moses Jackson in the very act of commemorating it, as his feelings of love are not reciprocated and must be carried unfulfilled to the grave:\n\n<poem>\n\n</poem>\n\nHis poem \"Oh who is that young sinner with the handcuffs on his wrists?\", written after the trial of Oscar Wilde, addressed more general attitudes towards homosexuals. In the poem the prisoner is suffering \"for the colour of his hair\", a natural quality that, in a coded reference to homosexuality, is reviled as \"nameless and abominable\" (recalling the legal phrase \"peccatum illud horribile, inter Christianos non nominandum\", \"that horrible sin, not to be named amongst Christians\").\n\nHousman's poetry, especially \"A Shropshire Lad\", was set to music by many British, and in particular English, composers in the first half of the 20th century. The national, pastoral and traditional elements of his style resonated with similar trends in English music. In 1904 the cycle \"A Shropshire Lad\" was set by Arthur Somervell, who had begun to develop the concept of the English song-cycle in his version of Tennyson's \"Maud\" a little previously. Ralph Vaughan Williams produced his most famous settings of six songs, the cycle \"On Wenlock Edge\", for string quartet, tenor and piano (dedicated to Gervase Elwes) in 1909, and it became very popular after Elwes recorded it with the London String Quartet and Frederick B. Kiddle in 1917. Between 1909 and 1911 George Butterworth produced settings in two collections or cycles, as \"Six Songs from A Shropshire Lad\", and \"Bredon Hill and Other Songs\". He also wrote an orchestral tone poem on \"A Shropshire Lad\", first performed at Leeds Festival under Arthur Nikisch in 1912.\n\nIvor Gurney, another most important setter of Housman, composed a work for voice and string quartet(\"Ludlow and Teme\"), and a song-cycle on Housman works, both of which won the Carnegie Award). The fatalism of the poems and their earlier settings foreshadowed responses to the universal bereavement of the First World War and became assimilated into them. This was reinforced when their foremost interpreter and performer, Gervase Elwes, who died in an accident in 1921. \n\nAmong other composers who set Housman songs were John Ireland (song cycle, \"The Land of Lost Content\" (192021)), Michael Head (e.g. 'Ludlow Fair'), Graham Peel (a famous version of 'In Summertime on Bredon'), Ian Venables (Songs of Eternity and Sorrow), and the American Samuel Barber (e.g. 'With rue my heart is laden'). Gerald Finzi began several settings, but never finished them. Even composers not directly associated with the 'pastoral' tradition, such as Arnold Bax, Lennox Berkeley and Arthur Bliss, were attracted to Housman's poetry. A 1976 catalogue listed 400 musical settings of Housman's poems. As of 2016, Lieder Net Archive records 606 settings of 187 texts.\n\nThe earliest commemoration of Housman was in his college chapel in Cambridge, where there is a memorial brass on the south wall. The Latin inscription was composed by his colleague there, A.S.F. Gow, who was also the author of a biographical and bibliographical sketch published immediately following his death. The memorial reads:\nBlue plaques followed later, the first being on Byron Cottage in Highgate in 1969, recording the fact that \"A Shropshire Lad\" was written there. More followed on his Worcestershire birthplace, his homes and school in Bromsgrove. The latter were encouraged by the Housman Society, which was founded in the town in 1973. Another initiative was the statue in Bromsgrove High Street, showing the poet striding with walking stick in hand. The work of local sculptor Kenneth Potts, it was unveiled on 22 March 1985.\n\nThe blue plaques in Worcestershire were set up on the centenary of \"A Shropshire Lad\" in 1996. In September of the same year a memorial window lozenge was dedicated at Poets' Corner in Westminster Abbey The following year saw the première of Tom Stoppard's play \"The Invention of Love\", whose subject is the relationship between Housman and Moses Jackson.\n\nAs the 150th anniversary of his birth approached, London University inaugurated its Housman lectures on classical subjects in 2005, initially given every second year then annually after 2011. The anniversary itself in 2009 saw the launch of a new edition of \"A Shropshire Lad\", including pictures from across Shropshire taken by local photographer Gareth Thomas. Among other events, there were performances of Vaughan Williams' \"On Wenlock Edge\" and Gurney's \"Ludlow and Teme\" at St Laurence's Church in Ludlow.\n\n\n\nThese lectures are listed by date of delivery, with date of first publication given separately if different.\n\n\"Selected Prose\", edited by John Carter, Cambridge University Press, 1961\n\n\n\n\n\n\n", "id": "3198", "title": "A. E. Housman"}
{"url": "https://en.wikipedia.org/wiki?curid=3201", "text": "Attribution of recent climate change\n\nAttribution of recent climate change is the effort to scientifically ascertain mechanisms responsible for recent climate changes on Earth, commonly known as 'global warming'. The effort has focused on changes observed during the period of instrumental temperature record, when records are most reliable; particularly in the last 50 years, when human activity has grown fastest and observations of the troposphere have become available. The dominant mechanisms are anthropogenic, i.e., the result of human activity. They are:\n\nThere are also natural mechanisms for variation including climate oscillations, changes in solar activity, and volcanic activity.\n\nAccording to the Intergovernmental Panel on Climate Change (IPCC), it is \"extremely likely\" that human influence was the dominant cause of global warming between 1951 and 2010. The IPCC defines \"extremely likely\" as indicating a probability of 95 to 100%, based on an expert assessment of all the available evidence.\n\nMultiple lines of evidence support attribution of recent climate change to human activities:\n\nThe IPCC's attribution of recent global warming to human activities is a view shared by the scientific community, and is also supported by 196 other scientific organizations worldwide (see also: scientific opinion on climate change).\n\nThis section introduces some concepts in climate science that are used in the following sections:\n\nFactors affecting Earth's climate can be broken down into feedbacks and forcings.\nA forcing is something that is imposed externally on the climate system. External forcings include natural phenomena such as volcanic eruptions and variations in the sun's output. Human activities can also impose forcings, for example, through changing the composition of the atmosphere.\n\nRadiative forcing is a measure of how various factors alter the energy balance of the Earth's atmosphere. A positive radiative forcing will tend to increase the energy of the Earth-atmosphere system, leading to a warming of the system. Between the start of the Industrial Revolution in 1750, and the year 2005, the increase in the atmospheric concentration of carbon dioxide (chemical formula: CO) led to a positive radiative forcing, averaged over the Earth's surface area, of about 1.66 watts per square metre (abbreviated W m).\n\nClimate feedbacks can either amplify or dampen the response of the climate to a given forcing.\nThere are many feedback mechanisms in the climate system that can either amplify (a positive feedback) or diminish (a negative feedback) the effects of a change in climate forcing.\n\nAspects of the climate system will show variation in response to changes in forcings.\nIn the absence of forcings imposed on it, the climate system will still show internal variability (see images opposite). This internal variability is a result of complex interactions between components of the climate system, such as the coupling between the atmosphere and ocean (see also the later section on Internal climate variability and global warming). An example of internal variability is the El Niño-Southern Oscillation.\n\nDetection and attribution of climate signals, as well as its common-sense meaning, has a more precise definition within the climate change literature, as expressed by the IPCC. Detection of a climate signal does not always imply significant attribution. The IPCC's Fourth Assessment Report says \"it is \"extremely likely\" that human activities have exerted a substantial net warming influence on climate since 1750,\" where \"extremely likely\" indicates a probability greater than 95%. \"Detection\" of a signal requires demonstrating that an observed change is statistically significantly different from that which can be explained by natural internal variability.\n\n\"Attribution\" requires demonstrating that a signal is:\n\nCarbon dioxide is the primary greenhouse gas that is contributing to recent climate change. is absorbed and emitted naturally as part of the carbon cycle, through animal and plant respiration, volcanic eruptions, and ocean-atmosphere exchange. Human activities, such as the burning of fossil fuels and changes in land use (see below), release large amounts of carbon to the atmosphere, causing concentrations in the atmosphere to rise.\n\nThe high-accuracy measurements of atmospheric CO concentration, initiated by Charles David Keeling in 1958, constitute the master time series documenting the changing composition of the atmosphere. These data have iconic status in climate change science as evidence of the effect of human activities on the chemical composition of the global atmosphere.\n\nAlong with CO, methane and nitrous oxide are also major forcing contributors to the greenhouse effect. The Kyoto Protocol lists these together with hydrofluorocarbons (HFCs), perfluorocarbons (PFCs), and sulphur hexafluoride (SF), which are entirely artificial (i.e. anthropogenic) gases, which also contribute to radiative forcing in the atmosphere. The chart at right attributes anthropogenic greenhouse gas emissions to eight main economic sectors, of which the largest contributors are power stations (many of which burn coal or other fossil fuels), industrial processes, transportation fuels (generally fossil fuels), and agricultural by-products (mainly methane from enteric fermentation and nitrous oxide from fertilizer use).\n\nWater vapor is the most abundant greenhouse gas and also the most important in terms of its contribution to the natural greenhouse effect, despite having a short atmospheric lifetime (about 10 days). Some human activities can influence local water vapor levels. However, on a global scale, the concentration of water vapor is controlled by temperature, which influences overall rates of evaporation and precipitation. Therefore, the global concentration of water vapor is not substantially affected by direct human emissions.\n\nClimate change is attributed to land use for two main reasons. Between 1750 and 2007, about two-thirds of anthropogenic emissions were produced from burning fossil fuels, and about one-third of emissions from changes in land use, primarily deforestation. Deforestation both reduces the amount of carbon dioxide absorbed by deforested regions and releases greenhouse gases directly, together with aerosols, through biomass burning that frequently accompanies it.\n\nA second reason that climate change has been attributed to land use is that the terrestrial albedo is often altered by use, which leads to radiative forcing. This effect is more significant locally than globally.\n\nWorldwide, livestock production occupies 70% of all land used for agriculture, or 30% of the ice-free land surface of the Earth.\nMore than 18% of anthropogenic greenhouse gas emissions are attributed to livestock and livestock-related activities such as deforestation and increasingly fuel-intensive farming practices. Specific attributions to the livestock sector include:\n\nWith virtual certainty, scientific consensus has attributed various forms of climate change, chiefly cooling effects, to aerosols, which are small particles or droplets suspended in the atmosphere.\nKey sources to which anthropogenic aerosols are attributed include:\n\nOver the past 150 years human activities have released increasing quantities of greenhouse gases into the atmosphere. This has led to increases in mean global temperature, or global warming. Other human effects are relevant—for example, sulphate aerosols are believed to have a cooling effect. Natural factors also contribute. According to the historical temperature record of the last century, the Earth's near-surface air temperature has risen around 0.74 ± 0.18 °Celsius (1.3 ± 0.32 °Fahrenheit).\n\nA historically important question in climate change research has regarded the relative importance of human activity and non-anthropogenic causes during the period of instrumental record. In the 1995 Second Assessment Report (SAR), the IPCC made the widely quoted statement that \"The balance of evidence suggests a discernible human influence on global climate\". The phrase \"balance of evidence\" suggested the (English) common-law standard of proof required in civil as opposed to criminal courts: not as high as \"beyond reasonable doubt\". In 2001 the Third Assessment Report (TAR) refined this, saying \"There is new and stronger evidence that most of the warming observed over the last 50 years is attributable to human activities\". The 2007 Fourth Assessment Report (AR4) strengthened this finding:\n\nOther findings of the IPCC Fourth Assessment Report include:\n\nOver the past five decades there has been a global warming of approximately 0.65 °C (1.17 °F) at the Earth's surface (see historical temperature record). Among the possible factors that could produce changes in global mean temperature are internal variability of the climate system, external forcing, an increase in concentration of greenhouse gases, or any combination of these. Current studies indicate that the increase in greenhouse gases, most notably , is mostly responsible for the observed warming. Evidence for this conclusion includes:\n\nRecent scientific assessments find that most of the warming of the Earth's surface over the past 50 years has been caused by human activities (see also the section on scientific literature and opinion). This conclusion rests on multiple lines of evidence. Like the warming \"signal\" that has gradually emerged from the \"noise\" of natural climate variability, the scientific evidence for a human influence on global climate has accumulated over the past several decades, from many hundreds of studies. No single study is a \"smoking gun.\" Nor has any single study or combination of studies undermined the large body of evidence supporting the conclusion that human activity is the primary driver of recent warming.\n\nThe first line of evidence is based on a physical understanding of how greenhouse gases trap heat, how the climate system responds to increases in greenhouse gases, and how other human and natural factors influence climate. The second line of evidence is from indirect estimates of climate changes over the last 1,000 to 2,000 years. These records are obtained from living things and their remains (like tree rings and corals) and from physical quantities (like the ratio between lighter and heavier isotopes of oxygen in ice cores), which change in measurable ways as climate changes. The lesson from these data is that global surface temperatures over the last several decades are clearly unusual, in that they were higher than at any time during at least the past 400 years. For the Northern Hemisphere, the recent temperature rise is clearly unusual in at least the last 1,000 years (see graph opposite).\n\nThe third line of evidence is based on the broad, qualitative consistency between observed changes in climate and the computer model simulations of how climate would be expected to change in response to human activities. For example, when climate models are run with historical increases in greenhouse gases, they show gradual warming of the Earth and ocean surface, increases in ocean heat content and the temperature of the lower atmosphere, a rise in global sea level, retreat of sea ice and snow cover, cooling of the stratosphere, an increase in the amount of atmospheric water vapor, and changes in large-scale precipitation and pressure patterns. These and other aspects of modelled climate change are in agreement with observations.\n\nFinally, there is extensive statistical evidence from so-called \"fingerprint\" studies. Each factor that affects climate produces a unique pattern of climate response, much as each person has a unique fingerprint. Fingerprint studies exploit these unique signatures, and allow detailed comparisons of modelled and observed climate change patterns. Scientists rely on such studies to attribute observed changes in climate to a particular cause or set of causes. In the real world, the climate changes that have occurred since the start of the Industrial Revolution are due to a complex mixture of human and natural causes. The importance of each individual influence in this mixture changes over time. Of course, there are not multiple Earths, which would allow an experimenter to change one factor at a time on each Earth, thus helping to isolate different fingerprints. Therefore, climate models are used to study how individual factors affect climate. For example, a single factor (like greenhouse gases) or a set of factors can be varied, and the response of the modelled climate system to these individual or combined changes can thus be studied.\nFor example, when climate model simulations of the last century include all of the major influences on climate, both human-induced and natural, they can reproduce many important features of observed climate change patterns. When human influences are removed from the model experiments, results suggest that the surface of the Earth would actually have cooled slightly over the last 50 years (see graph, opposite). The clear message from fingerprint studies is that the observed warming over the last half-century cannot be explained by natural factors, and is instead caused primarily by human factors.\n\nAnother fingerprint of human effects on climate has been identified by looking at a slice through the layers of the atmosphere, and studying the pattern of temperature changes from the surface up through the stratosphere (see the section on solar activity). The earliest fingerprint work focused on changes in surface and atmospheric temperature. Scientists then applied fingerprint methods to a whole range of climate variables, identifying human-caused climate signals in the heat content of the oceans, the height of the tropopause (the boundary between the troposphere and stratosphere, which has shifted upward by hundreds of feet in recent decades), the geographical patterns of precipitation, drought, surface pressure, and the runoff from major river basins.\n\nStudies published after the appearance of the IPCC Fourth Assessment Report in 2007 have also found human fingerprints in the increased levels of atmospheric moisture (both close to the surface and over the full extent of the atmosphere), in the decline of Arctic sea ice extent, and in the patterns of changes in Arctic and Antarctic surface temperatures.\n\nThe message from this entire body of work is that the climate system is telling a consistent story of increasingly dominant human influence – the changes in temperature, ice extent, moisture, and circulation patterns fit together in a physically consistent way, like pieces in a complex puzzle.\n\nIncreasingly, this type of fingerprint work is shifting its emphasis. As noted, clear and compelling scientific evidence supports the case for a pronounced human influence on global climate. Much of the recent attention is now on climate changes at continental and regional scales, and on variables that can have large impacts on societies. For example, scientists have established causal links between human activities and the changes in snowpack, maximum and minimum (diurnal) temperature, and the seasonal timing of runoff over mountainous regions of the western United States. Human activity is likely to have made a substantial contribution to ocean surface temperature changes in hurricane formation regions. Researchers are also looking beyond the physical climate system, and are beginning to tie changes in the distribution and seasonal behaviour of plant and animal species to human-caused changes in temperature and precipitation.\n\nFor over a decade, one aspect of the climate change story seemed to show a significant difference between models and observations. In the tropics, all models predicted that with a rise in greenhouse gases, the troposphere would be expected to warm more rapidly than the surface. Observations from weather balloons, satellites, and surface thermometers seemed to show the opposite behaviour (more rapid warming of the surface than the troposphere). This issue was a stumbling block in understanding the causes of climate change. It is now largely resolved. Research showed that there were large uncertainties in the satellite and weather balloon data. When uncertainties in models and observations are properly accounted for, newer observational data sets (with better treatment of known problems) are in agreement with climate model results.\n\nThis does not mean, however, that all remaining differences between models and observations have been resolved. The observed changes in some climate variables, such as Arctic sea ice, some aspects of precipitation, and patterns of surface pressure, appear to be proceeding much more rapidly than models have projected. The reasons for these differences are not well understood. Nevertheless, the bottom-line conclusion from climate fingerprinting is that most of the observed changes studied to date are consistent with each other, and are also consistent with our scientific understanding of how the climate system would be expected to respond to the increase in heat-trapping gases resulting from human activities.\n\nOne of the subjects discussed in the literature is whether or not extreme weather events can be attributed to human activities. Seneviratne \"et al.\" (2012) stated that attributing individual extreme weather events to human activities was challenging. They were, however, more confident over attributing changes in long-term trends of extreme weather. For example, Seneviratne \"et al.\" (2012) concluded that human activities had likely led to a warming of extreme daily minimum and maximum temperatures at the global scale.\n\nAnother way of viewing the problem is to consider the effects of human-induced climate change on the probability of future extreme weather events. Stott \"et al.\" (2003), for example, considered whether or not human activities had increased the risk of severe heat waves in Europe, like the one experienced in 2003. Their conclusion was that human activities had very likely more than doubled the risk of heat waves of this magnitude.\n\nAn analogy can be made between an athlete on steroids and human-induced climate change. In the same way that an athlete's performance may increase from using steroids, human-induced climate change increases the risk of some extreme weather events.\n\nHansen \"et al.\" (2012) suggested that human activities have greatly increased the risk of summertime heat waves. According to their analysis, the land area of the Earth affected by very hot summer temperature anomalies has greatly increased over time (refer to graphs on the left). In the base period 1951-1980, these anomalies covered a few tenths of 1% of the global land area. In recent years, this has increased to around 10% of the global land area. With high confidence, Hansen \"et al.\" (2012) attributed the 2010 Moscow and 2011 Texas heat waves to human-induced global warming.\n\nAn earlier study by Dole \"et al.\" (2011) concluded that the 2010 Moscow heatwave was mostly due to natural weather variability. While not directly citing Dole \"et al.\" (2011), Hansen \"et al.\" (2012) rejected this type of explanation. Hansen \"et al.\" (2012) stated that a combination of natural weather variability and human-induced global warming was responsible for the Moscow and Texas heat waves.\n\nThere are a number of examples of published and informal support for the consensus view. As mentioned earlier, the IPCC has concluded that most of the observed increase in globally averaged temperatures since the mid-20th century is \"very likely\" due to human activities. The IPCC's conclusions are consistent with those of several reports produced by the US National Research Council.\nA report published in 2009 by the U.S. Global Change Research Program concluded that \"[global] warming is unequivocal and primarily human-induced.\"\nA number of scientific organizations have issued statements that support the consensus view. Two examples include:\n\nThe IPCC Fourth Assessment Report (2007), concluded that attribution was possible for a number of observed changes in the climate (see effects of global warming). However, attribution was found to be more difficult when assessing changes over smaller regions (less than continental scale) and over short time periods (less than 50 years).\nOver larger regions, averaging reduces natural variability of the climate, making detection and attribution easier.\n\n\n\nAs described above, a small minority of scientists do disagree with the consensus: see list of scientists opposing global warming consensus. For example, Willie Soon and Richard Lindzen say that there is insufficient proof for anthropogenic attribution. Generally this position requires new physical mechanisms to explain the observed warming.\n\nSolar sunspot maximum occurs when the magnetic field of the sun collapses and reverse as part of its average 11 year solar cycle (22 years for complete North to North restoration).\n\nThe role of the sun in recent climate change has been looked at by climate scientists. Since 1978, output from the Sun has been measured by satellites significantly more accurately than was previously possible from the surface. These measurements indicate that the Sun's total solar irradiance has not increased since 1978, so the warming during the past 30 years cannot be directly attributed to an increase in total solar energy reaching the Earth (see graph above, left). In the three decades since 1978, the combination of solar and volcanic activity probably had a slight cooling influence on the climate.\n\nClimate models have been used to examine the role of the sun in recent climate change.\nModels are unable to reproduce the rapid warming observed in recent decades when they only take into account variations in total solar irradiance and volcanic activity. Models are, however, able to simulate the observed 20th century changes in temperature when they include all of the most important external forcings, including human influences and natural forcings. As has already been stated, Hegerl \"et al.\" (2007) concluded that greenhouse gas forcing had \"very likely\" caused most of the observed global warming since the mid-20th century. In making this conclusion, Hegerl \"et al.\" (2007) allowed for the possibility that climate models had been underestimated the effect of solar forcing.\n\nThe role of solar activity in climate change has also been calculated over longer time periods using \"proxy\" datasets, such as tree rings.\nModels indicate that solar and volcanic forcings can explain periods of relative warmth and cold between A.D. 1000 and 1900, but human-induced forcings are needed to reproduce the late-20th century warming.\n\nAnother line of evidence against the sun having caused recent climate change comes from looking at how temperatures at different levels in the Earth's atmosphere have changed.\nModels and observations (see figure above, middle) show that greenhouse gas results in warming of the lower atmosphere at the surface (called the troposphere) but cooling of the upper atmosphere (called the stratosphere). Depletion of the ozone layer by chemical refrigerants has also resulted in a cooling effect in the stratosphere. If the sun was responsible for observed warming, warming of the troposphere at the surface and warming at the top of the stratosphere would be expected as increase solar activity would replenish ozone and oxides of nitrogen. The stratosphere has a reverse temperature gradient than the troposphere so as the temperature of the troposphere cools with altitude, the stratosphere rises with altitude. Hadley cells are the mechanism by which equatorial generated ozone in the tropics (highest area of UV irradiance in the stratosphere) is moved poleward. Global climate models suggest that climate change may widen the Hadley cells and push the jetstream northward thereby expanding the tropics region and resulting in warmer, dryer conditions in those areas overall.\n\nHabibullo Abdussamatov (2004), head of space research at St. Petersburg's Pulkovo Astronomical Observatory in Russia, has argued that the sun is responsible for recently observed climate change. Journalists for news sources canada.com (Solomon, 2007b), National Geographic News (Ravillious, 2007), and LiveScience (Than, 2007) reported on the story of warming on Mars. In these articles, Abdussamatov was quoted. He stated that warming on Mars was evidence that global warming on Earth was being caused by changes in the sun.\n\nRavillious (2007) quoted two scientists who disagreed with Abdussamatov: Amato Evan, a climate scientist at the University of Wisconsin-Madison, in the US, and Colin Wilson, a planetary physicist at Oxford University in the UK. According to Wilson, \"Wobbles in the orbit of Mars are the main cause of its climate change in the current era\" (see also orbital forcing). Than (2007) quoted Charles Long, a climate physicist at Pacific Northwest National Laboratories in the US, who disagreed with Abdussamatov.\n\nThan (2007) pointed to the view of Benny Peiser, a social anthropologist at Liverpool John Moores University in the UK. In his newsletter, Peiser had cited a blog that had commented on warming observed on several planetary bodies in the Solar system. These included Neptune's moon Triton, Jupiter, Pluto and Mars. In an e-mail interview with Than (2007), Peiser stated that:\"I think it is an intriguing coincidence that warming trends have been observed on a number of very diverse planetary bodies in our solar system, (...) Perhaps this is just a fluke.\"Than (2007) provided alternative explanations of why warming had occurred on Triton, Pluto, Jupiter and Mars.\n\nThe US Environmental Protection Agency (US EPA, 2009) responded to public comments on climate change attribution. A number of commenters had argued that recent climate change could be attributed to changes in solar irradiance. According to the US EPA (2009), this attribution was not supported by the bulk of the scientific literature. Citing the work of the IPCC (2007), the US EPA pointed to the low contribution of solar irradiance to radiative forcing since the start of the Industrial Revolution in 1750. Over this time period (1750 to 2005), the estimated contribution of solar irradiance to radiative forcing was 5% the value of the combined radiative forcing due to increases in the atmospheric concentrations of carbon dioxide, methane and nitrous oxide (see graph opposite).\n\nHenrik Svensmark has suggested that the magnetic activity of the sun deflects cosmic rays, and that this may influence the generation of cloud condensation nuclei, and thereby have an effect on the climate. The website ScienceDaily reported on a 2009 study that looked at how past changes in climate have been affected by the Earth's magnetic field. Geophysicist Mads Faurschou Knudsen, who co-authored the study, stated that the study's results supported Svensmark's theory. The authors of the study also acknowledged that plays an important role in climate change.\n\nThe view that cosmic rays could provide the mechanism by which changes in solar activity affect climate is not supported by the literature. Solomon \"et al.\" (2007) state:[..] the cosmic ray time series does not appear to correspond to global total cloud cover after 1991 or to global low-level cloud cover after 1994. Together with the lack of a proven physical mechanism and the plausibility of other causal factors affecting changes in cloud cover, this makes the association between galactic cosmic ray-induced changes in aerosol and cloud formation controversial\n\nStudies by Lockwood and Fröhlich (2007) and Sloan and Wolfendale (2008) found no relation between warming in recent decades and cosmic rays. Pierce and Adams (2009) used a model to simulate the effect of cosmic rays on cloud properties. They concluded that the hypothesized effect of cosmic rays was too small to explain recent climate change. Pierce and Adams (2009) noted that their findings did not rule out a possible connection between cosmic rays and climate change, and recommended further research.\n\nErlykin \"et al.\" (2009) found that the evidence showed that connections between solar variation and climate were more likely to be mediated by direct variation of insolation rather than cosmic rays, and concluded: \"Hence within our assumptions, the effect of varying solar activity, either by direct solar irradiance or by varying cosmic ray rates, must be less than 0.07 °C since 1956, i.e. less than 14% of the observed global warming.\" Carslaw (2009) and Pittock (2009) review the recent and historical literature in this field and continue to find that the link between cosmic rays and climate is tenuous, though they encourage continued research. US EPA (2009) commented on research by Duplissy \"et al.\" (2009):The CLOUD experiments at CERN are interesting research but do not provide conclusive evidence that cosmic rays can serve as a major source of cloud seeding. Preliminary results from the experiment (Duplissy et al., 2009) suggest that though there was some evidence of ion mediated nucleation, for most of the nucleation events observed the contribution of ion processes appeared to be minor. These experiments also showed the difficulty in maintaining sufficiently clean conditions and stable temperatures to prevent spurious aerosol bursts. There is no indication that the earlier Svensmark experiments could even have matched the controlled conditions of the CERN experiment. We find that the Svensmark results on cloud seeding have not yet been shown to be robust or sufficient to materially alter the conclusions of the assessment literature, especially given the abundance of recent literature that is skeptical of the cosmic ray-climate linkage\n\n\n\nPublic-domain sources\n\n", "id": "3201", "title": "Attribution of recent climate change"}
{"url": "https://en.wikipedia.org/wiki?curid=3203", "text": "Achduart\n\nAchduart (Gaelic: Achadh Dhubhaird) is a small hamlet in Coigach, in Wester Ross in northwestern Scotland, now within the Highland council area. It is situated about 4 km southeast of the village of Achiltibuie, at the end of a minor road. A footpath continues on to the hamlet of Culnacraig, then along the coast past Ben More Coigach to Strathcanaird. \nAchduart has accommodation facilities for tourists, who come for its proximity to the ocean as well as its seclusion and remoteness. There is a Scottish Youth Hostels Association hostel in Acheninver, a short distance to the north.\n\nThe name of Achduart comes from the Gaelic for \"the field at the black headland\". Achduart was part of the Estate of Coigach, Lochbroom, belonging to the Countess of Cromartie.\n\nThe dominant geographical feature in the area is Cairn Conmheall, which rises to 541 metres.\n\n\n", "id": "3203", "title": "Achduart"}
{"url": "https://en.wikipedia.org/wiki?curid=3204", "text": "Achiltibuie\n\nAchiltibuie (; or \"Field of the yellow-haired boy\") is a long linear village in Ross and Cromarty, Highland, on the Coigach coast of northwestern Scotland, overlooking Badentarbet Bay to the west. Loch Broom and the Summer Isles lie to the south. Located 10 miles (16 km) northwest of Ullapool as the crow flies. Achiltibuie is the central community of a series of townships and communities stretching from Culnacraig, through Badenscallie and Polglass (where the community hall, the primary school and the Piping School are located), Polbain, and Reiff to Achnahaird.\n\nThe first post office in the village opened on 28 July 1884.\n\nFor a time the \"Summer Isles Smokehouse\" attracted visitors. In 2013 the community had hopes to re-establish the business.\n\nThe Hydroponicum, a facility for growing fresh fruit and vegetables indoors using hydroponics, was built in the village in the 1980s by Robert Irvine, then owner of the Summer Isles Hotel. The Hydroponicum was known for growing exotic fruit such as bananas all year round. It attracted up to 10,000 visitors a year until it was sold in 2007 to a company based in the Isle of Man. New greenhouses have since been built apart from the original hydroponicum buildings, and the new owners continue to grow fruit and vegetables for local businesses and residents. A community buyout attempt in 2011 by the Coigach Community Development Company fell through when the site's sellers pulled out. The building has now been demolished. Some of the former staff of the Hydroponicum run a small-scale activity known as The Achiltibuie Garden, situated nearby.\n\n\n'Coigach Community Rowing' the crew members of which coastal rowing club are all local, won the World St. Ayles Skiff Rowing Championships in July 2013 and a mixed crew from the club won the Alan Spong Trophy for 1st Mixed crew 4-oar rowing at the Thames Great River Race in September 2013. Coigach Community Rowing hand-built their two St Ayles rowing skiffs, the 'Coigach Lass' and the 'Lily~Rose' and race under the auspices of the Scottish Coastal Rowing Association, which is the governing body of St Ayles class coastal rowing around the world.\nThe Roman epic The Eagle, based on the 1954 novel \"The Eagle of the Ninth\" by Rosemary Sutcliff, was filmed on location in Achiltibuie for a week in October 2009. The main location was Fox Point, Old Dornie. The Pictish village which was constructed at Fox Point was used on most days of the filming. Other sites included Achnahaird beach where a horse chase was filmed and Loch Lurgainn.\n\nThe village and its residents featured in \"The Wee Mad Road\" (2008) by Jack and Barbara Maloney.\n\n", "id": "3204", "title": "Achiltibuie"}
{"url": "https://en.wikipedia.org/wiki?curid=3205", "text": "Adaptive expectations\n\nIn economics, adaptive expectations is a hypothesized process by which people form their expectations about what will happen in the future based on what has happened in the past. For example, if inflation has been higher than expected in the past, people would revise expectations for the future.\n\nOne simple version of adaptive expectations is stated in the following equation, where formula_1 is the next year's rate of inflation that is currently expected; formula_2is this year's rate of inflation that was expected last year; and formula_3 is this year's actual rate of inflation:\n\nwhere formula_5 is between 0 and 1. This says that current expectations of future inflation reflect past expectations and an \"error-adjustment\" term, in which current expectations are raised (or lowered) according to the gap between actual inflation and previous expectations. This error-adjustment is also called \"\"partial adjustment\".\"\n\nThe theory of adaptive expectations can be applied to all previous periods so that current inflationary expectations equal:\n\nwhere formula_7 equals actual inflation formula_8 years in the past. Thus, current expected inflation reflects a weighted average of all past inflation, where the weights get smaller and smaller as we move further in the past.\n\nOnce a forecasting error is made by agents, due to a stochastic shock, they will be unable to correctly forecast the price level again even if the price level experiences no further shocks since they only ever incorporate part of their errors. The backward nature of expectation formulation and the resultant systematic errors made by agents (see Cobweb model) was unsatisfactory to economists such as John Muth, who was pivotal in the development of an alternative model of how expectations are formed, called rational expectations. This has largely replaced adaptive expectations in macroeconomic theory since its assumption of optimality of expectations is consistent with economic theory. However, it must be stressed that confronting adaptivity and rationality is not necessarily justified, in other words, there are situations in which following the adaptive scheme is a rational response.\n\nAdaptive expectations were instrumental in the Phillips curve outlined by Milton Friedman. For Friedman, workers form adaptive expectations, so the government can easily surprise them through unexpected monetary policy changes. As agents are trapped by the money illusion, they are unable to correctly perceive price and wage dynamics, so, for Friedman, unemployment can always be reduced through monetary expansions. The result is an increasing level of inflation if the government chooses to fix unemployment at a low rate for an extended period of time. However, in this framework it is clear why and how adaptive expectations are problematic. Agents are arbitrarily supposed to ignore sources of information which, otherwise, would affect their expectations. For example, government announcements are such sources: agents are expected to modify their expectations and break with the former trends when changes in economic policy necessitate it. This is the reason why the theory of adaptive expectations is often regarded as a deviation from the rational tradition of economics.\n\n\n", "id": "3205", "title": "Adaptive expectations"}
{"url": "https://en.wikipedia.org/wiki?curid=3209", "text": "Mexican tetra\n\nThe Mexican tetra or blind cave fish (\"Astyanax mexicanus\") is a freshwater fish\nof the family Characidae of the order Characiformes. The type species of its genus, it is native to the Nearctic ecozone, originating in the lower Rio Grande and the Neueces and Pecos Rivers in Texas, as well as the central and eastern parts of Mexico.\n\nGrowing to a maximum overall length of , the Mexican tetra is of typical characin shape, with unremarkable, drab coloration. Its blind cave form, however, is notable for having no eyes and being albino, that is, completely devoid of pigmentation; it has a pinkish-white color to its body.\n\nThis fish, especially the blind variant, is reasonably popular among aquarists.\n\n\"A. mexicanus\" is a peaceful species that spends most of its time in midlevel water above the rocky and sandy bottoms of pools and backwaters of creeks and rivers of its native environment. Coming from a subtropical climate, it prefers water with 6.0–7.8 pH, a hardness of up to 30 dGH, and a temperature range of . In the winter, it migrates to warmer waters. Its natural diet consists of crustaceans, insects, and annelids, although in captivity it is omnivorous.\n\nThe Mexican tetra has been treated as a subspecies of \"A. fasciatus\", but this is not widely accepted.\n\n\"A. mexicanus\" is famous for its blind cave form, which is known by such names as blind cave tetra, blind tetra, blind cave characin and blind cavefish. Depending on the which population, cave forms can have degenerated sight or have total loss of sight and even their eyes. The fish in the Pachón caves have lost their eyes completely whilst the fish from the Micos cave only have limited sight. \nCave fish and surface fish are able to produce fertile offspring.\n\nThese fish can still, however, find their way around by means of their lateral lines, which are highly sensitive to fluctuating water pressure. Currently, 29 cave populations are known, dispersed over three geographically distinct areas in a karst region of San Luis Potosí, northeastern Mexico. Recent studies suggest at least two distinct genetic lineages occur among the blind populations, and the current distribution of populations arose by at least five independent invasions.\n\nThe eyed and eyeless forms of \"A. mexicanus,\" being members of the same species, are closely related and can interbreed making this species an excellent model organism for examining convergent and parallel evolution, regressive evolution in cave animals, and the genetic basis of regressive traits.\n\n\"Astyanax jordani\", another blind cave fish, is sometimes confused with the cave form of \"A. mexicanus.\"\n\nThe surface and cave forms of the Mexican tetra have proven powerful subjects for scientists studying evolution. When the surface-dwelling ancestors of current cave populations entered the subterranean environment, the change in ecological conditions rendered their phenotype—which included many biological functions dependent on the presence of light—subject to natural selection and genetic drift. One of the most striking changes to evolve was the loss of eyes. This is referred to as a \"regressive trait\" because the surface fish that originally colonized caves possessed eyes. In addition to regressive traits, cave forms evolved \"constructive traits\". In contrast to regressive traits, the purpose or benefit of constructive traits is generally accepted. Active research focuses on the mechanisms driving the evolution of regressive traits, such as the loss of eyes, in \"A. mexicanus\". Recent studies have produced evidence that the mechanism may be direct selection, or indirect selection through antagonistic pleiotropy, rather than genetic drift and neutral mutation, the traditionally favored hypothesis for regressive evolution.\n\nThe blind form of the Mexican tetra is different from the surface-dwelling form in a number of ways, including having unpigmented skin, having a better olfactory sense by having taste buds all over its head, and by being able to store four times more energy as fat, allowing it to deal with irregular food supplies more effectively.\n\nDarwin said of sightless fish:\n\nModern genetics has made clear that the lack of use does not, in itself, necessitate a feature's disappearance. In this context, the positive genetic benefits have to be considered, i.e., what advantages are obtained by cave-dwelling tetras by losing their eyes? Possible explanations include:\n\nAnother likely explanation for the loss of its eyes is that of selective neutrality and genetic drift; in the dark environment of the cave, the eyes are neither advantageous nor disadvantageous and thus any genetic factors that might impair the eyes (or their development) can take hold with no consequence on the individual or species. Because there is no selection pressure for sight in this environment, any number of genetic abnormalities that give rise to the damage or loss of eyes could proliferate among the population with no effect on the fitness of the population.\n\nAmong some creationists, the cave tetra is seen as evidence 'against' evolution. One argument claims this is an instance of \"devolution\"—showing an evolutionary trend of decreasing complexity. But evolution is a non-directional process, and while increased complexity is a common effect, there is no reason why evolution cannot tend towards simplicity if that makes an organism better suited to its environment.\n\nInhibition of the HSP90 protein has a dramatic effect in the development of the blind tetra. This research is seen by creationists as evidence of \"built-in adaptability, not slow and gradual evolution\".\n\nThe blind cave tetra is a fairly hardy species. Their lack of sight does not hinder their ability to get food. They prefer subdued lighting with a rocky substrate, like gravel, mimicking their natural environment. They become semi-aggressive as they age, and are by nature schooling fish. Experiments have shown that keeping these fish in bright aquarium set-ups has no effect on the development of the skin flap that forms over their eyes as they grow.\n\n", "id": "3209", "title": "Mexican tetra"}
{"url": "https://en.wikipedia.org/wiki?curid=3211", "text": "Atom probe\n\nThe atom probe was introduced at the 14th Field Emission Symposium in 1967 by Erwin Wilhelm Müller and J. A. Panitz. It combined a field ion microscope with a mass spectrometer having a single particle detection capability and, for the first time, an instrument could “... determine the nature of one single atom seen on a metal surface and selected from neighboring atoms at the discretion of the observer”.\n\nAtom probes are unlike conventional optical or electron microscopes, in that the magnification effect comes from the magnification provided by a highly curved electric field, rather than by the manipulation of radiation paths. The method is destructive in nature removing ions from a sample surface in order to image and identify them, generating magnifications sufficient to observe individual atoms as they are removed from the sample surface. Through coupling of this magnification method with time of flight mass spectrometry, ions evaporated by application of electric pulses can have their mass-to-charge ratio computed.\n\nThrough successive evaporation of material, layers of atoms are removed from a specimen, allowing for probing not only of the surface, but also through the material itself. Computer methods are utilised to rebuild a three-dimensional view of the sample, prior to it being evaporated, providing atomic scale information on the structure of a sample, as well as providing the type atomic species information. The instrument allows the three-dimensional reconstruction of up to billions of atoms from a sharp tip (corresponding to specimen volumes of 10,000-10,000,000 nm).\n\nAtom probe samples are shaped to implicitly provide a highly curved electric potential to induce the resultant magnification, as opposed to direct use of lensing, such as via magnetic lenses. Furthermore, in normal operation (as opposed to a field ionization modes) the atom probe does not utilize a secondary source to probe the sample. Rather, the sample is evaporated in a controlled manner (field evaporation) and the evaporated ions are impacted onto a detector, which is typically 10 to 100 cm away.\n\nThe samples are required to have a needle geometry and are produced by similar techniques as TEM sample preparation electropolishing, or focused ion beam methods. Since 2006, commercial systems with laser pulsing have become available and this has expanded applications from metallic only specimens into semiconducting, insulating such as ceramics, and even geological materials. Preparation is done, often by hand, to manufacture a tip radius sufficient to induce a high electric field, with radii on the order of 100 nm.\n\nTo conduct an atom probe experiment a very sharp needle shaped specimen is placed in an ultra high vacuum chamber. After introduction into the vacuum system, the sample is reduced to cryogenic temperatures (typically 20-100 K) and manipulated such that the needle's point is aimed towards an ion detector. A high voltage is applied to the specimen, and either a laser pulse is applied to the specimen or a voltage pulse (typically 1-2 kV) with pulse repetition rates in the hundreds of kilohertz range is applied to a counter electrode. The application of the pulse to the sample allows for individual atoms at the sample surface to be ejected as an ion from the sample surface at a known time. Typically the pulse amplitude and the high voltage on the specimen are computer controlled to encourage only one atom to ionize at a time, but multiple ionizations are possible. The delay between application of the pulse and detection of the ion(s) at the detector allow for the computation of a mass-to-charge ratio.\n\nWhilst the uncertainty in the atomic mass computed by time-of-flight methods in atom probe is sufficiently small to allow for detection of individual isotopes within a material this uncertainty may still, in some cases, confound definitive identification of atomic species. Effects such as superposition of differing ions with multiple electrons removed, or through the presence of complex species formation during evaporation may cause two or more species to have sufficiently close time-of-flights to make definitive identification impossible.\n\nField ion microscopy is a modification of field emission microscopy where a stream of tunneling electrons is emitted from the apex of a sharp needle-like \"tip\" cathode when subjected to a sufficiently high electric field (~3-6 V/nm). The needle is oriented towards a phosphor screen to create a projected image of the work function at the tip apex. The image resolution is limited to (2-2.5 nm), due to quantum mechanical effects and lateral variations in the electron velocity.\n\nIn field ion microscopy the tip is cooled by a cryogen and its polarity is reversed. When an \"imaging gas\" (usually hydrogen or helium) is introduced at low pressures (< 0.1 Pascal) gas ions in the high electric field at the tip apex are \"field ionized\" and produce a projected image of protruding atoms at the tip apex. The image resolution is determined primarily by the temperature of the tip but even at 78 Kelvin atomic resolution is achieved.\n\nThe 10-cm Atom Probe, invented in 1973 by J. A. Panitz was a “new and simple atom probe which permits rapid, in depth species identification or the more usual atom-by atom analysis provided by its predecessors ... in an instrument having a volume of less than two liters in which tip movement is unnecessary and the problems of evaporation pulse stability and alignment common to previous designs have been eliminated.” This was accomplished by combining a time of flight (TOF) mass spectrometer with a proximity focussed, dual channel plate detector, an 11.8 cm drift region and a 38° field of view. An FIM image or a desorption image of the atoms removed from the apex of a field emitter tip could be obtained. The 10-cm Atom Probe has been called the \"progenitor\" of later atom probes including the commercial instruments.\n\nThe Imaging Atom-Probe (IAP) was introduced in 1974 by J. A. Panitz. It incorporated the features of the 10-cm Atom-Probe yet “... departs completely from [previous] atom probe philosophy. Rather than attempt to determine the identity of a surface species producing a preselected ion-image spot, we wish to determine the complete crystallographic distribution of a surface species of preselected mass-to-charge ratio. Now suppose that instead of operating the [detector] continuously, it is turned on for a short time coincidentally with the arrival of a preselected species of interest by applying a \"gate pulse\" a time T after the evaporation pulse has reached the specimen. If the duration of the gate pulse is shorter than the travel time between adjacent species, only that surface species having the unique travel time T will be detected and its complete crystallographic distribution displayed.” It was patented in 1975 as the Field Desorption Spectrometer. The Imaging Atom-Probe moniker was coined by A. J. Waugh in 1978 and the instrument was described in detail by J. A. Panitz in the same year.\n\nModern day atom probe tomography (APT) uses a position-sensitive detector to deduce the lateral location of atoms. The idea of the APT, inspired by J. A. Panitz's \"Field Desorption Spectrometer\" patent, was developed by Mike Miller starting in 1983 and culminated with the first prototype in 1986. Various refinements were made to the instrument, including the use of a so-called position-sensitive (PoS) detector by Alfred Cerezo, Terence Godfrey, and George D. W. Smith at Oxford University in 1988. The Tomographic Atom Probe (TAP), developed by researchers at the University of Rouen in France in 1993, introduced a multichannel timing system and multianode array. Both instruments (PoSAP and TAP) were commercialized by Oxford Nanoscience and CAMECA respectively. Since then, there have been many refinements to increase the field of view, mass and position resolution, and data acquisition rate of the instrument. The Local Electrode Atom Probe was first introduced in 2003 by Imago Scientific Instruments. In 2005, the commercialization of the pulsed laser atom probe (PLAP) expanded the avenues of research from highly conductive materials (metals) to poor conductors (semiconductors like silicon) and even insulating materials. AMETEK acquired CAMECA in 2007 and Imago Scientific Instruments (Madison, WI) in 2010, making the company the sole commercial developer of APTs with more than 90 instruments installed around the world in 2016.\n\nThe first few decades of work with APT focused on metals. However, more recent work has been done on semiconductors, ceramic and geologic materials, with some work on biomaterials. The most advanced study of biological material to date using APT involved analyzing the chemical structure of teeth of the radula of chiton \"Chaetopleura apiculata\". In this study, the use of APT showed chemical maps of organic fibers in the surrounding nano-crystalline magnetite in the chiton teeth, fibers which were often co-located with sodium or magnesium. This has been furthered to study elephant tusks, dentin and potentially human enamel.\n\nField evaporation is an effect that can occur when an atom bonded at the surface of a material is in the presence of a sufficiently high and appropriately directed electric field, where the electric field is the differential of electric potential (voltage) with respect to distance. Once this condition is met, it is sufficient that local bonding at the specimen surface is capable of being overcome by the field, allowing for evaporation of an atom from the surface to which it is otherwise bonded.\n\nWhether evaporated from the material itself, or ionised from the gas, the ions that are evaporated are accelerated by electrostatic force, acquiring most of their energy within a few tip-radii of the sample.\n\nSubsequently, the accelerative force on any given ion is controlled by the electrostatic equation, where \"n\" is the ionisation state of the ion, and \"e\" is the fundamental electric charge.\n\nThis can be equated with the mass of the ion, \"m\", via Newton's law (F=ma):\n\nRelativistic effects in the ion flight are usually ignored, as realisable ion speeds are only a very small fraction of the speed of light.\n\nAssuming that the ion is accelerated during a very short interval, the ion can be assumed to be travelling at constant velocity. As the ion will travel from the tip at voltage V to some nominal ground potential, the speed at which the ion is travelling can be estimated by the energy transferred into the ion during (or near) ionisation. Therefore, the ion speed can be computed with the following equation, which relates kinetic energy to energy gain due to the electric field, the negative arising from the loss of electrons forming a net positive charge.\n\nWhere \"U\" is the ion velocity. Solving for \"U\", the following relation is found:\n\nLet's say that for at a certain ionization voltage, a singly charged hydrogen ion acquires a resulting velocity of X ms. A singly charged deuterium ion under the sample conditions would have acquired roughly X/1.41 ms. If a detector was placed at a distance of 1 m, the ion flight times would be 1/X and 1.41/X s. Thus, the time of the ion arrival can be used to infer the ion type itself, if the evaporation time is known.\n\nFrom the above equation, it can be re-arranged to show that\n\ngiven a known flight distance. F, for the ion, and a known flight time, t,\n\nand thus one can substitute these values to obtain the mass-to-charge for the ion.\n\nThus for an ion which traverses a 1 m flight path, across a time of 2000 ns, given an initial accelerating voltage of 5000 V (V in Si units is kg.m^2.s^-3.A^-1) and noting that one amu is 1×10 kg, the mass-to-charge ratio (more correctly the mass-to-ionisation value ratio) becomes ~3.86 amu/charge. The number of electrons removed, and thus net positive charge on the ion is not known directly, but can be inferred from the histogram (spectrum) of observed ions.\n\nThe magnification in an atom is due to the projection of ions radially away from the small, sharp tip. Subsequently, in the far field, the ions will be greatly magnified. This magnification is sufficient to observe field variations due to individual atoms, thus allowing in field ion and field evaporation modes for the imaging of single atoms.\n\nThe standard projection model for the atom probe is an emitter geometry that is based upon a revolution of a conic section, such as a sphere, hyperboloid or paraboloid. For these tip models, solutions to the field may be approximated or obtained analytically. The magnification for a spherical emitter is inversely proportional to the radius of the tip, given a projection directly onto a spherical screen, the following equation can be obtained geometrically.\n\nWhere r is the radius of the detection screen from the tip centre, and r the tip radius. Practical tip to screen distances may range from several centimeters to several meters, with increased detector area required at larger to subtend the same field of view.\n\nPractically speaking, the usable magnification will be limited by several effects, such as lateral vibration of the atoms prior to evaporation.\n\nWhilst the magnification of both the field ion and atom probe microscopes is extremely high, the exact magnification is dependent upon conditions specific to the examined specimen, so unlike for conventional electron microscopes, there is often little direct control on magnification, and furthermore, obtained images may have strongly variable magnifications due to fluctuations in the shape of the electric field at the surface.\n\nThe computational conversion of the ion sequence data, as obtained from a position sensitive detector, to a three-dimensional visualisation of atomic types, is termed \"reconstruction\". Reconstruction algorithms are typically geometrically based, and have several literature formulations. Most models for reconstruction assume that the tip is a spherical object, and utilise empirical corrections to stereographic projection to convert detector positions back to a 2D surface embedded in 3D space, R. By sweeping this surface through R as a function of the ion sequence input data, such as via ion-ordering, a volume is generated onto which positions the 2D detector positions can be computed and placed three-dimensional space.\n\nTypically the sweep takes the simple form of an advancement of the surface, such that the surface is expanded in a symmetric manner about its advancement axis, with the advancement rate set by a volume attributed to each ion detected and identified. This causes the final reconstructed volume to assume a rounded-conical shape, similar to a badminton shuttlecock. The detected events thus become a point cloud data with attributed experimentally measured values, such as ion time of flight or experimentally derived quantities, e.g. time of flight or detector data.\n\nThis form of data manipulation allows for rapid computer visualisation and analysis, with data presented as point cloud data with additional information, such as each ion's mass to charge (as computed from the velocity equation above), voltage or other auxiliary measured quantity or computation therefrom.\n\nThe canonical feature of atom probe data, is its high spatial resolution in the direction through the material, which has been attributed to an ordered evaporation sequence. This data can therefore image near atomically sharp buried interfaces with the associated chemical information.\n\nThe data obtained from the evaporative process is however not without artefacts that form the physical evaporation or ionisation process. A key feature of the evaporation or field ion images is that the data density is highly inhomogeneous, due to the corrugation of the specimen surface at the atomic scale. This corrugation gives rise to strong electric field gradients in the near-tip zone (on the order of an atomic radii or less from the tip), which during ionisation deflects ions away from the electric field normal.\n\nThe resultant deflection means that in these regions of high curvature, atomic terraces are belied by a strong anisotropy in the detection density. Where this occurs due to a few atoms on a surface is usually referred to as a \"pole\", as these are coincident with the crystallographic axes of the specimen (FCC, BCC, HCP) etc. Where the edges of an atomic terrace causes deflection, a low density line is formed and is termed a \"zone line\".\n\nThese poles and zone-lines, whilst inducing fluctuations in data density in the reconstructed datasets, which can prove problematic during post-analysis, are critical for determining information such as angular magnification, as the crystallographic relationships between features are typically well known.\n\nWhen reconstructing the data, owing to the evaporation of successive layers of material from the sample, the lateral and in-depth reconstruction values are highly anisotropic. Determination of the exact resolution of the instrument is of limited use, as the resolution of the device is set by the physical properties of the material under analysis.\n\nMany designs have been constructed since the method's inception. Initial field ion microscopes, precursors to modern atom probes, were usually glass blown devices developed by individual research laboratories.\n\nAt a minimum, an atom probe will consist of several key pieces of equipment.\n\n\nOptionally, an atom probe may also include laser-optical systems for laser beam targeting and pulsing, if using laser-evaporation methods. In-situ reaction systems, heaters, or plasma treatment may also be employed for some studies as well as pure noble gas introduction for FIM.\n\nCollectable ion volumes were previously limited to several thousand, or tens of thousands of ionic events. Subsequent electronics and instrumentation development has increased the rate of data accumulation, with datasets of hundreds of million atoms (dataset volumes of 10 nm). Data collection times vary considerably depending upon the experimental conditions and the number of ions collected. Experiments take from a few minutes, to many hours to complete.\n\nAtom probe has typically been employed in the chemical analysis of alloy systems at the atomic level. This has arisen as a result of voltage pulsed atom probes providing good chemical and sufficient spatial information in these materials. Metal samples from large grained alloys may be simple to fabricate, particularly from wire samples, with hand-electropolishing techniques giving good results.\n\nSubsequently, atom probe has been used in the analysis of the chemical composition of a wide range of alloys.\n\nSuch data is critical in determining the effect of alloy constituents in a bulk material, identification of solid-state reaction features, such as solid phase precipitates. Such information may not be amenable to analysis by other means (e.g. TEM) owing to the difficulty in generating a three-dimensional dataset with composition.\n\nSemi-conductor materials are often analysable in atom probe, however sample preparation may be more difficult, and interpretation of results may be more complex, particularly if the semi-conductor contains phases which evaporate at differing electric field strengths.\n\nApplications such as ion implantation may be used to identify the distribution of dopants inside a semi-conducting material, which is increasingly critical in the correct design of modern nanometre scale electronics.\n\n\n\n\n\n\n\n\nFor other listings, see: atomprobe.com-sites\n\n", "id": "3211", "title": "Atom probe"}
