{"url": "https://en.wikipedia.org/wiki?curid=2357", "text": "American Football League\n\nThe American Football League (AFL) was a major professional American football league that operated from 1960 until 1969, when it merged with the National Football League (NFL). The upstart AFL operated in direct competition with the more established NFL throughout its existence.\n\nThe AFL was created by a number of owners who had been refused NFL expansion franchises or had minor shares of NFL franchises. The AFL's original lineup consisted of an Eastern division of the New York Titans, Boston Patriots, Buffalo Bills, and the Houston Oilers, and a Western division of the Los Angeles Chargers, Denver Broncos, Oakland Raiders, and Dallas Texans. The league first gained attention by signing 75% of the NFL's first-round draft choices in 1960, including Houston's successful signing of Heisman Trophy winner Billy Cannon.\n\nWhile the first years of the AFL saw uneven competition and low attendance, the league was buttressed by a generous television contract with ABC (followed by a contract with NBC for games starting with the 1965 season) that broadcast the more offense-oriented football league nationwide. Continuing to attract top talent from colleges and the NFL by the mid-1960s, as well as successful franchise shifts of the Chargers to San Diego and the Texans to Kansas City, the AFL established a dedicated following. The transformation of the struggling Titans into the New York Jets under new ownership further solidified the league's reputation among the major media.\n\nAs fierce competition made player salaries skyrocket in both leagues, especially after a series of \"raids\", the leagues agreed to a merger in 1966. Among the conditions were a common draft and a championship game played between the two league champions, which would eventually become known as the Super Bowl.\n\nThe AFL and NFL operated as separate leagues until 1970, with separate regular season and playoff schedules except for the championship game. During this time the AFL added the Miami Dolphins and Cincinnati Bengals. After losses by Kansas City and Oakland in the first two AFL-NFL Championship Games to the Green Bay Packers, the New York Jets and Kansas City Chiefs won Super Bowls III and IV respectively, cementing the league's claim to being an equal to the NFL.\n\nIn 1970, the AFL was absorbed into the NFL, and the ten AFL franchises along with the Baltimore Colts, Cleveland Browns, and Pittsburgh Steelers became the American Football Conference.\n\nDuring the 1950s, the National Football League had grown to rival Major League Baseball as one of the most popular professional sports leagues in the United States. One franchise that did not share in this newfound success of the league was the Chicago Cardinals, owned by the Bidwill family, who had become overshadowed by the more popular Chicago Bears. The Bidwills hoped to relocate their franchise, preferably to St. Louis but could not come to terms with the league on a relocation fee. Needing cash, the Bidwills began entertaining offers from would-be investors, and one of the men who approached the Bidwills was Lamar Hunt, son and heir of millionaire oilman H. L. Hunt. Hunt offered to buy the Cardinals and move them to Dallas, where he had grown up. However, these negotiations came to nothing, since the Bidwills insisted on retaining a controlling interest in the franchise and were unwilling to move their team to a city where a previous NFL franchise had failed in 1952. While Hunt negotiated with the Bidwills, similar offers were made by Bud Adams, Bob Howsam, and Max Winter.\n\nWhen Hunt, Adams, and Howsam were unable to secure a controlling interest in the Cardinals, they approached NFL commissioner Bert Bell and proposed the addition of expansion teams. Bell, wary of expanding the 12-team league and risking its newfound success, rejected the offer. On his return flight to Dallas, Hunt conceived the idea of an entirely new league and decided to contact the others who had shown interest in purchasing the Cardinals. He contacted Adams, Howsam, and Winter (as well as Winter's business partner, Bill Boyer) to gauge their interest in starting a new league. Hunt's first meeting with Adams was held in March 1959. Hunt, who felt a regional rivalry would be critical for the success of the new league, convinced Adams to join and found his team in Houston. Hunt next secured an agreement from Howsam to bring a team to Denver.\n\nAfter Winter and Boyer agreed to start a team in Minneapolis-Saint Paul, the new league had its first four teams. Hunt then approached Willard Rhodes, who hoped to bring pro football to Seattle. However, the University of Washington was unwilling to let the fledgling league use Husky Stadium, probably due to the excessive wear and tear that would have been caused to the facility's grass surface. With no place for his team to play, Rhodes' effort came to nothing. Hunt also sought franchises in Los Angeles, Buffalo and New York City. During the summer of 1959, he sought the blessings of the NFL for his nascent league, as he did not seek a potentially costly rivalry. Within weeks of the July 1959 announcement of the league's formation, Hunt received commitments from Barron Hilton and Harry Wismer to bring teams to Los Angeles and New York, respectively. His initial efforts for Buffalo, however, were rebuffed, when Hunt's first choice of owner, Pat McGroder, declined to take part; McGroder had hoped that the threat of the AFL would be enough to prompt the NFL to expand to Buffalo.\n\nOn August 14, 1959, the first league meeting was held in Chicago, and charter memberships were given to Dallas, New York, Houston, Denver, Los Angeles, and Minneapolis-Saint Paul. On August 22 the league officially was named the American Football League. The NFL's initial reaction was not as openly hostile as it had been with the earlier All-America Football Conference (Bell had even given his public approval), yet individual NFL owners soon began a campaign to undermine the new league. AFL owners were approached with promises of new NFL franchises or ownership stakes in existing ones. Only the party from Minneapolis accepted, and the Minnesota group joined the NFL the next year in 1961; the Minneapolis group were joined by Ole Haugsrud and Bernie Ridder in the new NFL team's ownership group, with was named the Minnesota Vikings. The older league also announced on August 29 that it had conveniently reversed its position against expansion, and planned to bring NFL expansion teams to Houston and Dallas, to start play in 1961. (The NFL did not expand to Houston at that time, the promised Dallas team – the Dallas Cowboys – actually started play in 1960, and the Vikings began play in 1961.) Finally, the NFL quickly came to terms with the Bidwills and allowed them to relocate the struggling Cardinals to St. Louis, eliminating that city as a potential AFL market.\n\nRalph Wilson, who owned a minority interest in the NFL's Detroit Lions at the time, initially announced he was placing a team in Miami, but like the Seattle situation, was also rebuffed by local ownership; given five other choices, Wilson negotiated with McGroder and brought the team that would become the Bills to Buffalo. Buffalo was officially awarded its franchise on October 28. During a league meeting on November 22, a 10-man ownership group from Boston (led by Billy Sullivan) was awarded the AFL's eighth team. On November 30, 1959, Joe Foss, a World War II Marine fighter ace and former governor of South Dakota, was named the AFL's first commissioner. Foss commissioned a friend of Harry Wismer's to develop the AFL's eagle-on-football logo. Hunt was elected President of the AFL on January 26, 1960.\n\nThe AFL's first draft took place the same day Boston was awarded its franchise, and lasted 33 rounds. The league held a second draft on December 2, which lasted for 20 rounds. Because the Raiders joined after the AFL draft, they inherited Minnesota's selections. A special \"allocation draft\" was held in January 1960, to allow the Raiders to stock their team, as some of the other AFL teams had already signed some of Minneapolis' original draft choices.\n\nIn November 1959, Minneapolis owner Max Winter announced his intent to leave the AFL to accept a franchise offer from the NFL. In 1961, his team began play in the NFL as the Minnesota Vikings. Los Angeles Chargers owner Barron Hilton demanded that a replacement for Minnesota be placed in California, to reduce his team's operating costs and to create a rivalry. After a brief search, Oakland was chosen and an ownership group led by F. Wayne Valley and local real estate developer Chet Soda was formed. After initially being called the Oakland \"\"Señores\"\", the Oakland Raiders officially joined the AFL on January 30, 1960.\n\nThe AFL's first major success came when the Houston Oilers signed Billy Cannon, the All-American and 1959 Heisman Trophy winner from LSU. Cannon signed a $100,000 contract to play for the Oilers, despite having already signed a $50,000 contract with the NFL's Los Angeles Rams. The Oilers filed suit and claimed that Rams general manager Pete Rozelle had unduly manipulated Cannon. The court upheld the Houston contract, and with Cannon the Oilers appeared in the AFL's first three championship games (winning two).\n\nOn June 9, 1960, the league signed a five-year television contract with ABC, which brought in revenues of approximately US$2,125,000 per year for the entire league. On June 17, the AFL filed an antitrust lawsuit against the NFL, which was dismissed in 1962 after a two-month trial. The AFL began regular-season play (a night game on Friday, September 9, 1960) with eight teams in the league — the Boston Patriots, Buffalo Bills, Dallas Texans, Denver Broncos, Houston Oilers, Los Angeles Chargers, New York Titans, and Oakland Raiders. Raiders' co-owner Wayne Valley dubbed the AFL ownership \"The Foolish Club\", a term Lamar Hunt subsequently used on team photographs he sent as Christmas gifts.\n\nThe Oilers became the first-ever league champions by defeating the Chargers, 24–16, in the AFL Championship on January 1, 1961. Attendance for the 1960 season was respectable for a new league, but not nearly that of the NFL. In 1960, the NFL averaged attendance of more than 40,000 fans per game and more popular NFL teams in 1960 regularly saw attendance figures in excess of 50,000 per game, while CFL attendances averaged approximately 20,000 per game. By comparison, AFL attendance averaged about 16,500 per game and generally hovered between 10,000-20,000 per game. Professional football was still primarily a gate-driven business in 1960, so low attendance meant financial losses. The Raiders, with a league-worst average attendance of just 9,612, lost $500,000 in their first year and only survived after receiving a $400,000 loan from Bills owner Ralph Wilson. In an early sign of stability, however, the AFL did not lose any teams after its first year of operation. In fact, the only major change was the relocation of the Chargers from Los Angeles to nearby San Diego.\n\nOn August 8, 1961, the AFL challenged the Canadian Football League to an exhibition game that would feature the Hamilton Tiger-Cats and the Buffalo Bills, which was attended by 24,376 spectators. Playing at Civic Stadium in Hamilton, Ontario, the Tiger-Cats defeated the Bills 38–21 playing a mix of AFL and CFL rules.\n\nWhile the Oilers found instant success in the AFL, other teams did not fare as well. The Oakland Raiders and New York Titans struggled on and off the field during their first few seasons in the league. Oakland's eight-man ownership group was reduced to just three in 1961, after heavy financial losses in their first season. Attendance for home games was poor, partly due to the team playing in the San Francisco Bay Area—which already had an established NFL team (the San Francisco 49ers)—but the product on the field was also to blame. After winning six games in their debut season, the Raiders won a total of three times in the 1961 and 1962 seasons. Oakland took part in a 1961 supplemental draft meant to boost the weaker teams in the league, but it did little good. They participated in another such draft in 1962.\n\nThe Titans fared a little better on the field but had their own financial troubles. Attendance was so low for home games that team owner Harry Wismer had fans move to seats closer to the field to give the illusion of a fuller stadium on television. Eventually Wismer could no longer afford to meet his payroll, and on November 8, 1962 the AFL took over operations of the team. The Titans were sold to a five-person ownership group headed by Sonny Werblin on March 28, 1963, and in April the new owners changed the team's name to the New York Jets.\n\nThe Raiders and Titans both finished last in their respective divisions in the 1962 season. The Texans and Oilers, winners of their divisions, faced each other for the 1962 AFL Championship on December 23. The Texans dethroned the two-time champion Oilers, 20–17, in a double-overtime contest that was, at the time, professional football's longest-ever game.\n\nIn 1963, the Texans became the second AFL team to relocate. Lamar Hunt felt that despite winning the league championship in 1962, the Texans could not succeed financially competing in the same market as the Dallas Cowboys, which entered the NFL as an expansion franchise in 1960. After meetings with New Orleans, Atlanta, and Miami, Hunt announced on May 22 that the Texans' new home would be Kansas City, Missouri. Kansas City mayor Harold Roe Bartle (nicknamed \"Chief\") was instrumental in his city's success in attracting the team. Partly to honor Bartle, the franchise officially became the Kansas City Chiefs on May 26.\n\nThe San Diego Chargers, under head coach Sid Gillman, won a decisive 51–10 victory over the Boston Patriots for the 1963 AFL Championship. Confident that his team was capable of beating the NFL-champion Chicago Bears (he had the Chargers' rings inscribed with the phrase \"World Champions\"), Gillman approached NFL Commissioner Pete Rozelle and proposed a final championship game between the two teams. Rozelle declined the offer; however, the game would be instituted three seasons later.\n\nA series of events throughout the next few years demonstrated the AFL's ability to achieve a greater level of equality with the NFL. On January 29, 1964, the AFL signed a lucrative $36 million television contract with NBC (beginning in the 1965 season), which gave the league money it needed to compete with the NFL for players. Pittsburgh Steelers owner Art Rooney was quoted as saying to NFL Commissioner Pete Rozelle that \"They don't have to call us 'Mister' anymore\". A single-game attendance record was set on November 8, 1964, when 61,929 fans packed Shea Stadium to watch the New York Jets and Buffalo Bills.\n\nThe bidding war for players between the AFL and NFL escalated in 1965. The Chiefs drafted University of Kansas star Gale Sayers in the first round of the 1965 AFL draft (held November 28, 1964), while the Chicago Bears did the same in the NFL draft. Sayers eventually signed with the Bears. A similar situation occurred when the New York Jets and the NFL's St. Louis Cardinals both drafted University of Alabama quarterback Joe Namath. In what was viewed as a key victory for the AFL, Namath signed a $427,000 contract with the Jets on January 2, 1965 (the deal included a new car). It was the highest amount of money ever paid to a collegiate football player, and is cited as the strongest contributing factor to the eventual merger between the two leagues.\n\nAfter the 1963 season, the Newark Bears of the Atlantic Coast Football League expressed interest in joining the AFL; concerns over having to split the New York metro area with the still-uncertain Jets were a factor in the Bears bid being rejected. In early 1965, the AFL awarded its first expansion team to Rankin Smith of Atlanta. The NFL quickly counteroffered Smith a franchise, which Smith accepted; the Atlanta Falcons began play as an NFL franchise. In March 1965, Joe Robbie had met with Commissioner Foss to inquire about an expansion franchise for Miami. On May 6, after Atlanta's exit, Robbie secured an agreement with Miami mayor Robert King High to bring a team to Miami. League expansion was approved at a meeting held on June 7, and on August 16 the AFL's ninth franchise was officially awarded to Robbie and television star Danny Thomas. The Miami Dolphins joined the league for a fee of $7.5 million and started play in the AFL's Eastern Division in 1966.\n\nIn 1966, the rivalry between the AFL and NFL reached an all-time peak. On April 7, Joe Foss resigned as AFL commissioner. His successor was Oakland Raiders head coach and general manager Al Davis, who had been instrumental in turning around the fortunes of that franchise. No longer content with trying to outbid the NFL for college talent, the AFL under Davis started to recruit players already on NFL squads. Davis's strategy focused on quarterbacks in particular, and in two months he persuaded seven NFL quarterbacks to sign with the AFL. Although Davis's intention was to help the AFL win the bidding war, some AFL and NFL owners saw the escalation as detrimental to both leagues. Alarmed with the rate of spending in the league, Hilton Hotels forced Barron Hilton to relinquish his stake in the Chargers as a condition of maintaining his leadership role with the hotel chain.\n\nThe same month Davis was named commissioner, several NFL owners, along with Dallas Cowboys general manager Tex Schramm, secretly approached Lamar Hunt and other AFL owners and asked the AFL to merge. They held a series of secret meetings in Dallas to discuss their concerns over rapidly increasing player salaries, as well as the practice of player poaching. Hunt and Schramm completed the basic groundwork for a merger of the two leagues by the end of May, and on June 8, 1966, the merger was officially announced. Under the terms of the agreement, the two leagues would hold a common player draft. The agreement also called for a title game to be played between the champions of the respective leagues. The two leagues would be fully merged by 1970, NFL commissioner Pete Rozelle would remain as commissioner of the merged league, and additional expansion teams would eventually be awarded by 1970 or soon thereafter to bring it to a 28-team league. The AFL also agreed to pay indemnities of $18 million to the NFL over 20 years. In protest, Davis resigned as AFL commissioner on July 25 rather than remain until the completion of the merger, and Milt Woodard was named President of the AFL.\n\nOn January 15, 1967, the first-ever World Championship Game between the champions of the two separate professional football leagues, the AFL-NFL Championship Game (retroactively referred to as Super Bowl I), was played in Los Angeles. After a close first half, the NFL champion Green Bay Packers overwhelmed the AFL champion Kansas City Chiefs, 35–10. The loss reinforced for many the notion that the AFL was an inferior league. Packers head coach Vince Lombardi stated after the game, \"I do not think they are as good as the top teams in the National Football League.\"\n\nThe second AFL-NFL Championship (Super Bowl II) yielded a similar result. The Oakland Raiders—who had easily beaten the Houston Oilers to win their first AFL championship—were overmatched by the Packers, 33–14. The more experienced Packers capitalized on a number of Raiders miscues and never trailed. Green Bay defensive tackle Henry Jordan offered a compliment to Oakland and the AFL, when he said, \"... the AFL is becoming much more sophisticated on offense. I think the league has always had good personnel, but the blocks were subtler and better conceived in this game.\"\n\nThe AFL added its tenth and final team on May 24, 1967, when it awarded the league's second expansion franchise to an ownership group from Cincinnati, Ohio, headed by NFL legend Paul Brown. Although Brown had intended to join the NFL, he agreed to join the AFL when he learned that his team would be included in the NFL once the merger was completed. The Cincinnati Bengals began play in the 1968 season, finishing last in the Western Division.\n\nWhile many AFL players and observers believed their league was the equal of the NFL, their first two Super Bowl performances did nothing to prove it. However, on November 17, 1968, when NBC cut away from a game between the Jets and Raiders to air the children's movie \"Heidi\", the ensuing uproar helped disprove the notion that fans still considered the AFL an inferior product. The perception of AFL inferiority forever changed on January 12, 1969, when the AFL Champion New York Jets shocked the heavily favored NFL Champion Baltimore Colts in Super Bowl III. The Colts, who entered the contest favored by as many as 18 points, had completed the 1968 NFL season with a 13–1 record, and won the NFL title with a convincing 34–0 win over the Cleveland Browns. Led by their stalwart defense—which allowed a record-low 144 points—the 1968 Colts were considered one of the best-ever NFL teams.\n\nBy contrast, the Jets had allowed 280 points, the highest total for any division winner in the two leagues. They had also only narrowly beaten the favored Oakland Raiders 27–23 in the AFL championship game. Jets quarterback Joe Namath recalled that in the days leading up to the game, he grew increasingly angry when told New York had no chance to beat Baltimore. Three days before the game, a frustrated Namath responded to a heckler at the Touchdown Club in Miami by declaring, \"We're going to win Sunday, I'll guarantee you.\"\n\nNamath and the Jets made good on his guarantee as they held the Colts scoreless until late in the fourth quarter. The Jets won, 16–7, in what is considered one of the greatest upsets in American sports history. With the win, the AFL finally achieved parity with the NFL and legitimized the merger of the two leagues. That notion was reinforced one year later in Super Bowl IV, when the AFL champion Kansas City Chiefs upset the NFL champion Minnesota Vikings, 23–7, in the last championship game to be played between the two leagues. The Vikings, favored by 12½ points, were held to just 67 rushing yards.\n\nThe last game in AFL history was the AFL All-Star Game, held in Houston's Astrodome on January 17, 1970. The Western All-Stars, led by Chargers quarterback John Hadl, defeated the Eastern All-Stars, 26–3. Buffalo rookie back O.J. Simpson carried the ball for the last play in AFL history. Hadl was named the game's Most Valuable Player. Prior to the start of the 1970 NFL season, the merged league was organized into two conferences of three divisions each. All ten AFL teams made up the bulk of the new American Football Conference. To avoid having an inequitable number of teams in each conference, the leagues voted to move three NFL teams to the AFC. Motivated by the prospect of an intrastate rivalry with the Bengals as well as by personal animosity toward Paul Brown, Cleveland Browns owner Art Modell quickly offered to include his team in the AFC. He helped persuade the Pittsburgh Steelers (the Browns' archrivals) and Baltimore Colts (who shared the Baltimore/Washington, D.C. market with the Washington Redskins) to follow suit, and each team received US $3 million to make the switch. All the other NFL squads became part of the National Football Conference.\n\nPro Football Hall of Fame receiver Charlie Joiner, who started his career with the Houston Oilers (1969), was the last AFL player active in professional football, retiring after the 1986 season, when he played for the San Diego Chargers.\n\nThe American Football League stands as the only professional football league to successfully compete against the NFL. When the two leagues merged in 1970, all ten AFL franchises and their statistics became part of the new NFL. Every other professional league that had competed against the NFL before the AFL–NFL merger had folded completely: the three previous leagues named \"American Football League\" and the All-America Football Conference. From an earlier AFL (1936–1937), only the Cleveland Rams (now the Los Angeles Rams) joined the NFL and are currently operating, as are the Cleveland Browns and the San Francisco 49ers from the AAFC. A third AAFC team, the Baltimore Colts (not related to the 1953–1983 Baltimore Colts or to the current Indianapolis Colts franchise), played only one year in the NFL, disbanding at the end of the 1950 season. The league resulting from the merger was a 26-team juggernaut (since expanded to 32) with television rights covering all of the Big Three television networks and teams in close proximity to almost all of the top 40 metropolitan areas, a fact that has precluded any other competing league from gaining traction since the merger; failed attempts to mimic the AFL's success included the World Football League (1974–75), United States Football League (1983–85), XFL (2001) and United Football League (2009–2012).\n\nThe AFL was also the most successful of numerous upstart leagues of the 1960s and 1970s that attempted to challenge a major professional league's dominance. All nine teams that were in the AFL at the time the merger was agreed upon were accepted into the league intact (as was the tenth team added between the time of the merger's agreement and finalization), and none of the AFL's teams have ever folded. For comparison, the World Hockey Association (1972–79) managed to have four of its six remaining teams merged into the National Hockey League, which actually caused the older league to contract a franchise, but WHA teams were forced to disperse the majority of their rosters and restart as expansion teams. The merged WHA teams were also not financially sound (in large part from the expansion fees the NHL imposed on them), and three of the four were forced to relocate within 20 years. The American Basketball Association (1967–76) managed to have only four of its teams merged into the National Basketball Association, and the rest of the league was forced to fold. Both the WHA and ABA lost several teams to financial insolvency over the course of their existences. The Continental League, a proposed third league for Major League Baseball that was to begin play in 1961, never played a single game, largely because MLB responded to the proposal by expanding to four of that league's proposed cities. Historically, the only other professional sports league in the United States to exhibit a comparable level of franchise stability from its inception was the American League of Major League Baseball.\n\nThe NFL adopted some of the innovations introduced by the AFL immediately and a few others in the years following the merger. One was including the names on player jerseys. The older league also adopted the practice of using the stadium scoreboard clocks to keep track of the official game time, instead of just having a stopwatch used by the referee. The AFL played a 14-game schedule for its entire existence, starting in 1960. The NFL, which had played a 12-game schedule since 1947, changed to a 14-game schedule in 1961, a year after the American Football League instituted it. The AFL also introduced the two-point conversion to professional football thirty-four years before the NFL instituted it in 1994 (college football had adopted the two-point conversion in the late 1950s). All of these innovations pioneered by the AFL, including its more exciting style of play and colorful uniforms, have essentially made today's professional football more like the \"AFL\" than like the old-line NFL. The AFL's challenge to the NFL also laid the groundwork for the Super Bowl, which has become the standard for championship contests in the United States of America.\n\nThe NFL also adapted how the AFL used the growing power of televised football games, which were bolstered with the help of major network contracts (first with ABC and later with NBC). With that first contract with ABC, the AFL adopted the first-ever cooperative television plan for professional football, in which the proceeds were divided equally among member clubs. It featured many outstanding games, such as the classic 1962 double-overtime American Football League championship game between the Dallas Texans and the defending champion Houston Oilers. At the time it was the longest professional football championship game ever played. The AFL also appealed to fans by offering a flashier style of play (just like the ABA in basketball), compared to the more conservative game of the NFL. Long passes (\"bombs\") were commonplace in AFL offenses, led by such talented quarterbacks as John Hadl, Daryle Lamonica and Len Dawson.\n\nDespite having a national television contract, the AFL often found itself trying to gain a foothold, only to come up against roadblocks. For example, CBS-TV, which broadcast NFL games, ignored and did not report scores from the innovative AFL, on orders from the NFL. It was only after the merger agreement was announced that CBS began to give AFL scores.\n\nThe AFL took advantage of the burgeoning popularity of football by locating teams in major cities that lacked NFL franchises. Hunt's vision not only brought a new professional football league to California and New York, but introduced the sport to Colorado, restored it to Texas and later to fast-growing Florida, as well as bringing it to New England for the first time in 12 years. Buffalo, having lost its original NFL franchise in 1929 and turned down by the NFL at least twice (1940 and 1950) for a replacement, returned to the NFL with the merger. The return of football to Kansas City was the first time that city had seen professional football since the NFL's Kansas City Blues/Cowboys of the 1920s; the arrival of the Chiefs, and the contemporary arrival of the St. Louis Football Cardinals, brought professional football back to Missouri for the first time since the temporary St. Louis Gunners of 1934.\n\nIf not for the AFL, at least 17 of today's NFL teams would probably never have existed: the ten teams from the AFL, and seven clubs that were instigated by the AFL's presence to some degree. Three NFL franchises were awarded as a direct result of the AFL's competition with the older league: the Minnesota Vikings, who were awarded to Max Winter in exchange for dropping his bid to join the AFL; the Atlanta Falcons, whose franchise went to Rankin Smith to dissuade him from purchasing the AFL's Miami Dolphins; and the New Orleans Saints, because of successful anti-trust legislation which let the two leagues merge, and was supported by several Louisiana politicians.\n\nIn the case of the Dallas Cowboys, the NFL had long sought to return to the Dallas area after the Dallas Texans folded in 1952, but was originally met with strong opposition by Washington Redskins owner George Preston Marshall, who had enjoyed a monopoly as the only NFL team to represent the American South. Marshall later changed his position after future-Cowboys owner Clint Murchison bought the rights to Washington's fight song \"Hail to the Redskins\" and threatened to prevent Marshall from playing it at games. By then, the NFL wanted to quickly award the new Dallas franchise to Murchison so the team could immediately begin play and complete with the AFL's Texans. As a result, the Cowboys played its inaugural season in 1960 without the benefit of the NFL draft.\n\nAs part of the merger agreement, additional expansion teams would be awarded by 1970 or soon thereafter to bring the league to 28 franchises; this requirement was fulfilled when the Seattle Seahawks and the Tampa Bay Buccaneers began play in 1976. In addition, had it not been for the existence of the Oilers from 1960 to 1996, the Houston Texans also would likely not exist today; the 2002 expansion team restored professional football in Houston after the original charter AFL member Oilers relocated to become the Tennessee Titans.\n\nKevin Sherrington of \"The Dallas Morning News\" has argued that the presence of AFL and the subsequent merger radically altered the fortunes of the Pittsburgh Steelers, saving the team \"from stinking\". Before the merger, the Steelers had long been one of the NFL's worst teams. Constantly lacking the money to build a quality team, the Steelers had only posted eight winning seasons, and just one playoff appearance, since their first year of existence in 1933. They also finished with a 1-13 record in 1969, tied with the Chicago Bears for the worst record in the NFL. The $3 million indemnity that the Steelers received for joining the AFC with the rest of the former AFL teams after the merger helped them rebuild into a contender, drafting eventual-Pro Football Hall of Famers like Terry Bradshaw and Joe Greene, and ultimately winning four Super Bowls in the 1970s. Since the 1970 merger, the Steelers have the NFL's highest winning percentage, the most total victories, the most trips to either conference championship game, are tied for the second most trips to the Super Bowl (with the Dallas Cowboys and Denver Broncos, trailing only the New England Patriots), and have won an NFL-record six Super Bowl championships.\n\nPerhaps the greatest social legacy of the AFL was the domino effect of its policy of being more liberal than the entrenched NFL in offering opportunity for black players. While the NFL was still emerging from thirty years of segregation influenced by Washington Redskins' owner George Preston Marshall, the AFL actively recruited from small and predominantly black colleges. The AFL's color-blindness led not only to the explosion of black talent on the field, but to the eventual entry of blacks into scouting, coordinating, and ultimately head coaching positions, long after the league ceased to exist.\n\nThe AFL's free agents came from several sources. Some were players who could not find success playing in the NFL, while another source was the Canadian Football League. In the late 1950s, many players released by the NFL, or un-drafted and unsigned out of college by the NFL, went North to try their luck with the CFL, and later returned to the states to play in the AFL.\n\nIn the league's first years, players such as Oilers' George Blanda, Chargers/Bills' Jack Kemp, Texans' Len Dawson, the NY Titans' Don Maynard, Raiders/Patriots/Jets' Babe Parilli, Pats' Bob Dee proved to be AFL standouts. Other players such as the Broncos' Frank Tripucka, the Pats' Gino Cappelletti, the Bills' Cookie Gilchrist and the Chargers' Tobin Rote, Sam DeLuca and Dave Kocourek also made their mark to give the fledgling league badly needed credibility. Rounding out this mix of potential talent were the true \"free agents\", the walk-ons and the \"wanna-be's\", who tried out in droves for the chance to play professional American football.\n\nAfter the AFL–NFL merger agreement in 1966, and after the AFL's Jets defeated the \"best team in the history of the NFL\", the Colts, a popular misconception fostered by the NFL and spread by media reports was that the AFL defeated the NFL because of the Common Draft instituted in 1967. This apparently was meant to assert that the AFL could not achieve parity as long as it had to compete with the NFL in the draft. But the 1968 Jets had less than a handful of \"common draftees\". Their stars were honed in the AFL, many of them since the Titans days. As noted below, the AFL got its share of stars long before the \"common draft\".\n\nPlayers who chose the AFL to develop their talent included Lance Alworth and Ron Mix of the Chargers, who had also been drafted by the NFL's San Francisco 49ers and Baltimore Colts respectively. Both eventually were elected to the Pro Football Hall of Fame after earning recognition during their careers as being among the best at their positions. Among specific teams, the 1964 Buffalo Bills stood out by holding their opponents to a pro football record 913 yards rushing on 300 attempts, while also recording fifty quarterback sacks in a 14-game schedule.\n\nAnother example is cited by the University of Kansas website, which describes the 1961 Bluebonnet Bowl, won by KU, and goes on to say \"\"Two Kansas players, quarterback John Hadl and fullback Curtis McClinton, signed professional contracts on the field immediately after the conclusion of the game. Hadl inked a deal with the \"[AFL]\" San Diego Chargers, and McClinton went to the \"[AFL]\" Dallas Texans.\"\" Between them, in their careers Hadl and McClinton combined for an American Football League Rookie of the Year award, seven AFL All-Star selections, two Pro Bowl selections, a team MVP award, two AFL All-Star Game MVP awards, two AFL championships, and a World Championship. And these were players selected by the AFL long \"before\" the \"Common Draft\".\n\nIn 2009, a five-part series, \"\", on the \"Showtime Network\", refuted many of the long-held misconceptions about the AFL. In it, Abner Haynes tells of how his father forbade him to accept being drafted by the NFL, after drunken scouts from that league had visited the Haynes home; the NFL Cowboys' Tex Schramm is quoted as saying that if his team had ever agreed to play the AFL's Dallas Texans, they would very likely have lost; George Blanda makes a case for more AFL players being inducted to the Pro Football Hall of Fame by pointing out that Hall of Famer Willie Brown was cut by the Houston Oilers because he couldn't cover Oilers flanker Charlie Hennigan in practice. Later, when Brown was with the Broncos, Hennigan needed nine catches in one game against the Broncos to break Lionel Taylor's Professional Football record of 100 catches in one season. Hennigan caught the nine passes and broke the record, even though he was covered by Brown, Blanda's point being that if Hennigan could do so well against a Hall of Fame DB, he deserves induction, as well.\n\nThe AFL also spawned coaches whose style and techniques have profoundly affected the play of professional football to this day. In addition to AFL greats like Hank Stram, Lou Saban, Sid Gillman and Al Davis were eventual hall of fame coaches such as Bill Walsh, a protégé of Davis with the AFL Oakland Raiders for one season; and Chuck Noll, who worked for Gillman and the AFL LA/San Diego Chargers from 1960 through 1965. Others include Buddy Ryan (AFL's New York Jets), Chuck Knox (Jets), Walt Michaels (Jets), and John Madden (AFL's Oakland Raiders). Additionally, many prominent coaches began their pro football careers as players in the AFL, including Sam Wyche (Cincinnati Bengals), Marty Schottenheimer (Buffalo Bills), Wayne Fontes (Jets), and two-time Super Bowl winner Tom Flores (Oakland Raiders). Flores also has a Super Bowl ring as a player (1969 Kansas City Chiefs).\n\nAs the influence of the AFL continues through the present, the 50th anniversary of its launch was celebrated during 2009. The season-long celebration began in August with the 2009 Pro Football Hall of Fame Game in Canton, Ohio between two AFC teams (as opposed to the AFC-vs-NFC format the game first adopted in 1971). The opponents were two of the original AFL franchises, the Buffalo Bills and Tennessee Titans (the former Houston Oilers). Bills' owner Ralph C. Wilson Jr. (a 2009 Hall of Fame inductee) and Titans' owner Bud Adams were the only surviving members of the Foolish Club, the eight original owners of AFL franchises.\n\nThe Hall of Fame Game was the first of several \"Legacy Weekends\", during which each of the \"original eight\" AFL teams sported uniforms from their AFL era. Each of the 8 teams took part in at least two such \"legacy\" games. On-field officials also wore red-and-white-striped AFL uniforms during these games.\n\nIn the fall of 2009, the Showtime pay-cable network premiered \"\", a 5-part documentary series produced by NFL Films that features vintage game film and interviews as well as more recent interviews with those associated with the AFL.\n\nThe NFL sanctioned a variety of \"\"Legacy\"\" gear to celebrate the AFL anniversary, such as \"throwback\" jerseys, T-shirts, signs, pennants and banners, including items with the logos and colors of the Dallas Texans, Houston Oilers, and New York Titans, the three of the Original Eight AFL teams which have changed names or venues. A December 5, 2009 story by Ken Belson in the \"New York Times\" quotes league officials as stating that AFL \"\"Legacy\"\" gear made up twenty to thirty percent of the league's annual $3 billion merchandise income. Fan favorites were the Denver Broncos' vertically striped socks, which could not be re-stocked quickly enough.\n\nToday, two of the NFL's eight divisions are composed entirely of former AFL teams, the AFC West (Broncos, Chargers, Chiefs, and Raiders) and the AFC East (Bills, Dolphins, Jets, and Patriots). Additionally, the Bengals now play in the AFC North and the Tennessee Titans (formerly the Oilers) play in the AFC South.\n\nFrom 1960 to 1968, the AFL determined its champion via a single-elimination playoff game between the winners of its two divisions. The home teams alternated each year by division, so in 1968 the Jets hosted the Raiders, even though Oakland had a better record (this was changed in 1969). In 1963, the Buffalo Bills and Boston Patriots finished tied with identical records of 7–6–1 in the AFL East Division. There was no tie-breaker protocol in place, so a one-game playoff was held in War Memorial Stadium in December. The visiting Patriots defeated the host Bills 26–8. The Patriots traveled to San Diego as the Chargers completed a three-game season sweep over the weary Patriots with a 51–10 victory. A similar situation occurred in the 1968 season, when the Oakland Raiders and the Kansas City Chiefs finished the regular season tied with identical records of 12–2 in the AFL West Division. The Raiders beat the Chiefs 41–6 in a division playoff to qualify for the AFL Championship Game. In 1969, the final year of the independent AFL, Professional Football's first \"wild card\" playoffs were conducted. A four-team playoff was held, with the second-place teams in each division playing the winner of the other division. The Chiefs upset the Raiders in Oakland 17–7 in the league's Championship, the final AFL game played. The Kansas City Chiefs were the first Super Bowl champion to win two road playoff games and the first wildcard team to win the Super Bowl, although the term \"wildcard\" was coined by the media, and not used officially until several years later.\n\n\"Italics\" – Super Bowl Appearance, Bold – Super Bowl Victory\n\nThe AFL did not play an All-Star game after its first season in 1960, but did stage All-Star games for the 1961 through 1969 seasons. All-Star teams from the Eastern and Western divisions played each other after every season except 1965. That season, the league champion Buffalo Bills played all-stars from the other teams.\n\nAfter the 1964 season, the AFL All-Star game had been scheduled for early 1965 in New Orleans' Tulane Stadium. After numerous black players were refused service by a number of area hotels and businesses, black and white players alike called for a boycott. Led by Bills players such as Cookie Gilchrist, the players successfully lobbied to have the game moved to Houston's Jeppesen Stadium.\n\nAs chosen by 1969 AFL Hall of Fame Selection Committee Members:\n\nThe following is a sample of some records set during the existence of the league. The NFL considers AFL statistics and records equivalent to its own.\n\n\n\n\n\n", "id": "2357", "title": "American Football League"}
{"url": "https://en.wikipedia.org/wiki?curid=2358", "text": "A.S. Roma\n\nAssociazione Sportiva Roma (, ; \"Rome Sport Association\"), commonly referred to as simply Roma , is a professional Italian football club based in Rome. Founded by a merger in 1927, Roma have participated in the top-tier of Italian football for all of their existence except for 1951–52. For their 65th season in a row (84th overall), Roma are competing in Serie A for the 2016–17 season.\n\nRoma have won Serie A three times, first in 1941–42 then in 1982–83 and again in 2000–01, as well as winning nine Coppa Italia titles and two Supercoppa Italiana titles. On the European stage Roma won an Inter-Cities Fairs Cup in 1960–61, coming close to European Cup victory in 1983–84 (lost the one-legged final played at home against Liverpool), and finishing as runners-up in the UEFA Cup for 1990–91 (two-legged aggregate defeat against Internazionale). Therefore, Roma is the fourth Italian club by major honours won, behind Juventus, Milan and Inter.\n\nHome games are currently played at the Stadio Olimpico, a venue they share with city rivals Lazio. With a capacity of over 72,000, it is the second largest of its kind in Italy, with only the San Siro able to seat more. In September 2009 the club unveiled plans to build a Stadio della Roma (new 55,000-capacity) in the western suburbs of Rome. Its design was modelled after English football stadiums with the objective being to give fans a closer view of the pitch, and is said to be inspired by the Colosseum. In September 2011, it was announced that the new president, Thomas R. DiBenedetto, had reached an agreement with the mayor of Rome, Gianni Alemanno, to have the new stadium completed by 2016.\n\nA.S. Roma was founded in the summer of 1927 when Italo Foschi, initiated the merger of three older Italian Football Championship clubs from the city of Rome; Roman FC, SS Alba-Audace and Fortitudo-Pro Roma SGS. The purpose of the merger was to give the Italian capital a strong club to rival that of the more dominant Northern Italian clubs of the time. The only major Roman club to resist the merger was S.S. Lazio because of the intervention of the army General Vaccaro, member of the club and executive of Italian Football Federation.\nThe club played its earliest seasons at the \"Motovelodromo Appio\" stadium, before settling in the working-class streets of Testaccio, where it built an all-wooden ground \"Campo Testaccio\"; this was opened in November 1929. An early season in which Roma made a large mark was the 1930–31 championship, the club finished as runners-up behind Juventus. Captain Attilio Ferraris along with Guido Masetti, Fulvio Bernardini and Rodolfo Volk were highly important players during this period.\n\nAfter a slump in league form and the departure of high key players, Roma eventually rebuilt their squad adding goalscorers such as the Argentine Enrique Guaita. Under the management of Luigi Barbesino, the Roman club came close to their first title in 1935–36; finishing just one point behind champions Bologna.\n\nRoma returned to form after being inconsistent for much of the late 1930s; Roma recorded an unexpected title triumph in the 1941–42 season by winning their first ever\" scudetto\" title. The eighteen goals scored by local player Amedeo Amadei were essential to the Alfréd Schaffer coached Roma side winning the title. At the time Italy was involved in World War II and Roma were playing at the \"Stadio del Partito Nazionale Fascista\".\n\nIn the years just after the war, Roma were unable to recapture their league stature from the early 1940s. Roma finished in the lower half of Serie A for five seasons in a row, before eventually succumbing to their only ever relegation to Serie B at the end of the 1950–51 season; around a decade after their championship victory. Under future national team manager Giuseppe Viani, promotion straight back up was achieved.\n\nAfter returning to the Serie A, Roma managed to stabilise themselves as a top half club again with players such as Egisto Pandolfini, Dino Da Costa and Dane Helge Bronée. Their best finish of this period was under the management of Englishman Jesse Carver, when in 1954–55 they finished as runners-up, after Udinese who originally finished second were relegated for corruption.\nAlthough Roma were unable to break into the top four during the following decade, they did achieve some measure of cup success. Their first honour outside of Italy was recorded in 1960–61 when Roma won the Inter-Cities Fairs Cup by beating Birmingham City 4–2 in the finals. A few years later Roma won their first Coppa Italia trophy in 1963–64, by beating Torino 1–0.\n\nTheir lowest point came during the 1964–65 season when manager Juan Carlos Lorenzo announced that the club could not pay its players and was unlikely to be able to afford to travel to Vicenza to fulfil its next fixture. Supporters kept the club going with a fundraiser at the Sistine Theatre and bankruptcy was avoided with the election of a new club president Franco Evangelisti.\n\nTheir second Coppa Italia trophy was won in 1968–69 when it competed in a small league like system. Giacomo Losi set a Roma appearance record during 1969 with 450 appearances in all competitions, the record he set would last for 38 years.\n\nRoma were able to add another cup to their collection in 1972, with a 3–1 victory over Blackpool in the Anglo-Italian Cup. During much of the 1970s Roma's appearance in the top half of Serie A was sporadic. The best place the club were able to achieve during the decade was third in 1974–75. Notable players who turned out for the club during this period included midfielders Giancarlo De Sisti and Francesco Rocca.\n\nThe dawning of a newly successful era in Roma's footballing history was brought in with another Coppa Italia victory, they beat Torino on penalties to win the 1979–80 cup. Roma would reach heights in the league which they had not touched since the 1940s by narrowly and controversially finishing as runners-up to Juventus in 1980–81. Former Milan player Nils Liedholm was the manager at the time, with players such as Bruno Conti, Agostino Di Bartolomei, Roberto Pruzzo and Falcão.\nThe second \"scudetto\" did not elude Roma for much longer; in 1982–83 the Roman club won the title for the first time in 41 years, amidst celebrations in the capital. The following season Roma finished as runners-up in Italy and collected a Coppa Italia title, they also finished as runners-up in the European Cup final of 1984. The European Cup final with Liverpool ended in a 1–1 draw with a goal from Pruzzo, but Roma eventually lost the penalty shoot-out. Roma's successful run in the 1980s would finish with a runners-up spot in 1985–86 and a Coppa Italia victory, beating out Sampdoria 3–2.\n\nAfter that a comparative decline began in the league, one of the few league highs from the following period being a third-place finish in 1987–88. At the start of the 1990s the club was involved in an all-Italian UEFA Cup final, where they lost 2–1 to Internazionale in 1991; the same season the club won its seventh Coppa Italia trophy and ended runners-up to Sampdoria in the Supercoppa Italiana. Aside from finishing runners-up to Torino in a Coppa Italia final, the rest of the decade was largely sub-par in the history of Roma; especially in the league where the highest they could manage was fourth in 1997–98. The early 1990s also saw the emergence of homegrown striker Francesco Totti who would go on to be an important member of the team and the club's iconic captain.\n\nRoma returned to form in the 2000s, starting the decade in great style by winning their third ever Serie A title in 2000–01; the \"scudetto\" was won on the last day of the season by beating Parma 3–1, edging out Juventus by two points. The club's captain, Francesco Totti was a large reason for the title victory and he would become one of the main heroes in the club's history, going on to break several club records. Other important players during this period included Aldair, Cafu, Gabriel Batistuta, and Vincenzo Montella.\n\nThe club attempted to defend the title in the following season but ended as runners-up to Juventus by just one point. This would be the start of Roma finishing as runners-up many times in both Serie A and Coppa Italia during the 2000s; they lost out 4–2 to AC Milan in the Coppa Italia final of 2003 and lost out to Milan again by finishing second in Serie A for the 2003–04 season. The club also re-capitalized several time in 2003–04 season. In November 2003 €37.5 million was injected by \"Roma 2000\" to cover the half-year loss and loss carried from previous year. and again on 30 June for €44.57 million. Through stock market, a further €19.850 million of new shares issued, and at the year end, the share capital was €19.878 million, which unchanged . The following season also saw the departure of Walter Samuel for €25 million and Emerson for €28 million, which decreased the strength of the squad, thus \"Giallorossi\" finished as the eighth place, one of the worst of recent season. \n\nOn 9 July 2006, Roma's Francesco Totti, Daniele De Rossi and Simone Perrotta were part of the Italy team that beat France in the 2006 FIFA World Cup final. A Serie A scandal was revealed during 2006 and Roma were one of the teams not involved; after punishments were handed out, Roma was re-classified as runners-up for 2005–06; the same season in which they finished second in the Coppa Italia losing to Internazionale. In the two following seasons, 2006–07 and 2007–08, Roma finished as Serie A runners-up, meaning that in the 2000s Roma have finished in the top two positions more than any other decade in their history Meanwhile, in the UEFA Champions League during both of these seasons, they reached the quarter-finals before going out to Manchester United. Despite the sloppy start in the 2008–09 Champions League, Roma managed to reach the knockout stage ahead of Chelsea in their group, thus finishing for the first time in their history as winners of the group stage. The \"Giallorossi\", however, would lose to Arsenal in the knockout stage on penalty kicks, ending their Champions League campaign.\n\nAfter a disappointing start to the 2009–10 season, Claudio Ranieri replaced Luciano Spalletti as head coach. At the time of the switch, Roma lay bottom of the Serie A table after losses to Juventus and Genoa. Despite this setback, Roma would later embark on an incredible unbeaten streak of 24 matches in the league – with the last of the 24 being a 2–1 win over rivals Lazio, whereby Roma came from 1–0 down at half-time to defeat their city rivals after Ranieri courageously substituted both Totti and De Rossi at the interval. The Giallorossi were on top of the table at one point, before a loss to U.C. Sampdoria later in the season. Roma would finish runners-up to Inter yet again in both Serie A and the Coppa Italia. This rounded out a highly successful decade in Roma's history, following somewhat mediocre results of the 1990s. During the 2000s, Roma had finally recaptured the \"Scudetto\", two Coppa Italia trophies, and their first two Supercoppa Italiana titles. Other notable contributions to the club's history have included a return to the Champions League quarter-finals (in the 2006–07 and 2007–08 editions) since 1984, six runners up positions in the league, four Coppa Italia finals and three Supercoppa finals – marking Roma's greatest ever decade.\n\nIn the summer of 2010, the Sensi family agreed to relinquish their control of Roma as part of a debt-settlement agreement. This brought an end to the presidential reign of the Sensi family, who had presided over the club since 1993. Until a new owner was appointed, Rosella Sensi would continue her directorial role of the club. The 2010–11 season had once again seen Roma start off with mixed fortunes on both a domestic and European level. These included losses against teams like Cagliari, Brescia and a 2–0 defeat against Bayern Munich in the group stages of the Champions League, a match which saw manager Claudio Ranieri openly criticised by his players. However, these were accompanied by victories against Inter and a sensational victory against Bayern in the return fixture, which saw Roma fight back from 0–2 down at half-time to emerge as 3–2 winners. Following a series of poor results which saw Roma engage in a winless-streak of five consecutive matches, Ranieri resigned as head coach in February 2011, and former striker Vincenzo Montella was appointed as caretaker manager until the end of the season. It was also during this season that Roma icon Francesco Totti scored his 200th Serie A goal against Fiorentina in March 2011 – becoming only the sixth ever player to achieve such a feat.\n\nOn 16 April 2011, the takeover contract was closed with an American investment group led by Thomas R. DiBenedetto, with James Pallotta, Michael Ruane and Richard D'Amore as partners. DiBenedetto became the 22nd president of the club, serving from 27 September 2011 to 27 August 2012 and was succeeded by Pallotta. The new intermediate holding company, NEEP Roma Holding, was 60% owned by American's \"AS Roma SPV, LLC\" and the rest (40%) was retained by the creditor of Sensi, UniCredit; NEEP in turn owned all shares held previously by Sensi (about 67%) with the rest free float in the stock market. UniCredit later disinvested NEEP Roma Holding to sold to \"AS Roma SPV, LLC\" and Pallotta.\n\nThe new ownership immediately went into effect by making significant changes in the club, hiring Walter Sabatini as director of football and former Spanish international and Barcelona B coach Luis Enrique as manager. The first high-profile player signings from the duo were attacking midfielder Érik Lamela from River Plate, forward Bojan from Barcelona, goalkeeper Maarten Stekelenburg from Ajax and unattached defender Gabriel Heinze. The club also sold and released defender John Arne Riise, goalkeeper Doni and forwards Jérémy Ménez and Mirko Vučinić. At the financial level, the company had recapitalized for more than €100 million, the last recapitalization occurring in the early 2000s.\n\nRoma, however, was eliminated from 2011–12 UEFA Europa League play-off round. After the formal takeover on 18 August, Roma bought forward Dani Osvaldo, midfielders Miralem Pjanić and Fernando Gago and defender Simon Kjær, as well as youngster Fabio Borini, which cost the club more than €40 million. In 2012, Pallotta became the new president.\n\nThe 2012-13 pre-season started with the June hiring of former manager Zdeněk Zeman. Zeman replaced Luis Enrique who resigned at the end of the 2011–12 season. Enrique's lone season reign had seen the disappointing loss to Slovan Bratislava in the Europa League as well as the inability to qualify for international competitions for the 2012–13 season. Roma eventually finished 7th, losing the Europa League chase to rivals Lazio, Napoli and Internazionale. Zeman brought back his high-scoring 4–3–3 formation and his hard working ethic which successfully guided former team Pescara to the Serie A. He was, however, sacked on 2 February 2013. He was replaced by caretaker manager Aurelio Andreazzoli, who's reign saw the continuation of a disappointing season, with the team ending up in 6th place in Serie A, whilst also losing 1–0 to rivals Lazio in the Coppa Italia final. As a result, Roma missed out on European competition for the second season in a row. \n\nOn 12 June 2013, Pallotta announced that Rudi García had been appointed the new manager of Roma. He enjoyed a fantastic start to his Roma career, winning his first ten consecutive games (an all-time Serie A record) including a 2–0 derby win against Lazio, a 0–3 victory away to Inter and a 2–0 home win over title rivals Napoli. During this run, Roma scored 24 times while conceding just once, away to Parma. The 2013–14 season saw one of Roma's best ever in Serie A, the club tallying an impressive 85 points and finishing second to Juventus, who won the league with a record-breaking 102 points. Roma's defense was significantly better than in previous seasons, with only 25 goals conceded and a total of 21 clean sheets, including nine in their first ten matches.\n\nIn 2014-15, Roma finished second behind Juventus for the second consecutive season after a poor run of form in 2015. At the end of season the club was sanctioned for lose making and breaking UEFA Financial Fair Play Regulations.\n\nOn 13 January 2016, Garcia was sacked after a run of one win in seven Serie A games. Luciano Spalletti was appointed manager of Roma for his second spell. On 21 February, Totti publicly criticised Spalletti due to his own lack of playing-time since returning from injury; as a result, he was subsequently dropped by Spalletti for Roma's 5–0 win over Palermo, with the decision causing an uproar among the fans and in the media. After their initial disagreements, Spalletti began to use Totti as an immediate impact substitute, which proved to be an effective decision, as the Roma number 10 rediscovered his form, and contributed with four goals and an assist after coming off the bench in five consecutive Serie A games; as a result, Spalletti was able to lead Roma from a mid-table spot to a third-place finish in Serie A, clinching the UEFA Champions League play-off spot.\n\nDuring summer 2016 Roma lost star midfielder Miralem Pjanić to rivals Juventus in order to improve its financial position.\n\nRoma's colours of imperial purple with a golden yellow trim represents the traditional colours of Rome, the official seal of the \"Comune di Roma\" features the same colours. The gold and the purple-red represent Roman imperial dignity. White shorts and black socks are usually worn with the red shirt, however in particularly high key games the shorts and socks are the same colour as the home shirt.\n\nThe kit itself was originally worn by \"Roman Football Club\"; one of the three clubs who merged to form the current incarnation in 1927. Because of the colours they wear, Roma are often nicknamed \"i giallorossi\" meaning the yellow-reds. Roma's away kit is traditionally white, with a third kit changing colour from time to time. Maybe because of modern sport marketing, the last few years have seen the golden trim and details substituted by light orange. Modern alternate kits have included all orange and orange-maroon versions.\n\nA popular nickname for the club is \"i lupi\" (the wolves), the animal has always featured on the club's badge in different forms throughout their history. Currently the emblem of the team is the one which was used when the club was first founded. It portrays the female wolf with the two infant brothers Romulus and Remus, illustrating the myth of the founding of Rome, superimposed on a bipartite golden yellow over maroon red shield. In the myth from which the club take their nickname and logo, the twins (sons of Mars and Rhea Silvia) are thrown into the River Tiber by their uncle Amulius, a she-wolf saved the twins and looked after them. Eventually the two twins took revenge on Amulius, before falling out themselves; Romulus killed Remus and as thus was made king of a new city named in his honour, Rome.\n\nThe very first sport facility A.S. Roma used was Motovelodromo Appio which was previously used by Alba-Audace. A.S. Roma only played the 1927–28 season there until they moved to Campo Testaccio the very next season. Campo Testaccio was used through 1929 to 1940. The team moved later to the Stadio Nazionale del PNF where they spent 13 years before moving once again.\n\nIn the 1953–54 season A.S. Roma moved to the Olympic arena, Stadio Olimpico, which it shares with Lazio. The arena has undergone several changes over the years. The most significant change took place in the nineties when Stadio Olimpico was demolished and then reconstructed to for the Football World Cup 1990, witch took place in Italy. A.S. Roma has played almost every season since 1953–54, with exception of the 1989–90 seasons due to the reconstruction of Stadio Olimpico. That year Roma played its home games at Stadio Flaminio.\n\nOn 30 December 2012, AS Roma president James Pallotta announced the construction of a new stadium in the Tor di Valle area of Rome. The new stadium, Stadio della Roma will have a capacity of 60,000 spectators. On 2 February 2017, the Region of Lazio and the mayor of Rome rejected the proposal to build a new stadium, however, was later approved on 24 February after final review of the stadium's design adjustments. It is still uncertain how long it will take to open the stadium.\n\n\nA sports centre located in at kilometer 3600 in south-east of Rome was purchased on 22 July 1977 by the then club president Gaetano Anzalone. It was opened on 23 July 1979 as Anzalone's final act as president. The complex had its first expansion in 1984 when the club was handled by Dino Viola and another in 1998 under the chairmanship of Franco Sensi. The sports centre official name is Fulvio Bernardini di Trigoria, named after the club icon Fulvio Bernardini.\n\nThe sports centre is also known for hosting the Argentinian football team during the 1990 FIFA World Cup.\n\nRoma is the fifth-most supported football club in Italy, behind Juventus, Internazionale, Milan and Napoli, with around 7% of Italian football fans supporting the club (according to the Doxa Institute-L'Espresso's research of April 2006). Historically, the largest section of Roma supporters in the city of Rome have come from the inner-city, especially Testaccio.\n\nThe traditional ultras group of the club was \"Commando Ultrà Curva Sud\" commonly abbreviated as \"CUCS\". This group was founded by the merger of many smaller groups and was considered one of the most historic in the history of European football. By the mid-1990s, however, \"CUCS\" had been usurped by rival factions and ultimately broke up. Since that time, the \"Curva Sud\" of the Stadio Olimpico has been controlled by more right-wing groups, including \"A.S. Roma Ultras\", \"Boys\", \"Giovinezza\" and others. The oldest group, \"Fedayn\", is apolitical, however, and politics is not the main identity of Roma, just a part of their overall identity. Besides ultras groups, it is believed that Roma fans support the left as opposed to Lazio supporters, that are notoriously proud of their right-wing affiliation. In September 2009, the club unveiled plans to build a new 55,000-capacity stadium in Rome's western suburbs.\n\nIn November 2015, Roma's ultras and their Lazio counterparts boycotted Roma's 1-0 victory in the Derby della Capitale in protest at new safety measures imposed at the Stadio Olimpico. The measures, imposed by Rome’s prefect, Franco Gabrielli, had involved plastic glass dividing walls being installed in both the Curva Sud and Curva Nord, splitting the sections behind each goal in two. Both sets of ultras continued their protests for the rest of the season, including during Roma's 4-1 victory in the return fixture. Lazio's ultras returned to the Curva Nord for Roma's 1-4 victory in December 2016, but the Roma ultras continue to boycott games.\nThe most known club anthem is \"Roma (non-si discute, si ama)\", also known as \"Roma Roma\", by singer Antonello Venditti. The title roughly means, \"Roma is not to be questioned, it is to be loved,\" and it is sung before each match. The song \"Grazie Roma\", by the same singer, is played at the end of victorious home games. Recently, the main riff of The White Stripes' song \"Seven Nation Army\" has also become widely popular at games.\n\nIn Italian football, Roma is a club with many rivalries; first and foremost is their rivalry with Lazio, the club with whom they share the Stadio Olimpico. The derby between the two is called the \"Derby della Capitale\", it is amongst the most heated and emotional footballing rivalries in the world. The fixture has seen some occasional instances of violence in the past, including the death of Lazio fan Vincenzo Paparelli in 1979–80 as a result of an emergency flare fired from the Curva Sud, and the abandonment of a game in March 2004, following unfounded rumours of a fatality which led to violence outside the stadium.\n\nWith Napoli, Roma also compete in the \"Derby del Sole\", rivalry meaning the \"Derby of the Sun\". Nowadays, fans also consider other Serie A giants like Juventus (rivalry born especially in the 1980s), Milan and Inter (increased in recent years) among their rivals, as these four compete for the top three spots in the league table to secure a spot in the Champions League.\n\nThere have been a number of instances of conflict in recent years between some Roma supporters and fans of English clubs, and the subsequent violence outside the stadium which saw a number of Liverpool fans stabbed. Since then, there have been further instances of some English supporters being attacked and stabbed in Rome, including incidents in 2001 when Liverpool visited Roma twice and subsequent clashes with Middlesbrough fans in 2006 and Manchester United fans in 2007. In March 2009, a coach carrying Arsenal supporters was attacked by a group of Roma ultras just outside the Stadio Olimpico. The coach's windows were smashed and at least one person entered the vehicle, letting off a flare and stabbed a supporter in the knee.\n\nRoma have had numerous chairmen over the course of their history, some of which have been the owners of the club, others have been honorary chairmen. Franco Sensi was the chairman until his death in 2008, with his daughter Rosella Sensi in place as honorary chairmen. Here is a complete list of Roma chairmen from 1927 until the present day.\nRoma have had many managers and trainers running the team during their history, here is a chronological list of them from 1927 onwards.\nSerie A\n\nCoppa Italia\n\nSupercoppa Italiana\n\nSerie B\n\nInter-Cities Fairs Cup\n\nOn 7 October 2012, the Hall of Fame of Roma was announced.\nThe Hall of Fame players was voted via the club's official website and a special Hall of Fame panel. In 2013 four players was voted in as well as in 2014, the third year of AS Roma Hall of Fame four more players was voted in.\n\nAdded in 2012:\n\nAdded in 2013:\n\nAdded in 2014:\n\nAdded in 2015:\n\nAdded in 2016:\nFrancesco Totti holds Roma's official appearance record, having made 782 (as of 18 April 2017) appearances in all competitions, over the course of 25 seasons from 1992 until the present day. He also holds the record for Serie A appearances with 615, as he passed Giacomo Losi on 1 March 2008 during a home match against Parma.\n\nIncluding all competitions, Totti is the all-time leading goalscorer for Roma with 307 goals since joining the club, 250 of which were scored in Serie A (another Roma record). Roberto Pruzzo, who was the all-time topscorer since 1988, comes in second in all competitions with 136. In the 1930–31 season, Rodolfo Volk scored 29 goals in Serie A over the course of a single season; not only was he the league's top scorer that year, but he set a Roma record for most goals scored in a season, which still lasts today.\n\nIts major founders Fortitudo and Alba having been relegated at the end of 1926–27 campaign, new-founded Roma had to take part to Southern First Division championship (Serie B) for its inaugural season; nevertheless the FIGC decided a special enlargement of first level division re-admitting AS Roma as SSC Napoli. The first ever official game participated in by Roma was in the National Division, the predecessor of Serie A, of 1927–28, against Livorno; Roma won 2–0. The biggest ever victory recorded by Roma was 9–0 against Cremonese during the Serie A season of 1929–30. The heaviest defeat Roma have ever suffered is 7–1, which has occurred three times, first against Juventus during 1931–32, then against Torino in 1947–48 and most recently against Manchester United in 2006–07.\n\nSince 1999, during Franco Sensi's period in charge, Associazione Sportiva Roma has been a listed Società per azioni on Borsa Italiana. From 2004 to 2011, Roma's shares are distributed between; 67.1% to Compagnia Italpetroli SpA (the Sensi family \"holding\"; Banca di Roma later acquired 49% stake on Italpetroli due to debt restructuring) and 32.9% to other public shareholders.\n\nAlong with Lazio and Juventus, Roma is one of only three quotated Italian clubs. According to The Football Money League published by consultants Deloitte, in the 2010–11 season, Roma was the 15th highest-earning football club in the world with an estimated revenue of €143.5 million.\n\nIn April 2008, after months of speculation, George Soros was confirmed by Rosella Sensi, CEO of Italian Serie A association football club A.S. Roma, to be bidding for a takeover. The takeover bid was successively rejected by the Sensi family, who instead preferred to maintain the club's ownership. On 17 August 2008 club chairman and owner Franco Sensi died after a long illness; his place at the chairmanship of the club was successively taken by his daughter Rosella.\n\nSince the takeover in 2011, NEEP Roma Holding S.p.A. owned all shares Sensi previously hold. NEEP, itself a joint venture, was held by DiBenedetto AS Roma LLC (later renamed to AS Roma SPV, LLC) and Unicredit in 60–40 ratio from 2011 to 2013, which the former had four real person shareholders in equal ratio, led by future Roma president Thomas R. DiBenedetto (2011–12). The takeover also activated a mandatory bid of shares from the general public, however not all minority shareholders willing to sell their shares. The mandatory bid had made NEEP held 78.038% of shares of AS Roma (increased from 67.1% of the Sensi). On 1 August 2013, the president of Roma as well as one of the four American shareholder of AS Roma SPV, LLC, James Pallotta, bought an additional 9% shares of NEEP Roma Holding from Unicredit (through Raptor Holdco LLC), as the bank not willing to fully participate in the capital increase of NEEP from €120,000 to €160,008,905 (excluding share premium). On 4 April 2014 Starwood Capital Group also became the fifth shareholder of AS Roma SPV, as well as forming strategic partnership with AS Roma SpA to develop real estate around the new stadium. The private investment firm was represented by Zsolt Kohalmi in AS Roma SPV, whom was appointed on 4 April as a partner and head of European acquisitions of the firm. On 11 August 2014, UniCredit sold the remain shares on NEEP (of 31%) for €33 million which made AS Roma SPV LLC (91%) and Raptor Holdco LLC (9%) were the sole intermediate holding company of AS Roma SpA.\n\nSince re-capitalization in 2003–04, Roma had a short-lived financial self-sustainability, until the takeover in 2011. The club had set up a special amortisation fund using Articolo 18-bis Legge 91/1981 mainly for the abnormal signing prior 2002–03 season, (such as Davide Bombardini for €11 million account value in June 2002, which the flopped player exchange boosted 2001–02 season result) and the tax payment of 2002–03 was rescheduled. In 2004–05, Roma made a net profit of €10,091,689 and followed by €804,285 in 2005–06. In 2006–07 season the accounting method changed to IFRS, which 2005–06 result was reclassified as net loss of €4,051,905 and 2006–07 season was net income of €10,135,539 (€14.011 million as a group). Moreover, the special fund (€80,189,123) was removed from the asset and co-currently for the equity as scheduled, made Roma group had a negative equity of €8.795 million on 30 June 2007. In 2007–08, Roma made a net income of €18,699,219. (€19 million as a group) However, 2008–09 saw the decrease of gate and TV income, co-currently with finished sixth in Serie A, which saw Roma made a net loss of €1,894,330. (€1.56 million as a group) The gate and TV income further slipped in 2009–10 with a net loss of €21,917,292 (already boosted by the sale of Alberto Aquilani; €22 million as a group) despite sporting success (finishing in second place in 2009–10). Moreover, despite a positive equity as a separate company (€105,142,589), the AS Roma Group had a negative equity on the consolidated balance sheet, and fell from +€8.8 million to −€13.2 million. In the 2010–11 season, Roma was administrated by UniCredit as the Sensi family failed to repay the bank and the club was put into the market, which also saw Roma not have a major signing in 2010–11. Concurrently with no selling profit on the player, Roma's net loss rose to €30,589,137 (€30.778 million as a group) and the new owner already planned a re-capitalization after the mandatory bid on the shares. On the positive side, TV income was increased from €75,150,744 to €78,041,642, and gate income increased from €23,821,218 to €31,017,179. This was because Roma entered 2010–11 Champions League, which counter-weighed the effect of the new collective agreement of Serie A. In 2011–12, the renewal of squad and participate in 2011–12 UEFA Europa League had worsened the financial result, which the €50 million capital increase (in advance) was counter-weighted totally by the net loss. In the 2012–13 season, the participation in domestic league only, not only not harmful to the revenue but increase in gate income as well as decrease in wage bill, however Roma still did not yet break even (€40.130 million net loss in consolidated accounts). NEEP Roma also re-capitalized AS Roma in advance for another €26,550,000 during 2012–13. A proposed capital increase by €100 million for Roma was announced on 25 June 2014; however, until 22 May 2014, NEEP already injected €108 million into the club, which depends on public subscription; more than €8 million would convert to medium-long-term loan from shareholder instead of becoming share capital.\n\nOne of the subsidiaries of Roma (joint venture with football clubs Lazio, 37.5% x2 and Parma, 25%), Società Diritti Sportivi S.r.l., was in the process of liquidation since 2005. The company was a joint-venture of four football clubs, including Fiorentina. After the bankruptcy of the old \"Viola\", however, both Roma and Lazio had increased their shares ratio from 25% to 37.5%. Another subsidiary, \"Soccer S.A.S. di Brand Management S.r.l.\", was a special-purpose entity (SPV) that Roma sold their brand to the subsidiary in 2007. In February 2015, another SPV, \"ASR Media and Sponsorship S.r.l\", was set up in order to secure a five-year bank loan of €175 million from Goldman Sachs, for three month Euribor (min. 0.75%) + 6.25% spread (i.e. min. 7% interests rate p.a.).\n\nIn 2015, Inter and Roma were the only two Italian clubs that were sanctioned by UEFA for breaking UEFA Financial Fair Play Regulations.\n\nA.S. Roma had a team in the Superleague Formula race car series where teams were sponsored by football clubs. Roma's driver was ex-IndyCar Series driver Franck Perera. The team had posted three podiums and was operated by Alan Docking Racing.\n\n\n", "id": "2358", "title": "A.S. Roma"}
{"url": "https://en.wikipedia.org/wiki?curid=2360", "text": "Abu Nidal Organization\n\nThe Abu Nidal Organization (ANO) is the most common name for the Palestinian group Fatah–The Revolutionary Council (\"Fatah al-Majles al-Thawry\").\nThe ANO is named after its founder Abu Nidal. It was created by a split from Yasser Arafat's Fatah faction of the PLO in 1974. The group has been designated as a terrorist organization by the United States, the United Kingdom, Israel and the European Union.\n\nThe ANO was originally formed as a result of the 1974 Rejectionist Front split in the PLO, after Arafat's Fatah had pushed through amendments of the PLO's goals, which were seen as a step towards compromise with Israel. Abu Nidal then moved to Ba'athist Iraq where he set up the ANO, which soon began a vicious string of terrorist attacks.\n\nIt has not clearly defined its ideological position, but was clearly opposed to any form of compromise or negotiation with Israel. It is known as one of the most uncompromisingly militant Palestinian groups ever. It had an estimated membership of several hundred, but its strength today is not known.\n\nThe ANO carried out attacks in 20 countries, killing or injuring almost 1650 persons. Targets include the United States, the United Kingdom, France, Israel, moderate Palestinians, the PLO, and various Arab and European countries. The group has not attacked Western targets since the late 1980s.\n\nMajor attacks included the Rome and Vienna Airport Attacks in December 1985, the Neve Shalom synagogue in Istanbul and the Pan Am Flight 73 hijacking in Karachi in September 1986, and the \"City of Poros\" day-excursion ship attack in Greece in July 1988.\n\nThe ANO has been especially noted for its uncompromising stance on negotiation with Israel, treating anything less than all-out military struggle against Israel as treachery. This led the group to perform numerous attacks against the PLO, which had made clear it accepted a negotiated solution to the conflict. Fatah-RC is believed to have assassinated PLO deputy chief Abu Iyad and PLO security chief Abu Hul in Tunis in January 1991. It assassinated a Jordanian diplomat in Lebanon in January 1994 and has been linked to the killing of the PLO representative there. Noted PLO moderate Issam Sartawi was killed by the Fatah-RC in 1983. In the late 1970s, the group also made failed assassination attempt on the present Palestinian president and PLO chairman, Mahmoud Abbas. These attacks, and numerous others, led to the PLO issuing a death sentence \"in absentia\" against Abu Nidal. In the early 1990s, it made an attempt to gain control of a refugee camp in Lebanon, but this was thwarted by PLO organizations.\n\n\n", "id": "2360", "title": "Abu Nidal Organization"}
{"url": "https://en.wikipedia.org/wiki?curid=2362", "text": "Antibody\n\nAn antibody (Ab), also known as an immunoglobulin (Ig), is a large, Y-shaped protein produced mainly by plasma cells that is used by the immune system to neutralize pathogens such as bacteria and viruses. The antibody recognizes a unique molecule of the harmful agent, called an antigen, via the Fab's variable region. Each tip of the \"Y\" of an antibody contains a paratope (analogous to a lock) that is specific for one particular epitope (similarly analogous to a key) on an antigen, allowing these two structures to bind together with precision. Using this binding mechanism, an antibody can \"tag\" a microbe or an infected cell for attack by other parts of the immune system, or can neutralize its target directly (for example, by blocking a part of a microbe that is essential for its invasion and survival). Depending on the antigen, the binding may impede the biological process causing the disease or may activate macrophages to destroy the foreign substance. The ability of an antibody to communicate with the other components of the immune system is mediated via its Fc region (located at the base of the \"Y\"), which contains a conserved glycosylation site involved in these interactions. The production of antibodies is the main function of the humoral immune system.\n\nAntibodies are secreted by B cells of the adaptive immune system, mostly by differentiated B cells called plasma cells. Antibodies can occur in two physical forms, a soluble form that is secreted from the cell to be free in the blood plasma, and a membrane-bound form that is attached to the surface of a B cell and is referred to as the B-cell receptor (BCR). The BCR is found only on the surface of B cells and facilitates the activation of these cells and their subsequent differentiation into either antibody factories called plasma cells or memory B cells that will survive in the body and remember that same antigen so the B cells can respond faster upon future exposure. In most cases, interaction of the B cell with a T helper cell is necessary to produce full activation of the B cell and, therefore, antibody generation following antigen binding. Soluble antibodies are released into the blood and tissue fluids, as well as many secretions to continue to survey for invading microorganisms.\n\nAntibodies are glycoproteins belonging to the immunoglobulin superfamily. They constitute most of the gamma globulin fraction of the blood proteins. They are typically made of basic structural units—each with two large heavy chains and two small light chains. There are several different types of antibody heavy chains that define the five different types of crystallisable fragments (Fc) that may be attached to the antigen-binding fragments. The five different types of Fc regions allow antibodies to be grouped into five \"isotypes\". Each Fc region of a particular antibody isotype is able to bind to its specific Fc Receptor (except for IgD, which is essentially the BCR), thus allowing the antigen-antibody complex to mediate different roles depending on which FcR it binds. The ability of an antibody to bind to its corresponding FcR is further modulated by the structure of the glycan(s) present at conserved sites within its Fc region. The ability of antibodies to bind to FcRs helps to direct the appropriate immune response for each different type of foreign object they encounter. For example, IgE is responsible for an allergic response consisting of mast cell degranulation and histamine release. IgE's Fab paratope binds to allergic antigen, for example house dust mite particles, while its Fc region binds to Fc receptor ε. The allergen-IgE-FcRε interaction mediates allergic signal transduction to induce conditions such as asthma\n\nThough the general structure of all antibodies is very similar, a small region at the tip of the protein is extremely variable, allowing millions of antibodies with slightly different tip structures, or antigen-binding sites, to exist. This region is known as the \"hypervariable region\". Each of these variants can bind to a different antigen. This enormous diversity of antibody paratopes on the antigen-binding fragments allows the immune system to recognize an equally wide variety of antigens. The large and diverse population of antibody paratope is generated by random recombination events of a set of gene segments that encode different antigen-binding sites (or \"paratopes\"), followed by random mutations in this area of the antibody gene, which create further diversity. This recombinational process that produces clonal antibody paratope diversity is called V(D)J or VJ recombination. Basically, the antibody paratope is polygenic, made up of three genes, V, D, and J. Each paratope locus is also polymorphic, such that during antibody production, one allele of V, one of D, and one of J is chosen. These gene segments are then joined together using random genetic recombination to produce the paratope. The regions where the genes are randomly recombined together is the hyper variable region used to recognise different antigens on a clonal basis.\n\nAntibody genes also re-organize in a process called class switching that changes the one type of heavy chain Fc fragment to another, creating a different isotype of the antibody that retains the antigen-specific variable region. This allows a single antibody to be used by different types of Fc receptors, expressed on different parts of the immune system.\n\nThe membrane-bound form of an antibody may be called a \"surface immunoglobulin\" (sIg) or a \"membrane immunoglobulin\" (mIg). It is part of the \"B cell receptor\" (BCR), which allows a B cell to detect when a specific antigen is present in the body and triggers B cell activation. The BCR is composed of surface-bound IgD or IgM antibodies and associated Ig-α and Ig-β heterodimers, which are capable of signal transduction. A typical human B cell will have 50,000 to 100,000 antibodies bound to its surface. Upon antigen binding, they cluster in large patches, which can exceed 1 micrometer in diameter, on lipid rafts that isolate the BCRs from most other cell signaling receptors.\nThese patches may improve the efficiency of the cellular immune response. In humans, the cell surface is bare around the B cell receptors for several hundred nanometers, which further isolates the BCRs from competing influences.\n\nThe antibody's paratope interacts with the antigen's epitope. An antigen usually contains different epitopes along its surface arranged discontinuously, and dominant epitopes on a given antigen are called determinants.\n\nAntibody and antigen interact by spatial complementarity (lock and key). The molecular forces involved in the Fab-epitope interaction are weak and non-specific – for example electrostatic forces, hydrogen bonds, hydrophobic interactions, and van der Waals forces. This means binding between antibody and antigen is reversible, and the antibody's affinity towards an antigen is relative rather than absolute. Relatively weak binding also means it is possible for an antibody to cross-react with different antigens of different relative affinities.\n\nOften, once an antibody and antigen bind, they become an immune complex, which functions as a unitary object and can act as an antigen in its own right, being countered by other antibodies. Similarly, haptens are small molecules that provoke no immune response by themselves, but once they bind to proteins, the resulting complex or hapten-carrier adduct is antigenic.\n\nAntibodies can come in different varieties known as isotypes or classes. In placental mammals there are five antibody isotypes known as IgA, IgD, IgE, IgG, and IgM. They are each named with an \"Ig\" prefix that stands for immunoglobulin, a name sometimes used interchangeably with antibody, and differ in their biological properties, functional locations and ability to deal with different antigens, as depicted in the table. The different suffixes of the antibody isotypes denote the different types of heavy chains the antibody contains, with each heavy chain class named alphabetically: α (alpha), γ (gamma), δ (delta), ε (epsilon), and μ (mu). This gives rise to IgA, IgG, IgD, IgE, and IgM, respectively.\n\nThe antibody isotype of a B cell changes during cell development and activation. Immature B cells, which have never been exposed to an antigen, express only the IgM isotype in a cell surface bound form. The B lymphocyte, in this ready-to-respond form, is known as a \"naive B lymphocyte.\" The naive B lymphocyte expresses both surface IgM and IgD. The co-expression of both of these immunoglobulin isotypes renders the B cell ready to respond to antigen. B cell activation follows engagement of the cell-bound antibody molecule with an antigen, causing the cell to divide and differentiate into an antibody-producing cell called a plasma cell. In this activated form, the B cell starts to produce antibody in a secreted form rather than a membrane-bound form. Some daughter cells of the activated B cells undergo isotype switching, a mechanism that causes the production of antibodies to change from IgM or IgD to the other antibody isotypes, IgE, IgA, or IgG, that have defined roles in the immune system.\n\nAntibodies are heavy (~150 kDa) globular plasma proteins. They have sugar chains (glycans) added to conserved amino acid residues. In other words, antibodies are \"glycoproteins\". The attached glycans are critically important to the structure and function of the antibody. Among other things the expressed glycans can modulate an antibody's affinity for its corresponding FcR(s).\n\nThe basic functional unit of each antibody is an immunoglobulin (Ig) monomer (containing only one Ig unit); secreted antibodies can also be dimeric with two Ig units as with IgA, tetrameric with four Ig units like teleost fish IgM, or pentameric with five Ig units, like mammalian IgM.\n\nThe Ig monomer is a \"Y\"-shaped molecule that consists of four polypeptide chains; two identical \"heavy chains\" and two identical \"light chains\" connected by disulfide bonds.\nEach chain is composed of structural domains called immunoglobulin domains. These domains contain about 70–110 amino acids and are classified into different categories (for example, variable or IgV, and constant or IgC) according to their size and function. They have a characteristic immunoglobulin fold in which two beta sheets create a \"sandwich\" shape, held together by interactions between conserved cysteines and other charged amino acids.\n\nThere are five types of mammalian Ig heavy chain denoted by the Greek letters: α, δ, ε, γ, and μ. The type of heavy chain present defines the \"class\" of antibody; these chains are found in IgA, IgD, IgE, IgG, and IgM antibodies, respectively. Distinct heavy chains differ in size and composition; α and γ contain approximately 450 amino acids, whereas μ and ε have approximately 550 amino acids.\nEach heavy chain has two regions, the \"constant region\" and the \"variable region\". The constant region is identical in all antibodies of the same isotype, but differs in antibodies of different isotypes. Heavy chains γ, α and δ have a constant region composed of \"three\" tandem (in a line) Ig domains, and a hinge region for added flexibility; heavy chains μ and ε have a constant region composed of \"four\" immunoglobulin domains. The variable region of the heavy chain differs in antibodies produced by different B cells, but is the same for all antibodies produced by a single B cell or B cell clone. The variable region of each heavy chain is approximately 110 amino acids long and is composed of a single Ig domain.\n\nIn mammals there are two types of immunoglobulin light chain, which are called lambda (λ) and kappa (κ). A light chain has two successive domains: one constant domain and one variable domain. The approximate length of a light chain is 211 to 217 amino acids. Each antibody contains two light chains that are always identical; only one type of light chain, κ or λ, is present per antibody in mammals. Other types of light chains, such as the iota (ι) chain, are found in other vertebrates like sharks (Chondrichthyes) and bony fishes (Teleostei).\n\nSome parts of an antibody have the same functions. The arms of the Y, for example, contain the sites that can bind to antigens (in general, identical) and, therefore, recognize specific foreign objects. This region of the antibody is called the \"Fab (fragment, antigen-binding) region\". It is composed of one constant and one variable domain from each heavy and light chain of the antibody.\nThe paratope is shaped at the amino terminal end of the antibody monomer by the variable domains from the heavy and light chains. The variable domain is also referred to as the F region and is the most important region for binding to antigens. To be specific, variable loops of β-strands, three each on the light (V) and heavy (V) chains are responsible for binding to the antigen. These loops are referred to as the complementarity determining regions (CDRs).\nThe structures of these CDRs have been clustered and classified by Chothia et al.\nand more recently by North et al.\nand Nikoloudis et al.\nIn the framework of the immune network theory, CDRs are also called idiotypes. According to immune network theory, the adaptive immune system is regulated by interactions between idiotypes.\n\nThe base of the Y plays a role in modulating immune cell activity. This region is called the \"Fc (Fragment, crystallizable) region\", and is composed of two heavy chains that contribute two or three constant domains depending on the class of the antibody. Thus, the Fc region ensures that each antibody generates an appropriate immune response for a given antigen, by binding to a specific class of Fc receptors, and other immune molecules, such as complement proteins. By doing this, it mediates different physiological effects including recognition of opsonized particles (binding to FcγR), lysis of cells (binding to complement), and degranulation of mast cells, basophils, and eosinophils (binding to FcεR).\n\nIn summary, the Fab region of the antibody determines antigen specificity while the Fc region of the antibody determines the antibody's class effect. Since only the constant domains of the heavy chains make up the Fc region of an antibody, the classes of heavy chain in antibodies determine their class effects. Possible classes of heavy chains in antibodies include alpha, gamma, delta, epsilon, and mu, and they define the antibody's isotypes IgA, G, D, E, and M, respectively. This infers different isotypes of antibodies have different class effects due to their different Fc regions binding and activating different types of receptors. Possible class effects of antibodies include: Opsonisation, agglutination, haemolysis, complement activation, mast cell degranulation, and neutralisation (though this class effect may be mediated by the Fab region rather than the Fc region). It also implies that Fab-mediated effects are directed at microbes or toxins, whilst Fc mediated effects are directed at effector cells or effector molecules (see below).\n\nThe main categories of antibody action include the following:\n\nActivated B cells differentiate into either antibody-producing cells called plasma cells that secrete soluble antibody or memory cells that survive in the body for years afterward in order to allow the immune system to remember an antigen and respond faster upon future exposures.\n\nAt the prenatal and neonatal stages of life, the presence of antibodies is provided by passive immunization from the mother. Early endogenous antibody production varies for different kinds of antibodies, and usually appear within the first years of life. Since antibodies exist freely in the bloodstream, they are said to be part of the humoral immune system. Circulating antibodies are produced by clonal B cells that specifically respond to only one antigen (an example is a virus capsid protein fragment). Antibodies contribute to immunity in three ways: They prevent pathogens from entering or damaging cells by binding to them; they stimulate removal of pathogens by macrophages and other cells by coating the pathogen; and they trigger destruction of pathogens by stimulating other immune responses such as the complement pathway. Antibodies will also trigger vasoactive amine degranulation to contribute to immunity against certain types of antigens (helminths, allergens).\n\nAntibodies that bind to surface antigens (for example, on bacteria) will attract the first component of the complement cascade with their Fc region and initiate activation of the \"classical\" complement system. This results in the killing of bacteria in two ways. First, the binding of the antibody and complement molecules marks the microbe for ingestion by phagocytes in a process called opsonization; these phagocytes are attracted by certain complement molecules generated in the complement cascade. Second, some complement system components form a membrane attack complex to assist antibodies to kill the bacterium directly (bacteriolysis).\n\nTo combat pathogens that replicate outside cells, antibodies bind to pathogens to link them together, causing them to agglutinate. Since an antibody has at least two paratopes, it can bind more than one antigen by binding identical epitopes carried on the surfaces of these antigens. By coating the pathogen, antibodies stimulate effector functions against the pathogen in cells that recognize their Fc region.\n\nThose cells that recognize coated pathogens have Fc receptors, which, as the name suggests, interact with the Fc region of IgA, IgG, and IgE antibodies. The engagement of a particular antibody with the Fc receptor on a particular cell triggers an effector function of that cell; phagocytes will phagocytose, mast cells and neutrophils will degranulate, natural killer cells will release cytokines and cytotoxic molecules; that will ultimately result in destruction of the invading microbe. The activation of natural killer cells by antibodies initiates a cytotoxic mechanism known as antibody-dependent cell-mediated cytotoxicity (ADCC) – this process may explain the efficacy of monoclonal antibodies used in biological therapies against cancer. The Fc receptors are isotype-specific, which gives greater flexibility to the immune system, invoking only the appropriate immune mechanisms for distinct pathogens.\n\nHumans and higher primates also produce \"natural antibodies\" that are present in serum before viral infection. Natural antibodies have been defined as antibodies that are produced without any previous infection, vaccination, other foreign antigen exposure or passive immunization. These antibodies can activate the classical complement pathway leading to lysis of enveloped virus particles long before the adaptive immune response is activated. Many natural antibodies are directed against the disaccharide galactose α(1,3)-galactose (α-Gal), which is found as a terminal sugar on glycosylated cell surface proteins, and generated in response to production of this sugar by bacteria contained in the human gut. Rejection of xenotransplantated organs is thought to be, in part, the result of natural antibodies circulating in the serum of the recipient binding to α-Gal antigens expressed on the donor tissue.\n\nVirtually all microbes can trigger an antibody response. Successful recognition and eradication of many different types of microbes requires diversity among antibodies; their amino acid composition varies allowing them to interact with many different antigens. It has been estimated that humans generate about 10 billion different antibodies, each capable of binding a distinct epitope of an antigen. Although a huge repertoire of different antibodies is generated in a single individual, the number of genes available to make these proteins is limited by the size of the human genome. Several complex genetic mechanisms have evolved that allow vertebrate B cells to generate a diverse pool of antibodies from a relatively small number of antibody genes.\n\nThe chromosomal region that encodes an antibody is large and contains several distinct gene loci for each domain of the antibody—the chromosome region containing heavy chain genes (IGH@) is found on chromosome 14, and the loci containing lambda and kappa light chain genes (IGL@ and IGK@) are found on chromosomes 22 and 2 in humans. One of these domains is called the variable domain, which is present in each heavy and light chain of every antibody, but can differ in different antibodies generated from distinct B cells. Differences, between the variable domains, are located on three loops known as hypervariable regions (HV-1, HV-2 and HV-3) or complementarity determining regions (CDR1, CDR2 and CDR3). CDRs are supported within the variable domains by conserved framework regions. The heavy chain locus contains about 65 different variable domain genes that all differ in their CDRs. Combining these genes with an array of genes for other domains of the antibody generates a large cavalry of antibodies with a high degree of variability. This combination is called V(D)J recombination discussed below.\n\nSomatic recombination of immunoglobulins, also known as \"V(D)J recombination\", involves the generation of a unique immunoglobulin variable region. The variable region of each immunoglobulin heavy or light chain is encoded in several pieces—known as gene segments (subgenes). These segments are called variable (V), diversity (D) and joining (J) segments. V, D and J segments are found in Ig heavy chains, but only V and J segments are found in Ig light chains. Multiple copies of the V, D and J gene segments exist, and are tandemly arranged in the genomes of mammals. In the bone marrow, each developing B cell will assemble an immunoglobulin variable region by randomly selecting and combining one V, one D and one J gene segment (or one V and one J segment in the light chain). As there are multiple copies of each type of gene segment, and different combinations of gene segments can be used to generate each immunoglobulin variable region, this process generates a huge number of antibodies, each with different paratopes, and thus different antigen specificities. Interestingly, the rearrangement of several subgenes (i.e. V2 family) for lambda light chain immunoglobulin is coupled with the activation of microRNA miR-650, which further influences biology of B-cells.\n\nRAG proteins play an important role with V(D)J recombination in cutting DNA at a particular region. Without the presence of these proteins, V(D)J recombination would not occur.\n\nAfter a B cell produces a functional immunoglobulin gene during V(D)J recombination, it cannot express any other variable region (a process known as allelic exclusion) thus each B cell can produce antibodies containing only one kind of variable chain.\n\nFollowing activation with antigen, B cells begin to proliferate rapidly. In these rapidly dividing cells, the genes encoding the variable domains of the heavy and light chains undergo a high rate of point mutation, by a process called \"somatic hypermutation\" (SHM). SHM results in approximately one nucleotide change per variable gene, per cell division. As a consequence, any daughter B cells will acquire slight amino acid differences in the variable domains of their antibody chains.\n\nThis serves to increase the diversity of the antibody pool and impacts the antibody's antigen-binding affinity. Some point mutations will result in the production of antibodies that have a weaker interaction (low affinity) with their antigen than the original antibody, and some mutations will generate antibodies with a stronger interaction (high affinity). B cells that express high affinity antibodies on their surface will receive a strong survival signal during interactions with other cells, whereas those with low affinity antibodies will not, and will die by apoptosis. Thus, B cells expressing antibodies with a higher affinity for the antigen will outcompete those with weaker affinities for function and survival allowing the average affinity of antibodies to increase over time. The process of generating antibodies with increased binding affinities is called \"affinity maturation\". Affinity maturation occurs in mature B cells after V(D)J recombination, and is dependent on help from helper T cells.\nIsotype or class switching is a biological process occurring after activation of the B cell, which allows the cell to produce different classes of antibody (IgA, IgE, or IgG). The different classes of antibody, and thus effector functions, are defined by the constant (C) regions of the immunoglobulin heavy chain. Initially, naive B cells express only cell-surface IgM and IgD with identical antigen binding regions. Each isotype is adapted for a distinct function; therefore, after activation, an antibody with an IgG, IgA, or IgE effector function might be required to effectively eliminate an antigen. Class switching allows different daughter cells from the same activated B cell to produce antibodies of different isotypes. Only the constant region of the antibody heavy chain changes during class switching; the variable regions, and therefore antigen specificity, remain unchanged. Thus the progeny of a single B cell can produce antibodies, all specific for the same antigen, but with the ability to produce the effector function appropriate for each antigenic challenge. Class switching is triggered by cytokines; the isotype generated depends on which cytokines are present in the B cell environment.\n\nClass switching occurs in the heavy chain gene locus by a mechanism called class switch recombination (CSR). This mechanism relies on conserved nucleotide motifs, called \"switch (S) regions\", found in DNA upstream of each constant region gene (except in the δ-chain). The DNA strand is broken by the activity of a series of enzymes at two selected S-regions. The variable domain exon is rejoined through a process called non-homologous end joining (NHEJ) to the desired constant region (γ, α or ε). This process results in an immunoglobulin gene that encodes an antibody of a different isotype.\n\nA group of antibodies can be called \"monovalent\" (or \"specific\") if they have affinity for the same epitope, or for the same antigen (but potentially different epitopes on the molecule), or for the same strain of microorganism (but potentially different antigens on or in it). In contrast, a group of antibodies can be called \"polyvalent\" (or \"unspecific\") if they have affinity for various antigens or microorganisms. Intravenous immunoglobulin, if not otherwise noted, consists of polyvalent IgG. In contrast, monoclonal antibodies are monovalent for the same epitope.\n\nHeterodimeric antibodies, which are also asymmetrical and antibodies, allow for greater flexibility and new formats for attaching a variety of drugs to the antibody arms. One of the general formats for a heterodimeric antibody is the “knobs-into-holes” format. This format is specific to the heavy chain part of the constant region in antibodies. The “knobs” part is engineered by replacing a small amino acid with a larger one. It fits into the “hole”, which is engineered by replacing a large amino acid with a smaller one. What connects the “knobs” to the “holes” are the disulfide bonds between each chain. The “knobs-into-holes” shape facilitates antibody dependent cell mediated cytotoxicity. Single chain variable fragments (scFv) are connected to the variable domain of the heavy and light chain via a short linker peptide. The linker is rich in glycine, which gives it more flexibility, and serine/threonine, which gives it specificity. Two different scFv fragments can be connected together, via a hinge region, to the constant domain of the heavy chain or the constant domain of the light chain. This gives the antibody bispecificity, allowing for the binding specificities of two different antigens. The “knobs-into-holes” format enhances heterodimer formation but doesn’t suppress homodimer formation.\n\nTo further improve the function of heterodimeric antibodies, many scientists are looking towards artificial constructs. Artificial antibodies are largely diverse protein motifs that use the functional strategy of the antibody molecule, but aren’t limited by the loop and framework structural constraints of the natural antibody. Being able to control the combinational design of the sequence and three-dimensional space could transcend the natural design and allow for the attachment of different combinations of drugs to the arms.\n\nHeterodimeric antibodies have a greater range in shapes they can take and the drugs that are attached to the arms don’t have to be the same on each arm, allowing for different combinations of drugs to be used in cancer treatment. Pharmaceuticals are able to produce highly functional bispecific, and even multispecific, antibodies. The degree to which they can function is impressive given that such a change shape from the natural form should lead to decreased functionality.\n\nDetection of particular antibodies is a very common form of medical diagnostics, and applications such as serology depend on these methods. For example, in biochemical assays for disease diagnosis, a titer of antibodies directed against Epstein-Barr virus or Lyme disease is estimated from the blood. If those antibodies are not present, either the person is not infected or the infection occurred a \"very\" long time ago, and the B cells generating these specific antibodies have naturally decayed.\n\nIn clinical immunology, levels of individual classes of immunoglobulins are measured by nephelometry (or turbidimetry) to characterize the antibody profile of patient. Elevations in different classes of immunoglobulins are sometimes useful in determining the cause of liver damage in patients for whom the diagnosis is unclear. For example, elevated IgA indicates alcoholic cirrhosis, elevated IgM indicates viral hepatitis and primary biliary cirrhosis, while IgG is elevated in viral hepatitis, autoimmune hepatitis and cirrhosis.\n\nAutoimmune disorders can often be traced to antibodies that bind the body's own epitopes; many can be detected through blood tests. Antibodies directed against red blood cell surface antigens in immune mediated hemolytic anemia are detected with the Coombs test. The Coombs test is also used for antibody screening in blood transfusion preparation and also for antibody screening in antenatal women.\n\nPractically, several immunodiagnostic methods based on detection of complex antigen-antibody are used to diagnose infectious diseases, for example ELISA, immunofluorescence, Western blot, immunodiffusion, immunoelectrophoresis, and magnetic immunoassay. Antibodies raised against human chorionic gonadotropin are used in over the counter pregnancy tests.\n\nNew dioxaborolane chemistry enables radioactive fluoride (F) labeling of antibodies, which allows for positron emission tomography (PET) imaging of cancer.\n\nTargeted monoclonal antibody therapy is employed to treat diseases such as rheumatoid arthritis, multiple sclerosis, psoriasis, and many forms of cancer including non-Hodgkin's lymphoma, colorectal cancer, head and neck cancer and breast cancer.\n\nSome immune deficiencies, such as X-linked agammaglobulinemia and hypogammaglobulinemia, result in partial or complete lack of antibodies. These diseases are often treated by inducing a short term form of immunity called passive immunity. Passive immunity is achieved through the transfer of ready-made antibodies in the form of human or animal serum, pooled immunoglobulin or monoclonal antibodies, into the affected individual.\n\nRhesus factor, also known as Rhesus D (RhD) antigen, is an antigen found on red blood cells; individuals that are Rhesus-positive (Rh+) have this antigen on their red blood cells and individuals that are Rhesus-negative (Rh–) do not. During normal childbirth, delivery trauma or complications during pregnancy, blood from a fetus can enter the mother's system. In the case of an Rh-incompatible mother and child, consequential blood mixing may sensitize an Rh- mother to the Rh antigen on the blood cells of the Rh+ child, putting the remainder of the pregnancy, and any subsequent pregnancies, at risk for hemolytic disease of the newborn.\n\nRho(D) immune globulin antibodies are specific for human Rhesus D (RhD) antigen. Anti-RhD antibodies are administered as part of a prenatal treatment regimen to prevent sensitization that may occur when a Rhesus-negative mother has a Rhesus-positive fetus. Treatment of a mother with Anti-RhD antibodies prior to and immediately after trauma and delivery destroys Rh antigen in the mother's system from the fetus. It is important to note that this occurs before the antigen can stimulate maternal B cells to \"remember\" Rh antigen by generating memory B cells. Therefore, her humoral immune system will not make anti-Rh antibodies, and will not attack the Rhesus antigens of the current or subsequent babies. Rho(D) Immune Globulin treatment prevents sensitization that can lead to Rh disease, but does not prevent or treat the underlying disease itself.\n\nSpecific antibodies are produced by injecting an antigen into a mammal, such as a mouse, rat, rabbit, goat, sheep, or horse for large quantities of antibody. Blood isolated from these animals contains \"polyclonal antibodies\"—multiple antibodies that bind to the same antigen—in the serum, which can now be called antiserum. Antigens are also injected into chickens for generation of polyclonal antibodies in egg yolk. To obtain antibody that is specific for a single epitope of an antigen, antibody-secreting lymphocytes are isolated from the animal and immortalized by fusing them with a cancer cell line. The fused cells are called hybridomas, and will continually grow and secrete antibody in culture. Single hybridoma cells are isolated by dilution cloning to generate cell clones that all produce the same antibody; these antibodies are called \"monoclonal antibodies\". Polyclonal and monoclonal antibodies are often purified using Protein A/G or antigen-affinity chromatography.\n\nIn research, purified antibodies are used in many applications. Antibodies for research applications can be found directly from antibody suppliers, or through use of a specialist search engine. Research antibodies are most commonly used to identify and locate intracellular and extracellular proteins. Antibodies are used in flow cytometry to differentiate cell types by the proteins they express; different types of cell express different combinations of cluster of differentiation molecules on their surface, and produce different intracellular and secretable proteins. They are also used in immunoprecipitation to separate proteins and anything bound to them (co-immunoprecipitation) from other molecules in a cell lysate, in Western blot analyses to identify proteins separated by electrophoresis, and in immunohistochemistry or immunofluorescence to examine protein expression in tissue sections or to locate proteins within cells with the assistance of a microscope. Proteins can also be detected and quantified with antibodies, using ELISA and ELISPOT techniques.\n\nAntibodies used in research are some of the most powerful, yet most problematic reagents with a tremendous number of factors that must be controlled in any experiment including cross reactivity, or the antibody recognizing multiple epitopes and affinity, which can vary widely different depending on experimental conditions such as pH, solvent, state of tissue etc. Multiple attempts have been made to improve both the way that researchers validate antibodies and ways in which they report on antibodies. Researchers using antibodies in their work need to record them correctly in order to allow their research to be reproducible (and therefore tested, and qualified by other researchers). Less than half of research antibodies referenced in academic papers can be easily identified. Papers published in F1000 in 2014 and 2015 provide researchers with a guide for reporting research antibody use. The RRID paper, is co-published in 4 journals that implemented the RRIDs Standard for research resource citation, which draws data from the antibodyregistry.org as the source of antibody identifiers (see also group at Force11)\n\nTraditionally, most antibodies are produced by hybridoma cell lines through immortalization of antibody-producing cells by chemically-induced fusion with myeloma cells. In some cases, additional fusions with other lines have created \"triomas\" and \"quadromas\". The manufacturing process should be appropriately described and validated. Validation studies should\nat least include :\n\n\n\n\nThe importance of antibodies in health care and the biotechnology industry demands knowledge of their structures at high resolution. This information is used for protein engineering, modifying the antigen binding affinity, and identifying an epitope, of a given antibody. X-ray crystallography is one commonly used method for determining antibody structures. However, crystallizing an antibody is often laborious and time-consuming. Computational approaches provide a cheaper and faster alternative to crystallography, but their results are more equivocal, since they do not produce empirical structures. Online web servers such as \"Web Antibody Modeling\" (WAM) and \"Prediction of Immunoglobulin Structure\" (PIGS) enables computational modeling of antibody variable regions. Rosetta Antibody is a novel antibody F region structure prediction server, which incorporates sophisticated techniques to minimize CDR loops and optimize the relative orientation of the light and heavy chains, as well as homology models that predict successful docking of antibodies with their unique antigen.\n\nThe ability to describe the antibody through binding affinity to the antigen is supplemented by information on antibody structure and amino acid sequences for the purpose of patent claims.\n\nThe first use of the term \"antibody\" occurred in a text by Paul Ehrlich. The term \"Antikörper\" (the German word for \"antibody\") appears in the conclusion of his article \"Experimental Studies on Immunity\", published in October 1891, which states that, \"if two substances give rise to two different antikörper, then they themselves must be different\". However, the term was not accepted immediately and several other terms for antibody were proposed; these included \"Immunkörper\", \"Amboceptor\", \"Zwischenkörper\", \"substance sensibilisatrice\", \"copula\", \"Desmon\", \"philocytase\", \"fixateur\", and \"Immunisin\". The word \"antibody\" has formal analogy to the word \"antitoxin\" and a similar concept to \"Immunkörper\" (\"immune body\" in English). As such, the original construction of the word contains a logical flaw; the antitoxin is something directed against a toxin, while the antibody is a body directed against something.\n\nThe study of antibodies began in 1890 when Kitasato Shibasaburō described antibody activity against diphtheria and tetanus toxins. Kitasato put forward the theory of humoral immunity, proposing that a mediator in serum could react with a foreign antigen. His idea prompted Paul Ehrlich to propose the side-chain theory for antibody and antigen interaction in 1897, when he hypothesized that receptors (described as \"side-chains\") on the surface of cells could bind specifically to toxins – in a \"lock-and-key\" interaction – and that this binding reaction is the trigger for the production of antibodies. Other researchers believed that antibodies existed freely in the blood and, in 1904, Almroth Wright suggested that soluble antibodies coated bacteria to label them for phagocytosis and killing; a process that he named opsoninization.\n\nIn the 1920s, Michael Heidelberger and Oswald Avery observed that antigens could be precipitated by antibodies and went on to show that antibodies are made of protein. The biochemical properties of antigen-antibody-binding interactions were examined in more detail in the late 1930s by John Marrack. The next major advance was in the 1940s, when Linus Pauling confirmed the lock-and-key theory proposed by Ehrlich by showing that the interactions between antibodies and antigens depend more on their shape than their chemical composition. In 1948, Astrid Fagreaus discovered that B cells, in the form of plasma cells, were responsible for generating antibodies.\n\nFurther work concentrated on characterizing the structures of the antibody proteins. A major advance in these structural studies was the discovery in the early 1960s by Gerald Edelman and Joseph Gally of the antibody light chain, and their realization that this protein is the same as the Bence-Jones protein described in 1845 by Henry Bence Jones. Edelman went on to discover that antibodies are composed of disulfide bond-linked heavy and light chains. Around the same time, antibody-binding (Fab) and antibody tail (Fc) regions of IgG were characterized by Rodney Porter. Together, these scientists deduced the structure and complete amino acid sequence of IgG, a feat for which they were jointly awarded the 1972 Nobel Prize in Physiology or Medicine. The Fv fragment was prepared and characterized by David Givol. While most of these early studies focused on IgM and IgG, other immunoglobulin isotypes were identified in the 1960s: Thomas Tomasi discovered secretory antibody (IgA); David S. Rowe and John L. Fahey discovered IgD; and Kimishige Ishizaka and Teruko Ishizaka discovered IgE and showed it was a class of antibodies involved in allergic reactions. In a landmark series of experiments beginning in 1976, Susumu Tonegawa showed that genetic material can rearrange itself to form the vast array of available antibodies.\n\nAntibody mimetics are organic compounds that, like antibodies, can specifically bind antigens. They are usually artificial peptides or proteins with a molar mass of about 3 to 20 kDa. Nucleic acids and small molecules are sometimes considered antibody mimetics, but not artificial antibodies, antibody fragments and fusion proteins are composed from these. Common advantages over antibodies are better solubility, tissue penetration, stability towards heat and enzymes, and comparatively low production costs. Antibody mimetics such as the Affimer and the DARPin have being developed and commercialised as research, diagnostic and therapeutic agents.\n\n", "id": "2362", "title": "Antibody"}
{"url": "https://en.wikipedia.org/wiki?curid=2363", "text": "Alessandro Scarlatti\n\nAlessandro Scarlatti (2 May 1660 – 22 October 1725) was an Italian Baroque composer, especially famous for his operas and chamber cantatas. He is considered the founder of the Neapolitan school of opera. He was the father of two other composers, Domenico Scarlatti and Pietro Filippo Scarlatti.\n\nScarlatti was born in Palermo (or in Trapani), then part of the Kingdom of Sicily. He is generally said to have been a pupil of Giacomo Carissimi in Rome, and some theorize that he had some connection with northern Italy because his early works seem to show the influence of Stradella and Legrenzi. The production at Rome of his opera \"Gli Equivoci nell sembiante\" (1679) gained him the support of Queen Christina of Sweden (who at the time was living in Rome), and he became her \"Maestro di Cappella\". In February 1684 he became \"Maestro di Cappella\" to the viceroy of Naples, perhaps through the influence of his sister, an opera singer, who might have been the mistress of an influential Neapolitan noble. Here he produced a long series of operas, remarkable chiefly for their fluency and expressiveness, as well as other music for state occasions.\n\nIn 1702 Scarlatti left Naples and did not return until the Spanish domination had been superseded by that of the Austrians. In the interval he enjoyed the patronage of Ferdinando de' Medici, for whose private theatre near Florence he composed operas, and of Cardinal Ottoboni, who made him his \"maestro di cappella\", and procured him a similar post at the Basilica di Santa Maria Maggiore in Rome in 1703.\n\nAfter visiting Venice and Urbino in 1707, Scarlatti took up his duties in Naples again in 1708, and remained there until 1717. By this time Naples seems to have become tired of his music; the Romans, however, appreciated it better, and it was at the Teatro Capranica in Rome that he produced some of his finest operas (\"Telemaco\", 1718; \"Marco Attilio Regolò\", 1719; \"La Griselda\", 1721), as well as some noble specimens of church music, including a mass for chorus and orchestra, composed in honor of Saint Cecilia for Cardinal Acquaviva in 1721. His last work on a large scale appears to have been the unfinished serenata for the marriage of the prince of Stigliano in 1723. He died in Naples in 1725.\nScarlatti's music forms an important link between the early Baroque Italian vocal styles of the 17th century, with their centers in Florence, Venice and Rome, and the classical school of the 18th century. Scarlatti's style, however, is more than a transitional element in Western music; like most of his Naples colleagues he shows an almost modern understanding of the psychology of modulation and also frequently makes use of the ever-changing phrase lengths so typical of the Napoli school. His early operas (\"Gli equivoci nel sembiante\" 1679; \"L'honestà negli amori\" 1680, containing the famous aria \"Già il sole dal Gange\"; \"Il Pompeo\" 1683, containing the well-known airs \"O cessate di piagarmi\" and \"Toglietemi la vita ancor,\" and others down to about 1685) retain the older cadences in their recitatives, and a considerable variety of neatly constructed forms in their charming little arias, accompanied sometimes by the string quartet, treated with careful elaboration, sometimes with the continuo alone. By 1686 he had definitely established the \"Italian overture\" form (second edition of \"Dal male il bene\"), and had abandoned the ground bass and the binary form air in two stanzas in favour of the ternary form or da capo type of air. His best operas of this period are \"La Rosaura\" (1690, printed by the Gesellschaft für Musikforschung), and \"Pirro e Demetrio\" (1694), in which occur the arias \"Le Violette\", and \"Ben ti sta, traditor\".\n\nFrom about 1697 onwards (\"La caduta del Decemviri\"), influenced partly perhaps by the style of Giovanni Bononcini and probably more by the taste of the viceregal court, his opera arias become more conventional and commonplace in rhythm, while his scoring is hasty and crude, yet not without brilliance (\"L'Eraclea\", 1700), the oboes and trumpets being frequently used, and the violins often playing in unison. The operas composed for Ferdinando de' Medici are lost; they might have given a more favourable idea of his style as his correspondence with the prince shows that they were composed with a very sincere sense of inspiration.\n\n\"Mitridate Eupatore\", accounted his masterpiece, composed for Venice in 1707, contains music far in advance of anything that Scarlatti had written for Naples, both in technique and in intellectual power. The later Neapolitan operas (\"L'amor volubile e tiranno\" 1709; \"La principessa fedele\" 1710; \"Tigrane\", 1714, &c.) are showy and effective rather than profoundly emotional; the instrumentation marks a great advance on previous work, since the main duty of accompanying the voice is thrown upon the string quartet, the harpsichord being reserved exclusively for the noisy instrumental ritornelli. In his opera \"Teodora\" (1697) he originated the use of the orchestral \"ritornello\".\nHis last group of operas, composed for Rome, exhibit a deeper poetic feeling, a broad and dignified style of melody, a strong dramatic sense, especially in accompanied recitatives, a device which he himself had been the first to use as early as 1686 (\"Olimpia vendicata\") and a much more modern style of orchestration, the horns appearing for the first time, and being treated with striking effect.\n\nBesides the operas, oratorios (\"Agar et Ismaele esiliati\", 1684; \"La Maddalena\", 1685; \"La Giuditta\", 1693; \"Christmas Oratorio\", c. 1705; \"S. Filippo Neri\", 1714; and others) and serenatas, which all exhibit a similar style, Scarlatti composed upwards of five hundred chamber-cantatas for solo voice. These represent the most intellectual type of chamber-music of their period, and it is to be regretted that they have remained almost entirely in manuscript, since a careful study of them is indispensable to anyone who wishes to form an adequate idea of Scarlatti's development.\nHis few remaining Masses (the story of his having composed two hundred is hardly credible) and church music in general are comparatively unimportant, except the great \"St Cecilia Mass\" (1721), which is one of the first attempts at the style which reached its height in the great Masses of Johann Sebastian Bach and Beethoven. His instrumental music, though not without interest, is curiously antiquated as compared with his vocal works.\n\n\n\n", "id": "2363", "title": "Alessandro Scarlatti"}
{"url": "https://en.wikipedia.org/wiki?curid=2369", "text": "Aston Martin\n\nAston Martin Lagonda Limited is a British manufacturer of luxury sports cars and grand tourers. It was founded in 1913 by Lionel Martin and Robert Bamford. Steered from 1947 by David Brown it became associated with expensive grand touring cars in the 1950s and 1960s, and with the fictional character James Bond following his use of a DB5 model in the 1964 film \"Goldfinger\". Their sports cars are regarded as a British cultural icon. Aston Martin has held a Royal Warrant as purveyor of motorcars to HRH the Prince of Wales since 1982 .\n\nHeadquarters and the main production site are in Gaydon, Warwickshire, England, on the site of a former RAF V Bomber airbase. One of Aston Martins' recent cars was named after the 1950s Vulcan Bomber. Aston Martin has diversified to speed boats, and real estate development. \n\nAston Martin had a troubled history after the third quarter of the 20th century but has also enjoyed long periods of success and stability. “In the first century we went bankrupt seven times,” incoming CEO Andy Palmer told Automotive News Europe. “The second century is about making sure that is not the case.” \n\nAston Martin was founded in 1913 by Lionel Martin and Robert Bamford. The two had joined forces as Bamford & Martin the previous year to sell cars made by Singer from premises in Callow Street, London where they also serviced GWK and Calthorpe vehicles. Martin raced specials at Aston Hill near Aston Clinton, and the pair decided to make their own vehicles. The first car to be named \"Aston Martin\" was created by Martin by fitting a four-cylinder Coventry-Simplex engine to the chassis of a 1908 Isotta-Fraschini.\n\nThey acquired premises at Henniker Mews in Kensington and produced their first car in March 1915. Production could not start because of the outbreak of World War I, and Martin joined the Admiralty and Bamford the Royal Army Service Corps. All machinery was sold to the Sopwith Aviation Company.\n\nAfter the war they found new premises at Abingdon Road, Kensington and designed a new car. Bamford left in 1920 and Aston Martin was revitalised with funding from Count Louis Zborowski. In 1922, Bamford & Martin produced cars to compete in the French Grand Prix, which went on to set world speed and endurance records at Brooklands. Three works Team Cars with 16-valve were built for racing and record breaking: chassis number 1914, later developed as the Green Pea; chassis number 1915, the Razor Blade record car; and chassis number 1916, later developed as the Halford Special.\n\nApproximately 55 cars were built for sale in two configurations, and short chassis. Aston Martin went bankrupt in 1924 and was bought by Dorothea, Lady Charnwood who put her son John Benson on the board. Aston Martin failed again in 1925 and the factory closed in 1926, with Lionel Martin leaving.\n\nLater that year, Bill Renwick, Augustus (Bert) Bertelli and investors including Lady Charnwood took control of the business. They renamed it Aston Martin Motors and moved it to the former Whitehead Aircraft Limited Hanworth works in Feltham. Renwick and Bertelli had been in partnership some years and had developed an overhead-cam four-cylinder engine using Renwick's patented combustion chamber design, which they had tested in an Enfield-Allday chassis. The only \"Renwick and Bertelli\" motor car made, it was known as \"Buzzbox\" and still survives.\n\nThe pair had planned to sell their engine to motor manufacturers, but having heard that Aston Martin was no longer in production realised they could capitalise on its reputation to jump start the production of a completely new car.\n\nBetween 1926 and 1937 Bertelli was both technical director and designer of all new Aston Martins, since known as \"Bertelli cars\". They included the 1½-litre \"T-type\", \"International\", \"Le Mans\", \"MKII\" and its racing derivative, the \"Ulster\", and the 2-litre 15/98 and its racing derivative, the \"Speed Model\". Most were open two-seater sports cars bodied by Bert Bertelli's brother , with a small number of long-chassis four-seater tourers, dropheads and saloons also produced.\n\nBertelli was a competent driver keen to race his cars, one of few owner/manufacturer/drivers. The \"LM\" team cars were very successful in national and international motor racing including at Le Mans and the Mille Miglia.\n\nFinancial problems reappeared in 1932. Aston Martin was rescued for a year by Lance Prideaux Brune before passing it on to Sir Arthur Sutherland. In 1936, Aston Martin decided to concentrate on road cars, producing just 700 until World War II halted work. Production shifted to aircraft components during the war.\n\nSir David Brown (1904-1993) used his personal skills and a great deal of his considerable fortune to make Aston Martins the kind of car they remain today. He owned Aston Martin for 25 years, longer than anyone before or since, and as a memorial his initials remain on all the cars made since that time. Here is how he went about it.\n\nIn 1947, old-established (1860) privately-owned Huddersfield gear and machine tools manufacturer David Brown Limited bought Aston Martin putting it under control of its Tractor Group. Driving force, David, later Sir David Brown, 42 year-old grandson of the founder, became Aston Martin's latest saviour. He also acquired without its factory Lagonda's business for its 2.6-litre W. O. Bentley-designed engine. Lagonda moved operations to Newport Pagnell and shared engines, resources and workshops. Aston Martin began to build the classic \"DB\" series of cars. \n\nIn April 1950, they announced planned production of their Le Mans prototype to be called the DB2, followed by the DB2/4 in 1953, the DB2/4 MkII in 1955, the DB Mark III in 1957 and the Italian-styled 3.7 L DB4 in 1958.\n\nWhile these models helped Aston Martin establish a good racing pedigree, the DB4 stood out and yielded the famous DB5 in 1963. Aston stayed true to its grand touring style with the DB6 (1965–70), and DBS (1967–1972).\n\nThe six-cylinder engines of these cars from 1954 up to 1965 were designed by Tadek Marek.\n\nAston Martin was often financially troubled. In 1972 David Brown paid off all its debts, said to be £5 million or more, and handed it for £101 to Company Developments, a Birmingham-based investment bank consortium chaired by accountant William Willson. More detail on this period may be read at Willson's biography. The world-wide recession, lack of working capital and the difficulties of developing without proper resources an engine to meet California's exhaust emission requirements — it stopped Aston's US sales — again pulled Aston Martin into receivership at the end of 1974. There were 460 workers when the plant closed.\nThe receiver sold the business in April 1975 for £1.05 million to North American businessmen Peter Sprague of National Semiconductor and Toronto hotelier, George Minden, and Jeremy Turner, a London businessman, who insisted to reporters Aston Martin remained a British controlled business. Sprague later claimed he had fallen in love with the factory, not the cars, the workforce's craftsmanship dedication and intelligence. At this point he and Minden had brought in investor, Alan Curtis, a British office property developer together with George Flather, a retired Sheffield steel magnate.\n\nSix months later in September 1975 the factory — shut-down the previous December — re-opened under its new owner Aston Martin Lagonda (1975) Limited with 100 employees and plans to lift staff to 250 by the end of 1975. In January 1976 AML revealed they now held orders for 150 cars for USA, 100 for other markets and another 80 from a Japanese importing agency. At the Geneva Motor Show Fred Hartley, managing director and sales director for 13 years before that, announced he had resigned over \"differences in marketing policy\". Alan Curtis made himself managing director. \n\nThe new owners pushed Aston Martin into modernising its line, producing the V8 Vantage in 1977, the convertible Volante in 1978, and the one-off William Towns-styled Bulldog in 1980. Towns also styled the futuristic new Lagonda saloon, based on the V8 model.\n\nCurtis, who had a 42 per cent stake in Aston Martin, also brought about a change in direction from the usual customers who were Aston Martin fanatics (fans) to successful young married businessmen. Prices had been increased by 25 per cent. There was speculation that AML was about to buy Lamborghini. At the end of the 1970s there was widespread debate about running MG into the Aston Martin consortium. 85 Tory MPs formed themselves into a pressure group to get British Leyland to release their grip and hand it over. CH Industrials plc (car components) bought a 10 per cent share in AML. But in July 1980 blaming a recession AML cut back their workforce of 450 by more than 20 per cent making those people redundant and the following day British Leyland announced it had abandoned hope of an MG rescue by Aston Martin.\n\nin January 1981 there having been no satisfactory revival partners Alan Curtis and Peter Sprague announced they had never intended to maintain a long term financial stake in Aston Martin Lagonda and it was to be sold to Pace Petroleum's Victor Gauntlett. Sprague and Curtis pointed out that under their ownership AML finances had improved to where an offer for MG might have been feasible.Worldwide sales had shrunk to three cars per week, prompting chairman Alan Curtis, Sprague, and Minden to consider shutting down production to concentrate on service and restoration. At this point Curtis attended the 1980 Pace sponsored Stirling Moss benefit day at Brands Hatch, and met fellow Farnham resident Victor Gauntlett.\n\nGauntlett bought a 12.5% stake in Aston Martin for £500,000 via Pace Petroleum in 1980, with Tim Hearley of CH Industrials taking a similar share. Pace and CHI took over as joint 50/50 owners at the beginning of 1981, with Gauntlett as executive chairman. Gauntlett also led the sales team, and after some development and publicity when it became the world's fastest 4-seater production car, was able to sell the Aston Martin Lagonda in Oman, Kuwait, and Qatar.\n\nIn 1982, Aston Martin was granted a Royal Warrant of Appointment by the Prince of Wales. Aston Martin holds the warrant to this day.\n\nUnderstanding that it would take some time to develop new Aston Martin products, they created an engineering service subsidiary to develop automotive products for other companies. It was decided to use, a trade name of Salmons & Son their in-house coachbuilder, Tickford which Aston Martin had bought in 1955. Tickford's name had been long associated with expensive high quality carriages and cars and their folding roofs. New products included a Tickford Austin Metro, a Tickford Ford Capri and even Tickford train interiors, particularly on the Jaguar XJS. Pace continued sponsoring racing events, and now sponsored all Aston Martin Owners Club events, taking a Tickford-engined Nimrod Group C car owned by AMOC President Viscount Downe, which came third in the Manufacturers Championship in both 1982 and 1983. It also finished seventh in the 1982 24 Hours of Le Mans race. However, sales of production cars were now at an all-time low of 30 cars produced in 1982.\n\nAs trading became tighter in the petroleum market, and Aston Martin was requiring more time and money, Gauntlett agreed to sell Hays/Pace to the Kuwait Investment Office in September 1983. As Aston Martin required greater investment, he also agreed to sell his share holding to American importer and Greek shipping tycoon Peter Livanos, who invested via his joint venture with Nick and John Papanicolaou, ALL Inc. Gauntlett remained chairman of AML 55% owned by ALL, with Tickford a 50/50 venture between ALL and CHI. The uneasy relationship was ended when ALL exercised options to buy a larger share in AML; CHI's residual shares were exchanged for CHI's complete ownership of Tickford, which retained development of existing Aston Martin projects. In 1984 Papanicolaou's Titan shipping business was in trouble so Livanos's father George bought out the Papanicolaou's shares in ALL, while Gauntlett again became a shareholder with a 25% holding in AML. The deal valued Aston Martin/AML at £2 million, the year it built its 10,000th car.\n\nAlthough as a result Aston Martin had to make 60 members of the workforce redundant, Gauntlett bought a stake in Italian styling house Zagato, and resurrected its collaboration with Aston Martin.\n\nIn 1986, Gauntlett negotiated the return of fictional British secret agent James Bond to Aston Martin. Cubby Broccoli had chosen to recast the character using actor Timothy Dalton, in an attempt to re-root the Bond-brand back to a more Sean Connery-like feel. Gauntlett supplied his personal pre-production Vantage for use in the filming of \"The Living Daylights\", and sold a Volante to Broccoli for use at his home in America. Gauntlett turned down the role of a KGB colonel in the film, however: \"I would have loved to have done it but really could not afford the time.\"\n\nAston Martin needed funds to survive in the long term. In May 1987, Gauntlett and Prince Michael of Kent were staying at the home of Contessa Maggi, the wife of the founder of the original Mille Miglia, while watching the revival event. Another house guest was Walter Hayes, vice-President of Ford of Europe. Despite problems over the previous acquisition of AC Cars, Hayes saw the potential of the brand and the discussion resulted in Ford taking a share holding in September 1987. In 1988, having produced some 5,000 cars in 20 years, a revived economy and successful sales of limited edition Vantage, and 52 Volante Zagato coupes at £86,000 each; Aston Martin finally retired the ancient V8 and introduced the Virage range—the first new Aston launched in 20 years.\n\nAlthough Gauntlett was contractually to stay as chairman for two years, his racing interests took Aston back into sports car racing in 1989 with limited European success. However, with engine rule changes for the 1990 season and the launch of the new Aston Martin Volante model, Ford provided the limited supply of Cosworth engines to the Jaguar cars racing team. As the \"small Aston\" DB7 would require a large engineering input, Ford agreed to take full control of Aston Martin, and Gauntlett handed over Aston Martin's chairmanship to Hayes in 1991. In 1992, the Vantage version was announced, and the following year Aston Martin renewed the DB range by announcing the DB7.\n\nFord placed Aston in the Premier Automotive Group, invested in new manufacturing and ramped up production. In 1994, Ford opened a new factory at Banbury Road in Bloxham. In 1995 Aston Martin produced a record 700 vehicles. Until the Ford era, cars had been produced by hand coachbuilding craft methods, such as the English wheel. In 1998 the 2,000th DB7 was built, and in 2002 the 6,000th, exceeding production of all previous DB models. The DB7 range was boosted by the addition of V12 Vantage models in 1999, and in 2001 Aston Martin introduced the V12-engined Aston Martin Vanquish.\n\nAt the North American International Auto Show in Detroit, Michigan in 2003, Aston Martin introduced the AMV8 Vantage concept car. Expected to have few changes before its introduction in 2005, the Vantage brought back the classic V8 engine to allow Aston Martin to compete in a larger market. 2003 also saw the opening of the Gaydon factory, the first purpose-built factory in Aston Martin's history. Also introduced in 2003 was the DB9 coupé, which replaced the ten-year-old DB7. A convertible version of the DB9, the DB9 Volante, was introduced at the 2004 Detroit Auto Show.\n\nIn October 2004, Aston Martin set up the dedicated AMEP engine production plant within the Ford Germany Niehl, Cologne plant. With capacity to produce up to 5,000 engines a year by 100 specially trained personnel, like traditional Aston Martin engine production from Newport Pagnell, assembly of each unit is entrusted to a single technician from a pool of 30, with V8 and V12 variants assembled in under 20 hours. By bringing engine production back to within Aston Martin, the promise was that Aston Martin would be able to produce small runs of higher performance variants engines. This expanded engine capacity allowed in 2006, the V8 Vantage sports car to enter production at the Gaydon factory, joining the DB9 and DB9 Volante.\n\nIn December 2003 Aston Martin announced it would return to motor racing in 2005. A new division was created, called Aston Martin Racing, which became responsible, together with Prodrive, for the design, development, and management of the DBR9 program. The DBR9 competes in the GT class in sports car races, including the world-famous 24 Hours of Le Mans.\n\nIn 2006, an internal audit led Ford to consider divesting itself of parts of its Premier Automotive Group. After suggestions of selling Jaguar Cars, Land Rover, or Volvo Cars were weighed, Ford announced in August 2006 it had engaged UBS AG to sell all or part of Aston Martin at auction.\n\nOn 12 March 2007, a consortium led by Prodrive chairman David Richards purchased Aston Martin for £475m (US$848m). The group included American investment banker John Singers and two Kuwaiti companies, Investment Dar and Adeem Investment; Prodrive had no financial involvement in the deal.\nFord kept a stake in Aston Martin valued at £40m (US$70m).\n\nTo demonstrate the V8 Vantage's durability across hazardous terrain and promote the car in China, the first east-west crossing of the Asian Highway was undertaken between June and August 2007. A pair of Britons drove from Tokyo to Istanbul before joining the European motorway network for another to London. The promotion was so successful Aston Martin opened dealerships in Shanghai and Beijing within three months.\n\nOn 19 July 2007, the Newport Pagnell plant rolled out the last of nearly 13,000 cars made there since 1955, a Vanquish S. The Tickford Street facility was converted to Aston Martin's service and restoration department. UK production is now concentrated at Gaydon on the former RAF V-bomber airfield. In March 2008 Aston Martin announced a partnership with Magna Steyr to outsource manufacture of over 2,000 cars annually to Graz, Austria, reassuringly stating: \"The continuing growth and success of Aston Martin is based upon Gaydon as the focal point and heart of the business, with the design and engineering of all Aston Martin products continuing to be carried out there.\"\n\nMore dealers in Europe and the new pair in China brought the total to 120 in 28 countries.\n\nOn 1 September 2008, Aston Martin announced the revival of the Lagonda marque, proposing a concept to be shown in 2009 to coincide with the brand's 100th anniversary. The first production cars are slated for 2012.\n\nIn December 2008, Aston Martin announced it would cut its workforce from 1,850 to 1,250.\n\nThe first four-door Aston Martin Rapide sports cars rolled out of the Magna Steyr factory in Graz, Austria in 2010. The contract manufacturer provides dedicated facilities to ensure compliance with the exacting standards of Aston Martin and other marques, including Mercedes-Benz. Ulrich Bez has publicly speculated about outsourcing all of Aston Martin's operations with the exception of marketing. In September 2011 it was announced Rapide production would be returned to Gaydon in the second half of 2012, restoring all manufacture there.\n\nIn late 2012, Investment Dar reviewed its stake, with Mahindra & Mahindra emerging as a potential bidder for as much as half of Aston Martin. Instead, Italian private equity fund Investindustrial signed a deal on 6 December 2012 to buy 37.5% of Aston Martin, investing £150 million as a capital increase. This was confirmed by Aston Martin in a press release on 7 December 2012. In April 2013 it was reported that Dr Ulrich Bez would be leaving his role as chief executive officer to take up a more ambassadorial position widely seen as the first move by the new shareholders in reviewing the leadership and strategy of Aston Martin. On 2 September 2014, Aston Martin announced they had appointed the Nissan executive Andy Palmer as their new CEO with Ulrich Bez retaining a position as Non-Executive Chairman. As sales had been declining, from 2015 Aston Martin sought new customers (particularly wealthy female buyers) with cars like Lagonda and DBX while releasing concepts cars like the Vulcan. According to Palmer, the troubles started when sales of the DB9 failed to generate sufficient fund to develop next-generation models which led to a downward spiral of declining sales and profitability.\n\nIn 2014, Aston Martin suffered a pre-tax loss of £72 million, almost triple that of 2013 selling 3,500 cars during the year, well below 7,300 sold in 2007 and 4,200 sold in 2013. In March 2014 Aston Martin issued “payment in kind” notes of US$165 million, at 10.25 per cent interest, in addition to the £304 million of senior secured notes at 9.25 per cent issued in 2011. Aston Martin also had to secure an additional investment of £200 million from its shareholders to fund development of new models.\nIt is reported that Aston Martin's pre-tax losses for 2016 increased by 27 percent to £162.8 million, the sixth year it continued to suffer a loss.\n\nIn 2013 Aston Martin signed a deal with Daimler AG to supply the next generation Aston Martin cars with new Mercedes-AMG engines. Daimler AG now owns 5% of Aston Martin. Mercedes-AMG will also supply Aston Martin with electrical systems. This technical partnership will support Aston Martin’s launch of a new generation of models that will incorporate new technology and V8s. The first model to sport Mercedes technology is the DB11, announced at the 2016 Geneva Motor, sporting Mercedes electronics for the entertainment, navigation and other systems.\n\n\n\nAston Martin sponsors 2. Bundesliga club 1860 Munich.\n\n", "id": "2369", "title": "Aston Martin"}
{"url": "https://en.wikipedia.org/wiki?curid=2371", "text": "Albert Pike\n\nAlbert Pike (December 29, 1809 – April 2, 1891) was an attorney, soldier, writer, and Freemason. Albert Pike is the only Confederate military officer with an outdoor statue in Washington, D.C.\n\nPike was born in Boston, Massachusetts, the son of Ben and Sarah (Andrews) Pike, and spent his childhood in Byfield and Newburyport, Massachusetts. His colonial ancestors settled the area in 1635, and included John Pike (1613–1688/1689), the founder of Woodbridge, New Jersey. He attended school in Newburyport and Framingham until he was 15. In August 1825, he passed entrance exams at Harvard University, though when the college requested payment of tuition fees for the first two years he chose not to attend. He began a program of self-education, later becoming a schoolteacher in Gloucester, North Bedford, Fairhaven and Newburyport.\n\nPike was an imposing figure; six feet tall and 300 pounds with hair that reached his shoulders and a long beard. In 1831, he left Massachusetts to travel west, first stopping in Nashville, Tennessee and later moving on to St. Louis, Missouri. There he joined an expedition to Taos, New Mexico, hunting and trading. During the excursion his horse broke and ran, forcing Pike to walk the remaining 500 miles to Taos. After this he joined a trapping expedition to the Llano Estacado in New Mexico and Texas. Trapping was minimal and, after traveling about 1,300 miles (650 on foot), he finally arrived at Fort Smith, Arkansas.\n\nSettling in Arkansas in 1833, Pike taught in a school and wrote a series of articles for the Little Rock \"Arkansas Advocate\" under the pen name of \"Casca.\" The articles were popular enough that he was asked to join the newspaper's staff. After marrying Mary Ann Hamilton in 1834, he purchased the newspaper. Under Pike's administration the \"Advocate\" promoted the viewpoint of the Whig Party in a politically volatile and divided Arkansas December 1832.\n\nHe was the first reporter for the Arkansas Supreme Court and also wrote a book (published anonymously), titled \"The Arkansas Form Book\", which was a guidebook for lawyers. Pike then began to study law and was admitted to the bar in 1837, selling the \"Advocate\" the same year. He also made several contacts among the Native American tribes in the area. He specialized in claims on behalf of Native Americans against the federal government. In 1852 he represented Creek Nation before the Supreme Court in a claim regarding ceded tribal land. In 1854 he advocated for the Choctaw and Chickasaw although compensation later awarded to the tribes in 1856 and 1857 was insufficient. These relationships were to influence the course of his Civil War service.\n\nAdditionally, Pike wrote on several legal subjects and continued producing poetry, a hobby he had begun in his youth in Massachusetts. His poems were highly regarded in his day, but are now mostly forgotten. Several volumes of his works were privately published posthumously by his daughter. In 1859, he received an honorary Master of Arts degree from Harvard.\n\nWhen the Mexican–American War started, Pike joined the Regiment of Arkansas Mounted Volunteers (a cavalry regiment) and was commissioned as a troop commander with the rank of captain in June 1846. With his regiment, he fought in the Battle of Buena Vista. Pike was discharged in June 1847. He and his commander, Colonel John Selden Roane, had several differences of opinion. This situation led finally to an \"inconclusive\" duel between Pike and Roane on July 29, 1847 near Fort Smith, Arkansas. Although several shots were fired in the duel, nobody was injured, and the two were persuaded by their seconds to discontinue it.\n\nAfter the war, Pike returned to the practice of law, moving to New Orleans for a time beginning in 1853. He wrote another book, \"Maxims of the Roman Law and some of the Ancient French Law, as Expounded and Applied in Doctrine and Jurisprudence\". Although unpublished, this book increased his reputation among his associates in law. He returned to Arkansas in 1857, gaining some amount of prominence in the legal field and becoming an advocate of slavery, although retaining his affiliation with the Whig Party.\n\nIn 1847 Pike became disillusioned when the Whig Party refused to take a stand on slavery. At the Southern Commercial Convention of 1854, Pike said the South should remain in the Union and seek equality with the North, but if the South \"were forced into an inferior status, she would be better out of the Union than in it.\" His anti-Catholicism stand led him to join the Know Nothing movement when it was organized in 1856, but was again disappointed when it refused to adopt a strong pro-slavery platform. He joined the other Southern delegates and walked out of the convention. His stand was that state's rights superseded national law and supported the idea of a Southern secession. This stand is made clear in his pamphlet of 1861, \"State or Province, Bond or Free?\"\n\nIn 1861 Pike penned the lyrics to \"Dixie to Arms!\". At the beginning of the war, Pike was appointed as Confederate envoy to the Native Americans. In this capacity he negotiated several treaties, one of the most important being with Cherokee chief John Ross, which was concluded in 1861.\n\nPike was commissioned as a brigadier general on November 22, 1861, and given a command in the Indian Territory. With Gen. Ben McCulloch, Pike trained three Confederate regiments of Indian cavalry, most of whom belonged to the \"civilized tribes\", whose loyalty to the Confederacy was variable. Although initially victorious at the Battle of Pea Ridge (Elkhorn Tavern) in March 1862, Pike's unit was defeated later in a counterattack, after falling into disarray. When Pike was ordered to send troops to Arkansas in May 1862, he resigned in protest. As in the previous war, Pike came into conflict with his superior officers, at one time drafting a letter to Jefferson Davis complaining about his direct superior.\n\nAfter Pea Ridge, Pike was faced with charges that his troops had scalped soldiers in the field. Maj. Gen. Thomas C. Hindman also charged Pike with mishandling of money and material, ordering his arrest. Both these charges were later found to be considerably lacking in evidence; nevertheless Pike, facing arrest, escaped into the hills of Arkansas, sending his resignation from the Confederate States Army on July 12. He was at length arrested on November 3 under charges of insubordination and treason, and held briefly in Warren, Texas, but his resignation was accepted on November 11 and he was allowed to return to Arkansas.\n\nPike first joined the Independent Order of Odd Fellows in 1840, and he had then joined a Masonic Lodge, where he became extremely active in the affairs of the organization, being elected Sovereign Grand Commander of the Scottish Rite's Southern Jurisdiction in 1859. He remained Sovereign Grand Commander for the remainder of his life (a total of thirty-two years), devoting a large amount of his time to developing the rituals of the order. Notably, he published a book called \"Morals and Dogma of the Ancient and Accepted Scottish Rite of Freemasonry\" in 1871, of which there were several subsequent editions. Pike stated that half of the text was copied from other works, but did not indicate his sources.\n\nPike is still regarded in America as an eminent and influential Freemason, primarily in the Scottish Rite Southern Jurisdiction.\n\nPike died in Washington, D.C., at the age of 81, and was buried at Oak Hill Cemetery. Burial was against his wishes; he had left instructions for his body to be cremated. In 1944, his remains were moved to the House of the Temple, headquarters of the Southern Jurisdiction of the Scottish Rite. A memorial to Pike is located in the Judiciary Square neighborhood of Washington, D.C.\n\nThe Albert Pike Memorial Temple is a historic Masonic lodge in Little Rock, Arkansas listed on the National Register of Historic Places.\n\nAs a young man, Pike wrote poetry and he continued to do so for the rest of his life. At 23, he published his first poem, “Hymns to the Gods.” Later work was printed in literary journals like Blackwood’s \"Edinburgh Magazine\" and local newspapers. His first collection of poetry, \"Prose Sketches and Poems Written in the Western Country\", appeared in 1834. He later gathered many of his poems and republished them in \"Hymns to the Gods and Other Poems\" (1872). After his death these appeared again in \"Gen. Albert Pike’s Poems\" (1900) and \"Lyrics and Love Songs\" (1916).\n\n\n\n\nMy Personal Views On Pike's Morals and Dogma masonicme.com\n", "id": "2371", "title": "Albert Pike"}
{"url": "https://en.wikipedia.org/wiki?curid=2372", "text": "ALF Tales\n\nALF Tales is a 30-minute Saturday morning animated series that aired on NBC from September 10, 1988 to December 9, 1989. The show is a spin-off of \"\" which featured characters from that series play various characters from fairy tales. The fairy tale was usually altered for comedic effect in a manner akin to Fractured Fairy Tales.\n\nEach story typically spoofs a film genre, such as the \"Cinderella\" episode done as an Elvis movie. Some episodes featured a \"fourth wall\" effect where ALF is backstage preparing for the episode, and Rob Cowan would appear drawn as a TV executive (who introduced himself as \"Roger Cowan, network executive\") to try to brief ALF on how to improve this episode. For instance Cowan once told ALF who was readying for a medieval themed episode that \"less than 2% of our audience lives in the Dark Ages\".\n\n\n\n\nThe first seven episodes were released on DVD on May 30, 2006 in Region 1 from Lions Gate Home Entertainment in a single-disc release entitled \"ALF and The Beanstalk and Other Classic Fairy Tales\".\n\n", "id": "2372", "title": "ALF Tales"}
{"url": "https://en.wikipedia.org/wiki?curid=2376", "text": "Abdul Rashid Dostum\n\nAbdul Rashid Dostum (: ; Persian: عبدالرشید دوستم) (born 1954) is an Afghan politician who has served as Vice President of Afghanistan since 2014. He is an ethnic Uzbek, former warlord and general, previously part of the leadership council of the National Front of Afghanistan along with Ahmad Zia Massoud and Mohammad Mohaqiq, as well as chairman of his own political party, Junbish-e Milli-yi Islami-yi Afghanistan (National Islamic Movement of Afghanistan). He also served in the past as Chairman Joint Chiefs of Staff of the Afghan National Army, a role often viewed as ceremonial.\n\nDuring the Soviet war in Afghanistan, Dostum was a general in the Afghan army. He later became an independent warlord and leader of Afghanistan's Uzbek community. He participated in battles against the Mujahideen fighters in the 1980s as well as against the Taliban in the 1990s. After the fall of the Taliban, he mainly resided in Turkey before returning to the country. In 2013 he made a public apology for his role in the civil war. He subsequently entered parliament, and later joined Ashraf Ghani's presidential administration as a vice president.\n\nDostum was born in 1954 in Khwaja du koh, Jowzjan Province, Afghanistan. Coming from an impoverished family, he received a very basic traditional education as he was forced to drop out of school at a young age. From there, he took up work in the gas fields.\n\nDostum began working in 1970 in a state-owned gas refinery in Sheberghan, participating in union politics, as the new government started to arm the staff of the workers in the oil and gas refineries. The reason for this was to create \"groups for the defense of the revolution\". Because of the new communist ideas entering Afghanistan in the 1970s, he enlisted in the army in 1978. Dostum received his basic military training in Jalalabad. His squadron was deployed in the rural areas around Sheberghan, under the auspices of the Ministry of National Security.\n\nBy the mid-1980s he commanded around 20,000 militia men and controlled the northern provinces of Afghanistan. While the unit recruited throughout Jowzjan and had a relatively broad base, many of its early troops and commanders came from Dostum's home village. He left the army after the purge of Parchamis, but returned after the Soviet occupation began.\n\nDuring the Soviet war in Afghanistan, Dostum was commanding a militia battalion to fight and rout mujahideen forces; he had been appointed an officer due to prior military experience. This eventually became a regiment and later became incorporated into the defense forces as the 53rd Infantry Division. Dostum and his new division reported directly to President Mohammad Najibullah. Later on he became the commander of the military unit 374 in Jowzjan. He defended the Soviet-backed Afghan government against the U.S., Pakistani, and Iranian-backed mujahideen forces throughout the 1980s. While he was only a regional commander, he had largely raised his forces by himself. The Jowzjani militia Dostum controlled was one of the few in the country which was able to be deployed outside its own region. They were deployed in Kandahar in 1988 when Soviet forces were withdrawing from Afghanistan.\n\nDostum's men would become an important force in the fall of Kabul in 1992. In April 1992, the opposition forces began their march to Kabul against the government of Najibullah. Dostum had allied himself with the opposition commanders Ahmad Shah Massoud and Sayed Jafar Naderi, the head of the Isma'ili community, and together they captured the capital city. He and Massoud fought in a coalition against Gulbuddin Hekmatyar. Massoud and Dostum's forces joined together to defend Kabul against Hekmatyar, with some 4000-5000 of his troops, units of his Shiberghan-based 53rd Division and Balkh-based Guards Division, garrisoning Bala Hissar fort, Maranjan Hill, and Khwaja Rawash International Airport. In 1994, Dostum allied himself with Gulbuddin Hekmatyar against the government of Burhanuddin Rabbani and Ahmad Shah Massoud.\n\nFollowing the rise of the Taliban and their capture of Kabul, Dostum aligned himself with the Northern Alliance (United Front) against the Taliban. He stationed his troops in the city of Mazar-e-Sharif. The Northern Alliance was assembled in late 1996 by Dostum, Massoud and Karim Khalili against the Taliban. At this point he is said to have had a force of some 50,000 men supported by both aircraft and tanks. He ruled what was, in effect, an independent region. He printed his own Afghan currency and ran a small airline named Balkh Air.\n\nMuch like other northern alliance leaders, Dostum also faced infighting within his group and was later forced to surrender his power to General Abdul Malik Pahlawan. Malik entered into secret negotiations with the Taliban, who promised to respect his authority over much of northern Afghanistan, in exchange for the apprehension of Ismail Khan, one of their enemies. Accordingly, on 25 May 1997 Malik arrested Khan, handed him over and let the Taliban enter Mazar-e-Sharif, giving them control over most of northern Afghanistan. Because of this, Dostum was forced to flee to Turkey. However, Malik soon realized that the Taliban were not sincere with their promises as he saw his men being disarmed. He then rejoined the Northern Alliance, and turned against his erstwhile allies, driving them from Mazar-e-Sharif. In October 1997, Dostum returned from exile and retook charge. After Dostum briefly regained control of Mazar-e-Sharif, the Taliban returned in 1998 and he again fled to Turkey.\n\nDostum returned to Afghanistan in October 2001 to join the U.S.-led campaign against the Taliban. Along with General Fahim, Ismail Khan and Mohammad Mohaqiq. In November 2001, with the beginning of the U.S. invasion of Afghanistan, and against the wishes of the CIA who distrusted Dostum, a team including Johnny Micheal Spann landed to set up communications in the Dar-e-Suf. A few hours later 23 men of Operational Detachment Alpha (ODA) 595 landed to begin the war.\n\nOn 24 November 2001, 300 Taliban soldiers retreated after the Siege of Kunduz by American and Northern Alliance. The Taliban laid down their weapons a few miles from the city of Mazar-i-Sharif. They eventually surrendered to Dostum. A small group of armed foreign fighters were transferred to the 19th century prison fortress, Qala-i-Jangi. The Taliban used concealed weapons to start the Battle of Qala-i-Jangi against the opposition forces. The uprising was eventually brought under control.\n\nIn late 2001, Carlotta Gall, Jamie Doran and Newsweek began reporting rumors that Dostum's forces, who were fighting the Taliban alongside the US Special Forces, intentionally suffocated as many as 2,000 Taliban prisoners in container trucks in an ill-defined incident that has become known as the Dasht-i-Leili massacre. In July 2009, \"The New York Times\" reported that according to anonymous witnesses they interviewed, \"over a three-day period, Taliban prisoners were stuffed into closed metal shipping containers and given no food or water; many suffocated while being trucked to the prison. Other prisoners were killed when guards shot into the containers. The bodies were said to have been buried in a mass grave in Dasht-i-Leili, a stretch of desert just outside Sheberghan. A 2002 declassified U.S. State Department intelligence report quoting a news source states that another anonymous source concluded that about 1,500 Taliban prisoners died. Estimates from other anonymous witnesses or from a report by Physicians for Human Rights range from several hundred to several thousand. The report also says that several Afghan witnesses were later tortured or killed.\" Dostum, the Red Cross and eyewitnesses in the prison claimed that only 200 taliban prisoners died from wounds or sickness. Physicians for Human Rights claims there is satellite evidence that graves had been dug up but no investigation was done despite Dostum inviting the UN to investigate. No formal investigation was conducted and an official website of General Dostum using eyewitnesses who go on the record lays out a timeline of events that debunk the allegations. The foundation of the controversy lay in confusion in estimating the number of Taliban that possibly joined the Northern Alliance or simply returned to their villages after the Kunduz surrender. According to the biography \"The Last Warlord, The Life and Times of General Dostum written by Professor Brian Williams, General Dostum has been the target of a number of sensational claims that were later debunked. Among them was the famous claim in Ahmed Rashid's book \"The Taliban\" that describes a tank was used to crush a thief. Ahmed Rashid corrects what turns out to be a second hand story in William's book and provides first person description of events that directly contradict the rumors.\n\nIn the aftermath of Taliban's removal from northern Afghanistan, forces loyal to Dostum frequently clashed with Tajik forces loyal to Atta Muhammad Nur. Atta's men kidnapped and killed a number of Dostum's men, and constantly agitated to gain control of Mazar-e-Sharif. Through the political mediations of the Karzai administration, the International Security Assistance Force (ISAF) and the United Nations, the Dostum-Atta feud has gradually declined.\n\nDostum served as deputy defense minister the early period of the Karzai administration. In March 2003, he established a North Zone of Afghanistan. On 20 May 2003, Dostum narrowly escaped an assassination attempt. He was often residing outside Afghanistan, mainly in Turkey.\n\nOn 16 August 2009, Dostum made a requested return from exile to Afghanistan to support President Hamid Karzai in his bid for re-election. He later flew by helicopter to his northern stronghold of Sheberghan, where he was greeted by thousands of his supporters in the local stadium. He subsequently made overtures to the United States, promising he could \"destroy the Taliban and al Qaeda\" if supported by the U.S., saying that \"the U.S. needs strong friends like Dostum.\"\n\nDostum became Vice President of Afghanistan in the 2014 Afghan presidential election. His running mates were Ashraf Ghani and Sarwar Danish.\n\nIn July 2016 Human Rights Watch accused Abdul Rashid Dostum's National Islamic Movement of Afghanistan of killing, abusing and looting civilians in the northern Faryab Province during June. Militia forces loyal to Dostum stated that the civilians they targeted - at least 13 killed and 32 wounded - were supporters of the Taliban.\n\nSome media reports stated earlier that Dostum was \"seeking political asylum\" in Turkey while others said he was exiled. One Turkish media outlet said Dostum was visiting after flying there with then Turkey's Foreign Minister Ali Babacan during a meeting of the Organization for Security and Cooperation in Europe (OSCE).\n\nWhile Dostum was ruling northern Afghanistan before the Taliban took over in 1998, women were able to go about unveiled, girls were allowed to go to school and study at the University of Balkh in Mazar-e-Sharif, cinemas showed Indian films and music played on television, activities which were all banned by the Taliban.\n\nHe viewed the ISAF forces attempt to crush the Taliban as ineffective and has gone on record saying that he could mop up the Taliban \"in six months\" if allowed to raise a 10,000 strong army of Afghan veterans. Senior Afghan government officials do not trust Dostum as they are concerned that he might be secretly rearming his forces.\n\nDostum is barred from entering the U.S.\n\n\n", "id": "2376", "title": "Abdul Rashid Dostum"}
{"url": "https://en.wikipedia.org/wiki?curid=2377", "text": "Andhra Pradesh\n\nAndhra Pradesh ()() is one of the 29 states of India, situated on the southeastern coast of the country. The state is the eighth largest state in India covering an area of . As per 2011 Census of India, the state is tenth largest by population with 49,386,799 inhabitants.\n\nOn 2 June 2014, the north-western portion of the state was bifurcated to form a new state of Telangana. Andhra Pradesh's longtime capital, Hyderabad, was transferred to Telangana as part of the division. However, in accordance with the Andhra Pradesh Reorganisation Act, 2014, Hyderabad will remain the \"de jure\" capital of both Andhra Pradesh and Telangana states for a period of time not exceeding 10 years. The new riverfront proposed capital in Guntur district is Amaravati, which is under the jurisdiction of APCRDA. The Gross State Domestic Product (GSDP) of the state in the 2016–2017 financial year at current prices stood at .\n\nThe state has a coastline of with jurisdiction over nearly 15,000 km territorial waters, the second longest among all the states of India after Gujarat. It is bordered by Telangana in the north-west, Chhattisgarh in the north, Odisha in the north-east, Karnataka in the west, Tamil Nadu in the south and the water body of Bay of Bengal in the east. A small enclave of of Yanam, a district of Puducherry, lies south of Kakinada in the Godavari delta to the east of the state.\n\nAndhra Pradesh is composed of two regions: Coastal Andhra, located along the Bay of Bengal, and Rayalaseema, in the inland southwestern part of the state. These two regions comprise 13 districts, with 9 in Coastal Andhra and 4 in Rayalaseema. Visakhapatnam, located on the Bay of Bengal in North Coastal Andhra is the largest city and commercial hub of the state with a GDP of $26 billion, followed in population and GDP by Vijayawada, which is located on the Krishna River and which has a GDP of $3 billion as of 2010.\n\nAndhra Pradesh hosted 121.8 million visitors in 2015, a 30% growth in tourist arrivals over the previous year. The Tirumala Venkateswara Temple in Tirupati is one of the world's most visited religious sites, with 18.25 million visitors per year. Other pilgrimage centers in Andhra Pradesh include the Ameen Peer Dargah in Kadapa, the Mahachaitya at Amaravathi, and the Kanaka Durga Temple in Vijayawada, while the state's natural attractions include the beaches of Visakhapatnam, hill stations such as the Araku Valley and Horsley Hills, and the island of Konaseema in the Godavari River delta.\n\nA tribe named Andhra has been mentioned in the Sanskrit texts such as Aitareya Brahmana (800-500 BCE). According to \"Aitareya Brahmana\" of the Rig Veda, the Andhras left north India and settled in south India.\n\nArchaeological evidence from places such as Amaravati, Dharanikota and Vaddamanu suggests that the Andhra region was part of the Mauryan Empire. Amaravati might have been a regional centre for the Mauryan rule. After the death of emperor Ashoka, the Mauryan rule weakened around 200 BCE, and was replaced by several small kingships in the Andhra region.\n\nThe Satavahana dynasty dominated the Deccan region from the 1st century BCE to the 3rd century CE. The Satavahanas have been mentioned by the names \"Andhra\", \"Andhrara-jatiya\" and \"Andhra-bhrtya\" in the Puranic literature. Satavahanas do not refer to themselves as \"Andhra\" in any of their coins or inscriptions; it could be possible that they were termed as \"Andhras\" because of their ethnicity or because their territory included the Andhra region.\n\nDharanikota along with Amaravathi was the capital of the later Satavahanas. Amaravathi became a major trade and pilgrimage centre during the Satavahana rule. According to the Buddhist tradition, Nagarjuna lived here, possibly in second and third centuries CE.\n\n\"Andhra Ikshvakus\" were one of the earliest recorded ruling dynasties of the Guntur-Krishna regions of Andhra Pradesh. They ruled the eastern Andhra country along the Krishna river during the later half of the second century CE. Puranas called Andhra Ikshvakus \"Shri Parvatiya Andhras\". Their capital was Vijayapuri (Nagarjunakonda). It is a strong common belief among some historians that Andhra Ikshvakus were related to the mythological Ikshvakus, while some believe Andhra Ikshvakus seem to be a local tribe who adopted the title.\n\nArchaeological evidence has suggested that the Andhra Ikshvakus immediately succeeded the Satavahanas in the Krishna river valley. Ikshvakus have left inscriptions at Nagarjunakonda, Jaggayyapeta, Amaravati and Bhattiprolu.\n\nMost of the Pallava Prakrit and Sanskrit charters from the southern Andhra country intimately connects them with the history of southern Andhra. The influence of the Pallavas was still felt by Andhra till it was swept by the Western Chalukyan invasion led by Pulakesin II in the first quarter of the seventh century AD. The Pallavas were not a recognised political power before the 2nd century AD. Pallavas were originally executive officers under the Satavahana kings.\n\nSince the fall of the Ikshvakus, the Vishnukundinas were the first great dynasty, which held sway way over the entire Andhra country including Kalinga and parts of Telangana and played an important and imperial role in the history of Deccan during the fifth and sixth century AD. They had three important cities, near Eluru, Amaravati and Puranisangam.\n\n\"The Salankayanas\" were an ancient dynasty that ruled the Andhra region between Godavari and Krishna with their capital as Vengi, modern Pedavegi 12 km from Eluru in West Godavari district of Andhra Pradesh, India's from 300 to 440 AD. They were Brahmins and their name is derived from their symbol and gotra name, which stood for Nandi (the bull of Shiva).\n\nEastern Chalukyas, or Chalukyas of Vengi, were a South Indian dynasty whose kingdom was located in the present day Andhra Pradesh. Their capital was Vengi near Eluru and their dynasty lasted for around 500 years from the 7th century until c. 1130 C.E. when the Vengi kingdom merged with the Chola empire. The Vengi kingdom was continued to be ruled by Eastern Chalukyan kings under the protection of the Chola empire until 1189 C.E., when the kingdom succumbed to the Hoysalas and the Yadavas. They had their capital originally at Vengi near Eluru of the West Godavari district end later changed to Rajamahendravaram (Rajamundry).\n\nThe roots of the Telugu language have been seen on inscriptions found near the Guntur district and from others dating to the rule of Renati Cholas in the fifth century CE.\n\nThe Reddy dynasty (1325–1448 CE) was established in present-day coastal Andhra Pradesh by Prolaya Vema Reddi in the early fourteenth century. The region that was ruled by this dynasty spanned present day coastal andhra from Visakhapatnam in the north to Kanchipuram in the south. Prolaya Vema Reddi was part of the confederation of states that started a movement against the invading Turkic Muslim armies of the Delhi Sultanate in 1323 CE and succeeded in repulsing them from Warangal. Today Reddys is a social group or caste of India, predominantly inhabiting the states of Andhra Pradesh and Telangana.\n\nKondaveedu Fort was constructed by Prolaya Vema Reddy. Later it was ruled by the Reddy dynasty between 1328 and 1428 and then taken over by Gajpathis of Orissa later ravaged by the Muslim rulers of the Bahmani kingdom (1458). The Vijayanagara emperor Krishnadevaraya captured it in 1516. The Golconda Sultans fought for the fort in 1531, 1536 and 1579, and Sultan Quli Qutb Shah finally captured it in 1579, renaming it \"Murtuzanagar\". Efforts are in progress to classify Kondaveedu Fort as a UNESCO World Heritage Site.\n\nThe Vijayanagara Empire was an empire originated South India, in the Deccan Plateau region in the early fourteenth century. It was established in 1336 by Harihara Raya I and his brother Bukka Raya I of Sangama Dynasty. The empire rose to prominence as a culmination of attempts by the southern powers to ward off Islamic invasions by the end of the thirteenth century. It lasted until 1646 although its power declined after a major military defeat in 1565 to the Deccan sultanates. The empire is named after its capital city of Vijayanagara, whose ruins surround present day Hampi, now a World Heritage Site in Karnataka, India.\n\nThe empire's patronage enabled fine arts and literature to reach new heights in Kannada, Telugu, Tamil and Sanskrit, while Carnatic music evolved into its current form. The Vijayanagara Empire created an epoch in South Indian history that transcended regionalism by promoting Hinduism as a unifying factor.\n\nInspired by their success, the Vijayanagara Empire, one of the greatest empires in the history of Andhra Pradesh and India, was founded by Harihara and Bukka, who served as treasury officers of the Kakatiyas of Warangal. In 1347 CE, an independent Muslim state, the Bahmani Sultanate, was established in south India by Ala-ud-Din Bahman Shah in a revolt against the Delhi Sultanate. The Qutb Shahi dynasty held sway over the Andhra country for about two hundred years from the early part of the sixteenth century to the end of the seventeenth century.\n\nIn the early 19th century, Northern Circars was ceded and it became part of the British East India company held Madras Presidency. Eventually this region emerged as the Coastal Andhra region. Later the Nizam rulers of Hyderabad ceded five territories to the British which eventually emerged as Rayalaseema region. The Nizams retained control of the interior provinces as the princely state of Hyderabad, acknowledging British rule in return for local autonomy. However, Komaram Bheem, a tribal leader, started his fight against the erstwhile Asaf Jahi Dynasty for the liberation of Hyderabad State. Meanwhile, the French occupied Yanam, in the Godavari delta, and (save for periods of British control) would hold it until 1954. In 1947 Vizianagaram was the largest Hindu Princely state in Andhra Pradesh.\n\nIndia became independent from the United Kingdom in 1947. The Nizam wanted to retain the independence of the Princely Hyderabad State from India, but the people of the region launched a movement to join the Indian Union. The state of Hyderabad was forcibly joined to the Republic of India with Operation Polo in 1948.\n\nIn an effort to gain an independent state based on linguistic differences and to protect the interests of the Telugu-speaking people of Madras State, Potti Sreeramulu fasted until death in 1952. As Madras became a bone of contention, in 1949 a JVP committee report stated \"Andhra Province could be formed provided the Andhras give up their claim on the city of Madras (now Chennai)\". After Potti Sreeramulu's death, the Telugu-speaking areas, i.e. Andhra State, was carved out of Madras State on 1 October 1953, with Kurnool as its capital city.\n\nOn the basis of a gentlemen's agreement of 1 November 1956, the States Reorganisation Act formed Andhra Pradesh by merging Andhra State with the Telugu-speaking areas of the already existing Hyderabad State. Hyderabad was made the capital of the new state. The Marathi-speaking areas of Hyderabad State merged with Bombay State and the Kannada-speaking areas were merged with Mysore State.\n\nIn February 2014, the Andhra Pradesh Reorganisation Act, 2014 bill was passed by the Parliament of India for the formation of Telangana state comprising ten districts. Hyderabad will remain as a joint capital for 10 years for both Andhra Pradesh and Telangana. The new state of Telangana came into existence on 2 June 2014 after approval from the President of India. The formation of a new state named \"Telangana\" from \"Andhra Pradesh\" is not considered an amendment to the Constitution of India per article 3 and 4 of that document.\n\nAs per the amendment to Andhra Pradesh Reorganisation Act, 2014, 7 mandals from Khammam district of Telangana have been transferred to Andhra Pradesh. Four mandals from Bhadrachalam revenue division namely, Chinturu, Kunavaram, Vararamachandrapuram, Bhadrachalam (excluding the Bhadrachalam town) were transferred to East Godavari district. Three mandals namely, Kukunoor, Velerupadu and Burgampadu (except 12 villages namely, Pinapaka, Morampalli, Banjara, Burgampadu, Naginiprolu, Krishnasagar, Tekulapalli, Sarapaka, Iravendi, Motepattinagar, Uppusaka, Nakiripeta and Sompalli) of Palvancha revenue division in Khammam district have been added to West Godavari district. Number of petitions questioning the validity of Andhra Pradesh Reorganisation Act, 2014 are long pending for verdict since April,2014 before the Supreme court constitutional bench.\n\nGeographically, Andhra Pradesh has varied topography ranging from the hills of Eastern Ghats and Nallamala Hills to the shores of Bay of Bengal that supports varied ecosystems, rich diversity of flora and fauna. There are two main rivers namely, Krishna and Godavari, that flow through the state. The state has two regions Coastal Andhra and Rayalaseema. The plains to the east of Eastern Ghats form the Eastern coastal plains. The coastal plains are for the most part of delta regions formed by the Godavari, Krishna, and Penna rivers. The Eastern Ghats are discontinuous and individual sections have local names. The Eastern Ghats are a major dividing line in the state's geography. The Kadapa Basin formed by two arching branches of the Eastern Ghats is a mineral-rich area. The Ghats become more pronounced towards the south and extreme north of the coast. Most of the coastal plains are put to intense agricultural use. The Rayalaseema region has semi-arid conditions. Lambasingi (or Lammasingi), a village in the Chintapalli Mandal of Visakhapatnam district is situated at 1000 meters above the sea level. It is the only place in South India which has snowfall and is also nicknamed as \"Kashmir of Andhra Pradesh\". Throughout the year the temperature here ranges from 0 °C to 10 °C.\n\n\"Andhra Pradesh Forest Department\" deals with protection, conservation and management of forests. The total forest cover of the state after the bifurcation is left with an area of 22,862 km. The forest in the state can be broadly divided into four major biotic provinces. They are:\n\nEastern Ghats region is home to dense tropical forests, while the vegetation becomes sparse as the Ghats give way to the Deccan Plateau, where shrub vegetation is more common. These Ghats have rich biological diversity with a wide variety of plants, birds and lesser forms of animal life. The vegetation found in the state is largely of dry deciduous types with a mixture of teak, \"Terminalia\", \"Dalbergia\", \"Pterocarpus\", \"Anogeissus\", etc.\nThe state possesses some rare and endemic plants like \"Cycas beddomei\", \"Pterocarpus santalinus\", \"Terminalia pallida\", \"Syzygium alternifolium\", \"Shorea talura\", \"Shorea tumburgia\", \"Psilotum nudum\", etc.\n\nThe diversity of fauna includes tigers, panthers, hyenas, black bucks, cheetals, sambars, sea turtles and a number of birds and reptiles. The estuaries of river Godavari and Krishna support rich mangrove forests with fishing cats and otters as keystone species.\n\nThe climate of Andhra Pradesh varies considerably, depending on the geographical region. Monsoons play a major role in determining the climate of the state. Summers last from March to June. In the coastal plain, the summer temperatures are generally higher than the rest of the state, with temperature ranging between 20 °C and 41 °C.\n\nJuly to September is the season for tropical rains in Andhra Pradesh. The state receives heavy rainfall from the southwest monsoon during these months. About one third of the total rainfall in Andhra Pradesh is brought by the northeast monsoon. October and November see low-pressure systems and tropical cyclones form in the Bay of Bengal which, along with the northeast monsoon, bring rains to the southern and coastal regions of the state. November, December, January, and February are the winter months in Andhra Pradesh. Since the state has a long coastal belt the winters are not very cold. The range of winter temperature is generally 12 °C to 30 °C.\n\n Census of India, the state had a population of with a population density of . The total population constitute, 70.4% of rural population with inhabitants and 29.6% of urban population with inhabitants. Children in the age group of 0–6 years are , constituting 10.6% of the total population, among them are boys and are girls. Visakhapatnam district has the largest urban population of 47.5% and Srikakulam district with 83.8%, has the largest rural population, among others districts in the state. The overall population of the state comprises 17.1% of Scheduled Caste and 5.3% of Scheduled Tribe population.\n\nThere are male and female citizens—a sex ratio of 996 females per 1000 males, higher than the national average of 926 per 1000. The literacy rate of the state stands at 67.41%. West Godavari district has the highest literacy rate of 74.6% and Vizianagaram district has the least with 58.9%.\n\nAndhra Pradesh ranks tenth of all Indian States in the Human Development Index scores with a score of 0.416. The National Council of Applied Economic Research district analysis in 2001 reveals that Krishna, West Godavari and Chittoor are the three districts in rural AP with the highest Human Development Index scores in ascending order.\n\nThe official language of Andhra Pradesh is Telugu. The Minister of Tourism and Culture has issued a declaration of the Telugu language as a Classical Language.\n\nMajority of the people in Andhra Pradesh are Hindus while Muslims constitute a sizeable minority. According to the 2011 census, the major religious groups in the state are Hindus (90.93%) and Muslims (7.35%). Christians, Buddhists, Sikhs, Jains & the people who declined to state their religion make up the remaining portion of population.\nAndhra Pradesh is home to Shankaracharya of Pushpagiri Peetham. Other Hindu saints include Sadasiva Brahmendra, Bhaktha Kannappa, Yogi Vemana, Yogi Sri Potuluri Virabrahmendra Swami.\n\n\nBuddhism spread to Andhra Pradesh early in its history. The Krishna River valley was \"a site of extraordinary Buddhist activity for almost a thousand years.\" The ancient Buddhist sites in the lower Krishna Valley, including Amaravati, Nagarjunakonda and Jaggayyapeta \"can be traced to at least the third century BCE, if not earlier.\"\n\nThe region played a central role in the development of Mahayana-buddhism, along with the Magadha-area in northeastern India. A.K. Warder holds that \"the Mahāyāna originated in the south of India and almost certainly in the Andhra country.\" According to Xing, \"Several scholars have suggested that the Prajnaparamita probably developed among the Mahasamghikas in Southern India probably in the Andhra country, on the Krishna River.\" The Prajñāpāramitā Sutras belong to the earliest Mahayana Sutras.\n\nRegions:\n\nHitherto, it comprised two regions: Northern Circars and Ceded districts. Now, the state comprises two regions:\n\nDistricts:\n\nIt has a total of 13 districts, nine in Kosta and four in Rayalaseema.\n\nRevenue divisions:\n\nThese 13 districts are further divided into 50 revenue divisions\nThere are as many as 7 revenue divisions in East Godavari district and only 2 in Vizianagaram district.\n\nMandals:\n\nThe 50 revenue divisions are in turn divided into 670 mandals. Chittoor district has the most number of mandals with 66 and Vizianagaram district has the least with 34.\n\nCities:\n\nThere are a total of 31 cities which include, 16 municipal corporations and 14 municipalities. There are two million plus cities namely, Visakhapatnam and Vijayawada.\n\nLegislative Assembly of Andhra Pradesh is the lower house of the state and legislative council of andhra pradesh is the upper house. with 58 members. In the Parliament of India, Andhra Pradesh has 11 seats in the Rajya Sabha, and 25 seats in the Lok Sabha. There are a total of 175 Assembly constituencies in the state. East Godavari district has the most number of constituencies with 19 and Vizianagaram district has the least with 9 assembly seats. Whereas, the legislative council of the state has 58 seats, which is one-third of total assembly seats.\n\nUntil 1962, the CPI, along with socialist parties namely Praja Socialist Party and Krishi Lok Party played an important role in the 1950s. In the 1967 state assembly elections, all socialist parties were eliminated and CPI lost opposition party status. The first Chief Minister of Andhra Pradesh was Neelam Sanjiva Reddy who later served as President of India.\n\nIn 1983, the Telugu Desam Party (TDP) won the state elections and N.T. Rama Rao became the chief minister of the state for the first time. This broke the long time single party monopoly enjoyed by the INC from 1956 until 1982. Nandamuri Taraka Rama Rao is the founder of Telugu Desam party and served as the first chief minister from the party. The 1989 elections ended the rule of NTR, with the INC party returning to power with Marri Chenna Reddy at the helm. He was replaced by Janardhan Reddy in 1990, who was replaced by Kotla Vijaya Bhaskara Reddy in 1992.\n\nN. Chandrababu Naidu held the record for the longest serving chief minister (1995 to 2004). In 1994, Andhra Pradesh gave a mandate to the Telugu Desam Party again, and NTR became the chief minister again. Nara Chandrababu Naidu, the son-in-law of NTR, came to power with the backing of a majority of the MLAs. The Telugu Desam Party won both the assembly and Lok Sabha election in 1999 under the leadership of Chandrababu Naidu.\n\nIn what would be the last elections held in the unified state, Telugu Desam Party got a mandate in their favour in the residuary (new)state. Nara Chandrababu Naidu, the chief of Telugu Desam Party became Chief Minister on 8 June 2014, for the new state of Andhra Pradesh.\n\nAndhra Pradesh was ranked eighth among other Indian states in terms of GSDP for the financial year 2014–2015. The GSDP at current prices was and at constant prices was . The domestic product of agriculture sector accounts for and Industrial sector for . The service sector of the state accounts more percentage of the GSDP with a total of . In the 2010 list by \"Forbes\" magazine, there were several from Andhra Pradesh among the top 100 richest Indians.\n\nAndhra Pradesh economy is mainly based on agriculture and livestock. Four important rivers of India, the Godavari, Krishna, Penna, and Thungabhadra flow through the state and provide irrigation. 60 percent of population is engaged in agriculture and related activities. Rice is the major food crop and staple food of the state. It is an exporter of many agricultural products and is also known as \"Rice Bowl of India\". The state has three Agricultural Economic Zones in Chittoor district for mango pulp and vegetables, Krishna district for mangoes, Guntur district for chilies.\n\nBesides rice, farmers also grow jowar, bajra, maize, minor millet, coarse grain, many varieties of pulses, oil seeds, sugarcane, cotton, chili pepper, mango nuts and tobacco. Crops used for vegetable oil production such as sunflower and peanuts are popular. There are many multi-state irrigation projects under development, including Godavari River Basin Irrigation Projects and Nagarjuna Sagar Dam.\n\nLivestock and poultry is also another profitable business, which involves rearing cattle in enclosed areas for commercial purposes. The state is also a largest producer of eggs in the country and hence, it is nicknamed as \"\"Egg Bowl of Asia\"\".\n\nFisheries contribute 10% of total fish and over 70% of the shrimp production of India. The geographical location of the state allows marine fishing as well as inland fish production. The most exported marine exports include \"Vannamei shrimp\" and are expected to cross $1 billion in 2013–2014.\n\nThe industrial sector of the state includes some of the key sectors like Pharma, Automobile, Textiles etc. Sricity located in Chittoor district is an integrated business city which is home to many renowned firms like PepsiCo, Isuzu Motors, Cadbury India, Kellogg's, Colgate-Palmolive, Kobelco etc. The PepsiCo firm has its largest plant in India at Sri City.\n\nThe state is also emerging in information technology and biotechnology. The IT/ITES revenues of Visakhapatnam is at in 2012–2013. The development of IT in Tier-II and Tier-III cities like Vijayawada, Kakinada and Tirupati is also improving. In the fiscal year 2012–2013, Vijayawada's IT/ITeS revenues were crore. Tirupati with and Kakinada with stand next. For the benefit of state i.e., After separating Telangana from andhra, people of andhra protested for special status during the month of January in 2017\n\nAndhra Pradesh is one of the storehouses of mineral resources in India. Andhra Pradesh with varied geological formations, contain rich and variety of industrial minerals and building stones.\n\nAndhra Pradesh is listed top in the deposit and production of mica in India. Minerals found in the state include limestone, reserves of oil and natural gas, manganese, asbestos, iron ore, ball clay, fire clay, gold diamonds, graphite, dolomite, quartz, tungsten, steatitic, feldspar, silica sand. It has about one third of India's limestone reserves and is known for large exclusive deposits of barytes and galaxy granite in the international market.\n\nMining\n\nMining is identified as one of the growth engines for the overall development of industry and infrastructure. The Tummalapalle Uranium mine in Andhra has confirmed 49,000 tonnes of ore and there are indications that it could hold reserves totalling three times its current size. 700 million tonnes of metal grade Bauxite deposits in proximity to Visakhapatnam Port.\n\nReliance Industries Limited struck nine trillion cubic feet of gas reserves in the KG basin, off the Andhra Pradesh coast near Kakinada. Discovery of large quantity of natural gas in KG Basin is expected to provide rapid economic growth. During the year 2016, nearly 134 trillion cubic feet of methane hydrate deposits were explored in KG basin whose extraction is adequate to impart energy security for many decades to India.\n\nPower plants\n\nThe state is a pioneer nationwide in solar power generation. APGENCO is the power generating company owned by the state. The state has become power surplus with excess power generation being exported to other states.\nThermal (natural gas and coal based) and renewable power plants totalling to 21,000 MW were installed in the state by the year 2015. Local power plants of 9,600 MW capacity only are supplying electricity in the state which includes Simhadri Super Thermal Power Plant (2000 MW) of NTPC, Vizag Thermal Power Station (1040 MW), Rayalaseema Thermal Power Station (1050 MW), Sri Damodaram Sanjeevaiah Thermal Power Station (1600 MW), Vijayawada Thermal Power Plant (1760 MW), etc. Hydel power plants are having a capacity of 1671 MW.\n\nThere are as many as thirteen geographical indications from the state of Andhra Pradesh\nas per \"Geographical Indications of Goods (Registration and Protection) Act, 1999\". The geographical indications from the state covers handicrafts, foodstuff and textiles such as, Bobbili Veena, Budithi Bell and Brass Craft, Dharmavaram Handloom Pattu Sarees and Paavadas, Guntur Sannam, Kondapalli Toys, Machilipatnam Kalamkari, Mangalagiri Sarees and Fabrics, Srikalahasti Kalamkari, Tirupati Laddu, Uppada Jamdani Sari and Venkatagiri Sari.\n\nEluru is not only famous on the map of India but world as well. Carpets of this region have their presence in international markets from a long time ago. Eluru carpets were an invention of Persians and they brought it here during the Muhammaddin regime. There is a huge carpet industry situated in Eluru and most of the carpets are exported.\n\nMachilipatnam and Srikalahasti Kalamkari's are the two unique textile art forms practised in India. There are also other notable handicrafts present in the state, like the soft limestone idol carvings of Durgi. Etikoppaka in Visakhapatnam district is notable for its Lac industry, producing lacquered wooden.\n\nThe state has many museums, which features a varied collection of ancient sculptures, paintings, idols, weapons, cutlery and inscriptions, and religious artefacts such as the archaeological museum at Amaravati with features relics of nearby ancient sites, Visakha Museum and Telugu Cultural Museum in Visakhapatnam displays the history of the pre-Independence and Telugu culture and Heritage and the Victoria Jubilee Museum in Vijayawada with large collection of artifacts.\n\nNannayya, Tikkana and Yerrapragada form the trinity who translated the Sanskrit epic \"Mahabharata\" into Telugu language. Nannayya wrote the first treatise on Telugu grammar called \"Andhra Shabda Chintamani\" in Sanskrit, as there was no grammatical work in Telugu prior to that. Pothana is the poet who composed the classic \"Srimad Maha Bhagavatamu\", a Telugu translation of \"Sri Bhagavatam\". Vemana is notable for his philosophical poems. The Vijayanagara emperor Krishnadevaraya wrote Amuktamalyada. Telugu literature after Kandukuri Veeresalingam is termed as Adhunika Sahityam. He is known as \"Gadya Tikkana\" and was the author of Telugu social novel, \"Satyavati Charitam\". Jnanpith Award winners include Sri Viswanatha Satya Narayana. The Andhra Pradesh native and revolutionary poet Sri Sri brought new forms of expressionism into Telugu literature.\n\nDance\n\nKuchipudi is the state dance, originated at the village of Kuchipudi in Krishna district. It also entered the Guinness World Records for performing \"Mahabrinda Natyam\" with a total of 6,117 \ndancers in Vijayawada.\n\nMusic\nMany composers of Carnatic music like Annamacharya, Tyagaraja, Kshetrayya, and Bhadrachala Ramadas were of Telugu descent. Modern Carnatic music composers like Ghantasala and M. Balamuralikrishna are also of Telugu descent. The Telugu film industry hosts many music composers and playback singers such as S. P. Balasubrahmanyam, P. Susheela, S. Janaki, P B Srinivas. Folk songs are popular in the many rural areas of the state. Forms such as the \"Burra katha\" and \"Poli\" are still performed today.\n\nHarikatha:\n\n\"Harikathaa Kalakshepam (or Harikatha)\" involves the narration of a story, intermingled with various songs relating to the story. Harikatha was originated in Andhra.\n\nBurra katha\n\nBurra katha is an oral storytelling technique in the Katha tradition, performed in villages of coastal Andhra Pradesh region. The troupe consists of one main performer and two co-performers. It is a narrative entertainment that consists of prayers, solo drama, dance, songs, poems and jokes. The topic will be either a Hindu mythological story or a contemporary social issue.\n\nTheatre\n\n\"Rangasthalam\" is an Indian theatre in the Telugu language, based predominantly in Andhra Pradesh. Gurazada Apparao wrote the play, \"Kanyasulkam\" in 1892, which is often considered the greatest play in the Telugu language. C. Pullaiah is cited as the father of Telugu theatre movement.\n\nIn the early 1990s, the Telugu film industry had largely shifted from Chennai to Hyderabad. The Telugu film culture (or, \"Tollywood\") is the second -largest film industry in India next to Bollywood Film Industry . Prolific film producer from the state, D. Ramanaidu holds a Guinness Record for the most number of films produced by a person.\n\nIn the years 2005, 2006 and 2008 the Telugu film industry produced the largest number of films in India, exceeding the number of films produced in Bollywood. The industry holds the Guinness World Record for the largest film production facility in the world.\n\nPickles and chutneys (sauces) are made from chilli, ginger, coconut and other vegetables like tomato, brinjals, gongura are served with meals. Aavakaaya is probably the best known of the pickles.\n\nThe coastal region of the state has abundant seafood supply. The variety of fish curry recipes are famous. It is rich and aromatic, with a liberal use of exotic spices and ghee (clarified butter). Lamb, chicken are also the most widely used meats in the non-vegetarian dishes.\n\nAndhra Pradesh is promoted by its tourism department, APTDC as the Koh-i-Noor of India.\n\nBeaches\n\nThe seacoast of the state extends along the Bay of Bengal from Srikakulam to Nellore district.\n\nCaves\nBorra Caves in the Ananthagiri Hills of the Eastern Ghats, near Visakhapatnam are a million-year-old stalactite and stalagmite formations. Belum Caves in Kurnool district are the second largest natural caves of in length on the Indian subcontinent. Undavalli caves are Indian rock-cut architecture in Guntur district.\n\nValleys and Hills\nAraku Valley is the famous hill station in Visakhapatnam district with thick forests, coffee plantations and waterfalls. Horsley Hills is a summer hill resort in the Chittoor district, situated at an elevation of , has natural flora and fauna. Papi Hills in East Godavari district is famous for its scenic beauty of the location in the river Godavari with. Arma Konda peak located in Visakhapatnam district is the highest peak in Eastern Ghats.\n\nEcotourism\n\nThe state has rich forests, diverse flora & fauna that provides ample scope for promoting ecotourism. The state has many Sanctuaries, National Parks, Zoological Parks such as Coringa, Krishna Wildlife Sanctuary, Nagarjunsagar-Srisailam Tiger Reserve, Kambalakonda Wildlife Sanctuary, Sri Venkateswara Zoological Park, Indira Gandhi Zoological Park etc. Atapaka Bird Sanctuary, Nelapattu Bird Sanctuary and Pulicat Lake Bird Sanctuary attracts many migratory birds.\n\nReligious destinations\n\nApart from these, the state is home to many pilgrim destinations. It has many temples and shrines, mosques, and churches. Some famous temples, mosques, Buddhist shrines and churches of religious importance which are often visited by many tourists include Tirumala Temple in Chitoor District, Simhachalam Temple in Visakhapatnam District, Annavaram temple in East Godavari District, Dwaraka Tirumala in West Godavari District, Srisailam temple in Kurnool District, Kanaka Durga Temple of Vijayawada, Kotappakonda in Narasaraopet, Amaravathi, Srikalahasti temple, Shahi jamia masjid in Adoni, Gunadala Church in Vijayawada, \"Buddhist centres\" at Amaravati, Nagarjuna Konda etc., and many more as well.\n\nAdventure sports\n\nAndhra Pradesh government has started promoting adventure sports as a tourism industry in 2015. The state has long coastlines with amazing backwaters as well as numerous hills and mountain ranges. It has started partnering with specialist companies to develop and maintain these areas. Horsley Hills is 3 hours drive from Bengaluru and is the highest point in Andhra Pradesh also called Coorg of Andhra Pradesh. Gandikota in Kadapa district has some magnificent gorges. Puligundu is another place close to Bengaluru with rock climbing already happening through Freakouts Adventure Solutions. The state has also initiated water sports in numerous places along the coast.\n\nThe state is well connected to other states through road and rail networks. It is also connected to other countries by means of airways and seaports as well. With a long seacoast along the Bay of Bengal, it also has many ports for sea trade. The state has one of the largest railway junctions at Vijayawada and one of the largest seaports at Visakhapatnam.\n\nRoads in Andhra Pradesh consist of National Highways and state highways with district roads as well. NH 5, with a highway network of around in the state, is a part of Golden Quadrilateral Project undertaken by National Highways Development Project. It also forms part of AH 45 which comes under the Asian Highway Network.\n\nThe Andhra Pradesh State Road Transport Corporation (APSRTC) is the major public bus transport owned by the state government which runs thousands of buses connecting different parts of the state. Pandit Nehru Bus Station (PNBS) in Vijayawada is one of the largest bus terminals in Asia.\n\nAndhra Pradesh has a railway network of and have played a significant role in boosting the economy of the state alongside developing the industrial and the tourism sectors. One of the highest broad gauge tracks in the world is in Eastern Ghats route that runs from Visakhapatnam to Anantagiri. Most of Andhra Pradesh falls under with Guntur, Vijayawada, Guntakal (South Central Railway zone and Waltair (East Coast Railway zone) divisions. This serves the north coastal districts.\n\nWaltair Railway Division under ECoR zone, is fourth largest revenue earning division in India. Vijayawada railway station is the highest grosser in the SCR zone and one of busiest railway junctions in India.\n\nVisakhapatnam Airport, is the only airport in the state with international connectivity. The state has five domestic airports, Vijayawada Airport at Gannavaram, Rajahmundry Airport at Madhurapudi, Tirupati Airport at Renigunta, Cuddapah Airport and a privately owned, public use airport at Puttaparthi. There are also 16 small air strips located in the state.\n\nAndhra Pradesh has one of the country's largest port at Visakhapatnam in terms of cargo handling. The other famous ports are Krishnapatnam Port (Nellore), Gangavaram Port and Kakinada Port. Gangavaram Port is a deep seaport which can accommodate ocean liners up to 200,000–250,000 DWT. There are 14 notified non-major ports at Bheemunipatnam, S.Yanam, Machilipatnam, Nizampatnam, Vadarevu etc.\n\nAndhra Pradesh has an overall literacy rate of 67.41% as per the 2011 Indian census. The primary and secondary school education is imparted by government, aided and private schools under the administration of the \"School Education Department\" of the state. The various types of schools in the state include, Municipal, Andhra Pradesh Residential, Andhra Pradesh Social Welfare Residential, Zilla Parishad and private schools. The private schools are of both aided and unaided type. The medium of instructions followed by different schools are Telugu, English, Urdu, Hindi, Kannada, Odia and Tamil. The \"Directorate of Government Examinations\" of the state administers the conduct of Secondary School Certificate examinations. 644,961 candidates took the 2015 Secondary School Certificate exam and recorded a pass percentage of 91.42% for regular and 58.57% by private candidates.\n\nAccording to the report of Sarva Shiksha Abhiyan (2011–2012) and Statistical Abstract (2012–2013), 3,745,340 children out of 3,805,791 (98.4%), were enrolled in Primary schools with a teacher/student ratio of 29.3%. 2,101,928 children out of (97.5%), were enrolled in Upper Primary schools with a teacher/student ratio of 24.6%.\n\nApart from thousands of schools ranging from the pre-primary to the senior secondary ones, the state is home to a number of institutes for higher education. Notably,\nAndhra University & the Prestigious Andhra University College of Science & Technology, Andhra University College of Engineering are one of the oldest institutions in India and worldwide renowned institutions in the field of Science, Engineering & Research. The All India Institute of Medical Sciences is sanctioned by Government of India at Mangalagiri. The Indian Institute of Management at Visakhapatnam and Indian Institutes of Technology at Tirupathi, both started functioning from the academic year 2015–2016. NIT Tadepalligudem from 2015. The Indian Institute of Petroleum and Energy at Visakhapatnam started functioning from the year 2016 under the mentorship of IIT Kharagpur. The Government of Andhra Pradesh has established Rajiv Gandhi University of Knowledge Technologies (RGUKT) in 2008 to cater to the educational needs of the gifted rural youth of Andhra Pradesh. The higher education includes many colleges, universities and research institutes providing professional education in the fields of arts, humanities, science, engineering, law, medicine, business, and veterinary sciences, with undergraduate and post graduation. GITAM, K L University and Vignan University are the Deemed Universities.\n\nMajor state universities in the state are Andhra University, Acharya Nagarjuna University, Jawaharlal Nehru Technological University (Anantapur, Kakinada, Vizianagaram and Pulivendula), Dravidian University, Krishna University, Rayalaseema University, Sri Krishnadevaraya University, Sri Venkateswara University, Adikavi Nannaya University, Yogi Vemana University and Vikrama Simhapuri University. Other universities include, Dr. N.T.R. University of Health Sciences, Damodaram Sanjivayya National Law University, Sri Venkateswara Veterinary University, Sri Venkateswara Vedic University sponsored and supported by Tirumala Tirupati Devasthanams.\n\nResearch institutes have been set up by the central government in the state. NSTL Naval Science & Technological Laboratory, NIO National Institute of Oceanography, Visakhapatnam, School of Planning and Architecture at Vijayawada is an autonomous research institute under Ministry of Human Resource Development of Government of India, National Atmospheric Research Laboratory carry out fundamental and applied research in Atmospheric and Space Sciences, Indian Institute of Science Education and Research, Tirupati, Society For Applied Microwave Electronics Engineering and Research, Visakhapatnam Central Tobacco Research Institute, Rajahmundry under control of ICAR (Indian Council of Agriculture Research) conducts fundamental and applied research on Tobacco for the benefit of the farming community, Indian Institute of Oil Palm Research (IIOPR) at Pedavegi near Eluru in West Godavari district serves as a centre for conducting and co-ordinating research on all aspects of oil palm conservation, improvement, production, protection, post-harvest technology and transfer of technology, CCRH Regional Research Institute at Gudivada, Clinical Research Institute at Tirupati and National Institute of Oceanography at Visakhapatnam are some of them.\n\nSpace research organisation\n\nIndian Space Research Organisation (or Sriharikota Range (SHAR)) at barrier island of Sriharikota in Nellore district of Andhra Pradesh is a satellite launching station. It is India's primary orbital launch site. India's lunar orbiter Chandrayaan-1 was launched from the centre at 6:22 AM IST on 22 October 2008.\n\nThe Sports Authority of Andhra Pradesh, is the governing body which looks after the infrastructure development in cricket, field hockey, association football, Olympic weightlifting, chess, water sports, tennis, badminton, table tennis, cycling, etc.\n\nCricket is one of the most popular sports in the state. The ACA-VDCA Stadium in Visakhapatnam is the home to Andhra Pradesh cricket team. The venue regularly hosts international as well as domestic matches. Notable cricketers from Andhra Pradesh, include Maharajkumar of Vizianagram, M. V. Narasimha Rao, M. S. K. Prasad, V.V.S. Laxman, Tirumalasetti Suman, Arshad Ayub, Ambati Rayudu, Venkatapathy Raju, Sravanthi Naidu, Yalaka Venugopal Rao etc. Humpy Koneru, from Gudivada of Krishna district of the state, is an Indian chess Grandmaster.\n\nKarnam Malleswari, the first female Indian to win an Olympic medal, hails from Srikakulam district of Andhra Pradesh. She won the bronze medal on 19 September 2000, in the 69 kg category with a lift of 240 kg.\n\nPullela Gopichand, is a former Indian badminton player. He won the All England Open Badminton Championships (2001), to becoming the second Indian to achieve it after Prakash Padukone.\n\nCherukuri Lenin 1985 or 1986 — 24 October 2010) was an Indian archer and coach who won a silver medal at the Asian Grand Prix in Malaysia, and was a National Archery Coach.\n\n\n", "id": "2377", "title": "Andhra Pradesh"}
{"url": "https://en.wikipedia.org/wiki?curid=2380", "text": "Accelerated Graphics Port\n\nThe Accelerated Graphics Port (AGP) is a high-speed point-to-point channel for attaching a video card to a computer system, primarily to assist in the acceleration of 3D computer graphics. It was originally designed as a successor to PCI-type connections for video cards. Since 2004, AGP has been progressively phased out in favor of PCI Express (PCIe); by mid-2008, PCI Express cards dominated the market and only a few AGP models were available.\n\nAs computers increasingly became graphically oriented, successive generations of graphics adapters began to push the limits of PCI, a bus with shared bandwidth. This led to the development of AGP, a \"bus\" dedicated to graphics adapters.\n\nAGP is heavily based on PCI, and in fact the AGP bus is a superset of the conventional PCI bus, and AGP cards must act as PCI cards.\n\nThe primary advantage of AGP over PCI is that it provides a dedicated pathway between the slot and the processor rather than sharing the PCI bus. In addition to a lack of contention for the bus, the direct connection allows for higher clock speeds.\n\nThe second major change is that AGP uses split transactions, where the address and data phases of a PCI transaction are separated. The card may send many address phases, and the host processes them in order. This avoids long delays, with the bus idle, during read operations.\n\nThird, PCI bus handshaking is simplified. Unlike PCI bus transactions whose length is negotiated on a cycle-by-cycle basis using the FRAME# and STOP# signals, AGP transfers are always a multiple of 8 bytes long, and the total length is included in the request. Further, rather than using the IRDY# and TRDY# signals for each word, data is transferred in blocks of four clock cycles (32 words at AGP 8× speed), and pauses are allowed only between blocks.\n\nFinally, AGP allows (optional in AGP 1.0 and 2.0, mandatory in AGP 3.0) \"sideband addressing\", meaning that the address and data buses are separated so the address phase does not use the main address/data (AD) lines at all. This is done by adding an extra 8-bit \"SideBand Address\" bus over which the graphics controller can issue new AGP requests while other AGP data is flowing over the main 32 address/data (AD) lines. This results in improved overall AGP data throughput.\n\nThis great improvement in memory read performance makes it practical for an AGP card to read textures directly from system RAM, while a PCI graphics card must copy it from system RAM to the card's video memory. System memory is made available using the graphics address remapping table (GART), which apportions main memory as needed for texture storage. The maximum amount of system memory available to AGP is defined as the \"AGP aperture\".\n\nThe AGP slot first appeared on x86-compatible system boards based on Socket 7 Intel P5 Pentium and Slot 1 P6 Pentium II processors. Intel introduced AGP support with the i440LX Slot 1 chipset on August 26, 1997, and a flood of products followed from all the major system board vendors.\n\nThe first Socket 7 chipsets to support AGP were the VIA Apollo VP3, SiS 5591/5592, and the ALI Aladdin V. Intel never released an AGP-equipped Socket 7 chipset. FIC demonstrated the first Socket 7 AGP system board in November 1997 as the \"FIC PA-2012\" based on the VIA Apollo VP3 chipset, followed very quickly by the \"EPoX P55-VP3\" also based on the VIA VP3 chipset which was first to market.\n\nEarly video chipsets featuring AGP support included the Rendition Vérité V2200, 3dfx Voodoo Banshee, Nvidia RIVA 128, 3Dlabs PERMEDIA 2, Intel i740, ATI Rage series, Matrox Millennium II, and S3 ViRGE GX/2. Some early AGP boards used graphics processors built around PCI and were simply bridged to AGP. This resulted in the cards benefiting little from the new bus, with the only improvement used being the 66 MHz bus clock, with its resulting doubled bandwidth over PCI, and bus exclusivity. Examples of such cards were the Voodoo Banshee, Vérité V2200, Millennium II, and S3 ViRGE GX/2. Intel's i740 was explicitly designed to exploit the new AGP feature set. In fact it was designed to texture only from AGP memory, making PCI versions of the board difficult to implement (local board RAM had to emulate AGP memory.)\n\nMicrosoft first introduced AGP support into \"Windows 95 OEM Service Release 2\" (OSR2 version 1111 or 950B) via the \"USB SUPPLEMENT to OSR2\" patch. After applying the patch the Windows 95 system became \"Windows 95 version 4.00.950 B\". The first Windows NT-based operating system to receive AGP support was Windows NT 4.0 with Service Pack 3, introduced in 1997. Linux support for AGP enhanced fast data transfers was first added in 1999 with the implementation of the AGPgart kernel module.\n\nIntel released \"AGP specification 1.0\" in 1997. It specified 3.3 V signals and 1× and 2× speeds. Specification 2.0 documented 1.5 V signaling, which could be used at 1×, 2× and the additional 4× speed and 3.0 added 0.8 V signaling, which could be operated at 4× and 8× speeds. (1× and 2× speeds are physically possible, but were not specified.)\n\nAvailable versions are listed in the table on the right.\n\nAGP version 3.5 is only publicly mentioned by Microsoft under \"Universal Accelerated Graphics Port (UAGP)\", which specifies mandatory supports of extra registers once marked optional under AGP 3.0. Upgraded registers include PCISTS, CAPPTR, NCAPID, AGPSTAT, AGPCMD, NISTAT, NICMD. New required registers include APBASELO, APBASEHI, AGPCTRL, APSIZE, NEPG, GARTLO, GARTHI.\n\nThere are various physical interfaces (connectors); see the Compatibility section.\n\nAn official extension for cards that required more electrical power, with a longer slot with additional pins for that purpose. AGP Pro cards were usually workstation-class cards used to accelerate professional computer-aided design applications employed in the fields of architecture, machining, engineering, simulations, and similar fields.\n\nA 64-bit channel was once proposed as an optional standard for AGP 3.0 in draft documents, but it was dropped in the final version of the standard.\n\nThe standard allows 64-bit transfer for AGP8× reads, writes, and fast writes; 32-bit transfer for PCI operations.\n\nA number of non-standard variations of the AGP interface have been produced by manufacturers.\n\n\nAGP cards are backward and forward compatible within limits. 1.5 V-only keyed cards will not go into 3.3 V slots and vice versa, though \"Universal\" cards exist which will fit into either type of slot. There are also unkeyed \"Universal\" slots that will accept either type of card. When an AGP Universal card is plugged-into an AGP Universal slot, only the 1.5 V portion of the card is used. Some cards, like Nvidia's GeForce 6 series (except the 6200) or ATI's Radeon X800 series, only have keys for 1.5 V to prevent them from being installed in older mainboards without 1.5 V support. Some of the last modern cards with 3.3 V support were the Nvidia GeForce FX series (FX 5200, FX 5500, FX 5700, some FX 5800, FX 5900 and some FX 5950), Geforce 6 Series (6200, 6600/6600 LE/6600 GT only) and the ATI Radeon 9500/9700/9800(R350) (but not 9600/9800(R360)). Some Geforce 6200 and Geforce 6600 cards will function with AGP 1.0 (3.3v) slots.\n\nAGP Pro cards will not fit into standard slots, but standard AGP cards will work in a Pro slot. Motherboards equipped with a Universal AGP Pro slot will accept a 1.5 V or 3.3 V card in either the AGP Pro or standard AGP configuration, a Universal AGP card, or a Universal AGP Pro card.\n\nSome cards incorrectly have dual notches, and some motherboards incorrectly have fully open slots, allowing a card to be plugged into a slot that does not support the correct signaling voltage, which may damage card or motherboard. Some incorrectly designed older 3.3 V cards have the 1.5 V key.\n\nThere are some proprietary systems incompatible with standard AGP; for example, Apple Power Macintosh computers with the Apple Display Connector (ADC) have an extra connector which delivers power to the attached display. Some cards designed to work with a specific CPU architecture (e.g., PC, Apple) may not work with others due to firmware issues.\n\nMark Allen of Playtools.com made the following comments regarding Practical AGP Compatibility for AGP 3.0 and AGP 2.0:\n\n\"...nobody makes AGP 3.0 cards, and nobody makes AGP 3.0 motherboards. At least not any manufacturers I can find. Every single video card I could find which claimed to be an AGP 3.0 card was actually a universal 1.5V AGP 3.0 card. And every motherboard which claimed to be an AGP 3.0 motherboard turned out to be a universal 1.5V AGP 3.0 motherboard. It makes sense, if you think about it, because if anyone actually shipped a consumer-oriented product which supported only 0.8 volts, they would end up with lots of confused customers and a support nightmare. In the consumer market, you'd have to be crazy to ship a 0.8 volt only product.\"\n\nActual power supplied by an AGP slot depends upon the card used. The maximum current drawn from the various rails is given in the specifications for the various versions. For example, if maximum current is drawn from all supplies and all voltages are at their specified upper limits, an AGP 3.0 slot can supply up to 48.25 watts; this figure can be used to specify a power supply conservatively, but in practice a card is unlikely ever to draw more than 40 W from the slot, with many using less. AGP Pro provides additional power up to 110 W. Many AGP cards had additional power connectors to supply them with more power than the slot could provide.\n\nBy 2010 few new motherboards had AGP slots. No new motherboard chipsets were equipped with AGP support, but motherboards continued to be produced with older chipsets with support for AGP.\n\nGraphics processors of this period use PCI-Express, a general-purpose (not restricted to graphics) standard that supports higher data transfer rates and full-duplex. To create AGP-compatible graphics cards, those chips require an additional PCIe-to-AGP bridge-chip to convert PCIe signals to and from AGP signals. This incurs additional board costs due to the need for the additional bridge chip and for a separate AGP-designed circuit board.\n\nVarious manufacturers of graphics cards continued to produce AGP cards for the shrinking AGP user-base. The first bridged cards were the GeForce 6600 and ATI Radeon X800 XL boards, released during 2004-5. In 2009 AGP cards from Nvidia had a ceiling of the GeForce 7 Series. In 2011 DirectX 10-capable AGP cards from AMD vendors (Club 3D, HIS, Sapphire, Jaton, Visiontek, Diamond, etc.) included the Radeon HD 2400, 3450, 3650, 3850, 4350, 4650, and 4670. The HD 5000 AGP series mentioned in the catalyst software was never available. There were many problems with the AMD Catalyst 11.2 - 11.6 AGP hotfix drivers under Windows 7 with the HD 4000 series AGP video cards; use of 10.12 or 11.1 AGP hotfix drivers is the recommended workaround. Several of the vendors listed above make available past versions of the AGP drivers.\n\nAn AGP bus is a superset of a 66 MHz conventional PCI bus and, immediately after reset, follows the same protocol. The card must act as a PCI target, and optionally may act as a PCI master. (AGP 2.0 added a \"fast writes\" extension which allows PCI writes from the motherboard to the card to transfer data at higher speed.)\n\nAfter initialization, AGP transactions are permitted. For these, the card is always the AGP master and the motherboard is always the AGP target. The card queues multiple requests which correspond to the PCI address phase, and the motherboard schedules the corresponding data phases later. An important part of initialization is telling the card the maximum number of outstanding AGP requests which may be queued at a given time.\n\nAGP requests are similar to PCI memory read and write requests, but use a different encoding on command lines C/BE[3:0] and are always 8-byte aligned; their starting address and length are always multiples of 8 bytes (64 bits). The three low-order bits of the address are used instead to communicate the length of the request.\n\nWhenever the PCI GNT# signal is asserted, granting the bus to the card, three additional status bits ST[2:0] indicate the type of transfer to be performed next. If the three bits are codice_1, the card may begin a PCI transaction or (if sideband addressing is not in use) queue a request in-band using PIPE#.\n\nTo queue a request in-band, the card must request the bus using the standard PCI REQ# signal, and receive GNT# plus bus status ST[2:0] equal to codice_1. Then the card asserts the PIPE# signal while driving the AGP command, address, and length on the C/BE[3:0], AD[31:3] and AD[2:0] lines, respectively. (If the address is 64 bits, a dual address cycle similar to PCI is used.) For every cycle that PIPE# is asserted, the card sends another request without waiting for acknowledgement from the motherboard, up to the configured maximum queue depth. The last cycle is marked by deasserting REQ#, and PIPE# is deasserted on the following idle cycle.\n\nIn-band requests are always sent at single data rate (1× speed).\n\nPossible request codes are:\n\nAGP 3.0 dropped high-priority requests and the long read commands, as they were little used.\n\nIf side-band addressing is supported and configured, the PIPE# signal is not used. (And the signal is re-used for another purpose in the AGP 3.0 protocol, which requires side-band addressing.) Instead, requests are broken into 16-bit pieces and sent across the SBA bus. The possible values are:\n\n\nSideband address bytes are sent at the same rate as data transfers, up to 8× the 66 MHz basic bus clock. Sideband addressing has the advantage that it mostly eliminates the need for turnaround cycles on the AD bus between transfers, in the usual case when read operations greatly outnumber writes.\n\nWhile asserting GNT#, the motherboard may instead indicate via the ST bits that a data phase for a queued request will be performed next. There are four queues: two priorities (low- and high-priority) for each of reads and writes, and each is processed in order. Obviously, the motherboard will attempt to complete high-priority requests first, but there is no limit on the number of low-priority responses which may be delivered while the high-priority request is processed.\n\nFor each cycle when the GNT# is asserted and the status bits have the value codice_12, a read response of the indicated priority is scheduled to be returned. At the next available opportunity (typically the next clock cycle), the motherboard will assert TRDY# (target ready) and begin transferring the response to the oldest request in the indicated read queue. (Other PCI bus signals like FRAME#, DEVSEL# and IRDY# remain deasserted.) Up to four clock cycles worth of data (16 bytes at AGP 1× or 128 bytes at AGP 8×) are transferred without waiting for acknowledgement from the card. If the response is longer than that, both the card and motherboard must indicate their ability to continue on the third cycle by asserting IRDY# (initiator ready) and TRDY#, respectively. If either one does not, wait states will be inserted until two cycles after they both do. (The value of IRDY# and TRDY# at other times is irrelevant and they are usually deasserted.)\n\nThe C/BE# byte enable lines may be ignored during read responses, but are held asserted (all bytes valid) by the motherboard.\n\nThe card may also assert the RBF# (read buffer full) signal to indicate that it is temporarily unable to receive more low-priority read responses. The motherboard will refrain from scheduling any more low-priority read responses. The card must still be able to receive the end of the current response, and the first four-cycle block of the following one if scheduled, plus any high-priority responses it has requested.\n\nFor each cycle when GNT# is asserted and the status bits have the value codice_13, write data is scheduled to be sent across the bus. At the next available opportunity (typically the next clock cycle), the card will assert IRDY# (initiator ready) and begin transferring the data portion of the oldest request in the indicated write queue. If the data is longer than four clock cycles, the motherboard will indicate its ability to continue by asserting TRDY# on the third cycle. Unlike reads, there is no provision for the card to delay the write; if it didn't have the data ready to send, it shouldn't have queued the request.\n\nThe C/BE# lines \"are\" used with write data, and may be used by the card to select which bytes should be written to memory.\n\nThe multiplier in AGP 2×, 4× and 8× indicates the number of data transfers across the bus during each 66 MHz clock cycle. Such transfers use source synchronous clocking with a \"strobe\" signal (AD_STB[0], AD_STB[1], and SB_STB) generated by the data source. AGP 4× adds complementary strobe signals.\n\nAt AGP 4× and 8× speeds, it is possible for a request to complete in the middle of a clock cycle. In such a case, the cycle is padded with dummy data transfers (with the C/BE# byte enable lines held deasserted).\n\nThe AGP connector contains almost all PCI signals, plus several additions. The connector has 66 contacts on each side, although 4 are removed for each keying notch. Pin 1 is closest to the I/O bracket, and the B and A sides are as in the table, looking down at the motherboard connector.\n\nContacts are spaced at 1 mm intervals, however they are arranged in two staggered vertical rows so that there is 2 mm space between pins in each row. Odd-numbered A-side contacts, and even-numbered B-side contacts are in the lower row (1.0 to 3.5 mm from the card edge). The others are in the upper row (3.7 to 6.0 mm from the card edge).\n\nPCI signals omitted are:\n\nSignals added are:\n\n\n", "id": "2380", "title": "Accelerated Graphics Port"}
{"url": "https://en.wikipedia.org/wiki?curid=2381", "text": "Andreas Aagesen\n\nAndreas Aagesen (5 August 1826 – 26 October 1879) was a Danish jurist.\n\nAagesen was educated for the law at Christianshavn and Copenhagen, and interrupted his studies in 1848 to take part in the First Schleswig War, in which he served as the leader of a reserve battalion.\n\nIn 1855 Aagesen became a professor of jurisprudence at the University of Copenhagen. In 1870 he was appointed a member of the commission for drawing up a maritime and commercial code, and the navigation law of 1882 is mainly his work. In 1879 he was elected a member of the Landsting (one of two chambers of the Danish Parliament, the Rigsdagen); but it is as a teacher at the university that he won his reputation. Aagesen was Carl Christian Hall's successor as lecturer on Roman law at the university, and in this department his research was epoch-making.\n\nAmong his numerous juridical works may be mentioned:\n\n\n", "id": "2381", "title": "Andreas Aagesen"}
{"url": "https://en.wikipedia.org/wiki?curid=2382", "text": "Aalen\n\nAalen () is a former Free Imperial City located in the eastern part of the German state of Baden-Württemberg, about east of Stuttgart and north of Ulm. It is the seat of the Ostalbkreis district and is its largest town. It is also the largest town in the Ostwürttemberg region. Since 1956, Aalen has had the status of Große Kreisstadt (major district town). It is noted for its many half-timbered houses constructed from the 16th century through the 18th century.\n\nWith an area of 146.63 km, Aalen is ranked 7th in Baden-Württemberg and 2nd within the Government Region of Stuttgart, after Stuttgart. With a population of about 66,000, Aalen is the 15th most-populated settlement in Baden-Württemberg.\n\nAalen is situated on the upper reaches of the river Kocher, at the foot of the Swabian Jura which lies to the south and south-east, and close to the hilly landscapes of the Ellwangen Hills to the north and the \"Welland\" to the north-west.\n\nThe west of Aalen's territory is on the foreland of the eastern Swabian Jura, and the north and north-west is on the Swabian-Franconian Forest, both being part of the Swabian Keuper-Lias Plains. The south-west is part of the Albuch, the east is part of the Härtsfeld, these two both being parts of the Swabian Jura.\n\nThe Kocher enters the town's territory from Oberkochen to the south, crosses the district of Unterkochen, then enters the town centre, where the \"Aal\" flows into it. The \"Aal\" is a small river located only within the town's territory. Next, the Kocher crosses the district of Wasseralfingen, then leaves the town for Hüttlingen. Rivers originating near Aalen are the Rems (near Essingen, west of Aalen) and the Jagst (near Unterschneidheim, east of Aalen), both being tributaries of the Neckar, just like the Kocher.\n\nThe elevation in the centre of the market square is relative to Normalhöhennull. The territory's lowest point is at the Lein river near Rodamsdörfle, the highest point is the Grünberg's peak near Unterkochen at .\n\nAalen's territory ranges over all lithostratigraphic groups of the South German Jurassic: Aalen's south and the \"Flexner\" massif are on top of the White Jurassic, the town centre is on the Brown Jurassic, and a part of Wasseralfingen is on the Black Jurassic. As a result, the town advertises itself as a \"Geologist's Mecca\".\n\nMost parts of the territory are on the \"Opalinuston-Formation\" (Opalinum Clay Formation) of the Aalenian subdivision of the Jurassic Period, which is named after Aalen. On the \"Sandberg\", the \"Schnaitberg\" and the \"Schradenberg\" hills, all in the west of Aalen, the \"Eisensandstein\" (Iron Sandstone) formation emerges to the surface. On the other hills of the city, sands \"(Goldshöfer Sande)\", gravel and residual rubble prevail.\nThe historic centre of Aalen and the other areas in the Kocher valley are founded completely on holocenic floodplain loam \"(Auelehm)\" and riverbed gravel that have filled in the valley.\n\nMost parts of Dewangen and Fachsenfeld are founded on formations of \"Jurensismergel\" (Jurensis Marl), \"Posidonienschiefer\" (cf. Posidonia Shale), \"Amaltheenton\" (Amalthean Clay), \"Numismalismergel\" (Numismalis Marl) and \"Obtususton\" (Obtusus Clay, named after Asteroceras obtusum ammonites) moving from south to north, all belonging to the Jurassic and being rich in fossils. They are at last followed by the \"Trossingen Formation\" already belonging to the Late Triassic.\n\nUntil 1939 iron ore was mined on the \"Braunenberg\" hill. (see Tiefer Stollen section).\n\nThe maximum extent of the town's territory amounts to in a north-south dimension and in an east-west dimension. The area is , which includes 42.2% agriculturally used area and 37.7% of forest. 11.5% are built up or vacant, 6.4% is used by traffic infrastructure. Sporting and recreation grounds and parks comprise 1% , other areas 1.1% .\n\nThe following municipalities border on Aalen. They are listed clockwise, beginning south, with their respective linear distances to Aalen town centre given in brackets:\n\nOberkochen (), Essingen (), Heuchlingen (), Abtsgmünd (), Neuler (), Hüttlingen (), Rainau (), Westhausen (), Lauchheim (), Bopfingen () and Neresheim (), all in the Ostalbkreis district, furthermore Heidenheim an der Brenz () and Königsbronn (), both in Heidenheim district.\n\nAalen's territory consists of the town centre \"(Kernstadt)\" and the municipalities\nmerged from between 1938 (Unterrombach) and 1975 (Wasseralfingen, see mergings section).\nThe municipalities merged in the course of the latest municipal reform of the 1970s are also called \"Stadtbezirke\" (quarters or districts), and are \"Ortschaften\" (\"settlements\") in terms of Baden-Württemberg's \"Gemeindeordnung\" (municipal code), which means, each of them has its own council elected by its respective residents \"(Ortschaftsrat)\" and is presided by a spokesperson \"(Ortsvorsteher)\".\n\nThe town centre itself and the merged former municipalities consist of numerous villages \"(Teilorte)\", mostly separated by open ground from each other and having their own independent and long-standing history. Some however have been created as planned communities, which were given proper names, but no well-defined borders.\n\nList of villages:\n\nAalen forms a \"Mittelzentrum\" (\"medium-level centre\") within the Ostwürttemberg region. Its designated catchment area includes the following municipalities of the central and eastern Ostalbkreis district: Abtsgmünd, Bopfingen, Essingen, Hüttlingen, Kirchheim am Ries, Lauchheim, Neresheim, Oberkochen, Riesbürg and Westhausen, and is interwoven with the catchment area of Nördlingen, situated in Bavaria, east of Aalen.\n\nAs Aalen's territory sprawls on escarpments of the Swabian Jura, on the Albuch and the Härtsfeld landscapes, and its elevation has a range of , the climate varies from district to district.\n\nThe weather station the following data originate from is located between the town centre and Wasseralfingen at about and has been in operation since 1991.\n\nThe sunshine duration is about 1800 hours per year, which averages 4.93 hours per day. So Aalen is above the German average of 1550 hours per year. However, with 167 days of precipitation, Aalen's region also ranks above the German average of 138. The annual rainfall is , which places Aalen in the middle within Baden-Württemberg.\nThe annual mean temperature is . Here Aalen ranks above the German average of and the Baden-Württemberg average of .\n\nNumerous remains of early civilization have been found in the area. Tools made of flint and traces of Mesolithic human settlement dated between the 8th and 5th millennium BC were found on several sites on the margins of the Kocher and Jagst valleys. On the \"Schloßbaufeld\" plateau (appr. ), situated behind \"Kocherburg\" castle near Unterkochen, a hill-top settlement was found, with the core being dated to the Bronze Age. In the \"Appenwang\" forest near Wasseralfingen, in Goldshöfe, and in Ebnat, tumuli of the Hallstatt culture were found. In Aalen and Wasseralfingen, gold and silver coins left by the Celts were found. The Celts were responsible for the fortifications in the Schloßbaufeld settlement consisting of sectional embankments and a stone wall. Also, Near Heisenberg (Wasseralfingen), a Celtic nemeton has been identified; however it is no longer readily apparent.\n\nAfter abandoning the Alb Limes (a \"limes\" generally following the ridgeline of the Swabian Jura) around 150 AD, Aalen's territory became part of the Roman Empire, in direct vicinity of the then newly erected Rhaetian Limes. The Romans erected a castrum to house the cavalry unit \"Ala II Flavia milliaria\"; its remains are known today as \"Kastell Aalen\" (\"Aalen Roman fort\"). The site is west of today's town centre at the bottom of the \"Schillerhöhe\" hill. With about 1,000 horsemen and nearly as many grooms, it was the greatest fort of auxiliaries along the Rhaetian Limes. There were Civilian settlements adjacent along the south and the east. Around 260 AD, the Romans gave up the fort as they withdrew their presence in unoccupied Germania back to the Rhine and Danube rivers, and the Alamanni took over the region. Based on 3rd- and 4th-century coins found, the civilian settlement continued to exist for the time being. However, there is no evidence of continued civilization between the Roman era and the Middle Ages.\n\nBased on discovery of alamannic graves, archaeologists have established the 7th century as the origination of Aalen. In the northern and western walls of St. John's church, which is located directly adjacent to the eastern gate of the Roman fort, Roman stones were incorporated. The building that exists today probably dates to the 9th century.\n\nThe first mention of Aalen was in 839, when emperor Louis the Pious reportedly permitted the Fulda monastery to exchange land with the Hammerstadt village, then known as \"Hamarstat\".\nAalen itself was first mentioned in an inventory list of Ellwangen Abbey, dated ca. 1136, as the village \"Alon\", along with a lower nobleman named Conrad of Aalen. This nobleman probably had his ancestral castle at a site south of today's town centre and was subject first to Ellwangen abbey, later to the House of Hohenstaufen, and eventually to the House of Oettingen. 1426 was the last time a member of that house was mentioned in connection with Aalen.\nDocuments, from the Middle Ages, indicate that the town of Aalen was founded by the Hohenstaufen some time between 1241 and 1246, but at a different location than the earlier village, which was supposedly destroyed in 1388 during the war between the Alliance of Swabian Cities and the Dukes of Bavaria.\nLater, it is documented that the counts of Oettingen ruled the town in 1340. They are reported to have pawned the town to Count Eberhard II and subsequently to the House of Württemberg in 1358 or 1359 in exchange for an amount of money.\n\nDuring the war against Württemberg, Emperor Charles IV took the town without a fight after a siege. On 3 December 1360, he declared Aalen an Imperial City, that is, a city or town responsible only to the emperor, a status that made it a quasi-sovereign city-state and that it kept until 1803. In 1377, Aalen joined the Alliance of Swabian Cities, and in 1385, the term \"civitas\" appears in the town's seal for the first time. In 1398, Aalen was granted the right to hold markets, and in 1401 Aalen obtained proper jurisdiction.\nThe oldest artistic representation of Aalen was made in 1528. It was made as the basis of a lawsuit between the town and the Counts of Oettingen at the Reichskammergericht in Speyer. It shows Aalen surrounded by walls, towers, and double moats. The layout of the moats, which had an embankment built between them, is recognizable by the present streets named \"Nördlicher, Östlicher, Südlicher\" and \"Westlicher Stadtgraben\" (Northern, Eastern, Southern and Western Moat respectively). The wall was about tall, 1518 single paces () long and enclosed an area of . During its early years, the town had two town gates: The \"Upper\" or \"Ellwangen Gate\" in the east, and St. Martin's gate in the south; however due to frequent floods, St. Martin's gate was bricked up in the 14th century and replaced by the \"Lower\" or \"Gmünd Gate\" built in the west before 1400. Later, several minor side gates were added. The central street market took place on the \"Wettegasse\" (today called \"Marktplatz\", \"market square\") and the \"Reichsstädter Straße\". So the market district stretched from one gate to the other, however in Aalen it was not straight, but with a 90-degree curve between southern (St. Martin's) gate and eastern (Ellwangen) gate.\n\nAround 1500, the civic graveyard was relocated from the town church to St. John's Church, and in 1514, the \"Vierundzwanziger\" (\"Group of 24\") was the first assembly constituted by the citizens.\n\nDelegated by Württemberg's Duke Louis III, on 28 June 1575, nearly 30 years after Martin Luther's death, Jakob Andreae, professor and chancellor of the University of Tübingen, arrived in Aalen. The sermon he gave the following day convinced the mayor, the council, and the citizens to adopt the Reformation in the town. Andreae stayed in Aalen for four weeks to help with the change. This brought along enormous changes, as the council forbade the Roman Catholic priests to celebrate masses and give sermons. However, after victories of the imperial armies at the beginning of the Thirty Years' War, the Prince-Provostry of Ellwangen, which still held the right of patronage in Aalen, were able to temporarily bring Catholicism back to Aalen; however after the military successes of the Protestant Union, Protestant church practices were instituted again.\n\nOn the night of 5 September 1634, two ensigns of the army of Bernard of Saxe-Weimar who were fighting with the Swedes and retreating after the Battle of Nördlingen set fire to two powder carriages, to prevent the war material to fall into Croatian hands and to prevent their advance. The result was a conflagration, that some say destroyed portions of the town. There are differing stories regarding this fire. According to 17th-century accounts, the church and all the buildings, except of the \"Schwörturm\" tower, were casualties of the fire, and only nine families survived. 19th century research by Hermann Bauer, Lutheran pastor and local historian, discovered that the 17th-century account is exaggerated, but he does agree that the town church and buildings in a \"rather large\" semicircle around it were destroyed. The fire also destroyed the town archive housed in an addition to the church, with all of its documents. After the fire, soldiers of both armies went through the town looting. It took nearly 100 years for the town to reach its population of 2,000.\n\nFrench troops marched through Aalen in 1688 during the Nine Years' War; however, unlike other places, they left without leaving severe damages. The French came through again in 1702 during the War of the Spanish Succession and in 1741 during the War of the Austrian Succession, the latter also caused imperial troops to move through in 1743.\n\nThe town church's tower collapsed in 1765, presumably because proper building techniques were not utilized during the reconstruction after the fire of 1634. The collapsing tower struck two children of the tower watchman who died of their injuries, and destroyed the nave, leaving only the altar cross intact. The remaining walls had to be knocked down due to the damage. Reconstruction began the same year, creating the building that exists today.\n\nOn 22 November 1749, the so-called \"Aalen protocol\" regulating the cohabitation of Lutherans and Roman Catholics in the jointly ruled territory of Oberkochen was signed in Aalen by the Duchy of Württemberg and the Prince-Provostry of Ellwangen. Aalen had been chosen because of its neutral status as a Free Imperial City.\n\nDuring the War of the First Coalition (1796), Aalen was looted. The War of the Second Coalition concluded in 1801 with the signing of the Treaty of Lunéville, which led to the German Mediatisation of 1803 that assigned most Imperial Cities to the neighbouring principalities. Aalen was assigned to the electorate of Württemberg, which later became the Kingdom of Württemberg, and became seat of the District (\"Oberamt\") of Aalen. During the War of the Third Coalition, on 6 October 1805, Napoleon Bonaparte arrived in Aalen, with an army of 40,000. This event, along with Bavarian and Austrian troops moving in some days later, caused miseries that according to the town clerk \"no feather could describe\".\n\nIn 1811, the municipality of Unterrombach was formed out of some villages previously belonging to Aalen, some to the Barons of Wöllwarth, and the eastern villages were assigned to the municipality of Unterkochen.\n\nIn the age of the Napoleonic wars, the town walls were no longer of use, and in the 18th century, with the maintenance of walls, gates and towers becoming more neglected Finally, due to the fact that the funds were lacking, starting in 1800, most towers were demolished, the other buildings followed soon.\n\nBefore the industrial revolution, Aalen's economy was shaped by its rural setting. Many citizens were pursuing farming besides their craft, such as tanning. In the mid 19th century, there were twelve tanneries in Aalen, due to the proximity of Ulm, an important sales market. Other crafts that added to the economy were weaving mills, which produced linen and woolen goods, and baking of sweet pastry and gingerbread.\n\nIn Aalen, industrialisation was a slow process. The first major increase was in the 1840s, when three factories for nails and some other factories emerged. It was the link with the railway network, by the opening of the Rems Railway from Cannstatt to Wasseralfingen in 1861, that brought more industry to Aalen, along with the royal steel mill (later \"Schwäbische Hüttenwerke\") in Wasseralfingen. The Rems Railway's extension to Nördlingen in 1863, the opening of the Brenz Railway in 1864 and of the Upper Jagst Railway in 1866 turned Aalen into a railway hub. Furthermore, between 1901 and its shutdown in 1972, the Härtsfeld Railway connected Aalen with Dillingen an der Donau via Neresheim. Part of becoming a rail hub entailed more jobs based on the rail industry. These included, a maintenance facility, a roundhouse, an administrative office, two track maintenance shops, and a freight station with an industrial branch line. This helped shape Aalen into what today's historians call a \"railwayman's town\". Starting in 1866, the utilities in town all began to be upgraded. Starting with the Aalen gasworks which were opened and gas lighting was introduced. Then in 1870, a modern water supply system was started and in 1912 the mains electricity. Finally, in 1935, the first electrically powered street lights were installed.\nTo fight housing shortage during and immediately after World War I, the town set up barracks settlement areas at the \"Schlauch\" and \"Alter Turnplatz\" grounds. In spite of the industry being crippled by the Great Depression of 1929, the public baths at the Hirschbach creek where modernized, extended and re-opened in 1931.\n\nIn the federal election of 1932, the Nazi Party performed below average in Aalen with 25.8% of votes compared to 33.1% on the national level, thus finishing second to the Centre Party which had 26.6% (11.9% nationwide) of the votes, and ahead of the Social Democratic Party of Germany with 19.8% (20.4%). However, the March 1933 federal elections showed that the sentiment had changed as the Nazi Party received 34.1% (still below German average 43.9% nationwide), but by far the leading vote-getter in Aalen, followed by the Centre party at 26.6% (11.3% nationwide) and the Social Democrats 18.6% (18.3% nationwide).\n\nThe democratically elected mayor Friedrich Schwarz remained in office until the Nazis removed him from office, in 1934, and replaced him by chairman of the Nazi Party town council head and brewery owner Karl Barth. Karl Barth was a provisional mayor until the more permanent solution of Karl Schübel. In August 1934, the Nazi consumer fair Braune Messe (\"brown fair\") was held in Aalen.\n\nDuring Nazi rule in Germany, there were many military offices constructed in Aalen, starting with, in 1936, a military district riding and driving school. The Nazis also built an army replenishment office \"(Heeresverpflegungsamt)\", a branch arsenal office \"(Heeresnebenzeugamt)\" and a branch army ammunitions institute \"(Heeresnebenmunitionsanstalt)\".\n\nStarting in 1935, mergers of neighbouring towns began. In 1938, the Oberamt was transformed into the Landkreis of Aalen and the municipality of Unterrombach was disbanded. Its territory was mostly added to Aalen, with the exception of Hammerstadt, which was added to the municipality of Dewangen. Forst, Rauental and Vogelsang were added to Essingen (in 1952 the entire former municipality of Unterrombach was merged into Aalen, with the exception of Forst, which is part of Essingen until present).\n\nIn September 1944, the \"Wiesendorf\" concentration camp, a subcamp of Natzweiler-Struthof, was constructed nearby. It was designated for between 200 and 300 prisoners who were utilized for forced labor in industrial businesses nearby. Until the camp's dissolution in February 1945, 60 prisoners died. Between 1946 and 1957, the camp buildings were torn down; however, its foundations are still in place in house \"Moltkestraße 44/46\". Also, there were several other labour camps which existed where prisoners of war along with women and men from occupied countries occupied by Germany were pooled. The prisoners at these other camps had to work for the arms industry in major businesses like \"Schwäbische Hüttenwerke\" and the \"Alfing Keßler\" machine factory.\n\nIn the civic hospital, the deaconesses on duty were gradually replaced by National Socialist People's Welfare nurses. Nazi eugenics led to compulsory sterilization of some 200 persons there.\n\nFortunately, Aalen avoided most of the combat activity during World War II. It was only during the last weeks of the war that Aalen became a target of air warfare, which led to the destruction and severe damage of parts of the town, the train station, and other railway installations. A series of air attacks lasting for more than three weeks reached its peak on 17 April 1945, when United States Army Air Forces planes bombed the branch arsenal office and the train station. During this raid, 59 people were killed, more than half of them buried by debris, and more than 500 lost their homes. Also, 33 residential buildings, 12 other buildings and 2 bridges were destroyed, and 163 buildings, including 2 churches, were damaged. Five days later, the Nazi rulers of Aalen were unseated by the US forces.\n\nAalen became part of the State of Baden-Württemberg, upon its creation in 1952. Then, with the Baden-Württemberg territorial reform of 1973, the District of Aalen was merged into the Ostalbkreis district. Subsequently, Aalen became seat of that district, and in 1975, the town's borough attained its present size (see below).\n\nThe population of Aalen exceeded the limit of 20,000, which was the requirement for to gain the status of Große Kreisstadt (\"major district town\") in 1946. On 1 August 1947, Aalen was declared \"Unmittelbare Kreisstadt\" (\"immediate district town\"), and with the creation of the Gemeindeordnung (municipal code) of Baden-Württemberg on 1 April 1956, it was declared \"Große Kreisstadt\".\n\nOn 31 December 2008, 51.1 percent of Aalen were members of the Catholic Church, 23.9 percent were members of the Evangelical-Lutheran Church. About 25 percent belong to other or no religious community or gave no information. The district of Waldhausen was the district with the highest percentage of Roman Catholic inhabitants at 75.6 percent, and the central district was the one with the highest percentage of Evangelical-Lutheran inhabitants at 25.6 percent, as well as those claiming no religious preference at 32.5 percent.\n\nAalen's population originally was subject to the jus patronatus of Ellwangen Abbey, and thus subject to the Roman Catholic Diocese of Augsburg.\n\nWith the assistance of the Duke of Württemberg, in 1575, the reformation was implemented in Aalen. Subsequently, Aalen has been a predominantly Protestant town for centuries, with the exception of the years from 1628 until 1632 (see reformation section). Being an Imperial City, Aalen could govern its clerical matters on its own, so Clerics, organists and choir masters were direct subjects to the council, which thus exerted bishop-like power. There was even a proper hymn book for Aalen. After the transition to Württemberg, in 1803, Aalen became seat of a deanery, with the dean church being the Town Church (with the building constructed from 1765 to 1767 and existing until present). Another popular church is St. John's Church, located on the cemetery and refurbished in 1561.\n\nAs Aalen's population grew in the 20th century, more parishes were founded: St. Mark's parish with its church building of 1967 and St. Martin's parish with its church of 1974. In the borough of Unterrombach, Aalen had implemented the reformation as well, but the community remained a chapel-of-ease of Aalen. A proper church, the Christ Church, was erected in 1912 and a proper parish was established in 1947. In Fachsenfeld, the ruling family of Woellwarth resp. of Leinroden implemented the reformation. A parish church was built in 1591, however with an influx of Catholics in the 18th century, a Catholic majority was established. The other districts of present-day Aalen remained mostly catholic after the reformation, however Wasseralfingen established a Lutheran parish in 1891 and a church, St. Magdalene's Church, in 1893. In Unterkochen, after World War II, a parish was established and a church was built in 1960. All four parishes belong to the deanery of Aalen within the Evangelical-Lutheran Church in Württemberg. Furthermore, in Aalen there are Old Pietistic communities.\n\nThe few Catholics of today's central district were covered by the parish of Unterkochen until the 19th century, a situation which continued for some years even after completion of St. Mary's Church in 1868, which was constructed by Georg Morlok. However, in 1872 Aalen got its proper parish again, and in 1913, a second Catholic church, Salvator's Church, was completed, and in 1969 the Holy Cross Church was also finished. In 1963, a second parish was set up, and in 1972 it got a new Church, the new St. Mary's Church, which has been erected in place of the old St. Mary's church, which had been torn down in 1968. Another church of the second parish was St. Augustine's Church, which was completed in 1970. Finally, in 1976 and 1988, St. Elizabeth's Church and St. Thomas' Church were completed. Furthermore, in 1963, the St. Michael pastoral care office was built.\n\nHofherrnweiler has its own Catholic church, St. Boniface's, since 1904. The villages of Dewangen, Ebnat, Hofen, Waldhausen and Wasseralfingen had remained Catholic after reformation, so old parishes and churches persist there. The \"Assumption of Mary\" Church in Dewangen has an early Gothic tower and a newly built nave (1875). Mary's Immaculate Conception Church in Ebnat was constructed in 1723; however the church was first mentioned in 1298.\nHofen's Saint George's Church is a fortified church, whose current nave was built between 1762 and 1775. Alongside the church, the Late Gothic St. Odile's Chapel is standing, whose entrance has the year 1462 engraved upon it. Foundations of prior buildings have been dated to the 11th and 13th century.\n\nSt. Mary's Church of Unterkochen was first mentioned in 1248, and has served the Catholics of Aalen for a long time. Waldhausen's parish church of St. Nicholas was built between 1699 and 1716. Wasseralfingen at first was a chapel of ease for Hofen, but has since had its own chapel, St. Stephen, built. It was presumably built in 1353 and remodeled in 1832. In 1834, a proper parish was established, which built a new St. Stephen's Church. This new building utilized the Romanesque Revival architecture style and was built between 1881 and 1883, and has since remained the parish's landmark. Also, Fachsenfeld received its own church, named Sacred Heart in 1895. All Catholic parishes within Aalen are today incorporated into four pastoral care units within the \"Ostalb\" Deanery of the Diocese of Rottenburg-Stuttgart; however these units also comprise some parishes outside of Aalen. Pastoral Care Unit two comprises the parishes of Essingen, Dewangen and Fachsenfeld, unit four comprises Hofen and Wasseralfingen, unit five comprises both parishes of Aalen's centre and Hofherrnweiler, unit five comprises Waldhausen, Ebnat, Oberkochen and Unterkochen.\n\nIn addition to the two major religions within Aalen, there are also free churches and other communities, including the United Methodist Church, the Baptists, the Seventh-day Adventist Church and the New Apostolic Church.\n\nUntil the late 19th century, no Jews were documented within Aalen. In 1886 there were four Jews were living in Aalen, a number that rose to ten in 1900, fell to seven in 1905, and remained so until 1925. Upon the Nazis' rise to power in 1933, seven Jews, including two children, lived in Aalen. During the Kristallnacht in 1938, the vitrines of the three Jewish shops in the town were smashed and their proprietors imprisoned for several weeks. After their release, most Aalen Jews emigrated. The last Jews of Aalen, Fanny Kahn, was forcibly resettled to Oberdorf am Ipf, which had a large Jewish community. Today, a street of Aalen is named after her. The Jew Max Pfeffer returned from Brussels to Aalen in 1948 to continue his shop, but emigrated to Italy in 1967.\n\nIn Aalen, there is an Islamic Ditib community, which maintains the \"D.I.T.I.B. Mosque of Aalen (Central Mosque)\" located at Ulmer Straße. The mosque's construction started on 30 August 2008. The Millî Görüş organisation maintains the Fatih Mosque, as well at Ulmer Straße.\n\nThe present-day make up of Aalen was created on 21 June 1975 by the unification of the cities of Aalen and Wasseralfingen, with the initial name of \"Aalen-Wasseralfingen\". This annexation made Aalen's territory one third larger than its prior size. On 1 July 1975, the name \"Aalen\" was revived. Prior to this merger, the town of Aalen had already annexed the following municipalities:\n\nDuring the Middle Ages and the early modern period, Aalen was just a small town with a few hundred inhabitants. The population grew slowly due to numerous wars, famines and epidemics. It was the beginning of the Industrial Revolution in the 19th century where Aalen's growth accelerated. Whereas in 1803, only 1,932 people inhabited the town, in 1905 it had already increased to 10,442. The number continued to rise and reached 15,890 in 1939.\n\nThe influx of refugees and ethnic Germans from Germany's former eastern territories after World War II pushed the population to 31,814 in 1961. The merger with Wasseralfingen on 21 June 1975 added 14,597 persons and resulted in a total population of 65,165 people. On 30 June 2005, the population, which was officially determined by the Statistical Office of Baden-Württemberg, was 67,125.\n\nThe following overview shows how the population figures of the borough were ascertained. Until 1823, the figures are mostly estimates, thereafter census results or official updates by the state statistical office. Starting in 1871, the figures were determined by non-uniform method of tabulation using extrapolation.\n\nOn 31 December 2008, Aalen had precisely 66,058 inhabitants, of which 33,579 were female and 32,479 were male. The average age of Aalen's inhabitants rose from 40.5 years in 2000 to 42.4 in 2008. Within the borough, 6,312 foreigners resided, which is 9.56 percent. Of them, the largest percentage are from Turkey (38 percent of all foreigners), the second largest group are from Italy (13 percent), followed by Croatians (6 percent) and Serbs (5 percent).\n\nThe number of married residents fell from 32,948 in 1996 to 31,357 in 2007, while the number of divorced residents rose in the same period from 2,625 to 3,859. The number of single residents slightly increased between 1996 and 2004 from 25,902 to 26,268 and fell slightly until 2007 to 26,147. The number of widowed residents fell from 5,036 in 1996 to 4,783 in 2007.\n\nAalen has arranged a municipal association with Essingen and Hüttlingen.\n\nSince the local election of 7 June 2009, the town council consists of 54 representatives having a term of five years. The seats are distributed as follows on parties and groups (changes refer to the second last election of 2004):\n\nSince 1374, the mayor and the council maintain the government of the town. In the 16th century, the town had two, sometimes three mayors, and in 1552, the council had 13 members. Later, the head of the administration was reorganized several times. In the Württemberg era, the mayor's title was initially called \"Bürgermeister\", then from 1819 it was Schultheiß, and since 1947 it is \"Oberbürgermeister\". The mayor is elected for a term of eight years, and he is chairman and a voting member of the council. He has one deputy with the official title of \"Erster Bürgermeister\" (\"first mayor\") and one with the official title of \"Bürgermeister\" (\"mayor\").\n\nHeads of town in Aalen since 1802\n\nAalen's coat of arms depicts a black eagle with a red tongue on golden background, having a red shield on its breast with a bent silver eel on it. Eagle and eel were first acknowledged as Aalen's heraldic animals in the seal of 1385, with the eagle representing the town's imperial immediacy. After the territorial reform, it was bestowed again by the Administrative District of Stuttgart on 16 November 1976.\n\nThe coat of arms' blazon reads: “In gold, the black imperial eagle, with a red breast shield applied to it, therein a bent silver eel” \"(In Gold der schwarze Reichsadler, belegt mit einem roten Brustschild, darin ein gekrümmter silberner Aal)\".\n\nAalen’s flag is striped in red and white and contains the coat of arms.\n\nThe origin of the town’s name is uncertain. Matthäus Merian (1593–1650) presumed the name to originate from its location at the Kocher river, where \"frequently eels are caught\", while \"Aal\" is German for \"eel\". Other explanations point to Aalen as the garrison of an ala during the Roman empire, respectively to an abridgement of the Roman name \"Aquileia\" as a potential name of the Roman fort, a name that nearby Heidenheim an der Brenz bore as well. Another interpretation points to a Celtic word aa meaning \"water\".\n\nThe \"Twin Cities Society of Aalen\" \"(Städtepartnerschaftsverein Aalen e. V.)\" promotes \"friendly relations\" between Aalen and its twin cities, which comprises mutual exchanges of sports and cultural clubs, schools and other civic institutions. On the occasion of the Reichsstädter Tage, from 11 until 13 September 2009 the first conference of twinned cities was held.\n\nAalen has five twin cities:\n\nOn the occasion of the 1980 \"Reichsstädter Tage\", Aalen took over godparenthood for the more than 3000 ethnic Germans displaced from the Wischau linguistic enclave. 972 of them settled in Aalen in 1946. The \"Wischau Linguistic Enclave Society\" \"(Gemeinschaft Wischauer Sprachinsel)\" regularly organises commemorative meetings in Aalen. Their traditional costumes are stored in the Old Town Hall.\n\nAccording to the 2007 municipal poll by the Baden-Württemberg chapter of the German Taxpayers Federation, municipal tax revenues totalling to 54,755 million Euros (2006) resp. 62,148 million Euros (2007) face the following debts:\n\nThe town operates the “Theatre of the Town of Aalen” \"(Theater der Stadt Aalen)\". Having been founded in 1991 and featuring six salaried actors, it is the newest as well as the smallest civic theatre in Germany. In addition to regular plays, it also offers four theatre clubs for all age levels. During the 2008/2009 season, 400 performances of ten productions attracted more than 21,000 visitors.\n\nThe town endowed the \"Schubart Literary Award\" \"(Schubart-Literaturpreis)\" in 1955 in tribute to Christian Friedrich Daniel Schubart, who spent his childhood and youth in Aalen. It is one of the earliest literary awards in Baden-Württemberg and is awarded biennially to German-language writers whose work coincide with Schubart's \"liberal and enlightened reasoning\". It is compensated with 12,000 Euros.\n\nFounded in 1958, the \"Music School of the Town of Aalen\" today has about 1,500 students taught by 27 music instructors in 30 subjects. In 1977, a symphony orchestra was founde in Aalen, which today is called \"Aalener Sinfonieorchester\", and consists mostly of instructors and students of the music school. It performs three public concerts annually: The “New Year’s Concert” in January, the “Symphony Concert” in July and a “Christmas Concert” in December. Beyond that, music festivals regularly take place in Aalen, like the Aalen Jazzfest.\n\nThe Aalen volunteer fire department has had a marching band since 1952, whose roots date back to 1883. In 1959, the band received its first glockenspiel from TV host Peter Frankenfeld on the occasion of a TV appearance.\n\nA famous German rapper, designer and singer, that goes under the name of Cro, was born in Aalen and lived his early years here.\n\nIn the central district of Aalen, there are two museums: The “Aalen Limes Museum\" \"(Limesmuseum Aalen)\" is located at the place of the largest Roman cavalry fort north of the Alps until about 200 AD. It opened in 1964. The museum exhibits numerous objects from the Roman era. The ruins of the cavalry fort located beside the museum is open to museum visitors. Every other year, a Roman festival is held in the area of the museum (see below).\n\nIn the Geological-Paleontological Museum located in the historic town hall, there are more than 1500 fossils from the Swabian Jura, including ammonites, ichthyosaurs and corals, displayed.\n\nIn the Waldhausen district the \"Heimatstüble\" museum of local history has an exhibition on agriculture and rural living.\n\nIn the Wasseralfingen district, there are two more museums: The \"Museum Wasseralfingen\" comprises a local history exhibition and an art gallery including works of Hermann Plock, Helmut Schuster and Sieger Köder. Also, the stove plate collection of the \"Schwäbische Hüttenwerke\" steel mill is exhibited, with artists, modellers and the production sequence of a cast plate from design to final product being presented.\n\nThere is memorial stone at the \"Schillerlinde\" tree above Wasseralfingen's ore pit dedicated to four prisoners of the subcamp of Natzweiler-Struthof concentration camp killed there. Also in Wasseralfingen, in the cemetery a memorial with the Polish inscription \"To the victims of Hitler\" which commemorates the deceased forced labourers buried there.\n\nIn 1954, on the \"Schillerhöhe\" hill the town erected a bell tower as a memorial to Aalen's victims of both world wars and to the displacement of ethnic Germans. The tower was planned by Emil Leo, the bell was endowed by Carl Schneider. The tower is open on request. Every evening at 18:45 (before 2003: at 19:45), the memorial's bell rings.\n\nThe town centre is dominated by the Evangelical-Lutheran St. Nicholas' Church in the heart of the pedestrian area. The church, in its present shape being built between 1765 and 1767, is the only major Late Baroque building in Aalen and is the main church of the Evangelical-Lutheran parish of Aalen.\n\n\"St. John's Church\" is located inside of St. John's cemetery in the western centre. The building presumably is from the 9th century and thus is one of Württemberg's oldest existing churches. The interior features frescos from the early 13th century.\n\nFor other churches in Aalen, see the Religions section.\n\nThe Historic Town Hall was originally built in the 14th century. After the fire of 1634, it was re-constructed in 1636. This building received a clock from Lauterburg, and the Imperial City of Nuremberg donated a Carillon. It features a figurine of the \"Spy of Aalen\" and historically displayed other figurines, however the latter ones were lost by a fire in 1884. Since then, the Spy resides inside the reconstructed tower and has become a symbol of the town. The building was used as the town hall until 1907. Since 1977, the Geological-Paleontological Museum resides in the Historic Town Hall.\n\nAccording to legend, the citizens of Aalen owe the \"Spy of Aalen\" \"(Spion von Aalen)\" their town having been spared from destruction by the emperor's army:\n\nThe Imperial City of Aalen once was were in quarrel with the emperor, and his army was shortly before the gates to take the town. The people of Aalen got scared and thus dispatched their “most cunning” one out into the enemy’s camp to spy out the strength of their troops. Without any digression, he went straight into the middle of the enemy camp, which inescapably led to him being seized and presented to the emperor. When the emperor asked him what he had lost here, he answered in Swabian German: \"Don't frighten, high lords, I just want to peek how many cannons and other war things you've got, since I am the spy of Aalen\". The emperor laughed upon such a blatancy and \"acted\" naïvety, steered him all through the camp and then sent him back home. Soon the emperor withdrew with his army as he thought a town such \"wise guys\" reside in deserved being spared.\n\nThe earliest record of the Old Town Hall was in 1575. Its outside wall features the oldest known coat of arms, which is of 1664. Until 1851, the building also housed the \"Krone-Post\" hotel, which coincided with being a station of the Thurn und Taxis postal company. It has housed many notable persons. Thus the so-called \"Napoleon Window\" with its \"N\" painted on reminds of the stay of French emperor Napoleon Bonaparte in 1805. According to legend, he rammed his head so hard it bled on this window, when he was startled by the noise of his soldiers ridiculing the \"Spy of Aalen\". The building was used as Aalen's town hall from 1907 until 1975. Today it houses a cabaret café and the stage of the Theatre of the Town of Aalen. The town has adopted the \"Wischau Linguistic Enclave Society\" due to their godparenthood and stores their traditional constumes in the building.\n\nThe \"Bürgerspital\" (\"Civic Asylum\") is a timber-frame house erected on \"Spritzenhausplatz\" (\"Fire Engine House Square\") in 1702. Until 1873, it was used as civic hospital, then, later as a retirement home. After a comprehensive renovation in 1980 it was turned into a senior citizen's community centre.\n\nOn a slope of the \"Langert\" mountain, south of the town, the \"Limes-Thermen\" (\"Limes Thermae\") hot springs are located. They were built in ancient Roman style and opened in 1985. The health spa is supplied with water about .\n\nThe market square is the historic hub of Aalen and runs along about from the town hall in the south to the Historic Town Hall and the Old Town Hall in the north, where it empties into \"Radgasse\" alley. Since 1809, it is site of the weekly market on Wednesday and Saturday. About in front of the \"Reichsstädter Brunnen\" fountain at the town hall, the coats of arms of Aalen, its twinned cities and of the Wischau linguistic enclave are paved into the street as mosaic.\n\nIn 1705, for the water supply of Aalen a well casing was erected at the northern point of the market square, in front of the Historic Town Hall. It was a present of duke Eberhard Louis. The fountain bore a statue of emperor Joseph I., who was enthroned in 1705 and in 1707 renewed Aalen's Imperial City privileges. The fountain was supplied via a wooden pipe. Excessive water was dissipated through ditches branched from Kocher river. When in the early 1870s Aalen's water network was constructed, the fountain was replaced by a smaller fountain about distant. In 1975, the old market fountain was re-erected in baroque style. It bears a replica of the emperor's statue, with the original statue exhibited in the new town hall's lobby. The cast iron casing plates depict the 1718 coat of arms of the Duchy of Württemberg and the coats of arms of Aalen and of the merged municipalities.\n\nThe \"Reichsstädter Brunnen\" fountain (\"Imperial Civic Fountain\") is located in front of the town hall at the southern point of the market square. It was created by sculptor Fritz Nuss in 1977 to commemorate Aalen's time as an Imperial City (1360–1803). On its circumference is a frieze showing bronze figurines illustrating the town's history.\n\nThe \"Radgasse\" (\"Wheel Alley\") features Aalen's oldest façade. Originally a small pond was on its side. The buildings were erected between 1659 and 1662 for peasants with citizenry privileges and renovated in the mid-1980s. The namesake for the alley was the \"Wheel\" tavern, which was to be found at the site of today's address \"Radgasse 15\".\n\nThe former iron ore pit \"Wilhelm\" at Braunenberg hill was converted into the \"Tiefer Stollen\" tourist mine in order to remind of the old-day miners' efforts and to maintain it as a memorial of early industrialisation in the Aalen area. It has a mining museum open for visitors, and a mine railway takes visitors deep into the mountain. The Town of Aalen, a sponsorship association, and many citizens volunteered several thousand hours of labour to put the mine into its current state. As far as possible, things were left in the original state. In 1989, a sanitary gallery was established where respiratory diseases are treated within rest cures. Thus the Aalen village of Röthard, where the gallery is located, was awarded the title of \"Place with sanitary gallery service\" in 2004.\n\nThe Aalen Observatory was built in 1969 as school observatory for the Schubart Gymnasium. In 2001, it was converted to a public observatory. Since then, it has been managed by the \"Astronomische Arbeitsgemeinschaft Aalen\" (\"Aalen Astronomical Society\"). It is located on Schillerhöhe hill and features two refractive telescopes. They were manufactured by Carl Zeiss AG which has its headquarters in nearby Oberkochen and operates a manufacturing works in Aalen (see below). In the observatory, guided tours and lectures are held regularly.\n\nThe \"Windpark Waldhausen\" wind farm began operations in early 2007. It consists of seven REpower MM92 wind turbines with a nameplate capacity of 2 MW each. The hub height of each wind turbine is , with a rotor diameter of .\n\nThe tall \"Aalbäumle\" observation tower is built atop \"Langert\" mountain. This popular hiking destination was built in 1898 and was remodelled in 1992. It features a good view over Aalen and the Welland region, up to the Rosenstein mountain and Ellwangen. Beneath the tower, an adventure playground and a cabin is located. A flag on the tower signals whether the cabin's restaurant is open.\n\nThe Baden-Württemberg State Institute for Environment, Measurements and Natural Conservation has laid out six protected landscapes in Aalen (the \"Swabian Jura escarpment between Lautern and Aalen with adjacent territories\", the \"Swabian Jura escarpment between Unterkochen and Baiershofen\", the \"Hilllands around Hofen\", the \"Kugeltal and Ebnater Tal valleys with parts of Heiligental valley and adjacent territories\", \"Laubachtal valley\" and \"Lower Lein Valley with side valleys\"), two sanctuary forests (\"Glashütte\" and \"Kocher Origin\"), 65 extensive natural monuments, 30 individual natural monuments and the following two protected areas:\n\nThe large \"Dellenhäule\" protected area between Aalen's Waldhausen district and Neresheim's Elchingen district, created in 1969, is a sheep pasture with juniper and wood pasture of old willow oaks.\n\nThe large \"Goldshöfer Sande\" protected area was established in 2000 and is situated between Aalen's Hofen district and Hüttlingen. The sands on the hill originated from the Early Pleistocene are of geological importance, and the various grove structures offer habitat to severely endangered bird species.\n\nThe football team, VfR Aalen, was founded in 1921 and played in the 2nd German League between 2012 and 2015, after which they were relegated to 3. Liga. Its playing venue is the Scholz-Arena situated in the west of the town, which bore the name \"Städtisches Waldstadion Aalen\" (\"Civic Forest Stadium of Aalen\") until 2008. From 1939 until 1945, the VfR played in the Gauliga Württemberg, then one of several parallel top-ranking soccer leagues of Germany.\n\nThe KSV Aalen wrestles in the Wrestling Federal League. It was German champion in team wrestling in 2010. Its predecessor, the \"KSV Germania Aalen\" disbanded in 2005, was German champion eight times and runner-up five times since 1976. Another Aalen club, the TSV Dewangen, wrestled in the Federal League until 2009.\n\nTwo American sports, American Football and Baseball, are pursued by the \"MTV Aalen\". Volleyball has been gaining in popularity in Aalen for years. The first men's team of \"DJK Aalen\" accomplished qualification for regional league in the season of 2008/09.\n\nThe \"Ostalb\" ski lifts are located south of the town centre, at the northern slope of the Swabian Jura. The skiing area comprises two platter lifts that have a vertical rise of , with two runs with lengths of and a beginners' run.\n\nSince 1975, \"Reichsstädter Tage\" (\"Imperial City days\") festival is held annually in the town centre on the second weekend in September. It is deemed the largest festival of the Ostwürttemberg region, and is associated with a shopping Sunday in accordance with the Ladenschlussgesetz code. The festival is also attended by delegations from the twinned cities. On the town hall square, on Sunday an ecumenical service is held.\n\nThe international Roman Festival \"(Römertage)\" are held biannially on the site of the former Roman fort and the modern Limes museum. The festival's ninth event in 2008 was attended by around 11,000 people.\n\nAnnually during the second week of November, the Aalen Jazz Festival brings known and unknown artists to Aalen. It has already featured musicians like Miles Davis, B. B. King, Ray Charles, David Murray, McCoy Tyner, Al Jarreau, Esbjörn Svensson and Albert Mangelsdorff. The festival is complemented by individual concerts in spring and summer, and, including the individual concerts, comprises around 25 concerts with a total of about 13,000 visitors.\n\nIn 2008 there were 30,008 employees liable to social insurance living in Aalen. 13,946 (46.5 percent) were employed in the manufacturing sector, 4,715 (15.7 percent) in commerce, catering, hotels and transport, and 11,306 (37.7 percent) in other services. Annually 16,000 employees commute to work, with about 9,000 living in the town and commuting out.\n\nAltogether in Aalen there are about 4,700 business enterprises, 1,100 of them being registered in the trade register. The others comprise 2,865 small enterprises and 701 craft enterprises.\n\nIn Aalen, metalworking is the predominant industry, along with machine-building. Other industries include optics, paper, information technology, chemicals, textiles, medical instruments, pharmaceuticals, and food.\n\nNotable enterprises include \"SHW Automotive\" (originating from the former \"Schwäbische Hüttenwerke\" steel mills and a mill of 1671 in Wasseralfingen), the \"Alfing Kessler\" engineering works, the precision tools manufacturer \"MAPAL Dr. Kress\", the snow chain manufacturer \"RUD Ketten Rieger & Dietz\" and its subsidiary \"Erlau\", the \"Gesenkschmiede Schneider\" forging die smithery, the \"SDZ Druck und Medien\" media company, the \"Papierfabrik Palm\" paper mill, the alarm system manufacturer \"Telenot\", the laser show provider \"LOBO electronic\" and the textile finisher \"Lindenfarb\", which all have their seat in Aalen. A branch in Aalen is maintained by optical systems manufacturer Carl Zeiss headquartered in nearby Oberkochen.\n\nAalen station is a regional railway hub on the Rems Railway from Stuttgart, the Brenz Railway from Ulm, the Upper Jagst Railway to Crailsheim and the Ries Railway to Donauwörth. Until 1972, the Härtsfeld Railway connected Aalen with Dillingen an der Donau via Neresheim. Other railway stations within the town limits are \"Hofen (b Aalen)\", \"Unterkochen\", \"Wasseralfingen\" and Goldshöfe station. The \"Aalen-Erlau\" stop situated in the south is no longer operational.\n\nAalen station is served at two-hour intervals by trains of Intercity line 61 Karlsruhe–Stuttgart–Aalen–Nuremberg. For regional rail travel, Aalen is served by various lines of the Interregio-Express, Regional-Express and Regionalbahn categories. The town also operates the Aalen industrial railway \"(Industriebahn Aalen)\", which carries about 250 carloads per year.\n\nThe junctions of \"Aalen/Westhausen\" and \"Aalen/Oberkochen\" connect Aalen with the Autobahn A7 (Würzburg–Füssen). Federal roads (\"Bundesstraßen\") connecting with Aalen are B 19 (Würzburg–Ulm), B 29 (Waiblingen–Nördlingen) and B 290 (Tauberbischofsheim–Westhausen). The Schwäbische Dichterstraße (\"Swabian Poets' Route\") tourist route established in 1977/78 leads through Aalen.\n\nSeveral bus lines operate within the borough. The \"Omnibus-Verkehr Aalen\" company is one of the few in Germany that use double-decker buses, it has done so since 1966. A district-wide fare system, \"OstalbMobil\", has been in effect since 2007.\n\nStuttgart Airport, offering international connections, is about away, the travel time by train is about 100 Minutes. At Aalen-Heidenheim Airport, located south-east of Aalen, small aircraft are permitted. Gliding airfields nearby are in Heubach and Bartholomä.\n\nBicycle routes stretching through Aalen are the \"Deutscher Limes-Radweg\" (\"German Limes Bicycle Route\") and the \"Kocher-Jagst\" Bicycle Route.\n\nAalen houses an Amtsgericht (local district court), chambers of the Stuttgart Labour Court, a notary's office, a tax office and an employment agency. It is the seat of the Ostalbkreis district office, of the Aalen Deanery of the Evangelical-Lutheran Church and of the \"Ostalb\" deanery of the Roman Catholic Diocese of Rottenburg-Stuttgart.\n\nThe Stuttgart administrative court, the Stuttgart Labour Court and the Ulm Social Welfare Court are in charge for Aalen.\n\nAalen had a civic hospital, which resided in the \"Bürgerspital\" building until 1873, then in a building at \"Alte Heidenheimer Straße\". In 1942, the hospital was taken over by the district. The district hospital at the present site of \"Kälblesrain\", known today as \"Ostalb-Klinikum\", was opened in 1955.\n\nThe first local newspaper, \"Der Bote von Aalen\" (\"The Herald of Aalen\"), has been published on Wednesdays and Saturdays since 1837.\n\nCurrently, local newspapers published in Aalen are the \"Schwäbische Post\", which obtains its supra-regional pages from the Ulm-based Südwestpresse, and the \"Aalener Nachrichten\" (erstwhile \"Aalener Volkszeitung\"), a local edition of Schwäbische Zeitung in Leutkirch im Allgäu.\n\nTwo of Germany's biggest Lesezirkels (magazine rental services) are headquartered in Aalen: \"Brabandt LZ Plus Media\" and \"Lesezirkel Portal\".\n\nRegional event magazines are \"Xaver\", \"åla\", \"ålakultur\".\n\nThe commercial broadcasters \"Radio Ton\" and \"Radio 7\" have studios in Aalen.\n\nA Latin school was first recorded in Aalen in 1447; it was remodeled in 1616 and also later in various buildings that were all situated near the town church, and continued up through the 19th century. In the course of the reformation, a \"German school\" was established in tandem, being a predecessor of the latter Volksschule school type. In 1860, the \"Ritterschule\" was built as a \"Volksschule\" for girls; the building today houses the \"Pestalozzischule\". In 1866, a new building was erected for the Latin school and for the Realschule established in 1840. This building, later known as the \"Alte Gewerbeschule\", was torn down in 1975 to free up land for the new town hall. In 1912, the \"Parkschule\" building was opened. It was designed by Paul Bonatz and today houses the \"Schubart-Gymnasium\"\n\nThe biggest educational institution in the town is the \"Hochschule Aalen\", which was founded in 1962 and focuses on engineering and economics. It is attended by 5000 students on five campuses and employs 129 professors and 130 other lecturers.\n\nThe town provides three Gymnasiums, four Realschulen, two \"Förderschulen\" (special schools), six combined Grundschulen and Hauptschulen and eight standalone Grundschulen. The Ostalbkreis district provides three vocational schools and three additional special schools. Finally, six non-state schools of various types exist.\n\nThe German Esperanto Library (German: \"Deutsche Esperanto-Bibliothek\", Esperanto: \"Germana Esperanto-Biblioteko\") has been located in the building of the town library since 1989.\n\nThe Südwestrundfunk broadcasting company operates the Aalen transmission tower on the \"Braunenberg\" hill. The tower was erected in 1956, it is tall and made of reinforced concrete.\n\nThe following vehicles are named \"Aalen\":\n\n\n\n\n\n\n\n", "id": "2382", "title": "Aalen"}
{"url": "https://en.wikipedia.org/wiki?curid=2383", "text": "Alois Alzheimer\n\nDr. Aloysius \"Alois\" Alzheimer (; 14 June 1864 – 19 December 1915) was a German psychiatrist and neuropathologist and a colleague of Emil Kraepelin. Alzheimer is credited with identifying the first published case of \"presenile dementia\", which Kraepelin would later identify as Alzheimer's disease.\n\nAloysius Alzheimer was born in Marktbreit, Bavaria on 14 June 1864. His father served in the office of notary public in the family's hometown. The Alzheimers moved when Alois was still young in order to give their children an opportunity to attend the Royal Humanistic Gymnasium. Later, Alois would study medicine in Aschaffenburg, Tübingen, Berlin, and Würzburg Universities. His college years were fairly typical; in his final year of school Alois was on the fencing team and a member of a fraternity, and even received a fine for disturbing the peace while out with his team. In April 1884, he married Cecille Simonette Nathalie Geisenheimer, with whom he had three children. Cecille died in 1901. In 1887, Alois Alzheimer graduated from Würzburg with a degree in medicine.\n\nThe following year, he spent five months assisting mentally ill women before he took an office in the city mental asylum in Frankfurt am Main, the Städtische Anstalt für Irre und Epileptische (Asylum for Lunatics and Epileptics). , a noted psychiatrist, was the dean of the asylum. Another neurologist, Franz Nissl, began to work in the same asylum with Alzheimer. Together, they conducted research on the pathology of the nervous system, specifically the normal and pathological anatomy of the cerebral cortex. Alzheimer was the co-founder and co-publisher of the journal \"Zeitschrift für die gesamte Neurologie und Psychiatrie\", though he never wrote a book that he could call his own.\n\nWhile at the Frankfurt asylum, Alzheimer also met Emil Kraepelin, one of the best-known German psychiatrists of the time. Kraepelin became a mentor to Alzheimer, and the two worked very closely for the next several years. When Kraepelin moved to Munich to work at the Royal Psychiatric Hospital in 1903, he invited Alzheimer to join him. At the time, Kraepelin was doing clinical research on psychosis in senile patients; Alzheimer, on the other hand, was more interested in the lab work of senile illnesses. The two men would face many challenges involving the politics of the psychiatric community. For example, both formal and informal arrangements would be made among psychiatrists at asylums and universities to receive cadavers. In 1908 he was a professor at the Ludwig Maximilian University and the Neurological and Psychiatric Clinic of the Friedrich-Wilhelm University from 1912 until he fell ill.\n\nIn 1901, Dr. Alzheimer observed a patient at the Frankfurt Asylum named Auguste Deter. The 51-year-old patient had strange behavioral symptoms, including a loss of short-term memory; she became his obsession over the coming years. Auguste Deter was a victim of the politics of the time in the psychiatric community; the Frankfurt asylum was too expensive for her husband. Mr. Deter made several requests to have his wife moved to a less expensive facility, but Dr. Alzheimer intervened in these requests. Ms. Deter remained at the Frankfurt asylum, where Alzheimer had made a deal to receive her records and brain upon her death. On 8April 1906, Ms. Deter died, and Dr. Alzheimer had her medical records and brain brought to Munich where he was working in Kraepelin's laboratory. With two Italian physicians, he used the staining techniques of Bielschowsky to identify amyloid plaques and neurofibrillary tangles. These brain anomalies would become identifiers of what later became known as Alzheimer's Disease.\n\nAlzheimer discussed his findings on the brain pathology and symptoms of presenile dementia publicly on 3November 1906, at the Tübingen meeting of the Southwest German Psychiatrists. The attendees at this lecture seemed uninterested in what he had to say. The lecturer that followed Alzheimer was to speak on the topic of \"compulsive masturbation\", which the audience was so eagerly awaiting that they sent Alzheimer away without any questions or comments on his discovery of the pathology of a type of senile dementia. Following the lecture, Alzheimer published a short paper summarizing his lecture; in 1907 he wrote a larger paper detailing the disease and his findings. The disease would not become known as Alzheimer's disease until 1910, when Kraepelin named it so in the chapter on \"Presenile and Senile Dementia\" in the 8th edition of his \"Handbook of Psychiatry\". By 1911, his description of the disease was being used by European physicians to diagnose patients in the US.\n\nAmerican Solomon Carter Fuller gave a report similar to that of Alzheimer at a lecture five months before Alzheimer. Oskar Fischer was a fellow German psychiatrist, 12 years Alzheimer's junior, who reported 12 cases of senile dementia in 1907 around the time that Alzheimer published his short paper summarizing his lecture. The two men had different interpretations of the disease, but due to Alzheimer's short life, they never had the opportunity to meet and discuss their ideas.\n\nIn August 1912, Dr. Alzheimer fell ill on the train on his way to the University of Breslau, where he had been appointed professor of psychiatry in July 1912. Most probably he had a streptococcal infection and subsequent rheumatic fever leading to valvular heart disease, heart failure and kidney failure. He never recovered completely from this illness. He died of heart failure on 19December 1915, at the age of 51 in Breslau, Silesia (present-day Wrocław, Poland). He was buried on 23December 1915 next to his wife in the Hauptfriedhof in Frankfurt am Main.\n\nIn the early 1990s, critics began to question Alzheimer's findings and form their own hypotheses based on Alzheimer's notes and papers. Amaducci and colleagues hypothesized that Auguste Deter had metachromatic leukodystrophy, a rare condition in which accumulations of fats affect the cells that produce myelin. Another hypothesis offered by Claire O'Brien was that Auguste Deter actually had a vascular dementing disease. Through extremely fortunate circumstances the original microscope preparations on which Alzheimer based his description of the disease were rediscovered in 1998 in Munich, and his findings could thus be reevaluated. The slides confirmed that Auguste Deter did in fact have what is now known as Alzheimer's Disease.\n\nAlzheimer was known for having a variety of medical interests including vascular diseases of the brain, early dementia, brain tumors, forensic psychiatry and epilepsy. Alois Alzheimer was also a leading specialist in histopathology in Europe. His colleagues knew him to be a dedicated professor and cigar smoker.\n\n\n", "id": "2383", "title": "Alois Alzheimer"}
{"url": "https://en.wikipedia.org/wiki?curid=2384", "text": "Aedile\n\nAedile ( , from \"aedes,\" \"temple building\") was an office of the Roman Republic. Based in Rome, the aediles were responsible for maintenance of public buildings (\"aedēs\") and regulation of public festivals. They also had powers to enforce public order.\n\nThere were two pairs of aediles: the first were the \"plebeian aediles\" (Latin \"aediles plebis\") and possession of this office was limited to plebeians; the other two were \"curule aediles\" (Latin \"aediles curules\"), open to both plebeians and patricians, in alternating years. An \"aedilis curulis\" was classified as a \"magister curulis\".\n\nThe office of the aedilis was generally held by young men intending to follow the cursus honorum to high political office, traditionally after their quaestorship but before their praetorship. It was not a compulsory part of the cursus, and hence a former quaestor could be elected to the praetorship without having held the position of aedile. However, it was an advantageous position to hold because it demonstrated the aspiring politician's commitment to public service, as well as giving him the opportunity to hold public festivals and games, an excellent way to increase his name recognition and popularity.\n\nThe plebeian aediles were created in the same year as the Tribunes of the People (494 BC). Originally intended as assistants to the tribunes, they guarded the rights of the plebs with respect to their headquarters, the Temple of Ceres. Subsequently, they assumed responsibility for maintenance of the city's buildings as a whole. Their duties at first were simply ministerial. They were the assistants to the tribunes in whatever matters that the tribunes might entrust to them, although most matters with which they were entrusted were of minimal importance. Around 446 BC, they were given the authority to care for the decrees of the senate (\"senatus consulta\"). When a \"senatus consultum\" was passed, it would be transcribed into a document, and deposited in the public treasury, the \"Aerarium\". They were given this power because the Roman Consuls, who had held this power before, arbitrarily suppressed and altered the documents. They also maintained the acts of the Plebeian Council (popular assembly), the \"plebiscites\". Plebiscites, once passed, were also transcribed into a physical document for storage. While their powers grew over time, it is not always easy to distinguish the difference between their powers, and those of the Roman Censors. Occasionally, if a Censor was unable to carry out one of his tasks, an Aedile would perform the task instead.\n\nAccording to Livy (vi. 42), after the passing of the Licinian rogations in 367 BC, an extra day was added to the Roman games; the plebeian aediles refused to bear the additional expense, whereupon the patricians offered to undertake it, on condition that they were admitted to the aedileship. The plebeians accepted the offer, and accordingly two \"curule\" aediles were appointed—at first from the patricians alone, then from patricians and plebeians in turn, lastly, from either—at the Tribal Assembly under the presidency of the consul. Curule Aediles, as formal magistrates, held certain honors that Plebeian Aediles (who were not technically magistrates), did not hold. Besides having the right to sit on a Curule Chair (\"sella curulis\") and to wear a toga praetexta, the Curule Aediles also held the power to issue edicts (\"jus edicendi\"). These edicts often pertained to matters such as the regulation of the public markets, or what we might call \"economic regulation\". Livy suggests, perhaps incorrectly, that both Curule as well as Plebeian Aediles were sacrosanct. Although the curule aediles always ranked higher than the plebeian, their functions gradually approximated and became practically identical. Within five days after the beginning of their terms, the four Aediles (two Plebeian, two Curule) were required to determine, by lot or by agreement among themselves, what parts of the city each should hold jurisdiction over.\n\nThere was a distinction between the two sets of Aediles when it came to public festivals. Some festivals were Plebeian in nature, and thus were under the superintendence of Plebeian Aediles. Other festivals were supervised exclusively by the Curule Aediles, and it was often with these festivals that the Aediles would spend lavishly. This was often done so as to secure the support of voters in future elections. Because Aediles were not reimbursed for any of their public expenditures, most individuals who sought the office were independently wealthy. Since this office was a stepping stone to higher office and the Senate, it helped to ensure that only wealthy individuals (mostly landowners) would win election to high office. These extravagant expenditures began shortly after the end of Second Punic War, and increased as the spoils returned from Rome's new eastern conquests. Even the decadence of the emperors rarely surpassed that of the Aediles under the Republic, as could have been seen during Julius Caesar's Aedileship.\n\nPlebeian Aediles were elected by the Plebeian Council (popular assembly), usually while under the presidency of a Plebeian Tribune. Curule Aediles were elected by the Tribal Assembly, usually while under the presidency of a Roman Consul. Since the Plebeian Aediles were elected by the Plebeians (commoners), rather than by all of the People of Rome (Plebeians as well as members of the Patrician aristocracy), they were not technically magistrates. Before the passage of the \"lex annalis\", individuals could run for the Aedileship by the time they turned twenty-seven. After the passage of this law in 180 BC, a higher age was set, probably thirty-five. By the 1st century BC, Aediles were elected in July, and took office on the first day in January.\n\nCicero (Legg. iii. 3, 7) divides these functions under three heads:\n\n(1) Care of the city:\nthe repair and preservation of temples, sewers and aqueducts; street cleansing and paving; regulations regarding traffic, dangerous animals and dilapidated buildings; precautions against fire; superintendence of baths and taverns; enforcement of sumptuary laws; punishment of gamblers and usurers; the care of public morals generally, including the prevention of foreign superstitions and the registration of meretrices. They also punished those who had too large a share of the ager publicus, or kept too many cattle on the state pastures.\n\n(2) Care of provisions:\ninvestigation of the quality of the articles supplied and the correctness of weights and measures; the purchase of grain for disposal at a low price in case of necessity.\n\n(3) Care of the games: \nsuperintendence and organization of the public games, as well as of those given by themselves and private individuals (e.g. at funerals) at their own expense. \nAmbitious persons often spent enormous sums in this manner to win the popular favor with a view to official advancement.\n\nIn 44 BC Julius Caesar added two plebeian aediles, called \"Cereales\", whose special duty was the care of the cereal (grain) supply. Under Augustus the office lost much of its importance, its judicial functions and the care of the games being transferred to the praetor, while its city responsibilities were limited by the appointment of a praefectus urbi. Augustus took for himself its powers over various religious duties. By stripping it of its powers over temples, Augustus effectively destroyed the office, by taking from it its original function. After this point, few people were willing to hold such a powerless office, and Augustus was even known to compel individuals into holding the office. Augustus accomplished this by randomly selecting former tribunes and quaestors for the office. Future emperors would continue to dilute the power of the office by transferring its powers to newly created offices. However, the office did retain some powers over licentiousness and disorder, in particular over the baths and brothels, as well as the registration of prostitutes. In the 3rd century, it disappeared altogether.\n\nUnder the Empire, Roman colonies and cities often had officials with powers similar to those of the republican aediles, although their powers widely varied. It seems as though they were usually chosen annually. Today in Portugal the county mayor can still be referred to as 'edil' (e.g. 'O edil de Coimbra', meaning 'the mayor of Coimbra'), a way of reference used also in Romania for any mayors (ex. \"Edil al Bucureștiului\", meaning „mayor of Bucharest”). In Spain (and Latin America) the members of municipal councils are called concejales or ediles.\n\nIn his play \"Coriolanus\", Shakespeare references the aediles. However, they are minor characters, and their chief role is to serve as policemen.\n\n", "id": "2384", "title": "Aedile"}
{"url": "https://en.wikipedia.org/wiki?curid=2386", "text": "American Airlines\n\nAmerican Airlines, Inc. (AA), commonly referred to as American, is a major American airline headquartered in Fort Worth, Texas. It is the world's largest airline when measured by fleet size, revenue, scheduled passenger-kilometres flown, and number of destinations served. American together with its regional partners operates an extensive international and domestic network with an average of nearly 6,700 flights per day to nearly 350 destinations in more than 50 countries.\n\nAmerican Airlines is a founding member of Oneworld alliance, the third largest airline alliance in the world and coordinates fares, services, and scheduling with alliance partners British Airways, Iberia, and Finnair in the transatlantic market and with Cathay Pacific and Japan Airlines in the transpacific market. Regional service is operated by independent and subsidiary carriers under the brand name of American Eagle.\n\nAmerican operates out of ten hubs located in Dallas/Fort Worth, Charlotte, Chicago-O'Hare, Philadelphia, Miami, Phoenix, Washington, DC-National, Los Angeles, New York-JFK, and New York-LaGuardia. American operates its primary maintenance base at Tulsa International Airport in addition to the maintenance locations located at its hubs. Dallas/Fort Worth International Airport is American's largest passenger carrying hub handling 51.1 million passengers annually with an average of 140,000 passengers daily. The company as of 2015 employs over 113,300 people. Through the airline's parent company, American Airlines Group, it is publicly traded under NASDAQ: AAL with a market capitalization of over $40.99 billion as of 2015.\n\nAmerican Airlines was started in 1930 via a union of more than eighty small airlines.\n\nThe two organizations from which American Airlines was originated were Robertson Aircraft Corporation and Colonial Air Transport. The former was first formed in Missouri in 1921, with both being merged in 1929 into holding company The Aviation Corporation. This in turn, was made in 1930 into an operating company and rebranded as American Airways. In 1934, when new laws and attrition of mail contracts forced many airlines to reorganize, the corporation redid its routes into a connected system, and was renamed American Airlines. Between 1970 and 2000, the company grew into being an international carrier, purchasing Trans World Airlines in 2001.\n\nIn 2011, due to a downturn in the airline industry, American Airlines' parent company AMR Corporation filed for bankruptcy protection. In 2013, US Airways and American Airlines merged. Eventually operations were merged under one operating certificate to create the largest United States airline which kept the American Airlines brand name.\n\nAmerican Airlines is headquartered in Fort Worth, Texas, adjacent to the Dallas/Fort Worth International Airport. The headquarters is located in two office buildings in the CentrePort office complex and these buildings together have about of space. over 4,300 employees work at this complex.\n\nBefore it was headquartered in Texas, American Airlines was headquartered at 633 Third Avenue in the Murray Hill area of Midtown Manhattan, New York City. In 1979 American moved its headquarters to a site at Dallas/Fort Worth International Airport, which affected up to 1,300 jobs. Mayor of New York City Ed Koch described the move as a \"betrayal\" of New York City. American moved to two leased office buildings in Grand Prairie, Texas. On January 17, 1983, the airline finished moving into a $150 million ($ when adjusted for inflation), facility in Fort Worth; $147 million (about $ when adjusted for inflation) in Dallas/Fort Worth International Airport bonds financed the headquarters. The airline began leasing the facility from the airport, which owns the facility.\n\nAs of 2015 American Airlines is the corporation with the largest presence in Fort Worth.\n\nIn 2015 the airline announced it will build a new headquarters in Fort Worth. Groundbreaking began in the spring of 2016 and occupancy is scheduled for summer 2019. The airline plans to house 5,000 new workers in the building.\n\nIt will be located on a property adjacent to the airline's flight academy and conference and training center, west of Texas State Highway 360, west from the current headquarters. The airline will lease a total of from Dallas-Fort Worth International Airport and this area will include the headquarters.Construction of the new headquarters is scheduled to occur after the demolition of the Sabre facility.\n\nThe airline considered developing a new headquarters in Irving, on the Texas Stadium site, before deciding to keep the headquarters in Fort Worth.\n\nAs of November 2013 American Airlines and American Eagle received $10,011,836 in annual federal subsidies for Essential Air Services. These subsidies are awarded by public tender and ensure that small, rural airports can be connected to the national air network.\n\n\nViolations occurring over a 4½ year period—from October 1993 to July 1998—targeted American Airlines for using high-sulfur fuel in motor vehicles at 10 major airports around the country. Under the federal Clean Air Act high sulfur fuel cannot be used in motor vehicles. American Airlines promptly identified and corrected these violations of the Clean Air Act.\n\nAmerican Airlines' wastewater treatment plant recycles water used at the base to wash aircraft, process rinse water tanks, and irrigate landscape. That alone has saved almost $1 million since 2002. In addition to that, American Airlines has also won the award for the reduction of hazardous waste that saved them $229,000 after a $2,000 investment. A bar code system is used to track hazardous waste. It has led to reduction of waste by 50 percent since 2000.\n\nAmerican Airlines is title sponsor of two basketball venues: American Airlines Center (Dallas Mavericks) and American Airlines Arena (Miami Heat).\n\nThe company sponsors several professional sports teams:\n\nIn 1931, Goodrich Murphy, an American employee, designed the AA logo. The logo was redesigned by Massimo Vignelli in 1967. Thirty years later, in 1997, American Airlines was able to make its logo Internet-compatible by buying the domain AA.com. \"AA\" is also American's two-letter IATA airline designator.\n\nOn January 16, 2013, American launched a new rebranding and marketing campaign with FutureBrand dubbed, \"A New American\". This included a new logo replacing the logo used since 1967. American Airlines calls the new logo the \"Flight Symbol\", incorporating the eagle, star, and \"A\" of the classic logo.\n\nAmerican's early liveries varied widely, but a common livery was adopted in the 1930s, featuring an eagle painted on the fuselage. The eagle became a symbol of the company and inspired the name of American Eagle Airlines. Propeller aircraft featured an international orange lightning bolt running down the length of the fuselage, which was replaced by a simpler orange stripe with the introduction of jets.\n\nIn the late 1960s, American commissioned designer Massimo Vignelli to develop a new livery. The original design called for a red, white, and blue stripe on the fuselage, and a simple \"AA\" logo, without an eagle, on the tail; instead, Vignelli created a highly stylized eagle, which remained the company's logo until 2013. In 1999, American painted a new Boeing 757 (N679AN) in its 1959 international orange livery. One Boeing 777 and one Boeing 757 were painted in standard livery with a pink ribbon on the sides and on the tail, in support of Susan G. Komen for the Cure. One Boeing 757 is painted with a yellow ribbon on the tailfin on the aircraft and on the side of the body says \"Flagship Freedom\". American Eagle, the airline's regional airline has the same special livery on ERJ-145 aircraft.\nOn January 17, 2013, American unveiled a new livery. Before then, American had been the only major U.S. airline to leave most of its aircraft surfaces unpainted. This was because C. R. Smith hated painted aircraft, and refused to use any liveries that involved painting the entire plane. Robert \"Bob\" Crandall later justified the distinctive natural metal finish by noting that less paint reduced the aircraft's weight, thus saving on fuel costs.\n\nIn January 2013, American launched a new rebranding and marketing campaign dubbed, \"The New American\". In addition to a new logo, American Airlines introduced a new livery for its fleet. The airline calls the new livery and branding \"a clean and modern update\". The current design features an abstract American flag on the tail, along with a silver-painted fuselage, as a throw-back to the old livery. The new design was painted by Leading Edge Aviation Services in California. Doug Parker, the incoming CEO indicated that the new livery could be short-lived, stating that \"maybe we need to do something slightly different than that ... The only reason this is an issue now is because they just did it right in the middle, which kind of makes it confusing, so that gives us an opportunity, actually, to decide if we are going to do something different because we have so many airplanes to paint\".\n\nIn the end, American let its employees decide the new livery's fate. On an internal website for employees, American posted two options, one the new livery and one a modified version of the old livery. All of the American Airlines Group employees (including US Airways and other affiliates) were able to vote. American ultimately decided to keep the new look. Parker announced that American would keep a US Airways heritage aircraft in the fleet, with plans to add a heritage TWA aircraft and a heritage American plane with the old livery.\n\n\nAmerican currently operates ten hubs across the continental U.S.\n\n\n\nAmerican operated interchange flight services in conjunction with Alaska Airlines during the 1970s between Texas and Alaska during the construction of the Trans-Alaska oil pipeline. This interchange agreement allowed for single, no change of aircraft service between Houston, Texas and Dallas/Fort Worth, Texas, and Anchorage, Alaska and Fairbanks, Alaska. The round trip routing of this interchange flight was Houston-Dallas/Fort Worth-Seattle-Anchorage-Fairbanks with Seattle, Washington serving as the interchange point where flight and cabin crews were changed from one airline to the other. Boeing 727-200 jetliners provided by both American and Alaska Airlines were utilized to provide this interchange service.\n\nAmerican Airlines codeshares with the following airlines:\n\nIn particular, American has joint ventures with British Airways, Iberia, and Finnair on transatlantic routes and with Japan Airlines and Qantas on transpacific routes.\n\nAs of February 2017, American Airlines operates a fleet of 939 aircraft, making it the largest commercial fleet in the world. It operates a mix of Airbus, Boeing, Embraer, and McDonnell Douglas aircraft.\n\nOver two thirds of American's aircraft are narrow-bodies, mainly Airbus A320 series and Boeing 737-800. It also operates Boeing 757, Embraer 190 and McDonnell Douglas MD-82/83, but most of them are planned to be phased out within five years.\n\nIts wide-body aircraft are mainly Boeing airliners. It is the third-largest operator of the Boeing 767 series and the fifth-largest operator of the Boeing 777 series. It also operates the Boeing 787 and the Airbus A330.\n\nThe Flagship Suite is American's international first class product. The newest version is exclusively offered on all Boeing 777-300ERs in the fleet. The older version is offered on some Boeing 777-200s.\n\n• Boeing 777-300ER: Fully lie-flat seats with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat length: 82 inches (208 cm). Equipped with a 17 inch (43 cm) touchscreen monitor and touchscreen handset, two universal AC power outlets, and USB ports.\n\n• Boeing 777-200ER Pre-Retrofit: Fully lie-flat seats with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat Length: 82 inches (208 cm). Equipped with an 8.4 inch (21 cm) touchscreen monitor, and one DC power outlet. These seats are currently in the process of being replaced.\n\nAmenities Include:\n\n• Flagship check-in privileges\n\n• 3 complimentary checked bags\n\n• Access to the Flagship Lounge (International First Class Lounge while the Flagship Lounges are being refurbished)\n\n• Early boarding\n\n• First Class amenity kit\n\n• Turndown service with pajamas\n\n• A pair of Bose QuietComfort Acoustic Noise Canceling Headsets to use during flight\n\n• Inflight wine tasting\n\n• Premium alcoholic beverages and wine selections (including pre-departure champagne service)\n\n• Chef-inspired dining options\n\n• Access to the premium cabin walk-up bar, which features assorted snacks and beverages throughout the duration of the flight.\n\n• Airbus A330: Fully lie-flat Cirrus seats manufactured by Zodiac Seats France and designed by JPA Design with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat length: 76-80 inches (193–203 cm). Equipped with a 12.1 inch (31 cm) touchscreen monitor, one universal AC power outlet, and USB ports.[1]\n\n• Boeing 777-300ER: Fully lie-flat Cirrus seats manufactured by Zodiac Seats UK, designed by JPA Design, and licensed from Cathay Pacific with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat length: 76-80 inches (193–203 cm). Equipped with a 15.4 (39 cm) inch touchscreen monitor, one universal AC power outlet, and USB ports.[2]\n\n• Boeing 787-8: Fully lie-flat seats manufactured by Zodiac Seats France and designed for American Airlines with direct aisle access in a 1-2-1 reverse herringbone configuration with front-facing and rear-facing seats. Seat length: 77 inches (196cm). Equipped with a 16 inch (41 cm) touchscreen monitor and touchscreen handset, two universal AC power outlets, and USB ports.\n\n• Boeing 777-200ER Post-Retrofit (Version 1): Fully lie-flat seats manufactured by Zodiac Seats France, designed for American Airlines, with direct aisle access in a 1-2-1 reverse herringbone configuration with front-facing and rear-facing seats. Seat length: 77 inches (196cm). Equipped with a 16 inch (41 cm) touchscreen monitor and touchscreen handset, two universal AC power outlets, and USB ports.\n\n• Boeing 777-200ER Post-Retrofit (Version 2): Fully lie-flat Super Diamond seats manufactured by B/E Aerospace and designed for American Airlines with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat length: 77 inches (196cm). Equipped with a BLANK touchscreen monitor and touchscreen handset, one universal AC power outlet, and USB ports.\n\n• Boeing 777-200ER Pre-Retrofit: Angled lie-flat seats manufactured by Recaro in a 2-3-2 configuration. Seat length: 58-61 inches (147–155 cm). Equipped with a 10.6 inch touchscreen and a DC power outlet. These seats are currently in the process of being replaced.[3]\n\n• Boeing 767-300ER Post-Retrofit: Fully lie-flat seats designed by Thompson Aero Seating with direct aisle access in a 1-2-1 staggered configuration. Equipped with Samsung Galaxy Tab™ 10.1 inch (26 cm) tablets, two universal AC power outlets (one to power the tablet), and USB ports.\n\n• Boeing 767-300ER Pre-Retrofit: Angled lie-flat seats manufactured by Recaro in a 2-2-2 configuration. Seat length: 58-61 inches (147–155 cm). Equipped with Samsung Galaxy Tab™ 10.1 inch (26 cm) tablets, and two DC power outlets (one to power the tablet).These seats are currently in the process of being replaced.[5]\n\n• Boeing 757-200 Post-Retrofit: Fully lie-flat Diamond seats manufactured by B/E Aerospace and designed for American Airlines in a 2-2 configuration. Seat length: 75–78 inches (191–198cm). Equipped with Samsung Galaxy Tab™ 10.1 inch (26 cm) tablets, and two universal AC power outlets (one to power the tablet).\n\n• Boeing 757-200 Pre-Retrofit (Version 1): Angled lie-flat seats manufactured by Recaro in a 2-2 configuration equipped on legacy American Airlines aircraft. Seat length: 58-61 inches (147–155 cm). Equipped with a 10.6 inch touchscreen and a DC power outlet. These seats are currently in the process of being replaced.\n\n• Boeing 757-200 Pre-Retrofit (Version 2): Recliner seats in 2-2 configuration equipped on legacy US Airways aircraft. Seat length: 60 inches (152 cm). Equipped with Samsung Galaxy Tab™ 10.1 inch (26 cm) tablets, and a DC power outlet. These seats are currently in the process of being replaced.\n\nAmenities Include:\n\n• Priority check-in privileges\n\n• 2 complimentary checked bags\n\n• Access to the Admirals Club\n\n• Early boarding\n\n• Business Class amenity kit\n\n• A pair of Bose QuietComfort Acoustic Noise Canceling Headsets to use during flight\n\n• Premium alcoholic beverages and wine selections (including pre-departure beverage service)\n\n• Chef-inspired dining options\n\n• Access to the premium cabin walk-up bar, which features assorted snacks and beverages throughout the duration of the flight (available on the Boeing 777-300ER, Boeing 777-200 Retrofit, Boeing 787-8, and Boeing 787-9)\n\n• On flights from Los Angeles to Hong Kong and Sydney and Dallas to Hong Kong, turndown service and pajamas are also provided\n\nAmerican has dedicated 17 Airbus A321s (A321T) in its fleet for the specific use of flying transcontinental routes between New York JFK–Los Angeles and New York JFK–San Francisco. These aircraft offer two premium cabins, First Class and Business Class, which are unique among domestic mainline aircraft in American's fleet:\n\n• First Class: Seats are arranged in a 1-1 reverse herringbone configuration offering direct aisle access. They are fully lie-flat, and come equipped with a 15.4 (39 cm) inch touchscreen monitor, universal AC power outlets, and USB ports. These seats are similar to the ones in the Business Class cabin on the Boeing 777-300ER. Transcontinental First Class passengers receive exclusive amenities such as Flagship check-in at New York JFK and LAX, and an amenity kit that is similar to the one given to international Business Class passengers.\n\n• Business Class: Fully lie-flat seats are set up in a 2-2 configuration. Equipped with a 15.4 inch (39 cm) touchscreen monitor, two universal AC power outlets, and two USB ports.\n\nAmenities offered to all Transcontinental premium cabin passengers include Admirals Club access, premium food and beverage options, and a pair of Bose QuietComfort Acoustic Noise Canceling Headsets.\n\nFirst Class is offered on all domestic mainline aircraft, as well as regional aircraft with more than 50 seats. When such aircraft are used on flights to international destinations including Canada, Mexico, Central America, and the Caribbean, the First Class cabin is branded as Business Class. Seats range from 19–21 inches (48–53 cm) in width and have 37–42 inches (94–106 cm) of pitch. Dining options include free snacks, beverages, and alcohol on all flights, with three-course meals offered on flights 900 miles (1,448 km) or longer (select routes under 900 miles offer meal service).\n\nOn December 9, 2015, American announced a new Premium Economy product for most long-haul widebody aircraft. This new product will debut on the new 787-9s in late 2016 and will be available on the new A350s in 2018. It will also be retrofitted to all other widebody aircraft within the next three years, excluding 767s due to their upcoming retirement. The seats will be wider than standard Main Cabin seats and will offer 38\" of pitch, 2\" more than Main Cabin Extra seats, as well as a footrest. Premium Economy customers will also get two free checked bags, priority boarding, and enhanced food and drink service including free alcohol. This product will make American Airlines the first U.S. carrier to offer a four-cabin aircraft.\n\nAmerican's economy plus product (not to be confused with premium economy), Main Cabin Extra, is available on most of the mainline fleet and American Eagle regional aircraft with more than 50 seats. Exceptions include a majority of former US Airways aircraft (as of May 2015), US Airways Express regional aircraft, and a handful of 777-200ERs that have yet to be retrofitted. Seats range from 17.2–18.5 inches (44–47 cm) in width and have 34–38 inches (86–97 cm) of pitch, which is 4–6 more inches of pitch offered in regular economy seating. American will retain Main Cabin Extra when the new Premium Economy product enters service in late 2016.\n\nMain Cabin is American's economy product, and is found on all mainline and regional aircraft in its fleet. Seats range from 17–18.5 inches (43–47 cm) in width and have 30–32 inches (76–81 cm) of pitch. Newer aircraft, including all Boeing 777-300ER, refurbished Boeing 777-200ER's, all Boeing 787 Dreamliners, all Airbus A330s, all newly delivered Airbus A319s and Boeing 737s, and most newly delivered Airbus A321s, include seatback TVs, featuring AVOD in each seat.\n\nAmerican's basic economy product, Basic Economy, is available on select routes. It is American's lowest main cabin fare. Basic economy is located in main cabin, but comes with restrictions. These restrictions include assigned seat at check in, no access to overhead bins, no upgrades or refunds, and boarding in the last group.\n\nAmerican Airlines marketed increased legroom in economy class as \"More Room Throughout Coach\", also referred to as \"MRTC\" starting in February 2000. Two rows of economy class seats were removed on Boeing 737 and McDonnell Douglas MD-80 aircraft. Amid financial losses, this scheme was discontinued in 2004.\n\nThe Admirals Club was conceived by AA president C.R. Smith as a marketing promotion shortly after he was made an honorary Texas Ranger. Inspired by the Kentucky colonels and other honorary organizations, Smith decided to make particularly valued passengers \"admirals\" of the \"Flagship fleet\" (AA called its aircraft \"Flagships\" at the time). The list of Admirals included many celebrities, politicians, and other VIPs, as well as more \"ordinary\" customers who had been particularly loyal to the airline.\n\nThere was no physical Admirals Club until shortly after the opening of LaGuardia Airport. During the airport's construction, New York Mayor Fiorello LaGuardia had an upper-level lounge set aside for press conferences and business meetings. At one such press conference, he noted that the entire terminal was being offered for lease to airline tenants; after a reporter asked whether the lounge would be leased as well, LaGuardia replied that it would, and a vice president of AA immediately offered to lease the premises. The airline then procured a liquor license and began operating the lounge as the \"Admirals Club\" in 1939.\n\nThe second Admirals Club opened at Washington National Airport. Because it was illegal to sell alcohol in Virginia at the time, the club contained refrigerators for the use of its members, so they could store their own liquor at the airport. For many years, membership in the Admirals Club (and most other airline lounges) was by the airline's invitation. After a passenger sued for discrimination, the Club (and most other airline lounges) switched to a paid membership program.\n\nThough affiliated with the Admirals Club and staffed by many of the same employees, the Flagship Lounge is a separate lounge specifically designed for customers flying in First Class on transcontinental domestic flights and international flights, as well as AAdvantage Executive Platinum and Oneworld Emerald frequent flyers. Flagship Lounges are now available at four airports: Chicago-O'Hare, London-Heathrow, Los Angeles, and New York-JFK. American also previously offered a Flagship Lounge in Miami from 2000 to 2002, and again from 2009. It plans to open again in 2017.\n\n\n\n", "id": "2386", "title": "American Airlines"}
{"url": "https://en.wikipedia.org/wiki?curid=2388", "text": "Antidepressant\n\nAntidepressants are drugs used for the treatment of major depressive disorder and other conditions, including dysthymia, anxiety disorders, obsessive compulsive disorder, eating disorders, chronic pain, neuropathic pain and, in some cases, dysmenorrhoea, snoring, migraine, attention-deficit hyperactivity disorder (ADHD), addiction, dependence, and sleep disorders. They may be prescribed alone or in combination with other medications.\n\nThe most important classes of antidepressants are the selective serotonin reuptake inhibitors (SSRIs), serotonin–norepinephrine reuptake inhibitors (SNRIs), tricyclic antidepressants (TCAs), monoamine oxidase inhibitors (MAOIs), reversible monoamine oxidase A inhibitors (rMAO-A inhibitors), tetracyclic antidepressants (TeCAs), and noradrenergic and specific serotonergic antidepressant (NaSSAs). St John's wort is also used in the treatment of depression.\n\nOne theory regarding the cause of depression is that it is characterized by an overactive hypothalamic–pituitary–adrenal axis (HPA axis) that resembles the neuro-endocrine response to stress. These HPA axis abnormalities participate in the development of depressive symptoms, and antidepressants may serve to regulate HPA axis function.\n\nFor depression, the Hamilton Depression Rating Scale (HAM-D) is often used to measure the severity of depression. The maximum score for the 17-item HAM-D questionnaire is 52; the higher the score, the more severe the depression.\n\nThe UK National Institute for Health and Care Excellence (NICE) 2009 guidelines indicate that antidepressants should not be routinely used for the initial treatment of mild depression, because the risk-benefit ratio is poor. The guidelines recommend that antidepressant treatment should be considered for:\n\nThe guidelines further note that antidepressant treatment should be used in combination with psychosocial interventions in most cases, should be continued for at least six months to reduce the risk of relapse, and that SSRIs are typically better tolerated than other antidepressants.\n\nAmerican Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors that include severity of symptoms, co-existing disorders, prior treatment experience, and patient preference. Options may include pharmacotherapy, psychotherapy, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. Antidepressant medication is recommended as an initial treatment choice in people with mild, moderate, or severe major depression, and should be given to all patients with severe depression unless ECT is planned.\n\nConflicting results have arisen from studies analyzing the efficacy of antidepressants by comparisons to placebo in people with acute mild to moderate depression. Stronger evidence supports the usefulness of antidepressants in the treatment of depression that is chronic (dysthymia) or severe.\n\nResearchers Irving Kirsch and Thomas Moore have contested the pharmacological activity of antidepressants in the relief of depression, and state that the evidence is most consistent a role as active placebos. Their study consisted of a meta analysis incorporating data from both published studies and unpublished data obtained from the FDA via a Freedom of Information Act request. Overall, antidepressant pills worked 18% better than placebos, a statistically significant difference, but not one that is clinically significant. In a later publication, Kirsch concluded that the overall effect of new-generation antidepressant medication is below recommended criteria for clinical significance.\n\nAnother study focusing on paroxetine (Paxil) and imipramine found that antidepressant drugs were only slightly better than placebo in cases of mild or moderate depression they surveyed but offered \"substantial\" benefit in those with severe depression.\n\nIn 2014 the U.S. FDA published a systematic review of all antidepressant maintenance trials submitted to the agency between 1985 and 2012. The authors concluded that maintenance treatment reduced the risk of relapse by 52% compared to placebo, and that this effect was primarily due to recurrent depression in the placebo group rather than a drug withdrawal effect.\n\nA review commissioned by the National Institute for Health and Care Excellence concluded that there is strong evidence that SSRIs have greater efficacy than placebo on achieving a 50% reduction in depression scores in moderate and severe major depression, and that there is some evidence for a similar effect in mild depression. The treatment guidelines developed in conjunction with this review suggest that antidepressants should be considered in patients with moderate to severe depression and those with mild depression that is persistent or resistant to other treatment modalities.\n\nThe Cochrane Collaboration recently performed a systematic review of clinical trials of the tricyclic antidepressant amitriptyline. The study concluded that in spite of moderate evidence for publication bias, there is strong evidence that the efficacy of amitriptyline is superior to placebo.\n\nA 2015 systematic review of add-on therapies for treatment-resistant depression concluded that quetiapine and aripiprazole have the strongest evidence-base supporting their efficacy, but they are associated with additional treatment-related side effects when used as an add-on therapy.\n\nA 2008 Cochrane Collaboration review on St John's wort (specifically, any extracts which contain \"Hypericum perforatum\"), and a 2015 meta-analytic systematic review by some of the same authors, both concluded that it: has superior efficacy to placebo in treating depression; is as effective as standard antidepressant pharmaceuticals for treating depression; and has fewer adverse effects than other antidepressants. The 2015 meta analysis concluded that it is difficult to assign a place for St. John's wort in the treatment of depression owing to limitations in the available evidence base, including large variations in efficacy seen in trials performed in German-speaking relative to other countries. Reversible monoamine oxidase A inhibitors (rMAO-A inhibitors) have also been shown to be an effective drug therapy with greater tolerability than other antidepressants; however, the efficacy of SSRIs, tricyclic, and tetracyclic antidepressants in treating depression is supported by a much larger evidence base compared to other antidepressant drug therapies (i.e., St John's wort, rMAO-A inhibitors, serotonin–norepinephrine reuptake inhibitor, serotonin antagonist and reuptake inhibitors, noradrenaline reuptake inhibitors, and noradrenergic and specific serotonergic antidepressants).\n\nA study published in the \"Journal of the American Medical Association\" (\"JAMA\") demonstrated that the magnitude of the placebo effect in clinical trials of depression have been growing over time, while the effect size of tested drugs has remained relatively constant. The authors suggest that one possible explanation for the growing placebo effect in clinical trials is the inclusion of larger number of participants with shorter term, mild, or spontaneously remitting depression as a result of decreasing stigma associated with antidepressant use. Placebo response rates in clinical trials of complementary and alternative (CAM) therapies are significantly lower than those in clinical trials of traditional antidepressants.\n\nA 2004 review concluded that antidepressant studies that failed to support efficacy claims were dramatically less likely to be published than those that did support favorable efficacy claims. Similar results were obtained for a study of publication of clinical trials of antidepressants in children. A 2015 investigation of meta-analyses of antidepressant studies found that 79% of them had \"sponsorship or authors who were (pharmacutical) industry employees and/or had conflicts of interest\".\n\nA 2012 meta-analysis found that fluoxetine and venlafaxine were effective for major depression in all age groups. The authors also found no evidence of a relationship between baseline severity of depression and degree of benefit of antidepressants over placebo.\n\nA review published in 2012 found a negative correlation between study year and efficacy of antidepressants as measured by response rate. The change in response rate was largely driven by increase in placebo response. However the authors still concluded that antidepressants were effective in treating depression. The authors found that TCAs were the most effective drug, followed by SNRIs, MAOIs, SSRIs and atypical antidepressants.\n\nThe largest and most expensive study conducted to date, on the effectiveness of pharmacological treatment for depression, was commissioned by the National Institute of Mental Health. The study was dubbed \"The Sequenced Treatment Alternatives to Relieve Depression\" (STAR*D) Study. The results are summarized here.\nParticipants in the trial were recruited when they sought medical care at general medical or psychiatric clinics. No advertising was used to recruit subjects in order to maximize the generalizability of the study results. Participants were required to have a minimum score of 14 point on the Hamilton Depression Scale (HAM-D17) in order to be enrolled in the trial. Generally accepted cutoffs are 7–17 points for mild depression, 18–24 points for moderate depression, and ≥ 24 for severe depression. The average participant baseline HAM-D17 score was 22. The pre-specified primary endpoint of this trial was remission as determined by the HAM-D score, with all patients with missing scores rated as non-responders. In the aftermath of the trial, the investigators have presented the results mainly using the secondary endpoint of remission according to the QIDS-SR16 Score, which tend to be somewhat higher.\nThere were no statistical or meaningful clinical differences in remission rates, response rates, or times to remission or response among any of the medications compared in this study. These included bupropion sustained release, bupropion, citalopram, lithium, mirtazapine, nortriptyline, sertraline, triiodothyronine, tranylcypromine, and venlafaxine extended release.\n\nA 2008 review of randomized controlled trials concluded that symptomatic improvement with SSRIs was greatest by the end of the first week of use, but that some improvement continued for at least 6 weeks.\n\nBetween 30% and 50% of individuals treated with a given antidepressant do not show a response. In clinical studies, approximately one-third of patients achieve a full remission, one-third experience a response and one-third are nonresponders. Partial remission is characterized by the presence of poorly defined residual symptoms. These symptoms typically include depressed mood, psychic anxiety, sleep disturbance, fatigue and diminished interest or pleasure. It is currently unclear which factors predict partial remission. However, it is clear that residual symptoms are powerful predictors of relapse, with relapse rates 3–6 times higher in patients with residual symptoms than in those who experience full remission. In addition, antidepressant drugs tend to lose efficacy over the course of treatment. According to data from the Centers for Disease Control and Prevention, less than one-third of Americans taking one antidepressant medication have seen a mental health professional in the previous year. A number of strategies are used in clinical practice to try to overcome these limits and variations. They include switching medication, augmentation, and combination.\n\nThe American Psychiatric Association 2000 Practice Guideline advises that where no response is achieved following six to eight weeks of treatment with an antidepressant, to switch to an antidepressant in the same class, then to a different class of antidepressant.\nA 2006 meta-analysis review found wide variation in the findings of prior studies; for patients who had failed to respond to an SSRI antidepressant, between 12% and 86% showed a response to a new drug. However, the more antidepressants an individual had already tried, the less likely they were to benefit from a new antidepressant trial. However, a later meta-analysis found no difference between switching to a new drug and staying on the old medication; although 34% of treatment resistant patients responded when switched to the new drug, 40% responded without being switched.\n\nFor a partial response, the American Psychiatric Association guidelines suggest augmentation, or adding a drug from a different class. These include lithium and thyroid augmentation, dopamine agonists, sex steroids, NRIs, glucocorticoid-specific agents, or the newer anticonvulsants.\n\nA combination strategy involves adding another antidepressant, usually from a different class so as to have effect on other mechanisms. Although this may be used in clinical practice, there is little evidence for the relative efficacy or adverse effects of this strategy. Other tests recently conducted include the use of psychostimulants as an augmentation therapy. Several studies have shown the efficacy of combining modafinil to treatment-resistant patients. It has been used to help combat SSRI-associated fatigue.\n\nThe therapeutic effects of antidepressants typically do not continue once the course of medication ends, resulting in a high rate of relapse. A 2003 meta-analysis of 31 placebo-controlled antidepressant trials, mostly limited to studies covering a period of one year, found that 18% of patients who had responded to an antidepressant relapsed while still taking it, compared to 41% whose antidepressant was switched for a placebo.\n\nA gradual loss of therapeutic benefit occurs in a minority of people during the course of treatment. A strategy involving the use of pharmacotherapy in the treatment of the acute episode, followed by psychotherapy in its residual phase, has been suggested by some studies.\n\nAntidepressants are recommended by the National Institute for Health and Care Excellence (NICE) for the treatment of generalized anxiety disorder (GAD) that has failed to respond to conservative measures such as education and self-help activities. GAD is a common disorder of which the central feature is excessive worry about a number of different events. Key symptoms include excessive anxiety about multiple events and issues, and difficulty controlling worrisome thoughts that persists for at least 6 months.\n\nAntidepressants provide a modest-to-moderate reduction in anxiety in GAD, and are superior to placebo in treating GAD. The efficacy of different antidepressants is similar.\n\nSSRIs are a second-line treatment of adult obsessive-compulsive disorder (OCD) with mild functional impairment and as first-line treatment for those with moderate or severe impairment. In children, SSRIs can be considered as a second-line therapy in those with moderate-to-severe impairment, with close monitoring for psychiatric adverse effects. SSRIs are efficacious in the treatment of OCD; patients treated with SSRIs are about twice as likely to respond to treatment as those treated with placebo. Efficacy has been demonstrated both in short-term treatment trials of 6 to 24 weeks and in discontinuation trials of 28 to 52 weeks duration.\n\nAntidepressants are recommended as an alternative or additional first step to self-help programs in the treatment of bulimia nervosa. SSRIs (fluoxetine in particular) are preferred over other antidepressants due to their acceptability, tolerability, and superior reduction of symptoms in short-term trials. Long-term efficacy remains poorly characterized. Bupropion is not recommended for the treatment of eating disorders due to an increased risk of seizure.\n\nSimilar recommendations apply to binge eating disorder. SSRIs provide short-term reductions in binge eating behavior, but have not been associated with significant weight loss.\n\nClinical trials have generated mostly negative results for the use of SSRIs in the treatment of anorexia nervosa. Treatment guidelines from the National Institute of Health and Care Excellence recommend against the use of SSRIs in this disorder. Those from the American Psychiatric Association note that SSRIs confer no advantage regarding weight gain, but that they may be used for the treatment of co-existing depressive, anxiety, or obsessive-compulsive disorders.\n\nA 2012 meta-analysis concluded that antidepressants treatment favorably affects pain, health-related quality of life, depression, and sleep in fibromyalgia syndrome. Tricyclics appear to be the most effective class, with moderate effects on pain and sleep and small effects on fatigue and health-related quality of life. The fraction of people experiencing a 30% pain reduction on tricyclics was 48% versus 28% for placebo. For SSRIs and SNRIs the fraction of people experiencing a 30% pain reduction was 36% (20% in the placebo comparator arms) and 42% (32% in the corresponding placebo comparator arms). Discontinuation of treatment due to side effects was common. Antidepressants including amitriptyline, fluoxetine, duloxetine, milnacipran, moclobemide, and pirlindole are recommended by the European League Against Rheumatism (EULAR) for the treatment of fibromyalgia based on \"limited evidence\".\n\nA 2014 meta-analysis from the Cochrane Collaboration found the antidepressant duloxetine effective for the treatment of pain resulting from diabetic neuropathy. The same group reviewed data for amitryptyline in the treatment of neuropathic pain and found limited useful randomized clinical trial data, but concluded that the long history of successful use in the community for the treatment of fibromyalgia and neuropathic pain justified its continued use.\n\nDifficulty tolerating adverse effects is the most common reason for antidepressant discontinuation.\n\nAlmost any medication involved with serotonin regulation has the potential to cause serotonin toxicity (also known as \"serotonin syndrome\") an excess of serotonin that can induce mania, restlessness, agitation, emotional lability, insomnia and confusion as its primary symptoms. Although the condition is serious, it is not particularly common, generally only appearing at high doses or while on other medications. Assuming proper medical intervention has been taken (within about 24 hours) it is rarely fatal.\n\nMAOIs tend to have pronounced (sometimes fatal) interactions with a wide variety of medications and over-the-counter drugs. If taken with foods that contain very high levels of tyramine (e.g., mature cheese, cured meats, or yeast extracts), they may cause a potentially lethal hypertensive crisis. At lower doses the person may be bothered by only a headache due to an increase in blood pressure.\n\nIn response to these adverse effects, a different type of MAOI has been developed: the reversible inhibitor of monoamine oxidase A (RIMA) class of drugs. Their primary advantage is that they do not require the person to follow a special diet, while being purportedly effective as SSRIs and tricyclics in treating depressive disorders.\n\nSSRI use in pregnancy has been associated with a variety of risks with varying degrees of proof of causation. As depression is independently associated with negative pregnancy outcomes, determining the extent to which observed associations between antidepressant use and specific adverse outcomes reflects a causative relationship has been difficult in some cases. In other cases, the attribution of adverse outcomes to antidepressant exposure seems fairly clear.\n\nSSRI use in pregnancy is associated with an increased risk of spontaneous abortion of about 1.7-fold, and is associated with preterm birth and low birth weight.\n\nA systematic review of the risk of major birth defects in antidepressant-exposed pregnancies found a small increase (3% to 24%) in the risk of major malformations and a risk of cardiovascular birth defects that did not differ from non-exposed pregnancies. A study of fluoxetine-exposed pregnancies found a 12% increase in the risk of major malformations that just missed statistical significance. Other studies have found an increased risk of cardiovascular birth defects among depressed mothers not undergoing SSRI treatment, suggesting the possibility of ascertainment bias, e.g. that worried mothers may pursue more aggressive testing of their infants. Another study found no increase in cardiovascular birth defects and a 27% increased risk of major malformations in SSRI exposed pregnancies. The FDA advises for the risk of birth defects with the use of paroxetine and the MAOI should be avoided.\n\nA 2013 systematic review and meta-analysis found that antidepressant use during pregnancy was statistically significantly associated with some pregnancy outcomes, such as gestational age and preterm birth, but not with other outcomes. The same review cautioned that because differences between the exposed and unexposed groups were small, it was doubtful whether they were clinically significant.\n\nA neonate (infant less than 28 days old) may experience a withdrawal syndrome from abrupt discontinuation of the antidepressant at birth. Antidepressants have been shown to be present in varying amounts in breast milk, but their effects on infants are currently unknown.\n\nMoreover, SSRIs inhibit nitric oxide synthesis, which plays an important role in setting vascular tone. Several studies have pointed to an increased risk of prematurity associated with SSRI use, and this association may be due to an increase risk of pre-eclampsia of pregnancy.\n\nAnother possible problem with antidepressants is the chance of antidepressant-induced mania in patients with bipolar disorder. Many cases of bipolar depression are very similar to those of unipolar depression. Therefore, the patient can be misdiagnosed with unipolar depression and be given antidepressants. Studies have shown that antidepressant-induced mania can occur in 20–40% of bipolar patients. For bipolar depression, antidepressants (most frequently SSRIs) can exacerbate or trigger symptoms of hypomania and mania.\n\nStudies have shown that the use of antidepressants is correlated with an increased risk of suicidal behaviour and thinking (suicidality) in those aged under 25. This problem has been serious enough to warrant government intervention by the US Food and Drug Administration (FDA) to warn of the increased risk of suicidality during antidepressant treatment. According to the FDA, the heightened risk of suicidality is within the first one to two months of treatment. The National Institute for Health and Care Excellence (NICE) places the excess risk in the \"early stages of treatment\". A meta-analysis suggests that the relationship between antidepressant use and suicidal behavior or thoughts is age-dependent. Compared to placebo the use of antidepressants is associated with an increase in suicidal behavior or thoughts among those aged under 25 (OR=1.62). This increase in suicidality approaches that observed in children and adolescents. There is no effect or possibly a mild protective effect among those aged 25 to 64 (OR=0.79). Antidepressant treatment has a protective effect against suicidality among those aged 65 and over (OR=0.37).\n\nSexual side-effects are also common with SSRIs, such as loss of sexual drive, failure to reach orgasm, and erectile dysfunction. Although usually reversible, these sexual side-effects can, in rare cases, last for months or years after the drug has been completely withdrawn.\n\nIn a study of 1022 outpatients, overall sexual dysfunction with all antidepressants averaged 59.1% with SSRIs values between 57 and 73%, mirtazapine 24%, nefazodone 8%, amineptine 7% and moclobemide 4%. Moclobemide, a selective reversible MAO-A inhibitor, does not cause sexual dysfunction, and can actually lead to an improvement in all aspects of sexual function.\n\nBiochemical mechanisms suggested as causative include increased serotonin, particularly affecting 5-HT and 5-HT receptors; decreased dopamine; decreased norepinephrine; blockade of cholinergic and αadrenergic receptors; inhibition of nitric oxide synthetase; and elevation of prolactin levels. Mirtazapine is reported to have fewer sexual side-effects, most likely because it antagonizes 5-HT and 5-HT receptors and may, in some cases, reverse sexual dysfunction induced by SSRIs by the same mechanism.\n\nBupropion, a weak NDRI and nicotinic antagonist, may be useful in treating reduced libido as a result of SSRI treatment.\n\nChanges in appetite or weight are common among antidepressants, but largely drug-dependent and are related to which neurotransmitters they affect. Mirtazapine and paroxetine, for example, have the effect of weight gain and/or increased appetite, while others (such as bupropion and venlafaxine) achieve the opposite effect.\n\nThe antihistaminic properties of certain TCA- and TeCA-class antidepressants have been shown to contribute to the common side-effects of increased appetite and weight gain associated with these classes of medication.\n\nAntidepressant discontinuation symptoms were first reported with imipramine, the first tricyclic antidepressant (TCA), in the late 1950s, and each new class of antidepressants has brought reports of similar conditions, including monoamine oxidase inhibitors (MAOIs), SSRIs, and SNRIs. As of 2001, at least 21 different antidepressants, covering all the major classes, were known to cause discontinuation syndromes. The problem has been poorly studied, and most of the literature has been case reports or small clinical studies; incidence is hard to determine and controversial.\n\nPeople with discontinuation syndrome have been on an antidepressant for at least four weeks and have recently stopped taking the medication, either abruptly or after a fast taper. Common symptoms include flu-like symptoms (nausea, vomiting, diarrhea, headaches, sweating), sleep disturbances (insomnia, nightmares, constant sleepiness), sensory/movement disturbances (imbalance, tremors, vertigo, dizziness, electric-shock-like experiences), mood disturbances (dysphoria, anxiety, agitation) and cognitive disturbances (confusion and hyperarousal). Over fifty symptoms have been reported.\n\nMost cases of discontinuation syndrome last between one and four weeks, are relatively mild, and resolve on their own; in rare cases symptoms can be severe or extended. Paroxetine and venlafaxine seem to be particularly difficult to discontinue and prolonged withdrawal syndrome lasting over 18 months have been reported with paroxetine.\n\nWith the explosion of use and interest in SSRIs in the late 1980s and early 1990s, focused especially on Prozac, interest grew as well in discontinuation syndromes. In the late 1990s, some investigators thought that symptoms that emerged when antidepressants were discontinued, might mean that antidepressants were causing addiction, and some used the term \"withdrawal syndrome\" to describe the symptoms. Addictive substances cause physiological dependence, so that drug withdrawal causes suffering. These theories were abandoned, since addiction leads to drug-seeking behavior, and people taking antidepressants do not exhibit drug-seeking behavior. The term \"withdrawal syndrome\" is no longer used with respect to antidepressants, to avoid confusion with problems that arise from addiction. There are case reports of antidepressants being abused, but these are rare and are mostly limited to antidepressants with stimulant effects and to people who already had a substance use disorder. A 2012 comparison of the effects of stopping therapy with benzodiazepines and SSRIs argued that because the symptoms are similar, it makes no sense to say that benzodiazepines are addictive while SSRIs are not. Responses to that review noted that there is no evidence that people who stop taking SSRIs exhibit drug-seeking behavior while people who stop taking benzodiazepines do, and that the drug classes should be considered differently.\n\nThe earliest and probably most widely accepted scientific theory of antidepressant action is the monoamine hypothesis (which can be traced back to the 1950s), which states that depression is due to an imbalance (most often a deficiency) of the monoamine neurotransmitters (namely serotonin, norepinephrine and dopamine). It was originally proposed based on the observation that certain hydrazine anti-tuberculosis agents produce antidepressant effects, which was later linked to their inhibitory effects on monoamine oxidase, the enzyme that catalyses the breakdown of the monoamine neurotransmitters. All currently marketed antidepressants have the monoamine hypothesis as their theoretical basis, with the possible exception of agomelatine which acts on a dual melatonergic-serotonergic pathway. Despite the success of the monoamine hypothesis it has a number of limitations: for one, all monoaminergic antidepressants have a delayed onset of action of at least a week; and secondly, there are a sizeable portion (>40%) of depressed patients that do not adequately respond to monoaminergic antidepressants. A number of alternative hypotheses have been proposed, including the glutamate, neurogenic, epigenetic, cortisol hypersecretion and inflammatory hypotheses.\n\nSelective serotonin reuptake inhibitors (SSRIs) are believed to increase the extracellular level of the neurotransmitter serotonin by limiting its reabsorption into the presynaptic cell, increasing the level of serotonin in the synaptic cleft available to bind to the postsynaptic receptor. They have varying degrees of selectivity for the other monoamine transporters, with pure SSRIs having only weak affinity for the norepinephrine and dopamine transporters.\n\nSSRIs are the most widely prescribed antidepressants in many countries. The efficacy of SSRIs in mild or moderate cases of depression has been disputed.\n\nSerotonin-norepinephrine reuptake inhibitors (SNRIs) are potent inhibitors of the reuptake of serotonin and norepinephrine. These neurotransmitters are known to play an important role in mood. SNRIs can be contrasted with the more widely used selective serotonin reuptake inhibitors (SSRIs), which act mostly upon serotonin alone.\n\nThe human serotonin transporter (SERT) and norepinephrine transporter (NET) are membrane proteins that are responsible for the reuptake of serotonin and norepinephrine. Balanced dual inhibition of monoamine reuptake can possibly offer advantages over other antidepressants drugs by treating a wider range of symptoms.\n\nSNRIs are sometimes also used to treat anxiety disorders, obsessive-compulsive disorder (OCD), attention deficit hyperactivity disorder (ADHD), chronic neuropathic pain, and fibromyalgia syndrome (FMS), and for the relief of menopausal symptoms.\n\nSerotonin modulator and stimulators (SMSs), sometimes referred to more simply as serotonin modulators, are a type of drug with a multimodal action specific to the serotonin neurotransmitter system. To be precise, SMSs simultaneously modulate one or more serotonin receptors and inhibit the reuptake of serotonin. The term was created to describe the mechanism of action of the serotonergic antidepressant vortioxetine (Brintellix/Trintellix), which acts as a serotonin reuptake inhibitor (SRI), partial agonist of the 5-HT receptor, and antagonist of the 5-HT and 5-HT receptors. However, it can also technically be applied to vilazodone (Viibryd), which is an antidepressant as well and acts as an SRI and 5-HT receptor partial agonist.\n\nAn alternative term is serotonin partial agonist/reuptake inhibitor (SPARI), which can be applied only to vilazodone.\n\nSerotonin antagonist and reuptake inhibitors (SARIs) while mainly used as antidepressants, are also anxiolytics and hypnotics. They act by antagonizing serotonin receptors such as 5-HT and inhibiting the reuptake of serotonin, norepinephrine, and/or dopamine. Additionally, most also act as α-adrenergic receptor antagonists. The majority of the currently marketed SARIs belong to the phenylpiperazine class of compounds.\n\nNorepinephrine reuptake inhibitors (NRIs or NERIs) are a type of drug that acts as a reuptake inhibitor for the neurotransmitter norepinephrine (noradrenaline) by blocking the action of the norepinephrine transporter (NET). This in turn leads to increased extracellular concentrations of norepinephrine.\n\nNRIs are commonly used in the treatment of conditions like ADHD and narcolepsy due to their psychostimulant effects and in obesity due to their appetite suppressant effects. They are also frequently used as antidepressants for the treatment of major depressive disorder, anxiety and panic disorder. Additionally, many drugs of abuse such as cocaine and methylphenidate possess NRI activity, though it is important to mention that NRIs without combined dopamine reuptake inhibitor (DRI) properties are not significantly rewarding and hence are considered to have a negligible abuse potential. However, norepinephrine has been implicated as acting synergistically with dopamine when actions on the two neurotransmitters are combined (e.g., in the case of NDRIs) to produce rewarding effects in psychostimulant drugs of abuse.\n\nThe majority of the tricyclic antidepressants (TCAs) act primarily as serotonin-norepinephrine reuptake inhibitors (SNRIs) by blocking the serotonin transporter (SERT) and the norepinephrine transporter (NET), respectively, which results in an elevation of the synaptic concentrations of these neurotransmitters, and therefore an enhancement of neurotransmission. Notably, with the sole exception of amineptine, the TCAs have negligible affinity for the dopamine transporter (DAT), and therefore have no efficacy as dopamine reuptake inhibitors (DRIs). Both serotonin and norepinephrine have been highly implicated in depression and anxiety, and it has been shown that facilitation of their activity has beneficial effects on these mental disorders.\n\nAlthough TCAs are sometimes prescribed for depressive disorders, they have been largely replaced in clinical use in most parts of the world by newer antidepressants such as selective serotonin reuptake inhibitors (SSRIs), serotonin-norepinephrine reuptake inhibitors (SNRIs) and norepinephrine reuptake inhibitors (NRIs). Adverse effects have been found to be of a similar level between TCAs and SSRIs.\n\nTetracyclic antidepressants (TeCAs) are a class of antidepressants that were first introduced in the 1970s. They are named after their chemical structure, which contains four rings of atoms, and are closely related to the tricyclic antidepressants (TCAs), which contain three rings of atoms.\n\nMonoamine oxidase inhibitors (MAOIs) are chemicals which inhibit the activity of the monoamine oxidase enzyme family. They have a long history of use as medications prescribed for the treatment of depression. They are particularly effective in treating atypical depression. They are also used in the treatment of Parkinson's disease and several other disorders.\n\nBecause of potentially lethal dietary and drug interactions, monoamine oxidase inhibitors have historically been reserved as a last line of treatment, used only when other classes of antidepressant drugs (for example selective serotonin reuptake inhibitors and tricyclic antidepressants) have failed.\n\nMAOIs have been found to be effective in the treatment of panic disorder with agoraphobia, social phobia, atypical depression or mixed anxiety and depression, bulimia, and post-traumatic stress disorder, as well as borderline personality disorder. MAOIs appear to be particularly effective in the management of bipolar depression according to a recent retrospective-analysis. There are reports of MAOI efficacy in obsessive-compulsive disorder (OCD), trichotillomania, dysmorphophobia, and avoidant personality disorder, but these reports are from uncontrolled case reports.\n\nMAOIs can also be used in the treatment of Parkinson's disease by targeting MAO-B in particular (therefore affecting dopaminergic neurons), as well as providing an alternative for migraine prophylaxis. Inhibition of both MAO-A and MAO-B is used in the treatment of clinical depression and anxiety disorders.\n\nSee the list of antidepressants for other drugs which are not specifically characterized.\n\nAdjunct medications are an umbrella term used to describe substances that increase the potency or \"enhance\" antidepressants. They work by affecting variables very close to the antidepressant, sometimes affecting a completely different mechanism of action. This may be attempted when depression treatments have not been successful in the past.\n\nCommon types of adjunct medication techniques generally fall into the following categories:\nIt is unknown if undergoing psychological therapy at the same time as taking anti-depressants enhances the anti-depressive effect of the medication.\n\nLithium has been used to augment antidepressant therapy in those who have failed to respond to antidepressants alone. Furthermore, lithium dramatically decreases the suicide risk in recurrent depression. There is some evidence for the addition of a thyroid hormone, triiodothyronine, in patients with normal thyroid function. Stephen M. Stahl, renowned academician in psychopharmacology, has stated resorting to a dynamic psychostimulant, in particular, d-amphetamine is the \"\"classical augmentation strategy\" for treatment-refractory depression\". However, the use of stimulants in cases of treatment-resistant depression is relatively controversial. A review article published in 2007 found psychostimulants may be effective in treatment-resistant depression with concomitant antidepressant therapy, but a more certain conclusion could not be drawn due to substantial deficiencies in the studies available for consideration, and the somewhat contradictory nature of their results.\n\nBefore the 1950s, opioids and amphetamines were commonly used as antidepressants. Their use was later restricted due to their addictive nature and side effects. Extracts from the herb St John's wort had been used as a \"nerve tonic\" to alleviate depression.\n\nIn 1951, Irving Selikoff and Edward Robitzek, working out of Sea View Hospital on Staten Island, began clinical trials on two new anti-tuberculosis agents developed by Hoffman-LaRoche, isoniazid and iproniazid. Only patients with a poor prognosis were initially treated; nevertheless, their condition improved dramatically. Selikoff and Robitzek noted \"a subtle general stimulation … the patients exhibited renewed vigor and indeed this occasionally served to introduce disciplinary problems.\" The promise of a cure for tuberculosis in the Sea View Hospital trials was excitedly discussed in the mainstream press.\n\nIn 1952, learning of the stimulating side effects of isoniazid, the Cincinnati psychiatrist Max Lurie tried it on his patients. In the following year, he and Harry Salzer reported that isoniazid improved depression in two thirds of their patients and coined the term \"antidepressant\" to describe its action. A similar incident took place in Paris, where Jean Delay, head of psychiatry at Sainte-Anne Hospital, heard of this effect from his pulmonology colleagues at Cochin Hospital. In 1952 (before Lurie and Salzer), Delay, with the resident Jean-Francois Buisson, reported the positive effect of isoniazid on depressed patients. The mode of antidepressant action of isoniazid is still unclear. It is speculated that its effect is due to the inhibition of diamine oxidase, coupled with a weak inhibition of monoamine oxidase A.\n\nSelikoff and Robitzek also experimented with another anti-tuberculosis drug, iproniazid; it showed a greater psychostimulant effect, but more pronounced toxicity. Later, Jackson Smith, Gordon Kamman, George Crane, and Frank Ayd, described the psychiatric applications of iproniazid. Ernst Zeller found iproniazid to be a potent monoamine oxidase inhibitor. Nevertheless, iproniazid remained relatively obscure until Nathan Kline, the influential and flamboyant head of research at Rockland State Hospital, began to popularize it in the medical and popular press as a \"psychic energizer\". Roche put a significant marketing effort behind iproniazid. Its sales grew until it was recalled in 1961, due to reports of lethal hepatotoxicity.\n\nThe antidepressant effect of a tricyclic, a three ringed compound, was first discovered in 1957 by Roland Kuhn in a Swiss psychiatric hospital. Antihistamine derivatives were used to treat surgical shock and later as neuroleptics. Although in 1955 reserpine was shown to be more effective than placebo in alleviating anxious depression, neuroleptics were being developed as sedatives and antipsychotics.\n\nAttempting to improve the effectiveness of chlorpromazine, Kuhn in conjunction with the Geigy Pharmaceutical Company discovered the compound \"G 22355\", later renamed imipramine. Imipramine had a beneficial effect in patients with depression who showed mental and motor retardation. Kuhn described his new compound as a \"thymoleptic\" \"taking hold of the emotions,\" in contrast with neuroleptics, \"taking hold of the nerves\" in 1955–56. These gradually became established, resulting in the patent and manufacture in the US in 1951 by Häfliger and SchinderA.\n\nAntidepressants became prescription drugs in the 1950s. It was estimated that no more than 50 to 100 individuals per million suffered from the kind of depression that these new drugs would treat, and pharmaceutical companies were not enthusiastic in marketing for this small market. Sales through the 1960s remained poor compared to the sales of tranquilizers, which were being marketed for different uses. Imipramine remained in common use and numerous successors were introduced. The use of monoamine oxidase inhibitors (MAOI) increased after the development and introduction of \"reversible\" forms affecting only the MAO-A subtype of inhibitors, making this drug safer to use.\n\nBy the 1960s, it was thought that the mode of action of tricyclics was to inhibit norepinephrine reuptake. However, norepinephrine reuptake became associated with stimulating effects. Later tricyclics were thought to affect serotonin as proposed in 1969 by Carlsson and Lindqvist as well as Lapin and Oxenkrug.\n\nResearchers began a process of rational drug design to isolate antihistamine-derived compounds that would selectively target these systems. The first such compound to be patented was zimelidine in 1971, while the first released clinically was indalpine. Fluoxetine was approved for commercial use by the US Food and Drug Administration (FDA) in 1988, becoming the first blockbuster SSRI. Fluoxetine was developed at Eli Lilly and Company in the early 1970s by Bryan Molloy, Klaus Schmiegel, David Wong and others. SSRIs became known as \"novel antidepressants\" along with other newer drugs such as SNRIs and NRIs with various selective effects.\n\nSt John's wort fell out of favor in most countries through the 19th and 20th centuries, except in Germany, where Hypericum extracts were eventually licensed, packaged and prescribed. Small-scale efficacy trials were carried out in the 1970s and 1980s, and attention grew in the 1990s following a meta-analysis. It remains an over-the-counter drug (OTC) supplement in most countries. Research continues to investigate its active component hyperforin, and to further understand its mode of action.\n\nIn the United States, antidepressants were the most commonly prescribed medication in 2013. Of the estimated 16 million \"long term\" (over 24 months) users, roughly 70 percent are female.\n\nIn the UK, figures reported in 2010 indicated that the number of antidepressant prescribed by the National Health Service (NHS) almost doubled over a decade. Further analysis published in 2014 showed that number of antidepressants dispensed annually in the community went up by 25 million in the 14 years between 1998 and 2012, rising from 15 million to 40 million. Nearly 50% of this rise occurred in the four years after the 2008 banking crash, during which time the annual increase in prescriptions rose from 6.7% to 8.5%. These sources also suggest that aside from the recession, other factors that may influence changes in prescribing rates may include: improvements in diagnosis, a reduction of the stigma surrounding mental health, broader prescribing trends, GP characteristics, geographical location and housing status. Another factor that contribute to increasing consumption of antidepressants is the fact that these medications now are used for other conditions including social anxiety and post traumatic stress.\n\nUnited States: The most commonly prescribed antidepressants in the US retail market in 2010 were:\n\nNetherlands: In the Netherlands, paroxetine, marketed as Seroxat among generic preparations, is the most prescribed antidepressant, followed by amitriptyline, citalopram and venlafaxine.\n\nIn looking at the issue of antidepressant use, some academics have highlighted the need to examine the use of antidepressants and other medical treatments in cross-cultural terms, due to the fact that various cultures prescribe and observe different manifestations, symptoms, meanings and associations of depression and other medical conditions within their populations. These cross-cultural discrepancies, it has been argued, then have implications on the perceived efficacy and use of antidepressants and other strategies in the treatment of depression in these different cultures. In India antidepressants are largely seen as tools to combat marginality, promising the individual the ability to re-integrate into society through their use—a view and association not observed in the West.\n\nSomewhat less than 10% of orally administered fluoxetine is excreted from humans unchanged or as glucuronide. Because most antidepressants function by inhibiting the reuptake of neurotransmitters serotonin, dopamine, and norepinepherine these drugs can interfere with natural neurotransmitter levels in other organisms impacted by indirect exposure. Antidepressants fluoxetine and sertraline have been detected in aquatic organisms residing in effluent dominated streams. The presence of antidepressants in surface waters and aquatic organisms has caused concern because ecotoxicological effects to aquatic organisms due to fluoxetine exposure have been demonstrated. Coral reef fish have been demonstrated to modulate aggressive behavior through serotonin.\n\nExposure to fluoxetine has been demonstrated to increase serotonergic activity in fish, subsequently reducing aggressive behavior. Artificially increasing serotonin levels in crustaceans can temporarily reverse social status and turn subordinates into aggressive and territorial dominant males. Perinatal exposure to fluoxetine at relevant environmental concentrations has been shown to lead to significant modifications of memory processing in 1-month-old cuttlefish. This impairment may disadvantage cuttlefish and decrease their survival.\n\n", "id": "2388", "title": "Antidepressant"}
{"url": "https://en.wikipedia.org/wiki?curid=2389", "text": "Auger effect\n\nThe Auger effect is a physical phenomenon in which the filling of an inner-shell vacancy of an atom is accompanied by the emission of an electron from the same atom. When a core electron is removed, leaving a vacancy, an electron from a higher energy level may fall into the vacancy, resulting in a release of energy. Although most often this energy is released in the form of an emitted photon, the energy can also be transferred to another electron, which is ejected from the atom; this second ejected electron is called an Auger electron. The effect was first discovered by Lise Meitner in 1922; Pierre Victor Auger independently discovered the effect shortly after and is credited with the discovery in most of the scientific community.\n\nUpon ejection, the kinetic energy of the Auger electron corresponds to the difference between the energy of the initial electronic transition into the vacancy and the ionization energy for the electron shell from which the Auger electron was ejected. These energy levels depend on the type of atom and the chemical environment in which the atom was located. Auger electron spectroscopy involves the emission of Auger electrons by bombarding a sample with either X-rays or energetic electrons and measures the intensity of Auger electrons that result as a function of the Auger electron energy. The resulting spectra can be used to determine the identity of the emitting atoms and some information about their environment. Auger recombination is a similar Auger effect which occurs in semiconductors. An electron and electron hole (electron-hole pair) can recombine giving up their energy to an electron in the conduction band, increasing its energy. The reverse effect is known as impact ionization.\n\nThe Auger emission process was observed and published in 1922 by Lise Meitner, an Austrian-Swedish physicist, as a side effect in her competitive search for the nuclear beta electrons with the British physicist Charles Drummond Ellis.\n\nThe French physicist Pierre Victor Auger independently discovered it in 1923 upon analysis of a Wilson cloud chamber experiment and it became the central part of his PhD work. High-energy X-rays were applied to ionize gas particles and observe photoelectric electrons. The observation of electron tracks that were independent of the frequency of the incident photon suggested a mechanism for electron ionization that was caused from an internal conversion of energy from a radiationless transition. Further investigation, and theoretical work using elementary quantum mechanics and transition rate/transition probability calculations, showed that the effect was a radiationless effect more than an internal conversion effect.\n\n", "id": "2389", "title": "Auger effect"}
{"url": "https://en.wikipedia.org/wiki?curid=2391", "text": "Akio Morita\n\nAkio Morita (盛田 昭夫 \"Morita Akio\"; 26 January 1921 – 3 October 1999) was a Japanese businessman and co-founder of Sony along with Masaru Ibuka.\n\nAkio Morita was born in Nagoya, Aichi, Japan. Morita's family was involved in sake, miso and soy sauce production in the village of Kosugaya (currently a part of Tokoname City) on the western coast of Chita Peninsula in Aichi Prefecture since 1665. He was the oldest of four siblings and his father Kyuzaemon trained him as a child to take over the family business. Akio, however, found his true calling in mathematics and physics, and in 1944 he graduated from Osaka Imperial University with a degree in physics. He was later commissioned as a sub-lieutenant in the Imperial Japanese Navy, and served in World War II. During his service, Morita met his future business partner Masaru Ibuka in the Navy's Wartime Research Committee.\n\nOn May 7, 1946, Morita and Ibuka founded \"Tokyo Tsushin Kogyo Kabushiki Kaisha\" (Tokyo Telecommunications Engineering Corporation, the forerunner of Sony Corporation) with about 20 employees and initial capital of ¥190,000. Ibuka was 38 years old, Morita, 25. Morita's family invested in Sony during the early period and was the largest shareholder.\n\nIn 1949, the company developed magnetic recording tape and in 1950, sold the first tape recorder in Japan. In 1957, it produced a pocket-sized radio (the first to be fully transistorized), and in 1958, Morita and Ibuka decided to rename their company Sony (derived from \"sonus\"--Latin for \"sound\"—and \"Sonny-boys\" the most common American expression). Morita was an advocate for all the products made by Sony. However, since the radio was slightly too big to fit in a shirt pocket, Morita made his employees wear shirts with slightly larger pockets to give the radio a \"pocket sized\" appearance. In 1960, it produced the first transistor television in the world. In 1973, Sony received an Emmy Award for its Trinitron television-set technology. In 1975, it released the first Betamax home video recorder, a year before VHS format came out. In 1979, the Walkman was introduced, making it one of the world's first portable music players. In 1984, Sony launched the Discman series which extended their Walkman brand to portable CD products.\n\nIn 1960, the Sony Corporation of America (SONAM, currently abbreviated as SCA) was established in the United States. In 1961, Sony Corporation was the first Japanese company to be listed on the New York Stock Exchange, in the form of American depositary receipts (ADRs), which are traded over-the-counter. Sony bought CBS Records Group which consisted of Columbia Records, Epic Records and other CBS labels in 1988 and Columbia Pictures Entertainment (Columbia Pictures, TriStar Pictures and others) in 1989.\n\nOn November 25, 1994, Morita stepped down as Sony chairman after suffering a cerebral hemorrhage while playing tennis. He was succeeded by Norio Ohga, who had joined the company in the 1950s after sending Morita a letter denouncing the poor quality of the company's tape recorders.\n\nMorita was vice chairman of the Japan Business Federation (Japan Federation of Economic Organizations), and was a member of the Japan-U.S. Economic Relations Group, also known as the \"Wise Men's Group\". He was also the third Japanese chairman of the Trilateral Commission. His amateur radio call sign is JP1DPJ.\n\nIn 1966, Morita wrote a book called \"Gakureki Muyō Ron\" (学歴無用論, Never Mind School Records), where he stresses that school records are not important to success or one's business skills. In 1986, Morita wrote an autobiography titled \"Made in Japan\". He co-authored the 1991 book \"The Japan That Can Say No\" with politician Shintaro Ishihara, where they criticized American business practices and encouraged Japanese to take a more independent role in business and foreign affairs. The book was translated into English and caused controversy in the United States, and Morita later had his chapters removed from the English version and distanced himself from the book.\n\nMorita was awarded the Albert Medal by the United Kingdom's Royal Society of Arts in 1982, the first Japanese to receive the honor. Two years later, he received the prestigious Legion of Honour, and in 1991, was awarded the First Class Order of the Sacred Treasure from the Emperor of Japan. In 1993, he was awarded an honorary British knighthood (KBE). Morita received the International Distinguished Entrepreneur Award from the University of Manitoba in 1987. He was posthumously awarded the Grand Cordon of the Order of the Rising Sun in 1999.\n\nMorita suffered a stroke in 1993, during a game of tennis. On November 25, 1994, he stepped down as Sony chairman. On October 3, 1999, Morita died of pneumonia at the age of 78.\n\n\n\n \n", "id": "2391", "title": "Akio Morita"}
{"url": "https://en.wikipedia.org/wiki?curid=2392", "text": "Anode\n\nAn anode is an electrode through which conventional current flows into a polarized electrical device. A common mnemonic is ACID for \"anode current into device\". The direction of (positive) electric current is opposite to the direction of electron flow: (negatively charged) electrons flow out the anode to the outside circuit.\n\nThe terms anode and cathode do not relate to the voltage polarity of those electrodes but the direction of the current: whether positive charge is flowing into or out of the device. Conventional current quantifies the flow of positive charge. In most cases, positive charge leaves the device via the cathode, and positive charge flows into the device via the anode.\n\nConventional current depends not only on the direction the charge carriers move, but also the carriers' charge. The currents outside the device are usually carried by electrons in a metal conductor. The flow of electrons is opposite to conventional current because electrons have a negative charge. Consequently, electrons leave the device via the anode, and electrons enter the device through the cathode.\n\nThe anode and cathode have slightly different definitions for electrical devices such as diodes and vacuum tubes where the electrode naming is fixed and does not depend on the actual charge flow (current). These devices usually allow substantial current flow in one direction but negligible current in the other direction. Consequently, the electrode names use the terms that have substantial ordinary currents. An ideal diode allows current in one direction but not in the other. The electrode that allows positive charges to flow into it would be the anode, but that electrode would never allow positive charges to flow out, so that ideal diode terminal could never be the cathode. For the ideal diode, it makes sense to always call that terminal the anode. For non-ideal diodes, the electrodes are also given fixed names even though such a diode under reverse bias would have a positive charge flow out of the \"anode\". For some operating conditions and devices, such as diode breakdown, Zener diodes, or photodiodes, the positive charge flow out of the \"anode\" could be substantial.\n\nThe polarity of voltage on an anode with respect to an associated cathode varies depending on the device type and on its operating mode. In the following examples, the anode is negative in a device that provides power, and positive in a device that consumes power:\n\nIn a discharging battery or galvanic cell (diagram at right), the anode is the negative terminal because it is where conventional current flows into \"the device\" (i.e. the battery cell). This inward current is carried externally by electrons moving outwards, negative charge flowing in one direction being electrically equivalent to positive charge flowing in the opposite direction.\n\nIn a recharging battery, or an electrolytic cell, the anode is the positive terminal, which receives current from an external generator. The current through a recharging battery is opposite to the direction of current during discharge; in other words, the electrode which was the cathode during battery discharge becomes the anode while the battery is recharging.\n\nIn a diode, the anode is the positive terminal at the tail of the arrow symbol (flat side of the triangle), where current flows into the device. Note electrode naming for diodes is always based on the direction of the forward current (that of the arrow, in which the current flows \"most easily\"), even for types such as Zener diodes or solar cells where the current of interest is the reverse current.\n\nIn a cathode ray tube, the anode is the positive terminal where electrons flow out of the device, i.e., where positive electric current flows in.\n\nThe word was coined in 1834 from the Greek ἄνοδος (\"anodos\"), 'ascent', by William Whewell, who had been consulted by Michael Faraday over some new names needed to complete a paper on the recently discovered process of electrolysis. In that paper Faraday explained that when an electrolytic cell is oriented so that electric current traverses the \"decomposing body\" (electrolyte) in a direction \"from East to West, or, which will strengthen this help to the memory, that in which the sun appears to move\", the anode is where the current enters the electrolyte, on the East side: \"\"ano\" upwards, \"odos\" a way; the way which the sun rises\".\n\nThe use of 'East' to mean the 'in' direction (actually 'in' → 'East' → 'sunrise' → 'up') may appear contrived. Previously, as related in the first reference cited above, Faraday had used the more straightforward term \"eisode\" (the doorway where the current enters). His motivation for changing it to something meaning 'the East electrode' (other candidates had been \"eastode\", \"oriode\" and \"anatolode\") was to make it immune to a possible later change in the direction convention for current, whose exact nature was not known at the time. The reference he used to this effect was the Earth's magnetic field direction, which at that time was believed to be invariant. He fundamentally defined his arbitrary orientation for the cell as being that in which the internal current would run parallel to and in the same direction as a hypothetical magnetizing current loop around the local line of latitude which would induce a magnetic dipole field oriented like the Earth's. This made the internal current East to West as previously mentioned, but in the event of a later convention change it would have become West to East, so that the East electrode would not have been the 'way in' any more. Therefore, \"eisode\" would have become inappropriate, whereas \"anode\" meaning 'East electrode' would have remained correct with respect to the unchanged direction of the actual phenomenon underlying the current, then unknown but, he thought, unambiguously defined by the magnetic reference. In retrospect the name change was unfortunate, not only because the Greek roots alone do not reveal the anode's function any more, but more importantly because as we now know, the Earth's magnetic field direction on which the \"anode\" term is based is subject to reversals whereas the current direction convention on which the \"eisode\" term was based has no reason to change in the future.\n\nSince the later discovery of the electron, an easier to remember and more durably correct technically although historically false, etymology has been suggested: anode, from the Greek \"anodos\", 'way up', 'the way (up) out of the cell (or other device) for electrons'.\n\nIn electrochemistry, the \"anode\" is where oxidation occurs and is the positive polarity contact in an electrolytic cell. At the anode, anions (negative ions) are forced by the electrical potential to react chemically and give off electrons (oxidation) which then flow up and into the driving circuit. Mnemonics: LEO Red Cat (Loss of Electrons is Oxidation, Reduction occurs at the Cathode), or AnOx Red Cat (Anode Oxidation, Reduction Cathode), or OIL RIG (Oxidation is Loss, Reduction is Gain of electrons), or Roman Catholic and Orthodox (Reduction – Cathode, anode – Oxidation), or LEO the lion says GER (Losing electrons is Oxidation, Gaining electrons is Reduction).\n\nThis process is widely used in metals refining. For example, in copper refining, copper anodes, an intermediate product from the furnaces, are electrolysed in an appropriate solution (such as sulfuric acid) to yield high purity (99.99%) cathodes. Copper cathodes produced using this method are also described as electrolytic copper.\n\nIn a battery or galvanic cell, the anode is the negative electrode from which electrons flow out towards the external part of the circuit. Internally the positively charged cations are flowing away from the anode (even though it is negative and therefore would be expected to attract them, this is due to electrode potential relative to the electrolyte solution being different for the anode and cathode metal/electrolyte systems); but, external to the cell in the circuit, electrons are being pushed out through the negative contact and thus through the circuit by the voltage potential as would be expected. Note: in a galvanic cell, contrary to what occurs in an electrolytic cell, no anions flow to the anode, the internal current being entirely accounted for by the cations flowing away from it (cf drawing).\n\nIn the United States, many battery manufacturers regard the positive electrode as the anode, particularly in their technical literature. Though technically incorrect, it does resolve the problem of which electrode is the anode in a secondary (or rechargeable) cell. Using the traditional definition, the anode switches ends between charge and discharge cycles.\n\nIn electronic vacuum devices such as a cathode ray tube, the anode is the positively charged electron collector. In a tube, the anode is a charged positive plate that collects the electrons emitted by the cathode through electric attraction. It also accelerates the flow of these electrons.\n\nIn a semiconductor diode, the anode is the P-doped layer which initially supplies \"holes\" to the junction. In the junction region, the holes supplied by the anode combine with electrons supplied from the N-doped region, creating a depleted zone. As the P-doped layer supplies holes to the depleted region, negative dopant ions are left behind in the P-doped layer ('P' for positive charge-carrier ions). This creates a base negative charge on the anode. When a positive voltage is applied to anode of the diode from the circuit, more \"holes\" are able to be transferred to the depleted region, and this causes the diode to become conductive, allowing current to flow through the circuit. The terms anode and cathode should not be applied to a Zener diode, since it allows flow in either direction, depending on the polarity of the applied potential (i.e. voltage).\n\nIn cathodic protection, a metal anode that is more reactive to the corrosive environment of the system to be protected is electrically linked to the protected system, and partially corrodes or dissolves, which protects the metal of the system it is connected to. As an example, an iron or steel ship's hull may be protected by a zinc sacrificial anode, which will dissolve into the seawater and prevent the hull from being corroded. Sacrificial anodes are particularly needed for systems where a static charge is generated by the action of flowing liquids, such as pipelines and watercraft. Sacrificial anodes are also generally used in tank-type water heaters.\n\nIn 1824 to reduce the impact of this destructive electrolytic action on ships hulls, their fastenings and underwater equipment, the scientist-engineer Sir Humphry Davy, developed the first and still most widely used marine electrolysis protection system. Davy installed sacrificial anodes made from a more electrically reactive (less noble) metal attached to the vessel hull and electrically connected to form a cathodic protection circuit.\n\nA less obvious example of this type of protection is the process of galvanising iron. This process coats iron structures (such as fencing) with a coating of zinc metal. As long as the zinc remains intact, the iron is protected from the effects of corrosion. Inevitably, the zinc coating becomes breached, either by cracking or physical damage. Once this occurs, corrosive elements act as an electrolyte and the zinc/iron combination as electrodes. The resultant current ensures that the zinc coating is sacrificed but that the base iron does not corrode. Such a coating can protect an iron structure for a few decades, but once the protecting coating is consumed, the iron rapidly corrodes.\n\nIf, conversely, tin is used to coat steel, when a breach of the coating occurs it actually accelerates oxidation of the iron.\n\nThe opposite of an anode is a cathode. When the current through the device is reversed, the electrodes switch functions, so anode becomes cathode, while cathode becomes anode, as long as the reversed current is applied, with the exception of diodes where electrode naming is always based on the forward current direction.\n\n", "id": "2392", "title": "Anode"}
{"url": "https://en.wikipedia.org/wiki?curid=2393", "text": "Analog television\n\nAnalog television or analogue television is the original television technology that uses analog signals to transmit video and audio. In an analog television broadcast, the brightness, colors and sound are represented by rapid variations of either the amplitude, frequency or phase of the signal.\n\nAnalog signals vary over a continuous range of possible values which means that electronic noise and interference becomes reproduced by the receiver. So with analog, a moderately weak signal becomes snowy and subject to interference. In contrast, a moderately weak digital signal and a very strong digital signal transmit equal picture quality. Analog television may be wireless or can be distributed over a cable network using cable converters.\n\nAll broadcast television systems preceding digital transmission of digital television (DTV) used analog signals.\n\nAnalog television around the world has been in the process of shutting down since the late 2000s.\n\nThe earliest systems were mechanical television systems which used spinning disks with patterns of holes punched into the disc to scan an image. A similar disk reconstructed the image at the receiver. Synchronization of the receiver disc rotation was handled through sync pulses broadcast with the image information. However these mechanical systems were slow, the images were dim and flickered severely, and the image resolution very low. Camera systems used similar spinning discs and required intensely bright illumination of the subject for the light detector to work.\n\nAnalog television did not really begin as an industry until the development of the cathode-ray tube (CRT), which uses a focused electron beam to trace lines across a phosphor coated surface. The electron beam could be swept across the screen much faster than any mechanical disc system, allowing for more closely spaced scan lines and much higher image resolution. Also far less maintenance was required of an all-electronic system compared to a spinning disc system. All-electronic systems became popular with households after the Second World War.\n\nBroadcasters using analog television systems encode their signal using different systems. The official systems of transmission are named : A, B, C, D, E, F, G, H, I, K, K1, L, M and N. These systems determine the number of lines, channel width, vision bandwidth, vision-sound separation, etc.\n\nThe colors on those systems are encoded with one of the three color coding NTSC, PAL or SECAM, and then use RF modulation to modulate this signal onto a very high frequency (VHF) or ultra high frequency (UHF) carrier. Each frame of a television image is composed of lines drawn on the screen. The lines are of varying brightness; the whole set of lines is drawn quickly enough that the human eye perceives it as one image. The next sequential frame is displayed, allowing the depiction of motion. The analog television signal contains timing and synchronization information, so that the receiver can reconstruct a two-dimensional moving image from a one-dimensional time-varying signal.\n\nThe first commercial television systems were black-and-white; the beginning of color television was in the 1950s.\n\nA practical television system needs to take luminance, chrominance (in a color system), synchronization (horizontal and vertical), and audio signals, and broadcast them over a radio transmission. The transmission system must include a means of television channel selection.\n\nAnalog broadcast television systems come in a variety of frame rates and resolutions. Further differences exist in the frequency and modulation of the audio carrier. The monochrome combinations still existing in the 1950s are standardized by the International Telecommunication Union (ITU) as capital letters A through N. When color television was introduced, the hue and saturation information was added to the monochrome signals in a way that black and white televisions ignore. In this way backwards compatibility was achieved. That concept is true for all analog television standards.\n\nThere were three standards for the way the additional color information can be encoded and transmitted. The first was the American NTSC (National Television Systems Committee) color television system. The European/Australian PAL (Phase Alternation Line rate) and the French-former Soviet Union SECAM (Séquentiel Couleur Avec Mémoire) standard were developed later and attempt to cure certain defects of the NTSC system. PAL's color encoding is similar to the NTSC systems. SECAM, though, uses a different modulation approach than PAL or NTSC.\n\nIn principle, all three color encoding systems can be combined with any scan line/frame rate combination. Therefore, in order to describe a given signal completely, it's necessary to quote the color system and the broadcast standard as a capital letter. For example, the United States, Canada, Mexico and South Korea use NTSC-M (many of these transitioned or transitioning to digital), Japan uses NTSC-J (discontinued in 2012, when Japan transitioned to digital (ISDB)), the UK uses PAL-I (discontinued in 2012, when UK transitioned to digital (DVB-T)), France uses SECAM-L (discontinued in 2011, when France transitioned to digital (DVB-T)), much of Western Europe and Australia use PAL-B/G (Many of these transitioned or transitioning to DVB-T as digital television standards), most of Eastern Europe uses SECAM-D/K or PAL-D/K and so on.\n\nHowever, not all of these possible combinations actually exist. NTSC is currently only used with system M, even though there were experiments with NTSC-A (405 line) in the UK and NTSC-N (625 line) in part of South America. PAL is used with a variety of 625-line standards (B,G,D,K,I,N) but also with the North American 525-line standard, accordingly named PAL-M. Likewise, SECAM is used with a variety of 625-line standards.\n\nFor this reason many people refer to any 625/25 type signal as \"PAL\" and to any 525/30 signal as \"NTSC\", even when referring to digital signals; for example, on DVD-video, which does not contain any analog color encoding, and thus no PAL or NTSC signals at all. Even though this usage is common, it is misleading, as that is not the original meaning of the terms PAL/SECAM/NTSC.\n\nAlthough a number of different broadcast television systems were in use worldwide, the same principles of operation apply.\n\nIn many countries, over-the-air broadcast television of analog audio and analog video signals has been discontinued, to allow the re-use of the television broadcast radio spectrum for other services such as datacasting and subchannels.\n\nA cathode-ray tube (CRT) television displays an image by scanning a beam of electrons across the screen in a pattern of horizontal lines known as a raster. At the end of each line the beam returns to the start of the next line; the end of the last line is a link that returns to the top of the screen. As it passes each point the intensity of the beam is varied, varying the luminance of that point. A color television system is identical except that an additional signal known as chrominance controls the color of the spot.\n\nRaster scanning is shown in a slightly simplified form below.\n\nWhen analog television was developed, no affordable technology for storing any video signals existed; the luminance signal has to be generated and transmitted at the same time at which it is displayed on the CRT. It is therefore essential to keep the raster scanning in the camera (or other device for producing the signal) in exact synchronization with the scanning in the television.\n\nThe physics of the CRT require that a finite time interval be allowed for the spot to move back to the start of the next line (\"horizontal retrace\") or the start of the screen (\"vertical retrace\"). The timing of the luminance signal must allow for this.\n\nThe human eye has a characteristic called Phi phenomenon. Quickly displaying successive scan images will allow the apparent illusion of smooth motion. Flickering of the image can be partially solved using a long persistence phosphor coating on the CRT, so that successive images fade slowly. However, slow phosphor has the negative side-effect of causing image smearing and blurring when there is a large amount of rapid on-screen motion occurring.\n\nThe maximum frame rate depends on the bandwidth of the electronics and the transmission system, and the number of horizontal scan lines in the image. A frame rate of 25 or 30 hertz is a satisfactory compromise, while the process of interlacing two video fields of the picture per frame is used to build the image. This process doubles the apparent number of video frames per second and further reduces flicker and other defects in transmission.\n\nPlasma screens and LCD screens have been used in analog television sets. These types of display screens use lower voltages than older CRT displays. Many dual system television receivers, equipped to receive both analog transmissions and digital transmissions have analog tuner receiving capability and must use a television antenna.\n\nThe television system for each country will specify a number of television channels within the UHF or VHF frequency ranges. A channel actually consists of two signals: the picture information is transmitted using amplitude modulation on one frequency, and the sound is transmitted with frequency modulation at a frequency at a fixed offset (typically 4.5 to 6 MHz) from the picture signal.\n\nThe channel frequencies chosen represent a compromise between allowing enough bandwidth for video (and hence satisfactory picture resolution), and allowing enough channels to be packed into the available frequency band. In practice a technique called vestigial sideband is used to reduce the channel spacing, which would be nearly twice the video bandwidth if pure AM was used.\n\nSignal reception is invariably done via a superheterodyne receiver: the first stage is a \"tuner\" which selects a television channel and frequency-shifts it to a fixed intermediate frequency (IF). The signal amplifier performs amplification to the IF stages from the microvolt range to fractions of a volt.\n\nAt this point the IF signal consists of a video carrier signal at one frequency and the sound carrier at a fixed offset. A demodulator recovers the video signal. Also at the output of the same demodulator is a new frequency modulated sound carrier at the offset frequency. In some sets made before 1948, this was filtered out, and the sound IF of about 22 MHz was sent to an FM demodulator to recover the basic sound signal. In newer sets, this new carrier at the offset frequency was allowed to remain as \"intercarrier sound\", and it was sent to an FM demodulator to recover the basic sound signal. One particular advantage of intercarrier sound is that when the front panel fine tuning knob is adjusted, the sound carrier frequency does not change with the tuning, but stays at the above-mentioned offset frequency. Consequently, it is easier to tune the picture without losing the sound.\n\nSo the FM sound carrier is then demodulated, amplified, and used to drive a loudspeaker. Until the advent of the NICAM and MTS systems, television sound transmissions were invariably monophonic.\n\nThe video carrier is demodulated to give a composite video signal; this contains luminance, chrominance and synchronization signals; this is identical to the video signal format used by analog video devices such as VCRs or CCTV cameras. Note that the RF signal modulation is inverted compared to the conventional AM: the minimum video signal level corresponds to maximum carrier amplitude, and vice versa. To ensure good linearity (fidelity), consistent with affordable manufacturing costs of transmitters and receivers, the video carrier is never shut off altogether. When intercarrier sound was invented later in 1948, not completely shutting off the carrier had the side effect of allowing intercarrier sound to be economically implemented.\n\nEach line of the displayed image is transmitted using a signal as shown above. The same basic format (with minor differences mainly related to timing and the encoding of color) is used for PAL, NTSC and SECAM television systems. A monochrome signal is identical to a color one, with the exception that the elements shown in color in the diagram (the color burst, and the chrominance signal) are not present.\nThe \"front porch\" is a brief (about 1.5 microsecond) period inserted between the end of each transmitted line of picture and the leading edge of the next line sync pulse. Its purpose was to allow voltage levels to stabilise in older televisions, preventing interference between picture lines. The \"front porch\" is the first component of the horizontal blanking interval which also contains the horizontal sync pulse and the \"back porch\".\n\nThe \"back porch\" is the portion of each scan line between the end (rising edge) of the horizontal sync pulse and the start of active video. It is used to restore the black level (300 mV) reference in analog video. In signal processing terms, it compensates for the fall time and settling time following the sync pulse.\n\nIn color television systems such as PAL and NTSC, this period also includes the colorburst signal. In the SECAM system it contains the reference subcarrier for each consecutive color difference signal in order to set the zero-color reference.\n\nIn some professional systems, particularly satellite links between locations, the audio is embedded within the back porch of the video signal, to save the cost of renting a second channel.\n\nThe luminance component of a composite video signal varies between 0 V and approximately 0.7 V above the \"black\" level. In the NTSC system, there is a \"blanking\" signal level used during the front porch and back porch, and a \"black\" signal level 75 mV above it; in PAL and SECAM these are identical.\n\nIn a monochrome receiver the luminance signal is amplified to drive the control grid in the electron gun of the CRT. This changes the intensity of the electron beam and therefore the brightness of the spot being scanned. Brightness and contrast controls determine the DC shift and amplification, respectively.\n\nA color signal conveys picture information for each of the red, green, and blue components of an image (see the article on color space for more information). However, these are not simply transmitted as three separate signals, because: such a signal would not be compatible with monochrome receivers (an important consideration when color broadcasting was first introduced). It would also occupy three times the bandwidth of existing television, requiring a decrease in the number of television channels available. Furthermore, typical problems with signal transmission (such as differing received signal levels between different colors) would produce unpleasant side effects.\n\nInstead, the RGB signals are converted into YUV form, where the Y signal represents the lightness and darkness (luminance) of the colors in the image. Because the rendering of colors in this way is the goal of both black and white (monochrome) film and black and white (monochrome) television systems, the Y signal is ideal for transmission as the luminance signal. This ensures a monochrome receiver will display a correct picture in black and white, where a given color is reproduced by a shade of gray that correctly reflects how light or dark the original color is.\n\nThe U and V signals are \"color difference\" signals. The U signal is the difference between the B signal and the Y signal, also known as B minus Y (B-Y), and the V signal is the difference between the R signal and the Y signal, also known as R minus Y (R-Y). The U signal then represents how \"purplish-blue\" or its complementary color \"yellowish-green\" the color is, and the V signal how \"purplish-red\" or its complementary \"greenish-cyan\" it is. The advantage of this scheme is that the U and V signals are zero when the picture has no color content. Since the human eye is more sensitive to errors in luminance than in color, the U and V signals can be transmitted in a relatively lossy (specifically: bandwidth-limited) way with acceptable results.\n\nIn the receiver, a single demodulator can extract an additive combination of U plus V. An example is the X demodulator used in the X/Z demodulation system. In that same system, a second demodulator, the Z demodulator, also extracts an additive combination of U plus V, but in a different ratio. The X and Z color difference signals are further matrixed into three color difference signals, (R-Y), (B-Y), and (G-Y). The combinations of usually two, but sometimes three demodulators were:\n\na) (I) / (Q), (as used in the 1954 RCA CTC-2 and the 1985 RCA \"Colortrak\" series, and the 1954 Arvin, and some professional color monitors in the 1990s),\n\nb) (R-Y) / (Q), as used in the 1955 RCA 21 inch color receiver,\n\nc) (R-Y) / (B-Y), used in the first color receiver on the market (Westinghouse, not RCA),\n\nd) (R-Y) / (G-Y), (as used in the RCA Victor CTC-4 chassis),\n\ne) (R-Y) / (B-Y) / (G-Y),\n\nf) (X) / (Z), as used in many receivers of the late 50's and throughout the 60's.\n\nIn the end, further matrixing of the above color-difference signals c through f yielded the three color-difference signals, (R-Y), (B-Y), and (G-Y).\n\nThe R,G,B signals in the receiver needed for the display device (CRT, Plasma display or LCD display) are electronically derived by matrixing as follows: R is the additive combination of (R-Y) with Y, G is the additive combination of (G-Y) with Y, and B is the additive combination of (B-Y) with Y. All of this is accomplished electronically. It can be seen that in the combining process, the low resolution portion of the Y signals cancel out, leaving R,G, and B signals able to render a low-resolution image in full color. However, the higher resolution portions of the Y signals do not cancel out, and so are equally present in R, G, and B, producing the higher definition (higher resolution) image detail in monochrome, although it appears to the human eye as a full-color and full resolution picture.\n\nIn the NTSC and PAL color systems, U and V are transmitted by using quadrature amplitude modulation of a subcarrier. This kind of modulation applies two independent signals to one subcarrier, with the idea that both signals will be recovered independently at the receive end. Before transmission, the subcarrier itself, is removed from the active (visible) portion of the video, and moved, in the form of a burst, to the horizontal blanking portion, which is not directly visible on screen. (More about the burst below.)\n\nFor NTSC, the subcarrier is a 3.58 MHz sine wave. For the PAL system it is a 4.43 MHz sine wave. After the above-mentioned quadrature amplitude modulation of the subcarrier, subcarrier sidebands are produced, and the subcarrier itself is filtered out of the visible portion of the video, since it is the subcarrier sidebands that carry all of the U and V information, and the subcarrier itself carries no information.\n\nThe resulting subcarrier sidebands is also known as \"chroma\" or \"chrominance\". Physically, this chrominance signal is a 3.58 MHz(NTSC) or 4.43 MHz(PAL) sine wave which, in response to changing U and V values, changes phase as compared to the subcarrier, and also changes amplitude.\n\nAs it turns out, the chroma amplitude (when considered together with the Y signal) represents the approximate saturation of a color, and the chroma phase against the subcarrier as reference, approximately represents the hue of the color. For particular test colors found in the test color bar pattern, exact amplitudes and phases are sometimes defined for test and trouble shooting purposes only.\n\nAlthough, in response to changing U and V values, the chroma sinewave changes phase with respect to the subcarrier, it's not correct to say that the subcarrier is simply \"phase modulated\". That is because a single sine wave U test signal with QAM produces only one pair of sidebands, whereas real phase modulation under the same test conditions would produce multiple sets of sidebands occupying more frequency spectrum.\n\nIn NTSC, the chrominance sine wave has the same average frequency as the subcarrier frequency. But a spectrum analyzer instrument shows that, for transmitted chrominance, the frequency component at the subcarrier frequency is actually zero energy, verifying that the subcarrier was indeed removed before transmission.\n\nThese sideband frequencies are within the luminance signal band, which is why they are called \"subcarrier\" sidebands instead of simply \"carrier\" sidebands. Their exact frequencies were chosen such that (for NTSC), they are midway between two harmonics of the frame repetition rate, thus ensuring that the majority of the power of the luminance signal does not overlap with the power of the chrominance signal.\n\nIn the British PAL (D) system, the actual chrominance center frequency, with equal lower and upper sidebands, is 4.43361875 MHz, a direct multiple of the scan rate frequency. This frequency was chosen to minimize the chrominance beat interference pattern that would be visible in areas of high color saturation in the transmitted picture.\n\nAt certain times, the chrominance signal represents only the U signal, and 70 nanoseconds (NTSC) later, the chrominance signal represents only the V signal. (This is the nature of the quadrature amplitude modulation process that created the chrominance signal.) About 70 nanoseconds later still, -U, and another 70 nanoseconds, -V.\n\nSo to extract U, a synchronous demodulator is utilized, which uses the subcarrier to briefly gate (sample) the chroma every 280 nanoseconds, so that the output is only a train of discrete pulses, each having an amplitude that is the same as the original U signal at the corresponding time. In effect, these pulses are discrete-time analog samples of the U signal. The pulses are then low-pass filtered so that the original analog continuous-time U signal is recovered. For V, a 90 degree shifted subcarrier briefly gates the chroma signal every 280 nanoseconds, and the rest of the process is identical to that used for the U signal.\n\nGating at any other time than those times mentioned above will yield an additive mixture of any two of U, V, -U, or -V. One of these \"off-axis\" (that is, off the U and V axis) gating methods is called I/Q demodulation. Another much more popular \"off-axis\" scheme was the X/Z demodulation system. Further matrixing recovered the original U and V signals. This scheme was actually the most popular demodulator scheme throughout the 60's.\n\nThe above process uses the subcarrier. But as previously mentioned, it was deleted before transmission, and only the chroma is transmitted. Therefore, the receiver must reconstitute the subcarrier. For this purpose, a short burst of subcarrier, known as the color burst, is transmitted during the back porch (re-trace blanking period) of each scan line. A subcarrier oscillator in the receiver locks onto this signal (see phase-locked loop) to achieve a phase reference, resulting in the oscillator producing the reconstituted subcarrier.\n\nNTSC uses this process unmodified. Unfortunately, this often results in poor color reproduction due to phase errors in the received signal, caused sometimes by multipath, but mostly by poor implementation at the studio end. With the advent of solid state receivers, cable TV, and digital studio equipment for conversion to an over-the-air analog signal, these NTSC problems have been largely fixed, leaving operator error at the studio end as the sole color rendition weakness of the NTSC system. In any case, the PAL D (delay) system mostly corrects these kind of errors by reversing the phase of the signal on each successive line, and the averaging the results over pairs of lines. This process is achieved by the use of a 1H (where H = horizontal scan frequency) duration delay line. (A typical circuit used with this device converts the low frequency color signal to ultrasound and back again). Phase shift errors between successive lines are therefore cancelled out and the wanted signal amplitude is increased when the two in-phase (coincident) signals are re-combined.\n\nNTSC is more spectrum efficient than PAL, giving more picture detail for a given bandwidth. This is because sophisticated comb filters in receivers are more effective with NTSC's 4 field color phase cadence compared to PAL's 8 field cadence. However, in the end, the larger channel width of most PAL systems in Europe still give their PAL systems the edge in transmitting more picture detail.\n\nIn the SECAM television system, U and V are transmitted on \"alternate\" lines, using simple frequency modulation of two different color subcarriers.\n\nIn some analog color CRT displays, starting in 1956, the brightness control signal (luminance) is fed to the cathode connections of the electron guns, and the color difference signals (chrominance signals) are fed to the control grids connections. This simple CRT matrix mixing technique was replaced in later solid state designs of signal processing with the original matrixing method used in the 1954 and 1955 color TV receivers.\n\nSynchronizing pulses added to the video signal at the end of every scan line and video frame ensure that the sweep oscillators in the receiver remain locked in step with the transmitted signal, so that the image can be reconstructed on the receiver screen.\n\nA \"sync separator\" circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync. (see section below – Other technical information, for extra detail.)\n\nThe horizontal synchronization pulse (\"horizontal sync\" \"HSYNC\"), separates the scan lines. The horizontal sync signal is a single short pulse which indicates the start of every line. The rest of the scan line follows, with the signal ranging from 0.3 V (black) to 1 V (white), until the next horizontal or vertical synchronization pulse.\n\nThe format of the horizontal sync pulse varies. In the 525-line NTSC system it is a 4.85 µs-long pulse at 0 V. In the 625-line PAL system the pulse is 4.7 µs synchronization pulse at 0 V . This is lower than the amplitude of any video signal (\"blacker than black\") so it can be detected by the level-sensitive \"sync stripper\" circuit of the receiver.\n\nVertical synchronization (Also \"vertical sync\" or \"VSYNC\") separates the video fields. In PAL and NTSC, the vertical sync pulse occurs within the vertical blanking interval. The vertical sync pulses are made by prolonging the length of HSYNC pulses through almost the entire length of the scan line.\n\nThe \"vertical sync\" signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole of line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or midway through).\n\nThe format of such a signal in 525-line NTSC is:\n\nEach pre- or post- equalizing pulse consists in half a scan line of black signal: 2 µs at 0 V, followed by 30 µs at 0.3 V.\n\nEach long sync pulse consists in an equalizing pulse with timings inverted: 30 µs at 0 V, followed by 2 µs at 0.3 V.\n\nIn video production and computer graphics, changes to the image are often kept in step with the vertical synchronization pulse to avoid visible discontinuity of the image. Since the frame buffer of a computer graphics display imitates the dynamics of a cathode-ray display, if it is updated with a new image while the image is being transmitted to the display, the display shows a mishmash of both frames, producing a page tearing artifact partway down the image.\n\nVertical synchronization eliminates this by timing frame buffer fills to coincide with the vertical blanking interval, thus ensuring that only whole frames are seen on-screen. Software such as video games and computer aided design (CAD) packages often allow vertical synchronization as an option, because it delays the image update until the vertical blanking interval. This produces a small penalty in latency, because the program has to wait until the video controller has finished transmitting the image to the display before continuing. Triple buffering reduces this latency significantly.\n\nTwo timing intervals are defined – the \"front porch\" between the end of displayed video and the start of the sync pulse, and the \"back porch\" after the sync pulse and before displayed video. These and the sync pulse itself are called the \"horizontal blanking\" (or \"retrace\") \"interval\" and represent the time that the electron beam in the CRT is returning to the start of the next display line.\n\nThe lack of precision timing components in early television receivers meant that the timebase circuits occasionally needed manual adjustment.\nIf their free-run frequencies were too far from the actual line and field rates, the circuits would not be able to follow the incoming sync signals.\nLoss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.\n\nThe adjustment took the form of \"horizontal hold\" and \"vertical hold\" controls, usually on the front panel along with other common controls. These adjusted the free-run frequencies of the corresponding timebase oscillators.\n\nBy the early 1980s the efficacy of the synchronization circuits, plus the inherent stability of the sets' oscillators, had been improved to the point where these controls were no longer necessary.\n\nA typical analog monochrome television receiver is based around the block diagram shown below:\n\nImage synchronization is achieved by transmitting negative-going pulses; in a composite video signal of 1 volt amplitude, these are approximately 0.3 V below the \"black level\". The \"horizontal sync\" signal is a single short pulse which indicates the start of every line. Two timing intervals are defined – the \"front porch\" between the end of displayed video and the start of the sync pulse, and the \"back porch\" after the sync pulse and before displayed video. These and the sync pulse itself are called the \"horizontal blanking\" (or \"retrace\") \"interval\" and represent the time that the electron beam in the CRT is returning to the start of the next display line.\n\nThe \"vertical sync\" signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole of line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or midway through).\n\nIn the television receiver, a \"sync separator\" circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync.\n\nLoss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.\n\nIn an analog receiver with a CRT display sync pulses are fed to horizontal and vertical \"timebase\" circuits (commonly called \"sweep circuits\" in the United States), each consisting of an oscillator and an amplifier. These generate modified sawtooth and parabola current waveforms to scan the electron beam in a linear way. The waveform shapes are necessary to make up for the distance variations from the electron beam source and the screen surface. The oscillators are designed to free-run at frequencies very close to the field and line rates, but the sync pulses cause them to reset at the beginning of each scan line or field, resulting in the necessary synchronization of the beam sweep with the originating signal. The output waveforms from the timebase amplifiers are fed to the horizontal and vertical \"deflection coils\" wrapped around the CRT tube. These coils produce magnetic fields proportional to the changing current, and these deflect the electron beam across the screen.\n\nIn the 1950s, the power for these circuits was derived directly from the mains supply.\nA simple circuit consisted of a series voltage dropper resistance and a rectifier valve (tube) or semiconductor diode. This avoided the cost of a large high voltage mains supply (50 or 60 Hz) transformer. This type of circuit was used for thermionic valve (tube) technology. It was inefficient and produced a lot of heat which led to premature failures in the circuitry.\n\nIn the 1960s, semiconductor technology was introduced into timebase circuits. During the late 1960s in the UK, synchronous (with the scan line rate) power generation was introduced into solid state receiver designs. These had very complex circuits in which faults were difficult to trace, but had very efficient use of power.\n\nIn the early 1970s AC mains (50 or 60 Hz), and line timebase (15,625 Hz), thyristor based switching circuits were introduced. In the UK use of the simple (50 Hz) types of power circuits were discontinued. The reason for design changes arose from the electricity supply contamination problems arising from EMI, and supply loading issues due to energy being taken from only the positive half cycle of the mains supply waveform.\n\nMost of the receiver's circuitry (at least in transistor- or IC-based designs) operates from a comparatively low-voltage DC power supply. However, the anode connection for a cathode-ray tube requires a very high voltage (typically 10–30 kV) for correct operation.\n\nThis voltage is not directly produced by the main power supply circuitry; instead the receiver makes use of the circuitry used for horizontal scanning. Direct current (DC), is switched though the line output transformer, and alternating current (AC) is induced into the scan coils. At the end of each horizontal scan line the magnetic field, which has built up in both transformer and scan coils by the current, is a source of latent electromagnetic energy. This stored collapsing magnetic field energy can be captured. The reverse flow, short duration, (about 10% of the line scan time) current from both the line output transformer and the horizontal scan coil is discharged again into the primary winding of the flyback transformer by the use of a rectifier which blocks this negative reverse emf. A small value capacitor is connected across the scan switching device. This tunes the circuit inductances to resonate at a much higher frequency. This slows down (lengthens) the flyback time from the extremely rapid decay rate that would result if they were electrically isolated during this short period. One of the secondary windings on the flyback transformer then feeds this brief high voltage pulse to a Cockcroft–Walton generator design voltage multiplier. This produces the required EHT supply. A flyback converter is a power supply circuit operating on similar principles.\n\nA typical modern design incorporates the flyback transformer and rectifier circuitry into a single unit with a captive output lead, (known as a diode split line output transformer or an Integrated High Voltage Transformer (IHVT)), so that all high-voltage parts are enclosed. Earlier designs used a separate line output transformer and a well insulated high voltage multiplier unit. The high frequency (15 kHz or so) of the horizontal scanning allows reasonably small components to be used.\n\nThe first country to make a wholesale switch to digital over-the-air (terrestrial television) broadcasting was Luxembourg in 2006, followed later in 2006 by the Netherlands; in 2007 by Finland, Andorra, Sweden and Switzerland; in 2008 by Belgium (Flanders) and Germany; in 2009 by the United States (high power stations), southern Canada, the Isle of Man, Norway, and Denmark. In 2010, Belgium (Wallonia), Spain, Wales, Latvia, Estonia, the Channel Islands, San Marino and Slovenia; in 2011 Israel, Austria, Monaco, Cyprus, Japan (excluding Miyagi, Iwate, and Fukushima prefectures), Malta and France; in 2012 the Czech Republic, Arab World, Taiwan, Portugal, Japan (including Miyagi, Iwate, and Fukushima prefectures), Serbia, Italy, Canada, Mauritius, the United Kingdom, the Republic of Ireland, Lithuania, Slovakia, Gibraltar, and South Korea; in 2013, the Republic of Macedonia, Poland, Bulgaria, Hungary, Australia, and New Zealand, completed the transition. The United Kingdom made the transition to digital television between 2008 and 2012, with the exception of Barrow-in-Furness, which made the switch over in 2007. The first digital TV-only area in the United Kingdom was Ferryside in Carmarthenshire.\n\nIn the United States, high-power over-the-air broadcasts are solely in the ATSC digital format since 12 June 2009, the date that the Federal Communications Commission (FCC) set for the end of all high-power analog television transmissions. As a result, almost two million households could no longer watch television because they had not prepared for the transition. The switchover was originally scheduled for 17 February 2009, until the U.S. Congress passed the DTV Delay Act. By special dispensation, some analog television signals ceased on the original date. While the majority of the viewers of over-the-air broadcast television in the U.S. watch full-power stations (which number about 1800), there are three other categories of television stations in the U.S.: low-power broadcasting stations, class A stations, and television translator stations. There is presently no deadline for these stations, about 7100 in number, to convert to digital broadcasting. In broadcasting, whatever happens in the United States also influences southern Canada and northern Mexico because those areas are covered by television stations in the U.S.\n\nIn Japan, the switch to digital occurred on the 24 July 2011, but in Fukushima, Iwate, and Miyagi prefectures, the conversion was delayed to 31 March 2012, due to complications from the 2011 Tōhoku earthquake and tsunami and its related nuclear accidents. In Canada, most of the larger cities turned off analog broadcasts on 31 August 2011. China is scheduled to end analog broadcasting between 2015 and 2018, due to the large size of the country.\n\nBrazil switched to digital television on 2 December 2007 in its major cities. It is now estimated that Brazil will end analog broadcasting in 2023.\n\nIn Malaysia, the Malaysian Communications & Multimedia Commission (MCMC) advertised for tender bids to be submitted in the third quarter of 2009 for the 470 through 742 MHz UHF allocation, to enable Malaysia's broadcast system to move into DTV. The new broadcast band allocation would result in Malaysia's having to build an infrastructure for all broadcasters, using a single digital terrestrial transmission/television broadcast (DTTB) channel. Large portions of Malaysia are covered by television broadcasts from Singapore, Thailand, Brunei, and Indonesia (from Borneo and Batam)\n\nIn the Philippines, the National Telecommunications Commission required all broadcasting companies to end analog broadcasting on December 31, 2015 at 11:59 p.m. Due to delay of the release of the implementing rules and regulations for digital television broadcast, the target date was moved to 2020. Full digital broadcast is expected in 2021.\n\n", "id": "2393", "title": "Analog television"}
{"url": "https://en.wikipedia.org/wiki?curid=2395", "text": "April 11\n\n\n\n", "id": "2395", "title": "April 11"}
{"url": "https://en.wikipedia.org/wiki?curid=2396", "text": "Adhesive\n\nAdhesive may be used interchangeably with glue, cement, mucilage, or paste, and is any substance applied to one surface, or both surfaces, of two separate items that binds them together and resists their separation. Adjectives may be used in conjunction with the word \"adhesive\" to describe properties based on the substance's physical or chemical form, the type of materials joined, or conditions under which it is applied.\n\nThe use of adhesives offers many advantages over binding techniques such as sewing, mechanical fastening, thermal bonding, etc. These include the ability to bind different materials together, to distribute stress more efficiently across the joint, the cost effectiveness of an easily mechanized process, an improvement in aesthetic design, and increased design flexibility. Disadvantages of adhesive use include decreased stability at high temperatures, relative weakness in bonding large objects with a small bonding surface area, and greater difficulty in separating objects during testing. Adhesives are typically organized by the method of adhesion. These are then organized into reactive and non-reactive adhesives, which refers to whether the adhesive chemically reacts in order to harden. Alternatively they can be organized by whether the raw stock is of natural or synthetic origin, or by their starting physical phase.\n\nAdhesives may be found naturally or produced synthetically. The earliest human use of adhesive-like substances was approximately 200,000 years ago. The first references to adhesives in literature first appeared in approximately 2000 BCE. The Greeks and Romans made great contributions to the development of adhesives. In Europe, glue was not widely used until the period 1500–1700 CE. From then until the 1900s increases in adhesive use and discovery were relatively gradual. Only since the last century has the development of synthetic adhesives accelerated rapidly, and innovation in the field continues to the present.\n\nThe earliest use of adhesives was discovered in central Italy when two stone flakes partially covered with birch-bark tar and a third uncovered stone from the Middle Pleistocene era (circa 200,000 years ago) were found. This is thought to be the oldest discovered human use of tar-hafted stones.\n\nThe birch-bark-tar adhesive is a simple, one-component adhesive. Although sticky enough, plant-based adhesives are brittle and vulnerable to environmental conditions. The first use of compound adhesives was discovered in Sibudu, South Africa. Here, 70,000-year-old stone segments that were once inserted in axe hafts were discovered covered with an adhesive composed of plant gum and red ochre (natural iron oxide) as adding ochre to plant gum produces a stronger product and protects the gum from disintegrating under wet conditions. The ability to produce stronger adhesives allowed middle stone age humans to attach stone segments to sticks in greater variations, which led to the development of new tools.\n\nMore recent examples of adhesive use by prehistoric humans have been found at the burial sites of ancient tribes. Archaeologists studying the sites found that approximately 6,000 years ago the tribesmen had buried their dead together with food found in broken clay pots repaired with tree resins. Another investigation by archaeologists uncovered the use of bituminous cements to fasten ivory eyeballs to statues in Babylonian temples dating to approximately 4000 BCE\n\nIn 2000, a paper revealed the discovery of a 5,200-year-old man nicknamed the \"Tyrolean Iceman\" or \"Ötzi\", who was preserved in a glacier near the Austria-Italy border. Several of his belongings were found with him including two arrows with flint arrowheads and a copper hatchet, each with evidence of organic glue used to connect the stone or metal parts to the wooden shafts. The glue was analyzed as pitch, which requires the heating of tar during its production. The retrieval of this tar requires a transformation of birch bark by means of heat, in a process known as pyrolysis. \n\nThe first references to adhesives in literature first appeared in approximately 2000 BCE. Further historical records of adhesive use are found from the period spanning 1500–1000 BCE. Artifacts from this period include paintings depicting wood gluing operations and a casket made of wood and glue in King Tutankhamun's tomb. Other ancient Egyptian artifacts employ animal glue for bonding or lamination. Such lamination of wood for bows and furniture is thought to have extended their life and was accomplished using casein (milk protein)-based glues. The ancient Egyptians also developed starch-based pastes for the bonding of papyrus to clothing and a plaster of Paris-like material made of calcined gypsum.\n\nFrom 1 to 500 AD the Greeks and Romans made great contributions to the development of adhesives. Wood veneering and marquetry were developed, the production of animal and fish glues refined, and other materials utilized. Egg-based pastes were used to bond gold leaves incorporated various natural ingredients such as blood, bone, hide, milk, cheese, vegetables, and grains. The Greeks began the use of slaked lime as mortar while the Romans furthered mortar development by mixing lime with volcanic ash and sand. This material, known as pozzolanic cement, was used in the construction of the Roman Colosseum and Pantheon. The Romans were also the first people known to have used tar and beeswax as caulk and sealant between the wooden planks of their boats and ships.\n\nIn Central Asia, the rise of the Mongols in approximately 1000 AD can be partially attributed to the good range and power of the bows of Genghis Khan's hordes. These bows were constructed with laminated lemonwood and bullhorn bonded by an unknown adhesive.\n\nIn Europe, glue fell into disuse until the period 1500–1700 AD. At this time, world-renowned cabinet and furniture makers such as Chippendale and Duncan Phyfe began to use adhesives to hold their products together.\n\nThe development of modern adhesives began in 1690 with the founding of the first commercial glue plant in Holland. This plant produced glues from animal hides.\n\nIn 1750, the first British glue patent was issued for fish glue. The following decades of the next century witnessed the manufacture of casein glues in German and Swiss factories. In 1876, the first US patent (number 183,024) was issued to the Ross brothers for the production of casein glue.\n\nThe first US postage stamps used starch-based adhesives when issued in 1840. The first US patent (number 61,991) on dextrin (a starch derivative) adhesive was issued in 1867.\n\nNatural rubber was first used as material for adhesives starting in 1830. In 1839, Charles Goodyear discovered that a rubber and sulfur mixture, when heated, becomes elastic. In 1843, Thomas Hancock named this process vulcanization. In 1862, a British patent (number 3288) was issued for the plating of metal with brass by electrodeposition to obtain a stronger bond to rubber. The development of the automobile and the need for rubber shock mounts required stronger and more durable bonds of rubber and metal. This spurred the development of cyclized rubber treated in strong acids. By 1927, this process was used to produce solvent-based thermoplastic rubber cements for metal to rubber bonding.\n\nNatural rubber-based sticky adhesives were first used on a backing by Henry Day (US Patent 3,965) in 1845. Later these kinds of adhesives were used in cloth backed surgical and electric tapes. By 1925, the pressure-sensitive tape industry was born.\nToday, sticky notes, Scotch tape, and other tapes are examples of PSA (pressure-sensitive adhesives).\n\nA key step in the development of synthetic plastics was the introduction of a thermoset plastic known as Bakelite phenolic in 1910. Within two years, phenolic resin was applied to plywood as a coating varnish. In the early 1930s, phenolics gained importance as adhesive resins.\n\nThe 1920s, 1930s, and 1940s witnessed great advances in the development and production of new plastics and resins due to the First and Second World Wars. These advances greatly improved the development of adhesives by allowing the use of newly developed materials that exhibited a variety of properties. With changing needs and ever evolving technology, the development of new synthetic adhesives continues to the present. However, due to their low cost, natural adhesives are still more commonly used.\n\nIn the course of time and during their development, adhesives have gained a stable position in an increasing number of production processes. There is hardly any product in our surroundings that does not contain at least one adhesive—be it the label on a beverage bottle, protective coatings on automobiles, or profiles on window frames. Market researchers forecast a turnover of almost US$50 billion for the global adhesives market in 2019. In particular, the economic development of emerging countries such as China, India, Russia, and Brazil will cause a rising demand for adhesives in the future.\n\nAdhesives are typically organized by the method of adhesion. These are then organized into reactive and non-reactive adhesives, which refers to whether the adhesive chemically reacts in order to harden. Alternatively they can be organized by whether the raw stock is of natural, or synthetic origin, or by their starting physical phase.\n\nThere are two types of adhesives that harden by drying: \"solvent-based adhesives\" and \"polymer dispersion adhesives\", also known as \"emulsion adhesives\". \nSolvent-based adhesives are a mixture of ingredients (typically polymers) dissolved in a solvent. White glue, contact adhesives and rubber cements are members of the \"drying adhesive\" family. As the solvent evaporates, the adhesive hardens. Depending on the chemical composition of the adhesive, they will adhere to different materials to greater or lesser degrees.\n\nPolymer dispersion adhesives are milky-white dispersions often based on polyvinyl acetate (PVAc). They are used extensively in the woodworking and packaging industries. They are also used with fabrics and fabric-based components, and in engineered products such as loudspeaker cones.\n\n\"Pressure-sensitive adhesives\" (PSA) form a bond by the application of light pressure to marry the adhesive with the adherend. They are designed to have a balance between flow and resistance to flow. The bond forms because the adhesive is soft enough to flow (i.e., \"wet\") to the adherend. The bond has strength because the adhesive is hard enough to resist flow when stress is applied to the bond. Once the adhesive and the adherend are in close proximity, molecular interactions, such as van der Waals forces, become involved in the bond, contributing significantly to its ultimate strength.\n\nPSAs are designed for either permanent or removable applications. Examples of permanent applications include safety labels for power equipment, foil tape for HVAC duct work, automotive interior trim assembly, and sound/vibration damping films. Some high performance permanent PSAs exhibit high adhesion values and can support kilograms of weight per square centimeter of contact area, even at elevated temperatures. Permanent PSAs may initially be removable (for example to recover mislabeled goods) and build adhesion to a permanent bond after several hours or days.\n\nRemovable adhesives are designed to form a temporary bond, and ideally can be removed after months or years without leaving residue on the adherend. Removable adhesives are used in applications such as surface protection films, masking tapes, bookmark and note papers, barcodes labels, price marking labels, promotional graphics materials, and for skin contact (wound care dressings, EKG electrodes, athletic tape, analgesic and transdermal drug patches, etc.). Some removable adhesives are designed to repeatedly stick and unstick. They have low adhesion, and generally cannot support much weight. Pressure-sensitive adhesive is used in Post-it notes.\n\nPressure-sensitive adhesives are manufactured with either a liquid carrier or in 100% solid form. Articles are made from liquid PSAs by coating the adhesive and drying off the solvent or water carrier. They may be further heated to initiate a cross-linking reaction and increase molecular weight. 100% solid PSAs may be low viscosity polymers that are coated and then reacted with radiation to increase molecular weight and form the adhesive, or they may be high viscosity materials that are heated to reduce viscosity enough to allow coating, and then cooled to their final form. Major raw material for PSA's are acrylate-based polymers.\n\n\"Contact adhesives\" are used in strong bonds with high shear-resistance like laminates, such as bonding Formica to a wooden counter, and in footwear, as in attaching outsoles to uppers.\n\nNatural rubber and polychloroprene (Neoprene) are commonly used contact adhesives. Both of these elastomers undergo strain crystallization. In the construction industry a specialised proprietary adhesive known as \"liquid nails\" is used. This also copes with tasks such as sealing artificial turf.\n\nContact adhesives must be applied to both surfaces and allowed some time to dry before the two surfaces are pushed together. Some contact adhesives require as long as 24 hours to dry before the surfaces are to be held together. Once the surfaces are pushed together, the bond forms very quickly. It is usually not necessary to apply pressure for a long time, so there is less need for clamps.\n\n\"Hot adhesives\", also known as \"hot melt adhesives\", are thermoplastics applied in molten form (in the 65–180 °C range) which solidify on cooling to form strong bonds between a wide range of materials. Ethylene-vinyl acetate-based hot-melts are particularly popular for crafts because of their ease of use and the wide range of common materials they can join. A glue gun (shown at right) is one method of applying hot adhesives. The glue gun melts the solid adhesive, then allows the liquid to pass through its barrel onto the material, where it solidifies.\n\nThermoplastic glue may have been invented around 1940 by Procter & Gamble as a solution to the problem that water-based adhesives, commonly used in packaging at that time, failed in humid climates, causing packages to open.\n\n\"Multi-component adhesives\" harden by mixing two or more components which chemically react. This reaction causes polymers to cross-link into acrylics, urethanes, and epoxies - See thermosetting polymers.\n\nThere are several commercial combinations of multi-component adhesives in use in industry. Some of these combinations are:\n\nThe individual components of a multi-component adhesive are not adhesive by nature. The individual components react with each other after being mixed and show full adhesion only on curing. The multi-component resins can be either solvent-based or solvent-less. The solvents present in the adhesives are a medium for the polyester or the polyurethane resin. The solvent is dried during the curing process.\n\n\"One-part adhesives\" harden via a chemical reaction with an external energy source, such as radiation, heat, and moisture.\n\n\"Ultraviolet\" (UV) \"light curing adhesives\", also known as \"light curing materials\" (LCM), have become popular within the manufacturing sector due to their rapid curing time and strong bond strength. Light curing adhesives can cure in as little as a second and many formulations can bond dissimilar substrates (materials) and withstand harsh temperatures. These qualities make UV curing adhesives essential to the manufacturing of items in many industrial markets such as electronics, telecommunications, medical, aerospace, glass, and optical. Unlike traditional adhesives, UV light curing adhesives not only bond materials together but they can also be used to seal and coat products. They are generally acrylic-based.\n\n\"Heat curing adhesives\" consist of a pre-made mixture of two or more components. When heat is applied the components react and cross-link. This type of adhesive includes thermoset epoxies, urethanes, and polyimides.\n\n\"Moisture curing adhesives\" cure when they react with moisture present on the substrate surface or in the air. This type of adhesive includes cyanoacrylates and urethanes.\n\nNatural adhesives are made from organic sources such as vegetable starch (dextrin), natural resins, or animals (e.g. the milk protein casein and hide-based animal glues). These are often referred to as bioadhesives.\n\nOne example is a simple paste made by cooking flour in water. Starch-based adhesives are used in corrugated board and paper sack production, paper tube winding, and wallpaper adhesives. Casein glue is mainly used to adhere glass bottle labels. Animal glues have traditionally been used in bookbinding, wood joining, and many other areas but now are largely replaced by synthetic glues except in specialist applications like the production and repair of stringed instruments. Albumen made from the protein component of blood has been used in the plywood industry. Masonite, a wood hardboard, was originally bonded using natural wood lignin, an organic polymer, though most modern particle boards such as MDF use synthetic thermosetting resins.\n\nSynthetic adhesives are based on elastomers, thermoplastics, emulsions, and thermosets. Examples of thermosetting adhesives are: epoxy, polyurethane, cyanoacrylate and acrylic polymers. The first commercially produced synthetic adhesive was Karlsons Klister in the 1920s.\n\nApplicators of different adhesives are designed according to the adhesive being used and the size of the area to which the adhesive will be applied. The adhesive is applied to either one or both of the materials being bonded. The pieces are aligned and pressure is added to aid in adhesion and rid the bond of air bubbles.\n\nCommon ways of applying an adhesive include brushes, rollers, using films or pellets, spray guns and applicator guns (\"e.g.\", caulk gun). All of these can be used manually or automated as part of a machine.\n\nFor an adhesive to be effective it must have three main properties. It must be able to wet the substrate. It must harden and finally it must be able to transmit load between the two surfaces/substrates being adhered.\n\nAdhesion, the attachment between adhesive and substrate may occur either by mechanical means, in which the adhesive works its way into small pores of the substrate, or by one of several chemical mechanisms. The strength of adhesion depends on many factors, including the means by which it occurs.\n\nIn some cases, an actual chemical bond occurs between adhesive and substrate. In others, electrostatic forces, as in static electricity, hold the substances together. A third mechanism involves the van der Waals forces that develop between molecules. A fourth means involves the moisture-aided diffusion of the glue into the substrate, followed by hardening.\n\nThe quality of adhesive bonding depends strongly on the ability of the adhesive to efficiency cover (wet) the substrate area. This happens when the surface energy of the substrate is greater than the surface energy of the adhesive. However, high strength adhesives have high surface energy. Thus, their application is problematic for low energy materials such as polymers. To solve this problem, surface treatment can be used to increase the surface energy as a preparation step before adhesive bonding. Importantly, surface preparation provides a reproducible surface allowing consistent bonding results. The commonly used surface activation techniques include plasma activation, flame treatment and wet chemistry priming.\n\nThere are several factors that could contribute to the failure of two adhered surfaces. Sunlight and heat may weaken the adhesive. Solvents can deteriorate or dissolve adhesive. Physical stresses may also cause the separation of surfaces. When subjected to loading, debonding may occur at different locations in the adhesive joint. The major fracture types are the following:\n\n\"Cohesive fracture\" is obtained if a crack propagates in the bulk polymer which constitutes the adhesive. In this case the surfaces of both adherends after debonding will be covered by fractured adhesive. The crack may propagate in the center of the layer or near an interface. For this last case, the cohesive fracture can be said to be \"cohesive near the interface\".\n\n\"Adhesive fracture\" (sometimes referred to as \"interfacial fracture\") is when debonding occurs between the adhesive and the adherend. In most cases, the occurrence of adhesive fracture for a given adhesive goes along with smaller fracture toughness.\n\nOther types of fracture include:\n\n\nAs a general design rule, the material properties of the object need to be greater than the forces anticipated during its use. (i.e. geometry, loads, etc.). The engineering work will consist of having a good model to evaluate the function. For most adhesive joints, this can be achieved using fracture mechanics. Concepts such as the stress concentration factor and the strain energy release rate can be used to predict failure. In such models, the behavior of the adhesive layer itself is neglected and only the adherents are considered.\n\nFailure will also very much depend on the opening \"mode\" of the joint.\n\nAs the loads are usually fixed, an acceptable design will result from combination of a material selection procedure and geometry modifications, if possible. In adhesively bonded structures, the global geometry and loads are fixed by structural considerations and the design procedure focuses on the material properties of the adhesive and on local changes on the geometry.\n\nIncreasing the joint resistance is usually obtained by designing its geometry so that:\n\nSome glues and adhesives have a limited shelf life. Exposure to heat, oxygen, water vapor, etc. can degrade the adhesive over time, preventing it from functioning properly.\n\n\n\n", "id": "2396", "title": "Adhesive"}
{"url": "https://en.wikipedia.org/wiki?curid=2397", "text": "Anthony Hopkins\n\nSir Philip Anthony Hopkins (born 31 December 1937), is a Welsh actor of film, stage, and television. After graduating from the Royal Welsh College of Music & Drama in 1957, he trained at the Royal Academy of Dramatic Art in London, and was then spotted by Laurence Olivier who invited him to join the Royal National Theatre. In 1968, he got his break in film in \"The Lion in Winter\", playing Richard the Lionheart.\n\nConsidered to be one of the greatest living actors, Hopkins is well known for his portrayal of Hannibal Lecter in \"The Silence of the Lambs\", for which he won the Academy Award for Best Actor, its sequel \"Hannibal\", and the prequel \"Red Dragon\". Other notable films include \"The Mask of Zorro\", \"The Bounty\", \"Meet Joe Black\", \"The Elephant Man\", \"Magic\", \"84 Charing Cross Road\", \"Bram Stoker's Dracula\", \"Legends of the Fall\", \"Thor\", \"The Remains of the Day\", \"Amistad\", \"Nixon\", \"The World's Fastest Indian\", \"Instinct\", \"Fracture\", and \"The Dresser\". Since 2016, he has starred in the critically acclaimed HBO television series \"Westworld\".\n\nAlong with his Academy Award, Hopkins has won three BAFTA Awards, two Emmys, and the Cecil B. DeMille Award. In 1993, he was knighted by Queen Elizabeth II for services to the arts. He received a star on the Hollywood Walk of Fame in 2003, and was made a Fellow of the British Academy of Film and Television Arts in 2008.\n\nHopkins was born on New Year's Eve 1937, in Margam, a suburb of Port Talbot, Glamorgan. His parents were Annie Muriel (\"née\" Yeates) and Richard Arthur Hopkins, a baker. His school days were unproductive; he would rather immerse himself in art, such as painting and drawing, or playing the piano, than attend to his studies. In 1949, to instill discipline, his parents insisted he attend Jones' West Monmouth Boys' School in Pontypool. He remained there for five terms and was then educated at Cowbridge Grammar School in the Vale of Glamorgan.\n\nHopkins was influenced and encouraged by Welsh compatriot Richard Burton, whom he met at the age of 15. Hopkins promptly enrolled at the Royal Welsh College of Music & Drama in Cardiff, from which he graduated in 1957. After two years in the British Army doing his national service, he moved to London, where he trained at the Royal Academy of Dramatic Art.\n\nHopkins made his first professional stage appearance in the Palace Theatre, Swansea, in 1960 with Swansea Little Theatre's production of \"Have a Cigarette\". In 1965, after several years in repertory, he was spotted by Laurence Olivier, who invited him to join the Royal National Theatre in London. Hopkins became Olivier's understudy, and filled in when Olivier was struck with appendicitis during a production of August Strindberg's \"The Dance of Death\". Olivier later noted in his memoir, \"Confessions of an Actor\", that \"A new young actor in the company of exceptional promise named Anthony Hopkins was understudying me and walked away with the part of Edgar like a cat with a mouse between its teeth.\"\n\nDespite his success at the National, Hopkins tired of repeating the same roles nightly and yearned to be in films. He made his small-screen debut in a 1967 BBC broadcast of \"A Flea in Her Ear\". His first starring role in a film came in 1964 in \"Changes\", a short directed by Drewe Henley, written and produced by James Scott and co-starring Jacqueline Pearce. In 1968, he got his break in \"The Lion in Winter\" playing Richard I. Although Hopkins continued in theatre (most notably at the National Theatre as Lambert Le Roux in \"Pravda\" by David Hare and Howard Brenton and as Antony in \"Antony and Cleopatra\" opposite Judi Dench as well as in the Broadway production of Peter Shaffer's \"Equus\") he gradually moved away from it to become more established as a television and film actor. He portrayed Charles Dickens in the BBC television film \"The Great Inimitable Mr. Dickens\" in 1970, and Pierre Bezukhov in the BBC's mini series \"War and Peace\" (1972). In 1972 he starred as British politician David Lloyd George in \"Young Winston\", and in 1977 he played British Army officer John Frost in Richard Attenborough's World War II-set film \"A Bridge Too Far\".\n\nIn 1980, he starred in \"The Elephant Man\" as the English doctor Sir Frederick Treves, who attends to Joseph Merrick (portrayed by John Hurt), a severely deformed man in 19th century London. That year he also starred opposite Shirley MacLaine in \"A Change of Seasons\" and famously said \"she was the most obnoxious actress I have ever worked with.\"\n\nIn 1983, Hopkins also became a company member of The Mirror Theater Ltd's Repertory Company.\nHe remained an enthusiastic member of the company and the Mirror’s Producing Artistic Director Sabra Jones visited him in London in 1986 to discuss moving \"Pravda\" to New York from the National Theater. In 1984, he starred opposite Mel Gibson in \"The Bounty\" as William Bligh, captain of the Royal Navy ship the HMS \"Bounty\", in a retelling of the mutiny on the \"Bounty\". In 1992, Hopkins portrayed Abraham Van Helsing in Francis Ford Coppola's \"Bram Stoker's Dracula\".\n\nSet in 1950s post-war Britain, Hopkins starred opposite Emma Thompson in the critically acclaimed \"The Remains of the Day\" (1993). Hopkins was nominated for an Academy Award for Best Actor for his performance, and the film frequently ranks among the best British films of all time. Hopkins portrayed Oxford academic C. S. Lewis in the 1993 British biographical film \"Shadowlands\", and received the BAFTA Award for Best Actor. During the 1990s, Hopkins had the chance to work with Bart the Bear in two films: \"Legends of the Fall\" (1994) and \"The Edge\" (1997). According to trainer, Lynn Seus, \"Tony Hopkins was absolutely brilliant with Bart...He acknowledged and respected him like a fellow actor. He would spend hours just looking at Bart and admiring him. He did so many of his own scenes with Bart.\"\n\nHopkins was Britain's highest paid performer in 1998, starring in \"The Mask of Zorro\" and \"Meet Joe Black\", and also agreed to reprise his role as Dr Hannibal Lecter for a fee of £15 million. In 2000, Hopkins narrated \"Dr. Seuss' How the Grinch Stole Christmas\". Hopkins received a star on the Hollywood Walk of Fame in 2003.\n\nHopkins stated that his role as Burt Munro, whom he portrayed in his 2005 film \"The World's Fastest Indian\", was his favourite. He also asserted that Munro was the easiest role that he had played because both men have a similar outlook on life. In 2006, Hopkins was the recipient of the Golden Globe Cecil B. DeMille Award for lifetime achievement. In 2008, he received the BAFTA Academy Fellowship Award, the highest award the British Film Academy can bestow.\n\nOn 24 February 2010, it was announced that Hopkins had been cast in \"The Rite\", which was released on 28 January 2011. He played a priest who is \"an expert in exorcisms and whose methods are not necessarily traditional\". Hopkins, who is quoted as saying \"I don't know what I believe, myself personally\", reportedly wrote a line--\"Some days I don't know if I believe in God or Santa Claus or Tinkerbell\"—into his character in order to identify with it. On the other hand, in other sources from the same time, he is quoted as saying that he did believe in God and had done so for decades. On 21 September 2011, Peter R. de Vries named Hopkins in the role of the Heineken owner Freddy Heineken in a future film about his kidnapping.\n\nHopkins portrayed Odin, the Allfather or \"king\" of Asgard, in the 2011 film adaptation of Marvel Comics' \"Thor\". Hopkins portrayed Alfred Hitchcock in Sacha Gervasi's biopic \"Hitchcock\", following his career while making \"Psycho\". The film was released on 23 November 2012. In 2013, he reprised his role as Odin in \"\". In 2014, he portrayed Methuselah in Darren Aronofsky's \"Noah\". Since October 2016, Hopkins has been starring as Robert Ford in the HBO sci-fi series \"Westworld\". In June 2016, Hopkins was confirmed to star as Sir Edmund Burton in \"\" which is set to be released in June 2017.\n\nHopkins' most famous role is as the cannibalistic serial killer Hannibal Lecter in \"The Silence of the Lambs\", for which he won the Academy Award for Best Actor in 1991, with Jodie Foster as Clarice Starling, who also won for Best Actress. The film won Best Picture, Best Director and Academy Award for Best Adapted Screenplay. Hopkins reprised his role as Lecter twice; in Ridley Scott's \"Hannibal\" (2001), and \"Red Dragon\" (2002). His original portrayal of the character in \"The Silence of the Lambs\" has been labelled by the AFI as the number-one film villain. At the time he was offered the role, Hopkins was making a return to the London stage, performing in \"M. Butterfly\". He had come back to Britain after living for a number of years in Hollywood, having all but given up on a career there, saying, \"Well that part of my life's over; it's a chapter closed. I suppose I'll just have to settle for being a respectable actor poncing around the West End and doing respectable BBC work for the rest of my life.\"\n\nHopkins played the iconic villain in adaptations of the first three of the Lecter novels by Thomas Harris. The author was reportedly very pleased with Hopkins' portrayal of his antagonist. However, Hopkins stated that \"Red Dragon\" would feature his final performance as the character, and that he would not reprise even a narrative role in the latest addition to the series, \"Hannibal Rising\".\n\nHopkins is renowned for his preparation for roles. He indicated in interviews that once he has committed to a project, he will go over his lines as many times as is needed (sometimes upwards of 200) until the lines sound natural to him, so that he can \"do it without thinking\". This leads to an almost casual style of delivery that belies the amount of groundwork done beforehand. While it can allow for some careful improvisation, it has also brought him into conflict with the occasional director who departs from the script, or demands what the actor views as an excessive number of takes. Hopkins has stated that after he is finished with a scene, he simply discards the lines, not remembering them later on. This is unlike others who usually remember their lines from a film, even years later.\n\nRichard Attenborough, who directed Hopkins on five occasions, found himself going to great lengths during the filming of \"Shadowlands\" (1993) to accommodate the differing approaches of his two stars (Hopkins and Debra Winger), who shared many scenes. Whereas Hopkins, preferring the spontaneity of a fresh take, liked to keep rehearsals to a minimum, Winger rehearsed continuously. To allow for this, Attenborough stood in for Hopkins during Winger's rehearsals, only bringing him in for the last one before a take. The director praised Hopkins for \"this extraordinary ability to make you believe when you hear him that it is the very first time he has ever said that line. It's an incredible gift.\"\n\nRenowned for his ability to remember lines, Hopkins keeps his memory supple by learning things by heart such as poetry, and Shakespeare. In Steven Spielberg's \"Amistad\", Hopkins astounded the crew with his memorisation of a seven-page courtroom speech, delivering it in one go. An overawed Spielberg couldn't bring himself to call him Tony, and insisted on addressing him as Sir Anthony throughout the shoot.\n\nHopkins is a gifted mimic, adept at turning his native Welsh accent into whatever is required by a character. He duplicated the voice of his late mentor, Laurence Olivier, for additional scenes in \"Spartacus\" in its 1991 restoration. His interview on the 1998 relaunch edition of the British TV talk show \"Parkinson\" featured an impersonation of comedian Tommy Cooper. Hopkins has said acting \"like a submarine\" has helped him to deliver credible performances in his thriller movies. He said, \"It's very difficult for an actor to avoid, you want to show a bit. But I think the less one shows the better.\"\n\nAnthony Hopkins was made a Commander of the Order of the British Empire (CBE) in 1987, and was knighted as a Knight Bachelor at Buckingham Palace in 1993 for services to the arts. In 1988, Hopkins was made an Honorary D.Litt and in 1992 was awarded Honorary fellowship from the University of Wales, Lampeter. He was made a freeman of his hometown Port Talbot in 1996.\n\nHopkins resides in Malibu, California. He had moved to the US once before during the late 1970s to pursue his film career, but returned to London in the late 1980s. However, he decided to return to the US following his 1990s success. Retaining his British citizenship, he became a naturalised US citizen on 12 April 2000, with Hopkins stating: \"I have dual citizenship, it just so happens I live in America\".\n\nHopkins has been married three times. His first two wives were Petronella Barker from 1966 to 1972, and Jennifer Lynton from 1973 to 2002. He has a daughter from his first marriage, actress and singer Abigail Hopkins (born 20 August 1968). He married Stella Arroyave in 2003. On Christmas Eve 2012, he celebrated his 10th wedding anniversary by having a blessing at a private service at St David's Cathedral, Pembrokeshire in the most westerly point of Wales.\n\nHopkins is a recovering alcoholic; he stopped drinking just after Christmas 1975. He said that a major help in his recovery was his belief in God. He has criticised atheism, saying in 2011 that \"being an atheist must be like living in a closed cell with no windows\". In an interview with Larry King in 2016, Hopkins described himself as an agnostic and said he believed in a \"superior consciousness in all of us\". He gave up smoking using the Allen Carr method. In 2008, he embarked on a weight loss programme, and by 2010, he had lost 80 pounds.\n\nIn January 2017, in an interview with \"The Desert Sun\", Hopkins reported that he had been diagnosed with Asperger syndrome, but that he was \"high end\".\n\nHopkins has offered his support to various charities and appeals, notably becoming President of the National Trust's Snowdonia Appeal, raising funds for the preservation of Snowdonia National Park in north Wales. In 1998 he donated £1 million towards the £3 million needed to aid the Trust's efforts in purchasing parts of Snowdon. Prior to the campaign, Hopkins authored \"Anthony Hopkins' Snowdonia\", which was published in 1995. Due to his contributions to Snowdonia, in addition to his film career, in 2004 Hopkins was named among the 100 Welsh Heroes in a Welsh poll.\n\nHopkins has been a patron of the YMCA centre in his hometown of Port Talbot, South Wales for more than 20 years, having first joined the YMCA in the 1950s. He supports other various philanthropic groups. He was a Guest of Honour at a Gala Fundraiser for Women in Recovery, Inc., a Venice, California-based non-profit organisation offering rehabilitation assistance to women in recovery from substance abuse. He is also a volunteer teacher at the Ruskin School of Acting in Santa Monica, California. Hopkins served as the Honorary Patron of The New Heritage Theatre Company in Boise, Idaho from 1997-2007, participating in fundraising and marketing efforts for the repertory theatre.\n\nHopkins contributed toward the refurbishment of a £2.3 million wing at his alma mater, the Royal Welsh College of Music & Drama in Cardiff, named the Anthony Hopkins Centre. It opened in 1999.\n\nHopkins is a prominent member of environmental protection group Greenpeace and as of early 2008 featured in a television advertisement campaign, voicing concerns about Japan's continuing annual whale hunt. He has also been a patron of RAPt (Rehabilitation for Addicted Prisoners Trust) since its early days and helped open their first intensive drug and alcohol rehabilitation unit at Downview (HM Prison) in 1992.\n\nHopkins is an admirer of the Welsh comedian Tommy Cooper. On 23 February 2008, as patron of the Tommy Cooper Society, he unveiled a commemorative statue in the entertainer's home town of Caerphilly. For the ceremony, he donned Cooper's trademark fez and performed a comic routine.\n\nIn a 2012 interview, Hopkins stated, \"I've been composing music all my life and if I'd been clever enough at school I would like to have gone to music college. As it was I had to settle for being an actor.\" In 1986, he released a single called \"Distant Star\", which peaked at No. 75 in the UK Singles Chart. In 2007, he announced he would retire temporarily from the screen to tour around the world. Hopkins has also written music for the concert hall, in collaboration with Stephen Barton as orchestrator. These compositions include \"The Masque of Time\", given its world premiere with the Dallas Symphony Orchestra in October 2008, and \"Schizoid Salsa\".\n\nIn 1990, Hopkins directed a film about his Welsh compatriot, poet Dylan Thomas, titled \"Dylan Thomas: Return Journey\", which was his directing debut for the screen. In the same year, as part of the restoration process for the Stanley Kubrick film \"Spartacus\", Hopkins was approached to re-record lines from a scene that was being added back to the film; this scene featured Laurence Olivier and Tony Curtis, with Hopkins recommended by Olivier's widow, Joan Plowright to perform her late husband's part thanks to his talent for mimicry.\n\nIn 1996, he directed \"August\", an adaptation of Chekhov's \"Uncle Vanya\" set in Wales. His first screenplay, an experimental drama called \"Slipstream\", which he also directed and scored, premiered at the Sundance Film Festival in 2007. In 1997, Hopkins narrated the BBC natural documentary series, \"Killing for a Living\", which showed predatory behaviour in nature. He narrated episode 1 through 3 before being replaced by John Shrapnel.\n\nHopkins is a fan of the BBC sitcom \"Only Fools and Horses\", and once remarked in an interview how he would love to appear in the series. Writer John Sullivan saw the interview, and with Hopkins in mind created the character Danny Driscoll, a local villain. However, filming of the new series coincided with the filming of \"The Silence of the Lambs\", making Hopkins unavailable. The role instead went to Roy Marsden.\n\nOn 31 October 2011, André Rieu released an album including a waltz which Hopkins had composed in 1964, at the age of 27. Hopkins had never heard his composition, \"And the Waltz Goes On\", before it was premiered by Rieu's orchestra in Vienna; Rieu's album was given the same name as Hopkins' piece.\n\nIn January 2012, Hopkins released an album of classical music, entitled \"Composer\", performed by the City of Birmingham Symphony Orchestra, and released on CD via the UK radio station Classic FM. The album consists of nine of his original works and film scores, with one of the pieces titled \"Margam\" in tribute to his home town near Port Talbot in Wales.\n\nIn October 2015, Hopkins appeared as Sir in a BBC Two production of Ronald Harwood's \"The Dresser\", alongside Ian McKellen, Edward Fox and Emily Watson. \"The Dresser\" is set in a London theatre during the Blitz, where an aging actor-manager, Sir, prepares for his starring role in \"King Lear\" with the help of his devoted dresser, Norman.\n\n", "id": "2397", "title": "Anthony Hopkins"}
{"url": "https://en.wikipedia.org/wiki?curid=2398", "text": "Ardal O'Hanlon\n\nArdal O'Hanlon (; born 8 October 1965) is an Irish comedian and actor. He played Father Dougal McGuire in \"Father Ted\", George Sunday in \"My Hero\", and DI Jack Mooney in \"Death in Paradise\".\n\nArdal O'Hanlon was born on 8 October 1965 in Carrickmacross, the son of politician and doctor Rory O'Hanlon. He has five siblings. The episode of \"Who Do You Think You Are?\" which aired on 6 October 2008 revealed that O'Hanlon's paternal grandfather, Michael O'Hanlon, was a UCD medicine student who had joined the IRA during the Irish War of Independence and was a member of Michael Collins' squad which assassinated British secret service agents on the morning of Bloody Sunday. Details of his grandfather's activities survive in UCD Archives, as well as Blackrock College. It also transpired that, on his mother's side, he is a close relative of Peter Fenelon Collier.\n\nO'Hanlon was schooled in Blackrock College in Dublin and graduated, in 1987, from the National Institute for Higher Education, Dublin (now Dublin City University) with a degree in Communications Studies.\n\nTogether with Kevin Gildea and Barry Murphy, O'Hanlon founded the International Comedy Cellar, upstairs in the International Bar on Dublin's South Wicklow Street. Dublin had no comedy scene at the time. As a stand up, O'Hanlon won the Hackney Empire New Act of the Year competition in 1994. For a time he was the presenter of \"The Stand Up Show\".\n\nHe was spotted by Graham Linehan, who was to cast him as Father Dougal McGuire in \"Father Ted\" (1995–98). In 1995 he received the Top TV Comedy Newcomer at the British Comedy Awards for this role. In 1995, he appeared (as Father Dougal) in a Channel 4 ident (\"Hello, you're watching... television\"), and during Comic Relief on BBC1. This was followed by the award-winning short comedy film \"Flying Saucer Rock'n'Roll\".\n\nO'Hanlon moved into straight acting alongside Emma Fielding and Beth Goddard in the ITV comedy-drama \"Big Bad World\", which aired for two series in summer 1999 and winter 2001. He also played a minor role in \"The Butcher Boy\" as Joe's (Francie's best friend) father, and appeared in an episode of the original \"Whose Line is it Anyway?\".\n\nIn 2000, O'Hanlon starred in the comedy series \"My Hero\", in which he played a very naive superhero from the planet Ultron. His character juggled world-saving heroics with life in suburbia. He stayed in the role until early 2005 and was replaced by James Dreyfus for series 6 in 2006.\n\nHe also provided the voice of the lead character in the three Christmas television cartoon specials of \"Robbie the Reindeer\". He appeared in the 2005 BBC One sitcom \"Blessed\", written by Ben Elton; at the 2005 British Comedy Awards, it was publicly slated by Jonathan Ross, albeit in jest. Towards the end of 2005, he played an eccentric Scottish character, Coconut Tam, in the family-based film, \"The Adventures of Greyfriars Bobby\". Although more commonly on television, he has appeared on radio – on 18 July 2011, he appeared on \"Quote... Unquote\". Appropriately, one of his questions concerned a quotation from \"Father Ted\".\n\nIn 2006, O'Hanlon wrote and presented an RTÉ television series called \"Leagues Apart\", which saw him investigate the biggest and most passionate football rivalries in a number of European countries. Included were Roma vs Lazio in Italy, Barcelona vs Real Madrid in Spain, and Galatasaray vs Fenerbahce in Turkey. He followed this with another RTÉ show, \"So You Want To Be Taoiseach?\" in 2007. It was a political series where O'Hanlon gave tongue-in-cheek advice on how to go about becoming Taoiseach of Ireland. Both programmes went some way towards freeing O'Hanlon from his association with the character of Dougal in the minds of Irish audiences.\n\nHe appeared in the \"Doctor Who\" episode \"Gridlock\", broadcast on 14 April 2007, in which he played a cat-like creature named Thomas Kincade Brannigan. O'Hanlon appears in Series 3 of the TV show \"Skins\", playing Naomi Campbell (Lily Loveless)'s Politics teacher named Kieran, who attempted to kiss her. He then went on to form a relationship with Naomi's mother (Olivia Colman). O'Hanlon plays the lead role in Irish comedy television programme \"Val Falvey, TD\" on RTÉ One. He has recently performed in the Edinburgh Fringe.\n\nIn February 2011, O'Hanlon returned to the Gate Theatre, Dublin starring in the Irish premiere of Christopher Hampton's \"God of Carnage\", alongside Maura Tierney.\n\nIn 2011, he appeared in the comedy panel show \"Argumental\".\n\nO'Hanlon has written a novel, \"The Talk of the Town\" (known in the United States as \"Knick Knack Paddy Whack\"), which was published in 1998. The novel is about a teenage boy, Patrick Scully, and his friends.\n\nIn February 2015 he officially launched the 2015 Sky Cat Laughs Comedy Festival which takes place in Kilkenny from 28 May–1 June. In 2015 he played the role of Peter the Milkman in the Sky 1 sitcom \"After Hours\".\n\nOn 2 February 2017, it was announced he will play the lead role in the BBC crime sitcom \"Death in Paradise\" taking the role of DI Jack Mooney following Kris Marshall's departure the same day.\n\nArdal has been doing stand up for many years appearing on many shows including Live at the Apollo, Michael McIntyre's Comedy Roadshow and Dave's One Night Stand. In 1994 he won the Hackney Empire New Act of the Year.\nO'Hanlon is married to Melanie, whom he met as a teenager, and with whom he has three children: Emily, Rebecca and Red. He is a supporter of Leeds United.\n\n", "id": "2398", "title": "Ardal O'Hanlon"}
{"url": "https://en.wikipedia.org/wiki?curid=2400", "text": "Advanced Micro Devices\n\nAdvanced Micro Devices, Inc. (AMD) is an American multinational semiconductor company based in Sunnyvale, California, United States, that develops computer processors and related technologies for business and consumer markets. While initially it manufactured its own processors, the company became fabless after GlobalFoundries was spun off in 2009. AMD's main products include microprocessors, motherboard chipsets, embedded processors and graphics processors for servers, workstations and personal computers, and embedded systems applications.\n\nAMD is the second-largest supplier and only significant rival to Intel in the market for x86-based microprocessors. Since acquiring ATI in 2006, AMD and its competitor Nvidia have dominated the discrete Graphics Processing Unit (GPU) market.\n\nAdvanced Micro Devices was formally incorporated on May 1, 1969, by Jerry Sanders, along with seven of his colleagues from Fairchild Semiconductor. Sanders, an electrical engineer who was the director of marketing at Fairchild, had like many Fairchild executives, grown frustrated with the increasing lack of support, opportunity, and flexibility within that company, and decided to leave to start his own semiconductor company. The previous year Robert Noyce, who had invented the first practical integrated circuit or microchip in 1959 at Fairchild, had left Fairchild together with Gordon Moore and founded the semiconductor company Intel in July 1968.\n\nIn September 1969, AMD moved from its temporary location in Santa Clara to Sunnyvale, California. To immediately secure a customer base, AMD initially became a second source supplier of microchips designed by Fairchild and National Semiconductor. AMD first focused on producing logic chips. The company guaranteed quality control to United States Military Standard, an advantage in the early computer industry since unreliability in microchips was a distinct problem that customers – including computer manufacturers, the telecommunications industry, and instrument manufacturers – wanted to avoid.\n\nIn November 1969, the company manufactured its first product, the Am9300, a 4-bit MSI shift register, which began selling in 1970. Also in 1970, AMD produced its first proprietary product, the Am2501 logic counter, which was highly successful. Its best-selling product in 1971 was the Am2505, the fastest multiplier available.\n\nIn 1971, AMD entered the RAM chip market, beginning with the Am3101, a 64-bit bipolar RAM. That year AMD also greatly increased the sales volume of its linear integrated circuits, and by year end the company's total annual sales reached $4.6 million.\n\nAMD went public in September 1972. The company was a second source for Intel MOS/LSI circuits by 1973, with products such as Am14/1506 and Am14/1507, dual 100-bit dynamic shift registers. By 1975, AMD was producing 212 products – of which 49 were proprietary, including the Am9102 (a static N-channel 1024-bit RAM) and three low-power Schottky MSI circuits: Am25LS07, Am25LS08, and Am25LS09.\n\nIntel had created the first microprocessor, its 4-bit 4004, in 1971. By 1975, AMD entered the microprocessor market with the Am9080, a reverse-engineered clone of the Intel 8080, and the Am2900 bit-slice microprocessor family. When Intel began installing microcode in its microprocessors in 1976, it entered into a cross-licensing agreement with AMD, granting AMD a copyright license to the microcode in its microprocessors and peripherals, effective October 1976.\n\nIn 1977, AMD entered into a joint venture with Siemens, a German engineering conglomerate wishing to enhance its technology expertise and enter the U.S. market. Siemens purchased 20% of AMD's stock, giving AMD an infusion of cash to increase its product lines. That year the two companies also jointly established Advanced Micro Computers, located in Silicon Valley and in Germany, giving AMD an opportunity to enter the microcomputer development and manufacturing field, in particular based on AMD's second-source Zilog Z8000 microprocessors. When the two companies' vision for Advanced Micro Computers diverged, AMD bought out Siemens' stake in the U.S. division in 1979. AMD closed its Advanced Micro Computers subsidiary in late 1981, after switching focus to manufacturing second-source Intel x86 microprocessors.\n\nTotal sales in fiscal year 1978 topped $100 million, and in 1979, AMD debuted on the New York Stock Exchange. In 1979, production also began in AMD's new semiconductor fab in Austin; the company already had overseas assembly facilities in Penang and Manila, and it began construction on a semiconductor fab in San Antonio in 1981. In 1980, AMD began supplying semiconductor products for telecommunications, an industry undergoing rapid expansion and innovation.\n\nIntel had introduced the first x86 microprocessors in 1978. In 1981, IBM created its PC, and wanted Intel's x86 processors, but only under the condition that Intel also provide a second-source manufacturer for its patented x86 microprocessors. Intel and AMD entered into a 10-year technology exchange agreement, first signed in October 1981 and formally executed in February 1982. The terms of the agreement were that each company could acquire the right to become a second-source manufacturer for semiconductor products developed by the other; that is, each party could \"earn\" the right to manufacture and sell a product developed by the other, if agreed to, by exchanging the manufacturing rights to a product of equivalent technical complexity. The technical information and licenses needed to make and sell a part would be exchanged for a royalty to the developing company. The 1982 agreement also extended the 1976 AMD–Intel cross-licensing agreement through 1995. The agreement included the right to invoke arbitration of disagreements, and after five years the right of either party to end the agreement with one year's notice. The main result of the 1982 agreement was that AMD became a second-source manufacturer of Intel's x86 microprocessors and related chips, and Intel provided AMD with database tapes for its 8086, 80186, and 80286 chips.\n\nBeginning in 1982, AMD began volume-producing second-source Intel-licensed 8086, 8088, 80186, and 80188 processors, and by 1984 its own Am286 clone of Intel's 80286 processor, for the rapidly growing market of IBM PCs and IBM clones. It also continued its successful concentration on proprietary bipolar chips. In 1983, it introduced INT.STD.1000, the highest manufacturing quality standard in the industry.\n\nThe company continued to spend greatly on research and development, and in addition to other breakthrough products, created the world's first 512K EPROM in 1984. That year AMD was listed in the book \"The 100 Best Companies to Work for in America\", and based on 1984 income it made the \"Fortune\" 500 list for the first time in 1985.\n\nBy mid-1985, however, the microchip market experienced a severe downturn, mainly due to longterm aggressive trade practices (dumping) from Japan, but also due to a crowded and non-innovative chip market in the U.S. AMD rode out the mid-1980s crisis by aggressively innovating and modernizing, devising the Liberty Chip program of designing and manufacturing one new chip or chip set per week for 52 weeks in fiscal year 1986, and by heavily lobbying the U.S. government until sanctions and restrictions were put into place to prevent predatory Japanese pricing. During this time period, AMD withdrew from the DRAM market, and at the same time made some headway into the CMOS market, which it had lagged in entering, having focused instead on bipolar chips.\n\nAMD had some success in the mid-1980s with the AMD7910 and AMD7911 \"World Chip\" FSK modem, one of the first multi-standard devices that covered both Bell and CCITT tones at up to 1200 baud half duplex or 300/300 full duplex. Beginning in 1986, AMD embraced the perceived shift toward RISC with their own AMD Am29000 (29k) processor; the 29k survived as an embedded processor. The company also increased its EPROM memory market share in the late 1980s. Throughout the 1980s, AMD was a second-source supplier of Intel x86 processors. In 1991, it introduced its own 386-compatible Am386, an AMD-designed chip. Creating its own chips, AMD began to compete directly with Intel.\n\nAMD had a large and successful flash memory business, even during the dotcom bust. In 2003, to divest some manufacturing and aid its overall cash flow, which was under duress from aggressive microprocessor competition from Intel, AMD spun-off its flash memory business and manufacturing into Spansion, a joint venture with Fujitsu, which had been co-manufacturing flash memory with AMD since 1993. AMD divested itself of Spansion in December 2005, in order to focus on the microprocessor market, and Spansion went public in an IPO.\n\nAMD announced the acquisition of the graphics processor company ATI Technologies on July 24, 2006. AMD paid $4.3 billion in cash and 58 million shares of its stock, for a total of approximately $5.4 billion. The transaction completed on October 25, 2006. On August 30, 2010, AMD announced that it would retire the ATI brand name for its graphics chipsets in favor of the AMD brand name.\n\nIn October 2008, AMD announced plans to spin off manufacturing operations in the form of a multibillion-dollar joint venture with Advanced Technology Investment Co., an investment company formed by the government of Abu Dhabi. The new venture is called GlobalFoundries Inc. The partnership and spin-off gave AMD an infusion of cash and allowed AMD to focus solely on chip design. To assure the Abu Dhabi investors of the new venture's success, CEO Hector Ruiz stepped down as CEO of AMD in July 2008, while remaining Executive Chairman, in preparation to becoming Chairman of Global Foundries in March 2009. President and COO Dirk Meyer became AMD's CEO. Recessionary losses necessitated AMD cutting 1,100 jobs in 2009.\n\nIn August 2011, AMD announced that former Lenovo executive Rory Read would be joining the company as CEO, replacing Meyer. AMD announced in November 2011 plans to lay off more than 10% (1,400) of its employees from across all divisions worldwide. In October 2012, it announced plans to lay off an additional 15% of its workforce to reduce costs in the face of declining sales revenue.\n\nAMD acquired the low-power server manufacturer SeaMicro in early 2012, with an eye to bringing out an ARM architecture server chip.\n\nOn October 8, 2014, AMD announced that Rory Read had stepped down after three years as president and chief executive officer. He was succeeded by Lisa Su, a key lieutenant who had been serving as chief operating officer since June.\n\nOn October 16, 2014, AMD announced a new restructuring plan along with its Q3 results. Effective July 1, 2014, AMD reorganized into two business groups: Computing and Graphics, which primarily includes desktop and notebook processors and chipsets, discrete GPUs, and professional graphics; and Enterprise, Embedded and Semi-Custom, which primarily includes server and embedded processors, dense servers, semi-custom SoC products (including solutions for gaming consoles), engineering services, and royalties. As part of this restructuring AMD announced that 7% of its global workforce would be laid off by the end of 2014.\n\nIn February 1982, AMD signed a contract with Intel, becoming a licensed second-source manufacturer of 8086 and 8088 processors. IBM wanted to use the Intel 8088 in its IBM PC, but IBM's policy at the time was to require at least two sources for its chips. AMD later produced the Am286 under the same arrangement. In 1984 Intel, in order to shore up its advantage in the marketplace, internally decided to no longer cooperate with AMD in supplying product information, and delayed and eventually refused to convey the technical details of the Intel 80386 to AMD. In 1987, AMD invoked arbitration over the issue, and Intel reacted by cancelling the 1982 technological-exchange agreement altogether. After three years of testimony, AMD eventually won in arbitration in 1992, but Intel disputed this decision. Another long legal dispute followed, ending in 1994 when the Supreme Court of California sided with the arbitrator and AMD.\n\nIn 1990, Intel also countersued AMD, reneging on AMD's right to use derivatives of Intel's microcode for its cloned processors. In the face of uncertainty during the legal dispute, AMD was forced to develop clean room designed versions of Intel code for its x386 and x486 processors, the former long after Intel had released its own x386 in 1985. In March 1991, AMD released the Am386, its clone of the Intel 386 processor. By October of the same year it had sold one million units.\n\nIn 1993, AMD introduced the first of the Am486 family of processors, which proved popular with a large number of original equipment manufacturers, including Compaq, which signed an exclusive agreement using the Am486. Another Am486-based processor, the Am5x86, was released in November 1995 and continued AMD's success as a fast, cost-effective processor.\n\nFinally, in an agreement effective 1996, AMD received the rights to the microcode in Intel's x386 and x486 processor families, but not the rights to the microcode in the following generations of processors.\n\nAMD's first in-house x86 processor was the K5, which was launched in 1996. The \"K\" was a reference to Kryptonite. (In comic books, the only substance which could harm Superman was Kryptonite. This is a reference to Intel's hegemony over the market, i.e., an anthropomorphization of them as Superman.) The numeral \"5\" refers to the fifth generation of x86 processors; rival Intel had previously introduced its line of fifth-generation x86 processors as Pentium because the U.S. Trademark and Patent Office had ruled that mere numbers could not be trademarked.\n\nIn 1996, AMD purchased NexGen, specifically for the rights to their Nx series of x86-compatible processors. AMD gave the NexGen design team their own building, left them alone, and gave them time and money to rework the Nx686. The result was the K6 processor, introduced in 1997. Although the K6 was based on Socket 7, variants such as K6-3/450 were faster than Intel's Pentium II (sixth-generation processor).\n\nThe K7 was AMD's seventh-generation x86 processor, making its debut on June 23, 1999, under the brand name Athlon. Unlike previous AMD processors, it could not be used on the same motherboards as Intel's, due to licensing issues surrounding Intel's Slot 1 connector, and instead used a Slot A connector, referenced to the Alpha processor bus. The Duron was a lower-cost and limited version of the Athlon (64KB instead of 256KB L2 cache) in a 462-pin socketed PGA (socket A) or soldered directly onto the motherboard. Sempron was released as a lower-cost Athlon XP, replacing Duron in the socket A PGA era. It has since been migrated upward to all new sockets, up to AM3.\n\nOn October 9, 2001, the Athlon XP was released. On February 10, 2003, the Athlon XP with 512KB L2 Cache was released.\n\nThe K8 was a major revision of the K7 architecture, with the most notable features being the addition of a 64-bit extension to the x86 instruction set (called x86-64, AMD64, or x64), the incorporation of an on-chip memory controller, and the implementation of an extremely high performance point-to-point interconnect called HyperTransport, as part of the Direct Connect Architecture. The technology was initially launched as the Opteron server-oriented processor on April 22, 2003. Shortly thereafter it was incorporated into a product for desktop PCs, branded Athlon 64.\n\nOn April 21, 2005, AMD released the first dual core Opteron, an x86-based server CPU. A month later, AMD released the Athlon 64 X2, the first desktop-based dual core processor family. In May 2007, AMD abandoned the string \"64\" in its dual-core desktop product branding, becoming Athlon X2, downplaying the significance of 64-bit computing in its processors. Further updates involved improvements to the microarchitecture, and a shift of target market from mainstream desktop systems to value dual-core desktop systems. In 2008, AMD started to release dual-core Sempron processors exclusively in China, branded as the Sempron 2000 series, with lower HyperTransport speed and smaller L2 cache. Thus AMD completed its dual-core product portfolio for each market segment.\n\nAfter K8 came K10. In September 2007, AMD released the first K10 processors – nine quad-core Third Generation Opteron processors – followed in November by the Phenom processor for desktop. K10 processors came in dual-core, triple-core, and quad-core versions, with all cores on a single die. AMD released a new platform, codenamed \"Spider\", which utilized the new Phenom processor, as well as an R770 GPU and a 790 GX/FX chipset from the AMD 700 chipset series. However, AMD built the Spider at 65nm, which was uncompetitive with Intel's smaller and more power-efficient 45nm.\n\nIn January 2009, AMD released a new processor line dubbed Phenom II, a refresh of the original Phenom built using the 45 nm process. AMD's new platform, codenamed “Dragon”, utilised the new Phenom II processor, and an ATI R770 GPU from the R700 GPU family, as well as a 790 GX/FX chipset from the AMD 700 chipset series. The Phenom II came in dual-core, triple-core and quad-core variants, all using the same die, with cores disabled for the triple-core and dual-core versions. The Phenom II resolved issues that the original Phenom had, including a low clock speed, a small L3 cache and a Cool'n'Quiet bug that decreased performance. The Phenom II cost less but was not performance-competitive with Intel's mid-to-high-range Core 2 Quads. The Phenom II also enhanced the Phenom's memory controller, allowing it to use DDR3 in a new native socket AM3, while maintaining backwards compatibility with AM2+, the socket used for the Phenom, and allowing the use of the DDR2 memory that was used with the platform.\n\nIn April 2010, AMD released a new Phenom II hexa-core (6-core) processor codenamed \"Thuban\". This was a totally new die based on the hexa-core “Istanbul” Opteron processor. It included AMD's “turbo core” technology, which allows the processor to automatically switch from 6 cores to 3 faster cores when more pure speed is needed. AMD's enthusiast platform, codenamed \"Leo\", utilized the new Phenom II, a new chipset from the AMD 800 chipset series and an ATI “Cypress” GPU from the Evergreen GPU series.\nThe Magny Cours and Lisbon server parts were released in 2010. The Magny Cours part came in 8 to 12 cores and the Lisbon part in 4 and 6 core parts. Magny Cours is focused on performance while the Lisbon part is focused on high performance per watt. Magny Cours is an MCM (multi-chip module) with two hexa-core “Istanbul” Opteron parts. This will use a new G34 socket for dual and quad socket processors and thus will be marketed as Opteron 61xx series processors. Lisbon uses C32 socket certified for dual socket use or single socket use only and thus will be marketed as Opteron 41xx processors. Both will be built on a 45 nm SOI process.\n\nFollowing AMD's 2006 acquisition of Canadian graphics company ATI Technologies, an initiative codenamed \"Fusion\" was announced to integrate a CPU and GPU together on some of AMD's microprocessors, including a built in PCI Express link to accommodate separate PCI Express peripherals, eliminating the northbridge chip from the motherboard. The initiative intended to move some of the processing originally done on the CPU (e.g. floating-point unit operations) to the GPU, which is better optimized for some calculations. The Fusion was later renamed to the AMD APU (Accelerated Processing Unit).\n\nLlano was AMD's first APU built for laptops. Llano was the second APU released, targeted at the mainstream market. Incorporating a CPU and GPU on the same die, as well as northbridge functions, and using \"Socket FM1\" with DDR3 memory. The CPU part of the processor was based on the Phenom II \"Deneb\" processor. AMD suffered an unexpected decrease in revenue based on production problems for the Llano.\n\nBulldozer is AMD's microarchitecture codename for server and desktop AMD FX processors first released on October 12, 2011. This family 15h microarchitecture is the successor to the family 10h (K10) microarchitecture design. Bulldozer is designed from scratch, not a development of earlier processors. The core is specifically aimed at 10-125 W TDP computing products. AMD claims dramatic performance-per-watt efficiency improvements in high-performance computing (HPC) applications with Bulldozer cores. While hopes were very high that Bulldozer would bring AMD to be performance competitive with archrival Intel once more, most benchmarks were disappointing. In some cases the new Bulldozer products were slower than the K10 model they were built to replace.\n\nHondo is AMD's latest processor series used in Tablet computers.\n\nPiledriver is the name of AMD's microarchitecture used in some AMD FX processors released in 2012. This AMD FX series processor lineup is called Vishera, and targets the desktop performance market.\n\nJaguar is a x86-64 microarchitecture codename for a processor core that is used in various APUs from AMD aimed at the low-power/low-cost market. It is also used as the microarchitecture for the custom APUs in the PS4 and Xbox One (which contain CPU, GPU and memory).\n\nJaguar's predecessor, Bobcat, was revealed during a speech from AMD executive vice-president Henri Richard in Computex 2007 and was put into production Q1 2011. One of the major supporters was executive vice-president Mario A. Rivas who felt it was difficult to compete in the x86 market with a single core optimized for the 10-100 W range and actively promoted the development of the simpler core with a target range of 1-10 watts. In addition, it was believed that the core could migrate into the hand-held space if the power consumption can be reduced to less than 1 W.\n\nAMD intends to release 64-bit ARM System on Chips (SoC) that will begin sampling in early 2014 and shipping in the second half of 2015. They will be for use in servers as a low-power alternative to current x86 chips. Their implementation using the ARM architecture is codenamed \"Seattle\", based on the Cortex A57 core design (ARMv8-A), and will contain 8 and 16 cores each. They will include the proprietary SeaMicro \"Freedom Fabric\", as well as support for 128 GB RAM, and 10 gigabit Ethernet. This is to be followed by the custom ARM core K12 core, expected in 2016-2017.\n\nZen is a new architecture for x86-64 based Ryzen series CPUs and APUS, introduced in 2017 by AMD and built from the ground up by a team led by Jim Keller, beginning with his arrival in 2012, and taping out before his departure in September 2015. One of AMD's primary goals with Zen was an IPC increase of at least 40%, however recently AMD announced that they had actually achieved a 52% increase. Processors made on the Zen architecture are built on the 14 nm FinFET node and have a renewed focus on single-core performance and HSA compatibility. Previous processors from AMD were either built in the 32 nm process (\"Bulldozer\" and \"Piledriver\" CPUs) or the 28 nm process (\"Steamroller\" and \"Excavator\" APUs). Because of this, Zen is much more energy efficient. The Zen architecture is the first to encompass CPUs and APUs from AMD built for a single socket (Socket AM4). Also new for this architecture is the implementation of simultaneous multithreading (SMT) technology, something Intel has had for years on some of their processors with their proprietary Hyper-Threading implementation of SMT. This is a departure from the \"Clustered MultiThreading\" design introduced with the Bulldozer architecture. Zen also has support for DDR4 memory. AMD released the high-end Ryzen 7 \"Summit Ridge\" series CPUs on March 2, 2017, with their mid-range Ryzen 5 series and lower end Ryzen 3 series CPUs to be released later in 2017. AMD is also expected to release further information about their upcoming next-generation Zen-based \"Raven Ridge\" APUs and \"Naples\" server CPUs sometime in 2017.\n\nThe Ryzen 7 1800X, Ryzen 7 1700X and Ryzen 7 1700 each have eight cores and 16 threads using SMT. Other processors expected to be released in Q2 2017 include the Ryzen 5 1600X and Ryzen 5 1500X, which will have six cores 12 threads and 4 cores 8 threads, respectively.\n\nAMD's portfolio of dedicated graphics processors includes product families and associated technologies aimed at the consumer, professional and high-performance computing markets, such as:\n\n\n\nAMD Catalyst is a collection of proprietary device driver software available for Microsoft Windows and Linux.\n\nSince 2007, AMD has participated in the development of free and open-source graphics device drivers. The programming specifications for a number of chipsets and features were published in several rounds. Employees hired by AMD for this purpose contribute code to the Direct Rendering Manager in the Linux kernel.\n\nBefore the launch of Athlon 64 processors in 2003, AMD designed chipsets for their processors spanning the K6 and K7 processor generations. The chipsets include the AMD-640, AMD-751 and the AMD-761 chipsets. The situation changed in 2003 with the release of Athlon 64 processors, and AMD chose not to further design its own chipsets for its desktop processors while opening the desktop platform to allow other firms to design chipsets. This was the “Open Platform Management Architecture” with ATI, VIA and SiS developing their own chipset for Athlon 64 processors and later Athlon 64 X2 and Athlon 64 FX processors, including the Quad FX platform chipset from Nvidia.\n\nThe initiative went further with the release of Opteron server processors as AMD stopped the design of server chipsets in 2004 after releasing the AMD-8111 chipset, and again opened the server platform for firms to develop chipsets for Opteron processors. As of today, Nvidia and Broadcom are the sole designing firms of server chipsets for Opteron processors.\n\nAs the company completed the acquisition of ATI Technologies in 2006, the firm gained the ATI design team for chipsets which previously designed the Radeon Xpress 200 and the Radeon Xpress 3200 chipsets. AMD then renamed the chipsets for AMD processors under AMD branding (for instance, the CrossFire Xpress 3200 chipset was renamed as AMD 580X CrossFire chipset). In February 2007, AMD announced the first AMD-branded chipset since 2004 with the release of the AMD 690G chipset (previously under the development codename \"RS690\"), targeted at mainstream IGP computing. It was the industry's first to implement a HDMI 1.2 port on motherboards, shipping for more than a million units. While ATI had aimed at releasing an Intel IGP chipset, the plan was scrapped and the inventories of Radeon Xpress 1250 (codenamed \"RS600\", sold under ATI brand) was sold to two OEMs, Abit and ASRock. Although AMD stated the firm would still produce Intel chipsets, Intel had not granted the license of FSB to ATI.\n\nOn November 15, 2007, AMD announced a new chipset series portfolio, the AMD 7-Series chipsets, covering from enthusiast multi-graphics segment to value IGP segment, to replace the AMD 480/570/580 chipsets and AMD 690 series chipsets, marking AMD's first enthusiast multi-graphics chipset. Discrete graphics chipsets were launched on November 15, 2007 as part of the codenamed \"Spider\" desktop platform, and IGP chipsets were launched at a later time in spring 2008 as part of the codenamed \"Cartwheel\" platform.\n\nAMD returned to the server chipsets market with the AMD 800S series server chipsets. It includes support for up to six SATA 6.0 Gbit/s ports, the C6 power state, which is featured in Fusion processors and AHCI 1.2 with SATA FIS–based switching support. This is a chipset family supporting Phenom processors and Quad FX enthusiast platform (890FX), IGP(890GX).\n\n, AMD LIVE! was a platform marketing initiative focusing the consumer electronics segment, with an Active TV initiative for streaming Internet videos from web video services such as YouTube, into AMD Live! PC as well as connected digital TVs, together with a scheme for an ecosystem of certified peripherals for the ease of customers to identify peripherals for AMD LIVE! systems for digital home experience, called \"AMD LIVE! Ready\".\n\nThe AMD Quad FX platform, being an extreme enthusiast platform, allows two processors to connect through HyperTransport, which is a similar setup to dual-processor (2P) servers, excluding the use of buffered memory/registered memory DIMM modules, and a server motherboard, the current setup includes two Athlon 64 FX-70 series processors and a special motherboard. AMD pushed the platform for the surging demands for what AMD calls \"megatasking\", the ability to do more tasks on a single system. The platform refreshes with the introduction of Phenom FX processors and the next-generation RD790 chipset, codenamed \"\"FASN8\"\".\n\nAMD's first multi-processor server platform, codenamed \"Fiorano\", consists of AMD SR5690 + SP5100 server chipsets, supporting 45 nm, codenamed \"Shanghai\" Socket F+ processors and registered DDR2 memory. It was followed by the \"Maranello\" platform supporting 45 nm, codenamed \"Istanbul\", Socket G34 processors with DDR3 memory. On single-processor platform, the codenamed \"Catalunya\" platform consists of codenamed \"Suzuka\" 45 nm quad-core processor with AMD SR5580 + SP5100 chipset and DDR3 support.\n\nAMD's x86 virtualization extension to the 64-bit x86 architecture is named \"AMD Virtualization\", also known by the abbreviation \"AMD-V\", and is sometimes referred to by the code name \"Pacifica\". AMD processors using Socket AM2, Socket S1, and Socket F include AMD Virtualization support. AMD Virtualization is also supported by release two (8200, 2200 and 1200 series) of the Opteron processors. The third generation (8300 and 2300 series) of Opteron processors will see an update in virtualization technology, specifically the Rapid Virtualization Indexing (also known by the development name \"Nested Page Tables\"), alongside the tagged TLB and Device Exclusion Vector (DEV).\n\nAMD also promotes the \"AMD I/O Virtualization Technology\" (also known as IOMMU) for I/O virtualization. The AMD IOMMU specification has been updated to version 1.2. The specification describes the use of a HyperTransport architecture.\n\nAMD's server initiatives include the following:\n\nStarting in 2007, AMD, following Intel, began using codenames for its desktop platforms such as \"Spider\" or \"Dragon\". The platforms, unlike Intel's approach, will refresh every year, putting focus on platform specialization. The platform includes components such as AMD processors, chipsets, ATI graphics and other features, but continued to the open platform approach, and welcome components from other vendors such as VIA, SiS, and Nvidia, as well as wireless product vendors.\n\nUpdates to the platform includes the implementation of IOMMU I/O Virtualization with 45 nm generation of processors, and the AMD 800 chipset series in 2009.\n\nIn February 2002, AMD acquired Alchemy Semiconductor for its Alchemy line of MIPS processors for the hand-held and portable media player markets. On June 13, 2006, AMD officially announced that the line was to be transferred to Raza Microelectronics, Inc., a designer of MIPS processors for embedded applications.\n\nIn August 2003, AMD also purchased the Geode business which was originally the Cyrix MediaGX from National Semiconductor to augment its existing line of embedded x86 processor products. During the second quarter of 2004, it launched new low-power Geode NX processors based on the K7 Thoroughbred architecture with speeds of fanless processors and , and processor with fan, of TDP 25 W. This technology is used in a variety of embedded systems (Casino slot machines and customer kiosks for instance), several UMPC designs in Asia markets, as well as the OLPC XO-1 computer, an inexpensive laptop computer intended to be distributed to children in developing countries around the world. The Geode LX processor was announced in 2005 and is said will continue to be available through 2015.\n\nFor the past couple of years AMD has been introducing 64-bit processors into its embedded product line starting with the AMD Opteron processor. Leveraging the high throughput enabled through HyperTransport and the Direct Connect Architecture these server class processors have been targeted at high end telecom and storage applications. In 2007, AMD added the AMD Athlon, AMD Turion and Mobile AMD Sempron processors to its embedded product line. Leveraging the same 64-bit instruction set and Direct Connect Architecture as the AMD Opteron but at lower power levels, these processors were well suited to a variety of traditional embedded applications. Throughout 2007 and into 2008, AMD has continued to add both single-core Mobile AMD Sempron and AMD Athlon processors and dual-core AMD Athlon X2 and AMD Turion processors to its embedded product line and now offers embedded 64-bit solutions starting with 8W TDP Mobile AMD Sempron and AMD Athlon processors for fan-less designs up to multi-processor systems leveraging multi-core AMD Opteron processors all supporting longer than standard availability.\n\nThe ATI acquisition included the Imageon and Xilleon product lines. In late 2008, the entire handheld division was sold off to Qualcomm, who have since produced the Adreno series. The Xilleon division was sold to Broadcom.\n\nIn April 2007, AMD announced the release of the M690T integrated graphics chipset for embedded designs. This enabled AMD to offer complete processor and chipset solutions targeted at embedded applications requiring high performance 3D and video such as emerging digital signage, kiosk and Point of Sale applications. The M690T was followed by the M690E specifically for embedded applications which removed the TV output, which required Macrovision licensing for OEMs, and enabled native support for dual TMDS outputs, enabling dual independent DVI interfaces.\n\nIn 2008, AMD announced the Radeon E2400, the first discrete GPU in their embedded product line offering the same long term availability as their other embedded products. That was followed in 2009 with the higher performance Radeon E4690 discrete GPU.\n\nIn 2009, AMD announced their first BGA packaged e64 architecture processors, known as the ASB1 family.\n\nIn 2010, AMD announced a second generation BGA platform referred to as ASB2. They also announced several new AM3 based processors with support for DDR3 memory.\n\nIn January 2011, AMD announced the AMD Embedded G-Series Accelerated Processing Unit. The first Fusion family APU for embedded applications. This announcement was followed by announcements for the high performance AMD Radeon E6760 and the value-conscious Radeon E6460 discrete GPUs. These solutions all added support for DirectX 11, OpenGL 4.1 and OpenCL 1.1.\n\nIn May 2012, AMD Announced the AMD Embedded R-Series Accelerated Processing Unit. This family of products incorporates the Bulldozer CPU architecture, and Discrete-class AMD Radeon™ HD 7000G Series graphics.\n\nAMD Embedded solutions offer 5+ year product life.\n\nAMD builds graphic processors for use in embedded systems. These SOCs are used in a variety of applications and industries. They can be found in anything from casinos to healthcare, with a large portion of products being used in industrial machines. The latest E9000-Modules, based on the Polaris Microarchitecture, succeeded the previous E8000 series in 2016.\n\n\n\n\n\nEver since the spin-off of AMD's fabrication plants in early 2009, GlobalFoundries has been responsible for producing AMD's processors.\n\nGlobalFoundries' main microprocessor manufacturing facilities are located in Dresden, Germany. Additionally, highly integrated microprocessors are manufactured in Taiwan made by third-party manufacturers under strict license from AMD. Between 2003 and 2005, they constructed a second manufacturing plant ( 90 nm process SOI) in the same complex in order to increase the number of chips they could produce, thus becoming more competitive with Intel. The new plant was named \"Fab 36\", in recognition of AMD's 36 years of operation, and reached full production in mid-2007. Fab 36 was renamed to \"Fab 1\" during the spin-off of AMD's manufacturing business during the creation of GlobalFoundries. In July 2007, AMD announced that they completed the conversion of Fab 1 Module 1 from to 65 nm. They then shifted their focus to the 45 nm conversion.\n\nIn July 2016 Forbes reported that AMD had successfully produced products on Samsung's 14 nanometer FinFET process. This presents additional manufacturing opportunities, in addition to AMD's primary foundries: GlobalFoundries and TSMC. It was argued this would reduce risk for AMD by decreasing dependence on any one foundry.\n\nAMD utilizes strategic industry partnerships to further its business interests as well as to rival Intel's dominance and resources.\n\nA partnership between AMD and Alpha Processor Inc. developed HyperTransport, a point-to-point interconnect standard which was turned over to an industry standards body for finalization. It is now used in modern motherboards that are compatible with AMD processors.\n\nAMD also formed a strategic partnership with IBM, under which AMD gained silicon on insulator (SOI) manufacturing technology, and detailed advice on 90 nm implementation. AMD announced that the partnership would extend to 2011 for 32 nm and 22 nm fabrication-related technologies.\n\nTo facilitate processor distribution and sales, AMD is loosely partnered with end-user companies, such as HP, Compaq, ASUS, Acer, and Dell.\n\nIn 1993, AMD established a 50-50 partnership with Fujitsu called FASL, and merged into a new company called FASL LLC in 2003. The joint venture went public under the name Spansion and ticker symbol SPSN in December 2005, with AMD shares drop to 37%. AMD no longer directly participates in the Flash memory devices market now as AMD entered into a non-competition agreement, as of December 21, 2005, with Fujitsu and Spansion, pursuant to which it agreed not to directly or indirectly engage in a business that manufactures or supplies standalone semiconductor devices (including single chip, multiple chip or system devices) containing only Flash memory.\n\nOn May 18, 2006, Dell announced that it would roll out new servers based on AMD's Opteron chips by year's end, thus ending an exclusive relationship with Intel. In September 2006, Dell began offering AMD Athlon X2 chips in their desktop line-up.\n\nIn June 2011, HP announced new business and consumer notebooks equipped with the latest versions of AMD APUsaccelerated processing units. AMD will power HP's Intel-based business notebooks as well.\n\nIn the spring of 2013, AMD announced that it would be powering all three major next-generation consoles. The Xbox One and Sony PlayStation 4 are both powered by a custom-built AMD APU, and the Nintendo Wii U is powered by an AMD GPU. According to AMD, having their processors in all three of these consoles will greatly assist developers with cross-platform development to competing consoles and PCs as well as increased support for their products across the board.\n\nAMD has entered into an MoU with Hindustan Semiconductor Manufacturing Corporation(HSMC) to explore various options for providing technology licence to manufacture micro-processors in the semi conductor fabs.\n\nAMD has a long history of litigation with former partner and x86 creator Intel.\n\nOn August 31, 2011, in Austin, Texas, AMD achieved a Guinness World Record for the \"Highest frequency of a computer processor\": 8.429 GHz. The company ran an 8-core FX-8150 processor with only one active module (two cores), and cooled with liquid helium. The previous record was 8.308 GHz, with an Intel Celeron 352 (one core).\n\nOn November 1, 2011, geek.com reported that Andre Yang, an overclocker from Taiwan, used an FX-8150 to set another record: 8.461 GHz.\n\nOn November 19, 2012, Andre Yang used an FX-8350 to set another record yet again: 8.794 GHz.\n\nIn its 2012 report on progress relating to conflict minerals, the Enough Project rated AMD the fifth most progressive of 24 consumer electronics companies.\n\n\n", "id": "2400", "title": "Advanced Micro Devices"}
{"url": "https://en.wikipedia.org/wiki?curid=2402", "text": "Albrecht Dürer\n\nAlbrecht Dürer (; ; 21 May 1471 – 6 April 1528) was a painter, printmaker, and theorist of the German Renaissance. Born in Nuremberg, Dürer established his reputation and influence across Europe when he was still in his twenties due to his high-quality woodcut prints.\nHe was in communication with the major Italian artists of his time, including Raphael, Giovanni Bellini and Leonardo da Vinci, and from 1512 he was patronized by emperor Maximilian I.\n\nDürer's vast body of work includes engravings, his preferred technique in his later prints, altarpieces, portraits and self-portraits, watercolours and books. The woodcuts, such as the \"Apocalypse\" series (1498), are more Gothic than the rest of his work. \nHis well-known engravings include the \"Knight, Death, and the Devil\" (1513), \"Saint Jerome in his Study\" (1514) and \"Melencolia I\" (1514), which has been the subject of extensive analysis and interpretation. His watercolours also mark him as one of the first European landscape artists, while his ambitious woodcuts revolutionized the potential of that medium.\n\nDürer's introduction of classical motifs into Northern art, through his knowledge of Italian artists and German humanists, has secured his reputation as one of the most important figures of the Northern Renaissance. This is reinforced by his theoretical treatises, which involve principles of mathematics, perspective, and ideal proportions.\n\nDürer was born on 21 May 1471, third child and second son of his parents, who had at least fourteen and possibly as many as eighteen children. His father, Albrecht Dürer the Elder, was a successful goldsmith, originally Ajtósi, who in 1455 had moved to Nuremberg from Ajtós, near Gyula in Hungary. One of Albrecht's brothers, Hans Dürer, was also a painter and trained under him. Another of Albrecht's brothers, Endres Dürer, took over their father's business and was a master goldsmith. The German name \"Dürer\" is a translation from the Hungarian, \"Ajtósi\". Initially, it was \"Türer,\" meaning doormaker, which is \"ajtós\" in Hungarian (from \"ajtó\", meaning door). A door is featured in the coat-of-arms the family acquired. Albrecht Dürer the Younger later changed \"Türer\", his father's diction of the family's surname, to \"Dürer\", to adapt to the local Nuremberg dialect. Albrecht Dürer the Elder married Barbara Holper, the daughter of his master when he himself became a master in 1467.\n\nDürer's godfather was Anton Koberger, who left goldsmithing to become a printer and publisher in the year of Dürer's birth and quickly became the most successful publisher in Germany, eventually owning twenty-four printing-presses and having many offices in Germany and abroad. Koberger's most famous publication was the \"Nuremberg Chronicle\", published in 1493 in German and Latin editions. It contained an unprecedented 1,809 woodcut illustrations (albeit with many repeated uses of the same block) by the Wolgemut workshop. Dürer may have worked on some of these, as the work on the project began while he was with Wolgemut.\n\nBecause Dürer left autobiographical writings and became very famous by his mid-twenties, his life is well documented by several sources. After a few years of school, Dürer started to learn the basics of goldsmithing and drawing from his father. Though his father wanted him to continue his training as a goldsmith, he showed such a precocious talent in drawing that he started as an apprentice to Michael Wolgemut at the age of fifteen in 1486. A self-portrait, a drawing in silverpoint, is dated 1484 (Albertina, Vienna) \"when I was a child,\" as his later inscription says. Wolgemut was the leading artist in Nuremberg at the time, with a large workshop producing a variety of works of art, in particular woodcuts for books. Nuremberg was then an important and prosperous city, a centre for publishing and many luxury trades. It had strong links with Italy, especially Venice, a relatively short distance across the Alps.\n\nAfter completing his term of apprenticeship, Dürer followed the common German custom of taking \"Wanderjahre\"—in effect gap years —in which the apprentice learned skills from artists in other areas; Dürer was to spend about four years away. He left in 1490, possibly to work under Martin Schongauer, the leading engraver of Northern Europe, but who died shortly before Dürer's arrival at Colmar in 1492. It is unclear where Dürer travelled in the intervening period, though it is likely that he went to Frankfurt and the Netherlands. In Colmar, Dürer was welcomed by Schongauer's brothers, the goldsmiths Caspar and Paul and the painter Ludwig. In 1493 Dürer went to Strasbourg, where he would have experienced the sculpture of Nikolaus Gerhaert. Dürer's first painted self-portrait (now in the Louvre) was painted at this time, probably to be sent back to his fiancée in Nuremberg.\n\nIn early 1492 Dürer travelled to Basel to stay with another brother of Martin Schongauer, the goldsmith Georg. Very soon after his return to Nuremberg, on 7 July 1494, at the age of 23, Dürer was married to Agnes Frey following an arrangement made during his absence. Agnes was the daughter of a prominent brass worker (and amateur harpist) in the city. However, no children resulted from the marriage.\n\nWithin three months of his marriage, Dürer left for Italy, alone, perhaps stimulated by an outbreak of plague in Nuremberg. He made watercolour sketches as he traveled over the Alps. Some have survived and others may be deduced from accurate landscapes of real places in his later work, for example his engraving \"Nemesis\".\n\nIn Italy, he went to Venice to study its more advanced artistic world. Through Wolgemut's tutelage, Dürer had learned how to make prints in drypoint and design woodcuts in the German style, based on the works of Martin Schongauer and the Housebook Master. He also would have had access to some Italian works in Germany, but the two visits he made to Italy had an enormous influence on him. He wrote that Giovanni Bellini was the oldest and still the best of the artists in Venice. His drawings and engravings show the influence of others, notably Antonio Pollaiuolo with his interest in the proportions of the body, Andrea Mantegna, Lorenzo di Credi and others. Dürer probably also visited Padua and Mantua on this trip.\n\nOn his return to Nuremberg in 1495, Dürer opened his own workshop (being married was a requirement for this). Over the next five years his style increasingly integrated Italian influences into underlying Northern forms. Dürer's father died in 1502, and his mother died in 1513. His best works in the first years of the workshop were his woodcut prints, mostly religious, but including secular scenes such as \"The Men's Bath House\" (ca. 1496). These were larger and more finely cut than the great majority of German woodcuts hitherto, and far more complex and balanced in composition.\n\nIt is now thought unlikely that Dürer cut any of the woodblocks himself; this task would have been performed by a specialist craftsman. However, his training in Wolgemut's studio, which made many carved and painted altarpieces and both designed and cut woodblocks for woodcut, evidently gave him great understanding of what the technique could be made to produce, and how to work with block cutters. Dürer either drew his design directly onto the woodblock itself, or glued a paper drawing to the block. Either way, his drawings were destroyed during the cutting of the block.\n\nHis famous series of sixteen great designs for the \"Apocalypse\" is dated 1498, as is his engraving of\" St. Michael Fighting the Dragon\". He made the first seven scenes of the \"Great Passion\" in the same year, and a little later, a series of eleven on the Holy Family and saints. The \"Seven Sorrows Polyptych\", commissioned by Frederick III of Saxony in 1496, was executed by Dürer and his assistants c. 1500. Around 1503–1505 he produced the first seventeen of a set illustrating the \"Life of the Virgin\", which he did not finish for some years. Neither these, nor the \"Great Passion,\" were published as sets until several years later, but prints were sold individually in considerable numbers.\n\nDuring the same period Dürer trained himself in the difficult art of using the burin to make engravings. It is possible he had begun learning this skill during his early training with his father, as it was also an essential skill of the goldsmith. In 1496 he executed the \"Prodigal Son\", which the Italian Renaissance art historian Giorgio Vasari singled out for praise some decades later, noting its Germanic quality. He was soon producing some spectacular and original images, notably \"Nemesis\" (1502), \"The Sea Monster\" (1498), and \"Saint Eustace\" (c. 1501), with a highly detailed landscape background and animals. His landscapes of this period, such as \"Pond in the Woods\" and \"Willow Mill\", are quite different from his earlier watercolours. There is a much greater emphasis on capturing atmosphere, rather than depicting topography. He made a number of Madonnas, single religious figures, and small scenes with comic peasant figures. Prints are highly portable and these works made Dürer famous throughout the main artistic centres of Europe within a very few years.\n\nThe Venetian artist Jacopo de' Barbari, whom Dürer had met in Venice, visited Nuremberg in 1500, and Dürer said that he learned much about the new developments in perspective, anatomy, and proportion from him. De' Barbari was unwilling to explain everything he knew, so Dürer began his own studies, which would become a lifelong preoccupation. A series of extant drawings show Dürer's experiments in human proportion, leading to the famous engraving of \"Adam and Eve\" (1504), which shows his subtlety while using the burin in the texturing of flesh surfaces. This is the only existing engraving signed with his full name.\n\nDürer created large numbers of preparatory drawings, especially for his paintings and engravings, and many survive, most famously the \"Betende Hände\" (\"Praying Hands\") from circa 1508, a study for an apostle in the Heller altarpiece. He also continued to make images in watercolour and bodycolour (usually combined), including a number of still lifes of meadow sections or animals, including his \"Young Hare\" (1502) and the \"Great Piece of Turf\" (1503).\n\nIn Italy, he returned to painting, at first producing a series of works executed in tempera on linen. These include portraits and altarpieces, notably, the Paumgartner altarpiece and the \"Adoration of the Magi\". In early 1506, he returned to Venice and stayed there until the spring of 1507. By this time Dürer's engravings had attained great popularity and were being copied. In Venice he was given a valuable commission from the emigrant German community for the church of San Bartolomeo. This was the altar-piece known as the \"Adoration of the Virgin\" or the \"Feast of Rose Garlands\". It includes portraits of members of Venice's German community, but shows a strong Italian influence. It was subsequently acquired by the Emperor Rudolf II and taken to Prague. Other paintings Dürer produced in Venice include \"The Virgin and Child with the Goldfinch\", \"Christ among the Doctors\" (supposedly produced in a mere five days), and a number of smaller works.\n\nDespite the regard in which he was held by the Venetians, Dürer returned to Nuremberg by mid-1507, remaining in Germany until 1520. His reputation had spread throughout Europe and he was on friendly terms and in communication with most of the major artists including Raphael, Giovanni Bellini and—mainly through Lorenzo di Credi—Leonardo da Vinci.\n\nBetween 1507 and 1511 Dürer worked on some of his most celebrated paintings: \"Adam and Eve\" (1507), \"The Martyrdom of the Ten Thousand\" (1508, for Frederick of Saxony), \"Virgin with the Iris\" (1508), the altarpiece \"Assumption of the Virgin\" (1509, for Jacob Heller of Frankfurt), and \"Adoration of the Trinity\" (1511, for Matthaeus Landauer). During this period he also completed two woodcut series, the Great Passion and the Life of the Virgin, both published in 1511 together with a second edition of the Apocalypse series. The post-Venetian woodcuts show Dürer's development of chiaroscuro modelling effects, creating a mid-tone throughout the print to which the highlights and shadows can be contrasted.\n\nOther works from this period include the thirty-seven woodcut subjects of the Little Passion, published first in 1511, and a set of fifteen small engravings on the same theme in 1512. Indeed, complaining that painting did not make enough money to justify the time spent when compared to his prints, he produced no paintings from 1513 to 1516. However, in 1513 and 1514 Dürer created his three most famous engravings: \"Knight, Death, and the Devil\" (1513, probably based on Erasmus's treatise \"Enchiridion militis Christiani\"), \"St. Jerome in his Study\", and the much-debated \"Melencolia I\" (both 1514). Further outstanding pen and ink drawings of Dürer´s period of art work of 1513 were drafts for his friend Willibald Prickheimer. These drafts were later used to design the famous chandeliers lusterweibchen.\n\nIn 1515, he created his \"woodcut of a Rhinoceros\" which had arrived in Lisbon from a written description and sketch by another artist, without ever seeing the animal himself. An image of the Indian rhinoceros, the image has such force that it remains one of his best-known and was still used in some German school science text-books as late as last century. In the years leading to 1520 he produced a wide range of works, including the woodblocks for the first western printed star charts in 1515 and portraits in tempera on linen in 1516.\n\nFrom 1512, Maximilian I became Dürer's major patron. His commissions included \"The Triumphal Arch\", a vast work printed from 192 separate blocks, the symbolism of which is partly informed by Pirckheimer's translation of Horapollo's \"Hieroglyphica\". The design program and explanations were devised by Johannes Stabius, the architectural design by the master builder and court-painter Jörg Kölderer and the woodcutting itself by Hieronymous Andreae, with Dürer as designer-in-chief. \"The Arch\" was followed by \"The Triumphal Procession\", the program of which was worked out in 1512 by and includes woodcuts by Albrecht Altdorfer and Hans Springinklee, as well as Dürer.\n\nDürer worked with pen on the marginal images for an edition of the Emperor's printed Prayer-Book; these were quite unknown until facsimiles were published in 1808 as part of the first book published in lithography. Dürer's work on the book was halted for an unknown reason, and the decoration was continued by artists including Lucas Cranach the Elder and Hans Baldung. Dürer also made several portraits of the Emperor, including one shortly before Maximilian's death in 1519.\n\nMaximilian's death came at a time when Dürer was concerned he was losing \"my sight and freedom of hand\" (perhaps caused by arthritis) and increasingly affected by the writings of Martin Luther. In July 1520 Dürer made his fourth and last major journey, to renew the Imperial pension Maximilian had given him and to secure the patronage of the new emperor, Charles V, who was to be crowned at Aachen. Dürer journeyed with his wife and her maid via the Rhine to Cologne and then to Antwerp, where he was well received and produced numerous drawings in silverpoint, chalk and charcoal. In addition to going to the coronation, he made excursions to Cologne (where he admired the painting of Stefan Lochner), Nijmegen, 's-Hertogenbosch, Bruges (where he saw Michelangelo's Madonna of Bruges), Ghent (where he admired van Eyck's altarpiece), and Zeeland.\n\nDürer took a large stock of prints with him and wrote in his diary to whom he gave, exchanged or sold them, and for how much. This provides rare information of the monetary value placed on prints at this time. Unlike paintings, their sale was very rarely documented. While providing valuable documentary evidence, Dürer's Netherlandish diary also reveals that the trip was not a profitable one. For example, Dürer offered his last portrait of Maximilian to his daughter, Margaret of Austria, but eventually traded the picture for some white cloth after Margaret disliked the portrait and declined to accept it. During this trip he also met Bernard van Orley, Jan Provoost, Gerard Horenbout, Jean Mone, Joachim Patinir and Tommaso Vincidor, though he did not, it seems, meet Quentin Matsys.\n\nAt the request of Christian II of Denmark, Dürer went to Brussels to paint the King's portrait. There he saw \"the things which have been sent to the king from the golden land\"—the Aztec treasure that Hernán Cortés had sent home to Holy Roman Emperor Charles V following the fall of Mexico. Dürer wrote that this treasure \"was much more beautiful to me than miracles. These things are so precious that they have been valued at 100,000 florins\". Dürer also appears to have been collecting for his own cabinet of curiosities, and he sent back to Nuremberg various animal horns, a piece of coral, some large fish fins, and a wooden weapon from the East Indies.\n\nHaving secured his pension, Dürer finally returned home in July 1521, having caught an undetermined illness—perhaps malaria —which afflicted him for the rest of his life, and greatly reduced his rate of work.\n\nOn his return to Nuremberg, Dürer worked on a number of grand projects with religious themes, including a crucifixion scene and a Sacra Conversazione, though neither was completed. This may have been due in part to his declining health, but perhaps also because of the time he gave to the preparation of his theoretical works on geometry and perspective, the proportions of men and horses, and fortification.\n\nHowever, one consequence of this shift in emphasis was that during the last years of his life, Dürer produced comparatively little as an artist. In painting, there was only a portrait of , a , , and two panels showing St. John with St. Peter in and St. Paul with St. Mark in the . This last great work, the Four Apostles, was given by Dürer to the City of Nuremberg—although he was given 100 guilders in return.\n\nAs for engravings, Dürer's work was restricted to portraits and illustrations for his treatise. The portraits include Cardinal-Elector Albert of Mainz; Frederick the Wise, elector of Saxony; the humanist scholar Willibald Pirckheimer; Philipp Melanchthon, and Erasmus of Rotterdam. For those of the Cardinal, Melanchthon, and Dürer's final major work, a drawn portrait of the Nuremberg patrician Ulrich Starck, Dürer depicted the sitters in profile, perhaps reflecting a more mathematical approach.\n\nDespite complaining of his lack of a formal classical education, Dürer was greatly interested in intellectual matters and learned much from his boyhood friend Willibald Pirckheimer, whom he no doubt consulted on the content of many of his images. He also derived great satisfaction from his friendships and correspondence with Erasmus and other scholars. Dürer succeeded in producing two books during his lifetime. \"The Four Books on Measurement\" were published at Nuremberg in 1525 and was the first book for adults on mathematics in German, as well as being cited later by Galileo and Kepler. The other, a work on city fortifications, was published in 1527. \"The Four Books on Human Proportion\" were published posthumously, shortly after his death in 1528.\n\nDürer died in Nuremberg at the age of 56, leaving an estate valued at 6,874 florins—a considerable sum. His large house (purchased in 1509 from the heirs of the astronomer Bernhard Walther), where his workshop was located and where his widow lived until her death in 1539, remains a prominent Nuremberg landmark. It is now a museum. He is buried in the \"Johannisfriedhof\" cemetery.\n\nDürer's writings suggest that he may have been sympathetic to Martin Luther's ideas, though it is unclear if he ever left the Catholic Church. Dürer wrote of his desire to draw Luther in his diary in 1520: \"And God help me that I may go to Dr. Martin Luther; thus I intend to make a portrait of him with great care and engrave him on a copper plate to create a lasting memorial of the Christian man who helped me overcome so many difficulties.\" In a letter to Nicholas Kratzer in 1524, Dürer wrote \"because of our Christian faith we have to stand in scorn and danger, for we are reviled and called heretics.\" Most tellingly, Pirckheimer wrote in a letter to Johann Tscherte in 1530: \"I confess that in the beginning I believed in Luther, like our Albert of blessed memory...but as anyone can see, the situation has become worse.\" Dürer may even have contributed to the Nuremberg City Council's mandating Lutheran sermons and services in March 1525. Notably, Dürer had contacts with various reformers, such as Zwingli, Andreas Karlstadt, Melanchthon, Erasmus and Cornelius Grapheus from whom Dürer received Luther's \"Babylonian Captivity\" in 1520.\n\nDürer's later works have also been claimed to show Protestant sympathies. For example, his woodcut of \"The Last Supper\" of 1523 has often been understood to have an evangelical theme, focussing as it does on Christ espousing the Gospel, as well the inclusion of the Eucharistic cup, an expression of Protestant utraquism, although this interpretation has been questioned. The delaying of the engraving of St Philip, completed in 1523 but not distributed until 1526, may have been due to Dürer's uneasiness with images of Saints; even if Dürer was not an iconoclast, in his last years he evaluated and questioned the role of art in religion.\n\nDürer exerted a huge influence on the artists of succeeding generations, especially in printmaking, the medium through which his contemporaries mostly experienced his art, as his paintings were predominantly in private collections located in only a few cities. His success in spreading his reputation across Europe through prints was undoubtedly an inspiration for major artists such as Raphael, Titian, and Parmigianino, all of whom collaborated with printmakers in order to promote and distribute their work.\n\nHis work in engraving seems to have had an intimidating effect upon his German successors, the \"Little Masters\" who attempted few large engravings but continued Dürer's themes in small, rather cramped compositions. Lucas van Leyden was the only Northern European engraver to successfully continue to produce large engravings in the first third of the 16th century. The generation of Italian engravers who trained in the shadow of Dürer all either directly copied parts of his landscape backgrounds (Giulio Campagnola, Giovanni Battista Palumba, Benedetto Montagna and Cristofano Robetta), or whole prints (Marcantonio Raimondi and Agostino Veneziano). However, Dürer's influence became less dominant after 1515, when Marcantonio perfected his new engraving style, which in turn travelled over the Alps to dominate Northern engraving also.\n\nIn painting, Dürer had relatively little influence in Italy, where probably only his altarpiece in Venice was seen, and his German successors were less effective in blending German and Italian styles. His intense and self-dramatizing self-portraits have continued to have a strong influence up to the present, especially on painters in the 19th and 20th century who desired a more dramatic portrait style. Dürer has never fallen from critical favour, and there have been significant revivals of interest in his works in Germany in the \"Dürer Renaissance\" of about 1570 to 1630, in the early nineteenth century, and in German nationalism from 1870 to 1945.\n\nDürer's study of human proportions and the use of transformations to a coordinate grid to demonstrate facial variation inspired similar work by D'Arcy Thompson in his book \"On Growth and Form\".\n\nThe Lutheran Church remembers Dürer as a great Christian annually on April 6, along with Lucas Cranach the Elder and Hans Burgkmair. The liturgical calendar of the Episcopal Church (United States) remembers him, Cranach and Matthias Grünewald on August 5.\n\nIn all his theoretical works, in order to communicate his theories in the German language rather than in Latin, Dürer used graphic expressions based on a vernacular, craftsmen's language. For example, \"Schneckenlinie\" (\"snail-line\") was his term for a spiral form. Thus, Dürer contributed to the expansion in German prose which Martin Luther had begun with his translation of the Bible.\n\nDürer's work on geometry is called the \"Four Books on Measurement\" (\"Underweysung der Messung mit dem Zirckel und Richtscheyt\" or \"Instructions for Measuring with Compass and Ruler\"). The first book focuses on linear geometry. Dürer's geometric constructions include helices, conchoids and epicycloids. He also draws on Apollonius, and Johannes Werner's 'Libellus super viginti duobus elementis conicis' of 1522.\n\nThe second book moves onto two dimensional geometry, i.e. the construction of regular polygons. Here Dürer favours the methods of Ptolemy over Euclid.\n\nThe third book applies these principles of geometry to architecture, engineering and typography.\n\nIn architecture Dürer cites Vitruvius but elaborates his own classical designs and columns. In typography, Dürer depicts the geometric construction of the Latin alphabet, relying on Italian precedent. However, his construction of the Gothic alphabet is based upon an entirely different modular system. The fourth book completes the progression of the first and second by moving to three-dimensional forms and the construction of polyhedra. Here Dürer discusses the five Platonic solids, as well as seven Archimedean semi-regular solids, as well as several of his own invention.\n\nIn all these, Dürer shows the objects as nets. Finally, Dürer discusses the Delian Problem and moves on to the 'construzione legittima', a method of depicting a cube in two dimensions through linear perspective. It was in Bologna that Dürer was taught (possibly by Luca Pacioli or Bramante) the principles of linear perspective, and evidently became familiar with the 'costruzione legittima' in a written description of these principles found only, at this time, in the unpublished treatise of Piero della Francesca. He was also familiar with the 'abbreviated construction' as described by Alberti and the geometrical construction of shadows, a technique of Leonardo da Vinci. Although Dürer made no innovations in these areas, he is notable as the first Northern European to treat matters of visual representation in a scientific way, and with understanding of Euclidean principles. In addition to these geometrical constructions, Dürer discusses in this last book of \"Underweysung der Messung\" an assortment of mechanisms for drawing in perspective from models and provides woodcut illustrations of these methods that are often reproduced in discussions of perspective.\n\nDürer's work on human proportions is called the \"Four Books on Human Proportion\" (\"Vier Bücher von Menschlicher Proportion\") of 1528. The first book was mainly composed by 1512/13 and completed by 1523, showing five differently constructed types of both male and female figures, all parts of the body expressed in fractions of the total height. Dürer based these constructions on both Vitruvius and empirical observations of, \"two to three hundred living persons,\" in his own words. The second book includes eight further types, broken down not into fractions but an Albertian system, which Dürer probably learned from Francesco di Giorgio's 'De harmonica mundi totius' of 1525. In the third book, Dürer gives principles by which the proportions of the figures can be modified, including the mathematical simulation of convex and concave mirrors; here Dürer also deals with human physiognomy. The fourth book is devoted to the theory of movement.\n\nAppended to the last book, however, is a self-contained essay on aesthetics, which Dürer worked on between 1512 and 1528, and it is here that we learn of his theories concerning 'ideal beauty'. Dürer rejected Alberti's concept of an objective beauty, proposing a relativist notion of beauty based on variety. Nonetheless, Dürer still believed that truth was hidden within nature, and that there were rules which ordered beauty, even though he found it difficult to define the criteria for such a code. In 1512/13 his three criteria were function ('Nutz'), naïve approval ('Wohlgefallen') and the happy medium ('Mittelmass'). However, unlike Alberti and Leonardo, Dürer was most troubled by understanding not just the abstract notions of beauty but also as to how an artist can create beautiful images. Between 1512 and the final draft in 1528, Dürer's belief developed from an understanding of human creativity as spontaneous or inspired to a concept of 'selective inward synthesis'. In other words, that an artist builds on a wealth of visual experiences in order to imagine beautiful things. Dürer's belief in the abilities of a single artist over inspiration prompted him to assert that \"one man may sketch something with his pen on half a sheet of paper in one day, or may cut it into a tiny piece of wood with his little iron, and it turns out to be better and more artistic than another's work at which its author labours with the utmost diligence for a whole year.\"\n\nFor lists of Albrecht Dürer's works, see:\n\n\n\n\n", "id": "2402", "title": "Albrecht Dürer"}
{"url": "https://en.wikipedia.org/wiki?curid=2403", "text": "Australian rules football\n\nAustralian rules football, officially known as Australian football, but also called Aussie rules, football or footy (and in some regions marketed as AFL after the Australian Football League), is a contact sport played between two teams of eighteen players on an oval-shaped field, often a modified cricket ground.\n\nThe main way to score points is by kicking the oval-shaped ball between the two tall goal posts. The team with the higher score by the end of the match wins unless a draw is declared.\n\nDuring general play, players may position themselves anywhere on the field and use any part of their bodies to move the ball. The primary methods are kicking, handballing and running with the ball. There are rules on how the ball can be handled: for example, players running with the ball must intermittently bounce or touch it on the ground. Throwing the ball is not allowed and players must not get caught holding the ball. A distinctive feature of the game is the mark, where players anywhere on the field who catch a ball from a kick (with specific conditions) are awarded possession. Possession of the ball is in dispute at all times except when a free kick or mark is paid. Players can tackle using their hands or use their whole body to obstruct opponents. Dangerous physical contact (such as pushing an opponent in the back), interference when marking and deliberately slowing the play are discouraged with free kicks, distance penalties or suspension for a certain number of matches, depending on the seriousness of the infringement. The game features frequent physical contests, spectacular marking, fast movement of both players and the ball and high scoring.\n\nThe sport's origins can be traced to football matches played in Melbourne, Victoria in 1858, inspired by English public school football games. Seeking to develop a game more suited to adults and Australian conditions, the Melbourne Football Club published the first laws of Australian football in May 1859, making it the oldest of the world's major football codes.\n\nAustralian football has the highest spectator attendance and television viewership of all sports in Australia, while the AFL, the sport's only fully professional competition, is the nation's wealthiest sporting body. Its annual Grand Final is the highest attended club championship event in the world. The sport is also played at amateur level in many countries and in several variations. The game's rules are governed by the AFL Commission with the advice of the AFL's Laws of the Game Committee.\n\nThere is evidence of football being played sporadically in the Australian colonies in the first half of the 19th century. Compared to cricket and horse racing, football was viewed as a minor \"amusement\" at the time, and while little is known about these early one-off games, it is clear they share no causal link with Australian football. In 1858, in a move that would help to shape Australian football in its formative years, public schools in Melbourne, Victoria began organising football games inspired by precedents at English public schools. The earliest such match, held in St Kilda on 15 June, was between Melbourne Grammar and St Kilda Grammar.\n\nOn 10 July 1858, the Melbourne-based \"Bell's Life in Victoria and Sporting Chronicle\" published a letter by Tom Wills, captain of the Victoria cricket team, calling for the formation of a \"foot-ball club\" with a \"code of laws\" to keep cricketers fit during winter. Born in Australia, Wills played a nascent form of rugby football whilst a pupil at Rugby School in England, and returned to his homeland a star athlete and cricketer. His letter is regarded by many historians as giving impetus for the development of a new code of football today known as Australian football. Two weeks later, Wills' friend, cricketer Jerry Bryant, posted an advertisement for a scratch match at the Richmond Paddock adjoining the Melbourne Cricket Ground (MCG). This was the first of several \"kickabouts\" held that year involving members of the Melbourne Cricket Club, including Wills, Bryant, W. J. Hammersley and J. B. Thompson. Trees were used as goalposts and play typically lasted an entire afternoon. Without an agreed upon code of laws, some players were guided by rules they had learned in the British Isles, \"others by no rules at all\".\n\nAnother significant milestone in 1858 was a match played under experimental rules between Melbourne Grammar and Scotch College, held at the Richmond Paddock. This 40-a-side contest, umpired by Wills and Scotch College teacher John Macadam, began on 7 August and continued over two subsequent Saturdays, ending in a draw with each side kicking one goal. It is commemorated with a statue outside the MCG, and the two schools have competed annually ever since in the Cordner-Eggleston Cup, the world's oldest continuous football competition.\n\nSince the early 20th century, it has been suggested that Australian football was derived from the Irish sport of Gaelic football, despite the Australian code predating it by almost 30 years. There is no archival evidence in favour of a Gaelic influence, and the style of play shared between the two modern codes was evident in Australia long before the Irish game evolved in a similar direction. Another theory, first proposed in 1983, posits that Wills, having grown up amongst Aborigines in Victoria, may have seen or played the Aboriginal game of Marn Grook, and incorporated some of its features into early Australian football. This is purely speculative, and according to biographer Greg de Moore's research, Wills was \"almost solely influenced by his experience at Rugby School\".\n\nA loosely organised Melbourne side, captained by Wills, played against other football enthusiasts in the winter and spring of 1858. The following year, on 14 May, the Melbourne Football Club officially came into being, making it one of the world's oldest football clubs. Three days later, Wills, Hammersley, Thompson and teacher Thomas H. Smith met near the MCG at the Parade Hotel, owned by Bryant, and drafted ten simple rules: \"The Rules of the Melbourne Football Club\". These are the laws from which Australian football evolved. The document was signed by the rule-framers and three other club office bearers: Alex Bruce, T. Butterworth and J. Sewell. The club's stated aim was to create a code that was suited to the hard playing surfaces around Melbourne, and to eliminate the roughest aspects of English school games—such as \"hacking\" (shin-kicking) in Rugby School football—to lessen the chance of injuries to working men. In another significant departure from English public school football, the Melbourne rules omitted any offside law. \"The new code was as much a reaction against the school games as influenced by them\", writes Mark Pennings.\n\nThe rules were distributed throughout the colony; Thompson in particular did much to promote the new code in his capacity as a journalist. Australian football's date of codification predates that of any other major football code, including soccer (codified in 1863) and rugby union (codified in 1871).\n\nFollowing Melbourne's lead, Geelong and Melbourne University also formed football clubs in 1859. While many early Victorian teams participated in one-off matches, most had not yet formed clubs for regular competition. A South Yarra side devised its own rules. To ensure the supremacy of the Melbourne rules, the first-club level competition in Australia, the Caledonian Society's Challenge Cup (1861–64), stipulated that only the Melbourne rules were to be used. This law was reinforced by the Athletic Sports Committee (ASC), which ran a variation of the Challenge Cup in 1865–66. With input from other clubs, the rules underwent several minor revisions, establishing a uniform code known as \"Victorian rules\". In 1866, the \"first distinctively Victorian rule\", the running bounce, was formalised at a meeting of club delegates chaired by H. C. A. Harrison, an influential pioneer who took up football in 1859 at the invitation of Wills, his cousin.\n\nThe game around this time was defensive and low-scoring, played low to the ground in congested rugby-style scrimmages. The typical match was a 20-per-side affair, played with a ball that was roughly spherical, and lasted until a team scored two goals. The shape of the playing field had yet to be standarnised; matches often took place in rough, tree-spotted public parks, most notably the Richmond Paddock (Yarra Park), known colloquially as the Melbourne Football Ground. Wills argued that the turf of cricket fields would benefit from being trampled upon by footballers in winter, and as early as 1859, football was allowed on the MCG. However, cricket authorities frequently denied football on their grounds until the 1870s, when they saw an opportunity to capitalise on the sport's growing popularity. Football gradually adapted to an oval-shaped field, and most grounds in Victoria expanded to accommodate the dual purpose—a situation that continues to this day.\n\nAs \"Victorian rules\" gained roots in other Australasian colonies—beginning with South Australia (1860), Tasmania (1864), Queensland (1866), and New Zealand (1871)—it came to be known as \"Australian rules\" or \"Australasian rules\". In 1877, the sport's first governing bodies, the South Australian Football Association (SAFA) and the Victorian Football Association (VFA), formed on 30 April and 17 May respectively. The game was introduced to New South Wales in 1877 and Western Australia in 1881, where it took hold during the colony's gold rushes.\n\nBy the 1880s, Australian football had become the prevailing football code in Australia's southern and western colonies, and experienced a period of dominance in Queensland, where, like in areas of New South Wales, it struggled to thrive, largely due to the spread of rugby football, regional rivalries and the lack of strong local governing bodies. In the case of Sydney, denial of access to grounds, the influence of university headmasters from Britain who favoured rugby, and the loss of players to other codes inhibited the game's growth.\n\nIn 1879, the first intercolonial match took place in Melbourne between Victoria and South Australia, and clubs began touring the colonies. By this stage, the sport had become the first code of football to develop mass spectator appeal, with important matches drawing world record attendances for sports viewing. New rules such as holding the ball led to a \"golden era\" of fast, long-kicking and high-marking football in the 1880s, a time which also saw the rise of professionalism, particularly in Western Australia and Victoria, and players such as George Coulthard achieve superstardom. Australian football was now widely referred to as \"the people's game\".\n\nIn 1896, delegates from six of the wealthiest VFA clubs—Carlton, Essendon, Fitzroy, Geelong, Melbourne and South Melbourne—met to discuss the formation of a breakaway professional competition. Later joined by Collingwood and St Kilda, the clubs formed the Victorian Football League (VFL), which held its inaugural season in 1897. The VFL's popularity grew rapidly as it made several innovations, such as instituting a finals system, reducing teams from 20 to 18 players, and introducing the behind as a score. By 1925, with the addition of Hawthorn, Footscray and North Melbourne, it had become the preeminent league in the country and would take a leading role in many aspects of the sport.\n\nBoth World War I and World War II had a devastating effect on Australian football and on Australian sport in general. While scratch matches were played by Australian \"diggers\" in remote locations around the world, the game lost many of its great players to wartime service. Some clubs and competitions never fully recovered. Between 1914 and 1915, a proposed hybrid code of Australian football and rugby league, the predominant code of football in New South Wales and Queensland, was trialed without success. World War I saw the game in New Zealand go into recess for three quarters of a century. In Queensland, the state league went into recess for the duration of the war. VFL club University left the league and went into recess due to severe casualties. The WAFL lost two clubs and the SANFL was suspended for one year in 1916 due to heavy club losses. The ANZAC Day clash is one example of how the war continues to be remembered in the football community.\n\nThe role of the Australian National Football Council (ANFC) was primarily to govern the game at a national level and to facilitate interstate representative and club competition. The ANFC ran the Championship of Australia, the first national club competition, which commenced in 1888 and saw clubs from different states compete on an even playing field. Although clubs from other states were at times invited, the final was almost always between the premiers from the two strongest state competitions of the time—South Australia and Victoria—and the majority of matches were played in Adelaide at the request of the SAFA/SAFL. The last match was played in 1976, with North Adelaide being the last non-Victorian winner in 1972. Between 1976 and 1987, the ANFC, and later the Australian Football Championships (AFC) ran a night series, which invited clubs and representative sides from around the country to participate in a knock-out tournament parallel to the premiership seasons, which Victorian sides still dominated.\n\nWith the lack of international competition, state representative matches were regarded with great importance. The Australian Football Council co-ordinated regular interstate carnivals, including the Australasian Football Jubilee, held in Melbourne in 1908 to celebrate the game's bicentenary. Due in part to the VFL poaching talent from other states, Victoria dominated interstate matches for three quarters of a century. State of Origin rules, introduced in 1977, stipulated that rather than representing the state of their adopted club, players would return to play for the state they were first recruited in. This instantly broke Victoria's stranglehold over state titles and Western Australia and South Australia began to win more of their games against Victoria. Both New South Wales and Tasmania scored surprise victories at home against Victoria in 1990.\n\nThe term \"Barassi Line\", named after VFL star Ron Barassi, was coined by scholar Ian Turner in 1978 to describe the \"fictitious geographical barrier\" separating large parts of New South Wales and Queensland which predominately followed rugby from the rest of the country, where Australian football reigned. It became a reference point for the expansion of Australian football and for establishing a national league.\n\nThe way the game was played had changed dramatically due to innovative coaching tactics, with the phasing out of many of the game's kicking styles and the increasing use of handball; while presentation was influenced by television.\n\nIn 1982, in a move that heralded big changes within the sport, one of the original VFL clubs, South Melbourne, relocated to Sydney and became known as the Sydney Swans. In the late 1980s, due to the poor financial standing of many of the Victorian clubs, the VFL pursued a more national competition. Two more non-Victorian clubs, West Coast and Brisbane, joined the league in 1987. In their early years, the Sydney and Brisbane clubs struggled both on and off-field because the substantial TV revenues they generated by playing on a Sunday went to the VFL. To protect these revenues the VFL granted significant draft concessions and financial aid to keep the expansion clubs competitive. Each club was required to pay a licence fee which allowed the Victorian-based clubs to survive.\n\nThe VFL changed its name to the Australian Football League (AFL) for the 1990 season, and over the next decade, three non-Victorian clubs gained entry: Adelaide (1991), Fremantle (1995) and the SANFL's Port Adelaide (1997), the only pre-existing club outside Victoria to join the league. In 2011 and 2012 respectively, two new non-Victorian clubs were added to the competition: Gold Coast and Greater Western Sydney. The AFL, currently with 18 member clubs, is the sport's elite competition and most powerful body. Following the emergence of the AFL, state leagues were quickly relegated to a second-tier status. The VFA merged with the former VFL reserves competition in 1998, adopting the VFL name. State of Origin also declined in importance, especially after an increasing number of player withdrawals. The AFL turned its focus to the annual International Rules Series against Ireland in 1998 before abolishing State of Origin the following year. State and territorial leagues still contest interstate matches.\n\nAlthough a Tasmanian AFL bid is ongoing, the AFL's focus has been on expanding into markets outside Australian football's traditional heartlands. The AFL regularly schedules pre-season exhibition matches in all Australian states and territories as part of the Regional Challenge. The AFL signaled further attempts at expansion in the 2010s by hosting home-and-away matches in New Zealand, followed by China.\n\nAustralian rules football playing fields have no fixed dimensions but at senior level are typically between 135 and 185 metres long and 110 and 155 metres wide wing-to-wing. The field, like the ball, is oval-shaped, and in Australia, cricket grounds are often used. No more than 18 players of each team are permitted to be on the field at any time.\n\nUp to four interchange (reserve) players may be swapped for those on the field at any time during the game. In Australian rules terminology, these players wait for substitution \"on the bench\"—an area with a row of seats on the sideline. Players must interchange through a designated interchange \"gate\" with strict penalties for too many players from one team on the field. In addition, some leagues like the AFL have each team designate one player as a substitute who can be used to make a single permanent exchange of players during a game.\n\nThere is no offside rule nor are there set positions in the rules; unlike many other forms of football, players from both teams may disperse across the whole field before the start of play. However, a typical on-field structure consists of six forwards, six defenders or \"backmen\" and six midfielders, usually two wingmen, one centre and three followers, including a ruckman, ruck-rover and rover. Only four players from each team are allowed within the centre square () at every centre bounce, which occurs at the commencement of each quarter, and to restart the game after a goal is scored. There are also other rules pertaining to allowed player positions during set plays (that is, after a mark or free kick) and during kick-ins following the scoring of a behind.\n\nA game consists of four quarters and a timekeeper officiates their duration. At the professional level, each quarter consist of 20 minutes of play, with the clock being stopped for instances such as scores, the ball going out of bounds or at the umpire's discretion, e.g. for serious injury. Lower grades of competition might employ shorter quarters of play. The umpire signals \"time-off\" to stop the clock for various reasons, such as the player in possession being tackled into stagnant play. Time resumes when the umpire signals \"time-on\" or when the ball is brought into play. Stoppages cause quarters to extend approximately 5–10 minutes beyond the 20 minutes of play. 6 minutes of rest is allowed before the second and fourth quarters, and 20 minutes of rest is allowed at \"half-time\".\n\nThe official game clock is available only to the timekeeper(s), and is not displayed to the players, umpires or spectators. The only public knowledge of game time is when the timekeeper sounds a siren at the start and end of each quarter. Coaching staff may monitor the game time themselves and convey information to players via on-field trainers or substitute players. Broadcasters usually display an approximation of the official game time for television audiences.\n\nGames are officiated by umpires. Before the game, the winner of a coin toss determines which directions the teams will play to begin. Australian football begins after the first siren, when the umpire bounces the ball on the ground (or throws it into the air if the condition of the ground is poor), and the two ruckmen (typically the tallest players from each team) battle for the ball in the air on its way back down. This is known as the \"ball-up\". Certain disputes during play may also be settled with a \"ball-up\" from the point of contention. If the ball ever goes out of bounds (beyond the oval boundary line around the edge of the field), a boundary umpire will stand with his back to the infield and return the ball into play with a \"throw-in\", a high backwards toss back into the field of play.\n\nThe ball can be propelled in any direction by way of a foot, clenched fist (called a handball or \"handpass\") or open-hand tap but it cannot be thrown under any circumstances. Once a player takes possession of the ball he must dispose of it by either kicking or handballing it. Any other method of disposal is illegal and will result in a free kick to the opposing team. This is usually called \"incorrect disposal\", \"dropping the ball\" or \"throwing\". If the ball is not in the possession of one player it can be moved on with any part of the body.\n\nA player may run with the ball, but it must be bounced or touched on the ground at least once every 15 metres. Opposition players may bump or tackle the player to obtain the ball and, when tackled, the player must dispose of the ball cleanly or risk being penalised for holding the ball. The ball carrier may only be tackled between the shoulders and knees. If the opposition player forcefully contacts a player in the back while performing a tackle, the opposition player will be penalised for a push in the back. If the opposition tackles the player with possession below the knees (a \"low tackle\" or a \"trip\") or above the shoulders (a \"high tackle\"), the team with possession of the football gets a free kick.\nIf a player takes possession of the ball that has travelled more than from another player's kick, by way of a catch, it is claimed as a \"mark\" (meaning that the game stops while he prepares to kick from the point at which he marked). Alternatively, he may choose to \"play on\" forfeiting the set shot in the hope of pressing an advantage for his team (rather than allowing the opposition to reposition while he prepares for the free kick). Once a player has chosen to play on, normal play resumes and the player who took the mark is again able to be tackled.\n\nThere are different styles of kicking depending on how the ball is held in the hand. The most common style of kicking seen in today's game, principally because of its superior accuracy, is the drop punt, where the ball is dropped from the hands down, almost to the ground, to be kicked so that the ball rotates in a reverse end over end motion as it travels through the air. Other commonly used kicks are the torpedo punt (also known as the spiral, barrel, or screw punt), where the ball is held flatter at an angle across the body, which makes the ball spin around its long axis in the air, resulting in extra distance (similar to the traditional motion of an American football punt), and the checkside punt or \"banana\", kicked across the ball with the outside of the foot used to curve the ball (towards the right if kicked off the right foot) towards targets that are on an angle. There is also the \"snap\", which is almost the same as a checkside punt except that it is kicked off the inside of the foot and curves in the opposite direction. It is also possible to kick the ball so that it bounces along the ground. This is known as a \"grubber\". Grubbers can bounce in a straight line, or curve to the left or right.\n\nApart from free kicks, marks or when the ball is in the possession of an umpire for a \"ball up\" or \"throw in\", the ball is always in dispute and any player from either side can take possession of the ball.\n\nA \"goal\", worth 6 points, is scored when the football is propelled through the goal posts at any height (including above the height of the posts) by way of a kick from the attacking team. It may fly through \"on the full\" (without touching the ground) or bounce through, but must not have been touched, on the way, by any player from either team. A goal cannot be scored from the foot of an opposition (defending) player.\n\nA \"behind\", worth 1 point, is scored when the ball passes between a goal post and a behind post at any height, or if the ball hits a goal post, or if any player sends the ball between the goal posts by touching it with any part of the body other than a foot. A behind is also awarded to the attacking team if the ball touches any part of an opposition player, including his foot, before passing between the goal posts. When an opposition player deliberately scores a behind for the attacking team (generally as a last resort to ensure that a goal is not scored) this is termed a rushed behind. As of the 2009 AFL season, a free kick is awarded against any player who deliberately rushes a behind.\n\nThe goal umpire signals a goal with two hands pointed forward at elbow height, or a behind with one hand. The goal umpire then waves flags above their heads to confirm the goal or behind to the goal umpire at the opposite end of the ground.\n\nThe team that has scored the most points at the end of play wins the game. If the scores are level on points at the end of play, then the game is a draw; extra time applies only during finals matches in some competitions.\n\nAs an example of a score report, consider a match between and with the former as the home team. Essendon's score of 11 goals and 14 behinds equates to 80 points. Melbourne's score of 10 goals and 7 behinds equates to a 67-point tally. Essendon wins the match by a margin of 13 points. Such a result would be written as:\n\nAnd spoken as:\n\nAdditionally, it can be said that:\n\nThe home team is typically listed first and the visiting side is listed second. The scoreline is written with respect to the home side.\n\nFor example, won in successive weeks, once as the home side and once as the visiting side. These would be written out thus:\n\nThe \"football season\" proper is from March to August (early autumn to late winter in Australia) with finals being held in September and October. In the tropics, the game is sometimes played in the wet season (October to March). Pre-season competitions in southern Australia usually begin in late February.\n\nThe AFL is recognised by the Australian Sports Commission as being the National Sporting Organisation for Australian Football. There are also seven state/territory-based organisations in Australia, most of which are now either owned by or affiliated to the AFL. Most of these hold annual semi-professional club competitions while the others oversee more than one league. Local semi-professional or amateur organisations and competitions are often affiliated to their state organisations.\n\nThe AFL is the \"de facto\" world governing body for Australian football. There are also a number of affiliated organisations governing amateur clubs and competitions around the world.\n\nFor almost all Australian football club competitions the aim is to win the \"Premiership\". The premiership is always decided by a \"finals series\". The teams that occupy the highest positions on the \"ladder\" after the \"home-and-away\" season play off in a \"semi-knockout\" finals series, culminating in a single Grand Final match to determine the premiers. Typically between four and eight teams contest the finals series. The team which finishes first on the ladder after the home-and-away season is referred to as a \"minor premier\", but this usually holds little stand-alone significance, other than receiving a better draw in the finals.\n\nMany suburban and amateur leagues have a sufficient number of teams to be played across several tiered divisions, with promotion of the lower division premiers and relegation of the upper division's last placed team at the end of each year. At present, none of the top level national or state level leagues in Australia are large enough to warrant this structure.\n\nThe level of interest shown by women in Australian football is considered unique among the world's football codes. It was the case in the 19th-century, as it is in modern times, that women made up approximately half of crowds at Australian football matches—a far greater proportion than soccer and the two rugby codes. This has been attributed in part to the egalitarian character of Australian football's origins in public parks where women could mingle freely and support the game in various ways.\n\nIn 2016, over 380,000 females played in organised games across Australia. The AFL Women's National Championships is women's football's state of origin competition. On the back of the inaugural AFL Women's Draft in 2013 and a series of exhibition matches at the MCG, the AFL stated that, by 2020, it would like to establish AFL Women's, a semi-professional, nationally televised women's league. A surge in viewing interest and participation in women's football prompted the AFL to push the founding date of the competition to 2017.\n\nMany related games have emerged from Australian football, mainly with variations of contact to encourage greater participation. These include Auskick (played by children aged between 5 and 12), kick-to-kick (and its variants end-to-end footy and marks up), rec footy, 9-a-side footy, masters Australian football, handball and longest-kick competitions. Players outside of Australia sometimes engage in related games adapted to available fields, like metro footy (played on gridiron fields) and Samoa rules (played on rugby fields).\n\nThe similarities between Australian football and the Irish sport of Gaelic football have allowed for the creation of a hybrid code known as international rules football. The first international rules matches were contested in Ireland during the 1967 Australian Football World Tour. Since then, various sets of compromise rules have been trialed, and in 1984 the International Rules Series commenced with national representative sides selected by Australia's state leagues (later by the AFL) and the Gaelic Athletic Association (GAA). The competition became an annual event in 1998, but was postponed indefinitely in 2007 when the GAA pulled out due to Australia's severe and aggressive style of play. It resumed in Australia in 2008 under new rules to protect the player with the ball.\n\nAustralian football is played at an amateur level in various countries throughout the world, currently there are no professional competitions outside of Australia. Twenty countries participated in the Euro Cup and 23 countries have participated in the International Cup with both competitions prohibiting Australian players. Over 20 countries have either affiliation or working agreements with the AFL. There have been many VFL/AFL players who were born outside Australia, an increasing number of which have been recruited through initiatives such as the Irish experiment and more recently, international scholarship programs.\n\nIn the late 19th and early 20th centuries, the game spread with the Australian diaspora to areas such as New Zealand and South Africa; however this growth went into rapid decline following World War I. After World War II, the sport experienced a small amount of growth in the Pacific region, particularly in Nauru (where Australian football is the national sport) as well as Papua New Guinea and New Zealand.\n\nMost of the current amateur clubs and leagues in existence have developed since the 1980s, when leagues began to be established in North America, Europe and Asia. The sport developed a cult following in the United States when matches were broadcast on ESPN in the late 1980s. As the size of the Australian diaspora has increased, so has the number of clubs outside Australia. This expansion has been further aided by multiculturalism and assisted by exhibition matches as well as exposure generated through players who have converted to and from other football codes. In Papua New Guinea, New Zealand, South Africa, Canada, and the United States there are many thousands of players.\n\nA fan of the sport since attending school in Geelong, Prince Charles is the Patron of AFL Europe. In 2013, participation across AFL Europe's 21 member nations was more than 5,000 players, the majority of which are European nationals rather than Australian expats. The sport also has a growing presence in India.\n\nThe AFL became the de facto governing body when it pushed for the closure of the International Australian Football Council in 2002. The Australian Football International Cup, held triennially in Melbourne since 2002, is the highest level of international competition.\n\nAustralian football is a sport rich in tradition and Australian cultural references, especially surrounding the rituals of gameday for players, officials and supporters.\n\nAustralian football has been an inspiration for writers and poets including Manning Clarke, Bruce Dawe and Philip Hodgins. Paintings by Arthur Streeton (\"The National Game\", 1889) and Sidney Nolan (\"Footballer\", 1946) helped to establish Australian football as a serious subject for artists. Many Aboriginal artists have explored the game, often fusing it with the mythology of their region. Statues of Australian football identities can be found throughout the country. In cartooning, WEG's VFL/AFL premiership posters—inaugurated in 1954—have achieved iconic status among Australian football fans. Dance sequences based on Australian football feature heavily in Robert Helpmann's 1964 ballet \"The Display\", his first and most famous work for the Australian Ballet. The game has also inspired well-known plays such as \"And the Big Men Fly\" (1963) by Alan Hopgood and David Williamson's \"The Club\" (1977), which was adapted into a 1980 film, directed by Bruce Beresford. Mike Brady's 1979 hit \"Up There Cazaly\" is considered an Australian football anthem, and references to the sport can be found in works by popular musicians, from singer-songwriter Paul Kelly to the alternative rock band TISM. Many Australian football video games have been released, most notably the AFL series.\nAustralian football has attracted more overall interest among Australians (as measured by the Sweeney Sports report) than any other football code, and, when compared with all sports throughout the nation, has consistently ranked first in the winter reports, and most recently third behind cricket and swimming in summer. Over 875,000 fans were paying members of AFL clubs in 2016, which is equal to one in every 28 Australians. The 2016 AFL Grand Final was the year's most-watched television broadcast in Australia, with an in-home audience of up to 6.5 million watching the match.\n\nIn 2006, 615,549 registered participants played Australian football in Australia. Participation increased 7.84% between 2005 and 2006. The Australian Sports Commission statistics show a 64% increase in the total number of participants over the 10-year period between 2001 and 2010. In 2008 there were 35,000 people in 32 countries playing in structured competitions of Australian football outside of Australia.\n\nFor the centenary of the VFL/AFL in 1996, the Australian Football Hall of Fame was established. In that year 136 identities were inducted, including 100 players, 10 coaches, 10 umpires, 10 administrators and six media representatives.\n\nThe elite \"Legend\" status was bestowed on 12 members of the Hall of Fame in 1996: Ron Barassi, Haydn Bunton Sr., Roy Cazaly, John Coleman, Jack Dyer, Polly Farmer, Leigh Matthews, John Nicholls, Bob Pratt, Dick Reynolds, Bob Skilton and Ted Whitten.\n\nThe following thirteen members have been promoted to the status of \"Legend\" since 1996: Ian Stewart (1997), Gordon Coventry (1998), Peter Hudson (1999), Kevin Bartlett (2000), Barrie Robran (2001), Bill Hutchison (2003), Jock McHale (2005), Darrel Baldock (2006), Norm Smith (2007), Alex Jesaulenko (2008), Kevin Murray (2010), Barry Cable (2012), and Tony Lockett (2015).\n\n\nBooks\n\nJournals\n", "id": "2403", "title": "Australian rules football"}
{"url": "https://en.wikipedia.org/wiki?curid=2405", "text": "Aon (company)\n\nAon plc is a British multinational corporation headquartered in London, United Kingdom, that provides risk management, insurance and reinsurance brokerage, investment banking, human resource solutions and outsourcing services. Aon has approximately 500 offices worldwide, serving 120 countries with 72,000 employees.\n\nIn 2011, Aon was ranked as the largest insurance broker in the world based on revenue. Aon was the principal partner and global shirt sponsor of the Premier League team Manchester United F.C. from 2010 until 2014.\n\nAon was created in 1982 when the Ryan Insurance Group merged with the Combined Insurance Company of America. In 1987, that company was renamed Aon, a Gaelic word meaning [one].\n\nIn January 2012, Aon announced that its headquarters would be moved to London.\n\nAon is a global professional services firm that advises clients on the topics of risk and human resources. The company is a provider of risk management, insurance and reinsurance brokerage, human resource solutions and outsourcing services.\n\nAon is divided into three business units that each specialize in a particular line of business. The firm's risk management business, Aon Risk Solutions provides retail property/casualty, liability, and other insurance products for groups and businesses, as well as risk management services. Its reinsurance business, Aon Benfield, specializes in reinsurance brokerage and investment banking & capital advisory (through Aon Securities Inc.). The firm's human resource solutions business, Aon Hewitt, provides consulting and outsourcing services to clients.\n\nW. Clement Stone's mother bought a small Detroit insurance agency, and in 1918 brought her son into the business. Mr. Stone sold low-cost, low-benefit accident insurance, underwriting and issuing policies on-site. The next year he founded his own agency, the Combined Registry Co.\n\nAs the Great Depression began, Stone reduced his workforce and improved training. Forced by his son's respiratory illness to winter in the South, Stone moved to Arkansas and Texas. In 1939 he bought American Casualty Insurance Co. of Dallas, Texas. It was consolidated with other purchases as the Combined Insurance Co. of America in 1947. The company continued through the 1950s and 1960s, continuing to sell health and accident policies. In the 1970s, Combined expanded overseas despite being hit hard by the recession.\n\nIn 1982, after 10 years of stagnation under Clement Stone Jr., the elder Stone, then 79, resumed control until the completion of a merger with Ryan Insurance Co. allowed him to transfer control to Patrick Ryan. Ryan, the son of a Ford dealer in Wisconsin, had started his company as an auto credit insurer in 1964. In 1976, the company bought the insurance brokerage units of the Esmark conglomerate. Ryan focused on insurance brokering and added more upscale insurance products. He also trimmed staff and took other cost-cutting measures, and in 1987 he changed Combined's name to Aon. In 1992, he bought Dutch insurance broker Hudig-Langeveldt. In 1995, the company sold its remaining direct life insurance holdings to General Electric to focus on consulting. The following year, it began offering hostile takeover insurance policies to small and mid-sized companies.\n\nAon built a global presence through purchases. In 1997, it bought The Minet Group, as well as insurance brokerage Alexander & Alexander Services, Inc. in a deal that made Aon (temporarily) the largest insurance broker worldwide. The firm made no US buys in 1998, but doubled its employee base with purchases including Spain's largest retail insurance broker, Gil y Carvajal, and the formation of Aon Korea, the first non-Korean firm of its kind to be licensed there.\n\nResponding to industry demands, Aon announced its new fee disclosure policy in 1999, and the company reorganised to focus on buying personal line insurance firms and to integrate its acquisitions. That year it bought Nikols Sedgwick Group, an Italian insurance firm, and formed RiskAttack (with Zurich US), a risk analysis and financial management concern aimed at technology companies. The cost of integrating its numerous purchases, however, hammered profits in 1999.\n\nDespite its troubles, in 2000 Aon bought Reliance Group's accident and health insurance business, as well as Actuarial Sciences Associates, a compensation and employee benefits consulting company. Later in that year, however, the company decided to cut 6% of its workforce as part of a restructuring effort. In 2003, the company saw revenues increase primarily because of rate hikes in the insurance industry. Also that year, Endurance Specialty, a Bermuda-based underwriting operation that Aon helped to establish in November 2001 along with other investors, went public. The next year Aon sold most of its holdings in Endurance.\n\nIn late 2007, Aon announced the divestiture of its underwriting business. With this move, the firm sold off its two major underwriting subsidiaries: Combined Insurance Company of America (acquired by ACE Limited for $2.4 billion) and Sterling Life Insurance Company (purchased by Munich Re Group for $352 million). The low margin and capital-intensive nature of the underwriting industry was the primary reason for the firm's decision to divest. Upon completion of the move, Aon turned its attention to expanding its broking and consulting capabilities.\n\nThis growth strategy manifested in November 2008 when Aon announced it had acquired reinsurance intermediary and capital advisor Benfield Group Limited for $1.75 billion. The acquisition amplified the firm's broking capabilities, positioning Aon one of the largest players in the reinsurance brokerage industry.\n\nIn 2010, Aon made its most significant acquisition to date with the purchase of Lincolnshire, Illinois-based Hewitt Associates for $4.9 billion. Aside from drastically boosting Aon's human resources consulting capacity and entering the firm into the business process outsourcing industry, the move added 23,000 colleagues and more than $3 billion in revenue.\n\nIn 10 February 2017, Aon announced that it is selling its employee benefits outsourcing business to Private equity firm Blackstone Group LP (BX.N) for US$4.8 billion (£3.8 billion) \n\nAon's New York offices were on the 92nd and 98th–105th floors of the South Tower of the World Trade Center at the time of the 11 September 2001 terrorist attack. When the North Tower was struck at 8:46 a.m., many executives began evacuating their employees from the upper floors of the South Tower. The evacuation of Aon's offices, ordered by Eric Eisenberg, was carried out quickly as 924 of the estimated 1,100 Aon employees present at the time managed to evacuate the building before United Airlines Flight 175 struck it twenty stories below them at 9:03 a.m.\n\nHowever, many were influenced to stay by security guards and security announcements, or did not exit the building in time. As a result, 176 employees of Aon were killed in the attacks, including Eisenberg and Kevin Cosgrove, a vice-president of the company, who made a call to 911 when the tower collapsed at 9:59 a.m.\n\nIn 2004–2005, Aon, along with other brokers including Marsh & McLennan and Willis, fell under regulatory investigation under New York Attorney General Eliot Spitzer and other state attorneys general. At issue was the practice of insurance companies' payments to brokers (known as contingent commissions). The payments were thought to bring a conflict of interest, swaying broker decisions on behalf of carriers, rather than customers. In the spring of 2005, without acknowledging any wrongdoing, Aon agreed to a $190 million settlement, payable over 30 months.\n\nIn January 2009, Aon was fined £5.25 million in the UK by the Financial Services Authority, who stated that the fine related to the company's inadequate bribery and corruption controls, claiming that between 14 January 2005 and 30 September 2007 Aon had failed to properly assess the risks involved in its dealings with overseas firms and individuals. The Authority did not find that any money had actually made its way to illegal organisations. Aon qualified for a 30% discount on the fine as a result of its co-operation with the investigation. Aon said its conduct was not deliberate, adding it had since \"significantly strengthened and enhanced its controls around the usage of third parties\".\n\nIn December 2011, Aon Corporation paid a $16.26 million penalty to the US Securities and Exchange Commission (SEC) and the US Department of Justice (DOJ) for violations of the US Foreign Corrupt Practices Act (FCPA).\nAccording to the SEC, Aon's subsidiaries made improper payments of over $3.6 million to government officials and third-party facilitators in Costa Rica, Egypt, Vietnam, Indonesia, the United Arab Emirates, Myanmar and Bangladesh, between 1983 and 2007, to obtain and retain insurance contracts.\n\nOn 10 February 2017, Aon announced that it is selling its employee benefits outsourcing business to Private equity firm Blackstone Group LP (BX.N) for US$4.8 billion (£3.8 billion) \n\nOn 31 October 2016, Aon's Aon Risk Solutions completed acquisition of Stroz Friedberg LLC, a specialised risk management firm focusing on cybersecurity. \n\nOn 16 June 2014, Aon announced that it agreed to buy National Flood Services, Inc., a leading processor of flood insurance, from Stoneriver Group, L.P.\n\nOn 22 October 2012, Aon announced that it agreed to buy OmniPoint, Inc, a Workday consulting firm. Financial terms were not disclosed.\n\nOn 19 July 2011, Aon announced that it bought Westfield Financial Corp., the owner of insurance-industry consulting firm Ward Financial Group, from Ohio Farmers Insurance Co. Financial terms were not disclosed.\n\nOn 7 April 2011, Aon announced that it had acquired Johannesburg, South Africa-based Glenrand MIB. Financial terms were not disclosed.\n\nOn 12 July 2010, Aon announced that it had agreed to buy Lincolnshire, Illinois-based Hewitt Associates for $4.9 billion in cash and stock.\n\nOn 5 Mar 2010, Hewitt Associates announced that it acquired Senior Educators Ltd. The acquisition offers companies a new way to address retiree medical insurance commitments.\n\nOn 22 August 2008, Aon announced that it had acquired London-based Benfield Group. The acquiring price was US$1.75 billion or £935 million, with US$170 million of debt.\n\nOn February 10, 2017, Aon PLC agreed to sell its human resources outsourcing platform for $4.3 billion to Blackstone Group L.P., creating a new company.\n\nOn 3 June 2009, it was reported that Aon had signed a four-year shirt sponsorship deal with English football giant Manchester United. On 1 June 2010, Aon replaced American insurance company AIG as the principal sponsor of the club. The Aon logo was prominently displayed on the front of the club's shirts until the 2014/2015 season when Chevrolet replaced them. The deal was said to be worth £80 million over four years, replacing United's deal with AIG as the most lucrative shirt deal in history at the time.\n\nIn April 2013, Aon signed a new eight-year deal with Manchester United to rename their training ground as the Aon Training Complex and sponsor the club's training kits, reportedly worth £180 million to the club.\n\n\n", "id": "2405", "title": "Aon (company)"}
{"url": "https://en.wikipedia.org/wiki?curid=2406", "text": "Alban Berg\n\nAlban Maria Johannes Berg (; ; February 9, 1885 – December 24, 1935) was an Austrian composer of the Second Viennese School. His compositional style combined Romantic lyricism with twelve-tone technique.\n\nBerg was born in Vienna, the third of four children of Johanna and Conrad Berg. His family lived comfortably until the death of his father in 1900.\n\nHe was more interested in literature than music as a child and did not begin to compose until he was fifteen, when he started to teach himself music. In late February or early March 1902 he fathered a child with Marie Scheuchl, a servant girl in the Berg family household. His daughter, Albine, was born on December 4, 1902.\n\nBerg had little formal music education before he became a student of Arnold Schoenberg in October 1904. With Schoenberg he studied counterpoint, music theory, and harmony. By 1906, he was studying music full-time; by 1907, he began composition lessons. His student compositions included five drafts for piano sonatas. He also wrote songs, including his \"Seven Early Songs\" (\"Sieben Frühe Lieder\"), three of which were Berg's first publicly performed work in a concert that featured the music of Schoenberg's pupils in Vienna that year. The early sonata sketches eventually culminated in Berg's Piano Sonata, Op. 1 (1907–1908); it is one of the most formidable \"first\" works ever written. Berg studied with Schoenberg for six years until 1911. Berg admired him as a composer and mentor, and they remained close lifelong friends.\n\nAmong Schoenberg's teaching was the idea that the unity of a musical composition depends upon all its aspects being derived from a single basic idea; this idea was later known as \"developing variation\". Berg passed this on to his students, one of whom, Theodor W. Adorno, stated: \"The main principle he conveyed was that of variation: everything was supposed to develop out of something else and yet be intrinsically different\". The Piano Sonata is an example—the whole composition is derived from the work's opening quartal gesture and its opening phrase.\n\nBerg was a part of Vienna's cultural elite during the heady \"fin de siècle\" period. His circle included the musicians Alexander von Zemlinsky and Franz Schreker, the painter Gustav Klimt, the writer and satirist Karl Kraus, the architect Adolf Loos, and the poet Peter Altenberg. In 1906, Berg met the singer Helene Nahowski, daughter of a wealthy family (said by some to be in fact the illegitimate daughter of Emperor Franz Joseph I of Austria from his liaison with Anna Nahowski); despite the outward hostility of her family, the two were married on May 3, 1911.\n\nIn 1913, two of Berg's \"Five Songs on Picture Postcard Texts by Peter Altenberg\" (1912) were premièred in Vienna, conducted by Schoenberg in the infamous \"Skandalkonzert\". Settings of aphoristic poetic utterances, the songs are accompanied by a very large orchestra. The performance caused a riot, and had to be halted. This was a crippling blow to Berg's self-confidence: he effectively withdrew the work, which is surely one of his most innovative and assured first orchestral compositions in the literature, and it was not performed in full until 1952. The full score remained unpublished until 1966.\n\nFrom 1915 to 1918, Berg served in the Austro-Hungarian Army and during a period of leave in 1917 he accelerated work on his first opera, \"Wozzeck\". After the end of World War I, he settled again in Vienna, where he taught private pupils. He also helped Schoenberg run his Society for Private Musical Performances, which sought to create the ideal environment for the exploration and appreciation of unfamiliar new music by means of open rehearsals, repeat performances, and the exclusion of professional critics.\n\nBerg had a particular interest in the number 23, using it to structure several works. Various suggestions have been made as to the reason for this interest: that he took it from the Biorhythms theory of Wilhelm Fliess, in which a 23-day cycle is considered significant, or because he first suffered an asthma attack on 23rd of the month.\n\nThree excerpts from \"Wozzeck\" were performed in 1924, and this brought Berg his first public success. The opera, which Berg completed in 1922, was first performed on December 14, 1925, when Erich Kleiber conducted the first performance in Berlin. Today \"Wozzeck\" is seen as one of the century's most important works. Berg made a start on his second opera, the three-act \"Lulu\", in 1928 but interrupted the work in 1929 for the concert aria \"Der Wein\" which he completed that summer. \"Der Wein\" presaged \"Lulu\" in a number of ways, including vocal style, orchestration, design and text.\n\nOther well-known Berg compositions include the \"Lyric Suite\" (1926), which was later shown to employ elaborate cyphers to document a secret love affair; the post-Mahlerian \"Three Pieces for Orchestra\" (completed in 1915 but not performed until after \"Wozzeck\"); and the Chamber Concerto (\"Kammerkonzert\", 1923–25) for violin, piano, and 13 wind instruments: this latter is written so conscientiously that Pierre Boulez has called it \"Berg's strictest composition\" and it, too, is permeated by cyphers and posthumously disclosed hidden programs.\n\nLife for the musical world was becoming increasingly difficult in the 1930s both in Vienna and Germany due to the rising tide of antisemitism and the Nazi cultural ideology that denounced modernity. Even to have an association with someone who was Jewish could lead to denunciation, and Berg's \"crime\" was to have studied with the Jewish composer Arnold Schoenberg. Berg found that opportunities for his work to be performed in Germany were becoming rare, and eventually his music was proscribed and placed on the list of degenerate music. In 1932 Berg and his wife acquired an isolated lodge, the \"Waldhaus\" on the southern shore of the \"Wörthersee\", near Schiefling am See in Carinthia, where he was able to work in seclusion, mainly on Lulu and the Violin Concerto. At the end of 1934 Berg became involved in the political intrigues around finding a replacement for Clemens Krauss as director of the Vienna State Opera. As more of the performances of his work in Germany were cancelled by the Nazis, who had come to power in early 1933, he needed to ensure the new director would be an advocate for modernist music. Originally the premiere of Lulu had been planned for the Berlin State Opera, where Erich Kleiber continued to champion his music and had conducted the premiere of \"Wozzeck\" in 1925, but now this was looking increasingly uncertain, and Lulu was rejected by the Berlin authorities in the spring of 1934. Kleiber's production of the Lulu symphonic suite on 30 November 1934 in Berlin was also the occasion of his resignation in protest at the extent of conflation of culture with politics. Even in Vienna, the opportunities for the Vienna School of musicians was dwindling.\n\nBerg had interrupted the orchestration of \"Lulu\" because of an unexpected (and financially much-needed) commission from the Russian-American violinist Louis Krasner for a Violin Concerto (1935). This profoundly elegiac work, composed at unaccustomed speed and posthumously premièred, has become Berg's best-known and beloved composition. Like much of his mature work, it employs an idiosyncratic adaptation of Schoenberg's \"dodecaphonic\" or twelve-tone technique, that enables the composer to produce passages openly evoking tonality, including quotations from historical tonal music, such as a Bach chorale and a Carinthian folk song. The Violin Concerto was dedicated \"to the memory of an Angel\", Manon Gropius, the deceased daughter of architect Walter Gropius and Alma Mahler.\n\nBerg died in Vienna, on Christmas Eve 1935, from blood poisoning apparently caused by an insect-sting-induced carbuncle on his back that occurred in November. He was 50 years old.\n\nBerg completed the orchestration of only the first two acts of \"Lulu\" before he died. The first two acts were successfully premièred in Zürich in 1937, but for personal reasons Helene Berg subsequently imposed a ban on any attempt to \"complete\" the final act, which Berg had in fact completed in particell (short score) format. An orchestration was therefore commissioned in secret from Friedrich Cerha and premièred in Paris (under Pierre Boulez) only in 1979, soon after Helene Berg's own death. The complete opera has rapidly entered the repertoire as one of the landmarks of contemporary music and, like \"Wozzeck\", remains a consistent audience draw.\n\nBerg is remembered as one of the most important composers of the 20th century and to date is the most widely performed opera composer among the Second Viennese School. He is considered to have brought more \"human values\" to the twelve-tone system, his works seen as more \"emotional\" than Schoenberg's. Critically, he is seen as having preserved the Viennese tradition in his music. His popularity has been more easily secured than many other Modernists since he plausibly combined both Romantic and Expressionist idioms. Though Berg's Romanticism at one time seemed a drawback for some more modernist composers, the Berg scholar Douglas Jarman writes in the New Grove: \"As the 20th century closed, the 'backward-looking' Berg suddenly came as [George] Perle remarked, to look like its most forward-looking composer.\"\n\nThe asteroid 4528 Berg is named after him.\n\n\n\n\n\n\n\n\n\n\n", "id": "2406", "title": "Alban Berg"}
{"url": "https://en.wikipedia.org/wiki?curid=2408", "text": "Analytical chemistry\n\nAnalytical chemistry studies and uses instruments and methods used to separate, identify, and quantify matter. In practice separation, identification or quantification may constitute the entire analysis or be combined with another method. Separation isolates analytes. Qualitative analysis identifies analytes, while quantitative analysis determines the numerical amount or concentration.\n\nAnalytical chemistry consists of classical, wet chemical methods and modern, instrumental methods. Classical qualitative methods use separations such as precipitation, extraction, and distillation. Identification may be based on differences in color, odor, melting point, boiling point, radioactivity or reactivity. Classical quantitative analysis uses mass or volume changes to quantify amount. Instrumental methods may be used to separate samples using chromatography, electrophoresis or field flow fractionation. Then qualitative and quantitative analysis can be performed, often with the same instrument and may use light interaction, heat interaction, electric fields or magnetic fields . Often the same instrument can separate, identify and quantify an analyte.\n\nAnalytical chemistry is also focused on improvements in experimental design, chemometrics, and the creation of new measurement tools. Analytical chemistry has broad applications to forensics, medicine, science and engineering.\n\nAnalytical chemistry has been important since the early days of chemistry, providing methods for determining which elements and chemicals are present in the object in question. During this period significant contributions to analytical chemistry include the development of systematic elemental analysis by Justus von Liebig and systematized organic analysis based on the specific reactions of functional groups.\n\nThe first instrumental analysis was flame emissive spectrometry developed by Robert Bunsen and Gustav Kirchhoff who discovered rubidium (Rb) and caesium (Cs) in 1860.\n\nMost of the major developments in analytical chemistry take place after 1900. During this period instrumental analysis becomes progressively dominant in the field. In particular many of the basic spectroscopic and spectrometric techniques were discovered in the early 20th century and refined in the late 20th century.\n\nThe separation sciences follow a similar time line of development and also become increasingly transformed into high performance instruments. In the 1970s many of these techniques began to be used together as hybrid techniques to achieve a complete characterization of samples.\n\nStarting in approximately the 1970s into the present day analytical chemistry has progressively become more inclusive of biological questions (bioanalytical chemistry), whereas it had previously been largely focused on inorganic or small organic molecules. Lasers have been increasingly used in chemistry as probes and even to initiate and influence a wide variety of reactions. The late 20th century also saw an expansion of the application of analytical chemistry from somewhat academic chemical questions to forensic, environmental, industrial and medical questions, such as in histology.\n\nModern analytical chemistry is dominated by instrumental analysis. Many analytical chemists focus on a single type of instrument. Academics tend to either focus on new applications and discoveries or on new methods of analysis. The discovery of a chemical present in blood that increases the risk of cancer would be a discovery that an analytical chemist might be involved in. An effort to develop a new method might involve the use of a tunable laser to increase the specificity and sensitivity of a spectrometric method. Many methods, once developed, are kept purposely static so that data can be compared over long periods of time. This is particularly true in industrial quality assurance (QA), forensic and environmental applications. Analytical chemistry plays an increasingly important role in the pharmaceutical industry where, aside from QA, it is used in discovery of new drug candidates and in clinical applications where understanding the interactions between the drug and the patient are critical.\n\nAlthough modern analytical chemistry is dominated by sophisticated instrumentation, the roots of analytical chemistry and some of the principles used in modern instruments are from traditional techniques many of which are still used today. These techniques also tend to form the backbone of most undergraduate analytical chemistry educational labs.\n\nA qualitative analysis determines the presence or absence of a particular compound, but not the mass or concentration. By definition, qualitative analyses do not measure quantity.\n\nThere are numerous qualitative chemical tests, for example, the acid test for gold and the Kastle-Meyer test for the presence of blood.\n\nInorganic qualitative analysis generally refers to a systematic scheme to confirm the presence of certain, usually aqueous, ions or elements by performing a series of reactions that eliminate ranges of possibilities and then confirms suspected ions with a confirming test. Sometimes small carbon containing ions are included in such schemes. With modern instrumentation these tests are rarely used but can be useful for educational purposes and in field work or other situations where access to state-of-the-art instruments are not available or expedient.\n\nGravimetric analysis involves determining the amount of material present by weighing the sample before and/or after some transformation. A common example used in undergraduate education is the determination of the amount of water in a hydrate by heating the sample to remove the water such that the difference in weight is due to the loss of water.\n\nTitration involves the addition of a reactant to a solution being analyzed until some equivalence point is reached. Often the amount of material in the solution being analyzed may be determined. Most familiar to those who have taken chemistry during secondary education is the acid-base titration involving a color changing indicator. There are many other types of titrations, for example potentiometric titrations.\nThese titrations may use different types of indicators to reach some equivalence point.\n\nSpectroscopy measures the interaction of the molecules with electromagnetic radiation. Spectroscopy consists of many different applications such as atomic absorption spectroscopy, atomic emission spectroscopy, ultraviolet-visible spectroscopy, x-ray fluorescence spectroscopy, infrared spectroscopy, Raman spectroscopy, dual polarization interferometry, nuclear magnetic resonance spectroscopy, photoemission spectroscopy, Mössbauer spectroscopy and so on.\n\nMass spectrometry measures mass-to-charge ratio of molecules using electric and magnetic fields. There are several ionization methods: electron impact, chemical ionization, electrospray, fast atom bombardment, matrix assisted laser desorption ionization, and others. Also, mass spectrometry is categorized by approaches of mass analyzers: magnetic-sector, quadrupole mass analyzer, quadrupole ion trap, time-of-flight, Fourier transform ion cyclotron resonance, and so on.\n\nElectroanalytical methods measure the potential (volts) and/or current (amps) in an electrochemical cell containing the analyte. These methods can be categorized according to which aspects of the cell are controlled and which are measured. The three main categories are potentiometry (the difference in electrode potentials is measured), coulometry (the transferred charge is measured over time), amperometry (the cell's current is measured over time), and voltammetry (the cell's current is measured while actively altering the cell's potential).\n\nCalorimetry and thermogravimetric analysis measure the interaction of a material and heat.\n\nSeparation processes are used to decrease the complexity of material mixtures. Chromatography, electrophoresis and Field Flow Fractionation are representative of this field.\n\nCombinations of the above techniques produce a \"hybrid\" or \"hyphenated\" technique. Several examples are in popular use today and new hybrid techniques are under development. For example, gas chromatography-mass spectrometry, gas chromatography-infrared spectroscopy, liquid chromatography-mass spectrometry, liquid chromatography-NMR spectroscopy. liquid chromagraphy-infrared spectroscopy and capillary electrophoresis-mass spectrometry.\n\nHyphenated separation techniques refers to a combination of two (or more) techniques to detect and separate chemicals from solutions. Most often the other technique is some form of chromatography. Hyphenated techniques are widely used in chemistry and biochemistry. A slash is sometimes used instead of hyphen, especially if the name of one of the methods contains a hyphen itself.\n\nThe visualization of single molecules, single cells, biological tissues and nanomaterials is an important and attractive approach in analytical science. Also, hybridization with other traditional analytical tools is revolutionizing analytical science. Microscopy can be categorized into three different fields: optical microscopy, electron microscopy, and scanning probe microscopy. Recently, this field is rapidly progressing because of the rapid development of the computer and camera industries.\n\nDevices that integrate (multiple) laboratory functions on a single chip of only millimeters to a few square centimeters in size and that are capable of handling extremely small fluid volumes down to less than picoliters.\n\nError can be defined as numerical difference between observed value and true value.\n\nIn error the true value and observed value in chemical analysis can be related with each other by the equation\nwhere \nError of a measurement is an inverse measure of accurate measurement i.e. smaller the error greater the accuracy of the measurement. Errors are expressed relatively as:\n\nA general method for analysis of concentration involves the creation of a calibration curve. This allows for determination of the amount of a chemical in a material by comparing the results of unknown sample to those of a series of known standards. If the concentration of element or compound in a sample is too high for the detection range of the technique, it can simply be diluted in a pure solvent. If the amount in the sample is below an instrument's range of measurement, the method of addition can be used. In this method a known quantity of the element or compound under study is added, and the difference between the concentration added, and the concentration observed is the amount actually in the sample.\n\nSometimes an internal standard is added at a known concentration directly to an analytical sample to aid in quantitation. The amount of analyte present is then determined relative to the internal standard as a calibrant. An ideal internal standard is isotopically-enriched analyte which gives rise to the method of isotope dilution.\n\nThe method of standard addition is used in instrumental analysis to determine concentration of a substance (analyte) in an unknown sample by comparison to a set of samples of known concentration, similar to using a calibration curve. Standard addition can be applied to most analytical techniques and is used instead of a calibration curve to solve the matrix effect problem.\n\nOne of the most important components of analytical chemistry is maximizing the desired signal while minimizing the associated noise. The analytical figure of merit is known as the signal-to-noise ratio (S/N or SNR).\n\nNoise can arise from environmental factors as well as from fundamental physical processes.\n\nThermal noise results from the motion of charge carriers (usually electrons) in an electrical circuit generated by their thermal motion. Thermal noise is white noise meaning that the power spectral density is constant throughout the frequency spectrum.\n\nThe root mean square value of the thermal noise in a resistor is given by\n\nwhere \"k\" is Boltzmann's constant, \"T\" is the temperature, \"R\" is the resistance, and formula_5 is the bandwidth of the frequency formula_6.\n\nShot noise is a type of electronic noise that occurs when the finite number of particles (such as electrons in an electronic circuit or photons in an optical device) is small enough to give rise to statistical fluctuations in a signal.\n\nShot noise is a Poisson process and the charge carriers that make up the current follow a Poisson distribution. The root mean square current fluctuation is given by\n\nwhere \"e\" is the elementary charge and \"I\" is the average current. Shot noise is white noise.\n\nFlicker noise is electronic noise with a 1/\"ƒ\" frequency spectrum; as \"f\" increases, the noise decreases. Flicker noise arises from a variety of sources, such as impurities in a conductive channel, generation and recombination noise in a transistor due to base current, and so on. This noise can be avoided by modulation of the signal at a higher frequency, for example through the use of a lock-in amplifier.\n\nEnvironmental noise arises from the surroundings of the analytical instrument. Sources of electromagnetic noise are power lines, radio and television stations, wireless devices, Compact fluorescent lamps and electric motors. Many of these noise sources are narrow bandwidth and therefore can be avoided. Temperature and vibration isolation may be required for some instruments.\n\nNoise reduction can be accomplished either in computer hardware or software. Examples of hardware noise reduction are the use of shielded cable, analog filtering, and signal modulation. Examples of software noise reduction are digital filtering, ensemble average, boxcar average, and correlation methods.\n\nAnalytical chemistry has applications including in forensic science, bioanalysis, clinical analysis, environmental analysis, and materials analysis. Analytical chemistry research is largely driven by performance (sensitivity, detection limit, selectivity, robustness, dynamic range, linear range, accuracy, precision, and speed), and cost (purchase, operation, training, time, and space). Among the main branches of contemporary analytical atomic spectrometry, the most widespread and universal are optical and mass spectrometry. In the direct elemental analysis of solid samples, the new leaders are laser-induced breakdown and laser ablation mass spectrometry, and the related techniques with transfer of the laser ablation products into inductively coupled plasma. Advances in design of diode lasers and optical parametric oscillators promote developments in fluorescence and ionization spectrometry and also in absorption techniques where uses of optical cavities for increased effective absorption pathlength are expected to expand. The use of plasma- and laser-based methods is increasing. An interest towards absolute (standardless) analysis has revived, particularly in emission spectrometry.\n\nGreat effort is being put in shrinking the analysis techniques to chip size. Although there are few examples of such systems competitive with traditional analysis techniques, potential advantages include size/portability, speed, and cost. (micro total analysis system (µTAS) or lab-on-a-chip). Microscale chemistry reduces the amounts of chemicals used.\n\nMany developments improve the analysis of biological systems. Examples of rapidly expanding fields in this area are genomics, DNA sequencing and related research in genetic fingerprinting and DNA microarray; proteomics, the analysis of protein concentrations and modifications, especially in response to various stressors, at various developmental stages, or in various parts of the body, metabolomics, which deals with metabolites; transcriptomics, including mRNA and associated fields; lipidomics - lipids and its associated fields; peptidomics - peptides and its associated fields; and metalomics, dealing with metal concentrations and especially with their binding to proteins and other molecules.\n\nAnalytical chemistry has played critical roles in the understanding of basic science to a variety of practical applications, such as biomedical applications, environmental monitoring, quality control of industrial manufacturing, forensic science and so on.\n\nThe recent developments of computer automation and information technologies have extended analytical chemistry into a number of new biological fields. For example, automated DNA sequencing machines were the basis to complete human genome projects leading to the birth of genomics. Protein identification and peptide sequencing by mass spectrometry opened a new field of proteomics.\n\nAnalytical chemistry has been an indispensable area in the development of nanotechnology. Surface characterization instruments, electron microscopes and scanning probe microscopes enables scientists to visualize atomic structures with chemical characterizations.\n\n\n", "id": "2408", "title": "Analytical chemistry"}
{"url": "https://en.wikipedia.org/wiki?curid=2411", "text": "A cappella\n\nA cappella (Italian for \"in the manner of the chapel\") music is specifically group or solo singing without instrumental accompaniment, or a piece intended to be performed in this way. It contrasts with cantata, which is usually accompanied singing. The term \"a cappella\" was originally intended to differentiate between Renaissance polyphony and Baroque concertato style. In the 19th century a renewed interest in Renaissance polyphony coupled with an ignorance of the fact that vocal parts were often doubled by instrumentalists led to the term coming to mean unaccompanied vocal music. The term is also used, albeit rarely, as a synonym for alla breve.\n\nA cappella music was originally used in religious music, especially church music as well as anasheed and zemirot. Gregorian chant is an example of a cappella singing, as is the majority of secular vocal music from the Renaissance. The madrigal, up until its development in the early Baroque into an instrumentally-accompanied form, is also usually in a cappella form. Jewish and Christian music were originally a cappella, and this practice has continued in both of these religions as well as in Islam.\n\nThe polyphony of Christian a cappella music began to develop in Europe around the late 15th century AD, with compositions by Josquin des Prez. The early a cappella polyphonies may have had an accompanying instrument, although this instrument would merely double the singers' parts and was not independent. By the 16th century, a cappella polyphony had further developed, but gradually, the cantata began to take the place of a cappella forms. 16th century a cappella polyphony, nonetheless, continued to influence church composers throughout this period and to the present day. Recent evidence has shown that some of the early pieces by Palestrina, such as what was written for the Sistine Chapel was intended to be accompanied by an organ \"doubling\" some or all of the voices. Such is seen in the life of Palestrina becoming a major influence on Bach, most notably in the \"Mass in B Minor\". Other composers that utilized the a cappella style, if only for the occasional piece, were Claudio Monteverdi and his masterpiece, \"Lagrime d'amante al sepolcro dell'amata\" (A lover's tears at his beloved's grave), which was composed in 1610, and Andrea Gabrieli when upon his death it was discovered many choral pieces, one of which was in the unaccompanied style. Learning from the preceding two composeres, Heinrich Schütz utilized the a cappella style in numerous pieces, chief among these were the pieces in the oratorio style, which were traditionally performed during the Easter week and dealt with the religious subject matter of that week, such as Christ's suffering and the Passion. Five of Schutz's \"Historien\" were Easter pieces, and of these the latter three, which dealt with the passion from three different viewpoints, those of Matthew, Luke and John, were all done a cappella style. This was a near requirement for this type of piece, and the parts of the crowd were sung while the solo parts which were the quoted parts from either Christ or the authors were performed in a plainchant.\n\nIn the Byzantine Rite of the Eastern Orthodox Church and the Eastern Catholic Churches, the music performed in the liturgies is exclusively sung without instrumental accompaniment. Bishop Kallistos Ware says, \"The service is sung, even though there may be no choir... In the Orthodox Church today, as in the early Church, singing is unaccompanied and instrumental music is not found.\" This \"a cappella\" behavior arises from strict interpretation of Psalms 150, which states, \"Let every thing that hath breath praise the Lord. Praise ye the Lord.\" In keeping with this philosophy, early Russian \"musika\" which started appearing in the late 17th century, in what was known as \"khorovïye kontsertï\" (choral concertos) made a cappella adaptations of Venetian-styled pieces, such as the treatise, \"Grammatika musikiyskaya\" (1675), by Nikolai Diletsky. Divine Liturgies and Western Rite masses composed by famous composers such as Peter Tchaikovsky, Sergei Rachmaninoff, Alexander Arkhangelsky, and Mykola Leontovych are fine examples of this.\n\nPresent-day Christian religious bodies known for conducting their worship services without musical accompaniment include some Presbyterian churches devoted to the regulative principle of worship, Old Regular Baptists, Primitive Baptists, Plymouth Brethren, Churches of Christ, Church of God (Guthrie, Oklahoma), the Old German Baptist Brethren, Doukhobors the Byzantine Rite and the Amish, Old Order Mennonites and Conservative Mennonites. Certain high church services and other musical events in liturgical churches (such as the Roman Catholic Mass and the Lutheran Divine Service) may be a cappella, a practice remaining from apostolic times. Many Mennonites also conduct some or all of their services without instruments. Sacred Harp, a type of folk music, is an a cappella style of religious singing with shape notes, usually sung at singing conventions.\n\nOpponents of musical instruments in the Christian worship believe that such opposition is supported by the Christian scriptures and Church history. The scriptures typically referenced are Matthew 26:30; Acts 16:25; Romans 15:9; 1 Corinthians 14:15; Ephesians 5:19; Colossians 3:16; Hebrews 2:12, 13:15; James 5:13, which show examples and exhortations for Christians to sing.\n\nThere is no reference to instrumental music in early church worship in the New Testament, or in the worship of churches for the first six centuries. Several reasons have been posited throughout church history for the absence of instrumental music in church worship.\n\nChristians who believe in a cappella music today believe that in the Israelite worship assembly during Temple worship only the Priests of Levi sang, played, and offered animal sacrifices, whereas in the church era, all Christians are commanded to sing praises to God. They believe that if God wanted instrumental music in New Testament worship, He would have commanded not just singing, but singing and playing like he did in the Hebrew scriptures.\n\nThe first recorded example of a musical instrument in Roman Catholic worship was a pipe organ introduced by Pope Vitalian into a cathedral in Rome around 670.\n\nInstruments have divided Christendom since their introduction into worship. They were considered a Catholic innovation, not widely practiced until the 18th century, and were opposed vigorously in worship by a number of Protestant Reformers, including Martin Luther (1483–1546), Ulrich Zwingli, John Calvin (1509–1564) and John Wesley (1703–1791). Alexander Campbell referred to the use of an instrument in worship as \"a cow bell in a concert\". In Sir Walter Scott's \"The Heart of Midlothian\", the heroine, Jeanie Deans, a Scottish Presbyterian, writes to her father about the church situation she has found in England (bold added):\n\nThose who do not adhere to the regulative principle of interpreting Christian scripture, believe that limiting praise to the unaccompanied chant of the early church is not commanded in scripture, and that churches in any age are free to offer their songs with or without musical instruments.\n\nThose who subscribe to this interpretation believe that since the Christian scriptures never counter instrumental language with any negative judgment on instruments, opposition to instruments instead comes from an interpretation of history. There is no written opposition to musical instruments in any setting in the first century and a half of Christian churches (33 AD to 180AD). The use of instruments for Christian worship during this period is also undocumented. Toward the end of the 2nd century, Christians began condemning the instruments themselves. Those who oppose instruments today believe these Church Fathers had a better understanding of God's desire for the church, but there are significant differences between the teachings of these Church Fathers and Christian opposition to instruments today.\n\nSince \"a cappella\" singing brought a new polyphony (more than one note at a time) with instrumental accompaniment, it is not surprising that Protestant reformers who opposed the instruments (such as Calvin and Zwingli) also opposed the polyphony. While Zwingli was burning organs in Switzerland – Luther called him a fanatic – the Church of England was burning books of polyphony.\n\nSome Holiness Churches such as the Free Methodist Church opposed the use of musical instruments in church worship until the mid-20th century. The Free Methodist Church allowed for local church decision on the use of either an organ or piano in the 1943 Conference before lifting the ban entirely in 1955.\n\nWhile worship in the Temple in Jerusalem included musical instruments (), traditional Jewish religious services in the Synagogue, both before and after the last destruction of the Temple, did not include musical instruments given the practice of scriptural cantillation. The use of musical instruments is traditionally forbidden on the Sabbath out of concern that players would be tempted to repair (or tune) their instruments, which is forbidden on those days. (This prohibition has been relaxed in many Reform and some Conservative congregations.) Similarly, when Jewish families and larger groups sing traditional Sabbath songs known as zemirot outside the context of formal religious services, they usually do so a cappella, and Bar and Bat Mitzvah celebrations on the Sabbath sometimes feature entertainment by a cappella ensembles. During the Three Weeks musical instruments are prohibited. Many Jews consider a portion of the 49-day period of the counting of the omer between Passover and Shavuot to be a time of semi-mourning and instrumental music is not allowed during that time. This has led to a tradition of a cappella singing sometimes known as \"sefirah\" music.\n\nThe popularization of the Jewish chant may be found in the writings of the Jewish philosopher Philo, born 20 BCE. Weaving together Jewish and Greek thought, Philo promoted praise without instruments, and taught that \"silent singing\" (without even vocal chords) was better still. This view parted with the Jewish scriptures, where Israel offered praise with instruments by God's own command (). The shofar is the only temple instrument still being used today in the synagogue, and it is only used from Rosh Chodesh Elul through the end of Yom Kippur. The shofar is used by itself, without any vocal accompaniment, and is limited to a very strictly defined set of sounds and specific places in the synagogue service. However, silver trumpets, as described in , have been made in recent years and used in prayer services at the Western Wall.\n\nPeter Christian Lutkin, dean of the Northwestern University School of Music, helped popularize a cappella music in the United States by founding the Northwestern A Cappella Choir in 1906. The A Cappella Choir was \"the first permanent organization of its kind in America.\"\n\nA strong and prominent a cappella tradition was begun in the midwest part of the United States in 1911 by F. Melius Christiansen, a music faculty member at St. Olaf College in Northfield, Minnesota. The St. Olaf College Choir was established as an outgrowth of the local St. John's Lutheran Church, where Christiansen was organist and the choir was composed, at least partially, of students from the nearby St. Olaf campus. The success of the ensemble was emulated by other regional conductors, and a rich tradition of a cappella choral music was born in the region at colleges like Concordia College (Moorhead, Minnesota), Augustana College (Rock Island, Illinois), Wartburg College (Waverly, Iowa), Luther College (Decorah, Iowa), Gustavus Adolphus College (St. Peter, Minnesota), Augustana College (Sioux Falls, South Dakota), and Augsburg College (Minneapolis, Minnesota). The choirs typically range from 40 to 80 singers and are recognized for their efforts to perfect blend, intonation, phrasing and pitch in a large choral setting.\n\nMajor movements in modern a cappella over the past century include Barbershop and doo wop. The Barbershop Harmony Society, Sweet Adelines International, and Harmony Inc. host educational events including Harmony University, Directors University, and the International Educational Symposium, and international contests and conventions, recognizing international champion choruses and quartets.\n\nThese days, many a cappella groups can be found in high schools and colleges. There are amateur Barbershop Harmony Society and professional groups that sing a cappella exclusively. Although a cappella is technically defined as singing without instrumental accompaniment, some groups use their voices to emulate instruments; others are more traditional and focus on harmonizing. A cappella styles range from gospel music to contemporary to barbershop quartets and choruses.\n\nA cappella music was popularized between the late 2000s and the mid 2010s with media hits such as the 2009–2014 TV show \"The Sing-Off\", the musical \"Perfect Harmony\", and the musical comedy film series \"Pitch Perfect\".\n\nIn July 1943, as a result of the American Federation of Musicians boycott of US recording studios, the a cappella vocal group \"The Song Spinners\" had a best-seller with \"Comin' In On A Wing And A Prayer\". In the 1950s several recording groups, notably The Hi-Los and the Four Freshmen, introduced complex jazz harmonies to a cappella performances. The King's Singers are credited with promoting interest in small-group a cappella performances in the 1960s. Frank Zappa loves Doo wop and A cappella, so Zappa released The Persuasions first album from his label in 1970. In 1983 an a cappella group known as The Flying Pickets had a Christmas 'number one' in the UK with a cover of Yazoo's (known in the US as Yaz) \"Only You\". A cappella music attained renewed prominence from the late 1980s onward, spurred by the success of Top 40 recordings by artists such as The Manhattan Transfer, Bobby McFerrin, Huey Lewis and the News, All-4-One, The Nylons, Backstreet Boys and Boyz II Men.\n\nContemporary a cappella includes many vocal groups and bands who add vocal percussion or beatboxing to create a pop/rock/gospel sound, in some cases very similar to bands with instruments. Examples of such professional groups include Straight No Chaser, Pentatonix, The House Jacks, Rockapella, Mosaic, Home Free and M-pact. There also remains a strong a cappella presence within Christian music, as some denominations purposefully do not use instruments during worship. Examples of such groups are Take 6, Glad and Acappella. Arrangements of popular music for small a cappella ensembles typically include one voice singing the lead melody, one singing a rhythmic bass line, and the remaining voices contributing chordal or polyphonic accompaniment.\n\nA cappella can also describe the isolated vocal track(s) from a multitrack recording that originally included instrumentation. These vocal tracks may be remixed or put onto vinyl records for DJs, or released to the public so that fans can remix them. One such example is the a cappella release of Jay-Z's \"Black Album\", which Danger Mouse mixed with The Beatles' \"White Album\" to create \"The Grey Album\".\n\nA cappella's growth is not limited to live performance, with hundreds of recorded a cappella albums produced over the past decade. As of December 2006, the Recorded A Cappella Review Board (RARB) had reviewed over 660 a cappella albums since 1994, and its popular discussion forum had over 900 users and 19,000 articles.\n\nOn their 1966 album titled \"Album\", Peter, Paul and Mary included the song \"Normal Normal.\" All the sounds on that song, both vocals and instruments, were created by Paul's voice, with no actual instruments used.\n\nIn 2013, an artist by the name Smooth McGroove rose to prominence with his style of a cappella music. He is best known for his a cappella covers of video game music tracks on YouTube.\n\nin 2015, an a cappella version of Jerusalem by multi-instrumentalist Jacob Collier was selected for Beats by Dre \"The Game Starts Here\" for the England Rugby World Cup campaign.\n\nA cappella has been used as the sole orchestration for original works of musical theater that have had commercial runs Off-Broadway (theaters in New York City with 99 to 500 seats) only four times. The first was Avenue X which opened on 28 January 1994 and ran for 77 performances. It was produced by Playwrights Horizons with book by John Jiler, music and lyrics by Ray Leslee. The musical style of the show's score was primarily Doo-Wop as the plot revolved around Doo-Wop group singers of the 1960s.\n\nIn 2001, The Kinsey Sicks, produced and starred in the critically acclaimed off-Broadway hit, \"DRAGAPELLA! Starring the Kinsey Sicks\" at New York's legendary Studio 54. That production received a nomination for a Lucille Lortel award as Best Musical and a Drama Desk nomination for Best Lyrics. It was directed by Glenn Casale with original music and lyrics by Ben Schatz.\n\nThe a cappella musical Perfect Harmony, a comedy about two high school a cappella groups vying to win the National championship, made its Off Broadway debut at Theatre Row’s Acorn Theatre on 42nd Street in New York City in October, 2010 after a successful out-of-town run at the Stoneham Theatre, in Stoneham, Massachusetts. Perfect Harmony features the hit music of The Jackson 5, Pat Benatar, Billy Idol, Marvin Gaye, Scandal, Tiffany, The Romantics, The Pretenders, The Temptations, The Contours, The Commodores, Tommy James & the Shondells and The Partridge Family, and has been compared to a cross between Altar Boyz and The 25th Annual Putnam County Spelling Bee.\n\nThe fourth a cappella musical to appear Off-Broadway, In Transit, premiered 5 October 2010 and was produced by Primary Stages with book, music, and lyrics by Kristen Anderson-Lopez, James-Allen Ford, Russ Kaplan, and Sara Wordsworth. Set primarily in the New York City subway system its score features an eclectic mix of musical genres (including jazz, hip hop, Latin, rock, and country). In Transit incorporates vocal beat boxing into its contemporary a cappella arrangements through the use of a subway beat boxer character. Beat boxer and actor Chesney Snow performed this role for the 2010 Primary Stages production. According to the show's website, it is scheduled to reopen for an open-ended commercial run in the Fall of 2011. In 2011 the production received four Lucille Lortel Award nominations including Outstanding Musical, Outer Critics Circle and Drama League nominations, as well as five Drama Desk nominations including Outstanding Musical and won for Outstanding Ensemble Performance.\n\nIn December 2016, In Transit became the first a cappella musical on Broadway.\n\nBarbershop music is one of several uniquely American art forms. The earliest reports of this style of a cappella music involved African Americans. The earliest documented quartets all began in barbershops. In 1938, the first formal men's barbershop organization was formed, known as the Society for the Preservation and Encouragement of Barber Shop Quartet Singing in America (S.P.E.B.S.Q.S.A), and in 2004 rebranded itself and officially changed its public name to the Barbershop Harmony Society (BHS). Today the BHS has over 22,000 members in approximately 800 chapters across the United States, and the barbershop style has spread around the world with organizations in many other countries. The Barbershop Harmony Society provides a highly organized competition structure for a cappella quartets and choruses singing in the barbershop style.\n\nIn 1945, the first formal women's barbershop organization, Sweet Adelines, was formed. In 1953 Sweet Adelines became an international organization, although it didn't change its name to Sweet Adelines International until 1991. The membership of nearly 25,000 women, all singing in English, includes choruses in most of the fifty United States as well as in Australia, Canada, England, Finland, Germany, Ireland, Japan, New Zealand, Scotland, Sweden, Wales and the Netherlands. Headquartered in Tulsa, Oklahoma, the organization encompasses more than 1,200 registered quartets and 600 choruses.\n\nIn 1959, a second women's barbershop organization started as a break off from Sweet Adelines due to ideological differences. Based on democratic principles which continue to this day, Harmony, Inc. is smaller than its counterpart, but has an atmosphere of friendship and competition. With about 2,500 members in the United States and Canada, Harmony, Inc. uses the same rules in contest that the Barbershop Harmony Society uses. Harmony, Inc. is registered in Providence, Rhode Island.\n\nThe popularity of a cappella among high schools and amateurs was revived by television shows and movies such as \"Glee\" and \"Pitch Perfect\". High school groups have conductors or student leaders who keep the tempo for the group.\n\nComposer Dinesh Subasinghe became the first Sri Lankan to write a cappella pieces for SATB choirs. He wrote \"The Princes of the Lost Tribe\" and \"Ancient Queen of Somawathee\" for Menaka De Shabandu and Bridget Halpe's choirs, respectively, based on historical incidents in ancient Sri Lanka. Voice Print is also a professional a cappella music group in Sri Lanka.\n\nThe European a cappella tradition is especially strong in the countries around the Baltic and perhaps most so in Sweden as described by Richard Sparks in his doctoral thesis \"The Swedish Choral Miracle\" in 2000.\n\nSwedish a cappella choirs have over the last 25 years won around 25% of the annual prestigious European Grand Prix for Choral Singing (EGP) that despite its name is open to choirs from all over the world (see list of laureates in the Wikipedia article on the EGP competition).\n\nThe reasons for the strong Swedish dominance are as explained by Richard Sparks manifold; suffice to say here that there is a long-standing tradition, an unsusually large proportion of the populations (5% is often cited) regularly sing in choirs, the Swedish choral director Eric Ericson had an enormous impact on a cappella choral development not only in Sweden but around the world, and finally there are a large number of very popular primary and secondary schools (\"music schools\") with high admission standards based on auditions that combine a rigid academic regimen with high level choral singing on every school day, a system that started with Adolf Fredrik's Music School in Stockholm in 1939 but has spread over the country.\n\nA cappella has gained attention in the UK in recent years, with many groups forming at British universities by students seeking an alternative singing pursuit to traditional choral and chapel singing. This movement has been bolstered by organisations such as The Voice Festival UK.\n\nIt is not clear exactly where collegiate a cappella began. The Rensselyrics of Rensselaer Polytechnic Institute (formerly known as the RPI Glee Club), established in 1873 is perhaps the oldest known collegiate a cappella group. However the longest continuously-singing group is probably The Whiffenpoofs of Yale University, which was formed in 1909 and once included Cole Porter as a member. Collegiate a cappella groups grew throughout the 20th century. Some notable historical groups formed along the way include Colgate University's The Colgate 13 (1942), Dartmouth College's Aires (1946), Cornell University's Cayuga's Waiters (1949) and The Hangovers (1968), the University of Maine Maine Steiners (1958), the Columbia University Kingsmen (1949), the Jabberwocks of Brown University (1949), and the University of Rochester YellowJackets (1956). All-women a cappella groups followed shortly, frequently as a parody of the men's groups: the Smiffenpoofs of Smith College (1936), The Shwiffs of Connecticut College (The She-Whiffenpoofs, 1944), and The Chattertocks of Brown University (1951). A cappella groups exploded in popularity beginning in the 1990s, fueled in part by a change in style popularized by the Tufts University Beelzebubs and the Boston University Dear Abbeys. The new style used voices to emulate modern rock instruments, including vocal percussion/\"beatboxing\". Some larger universities now have multiple groups. Groups often join one another in on-campus concerts, such as the Georgetown Chimes' Cherry Tree Massacre, a 3-weekend a cappella festival held each February since 1975, where over a hundred collegiate groups have appeared, as well as International Quartet Champions The Boston Common and the contemporary commercial a cappella group Rockapella. Co-ed groups have produced many up-and-coming and major artists, including John Legend, an alumnus of the Counterparts at the University of Pennsylvania, and Sara Bareilles, an alumna of Awaken A Cappella at University of California, Los Angeles. Mira Sorvino is an alumna of the Harvard-Radcliffe Veritones of Harvard College, where she had the solo on Only You by Yaz.\n\nA cappella is gaining popularity among South Asians with the emergence of primarily Hindi-English College groups. The first South Asian a cappella group was Penn Masala, founded in 1996 at the University of Pennsylvania. Co-ed South Asian a cappella groups are also gaining in popularity. The first co-ed south Asian a cappella was Anokha, from the University of Maryland, formed in 2001. Also, Dil se, another co-ed a cappella from UC Berkeley, hosts the \"Anahat\" competition at the University of California, Berkeley annually. Maize Mirchi, the co-ed a cappella group from the University of Michigan hosts \"Sa Re Ga Ma Pella\", an annual South Asian a cappella invitational with various groups from the Midwest. Another South Asian group from the Midwest is Chai Town who is based in the University of Illinois at Urbana- Champaign.\n\nJewish-interest groups such as Tufts University's Shir Appeal, University of Chicago's Rhythm and Jews, Binghamton University's Kaskeset, Ohio State University's Meshuganotes, Rutgers University's Kol Halayla, New York University's Ani V'Ata and Yale University's Magevet are also gaining popularity across the U.S.\n\nIncreased interest in modern a cappella (particularly collegiate a cappella) can be seen in the growth of awards such as the Contemporary A Cappella Recording Awards (overseen by the Contemporary A Cappella Society) and competitions such as the International Championship of Collegiate A Cappella for college groups and the Harmony Sweepstakes for all groups. In December 2009, a new television competition series called \"The Sing-Off\" aired on NBC. The show featured eight a cappella groups from the United States and Puerto Rico vying for the prize of $100,000 and a recording contract with Epic Records/Sony Music. The show was judged by Ben Folds, Shawn Stockman, and Nicole Scherzinger and was won by an all-male group from Puerto Rico called Nota. The show returned for a second and third season, won by Committed and Pentatonix, respectively.\n\nEach year, hundreds of Collegiate a cappella groups submit their strongest songs in a competition to be on The Best of College A Cappella (BOCA), an album compilation of tracks from the best college a cappella groups around the world. The album is produced by Varsity Vocals – which also produces the International Championship of Collegiate A Cappella – and Deke Sharon. A group chosen to be on the BOCA album earns much credibility among the a cappella community.\n\nCollegiate a cappella groups may also submit their tracks to Voices Only, a two-disc series released at the beginning of each school year. A Voices Only album has been released every year since 2005.\n\nIn addition, all women's a cappella groups can send their strongest song tracks to the Women’s A Cappella Association (WACA) for its annual best of women's a cappella album. WACA offers another medium for women's voices to receive recognition and has released an album every year since 2014, featuring women's groups from across the United States.\n\nIn addition to singing words, some a cappella singers also emulate instrumentation by reproducing instrumental sounds with their vocal cords and mouth. One of the earliest 20th century practitioners of this method were The Mills Brothers whose early recordings of the 1930s clearly stated on the label that all instrumentation was done vocally. More recently, \"Twilight Zone\" by 2 Unlimited was sung a cappella to the instrumentation on the comedy television series \"Tompkins Square\". Another famous example of emulating instrumentation instead of singing the words is the theme song for \"The New Addams Family\" series on Fox Family Channel (now ABC Family). Groups such as Vocal Sampling and Undivided emulate Latin rhythms a cappella. In the 1960s, the Swingle Singers used their voices to emulate musical instruments to Baroque and Classical music. Vocal artist Bobby McFerrin is famous for his instrumental emulation. A cappella group Naturally Seven recreates entire songs using vocal tones for every instrument.\n\nThe Swingle Singers used nonsense words to sound like instruments, but have been known to produce non-verbal versions of musical instruments. Beatboxing, more accurately known as vocal percussion, is a technique used in a cappella music popularized by the hip-hop community, where rap is often performed a cappella also. The advent of vocal percussion added new dimensions to the a cappella genre and has become very prevalent in modern arrangements. Jazz vocalist Petra Haden used a four-track recorder to produce an a cappella version of \"The Who Sell Out\" including the instruments and fake advertisements on her album \"\" in 2005. Haden has also released a cappella versions of Journey's \"Don't Stop Believin'\", The Beach Boys' \"God Only Knows\" and Michael Jackson's \"Thriller\".\n\nChristian rock group Relient K recorded the song \"Plead the Fifth\" a cappella on its album \"Five Score and Seven Years Ago\". The group recorded lead singer Matt Thiessen making drum noises and played them with an electronic drum machine to record the song.\n\nThe German metal band van Canto uses vocal noises to imitate guitars on covers of well-known rock and metal songs (such as \"Master of Puppets\" by Metallica) as well as original compositions. Although they are generally classified as a cappella metal, the band also includes a drummer, and uses amplifiers on some songs to distort the voice to sound more like an electric guitar.\n\n\n\n", "id": "2411", "title": "A cappella"}
{"url": "https://en.wikipedia.org/wiki?curid=2414", "text": "Arrangement\n\nIn music, an arrangement is a musical reconceptualization of a previously composed work. It may differ from the original work by means of reharmonization, melodic paraphrasing, orchestration, or development of the formal structure. Arranging differs from orchestration in that the latter process is limited to the assignment of notes to instruments for performance by an orchestra, concert band, or other musical ensemble. Arranging \"involves adding compositional techniques, such as new thematic material for introductions, transitions, or modulations, and endings... Arranging is the art of giving an existing melody musical variety\".\n\nArrangement and transcriptions of classical and serious music go back to the early history of this genre. In particular, music written for the piano has frequently undergone this treatment. The suite of ten piano pieces \"Pictures at an Exhibition\", by Modest Mussorgsky, has been arranged over twenty times, notably by Maurice Ravel.\n\nDue to his lack of expertise in orchestration, the American composer George Gershwin had his \"Rhapsody in Blue\" orchestrated and arranged by Ferde Grofé.\n\nPopular music recordings often include parts for brass, string, and other instruments which were added by arrangers and not composed by the original songwriters. Popular music arrangements may also be considered to include new releases of existing songs with a new musical treatment. These changes can include alterations to tempo, meter, key, instrumentation, and other musical elements.\n\nWell-known examples include Joe Cocker's version of the Beatles' \"With a Little Help from My Friends,\" Cream's Crossroads, and Ike And Tina Turner's version of Creedence Clearwater Revival's \"Proud Mary\". The American group Vanilla Fudge and British group Yes based their early careers on radical re-arrangements of contemporary hits. Bonnie Pointer performed disco and Motown-themed versions of \"Heaven Must Have Sent You.\" Remixes, such as in dance music, can also be considered arrangements.\n\nThough arrangers may contribute substantially to finished musical products, for copyright and royalty purposes, they usually hold no legal claim to their work.\n\nArrangements for small jazz combos are usually informal, minimal, and uncredited. Larger ensembles have generally had greater requirements for notated arrangements, though the early Count Basie big band is known for its many \"head\" arrangements, so called because they were worked out by the players themselves, memorized (in the player's \"head\"), and never written down. Most arrangements for big bands, however, were written down and credited to a specific arranger, as with arrangements by Sammy Nestico and Neal Hefti for Count Basie's later big bands.\n\nDon Redman made innovations in jazz arranging as a part of Fletcher Henderson's orchestra in the 1920s. Redman's arrangements introduced a more intricate melodic presentation and \"soli\" performances for various sections of the big band. Benny Carter became Henderson's primary arranger in the early 1930s, becoming known for his arranging abilities in addition to his previous recognition as a performer. Beginning in 1938, Billy Strayhorn became an arranger of great renown for the Duke Ellington orchestra. Jelly Roll Morton is sometimes considered the earliest jazz arranger. While he toured around the years 1912 to 1915, he wrote down parts to enable \"pick-up\" bands to perform his compositions.\n\nBig band arrangements are informally called \"charts\". In the swing era they were usually either arrangements of popular songs or they were entirely new compositions. Duke Ellington's and Billy Strayhorn's arrangements for the Duke Ellington big band were usually new compositions, and some of Eddie Sauter's arrangements for the Benny Goodman band and Artie Shaw's arrangements for his own band were new compositions as well. It became more common to arrange sketchy jazz combo compositions for big band after the bop era.\n\nAfter 1950, the big bands declined in number. However, several bands continued and arrangers provided renowned arrangements. Gil Evans wrote a number of large-ensemble arrangements in the late 1950s and early 1960s intended for recording sessions only. Other arrangers of note include Vic Schoen, Pete Rugolo, Oliver Nelson, Johnny Richards, Billy May, Thad Jones, Maria Schneider, Bob Brookmeyer, Lou Marini, Nelson Riddle, Ralph Burns, Billy Byers, Gordon Jenkins, Ray Conniff, Henry Mancini, Ray Reach, and Claus Ogerman.\n\nIn the 21st century, the Big Band arrangement has made a modest comeback. Gordon Goodwin, Roy Hargrove, and Christian McBride have all rolled out New Big Bands with both original compositions and new arrangements of standard tunes.\n\nThe string section is a body of instruments composed of various stringed instruments. By the 19th century orchestral music in Europe had standardized the string section into the following homogeneous instrumental groups: first violins, second violins, violas, cellos, and double basses. The string section in a multi-sectioned orchestra is referred sometimes to as the \"string choir.\"\n\nThe harp is also a stringed instrument, but is not a member of nor homogeneous with the violin family and is not considered part of the string choir. Samuel Adler classifies the harp as a plucked string instrument in the same category as the guitar (acoustic or electric), mandolin, banjo, or zither. Like the harp these instruments do not belong to the violin family and are not homogeneous with the string choir. In modern arranging these instruments are considered part of the rhythm section. The electric string bass and upright string bass—depending on the circumstance—can be treated by the arranger as either string section or rhythm section instruments.\n\nA group of instruments in which each member plays a unique part—rather than playing in unison with other like instruments—is referred to as a chamber ensemble. A chamber ensemble made up entirely of strings of the violin family is referred to by its size. A string trio consists of three players, a string quartet four, a string quintet five, and so on.\n\nIn most circumstances the string section is treated by the arranger as one homogeneous unit and its members are required to play preconceived material rather than improvise.\n\nA string section can be utilized on its own (this is referred to as a string orchestra) or in conjunction with any of the other instrumental sections. More than one string orchestra can be utilized.\n\nA standard string section (vln., vln 2., vla., vcl, cb.) with each section playing unison allows the arranger to create a five-part texture. Often an arranger will divide each violin section in half or thirds to achieve a denser texture. It is possible to carry this division to its logical extreme in which each member of the string section plays his or her own unique part.\n\nArtistic, budgetary and logistical concerns will determine the size and instrumentation of a string section. The Broadway musical West Side Story, in 1957, was booked into the Winter Garden theater; composer Leonard Bernstein disliked the playing of \"house\" viola players he would have to use there, and so he chose to leave them out of the show's instrumentation; a benefit was the creation of more space in the pit for an expanded percussion section.\n\nGeorge Martin, producer and arranger for The Beatles, warns arrangers about the intonation issues when only two like instruments play in unison. \"After a string quartet,\" Martin explains, \"I do not think there is a satisfactory sound for strings until one has at least three players on each line...as a rule two stringed instruments together create a slight \"beat\" which does not give a smooth sound.\"\n\nWhile any combination and number of string instruments is possible in a section, a traditional string section sound is achieved with a violin-heavy balance of instruments.\n\n\n", "id": "2414", "title": "Arrangement"}
{"url": "https://en.wikipedia.org/wiki?curid=2416", "text": "Athanasian Creed\n\nThe Athanasian Creed, also known as Pseudo-Athanasian Creed or Quicunque Vult (also \"Quicumque Vult\"), is a Christian statement of belief focused on Trinitarian doctrine and Christology. The Latin name of the creed, \"Quicunque vult\", is taken from the opening words, \"Whosoever wishes\". The creed has been used by Christian churches since the sixth century. It is the first creed in which the equality of the three persons of the Trinity is explicitly stated. It differs from the Nicene-Constantinopolitan and Apostles' Creeds in the inclusion of anathemas, or condemnations of those who disagree with the creed (like the original Nicene Creed).\n\nWidely accepted among Western Christians, including the Roman Catholic Church and some Anglican churches, Lutheran churches (it is considered part of Lutheran confessions in the Book of Concord), and ancient, liturgical churches generally, the Athanasian Creed has been used in public worship less and less frequently, but part of it can be found as an \"Authorized Affirmation of Faith\" in the recent (2000) Common Worship liturgy of the Church of England [Main Volume page 145]. \n\nIt was designed to distinguish Nicene Christianity from the heresy of Arianism. Liturgically, this Creed was recited at the Sunday Office of Prime in the Western Church; it is not in common use in the Eastern Church. The creed has never gained acceptance in liturgy among Eastern Christians since it was considered as one of many unorthodox fabrications that contained the Filioque clause. Today, the Athanasian Creed is rarely used even in the Western Church. When used, one common practice is to use it once a year on Trinity Sunday.\n\nA medieval account credited Athanasius of Alexandria, the famous defender of Nicene theology, as the author of the Creed. According to this account, Athanasius composed it during his exile in Rome and presented it to Pope Julius I as a witness to his orthodoxy. This traditional attribution of the Creed to Athanasius was first called into question in 1642 by Dutch Protestant theologian G.J. Voss. \n\nIt has since been widely accepted by modern scholars that the creed was not authored by Athanasius, that it was not originally called a creed at all, nor was Athanasius' name originally attached to it. Athanasius' name seems to have become attached to the creed as a sign of its strong declaration of Trinitarian faith. The reasoning for rejecting Athanasius as the author usually relies on a combination of the following:\n\n\nThe use of the creed in a sermon by Caesarius of Arles, as well as a theological resemblance to works by Vincent of Lérins, point to Southern Gaul as its origin. The most likely time frame is in the late fifth or early sixth century AD – at least 100 years after Athanasius. The theology of the creed is firmly rooted in the Augustinian tradition, using exact terminology of Augustine's \"On the Trinity\" (published 415 AD). In the late 19th century, there was a great deal of speculation about who might have authored the creed, with suggestions including Ambrose of Milan, Venantius Fortunatus, and Hilary of Poitiers, among others. \n\nThe 1940 discovery of a lost work by Vincent of Lérins, which bears a striking similarity to much of the language of the Athanasian Creed, have led many to conclude that the creed originated either with Vincent or with his students. For example, in the authoritative modern monograph about the creed, J.N.D. Kelly asserts that Vincent of Lérins was not its author, but that it may have come from the same milieu, namely the area of Lérins in southern Gaul. The oldest surviving manuscripts of the Athanasian Creed date from the late 8th century.\n\nThe Athanasian Creed is usually divided into two sections: lines 1–28 addressing the doctrine of the Trinity, and lines 29–44 addressing the doctrine of Christology. Enumerating the three persons of the Trinity (i.e., Father, the Son, and the Holy Spirit), the first section of the creed ascribes the divine attributes to each individually. Thus, each person of the Trinity is described as uncreated (\"increatus\"), limitless (\"Immensus\"), eternal (\"æternus\"), and omnipotent (\"omnipotens\"). \n\nWhile ascribing the divine attributes and divinity to each person of the Trinity, thus avoiding subordinationism, the first half of the Athanasian Creed also stresses the unity of the three persons in the one Godhead, thus avoiding a theology of tritheism. Furthermore, although one God, the Father, Son, and Holy Spirit are distinct from each other. For the Father is neither made nor begotten; the Son is not made but is begotten from the Father; the Holy Spirit is neither made nor begotten but proceeds from the Father and the Son (filioque).\n\nThe text of the Athanasian Creed is as follows:\n\nThe Christology of the second section is more detailed than that of the Nicene Creed, and reflects the teaching of the First Council of Ephesus (431) and the definition of the Council of Chalcedon (451). The Athanasian Creed uses the term \"substantia\" (a Latin translation of the Nicene \"homoousios\": 'same being' or 'consubstantial') not only with respect to the relation of the Son to the Father according to his divine nature, but also says the Son is \"substantia\" of his mother Mary according to his human nature.\n\nThe Creed's wording thus excludes not only Sabellianism and Arianism, but the Christological heresies of Nestorianism and Eutychianism. A need for a clear confession against Arianism arose in western Europe when the Ostrogoths and Visigoths, who had Arian beliefs, invaded at the beginning of the 5th century.\n\nThe final section of this Creed also moved beyond the Nicene (and Apostles') Creeds in making negative statements about the people's fate: \"They that have done good shall go into life everlasting: and they that have done evil into everlasting fire.\" This caused considerable debate in England in the mid-nineteenth century, centred on the teaching of Frederick Denison Maurice.\n\nComposed of 44 rhythmic lines, the Athanasian Creed appears to have been intended as a liturgical document – that is, the original purpose of the creed was to be spoken or sung as a part of worship. The creed itself uses the language of public worship, speaking of the worship of God rather than the language of belief (\"Now this is the catholic faith: We worship one God\"). In the Catholic Church in medieval times, this creed was recited following the Sunday sermon or at the Sunday Office of Prime. The creed was often set to music and used in the place of a Psalm.\n\nEarly Protestants inherited the late medieval devotion to the Athanasian Creed, and it was considered to be authoritative in many Protestant churches. The statements of Protestant belief (confessional documents) of various Reformers commend the Athanasian Creed to their followers, including the Augsburg Confession, the Formula of Concord, the Second Helvetic Confession, the Belgic Confession, the Bohemian Confession and the Thirty-nine Articles. A metric version titled \"Quicumque vult\", with a musical setting, was published in \"The Whole Booke of Psalmes\" printed by John Day in 1562. Among modern Lutheran and Reformed churches adherence to the Athanasian Creed is prescribed by the earlier confessional documents, but the creed does not receive much attention outside of occasional use – especially on Trinity Sunday.\n\nIn Reformed circles, it is included (for example) in the Christian Reformed Churches of Australia's Book of Forms (publ. 1991). However, it is rarely recited in public worship.\n\nIn the successive Books of Common Prayer of the reformed Church of England, from 1549 to 1662, its recitation was provided for on 19 occasions each year, a practice which continued until the nineteenth century, when vigorous controversy regarding its statement about 'eternal damnation' saw its use gradually decline. It remains one of the three Creeds approved in the Thirty-Nine Articles, and is printed in several current Anglican prayer books (e.g. A Prayer Book for Australia (1995)). As with Roman Catholic practice, its use is now generally only on Trinity Sunday or its octave. The Episcopal Church based in the United States has never provided for its use in worship, but added it to its Book of Common Prayer for the first time in 1979, where it is included in small print in a reference section entitled \"Historical Documents of the Church.\"\n\nIn Roman Catholic churches, it was traditionally said at Prime on Sundays when the Office was of the Sunday. The 1911 reforms reduced this to Sundays after Epiphany and Pentecost, and on Trinity Sunday, except when a commemoration of a Double feast or a day within an Octave occurred. The 1960 reforms further reduced its use to once a year, on Trinity Sunday. It has been effectively dropped from the Catholic liturgy since the Second Vatican Council. It is however maintained in the \"Forma Extraordinaria\", per the decree Summorum Pontificum, and also in the rite of exorcism, both in the \"Forma Ordinaria\" and the \"Forma Extraordinaria\" of the Roman Rite.\n\nIn Lutheranism, the Athanasian Creed is—along with the Apostles' and Nicene Creeds—one of the three ecumenical creeds placed at the beginning of the 1580 Book of Concord, the historic collection of authoritative doctrinal statements (confessions) of the Lutheran Church. It is still used in the liturgy on Trinity Sunday.\n\nA common visualisation of the first half of the Creed is the Shield of the Trinity.\n\n", "id": "2416", "title": "Athanasian Creed"}
{"url": "https://en.wikipedia.org/wiki?curid=2417", "text": "Alicante\n\nAlicante (, ), or (), both the Spanish and Valencian being official names, is a city and port in Spain on the Costa Blanca, the capital of the province of Alicante and of the comarca of Alacantí, in the south of the Valencian Community. It is also a historic Mediterranean port. The population of the city of Alicante proper was 328,648, estimated , ranking as the second-largest Valencian city. Including nearby municipalities, the Alicante conurbation had 452,462 residents. The population of the metropolitan area (including Elche and satellite towns) was 757,085 estimates, ranking as the eighth-largest metropolitan area of Spain.\nThe name of the city echoes the Arabic name \"Laqant\" (لَقَنْت) or \"Al-Laqant\" (ألَلَقَنْت), which in turn reflects the Latin \"Lucentum\".\n\nThe area around Alicante has been inhabited for over 7000 years. The first tribes of hunter-gatherers moved down gradually from Central Europe between 5000 and 3000 BC. Some of the earliest settlements were made on the slopes of Mount Benacantil. By 1000 BC Greek and Phoenician traders had begun to visit the eastern coast of Spain, establishing small trading ports and introducing the native Iberian tribes to the alphabet, iron and the pottery wheel. The town of Leuce Akra (white cape) was then founded by Greek settlers from Marseille around 325/324 b.C. By the 3rd century BC, the rival armies of Carthage and Rome began to invade and fight for control of the Iberian Peninsula. The Carthaginian general Hamilcar Barca established the fortified settlement of \"Akra Leuka\" (Greek: , meaning \"White Mountain\" or \"White Point\"), where Alicante stands today.\nAlthough the Carthaginians conquered much of the land around Alicante, the Romans would eventually rule Hispania Tarraconensis for over 700 years. By the 5th century AD, Rome was in decline and the Roman predecessor town of Alicante, known as \"Lucentum\" (Latin), was more or less under the control of the Visigothic warlord Theudimer. However neither the Romans nor the Goths put up much resistance to the Arab conquest of \"Medina Laqant\" in the 8th century. The Moors ruled southern and eastern Spain until the 13th century \"Reconquista\" (Reconquest). Alicante was finally taken in 1246 by the Castilian king Alfonso X, but it passed soon and definitively to the Kingdom of Valencia in 1298 with King James II of Aragon. It gained the status of Royal Village (\"Vila Reial\") with representation in the medieval Valencian Parliament (\"Corts Valencianes\").\nAfter several decades of being the battlefield where the Kingdom of Castile and the Crown of Aragon clashed, Alicante became a major Mediterranean trading station exporting rice, wine, olive oil, oranges and wool. But between 1609 and 1614 King Felipe III expelled thousands of Moriscos who had remained in Valencia after the Reconquista, due to their cooperation with Barbary pirates who continually attacked coastal cities and caused much harm to trade. This act cost the region dearly; with so many skilled artisans and agricultural labourers gone, the feudal nobility found itself sliding into bankruptcy. Things got worse in the early 18th century; after the War of Spanish Succession, Alicante went into a long, slow decline, surviving through the 18th and 19th centuries by making shoes and growing agricultural produce such as oranges and almonds, and thanks to its fisheries. The end of the 19th century witnessed a sharp recovery of the local economy with increasing international trade and the growth of the city harbour leading to increased exports of several products (particularly during World War I when Spain was a neutral country).\nDuring the early 20th century, Alicante was a minor capital that enjoyed the benefit of Spain's neutrality during World War I, and that provided new opportunities for local industry and agriculture. The Rif War in the 1920s saw numerous \"alicantinos\" drafted to fight in the long and bloody campaigns in the former Spanish protectorate (Northern Morocco) against the Rif rebels. The political unrest of the late 1920s led to the victory of Republican candidates in local council elections throughout the country, and the abdication of King Alfonso XIII. The proclamation of the Second Spanish Republic was much celebrated in the city on 14 April 1931. The Spanish Civil War broke out on 17 July 1936. Alicante was the last city loyal to the Republican government to be occupied by dictator Franco's troops on 1 April 1939, and its harbour saw the last Republican government officials fleeing the country. Vicious air bombings were targeted on Alicante during the three years of civil conflict, most notably the bombing by the Italian \"Aviazione Legionaria\" of the Mercado de Abastos on 25 May 1938 in which more than 300 civilians perished.\nThe late 1950s and early 1960s saw the onset of a lasting transformation of the city by the tourist industry. Large buildings and complexes rose in nearby Albufereta (e.g. El Barco) and Playa de San Juan, with the benign climate being the biggest draw to attract prospective buyers and tourists who kept the hotels reasonably busy. New construction benefited the whole economy, as the development of the tourism sector also spawned new businesses such as restaurants, bars and other tourist-oriented enterprises. Also, the old airfield at Rabassa was closed and air traffic moved to the new El Altet Airport, which made a more convenient and modern facility for charter flights bringing tourists from northern European countries.\n\nWhen Franco died in 1975, his successor Juan Carlos I played his part as the living symbol of the transition of Spain to a democratic constitutional monarchy. The governments of regional communities were given constitutional status as \"nationalities\", and their governments were given more autonomy, including that of the Valencian region, the \"Generalitat Valenciana\".\n\nThe Port of Alicante has been reinventing itself since the industrial decline the city suffered in the 1980s (with most mercantile traffic lost to Valencia's harbour). In recent years, the Port Authority has established it as one of the most important ports in Spain for cruises, with 72 calls to port made by cruise ships in 2007 bringing some 80,000 passengers and 30,000 crew to the city each year. The moves to develop the port for more tourism have been welcomed by the city and its residents, but the latest plans to develop an industrial estate in the port have caused great controversy.\n\nUntil the global recession which started in 2008, Alicante was one of the fastest-growing cities in Spain. The boom depended partly on tourism directed to the beaches of the Costa Blanca and particularly on the second residence-construction boom which started in the 1960s and revived again by the late 1990s. Services and public administration also play a major role in the city's economy. The construction boom has raised many environmental concerns and both the local autonomous government and city council are under scrutiny by the European Union. The construction surge was the subject of hot debates among politicians and citizens alike. The latest of many public battles concerns the plans of the Port Authority of Alicante to construct an industrial estate on reclaimed land in front of the city's coastal strip, in breach of local, national and European regulations. (See Port of Alicante for details).\nThe city serves as the headquarters of the European Union Intellectual Property Office and a sizeable population of European public workers live there.\n\nThe campus of the University of Alicante lies in San Vicente del Raspeig, bordering the city of Alicante to the north. More than 27,000 students attend the University.\n\nSince 2005 Ciudad de la Luz, one of the largest film studios in Europe, has had its base in Alicante. The studio has shot Spanish and international movies such as \"Asterix at the Olympic Games\" by Frédéric Forestier and Thomas Langmann, and \"Manolete\" by Menno Meyjes.\n\nThe official population of Alicante in 2014 was 332,067 inhabitants and 757,085 in the metropolitan area \"Alicante-Elche\". About 15% of the population is foreign, most of them immigrants from Argentina, Ecuador, United Kingdom and Colombia who have arrived in the previous 20 years. There are also immigrants from other countries such as Germany, Romania, Russia, Algeria, Ukraine, Morocco and Italy, many of whom coming outside the EU are under illegal alien status and therefore are not accounted for in official population figures. The real percentage of foreign residents is higher, since the Alicante metropolitan area is home to many Northern European retirees who are officially still residents of their own countries. In the same pattern, a sizable number of permanent residents are Spanish nationals who officially still live in Madrid, the Basque provinces, or other areas of the country.\n\nGabriel Echávarri is the Mayor of the city. He was elected for the post on June 13, 2015, following the municipal elections on May 24, 2015. He was supported by the votes from his own group (6), plus those from leftist parties Guanyar Alacant (6) and Compromís (3), as well as from centre-right party Ciudadanos (6). The People's Party (\"Partido Popular\", PP), with only 8 elected seats, lost the majority.\n\nIn the previous municipal elections of May 2011, Sonia Castedo of People's Party won the elections with an absolute majority, but resigned in December 2014 due to her involvement in several corruption scandals, at present being under investigation. Her fellow party member Miguel Valor went on to become mayor up until Echávarri's election.\n\nAt the foot of the main staircase of the City Hall Building (\"Ayuntamiento\") is the zero point (\"cota cero\"), used as the point of reference for measuring the height above or below sea level of any point in Spain, due to the marginal tidal variations of the Mediterranean sea in Alicante.\n\nAlicante enjoys mild winter temperatures, hot summers and little rain, concentrated in equinoctial periods. The climate of the Alicante region according to Köppen climate classification is a Hot semi-arid climate (\"BSh\"). On average the temperature ranges between and in January, and between and in August, with an average annual temperature of . Daily variations in temperature are generally small because of the stabilising influence of the sea, although occasional periods of westerly wind can produce temperature changes of or more. Seasonal variations in temperature are also relatively small, meaning that winters are mild and summers are hot.\n\nThe average rainfall is per year. The cold drop means that September and October are the wettest months. Rarely, the rainfall can be torrential, reaching over in a 24-hour period, leading to severe flooding. Because of this irregularity, only 35 rainy days are observed on average per year, and the annual number of sunshine hours is 2,953.\n\nThe record maximum temperature of was observed on 4 July 1994. The record minimum temperature of was recorded on 26 December 1970. The worst flooding in modern history occurred on 30 September 1997 when of rain fell within six hours. Temperatures under are very rare. Snow is unknown since 1926 The climate of Alicante is very similar to the climate of Los Angeles, California.\n\nAlicante Airport outranks its Valencian counterpart, being among the busiest airports in Spain after Madrid, Barcelona, Palma de Mallorca and Málaga. It is connected with Madrid and Barcelona by frequent Iberia and Vueling flights, and with many Western European cities through carriers such as Ryanair, Easyjet, Air Berlin, Monarch Airlines, and Jet2.com. There are also regular flights to Algeria and Russia.\nAlicante railway station is used by Cercanías linking Alicante with suburbs and Murcia. Long-range RENFE trains run frequently to Madrid, Barcelona, and Valencia.\n\nAlicante Tram connects the city with outlying settlements along Costa Blanca. , electric tram-trains run up to Benidorm, and diesel trains go further to Dénia.\n\nThe city has regular ferry services to the Balearic Islands and Algeria. The city is strongly fortified, with a spacious harbour.\n\nAmongst the most notable features of the city are the Castle of Santa Bárbara, which sits high above the city, and the port of Alicante. The latter was the subject of bitter controversy in 2006–2007 as residents battled, successfully, to keep it from being changed into an industrial estate.\n\nThe Santa Bárbara castle is situated on Mount Benacantil, overlooking the city. The tower (\"La Torreta\") at the top, is the oldest part of the castle, while part of the lowest zone and the walls were constructed later in the 18th century.\nThe promenade \"Explanada de España\", lined by palm trees, is paved with 6.5 million marble floor tiles creating a wavy form and is one of the most lovely promenades in Spain. The Promenade extends from the Port of Alicante to the Gran Vía and ends at the famous statue of Mark Hersch. For the people of Alicante, the promenade is the meeting place for the traditional Spanish \"paseo\", or stroll along the waterfront in the evenings, and a venue for outdoor musical concerts. At the end of the promenade is a monument by the artist Bañuls of the 19th century.\n\n\"Barrio de la Santa Cruz\" is a colourful quarter of the old city, situated on the south-west of Santa Bárbara castle. Its small houses climb up the hill leading to the walls and the castle, through narrow streets decorated with flags and tubs of flowers.\n\n\"L'Ereta Park\" is situated on the foothills of Mount Benacantil, on the way to the castle. It runs from the Santa Bárbara castle down to the old part of Alicante and consists of several levels, routes, decks and rest stops which offer a panoramic view overlooking the city.\n\n\"El Palmeral Park\" is one of the favorite parks of Alicante's citizens. It includes walking trails, children's playgrounds, ponds and brooks, picnic tables and an auditorium for concerts.\n\nJust a few kilometers from Alicante on the Mediterranean Sea lies Tabarca island. What was once a haven for Barbary pirates is now a beautiful tourist attraction.\nOther sights include:\n\nThere are a dozen museums in Alicante. On exhibition at the Archaeological Museum of Alicante (MARQ) are local artifacts dating from 100,000 years ago till the early 20th century. The collection is divided into different rooms representing three divisions of archaeological methodology: ground, urban and underwater archaeology, with dioramas, audiovisual and interactive zones. The archaeological museum won the European Museum of the Year Award in 2004. Gravina Museum of Fine Arts presents a number of paintings and sculptures from the 16th century to the 19th century. Asegurada Museum of Contemporary Art houses a major collection of twentieth-century art, composed mainly of works donated by .\n\nThe most important festival, the \"Bonfires of Saint John\" (\"Fogueres de Sant Joan\"), takes place during the summer solstice. This is followed a week later by seven nights of firework and pyrotechnic contests between companies on the urban beach \"Playa del Postiguet\". Another well-known festival is \"Moros i Cristians\" in Altozano or \"San Blas\" district. Overall, the city boasts a year-round nightlife for the enjoyment of tourists, residents, and a large student population of the University of Alicante. The nightlife social scene tends to shift to nearby Playa de San Juan (St. John's Beach) during the summer months.\n\nEvery summer in Alicante, a two-month-long programme of music, theatre and dance is staged in the Paseo del Puerto.\n\nThe two established Alicante football teams are Hércules CF, which competes in the Spanish Segunda División B, and Alicante CF, which plays in Tercera División and was dissolved in 2014 due to economic problems. Hércules CF is more well known as it was in the first division in Spain during 96/97 and had many popular players such as David Trezeguet, Royston Drenthe and Aedo Valvez. It is also known because, thanks to this team beating Barcelona, Real Madrid won the league in 1997. Nowadays their home games are played in the Estadio José Rico Pérez.\n\nBasketball club Lucentum Alicante participates in the Spanish basketball league. It plays in the Centro de Tecnificación de Alicante.\n\nAlicante serves as headquarters and the starting point of Volvo Ocean Race, a yacht race around the world. The latest race sailed in October 2014.\n\nAlicante is twinned with:\nIn 2009 a bid was made to twin Newcastle, United Kingdom, with Alicante.\n\n\n", "id": "2417", "title": "Alicante"}
{"url": "https://en.wikipedia.org/wiki?curid=2418", "text": "August 4\n\n\n\n", "id": "2418", "title": "August 4"}
{"url": "https://en.wikipedia.org/wiki?curid=2421", "text": "Albrecht Achilles\n\nAlbrecht Achilles may refer to:\n", "id": "2421", "title": "Albrecht Achilles"}
{"url": "https://en.wikipedia.org/wiki?curid=2422", "text": "Ann Widdecombe\n\nAnn Noreen Widdecombe, (born 4 October 1947) is a former British Conservative Party politician. She is a Privy Councillor and was the Member of Parliament for Maidstone from 1987 to 1997 and for Maidstone and The Weald from 1997 to 2010. She was a social conservative and a member of the Conservative Christian Fellowship. She retired from politics at the 2010 general election. Since 2002 she has also made numerous television and radio appearances, including as a television presenter. She is a convert from Anglicanism to Roman Catholicism.\n\nAs an MP, Widdecombe was known for opposing the legality of abortion, her opposition to various issues of LGBT equality such as an equal age of consent and the repeal of Section 28, her support for the re-introduction of the death penalty, the retention of blasphemy laws and her opposition to fox hunting.\n\nBorn in Bath, Somerset, Widdecombe is the daughter of Rita Noreen (née Plummer; 1911-2007) and Ministry of Defence civil servant James Murray Widdecombe. Widdecombe's maternal grandfather, James Henry Plummer, was born to an Irish Catholic family of English descent in Crosshaven, County Cork in 1874. She attended the Royal Naval School in Singapore, and La Sainte Union Convent School in Bath. She then read Latin at the University of Birmingham and later attended Lady Margaret Hall, Oxford, to read Philosophy, Politics and Economics (PPE). She worked for Unilever (1973–75) and then as an administrator at the University of London (1975–87) before entering Parliament.\n\nFrom 1976 to 1978, Widdecombe was a councillor on Runnymede District Council in Surrey. She contested the seat of Burnley in Lancashire in the 1979 general election and then, against David Owen, the Plymouth Devonport seat in the 1983 general election.\n\nShe was first elected to the House of Commons in the 1987 general election as member for the constituency of Maidstone (which became Maidstone and The Weald in 1997).\n\nAs an MP, Widdecombe expressed conservative views, including opposition to abortion; it was understood during her time in frontline politics that she would not become Health Secretary as long as this involved responsibility for abortions. Although a committed Christian, she has characterised the issue as one of life and death on which her view had been the same when she was agnostic. Along with John Gummer MP, she converted from the Church of England to the Catholic Church following the decision of the Church of England on the Ordination of women as priests. In her speech at the 2000 Conservative conference, she called for a zero tolerance policy of prosecution, with the punishment of £100 fines for users of cannabis. This was well received by rank-and-file Conservative delegates.\n\nWiddecombe consistently opposed LGBT equality. On the issue of an equal age of consent, she said in 2000: \"I do not believe that issues of equality should override the imperatives of protecting the young.\" In 2003, Widdecombe proposed an amendment opposing repeal of Section 28 of the Local Government Act, which banned the promotion of homosexuality by local governments. Out of the 17 parliamentary votes considered by the Public Whip website to concern equal rights for homosexuals, Widdecombe took the opposing position in 15 cases, not being present at the other two votes. Widdecombe has also expressed her opposition to same-sex marriage, introduced by David Cameron's government in 2014, claiming that \"the state must have a preferred model\" and \"a union that is generally open to procreation\".\n\nShe is a committed animal lover and one of the few Conservative MPs to have consistently voted for the ban on fox hunting. Widdecombe was among more than 20 high-profile people who signed a letter to Members of Parliament in 2015 to oppose David Cameron's plan to amend the Hunting Act 2004.\n\nShe has expressed a variety of views on scientific issues such as climate change but has been opposed to legislation reducing emissions. Her views on the subject appear to have hardened over time. In 2007, she wrote that she did not want to belittle the issue but was sceptical of the claims that specific actions would prevent catastrophe, then in 2008 that her doubts had been \"crystalised\" by Nigel Lawson's book \"An Appeal to Reason\", before stating in 2009 that \"There is no climate change, hasn’t anybody looked out of their window recently?\" She was one of the five MPs who voted against the Climate Change Act 2008. In 2011 she expressed the view that \"climate change money should go to armed services\". The previous year, she voted to support a parliamentary motion supporting homeopathy, criticizing the Science and Technology Committee's Report on the subject.\n\nOver the years, Widdecombe has expressed her support for a reintroduction of the death penalty, which was abolished in the UK in 1965. She notably spoke of her support for its reintroduction for the worst cases of murder in the aftermath of the murder of two 10-year-old girls from Soham, Cambridgeshire, in August 2002, in the Soham murders. She supported the argument that the death penalty would have deterrent value, as within five years of its abolition the national murder rate had more than doubled.\n\nWiddecombe joined John Major's government as Parliamentary Under-Secretary of State for Social Security in 1990. In 1993, she was moved to the Department of Employment, and she was promoted to Minister of State the following year. In 1995, she joined the Home Office as Minister of State for Prisons and visited every prison in Britain.\n\nAfter the fall of the Conservative government to Labour in 1997, she served as Shadow Health Secretary between 1998 and 1999 and later as Shadow Home Secretary between 1999 and 2001 under William Hague.\n\nDuring the 2001 Conservative leadership election, she could not find sufficient support amongst Conservative MPs for her leadership candidacy. She first supported Michael Ancram, who was eliminated in the first round, and then Kenneth Clarke, who lost in the final round. She afterwards declined to serve in Iain Duncan Smith's Shadow Cabinet (although she indicated on the television programme \"When Louis Met...\", prior to the leadership contest, that she wished to retire to the backbenches anyway).\n\nIn the 2005 leadership election, she initially supported Kenneth Clarke again. Once he was eliminated, she turned support towards Liam Fox. Following Fox's subsequent elimination, she took time to reflect before finally declaring for David Davis. She expressed reservations over the eventual winner David Cameron, feeling that he did not, like the other candidates, have a proven track record, and she was later a leading figure in parliamentary opposition to his A-List policy, which she has said is \"an insult to women\". At the October 2006 Conservative Conference, she was Chief Dragon in a political version of the television programme \"Dragons' Den\", in which A-list candidates were invited to put forward a policy proposal, which was then torn apart by her team of Rachel Elnaugh, Oliver Letwin and Michael Brown.\n\nIn an interview with \"Metro\" in September 2006 she stated that if Parliament were of a normal length, it was likely she would retire at the next general election. She confirmed her intention to stand down to \"The Observer\"'s Pendennis diary in September 2007, and again in October 2007 after Prime Minister Gordon Brown quashed speculation of an autumn 2007 general election.\n\nWiddecombe was one of the 98 MPs who voted to keep their expense details secret. When the expenses claims were leaked, however, Widdecombe was described by \"The Daily Telegraph\" as one of the \"saints\" amongst all MPs.\n\nIn May 2009, following the resignation of Michael Martin as Speaker of the House of Commons, it was reported that Widdecombe was gathering support for election as interim Speaker until the next general election. On 11 June 2009, she confirmed her bid to be the Speaker. She made it through to the second ballot but came last and was eliminated.\n\nWiddecombe retired from politics at the 2010 general election. It was rumoured that she would be a Conservative candidate for Police and Crime Commissioner in 2012, but she refused. She has since spoken about her opposition to the Coalition Government and her surprise at not being given a peerage by David Cameron.\n\nIn 2016, she backed Britain's withdrawal from the European Union during the 2016 EU referendum and, following the resignation of David Cameron, endorsed Andrea Leadsom in her candidacy for election for the leadership of the governing Conservative Party.\n\nWiddecombe was appointed an Honorary Fellow of Canterbury Christ Church University at a ceremony held at Canterbury Cathedral on 30 January 2009.\n\nUntil her retirement at the 2010 general election, Widdecombe divided her time between her two homes – one in London and one in the village of Sutton Valence, Kent, in her constituency. She sold both of these properties, however, upon deciding to retire at the next general election. She shared her home in London with her widowed mother, Rita Widdecombe, until Rita's death, on 25 April 2007, aged 95. In March 2008, she purchased a house in Haytor Vale, on Dartmoor in Devon, to where she has now retired. Her brother, Malcolm (1937–2010), who was an Anglican Canon in Bristol, retired in May 2009 and died of metastatic oesophageal cancer on 12 October 2010. Her nephew, Roger Widdecombe, is an Anglican priest.\n\nShe has never married nor had any children. In November 2007 on BBC Radio 4 she described how a journalist once produced a profile on her with the assumption that she had had at least \"one sexual relationship\", to which Widdecombe replied: \"Be careful, that's the way you get sued\". When interviewer Jenni Murray asked if she had ever had a sexual relationship, Widdecombe laughed \"it's nobody else's business\".\n\nWiddecombe has a fondness for cats and has a section of her website devoted to all the pet cats with which she has shared her life. In an interview, Widdecombe talked about her appreciation of music despite describing herself as \"pretty well tone-deaf\".\n\nWiddecombe is a practising Roman Catholic. She converted in 1993 after leaving the Church of England. Her reasons for leaving the latter were many, as she explained to reporters from the \"New Statesman\":\n\nIn 2010, Widdecombe turned down an offer to be Britain's next ambassador to the Holy See, being prevented from accepting by suffering a detached retina. She was made a Dame of the Order of St. Gregory the Great by Pope Benedict XVI for services to politics and public life on 31 January 2013.\n\nIn 1990, following the assassination of the Conservative politician Ian Gow by the Provisional Irish Republican Army (IRA), the Eastbourne by-election for his seat in the House of Commons was won by the Liberal Democrat David Bellotti. Upon the announcement, Widdecombe told the voters that the IRA would be \"toasting their success\".\n\nIn 1996, Widdecombe, as prisons minister, defended the Government's policy to shackle pregnant prisoners with handcuffs and chains when in hospital receiving ante-natal care. Widdecombe told the Commons the restrictions were needed to prevent prisoners from escaping. \"Some MPs may like to think that a pregnant woman would not or could not escape. Unfortunately this is not true. The fact is that hospitals are not secure places in which to keep prisoners, and since 1990, 20 women have escaped from hospitals\". Jack Straw, Labour's Home Affairs spokesman at the time, said it was \"degrading and unnecessary\" for a woman to be shackled at any stage.\n\nIn 1997, during the Conservative leadership election of William Hague, Widdecombe spoke out against Michael Howard, under whom she had served when he was Home Secretary. She remarked in the House of Commons that there is \"something of the night\" about him. The remark was considered to be damaging to Howard, who came last in the first round, an opinion both former ministers share.\n\nIn 2001, when Michael Portillo was running for leader of the Conservative Party, Widdecombe described him and his allies as \"backbiters\". She went on to say that, should he be appointed leader, she would never give him her allegiance.\n\nIn 2002, she took part in the ITV programme \"Celebrity Fit Club\". Also in 2002 she took part in a Louis Theroux television documentary, depicting her life, both in and out of politics. In March 2004 she briefly became \"The Guardian\" newspaper's agony aunt, introduced with an Emma Brockes interview. In 2005 BBC Two showed six episodes of \"The Widdecombe Project\", an agony aunt television programme. In 2005, she appeared in a new series of \"Celebrity Fit Club\", but this time as a panel member dispensing wisdom and advice to the celebrities taking part. Also in 2005, she presented the show \"Ann Widdecombe to the Rescue\" in which she acted as an agony aunt, dispensing no-nonsense advice to disputing families, couples, and others across the UK. In 2005, she also appeared in a discussion programme on Five to discuss who had been England's greatest monarch since the Norman Conquest; her choice of monarch was Charles II.\n\nShe was the guest host of news quiz \"Have I Got News for You\" twice, in 2006 and 2007. Following her second appearance, Widdecombe vowed she would never appear on the show again because of comments made by panellist Jimmy Carr. She wrote, \"His idea of wit is a barrage of filth and the sort of humour most men grow out of in their teens... [T]here's no amount of money for which I would go through those two recording hours again. At one stage I nearly walked out.\" She did, however, stand by her appraisal of regular panellists Ian Hislop and Paul Merton, whom she has called \"the fastest wits in showbusiness\".\n\nIn 2007, she awarded the \"University Challenge\" trophy to the winners. In the same year, she was cast as herself in \"The Sound of Drums\", the 12th episode of the third series of the science-fiction drama \"Doctor Who\" supporting Mr Saxon, the alias of the Master.\n\nSince 2007, Widdecombe has fronted a television series called \"Ann Widdecombe Versus\", on ITV1, in which she speaks to various people about things related to her as an MP, with an emphasis on confronting those responsible for problems she wished to tackle. On 15 August 2007 she talked about prostitution, the next week about benefits and the week after that about truancy. A fourth episode was screened on 18 September 2008 in which she travelled around London and Birmingham talking to girl gangs.\n\nIn 2009, Widdecombe appeared with Archbishop John Onaiyekan in an \"Intelligence Squared\" debate in which they defended the motion that the Catholic Church was a force for good. Arguing against the motion were Stephen Fry and Christopher Hitchens.\n\nIn October 2010, she appeared on BBC One's \"Strictly Come Dancing\", partnered by Anton du Beke, winning the support of some viewers despite low marks from the judges. After nine weeks of routines strongly flavoured by comedy the couple had received enough support in the public vote to stay in the contest. Widdecombe was eliminated from the competition on Sunday 5 December after the public vote had been combined with the judges' score; she was with Scott Maslen of \"EastEnders\" in the bottom two.\n\nIn 2012, Widdecombe hosted a new quiz show with herself as questionmaster, for the Sky Atlantic channel, called \"Cleverdicks\". The show ran for one series with 30 one-hour episodes. It featured four contestants, usually high quality members of the UK national quiz circuit and ended with a money round for the winner of each show.\n\nOn 23 April 2012 Widdecombe presented an hour-long documentary for BBC Radio 5 Live, \"Drunk Again: Ann Widdecombe Investigates\", looking at how the British attitude to getting drunk has changed over the last few years.\n\nIt was revealed in October 2012, that the year's Children in Need's appeal night will feature a \"Strictly Come Dancing\" special with former show favourites Russell Grant and Ann Widdecombe.\n\nOn 4 November 2012, Ann presented guest hosted one episode of BBC's \"Songs of Praise\" programme about singleness.\n\nIn October 2014 she appeared in the BBC series \"Celebrity Antiques Road Trip\", partnered with expert Mark Stacey, where the pair beat the rival team of Craig Revel Horwood and Catherine Southon.\n\nWiddecombe was a part of television series \"24 Hours in the Past\", along with Colin Jackson, Alistair McGowan, Miquita Oliver, Tyger Drew-Honey and Zoe Lucker. The 4 -part series was aired from 28 April–19 May 2015 on BBC One. She took part in an episode of \"\" in 2016. In 2017, Widdecombe took part in ITV's \"Sugar Free Farm\".\n\nFollowing her retirement, Widdecombe made her stage debut, on 9 December 2011, at The Orchard Theatre, Dartford in the Christmas pantomime \"Snow White and the Seven Dwarfs\", alongside \"Strictly Come Dancing\" judge Craig Revel Horwood. In April 2012, she had a ten-minute non-singing cameo part in Gaetano Donizetti's comic opera \"La Fille Du Regiment\", playing the Duchesse de Crackentorp. Ann reprised her pantomime performance, again with Revel Horwood, at The Swan Theatre, High Wycombe in December 2012.\n\nHer non-political accomplishments include being a popular novelist. Widdecombe also currently writes a weekly column for the \"Daily Express\".\n\nIn October 2006, she pledged to boycott British Airways for suspending a worker who refused to hide her cross. The matter was resolved when the company reversed the suspension. In November 2006, she moved into the house of an Islington Labour Councillor to experience life on a council estate, her response to her experience being \"Five years ago I made a speech in the House of Commons about the forgotten decents. I have spent the last week on estates in the Islington area finding out that they are still forgotten.\"\n\nIn January 2011 Widdecombe was joint President of the North of England Education Conference in Blackpool. She shared the responsibility with a young person from the town. She has also become a patron of The Grace Charity for M.E.\n\nWiddecombe revealed, in an April 2012 interview with Matt Chorley of \"The Independent\", that she was writing her autobiography, which she described as \"rude about all and sundry, but an amount of truth is always necessary\".\n\nWiddecombe is a Patron of the charity Safe Haven for Donkeys in the Holy Land (SHADH) and in 2014 visited the SHADH Donkey Sanctuary in Palestine.\n\n\n\n\n", "id": "2422", "title": "Ann Widdecombe"}
{"url": "https://en.wikipedia.org/wiki?curid=2425", "text": "Aurangzeb\n\nAbu'l Muzaffar Muhi-ud-Din Muhammad (3 November 1618 – 3 March 1707), commonly known as Aurangzeb or by his regnal title Alamgir (\"He who seizes the universe\"), was the sixth, and widely considered the last effective Mughal Emperor. He ruled over most of the Indian subcontinent during some parts of his reign, which lasted for 49 years from 1658 until his death in 1707.\n\nAurangzeb was a notable expansionist and during his reign, the Mughal Empire temporarily reached its greatest extent. During his lifetime, victories in the south expanded the Mughal Empire to more than 3.2 million square kilometres and he ruled over a population estimated as being in the range of 100–150 million subjects, with an annual yearly tribute of £38,624,680 (2,879,469,894 rupees) in 1690. During his reign, 4.6 million people were said have died due to war and devastation. \n\nAurangzeb's policies partly abandoned the legacy of pluralism, which remains a very controversial aspect of his reign and led to the downfall of the Mughal Empire. Rebellions and wars led to the exhaustion of the imperial Mughal treasury and army. He was a strong-handed authoritarian ruler, and following his death the expansionary period of the Mughal Empire came to an end. Nevertheless, the contiguous territory of the Mughal Empire still remained intact more or less until the reign of Muhammad Shah.\n\nAurangzeb was born on 3 November 1618, in Dahod, Gujarat. He was the third son and sixth child of Shah Jahan and Mumtaz Mahal. \nIn June 1626, after an unsuccessful rebellion by his father, Aurangzeb and his brother Dara Shikoh were kept as hostages under their grandparents' (Nur Jahan and Jahangir) Lahore court. On 26 February 1628, Shah Jahan was officially declared the Mughal Emperor, and Aurangzeb returned to live with his parents at Agra Fort, where Aurangzeb received his formal education in Arabic and Persian. His daily allowance was fixed at Rs. 500 which he spent on religious education and the study of history. \nOn 28 May 1633, Aurangzeb escaped death when a powerful war elephant stampeded through the Mughal Imperial encampment. He rode against the elephant and struck its trunk with a lance, and successfully defended himself from being crushed. Aurangzeb's valour was appreciated by his father who conferred him the title of \"Bahadur\" (Brave) and had him weighed in gold and presented gifts worth Rs. 200,000. This event was celebrated in Persian and Urdu verses and Aurangzeb said:\n\nAurangzeb was nominally in charge of the force sent to Bundelkhand with the intent of subduing the rebellious ruler of Orchha, Jhujhar Singh, who had attacked another territory in defiance of Shah Jahan's policy and was refusing to atone for his actions. By arrangement, Aurangzeb stayed in the rear, away from the fighting, and took the advice of his generals as the Mughal Army gathered and commenced the Siege of Orchha in 1635. The campaign was successful and Singh was removed from power.\n\nAurangzeb was appointed viceroy of the Deccan in 1636. After Shah Jahan's vassals had been devastated by the alarming expansion of Ahmednagar during the reign of the Nizam Shahi boy-prince Murtaza Shah III, the emperor dispatched Aurangzeb, who in 1636 brought the Nizam Shahi dynasty to an end. In 1637, Aurangzeb married the Safavid princess, Dilras Banu Begum, also known as Rabia-ud-Daurani. She was his first wife and chief consort. He also had an infatuation with a slave girl, Hira Bai, whose death at a young age greatly affected him. In his old age, he was under the charms of his concubine, Udaipuri Bai. The latter had formerly been a companion to Dara Shikoh. In the same year, 1637, Aurangzeb was placed in charge of annexing the small Rajput kingdom of Baglana, which he did with ease.\n\nIn 1644, Aurangzeb's sister, Jahanara, was burned when the chemicals in her perfume were ignited by a nearby lamp while in Agra. This event precipitated a family crisis with political consequences. Aurangzeb suffered his father's displeasure by not returning to Agra immediately but rather three weeks later. Shah Jahan had been nursing Jahanara back to health in that time and thousands of vassals had arrived in Agra to pay their respects. Shah Jahan was outraged to see Aurangzeb enter the interior palace compound in military attire and immediately dismissed him from his position of viceroy of the Deccan; Aurangzeb was also no longer allowed to use red tents or to associate himself with the official military standard of the Mughal emperor. Other sources tell us that Aurangzeb was dismissed from his position because Aurangzeb left the life of luxery and became a Faqir.\n\nIn 1645, he was barred from the court for seven months and mentioned his grief to fellow Mughal commanders. Thereafter, Shah Jahan appointed him governor of Gujarat where he served well and was rewarded for bringing stability.\n\nIn 1647, Shah Jahan moved Aurangzeb from Gujarat to be governor of Balkh, replacing a younger son, Murad Baksh, who had proved ineffective there. The area was under attack from Uzbek and Turkmen tribes. Whilst the Mughal artillery and muskets were a formidable force, so too were the skirmishing skills of their opponents. The two sides were in stalemate and Aurangzeb discovered that his army could not live off the land, which was devastated by war. With the onset of winter, he and his father had to make a largely unsatisfactory deal with the Uzbeks, giving away territory in exchange for nominal recognition of Mughal sovereignty. The Mughal force suffered still further with attacks by Uzbeks and other tribesmen as it retreated through snow to Kabul. By the end of this two-year campaign, into which Aurangzeb had been plunged at a late stage, a vast sum of money had been expended for little gain.\n\nFurther inauspicious military involvements followed, as Aurangzeb was appointed governor of Multan and Sindh. His efforts in 1649 and 1652 to dislodge the Safavids at Kandahar, which they had recently retaken after a decade of Mughal control, both ended in failure as winter approached. The logistical problems of supplying an army at the extremity of the empire, combined with the poor quality of armaments and the intransigence of the opposition have been cited by John Richards as the reasons for failure, and a third attempt in 1653, led by Dara Shikoh, met with the same outcome.\n\nAurangzeb became viceroy of the Deccan again after he was replaced by Dara Shikoh in the attempt to recapture Kandahar. Aurangzeb regretted this and harboured feelings that Shikoh had manipulated the situation to serve his own ends. Aurangbad's two \"jagirs\" (land grants) were moved there as a consequence of his return and, because the Deccan was a relatively impoverished area, this caused him to lose out financially. So poor was the area that grants were required from Malwa and Gujarat in order to maintain the administration and the situation caused ill-feeling between father and son. Shah Jahan insisted that things could be improved if Aurangzeb made efforts to develop cultivation. Aurangzeb appointed Murshid Quli Khan to extend to the Deccan the \"zabt\" revenue system used in northern India. Murshid Quli Khan organised a survey of agricultural land and a tax assessment on what it produced. To increase revenue, Murshid Quli Khan granted loans for seed, livestock, and irrigation infrastructure. The Deccan returned to prosperity, but too slowly to satisfy the emperor.\n\nAurangzeb proposed to resolve the situation by attacking the dynastic occupants of Golconda (the Qutb Shahis) and Bijapur (the Adil Shahis). As an adjunct to resolving the financial difficulties, the proposal would also extend Mughal influence by accruing more lands. Again, he was to feel that Dara had exerted influence on his father: believing that he was on the verge of victory in both instances, Aurangzeb was frustrated that Shah Jahan chose then to settle for negotiations with the opposing forces rather than pushing for complete victory.\n\nThe four sons of Shah Jahan all held governorships during their father's reign. The emperor favoured the eldest, Dara Shikoh. This had caused resentment among the younger three, who sought at various times to strengthen alliances between themselves and against Dara. There was no Mughal tradition of primogeniture, the systematic passing of rule, upon an emperor's death, to his eldest son. Instead it was customary for sons to overthrow their father and for brothers to war to the death among themselves. Historian Satish Chandra says that \"In the ultimate resort, connections among the powerful military leaders, and military strength and capacity [were] the real arbiters\". The contest for power was primarily between Dara Shikoh and Aurangzeb because, although all four sons had demonstrated competence in their official roles, it was around these two that the supporting cast of officials and other influential people mostly circulated. There were ideological differences — Dara was an intellectual and a religious liberal in the mould of Akbar, while Aurangzeb was much more conservative — but, as historians Barbara D. Metcalf and Thomas R. Metcalf say, \"To focus on divergent philosophies neglects the fact that Dara was a poor general and leader. It also ignores the fact that factional lines in the succession dispute were not, by and large, shaped by ideology.\" Marc Gaborieau, professor of Indian studies at l'École des Hautes Études en Sciences Sociales, explains that \"The loyalties of [officials and their armed contingents] seem to have been motivated more by their own interests, the closeness of the family relation and above all the charisma of the pretenders than by ideological divides.\" Muslims and Hindus did not divide along religious lines in their support for one pretender or the other nor, according to Chandra, is there much evidence to support the belief that Jahanara and other members of the royal family were split in their support. Jahanara, certainly, interceded at various times on behalf of all of the princes and was well-regarded by Aurangzeb even though she shared the religious outlook of Dara.\n\nIn 1656, a general under Qutb Shahi dynasty named Musa Khan led an army of 12,000 Musketeers to attack Aurangzeb, and later on the same campaign Aurangzeb in turn rode against an army consisting 8,000 horsemen and 20,000 Karnataka Musketeers\n\nHaving made clear that he wanted Dara to succeed him, Shah Jahan became ill with stranguary in 1657 and was closeted under the care of his favourite son in the newly built city of Shahjahanabad (Old Delhi). Rumours of the death of Shah Jahan abounded and the younger sons were concerned that Dara might be hiding it for Machiavellian reasons. Thus, they took action: Shah Shuja prepared to contest the throne from Bengal, where he had been governor since 1637, while Murad did the same in his governorship of Gujarat and Aurangzeb did so in the Deccan. It is not known whether these preparations were made in the mistaken belief that the rumours of death were true or whether the challengers were just taking advantage of the situation.\n\nAfter regaining some of his health, Shah Jahan moved to Agra and Dara urged him to send forces to challenge Shah Shuja and Murad, who had declared themselves rulers in their respective territories. While Shah Shuja was defeated at Banares in February 1658, the army sent to deal with Murad discovered to their surprise that he and Aurangzeb had combined their forces, the two brothers having agreed to partition the empire once they had gained control of it. The two armies clashed at Dharmat in April 1658, with Aurangzeb being the victor. Shuja was being chased through Bihar and the victory of Aurangzeb proved this to be a poor decision by Dara Shikoh, who now had a defeated force on one front and a successful force unnecessarily pre-occupied on another. Realising that his recalled Bihar forces would not arrive at Agra in time to resist the emboldened Aurangzeb's advance, Dara scrambled to form alliances in order but found that Aurangzeb had already courted key potential candidates. When Dara's disparate, hastily concocted army clashed with Aurangzeb's well-disciplined, battle-hardened force at the Battle of Samugarh in late May, neither Dara's men nor his generalship were any match for Aurangzeb. Dara had also become over-confident in his own abilities and, by ignoring advice not to lead in battle while his father was alive, he cemented the idea that he had usurped the throne. \"After the defeat of Dara, Shah Jahan was imprisoned in the fort of Agra where he spent eight long years under the care of his favourite daughter Jahanara.\"\n\nAurangzeb then broke his arrangement with Murad Baksh, which probably had been his intention all along. Instead of looking to partition the empire between himself and Murad, he had his brother arrested and imprisoned at Gwalior Fort. Murad was executed on 4 December 1661, ostensibly for the murder of the \"diwan\" of Gujarat some time earlier. The allegation was encouraged by Aurangzeb, who caused the \"diwan's\" son to seek retribution for the death under the principles of Sharia law. Meanwhile, Dara gathered his forces, and moved to the Punjab. The army sent against Shuja was trapped in the east, its generals Jai Singh and Dilir Khan submitted to Aurangzeb, but Dara's son, Suleiman Shikoh, escaped. Aurangzeb offered Shah Shuja the governorship of Bengal. This move had the effect of isolating Dara Shikoh and causing more troops to defect to Aurangzeb. Shah Shuja, who had declared himself emperor in Bengal began to annex more territory and this prompted Aurangzeb to march from Punjab with a new and large army that fought during the Battle of Khajwa, where Shah Shuja and his chain-mail armoured war elephants were routed by the forces loyal to Aurangzeb. Shah Shuja then fled to Arakan (in present-day Burma), where he was executed by the local rulers.\n\nWith Shuja and Murad disposed of, and with his father immured in Agra, Aurangzeb pursued Dara Shikoh, chasing him across the north-western bounds of the empire. Aurangzeb claimed that Dara was no longer a Muslim and accused him of poisoning the Mughal Grand Vizier Saadullah Khan. Both of these statements however lacked any evidence. After a series of battles, defeats and retreats, Dara was betrayed by one of his generals, who arrested and bound him. In 1658, Aurangzeb arranged his formal coronation in Delhi.\n\nOn 10 August 1659, Dara was executed on grounds of apostasy and his head was sent to Shahjahan. Having secured his position, Aurangzeb confined his frail father at the Agra Fort but did not mistreat him. Shah Jahan was cared for by Jahanara and died in 1666.\n\nHistorian Katherine Brown has noted that \"The very name of Aurangzeb seems to act in the popular imagination as a signifier of politico-religious bigotry and repression, regardless of historical accuracy.\" The subject is controversial and, despite no proof, has resonated in modern times with popularly accepted claims that he intended to destroy the Bamiyan Buddhas. As a political and religious conservative, Aurangzeb chose not to follow the liberal religious viewpoints of his predecessors after his ascension. Shah Jahan had already moved away from the liberalism of Akbar, although in a token manner rather than with the intent of suppressing Hinduism, and Aurangzeb took the change still further. Though the approach to faith of Akbar, Jahangir and Shah Jahan was more syncretic than Babur, the founder of the empire, Aurangzeb's position is not so obvious. His emphasis on sharia competed, or was directly in conflict, with his insistence that \"zawabit\" or secular decrees could supersede sharia. Despite claims of sweeping edicts and policies, contradictory accounts exist. He sought to codify Hanafi law by the work of several hundred jurists, called Fatawa-e-Alamgiri. It is possible the War of Succession and continued incursions combined with Shah Jahan's spending made cultural expenditure impossible.\n\nAs emperor, Aurangzeb banned the drinking of alcohol, gambling, castration, servitude, eunuchs, music, nautch and narcotics in the Mughal Empire. He learnt that at Sindh, Multan, Thatta and particularly at Varanasi, the Hindu Brahmins attracted large numbers of indigenous local Muslims to their discourses. He ordered the Subahdars of these provinces to demolish the schools and the temples of non-Muslims. Aurangzeb also ordered Subahdars to punish Muslims who dressed like non-Muslims. The executions of the antinomian Sufi mystic Sarmad Kashani and the ninth Sikh Guru Tegh Bahadur bear testimony to Aurangzeb's religious policy; the former was beheaded on multiple accounts of heresy, the latter, according to Sikhs, because he objected to Aurangzeb's forced conversions. According to other sources, there is no official account that Aurangzeb forcefully converted people.\n\nHe imposed Jizya, a military tax on non-Muslims who is not fighting for Mughal empire in his second decade on ruling in the year 1679. Further, Aurangzeb levied discriminatory taxes on Hindu merchants at the rate of 5% as against 2.5% on Muslim merchants. He ordered to dismiss all Hindu \"quanungos\" and \"patwaris\" from revenue administration.\n\nAnother instance of Aurangzeb's notoriety was his policy of temple destruction, for which figures vary wildly from 80 to 60,000. Indian historian Harbans Mukhia wrote that \"In the end, as recently recorded in Richard Eaton's careful tabulation, some 80 temples were demolished between 1192 and 1760 (15 in Aurangzeb's reign) and he compares this figure with the claim of 60,000 demolitions, advanced rather nonchalantly by 'Hindu nationalist' propagandists,' although even in that camp professional historians are slightly more moderate.\" Among the Hindu temples he demolished were the three most sacred: the Kashi Vishwanath temple, Kesava Deo temple and Somnath temple. He built large mosques in their place. In 1679, he ordered destruction of several prominent temples that had become associated with his enemies: these included the temples of Khandela, Udaipur, Chittor and Jodhpur. Historian Richard Eaton believes the overall understanding of temples to be flawed. As early as the sixth century, temples became vital political landmarks as well as religious ones. He writes that not only was temple desecration widely practised and accepted, it was a necessary part of political struggle.\n\nRam Puniyani states that Aurangzeb was not always fanatically anti-Hindu, and kept changing his policies depending on the needs of the situation. He banned the construction of new temples, but permitted the repair and maintenance of existing temples. He also made generous donations of \"jagirs\" to several temples to win the sympathies of his Hindu subjects. There are several \"firman\"s (orders) in his name, supporting temples and gurudwaras, including Mahakaleshwar temple of Ujjain, Balaji temple of Chitrakoot, Umananda Temple of Guwahati and the Shatrunjaya Jain temples. During his time, the number of Hindu Mansabdars increased from 22% to 31% in the Mughal administration as he needed them to continue his fight in the Deccan.\n\nThe first prominent execution during the long reign of Aurangzeb started with that of his brother Prince Dara Shikoh, who was accused of being influenced by Hinduism although some sources argue it was done for political reasons. Aurangzeb had his allied brother Prince Murad Baksh held for murder, judged and then executed. Aurangzeb is accused of poisoning his imprisoned nephew Sulaiman Shikoh.\n\nLater Sambhaji was executed during his reign, In a trial he was found guilty of murder and violence, atrocities against the Muslims of Burhanpur and Bahadurpur in Berar by Marathas under his command.\n\nThe Sikh leader Guru Tegh Bahadur was arrested on orders by Aurangzeb, found guilty of blasphemy by a Qadi's court and executed.\n\n32 nd Da'i al-Mutlaq (Absolute Missionary) of the Dawoodi Bohra sect of Musta‘lī Islam Syedna Qutubkhan Qutubuddin was executed by Aurangzeb, then governor of Gujarat, for heresy; on 27 Jumadil Akhir 1056 AH/ 1648 AD), Ahmedabad, India.\n\nThroughout his reign, Aurangzeb engaged in almost constant warfare. He built up a massive army and began a program of military expansion along all the boundaries of his empire. He pushed north-west into the Punjab and also drove south, conquering two further Muslim kingdoms - the Adil Shahis of Bijapur and Qutbshahis of Golconda — to add to the defeat of the Ahmednagar Sultanate that had been accomplished in 1636 while he had been viceroy of the Deccan. These new territories were administered by the Mughal Nawabs loyal to Aurangzeb.\n\nSoon after seizing the throne, Aurangzeb began advancements against the unruly Sultan of Bijapur and during 1657, the Mughals are known to have utilised rockets during the Siege of Bidar, against Sidi Marjan. Aurangzeb's forces discharged rockets and grenades while scaling the walls, and Sidi Marjan himself was mortally wounded after a rocket struck his large gunpowder depot. After twenty-seven days of hard fighting, Bidar was captured by the Mughals.\n\nIn 1663, during his visit to Ladakh, Aurangzeb established direct control over that part of the empire and loyal subjects such as Deldan Namgyal agreed to pledge tribute and loyalty. Deldan Namgyal is also known to have constructed a Grand Mosque in Leh, which he dedicated to Mughal rule.\n\nIn 1664, Aurangzeb appointed Shaista Khan subedar (governor) of Bengal. Shaista Khan eliminated Portuguese and Arakanese pirates from the region, and in 1666 recaptured the port of Chittagong from the Arakanese king, Sanda Thudhamma. Chittagong remained a key port throughout Mughal rule.\n\nIn 1685, Aurangzeb dispatched his son, Muhammad Azam Shah, with a force of nearly 50,000 men to capture Bijapur Fort and defeat Sikandar Adil Shah (the ruler of Bijapur) who refused to be a vassal. The Mughals could not make any advancements upon Bijapur Fort mainly because of the superior usage of cannon batteries on both sides. Outraged by the stalemate Aurangzeb himself arrived on 4 September 1686 and commanded the Siege of Bijapur; after eight days of fighting, the Mughals were victorious.\n\nOnly one remaining ruler, Abul Hasan Qutb Shah (the Qutbshahi ruler of Golconda), refused to surrender. He and his servicemen fortified themselves at Golconda and fiercely protected the Kollur Mine, which was then probably the world's most productive diamond mine, and an important economic asset. In 1687, Aurangzeb led his grand Mughal army against the Deccan Qutbshahi fortress during the Siege of Golconda. The Qutbshahis had constructed massive fortifications throughout successive generations on a granite hill over 400 ft high with an enormous eight-mile long wall enclosing the city. The main gates of Golconda had the ability to repulse any war elephant attack. Although the Qutbshahis maintained the impregnability of their walls, at night Aurangzeb and his infantry erected complex scaffolding that allowed them to scale the high walls. During the eight-month siege the Mughals faced many hardships including the death of their experienced commander Kilich Khan Bahadur. Eventually, Aurangzeb and his forces managed to penetrate the walls by capturing a gate, and their entry into the fort led Abul Hasan Qutb Shah to surrender peacefully.\n\nMughal cannon making skills advanced during the 17th century. One of the most impressive Mughal cannons is known as the Zafarbaksh, which is a very rare \"composite cannon\", that required skills in both wrought-iron forge welding and bronze-casting technologies and the in-depth knowledge of the qualities of both metals.\n\nAurangzeb military entourage consisted of 16 cannons including the \"Azdaha Paikar\" (which, was capable of firing a 33.5 kg ordnance) and \"Fateh Rahber\" (20 feet long with Persian and Arabic inscriptions).\n\nThe \"Ibrahim Rauza\" was also a famed cannon, which was well known for its multi-barrels. François Bernier, the personal physician to Aurangzeb, observed versatile Mughal gun-carriages each drawn by two horses.\n\nDespite these innovations, most soldiers used bows and arrows, the quality of sword manufacture was so poor that they preferred to use ones imported from England, and the operation of the cannons was entrusted not to Mughals but to European gunners. Other weapons used during the period included rockets, cauldrons of boiling oil, muskets and manjaniqs (stone-throwing catapults).\n\nInfantry who were later called Sepoy and who specialised in siege and artillery emerged during the reign of Aurangzeb\n\nIn 1703, the Mughal commander at Coromandel, Daud Khan Panni spent 10,500 coins to purchase 30 to 50 war elephants from Ceylon.\n\nAurangzeb was known to be of a more austere nature than his predecessors. Being religious he encouraged Islamic calligraphy. His reign also saw the building of the Lahore badshahi Mosque, and Bibi ka Maqbara in Aurangabad for his wife Rabia-ud-Daurani.\n\nThe Mughal Emperor Aurangzeb is known to have patronised works of Islamic Calligraphy during his reign particularly Syed Ali Tabrizi.\n\nUnlike his father, Aurangzeb was not much interested in architecture. Aurangzeb constructed a small marble mosque known as the Moti Masjid (Pearl Mosque) in the Red Fort complex in Delhi. He ordered the construction of the Badshahi Mosque in Lahore. He also constructed a mosque on Benares. The mosque he constructed in Srinagar is still the largest in Kashmir. The structure of Bibi Ka Maqbara in Aurangabad, which now is a historical monument was constructed by the sons of Aurangzeb in remembrance of their mother. The inspiration came from Taj mahal as is quite visible from its architecture.\n\nThe textile industry in the Mughal Empire emerged very firmly during the reign of the Mughal Emperor Aurangzeb and was particularly well noted by Francois Bernier, a French physician of the Mughal Emperor. Francois Bernier writes how \"Karkanahs\", or workshops for the artisans, particularly in textiles flourished by \"employing hundreds of embroiderers, who were superintended by a master\". He further writes how \"Artisans manufacture of silk, fine brocade, and other fine muslins, of which are made turbans, robes of gold flowers, and tunics worn by females, so delicately fine as to wear out in one night, and cost even more if they were well embroidered with fine needlework\".\n\nHe also explains the different techniques employed to produce such complicated textiles such as \"Himru\" (whose name is Persian for \"brocade\"), \"Paithani\" (whose pattern is identical on both sides), \"Mushru\" (satin weave) and how \"Kalamkari\", in which fabrics are painted or block-printed, was a technique that originally came from Persia. Francois Bernier provided some of the first, impressive descriptions of the designs and the soft, delicate texture of Pashmina Shawls also known as \"Kani\", which were very valued for their warmth and comfort among the Mughals, and how these textiles and shawls eventually began to find their way to France and England.\n\nAs soon as he became emperor, Aurangzeb sent some of the finest ornate gifts such as carpets, lamps, tiles and others to the Islamic shrines at Mecca and Medina. He also ordered the construction of very large ships in Surat that would transport these gifts and even pilgrims to the Hijaz. These annual expeditions organised by Aurangzeb were led by Mir Aziz Badakhshi who died in Mecca of natural causes but managed to deliver more than 45,000 silver coins and several thousand Kaftans of honour.\n\nSubhan Quli, Balkh's Uzbek ruler was the first to recognise him in 1658 and requested for a general alliance, he worked alongside the new Mughal Emperor since 1647, when Aurangzeb was the Subedar of Balkh.\n\nAurangzeb received the embassy of Abbas II of Persia in 1660 and returned them with gifts. However relations between the Mughal Empire and the Safavid dynasty were tense because the Persians attacked the Mughal army positioned near Kandahar. Aurangzeb prepared his armies in the Indus River Basin for a counteroffensive, but Abbas II's death in 1666 caused Aurangzeb to end all hostilities. Aurangzeb's rebellious son, Sultan Muhammad Akbar, sought refuge with Suleiman I of Persia, who had rescued him from the Imam of Musqat and later refused to assist him in any military adventures against Aurangzeb.\n\nIn 1667, the French East India Company ambassadors Le Gouz and Bebert presented Louis XIV of France's letter which urged the protection of French merchants from various rebels in the Deccan. In response to the letter Aurangzeb issued a Firman allowing the French to open a factory in Surat.\n\nIn the 1660s, the Sultan of the Maldives, Ibrahim Iskandar I, requested help from Aurangzeb's representative, the Faujdar of Balasore. The sultan was concerned about the impact of Dutch and English trading ships but the powers of Aurangzeb did not extend to the seas, the Maldives were not under his governance and nothing came of the request.\n\nIn 1688, the desperate Ottoman Sultan Suleiman II urgently requested for assistance against the rapidly advancing Austrians, during the Ottoman–Habsburg War. However, Aurangzeb and his forces were heavily engaged in the Deccan Wars against the Marathas to commit any formal assistance to their Ottoman allies.\n\nIn 1686, the English East India Company, which had unsuccessfully tried to obtain a firman, an imperial directive that would grant England regular trading privileges throughout the Mughal empire, initiated the so-called Child's War. This hostility against the empire ended in disaster for the English, particularly when Aurangzeb dispatched a strong fleet from Janjira commanded by the Sidi Yaqub and manned by Mappila loyal to Ali Raja Ali II and Abyssinian sailors firmly blockaded Bombay in 1689. In 1690, the company sent envoys to Aurangzeb's camp to plead for a pardon. The company's envoys had to prostrate themselves before the emperor, pay a large indemnity, and promise better behaviour in the future.\n\nIn September 1695, English pirate Henry Every perpetrated one of the most profitable pirate raids in history with his capture of a Grand Mughal convoy near Surat. The Indian ships had been returning home from their annual pilgrimage to Mecca when the pirates struck, capturing the \"Ganj-i-Sawai\", reportedly the greatest ship in the Muslim fleet, and its escorts in the process. When news of the piracy reached the mainland, a livid Aurangzeb nearly ordered an armed attack against the English-governed city of Bombay, though he finally agreed to compromise after the East India Company promised to pay financial reparations, estimated at £600,000 by the Mughal authorities. Meanwhile, Aurangzeb shut down four of the East India Company's factories, imprisoned the workers and captains (who were nearly lynched by a rioting mob), and threatened to put an end to all English trading in India until Every was captured. The Privy Council and East India Company offered a massive bounty for Every's apprehension, leading to the first worldwide manhunt in recorded history. However, Every successfully eluded capture.\n\nIn 1702, Aurangzeb sent Daud Khan Panni, the Mughal Empire's Subhedar of the Carnatic region, to besiege and blockade Fort St. George for more than three months. The governor of the fort Thomas Pitt was instructed by the English East India Company to sue for peace.\n\nAurangzeb's exchequer raised a record £100 million in annual revenue through various sources like taxes, customs and land revenue, \"et al.\" from 24 provinces.\n\nAurangzeb felt that verses from the \"Quran\" should not be stamped on coins, as done in former times, because they were constantly touched by the hands and feet of people. His coins had the name of the mint city and the year of issue on one face, and, the following couplet on other:\n\nBy 1700, the Marathas attacked the Mughal provinces from the Deccan and secessionist agendas from the Rajputs, Hindu Jats, Pashtuns and Sikhs rebelled against the Mughal Empire's administrative and economic systems.\n\nIn 1669, Hindu Jats began to organise a rebellion that is believed to have been caused by Aurangzeb's imposition of Jizya (a form of organised religious taxation). The Jats were led by \"Gokula\", a rebel landholder from Tilpat. By the year 1670 20,000 Jat rebels were quelled and the Mughal Army took control of Tilpat, Gokula's personal fortune amounted to 93,000 gold coins and hundreds of thousands of silver coins.\n\nGokula was caught and executed. But the Jats continued to terrorise the Mughals and attacked Akbar's mausoleum the gold, silver and fine carpets within the tomb . There are claims that Jats caused two large silver doors at the entrance of the Taj Mahal to be stolen and melted down. However, Jats later established their independent state of Bharatpur.\n\nIn 1657, while Aurangzeb attacked Golconda and Bijapur in the Deccan, the Hindu Maratha warrior aristocrat, Shivaji, used guerrilla tactics to take control of three Adil Shahi forts formerly under his father's command. With these victories, Shivaji assumed de facto leadership of many independent Maratha clans. The Marathas harried the flanks of the warring Adil Shahis and Mughals, gaining weapons, forts, and territory. Shivaji's small and ill-equipped army survived an all out Adil Shahi attack, and Shivaji personally killed the Adil Shahi general, Afzal Khan. With this event, the Marathas transformed into a powerful military force, capturing more and more Adil Shahi and Mughal territories. Shivaji went on to neutralise Mughal power in the region.\n\nIn 1659, Aurangzeb sent his trusted general and maternal uncle Shaista Khan, the Wali in Golconda to recover forts lost to the Maratha rebels. Shaista Khan drove into Maratha territory and took up residence in Pune. But in a daring raid on the governor's palace in Pune during a midnight wedding celebration, the Marathas killed Shaista Khan's son and maimed Shaista Khan by cutting off the fingers of his hand. Shaista Khan, however, survived and was re-appointed the administrator of Bengal going on to become a key commander in the war against the Ahoms.\n\nShivaji captured forts belonging to both Mughals and Bijapur. At last Aurangzeb ordered the armament of the Daulatabad Fort with two bombards (the Daulatabad Fort was later utilised as a Mughal bastion during the Deccan Wars). Aurangzeb also sent his general Raja Jai Singh of Amber, a Hindu Rajput, to attack the Marathas. Jai Singh won the fort of Purandar after fierce battle in which the Maratha commander Murarbaji fell. Foreseeing defeat, Shivaji agreed for a truce and a meeting with Aurangjeb at Delhi. Jai Singh also promised Shivaji his safety, placing him under the care of his own son, the future Raja Ram Singh I. However, circumstances at the Mughal court were beyond the control of the Raja, and when Shivaji and his son Sambhaji went to Agra to meet Aurangzeb, they were placed under house arrest, from which they managed to effect a daring escape.\n\nShivaji returned to the Deccan, and crowned himself \"Chhatrapati\" or the ruler of the Maratha Kingdom in 1674. While Aurangzeb continued to send troops against him, Shivaji expanded Maratha control throughout the Deccan until his death in 1680. Shivaji was succeeded by his son, Sambhaji. Militarily and politically, Mughal efforts to control the Deccan continued to fail.\n\nOn the other hand, Aurangzeb's third son Akbar left the Mughal court along with a few Muslim Mansabdar supporters and joined Muslim rebels in the Deccan. Aurangzeb in response moved his court to Aurangabad and took over command of the Deccan campaign. The rebels were defeated and Akbar fled south to seek refuge with Sambhaji, Shivaji's successor. More battles ensued, and Akbar fled to Persia and never returned.\n\nIn 1689, Aurangzeb's forces captured and executed Sambhaji. His successor Rajaram, later Rajaram's widow Tarabai and their Maratha forces fought individual battles against the forces of the Mughal Empire. Territory changed hands repeatedly during the years (1689–1707) of interminable warfare . As there was no central authority among the Marathas, Aurangzeb was forced to contest every inch of territory, at great cost in lives and money. Even as Aurangzeb drove west, deep into Maratha territory – notably conquering Satara — the Marathas expanded their attacks further into Mughal lands – Malwa, Hyderabad and Jinji in Tamil Nadu. Aurangzeb waged continuous war in the Deccan for more than two decades with no resolution. He thus lost about a fifth of his army fighting rebellions led by the Marathas in Deccan India. He travelled a long distance to the Deccan to conquer the Marathas and eventually died at the age of 90, still fighting the Marathas.\n\nAurangzeb's shift from conventional warfare to anti-insurgency in the Deccan region shifted the paradigm of Mughal military thought. There were conflicts between Marathas and Mughals in Pune, Jinji, Malwa and Vadodara. The Mughal Empire's port city of Surat was sacked twice by the Marathas during the reign of Aurangzeb and the valuable port was in ruins.\n\nWhile Aurangzeb and his brother Shah Shuja had been fighting against each other, the Hindu rulers of Kuch Behar and Assam took advantage of the disturbed conditions in the Mughal Empire, had invaded imperial dominions. For three years they were not attacked, but in 1660 Mir Jumla II, the viceroy of Bengal, was ordered to recover the lost territories.\n\nThe Mughals set out in November 1661, and within weeks occupied the capital of Kuch Behar after a few fierce skirmishes. The Kuch Behar was annexed, and the Mughal Army reorganised and began to retake their territories in Assam. Mir Jumla II's forces captured Pandu, Guwahati, and Kajali practically unopposed. In February 1662, Mir Jumla II initiated the Siege of Simalugarh and after the Mughal cannon breached the fortifications, the Ahoms abandoned the fort and escaped. Mir Jumla II then proceeded towards Garhgaon the capital of the Ahom kingdom, which was reached on 17 March 1662, although the ruler Raja Sutamla fled and the victorious Mughals captured 100 elephants, about 300,000 coins of silver, 8000 shields, 1000 ships, and 173 massive stores of rice.\n\nLater that year in December 1663, the aged Mir Jumla II died on his way back to Dacca of natural causes, but skirmishes continued between the Mughals and Ahoms after the rise of Chakradhwaj Singha, who refused to pay further indemnity to the Mughals and during the wars that continued the Mughals suffered great hardships. Munnawar Khan emerged as a leading figure and is known to have supplied food to vulnerable Mughal forces in the region near Mathurapur. Although the Mughals under the command of Syed Firoz Khan the Faujdar at Guwahati were overrun by two Ahom armies in the year 1667, but they continued to hold and maintain presence along their the eastern territories even after the Battle of Saraighat in the year 1671.\n\nThe Battle of Saraighat was fought in 1671 between the Mughal empire (led by the Kachwaha king, Raja Ramsingh I), and the Ahom Kingdom (led by Lachit Borphukan) on the Brahmaputra river at Saraighat, now in Guwahati. Although much weaker, the Ahom Army defeated the Mughal Army by brilliant uses of the terrain, clever diplomatic negotiations to buy time, guerrilla tactics, psychological warfare, military intelligence and by exploiting the sole weakness of the Mughal forces—its navy.\n\nThe Battle of Saraighat was the last battle in the last major attempt by the Mughals to extend their empire into Assam. Though the Mughals managed to regain Guwahati briefly after a later Borphukan deserted it, the Ahoms wrested control in the Battle of Itakhuli in 1682 and maintained it till the end of their rule.\n\nIn May 1672, the Satnami sect obeying the commandments of an \"old toothless woman\" (according to Mughal accounts) organised a massive revolt in the agricultural heartlands of the Mughal Empire. The Satnamis were known to have shaved off their heads and even eyebrows and had temples in many regions of Northern India. They began a large-scale rebellion 75 miles southwest of Delhi.\n\nThe Satnamis believed they were invulnerable to Mughal bullets and believed they could multiply in any region they entered. The Satnamis initiated their march upon Delhi and overran small-scale Mughal infantry units.\n\nAurangzeb responded by organising a Mughal army of 10,000 troops and artillery, and dispatched detachments of his own personal Mughal imperial guards to carry out several tasks. To boost Mughal morale, Aurangzeb wrote Islamic prayers, made amulets, and drew designs that would become emblems in the Mughal Army. This rebellion would have a serious aftermath effect on the Punjab.\n\nEarly in Aurangzeb's reign, various insurgent groups of Sikhs engaged Mughal troops in increasingly bloody battles. The ninth Sikh Guru, Guru Tegh Bahadur, like his predecessors was opposed to conversion of the local population as he considered it wrong. According to Sikh sources, approached by Kashmiri Pandits to help them retain their faith and avoid forced religious conversions, Guru Tegh Bahadur took on Aurangzeb. The emperor perceived the rising popularity of the Guru as a threat to his sovereignty and in 1670 had him executed, which infuriated the Sikhs. In response, Guru Tegh Bahadur's son and successor, Guru Gobind Singh, further militarised his followers, starting with the establishment of Khalsa in 1699, eight years before Aurangzeb's death. In 1705, Guru Gobind Singh sent a letter entitled \"Zafarnamah\" to Aurangzeb. This drew attention to Auranzeb's cruelty and how he had betrayed Islam. The letter caused him much distress and remorse. Guru Gobind Singh's formation of Khalsa in 1699 led to the establishment of the Sikh Confederacy and later Sikh Empire.\n\nThe Pashtun revolt in 1672 under the leadership of the warrior poet Khushal Khan Khattak of Kabul, was triggered when soldiers under the orders of the Mughal Governor Amir Khan allegedly molested women of the Pashtun tribes in modern-day Kunar Province of Afghanistan. The Safi tribes retaliated against the soldiers. This attack provoked a reprisal, which triggered a general revolt of most of tribes. Attempting to reassert his authority, Amir Khan led a large Mughal Army to the Khyber Pass, where the army was surrounded by tribesmen and routed, with only four men, including the Governor, managing to escape.\n\nAfter that the revolt spread, with the Mughals suffering a near total collapse of their authority in the Pashtun belt. The closure of the important Attock-Kabul trade route along the Grand Trunk road was particularly disastrous. By 1674, the situation had deteriorated to a point where Aurangzeb camped at Attock to personally take charge. Switching to diplomacy and bribery along with force of arms, the Mughals eventually split the rebels and partially suppressed the revolt, although they never managed to wield effective authority outside the main trade route.\n\nBy 1689, almost all of Southern India was a part of the Mughal Empire and after the conquest of Golconda, Aurangzeb may have been the richest and most powerful man alive. Mughal victories in the south expanded the Mughal Empire to 3.2 million square kilometres, with a population estimated as being between 100 million and 150 million. But this supremacy was short-lived. Jos Gommans, Professor of Colonial and Global History at the University of Leiden, says that \"... the highpoint of imperial centralisation under emperor Aurangzeb coincided with the start of the imperial downfall.\"\n\nAurangzeb's vast imperial campaigns against rebellion-affected areas of the Mughal Empire caused his opponents to exaggerate the \"importance\" of their rebellions. The results of his campaigns were made worse by the incompetence of his regional Nawabs.\n\nMuslim views regarding Aurangzeb vary. Most Muslim historians believe that Aurangzeb was the last powerful ruler of an empire inevitably on the verge of decline. The major rebellions organised by the Sikhs and the Marathas had deep roots in the remote regions of the Mughal Empire.\n\nUnlike his predecessors, Aurangzeb considered the royal treasury to be held in trust for the citizens of his empire. He made caps and copied the Quran to earn money for his use. Aurangzeb constructed a small marble mosque known as the Moti Masjid (Pearl Mosque) in the Red Fort complex in Delhi. However, his constant warfare, especially with the Marathas, drove his empire to the brink of bankruptcy just as much as the wasteful personal spending and opulence of his predecessors. Aurangzeb knew he would not return to the throne after his final campaign against the Marathas in 1706, in which he was joined by newly emerging commanders in the Mughal army such as Syed Hassan Ali Khan Barha, Saadat Ali Khan and Asaf Jah I, and Daud Khan.\n\nThe Indologist Stanley Wolpert, emeritus professor at UCLA, says that:\n\nEven when ill and dying, Aurangzeb made sure that the populace knew he was still alive, for if they had thought otherwise then the turmoil of another war of succession was likely. He died in Ahmednagar on 20 February 1707 at the age of 88, having outlived many of his children. His modest open-air grave in Khuldabad expresses his deep devotion to his Islamic beliefs. It is sited in the courtyard of the shrine of the Sufi saint Shaikh Burhan-u'd-din Gharib, who was a disciple of Nizamuddin Auliya of Delhi.\n\nBrown writes that after his death, \"a string of weak emperors, wars of succession, and coups by noblemen heralded the irrevocable weakening of Mughal power\". She notes that the populist but \"fairly old-fashioned\" explanation for the decline is that there was a reaction to Aurangzeb's oppression. Aurangzeb's son, Bahadur Shah I, succeeded him and the empire, both because of Aurangzeb's over-extension and because of Bahadur Shah's weak military and leadership qualities, entered a period of terminal decline. Immediately after Bahadur Shah occupied the throne, the Maratha Empire – which Aurangzeb had held at bay, inflicting high human and monetary costs even on his own empire – consolidated and launched effective invasions of Mughal territory, seizing power from the weak emperor. Within decades of Aurangzeb's death, the Mughal Emperor had little power beyond the walls of Delhi.\n\nHis full imperial title was Al-Sultan al-Azam wal Khaqan al-Mukarram Hazrat Abul Muzaffar Muhy-ud-Din Muhammad Aurangzeb Bahadur Alamgir I, Badshah Ghazi, Shahanshah-e-Sultanat-ul-Hindiya Wal Mughaliya.\n\n\nNotes\n\nCitations\n\n", "id": "2425", "title": "Aurangzeb"}
{"url": "https://en.wikipedia.org/wiki?curid=2427", "text": "Alexandrine\n\nAlexandrine is a name used for several distinct types of verse line with related metrical structures, most of which are ultimately derived from the classical French alexandrine. The line's name derives from its use in the Medieval French \"Roman d'Alexandre\" of 1170, although it had already been used several decades earlier in \"Le Pèlerinage de Charlemagne\". The foundation of most alexandrines consists of two hemistichs (half-lines) of six syllables each, separated by a caesura (a word break, though often realized as a stronger syntactic break):\n\nHowever, no tradition remains this simple. Each applies additional constraints (such as obligatory stress or nonstress on certain syllables) and options (such as a permitted or required additional syllable at the end of one or both hemistichs). Thus a line that is metrical in one tradition may be unmetrical in another.\n\nThe term \"alexandrine\" may be used with greater or lesser rigor. Peureux suggests that only French syllabic verse with a 6+6 structure is, strictly speaking, an alexandrine. Preminger \"et al\". allow a broader scope: \"Strictly speaking, the term 'alexandrine' is appropriate to French syllabic meters, and it may be applied to other metrical systems only where they too espouse syllabism as their principle, introduce phrasal accentuation, or rigorously observe the medial caesura, as in French.\" Common usage within the literatures of European languages is broader still, embracing lines syllabic, accentual-syllabic, and (inevitably) stationed ambivalently between the two; lines of 12, 13, or even 14 syllables; lines with obligatory, predominant, and optional caesurae.\n\nAlthough alexandrines occurred in French verse as early as the 12th century, they were slightly looser rhythmically, and vied with the \"décasyllabe\" and \"octosyllabe\" for cultural prominence and use in various genres. \"The alexandrine came into its own in the middle of the sixteenth century with the poets of the Pléiade and was firmly established in the seventeenth century.\" It became the preferred line for the prestigious genres of epic and tragedy. The structure of the classical French alexandrine is\n\nClassical alexandrines are always rhymed, often in couplets alternating masculine rhymes and feminine rhymes, though other configurations (such as quatrains and sonnets) are also common.\n\nVictor Hugo began the process of loosening the strict two-hemistich structure. While retaining the medial caesura, he often reduced it to a mere word-break, creating a three-part line (\"alexandrin ternaire\") with this structure:\n\nThe Symbolists further weakened the classical structure, sometimes eliminating any or all of these caesurae. However, at no point did the newer line \"replace\" the older; rather, they were used concurrently, often in the same poem. This loosening process eventually led to \"vers libéré\" and finally to \"vers libre\".\n\nIn English verse, \"alexandrine\" is typically used to mean \"iambic hexameter\":\n\nWhereas the French alexandrine is syllabic, the English is accentual-syllabic; and the central caesura (a defining feature of the French) is not always rigidly preserved in English.\n\nThough English alexandrines have occasionally provided the sole metrical line for a poem, for example in lyric poems by Henry Howard, Earl of Surrey and Sir Philip Sidney, and in two notable long poems, Michael Drayton's \"Poly-Olbion\" and Robert Browning's \"Fifine at the Fair\", they have more often featured alongside other lines. During the Middle Ages they typically occurred with heptameters (seven-beat lines), both exhibiting metrical looseness. Around the mid-16th century stricter alexandrines were popular as the first line of poulter's measure couplets, fourteeners (strict iambic heptameters) providing the second line.\n\nThe strict English alexandrine may be exemplified by a passage from \"Poly-Olbion\", which features a rare caesural enjambment (symbolized codice_1) in the first line:\n\n<poem style=\"margin-left:2em\">\nYe sacred Bards, that to ¦ your harps' melodious strings\nSung th'ancient Heroes' deeds (the monuments of Kings)\nAnd in your dreadful verse ingrav'd the prophecies,\nThe agèd world's descents, and geneaologies; (lines 31-34)\n</poem>\n\nThe Faerie Queene by Edmund Spenser, with its stanzas of eight iambic pentameter lines followed by one alexandrine, exemplifies what came to be its chief role: as a somewhat infrequent variant line in an otherwise iambic pentameter context. Alexandrines provide occasional variation in the blank verse of William Shakespeare and his contemporaries (but rarely; they constitute only about 1% of Shakespeare's blank verse). John Dryden and his contemporaries and followers likewise occasionally employed them as the second (rarely the first) line of heroic couplets, or even more distinctively as the third line of a triplet.\n\nThe Spanish \"alejandrino\" is a line of 7+7 syllables, probably developed in imitation of the French alexandrine.\n\nIt was used beginning about 1200 for \"mester de clerecía\" (clerical verse), typically occurring in the \"cuaderna vía\", a stanza of four \"alejandrinos\" all with a single end-rhyme.\n\nThe \"alejandrino\" was most prominent during the 13th and 14th centuries, after which time it was eclipsed by the metrically more flexible \"arte mayor\". Juan Ruiz's Book of Good Love is one of the best-known examples of \"cuaderna vía\", though other verse forms also appear in the work.\n\nThe mid-16th-century poet Jan van der Noot pioneered syllabic Dutch alexandrines on the French model, but within a few decades Dutch alexandrines had been transformed into strict iambic hexameters with a caesura after the third foot. From Holland the accentual-syllabic alexandrine spread to other continental literatures.\n\nSimilarly, in early 17th-century Germany, Georg Rudolf Weckherlin advocated for an alexandrine with free rhythms, reflecting French practice; whereas Martin Opitz advocated for a strict accentual-syllabic iambic alexandrine in imitation of contemporary Dutch practice — and German poets followed Opitz. The alexandrine (strictly iambic with a consistent medial caesura) became the dominant long line of the German baroque.\n\nUnlike many similar lines, the Polish alexandrine developed not from French verse but from Latin, specifically, the 13-syllable goliardic line:\n\nThough looser instances of this (nominally) 13-syllable line were occasionally used in Polish literature, it was Mikołaj Rej and Jan Kochanowski who, in the 16th century, introduced the syllabically strict line as a vehicle for major works.\n\nThe Czech alexandrine is a comparatively recent development, based on the French alexandrine and introduced by Karel Hynek Mácha in the 19th century. Its structure forms a halfway point between features usual in syllabic and in accentual-syllabic verse, being more highly constrained than most syllabic verse, and less so than most accentual-syllabic verse. Moreover, it equally encourages the very different rhythms of iambic hexameter and dactyllic tetrameter to emerge by preserving the constants of both measures:\n\nIn the comic book \"Asterix and Cleopatra\", the author Goscinny inserted a pun about alexandrines: when the Druid Panoramix (\"Getafix\" in the English translation) meets his Alexandrian (Egyptian) friend the latter exclaims \"Je suis, mon cher ami, || très heureux de te voir\" at which Panoramix observes \"C'est un Alexandrin\" (\"That's an alexandrine!\"/\"He's an Alexandrian!\"). The pun can also be heard in the theatrical adaptations. The English translation renders this as \"My dear old Getafix || How good to see you here\", with the reply \"Aha, an Alexandrine\".\n\n", "id": "2427", "title": "Alexandrine"}
{"url": "https://en.wikipedia.org/wiki?curid=2428", "text": "Analog computer\n\nAn analog computer is a form of computer that uses the continuously changeable aspects of physical phenomena such as electrical, mechanical, or hydraulic quantities to model the problem being solved. In contrast, digital computers represent varying quantities symbolically, as their numerical values change. As an analog computer does not use discrete values, but rather continuous values, processes cannot be reliably repeated with exact equivalence, as they can with Turing machines. Unlike digital signal processing, analog computers do not suffer from the quantization noise, but are limited by analog noise.\n\nAnalog computers were widely used in scientific and industrial applications where digital computers of the time lacked sufficient performance. Analog computers can have a very wide range of complexity. Slide rules and nomographs are the simplest, while naval gunfire control computers and large hybrid digital/analog computers were among the most complicated. Systems for process control and protective relays used analog computation to perform control and protective functions.\n\nThe advent of digital computing made simple analog computers obsolete as early as the 1950s and 1960s, although analog computers remained in use in some specific applications, like the flight computer in aircraft, and for teaching control systems in universities. More complex applications, such as synthetic aperture radar, remained the domain of analog computing well into the 1980s, since digital computers were insufficient for the task.\n\nSetting up an analog computer required scale factors to be chosen, along with initial conditions—that is, starting values. Another essential was creating the required network of interconnections between computing elements. Sometimes it was necessary to re-think the structure of the problem so that the computer would function satisfactorily. No variables could be allowed to exceed the computer's limits, and differentiation was to be avoided, typically by rearranging the \"network\" of interconnects, using integrators in a different sense.\n\nRunning an electronic analog computer, assuming a satisfactory setup, started with the computer held with some variables fixed at their initial values. Moving a switch released the holds and permitted the problem to run. In some instances, the computer could, after a certain running time interval, repeatedly return to the initial-conditions state to reset the problem, and run it again.\n\nThis is a list of examples of early computation devices which are considered to be precursors of the modern computers. Some of them may even have been dubbed as 'computers' by the press, although they may fail to fit the modern definitions.\n\nThe south-pointing chariot, invented in ancient China during the first millennium BC, can be considered the earliest analog computer. It was a mechanical-geared wheeled vehicle used for to discern the southern cardinal direction.\nThe Antikythera mechanism was an orrery and is claimed to be an early mechanical analog computer, according to Derek J. de Solla Price. It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to \"circa\" 100 BC. Devices of a level of complexity comparable to that of the Antikythera mechanism would not reappear until a thousand years later.\n\nMany mechanical aids to calculation and measurement were constructed for astronomical and navigation use.\nThe planisphere was a star chart invented by Abū Rayḥān al-Bīrūnī in the early 11th century. The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235. Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, \"circa\" 1000 AD. The castle clock, a hydropowered mechanical astronomical clock invented by Al-Jazari in 1206, was the first programmable analog computer.\n\nThe sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.\n\nThe planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.\nThe slide rule was invented around 1620–1630, shortly after the publication of the concept of the logarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Aviation is one of the few fields where slide rules are still in widespread use, particularly for solving time–distance problems in light aircraft.\n\nThe tide-predicting machine invented by Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.\n\nThe differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876 Lord Kelvin had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.\n\nThe Dumaresq was a mechanical calculating device invented around 1902 by Lieutenant John Dumaresq of the Royal Navy. It was an analog computer which related vital variables of the fire control problem to the movement of one's own ship and that of a target ship. It was often used with other devices, such as a Vickers range clock to generate range and deflection data so the gun sights of the ship could be continuously set. A number of versions of the Dumaresq were produced of increasing complexity as development proceeded.\n\nBy 1912 Arthur Pollen had developed an electrically driven mechanical analog computer for fire-control systems, based on the differential analyser. It was used by the Imperial Russian Navy in World War I.\n\nStarting in 1929, AC network analyzers were constructed to solve calculation problems related to electrical power systems that were too large to solve with numerical methods at the time. These were essentially scale models of the electrical properties of the full-size system. Since network analyzers could handle problems too large for analytic methods or hand computation, they were also used to solve problems in nuclear physics and in the design of structures. More than 50 large network analyzers were built by the end of the 1950s.\n\nWorld War II era gun directors, gun data computers, and bomb sights used mechanical analog computers. In 1941 Helmut Hölzer built a fully electronic general-purpose analog computer at Peenemünde Army Research Center. Mechanical analog computers were very important in gun fire control in World War II, The Korean War and well past the Vietnam War; they were made in significant numbers.\n\nThe FERMIAC was an analog computer invented by physicist Enrico Fermi in 1947 to aid in his studies of neutron transport. Project Cyclone was an analog computer developed by Reeves in 1950 for the analysis and design of dynamic systems. Project Typhoon was an analog computer developed by RCA in 1952. It consisted of over 4000 electron tubes and used 100 dials and 6000 plug-in connectors to program. The MONIAC Computer was a hydraulic model of a national economy first unveiled in 1949.\n\nComputer Engineering Associates was spun out of Caltech in 1950 to provide commercial services using the \"Direct Analogy Electric Analog Computer\" (\"the largest and most impressive general-purpose analyzer facility for the solution of field problems\") developed there by Gilbert D. McCann, Charles H. Wilts, and Bart Locanthi.\n\nEducational analog computers illustrated the principles of analog calculation. The Heathkit EC-1, a $199 educational analog computer, was made by the Heath Company, USA c. 1960. It was programmed using patch cords that connected nine operational amplifiers and other components. General Electric also marketed an \"educational\" analog computer kit of a simple design in the early 1960s consisting of a two transistor tone generator and three potentiometers wired such that the frequency of the oscillator was nulled when the potentiometer dials were positioned by hand to satisfy an equation. The relative resistance of the potentiometer was then equivalent to the formula of the equation being solved. Multiplication or division could be performed depending on which dials were considered inputs and which was the output. Accuracy and resolution was limited and a simple slide rule was more accurate; however, the unit did demonstrate the basic principle.\n\nIn industrial process control, thousands of analog loop controllers were used to automatically regulate temperature, flow, pressure, or other process conditions. The technology of these controllers ranged from purely mechanical integrators, through vacuum-tube and solid-state devices, to emulation of analog controllers by microprocessors.\n\nThe similarity between linear mechanical components, such as springs and dashpots (viscous-fluid dampers), and electrical components, such as capacitors, inductors, and resistors is striking in terms of mathematics. They can be modeled using equations of the same form.\n\nHowever, the difference between these systems is what makes analog computing useful. If one considers a simple mass–spring system, constructing the physical system would require making or modifying the springs and masses. This would be followed by attaching them to each other and an appropriate anchor, collecting test equipment with the appropriate input range, and finally, taking measurements. In more complicated cases, such as suspensions for racing cars, experimental construction, modification, and testing is both complicated and expensive.\n\nThe electrical equivalent can be constructed with a few operational amplifiers (op amps) and some passive linear components; all measurements can be taken directly with an oscilloscope. In the circuit, the (simulated) 'stiffness of the spring', for instance, can be changed by adjusting the parameters of a capacitor. The electrical system is an analogy to the physical system, hence the name, but it is less expensive to construct, generally safer, and typically much easier to modify.\n\nAs well, an electronic circuit can typically operate at higher frequencies than the system being simulated. This allows the simulation to run faster than real time (which could, in some instances, be hours, weeks, or longer). Experienced users of electronic analog computers said that they offered a comparatively intimate control and understanding of the problem, relative to digital simulations.\n\nThe drawback of the mechanical-electrical analogy is that electronics are limited by the range over which the variables may vary. This is called dynamic range. They are also limited by noise levels. Floating-point digital calculations have a comparatively huge dynamic range.\n\nThese electric circuits can also easily perform a wide variety of simulations. For example, voltage can simulate water pressure and electric current can simulate rate of flow in terms of cubic metres per second. An integrator can provide the total accumulated volume of liquid, using an input current proportional to the (possibly varying) flow rate.\n\nAnalog computers are especially well-suited to representing situations described by differential equations. Occasionally, they were used when a differential equation proved very difficult to solve by traditional means.\n\nThe accuracy of an analog computer is limited by its computing elements as well as quality of the internal power and electrical interconnections. The precision of the analog computer readout was limited chiefly by the precision of the readout equipment used, generally three or four significant figures. The precision of a digital computer is limited by the word size; arbitrary-precision arithmetic, while relatively slow, provides any practical degree of precision that might be needed.\n\nMany small computers dedicated to specific computations are still part of industrial regulation equipment, but from the 1950s to the 1970s, general-purpose analog computers were the only systems fast enough for real time simulation of dynamic systems, especially in the aircraft, military and aerospace field.\n\nIn the 1960s, the major manufacturer was Electronic Associates of Princeton, New Jersey, with its 231R Analog Computer (vacuum tubes, 20 integrators) and subsequently its 8800 Analog Computer (solid state operational amplifiers, 64 integrators). Its challenger was Applied Dynamics of Ann Arbor, Michigan.\n\nAlthough the basic technology for analog computers is usually operational amplifiers (also called \"continuous current amplifiers\" because they have no low frequency limitation), in the 1960s an attempt was made in the French ANALAC computer to use an alternative technology: medium frequency carrier and non dissipative reversible circuits.\n\nIn the 1970s every big company and administration concerned with problems in dynamics had a big analog computing center, for example:\n\nAnalog computing devices are fast, digital computing devices are more versatile and accurate, so the idea is to combine the two processes for the best efficiency. An example of such hybrid elementary device is the hybrid multiplier where one input is an analog signal, the other input is a digital signal and the output is analog. It acts as an analog potentiometer upgradable digitally. This kind of hybrid technique is mainly used for fast dedicated real time computation when computing time is very critical as signal processing for radars and generally for controllers in embedded systems.\n\nIn the early 1970s analog computer manufacturers tried to tie together their analog computer with a digital computer to get the advantages of the two techniques. In such systems, the digital computer controlled the analog computer, providing initial set-up, initiating multiple analog runs, and automatically feeding and collecting data. The digital computer may also participate to the calculation itself using analog-to-digital and digital-to-analog converters.\n\nThe largest manufacturer of hybrid computers was Electronics Associates. Their hybrid computer model 8900 was made of a digital computer and one or more analog consoles. These systems were mainly dedicated to large projects such as the Apollo program and Space Shuttle at NASA, or Ariane in Europe, especially during the integration step where at the beginning everything is simulated, and progressively real components replace their simulated part. \n\nOnly one company was known as offering general commercial computing services on its hybrid computers, CISI of France, in the 1970s.\n\nThe best reference in this field is the 100 000 simulations runs for each certification of the automatic landing systems of Airbus and Concorde aircraft. \n\nAfter 1980, purely digital computers progressed more and more rapidly and were fast enough to compete with analog computers.\nOne key to the speed of analog computers was their fully parallel computation, but this was also a limitation. The more equations required for a problem, the more analog components were needed, even when the problem wasn't time critical. \"Programming\" a problem meant interconnecting the analog operators; even with a removable wiring panel this was not very versatile. Today there are no more big hybrid computers, but only hybrid components.\n\nWhile a wide variety of mechanisms have been developed throughout history, some stand out because of their theoretical importance, or because they were manufactured in significant quantities.\n\nMost practical mechanical analog computers of any significant complexity used rotating shafts to carry variables from one mechanism to another. Cables and pulleys were used in a Fourier synthesizer, a tide-predicting machine, which summed the individual harmonic components. Another category, not nearly as well known, used rotating shafts only for input and output, with precision racks and pinions. The racks were connected to linkages that performed the computation. At least one US Naval sonar fire control computer of the later 1950s, made by Librascope, was of this type, as was the principal computer in the Mk. 56 Gun Fire Control System.\n\nOnline, there is a remarkably clear illustrated reference (OP 1140) that describes the fire control computer mechanisms.\nFor adding and subtracting, precision miter-gear differentials were in common use in some computers; the Ford Instrument Mark I Fire Control Computer contained about 160 of them.\n\nIntegration with respect to another variable was done by a rotating disc driven by one variable. Output came from a pickoff device (such as a wheel) positioned at a radius on the disc proportional to the second variable. (A carrier with a pair of steel balls supported by small rollers worked especially well. A roller, its axis parallel to the disc's surface, provided the output. It was held against the pair of balls by a spring.)\n\nArbitrary functions of one variable were provided by cams, with gearing to convert follower movement to shaft rotation.\n\nFunctions of two variables were provided by three-dimensional cams. In one good design, one of the variables rotated the cam. A hemispherical follower moved its carrier on a pivot axis parallel to that of the cam's rotating axis. Pivoting motion was the output. The second variable moved the follower along the axis of the cam. One practical application was ballistics in gunnery.\n\nCoordinate conversion from polar to rectangular was done by a mechanical resolver (called a \"component solver\" in US Navy fire control computers). Two discs on a common axis positioned a sliding block with pin (stubby shaft) on it. One disc was a face cam, and a follower on the block in the face cam's groove set the radius. The other disc, closer to the pin, contained a straight slot in which the block moved. The input angle rotated the latter disc (the face cam disc, for an unchanging radius, rotated with the other (angle) disc; a differential and a few gears did this correction).\n\nReferring to the mechanism's frame, the location of the pin corresponded to the tip of the vector represented by the angle and magnitude inputs. Mounted on that pin was a square block.\n\nRectilinear-coordinate outputs (both sine and cosine, typically) came from two slotted plates, each slot fitting on the block just mentioned. The plates moved in straight lines, the movement of one plate at right angles to that of the other. The slots were at right angles to the direction of movement. Each plate, by itself, was like a Scotch yoke, known to steam engine enthusiasts.\n\nDuring World War II, a similar mechanism converted rectilinear to polar coordinates, but it was not particularly successful and was eliminated in a significant redesign (USN, Mk. 1 to Mk. 1A).\n\nMultiplication was done by mechanisms based on the geometry of similar right triangles. Using the trigonometric terms for a right triangle, specifically opposite, adjacent, and hypotenuse, the adjacent side was fixed by construction. One variable changed the magnitude of the opposite side. In many cases, this variable changed sign; the hypotenuse could coincide with the adjacent side (a zero input), or move beyond the adjacent side, representing a sign change.\n\nTypically, a pinion-operated rack moving parallel to the (trig.-defined) opposite side would position a slide with a slot coincident with the hypotenuse. A pivot on the rack let the slide's angle change freely. At the other end of the slide (the angle, in trig, terms), a block on a pin fixed to the frame defined the vertex between the hypotenuse and the adjacent side.\n\nAt any distance along the adjacent side, a line perpendicular to it intersects the hypotenuse at a particular point. The distance between that point and the adjacent side is some fraction that is the product of \"1\" the distance from the vertex, and \"2\" the magnitude of the opposite side.\n\nThe second input variable in this type of multiplier positions a slotted plate perpendicular to the adjacent side. That slot contains a block, and that block's position in its slot is determined by another block right next to it. The latter slides along the hypotenuse, so the two blocks are positioned at a distance from the (trig.) adjacent side by an amount proportional to the product.\n\nTo provide the product as an output, a third element, another slotted plate, also moves parallel to the (trig.) opposite side of the theoretical triangle. As usual, the slot is perpendicular to the direction of movement. A block in its slot, pivoted to the hypotenuse block positions it.\n\nA special type of integrator, used at a point where only moderate accuracy was needed, was based on a steel ball, instead of a disc. It had two inputs, one to rotate the ball, and the other to define the angle of the ball's rotating axis. That axis was always in a plane that contained the axes of two movement-pickoff rollers, quite similar to the mechanism of a rolling-ball computer mouse (in this mechanism, the pickoff rollers were roughly the same diameter as the ball). The pickoff roller axes were at right angles.\n\nA pair of rollers \"above\" and \"below\" the pickoff plane were mounted in rotating holders that were geared together. That gearing was driven by the angle input, and established the rotating axis of the ball. The other input rotated the \"bottom\" roller to make the ball rotate.\n\nEssentially, the whole mechanism, called a component integrator, was a variable-speed drive with one motion input and two outputs, as well as an angle input. The angle input varied the ratio (and direction) of coupling between the \"motion\" input and the outputs according to the sine and cosine of the input angle.\n\nAlthough they did not accomplish any computation, electromechanical position servos were essential in mechanical analog computers of the \"rotating-shaft\" type for providing operating torque to the inputs of subsequent computing mechanisms, as well as driving output data-transmission devices such as large torque-transmitter synchros in naval computers.\n\nOther non-computational mechanisms included internal odometer-style counters with interpolating drum dials for indicating internal variables, and mechanical multi-turn limit stops.\n\nConsidering that accurately controlled rotational speed in analog fire-control computers was a basic element of their accuracy, there was a motor with its average speed controlled by a balance wheel, hairspring, jeweled-bearing differential, a twin-lobe cam, and spring-loaded contacts (ship's AC power frequency was not necessarily accurate, nor dependable enough, when these computers were designed).\n\nElectronic analog computers typically have front panels with numerous jacks (single-contact sockets) that permit patch cords (flexible wires with plugs at both ends) to create the interconnections which define the problem setup. In addition, there are precision high-resolution potentiometers (variable resistors) for setting up (and, when needed, varying) scale factors. In addition, there is likely to be a zero-center analog pointer-type meter for modest-accuracy voltage measurement. Stable, accurate voltage sources provide known magnitudes.\n\nTypical electronic analog computers contain anywhere from a few to a hundred or more operational amplifiers (\"op amps\"), named because they perform mathematical operations. Op amps are a particular type of feedback amplifier with very high gain and stable input (low and stable offset). They are always used with precision feedback components that, in operation, all but cancel out the currents arriving from input components. The majority of op amps in a representative setup are summing amplifiers, which add and subtract analog voltages, providing the result at their output jacks. As well, op amps with capacitor feedback are usually included in a setup; they integrate the sum of their inputs with respect to time.\n\nIntegrating with respect to another variable is the nearly exclusive province of mechanical analog integrators; it is almost never done in electronic analog computers. However, given that a problem solution does not change with time, time can serve as one of the variables.\n\nOther computing elements include analog multipliers, nonlinear function generators, and analog comparators.\n\nElectrical elements such as inductors and capacitors used in electrical analog computers had to be carefully manufactured to reduce non-ideal effects. For example, in the construction of AC power network analyzers, one motive for using higher frequencies for the calculator (instead of the actual power frequency) was that higher-quality inductors could be more easily made. Many general-purpose analog computers avoided the use of inductors entirely, re-casting the problem in a form that could be solved using only resistive and capacitive elements, since high-quality capacitors are relatively easy to make.\n\nThe use of electrical properties in analog computers means that calculations are normally performed in real time (or faster), at a speed determined mostly by the frequency response of the operational amplifiers and other computing elements. In the history of electronic analog computers, there were some special high-speed types.\n\nNonlinear functions and calculations can be constructed to a limited precision (three or four digits) by designing function generators — special circuits of various combinations of resistors and diodes to provide the nonlinearity. Typically, as the input voltage increases, progressively more diodes conduct.\n\nWhen compensated for temperature, the forward voltage drop of a transistor's base-emitter junction can provide a usably accurate logarithmic or exponential function. Op amps scale the output voltage so that it is usable with the rest of the computer.\n\nAny physical process which models some computation can be interpreted as an analog computer. Some examples, invented for the purpose of illustrating the concept of analog computation, include using a bundle of spaghetti as a model of sorting numbers; a board, a set of nails, and a rubber band as a model of finding the convex hull of a set of points; and strings tied together as a model of finding the shortest path in a network. These are all described in Dewdney (1984).\n\nAnalog computers often have a complicated framework, but they have, at their core, a set of key components which perform the calculations, which the operator manipulates through the computer's framework.\n\nKey hydraulic components might include pipes, valves and containers.\n\nKey mechanical components might include rotating shafts for carrying data within the computer, miter gear differentials, disc/ball/roller integrators, cams (2-D and 3-D), mechanical resolvers and multipliers, and torque servos.\n\nKey electrical/electronic components might include:\n\nThe core mathematical operations used in an electric analog computer are:\n\nIn some analog computer designs, multiplication is much preferred to division. Division is carried out with a multiplier in the feedback path of an Operational Amplifier.\n\nDifferentiation with respect to time is not frequently used, and in practice is avoided by redefining the problem when possible. It corresponds in the frequency domain to a high-pass filter, which means that high-frequency noise is amplified; differentiation also risks instability.\n\nIn general, analog computers are limited by non-ideal effects. An analog signal is composed of four basic components: DC and AC magnitudes, frequency, and phase. The real limits of range on these characteristics limit analog computers. Some of these limits include the operational amplifier offset, finite gain, and frequency response, noise floor, non-linearities, temperature coefficient, and parasitic effects within semiconductor devices. For commercially available electronic components, ranges of these aspects of input and output signals are always figures of merit.\n\nIn 1950s to 1970s, digital computers based on first vacuum tubes, transistors, integrated circuits and then micro-processors became more economical and precise. This led digital computers to largely replace analog computers. Even so, some research in analog computation is still being done. A few universities still use analog computers to teach control system theory. The American company Comdyna manufactures small analog computers. At Indiana University Bloomington, Jonathan Mills has developed the Extended Analog Computer based on sampling voltages in a foam sheet. At the Harvard Robotics Laboratory, analog computation is a research topic. Lyric Semiconductor's error correction circuits use analog probabilistic signals. Slide rules are still popular among aircraft personnel. \n\nWith the development of very-large-scale integration (VLSI) technology, Yannis Tsividis' group at Columbia University has been revisiting analog/hybrid computers design in standard CMOS process. Two VLSI chips have been developed, an 80th-order analog computer (250 nm) by Glenn Cowan in 2005 and an 4th-order hybrid computer (65 nm) developed by Ning Guo in 2015, both targeting at energy-efficient ODE/PDEs applications. Glenn's chip contains 16 macros, in which there are 25 analog computing blocks, namely integrators, multipliers, fanouts, few nonlinear blocks. Ning's chip contains one macro block, in which there are 26 computing blocks including integrators, multipliers, fanouts, ADCs, SRAMs and DACs. Arbitrary nonlinear function generation is made possible by the ADC+SRAM+DAC chain, where the SRAM block stores the nonlinear function data. The experiments from the related publications revealed that VLSI analog/hybrid computers demonstrated about 1~2 orders magnitude of advantage in both solution time and energy while achieving accuracy within 5%, which points to the promise of using analog/hybrid computing techniques in the area of energy-efficient approximate computing.\n\nThese are examples of analog computers that have been constructed or practically used:\n\nAnalog (audio) synthesizers can also be viewed as a form of analog computer, and their technology was originally based in part on electronic analog computer technology. The ARP 2600's Ring Modulator was actually a moderate-accuracy analog multiplier.\n\nThe Simulation Council (or Simulations Council) was an association of analog computer users in USA. It is now known as The Society for Modeling and Simulation International. The Simulation Council newsletters from 1952 to 1963 are available online and show the concerns and technologies at the time, and the common use of analog computers for missilry.\n\nComputer theorists often refer to idealized analog computers as real computers (because they operate on the set of real numbers). Digital computers, by contrast, must first quantize the signal into a finite number of values, and so can only work with the rational number set (or, with an approximation of irrational numbers).\n\nThese idealized analog computers may \"in theory\" solve problems that are intractable on digital computers; however as mentioned, in reality, analog computers are far from attaining this ideal, largely because of noise minimization problems. \"In theory\", ambient noise is limited by quantum noise (caused by the quantum movements of ions). Ambient noise may be severely reduced – but never to zero – by using cryogenically cooled parametric amplifiers. Moreover, given unlimited time and memory, the (ideal) digital computer may also solve real number problems.\n\n\n\n", "id": "2428", "title": "Analog computer"}
{"url": "https://en.wikipedia.org/wiki?curid=2429", "text": "Audio\n\nAudio may refer to:\n\n\n\n\n", "id": "2429", "title": "Audio"}
{"url": "https://en.wikipedia.org/wiki?curid=2431", "text": "Minute and second of arc\n\nA minute of arc, arcminute (arcmin), arc minute, or minute arc is a unit of angular measurement equal to of one degree. Since one degree is of a turn (or complete rotation), one minute of arc is of a turn (or, in radians, ). A second of arc, arcsecond (arcsec), or arc second is of an arcminute, of a degree, of a turn, and (about ) of a radian. These units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying and marksmanship.\n\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (μas), for instance, are commonly used in astronomy.\n\nThe number of square arcminutes in a complete sphere is formula_1 square arcminutes.\n\nThe standard symbol for marking the arcminute is the prime (′) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1′. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (formula_2).\n\nThe standard symbol for the arcsecond is the double prime (″) (U+2033), though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1″. It is also abbreviated as arcsec or asec.\n\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42° 25.32′ or 42° 25.322′. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\n\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18 mm) at a distance of .\n\nAn arcsecond is also the angle subtended by\n\nA milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.\n\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\n\nSince antiquity the arcminute and arcsecond have been used in astronomy. In the ecliptic coordinate system, latitude (β) and longitude (λ); in the horizon system, altitude (Alt) and azimuth (Az); and in the equatorial coordinate system, declination (δ), are all measured in degrees, arcminutes and arcseconds. The principal exception is Right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\n\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10\" and 60\"), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the parallax of one arcsecond, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit would subtend an angle of one arcsecond.\n\nThe ESA astrometric space probe Gaia is hoped to measure star positions to 20 microarcseconds (µas) when it begins producing catalog positions sometime after 2016. There are about 1.3 trillion µas in a turn. Currently the best catalog positions of stars actually measured are in terms of milliarcseconds, by the U.S. Naval Observatory.\n\nApart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond.\n\nSpace telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble space telescope can reach an angular size of stars down to about 0.1″. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.\n\nMinutes (') and seconds (\") of arc are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals exactly one geographical mile along the Earth's equator or approximately one nautical mile (1852 meters, or ≈1.15078 statute miles). A second of arc, one sixtieth of this amount, is roughly 30 meters or 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\n\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, because of the somewhat clumsy base-60 nature of minutes and seconds, positions are frequently expressed in fractional degrees only, expressed in decimal form to an equal amount of precision. Degrees given to three decimal places ( of a degree) have about the precision of degrees-minutes-seconds ( of a degree) and specify locations within about 120 meters or 400 feet.\n\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, \"North 65° 39′ 18″ West 85.69 feet\" would describe a line running from the starting point 85.69 feet in a direction 65° 39′ 18″ (or 65.655°) away from north toward the west.\n\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA subtends 1.047 inches at 100 yards (approximately 3 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, 500 yards = 5.235 inches, and 1000 yards = 10.47 inches. Since lots of modern telescopic sights are adjustable in half (), quarter (), or eighth () MOA increments, also known as \"clicks\", zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\n\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that \"click\" in fractions of MOA. This makes zeroing and adjustments much easier:\n\n\nAnother common system of measurement in firearm scopes is the milliradian. Zeroing a mil based scope is easy for users familiar with base ten systems. The most common adjustment value in mil based scopes is mil (which approximates MOA).\n\n\nOne thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047\". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\n\nThe physical group size equivalent to \"m\" minutes of arc can be calculated as follows: group size = tan() × distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan() ≈ 1.047 inches. In metric units 1 MOA at 100 meters ≈ 2.908 centimeters.\n\nSometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a \"1 MOA rifle\" should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.\n\nRifle manufacturers and gun magazines often refer to this capability as \"sub-MOA\", meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.\n\nThe Metric System counterpart of the MOA is the milliradian or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 × × 1000, regardless the target range. Therefore, 1 MOA ≈ 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 Milrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system. A reticle with markings (hashes or dots) spaced with a one mil apart (or a fraction of a mil) are collectively called a mil reticle. If the markings are round they are called mil-dots.\n\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\n\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (ω-scan) x ray diffraction measurements of high-quality epitaxial thin films.\n\n\n", "id": "2431", "title": "Minute and second of arc"}
{"url": "https://en.wikipedia.org/wiki?curid=2433", "text": "Alberto Giacometti\n\nAlberto Giacometti (; 10 October 1901 – 11 January 1966) was a Swiss sculptor, painter, draughtsman and printmaker.\nHe was born in the canton Graubünden's southerly alpine valley Val Bregaglia, as the eldest of four children to Giovanni Giacometti, a well-known post-Impressionist painter. Coming from an artistic background, he was interested in art from an early age.\n\nGiacometti was born in Borgonovo, now part of the Switzerland municipality of Bregaglia, near the Italian border. He was a descendant of Protestant refugees escaping the inquisition. Alberto attended the Geneva School of Fine Arts. His brothers Diego (1902–85) and Bruno (1907–2012) would go on to become artists as well. Additionally, Zaccaria Giacometti, later professor of constitutional law and chancellor of the University of Zurich grew up together with them, having been orphaned at the age of 12 in 1905.\n\nIn 1922 he moved to Paris to study under the sculptor Antoine Bourdelle, an associate of Rodin. It was there that Giacometti experimented with cubism and surrealism and came to be regarded as one of the leading surrealist sculptors. Among his associates were Miró, Max Ernst, Picasso, Bror Hjorth and Balthus.\n\nBetween 1936 and 1940, Giacometti concentrated his sculpting on the human head, focusing on the sitter's gaze. He preferred models he was close to, his sister and the artist Isabel Rawsthorne (then known as Isabel Delmer). This was followed by a phase in which his statues of Isabel became stretched out; her limbs elongated. Obsessed with creating his sculptures exactly as he envisioned through his unique view of reality, he often carved until they were as thin as nails and reduced to the size of a pack of cigarettes, much to his consternation. A friend of his once said that if Giacometti decided to sculpt you, \"he would make your head look like the blade of a knife\". After his marriage to Annette Arm in 1946 his tiny sculptures became larger, but the larger they grew, the thinner they became. Giacometti said that the final result represented the sensation he felt when he looked at a woman.\n\nHis paintings underwent a parallel procedure. The figures appear isolated and severely attenuated, as the result of continuous reworking. Subjects were frequently revisited: one of his favorite models was his younger brother Diego Giacometti. A third brother, Bruno Giacometti, was a noted architect.\n\nIn 1958 Giacometti was asked to create a monumental sculpture for the Chase Manhattan Bank building in New York, which was beginning construction. Although he had for many years \"harbored an ambition to create work for a public square\", he \"had never set foot in New York, and knew nothing about life in a rapidly evolving metropolis. Nor had he ever laid eyes on an actual skyscraper\", according to his biographer James Lord. Giacometti's work on the project resulted in the four figures of standing women—his largest sculptures—entitled \"Grande femme debout\" I through IV (1960). The commission was never completed, however, because Giacometti was unsatisfied by the relationship between the sculpture and the site, and abandoned the project.\n\nIn 1962, Giacometti was awarded the grand prize for sculpture at the Venice Biennale, and the award brought with it worldwide fame. Even when he had achieved popularity and his work was in demand, he still reworked models, often destroying them or setting them aside to be returned to years later. The prints produced by Giacometti are often overlooked but the catalogue raisonné, \"Giacometti – The Complete Graphics and 15 Drawings by Herbert Lust\" (Tudor 1970), comments on their impact and gives details of the number of copies of each print. Some of his most important images were in editions of only 30 and many were described as rare in 1970.\n\nIn his later years Giacometti's works were shown in a number of large exhibitions throughout Europe. Riding a wave of international popularity, and despite his declining health, he travelled to the United States in 1965 for an exhibition of his works at the Museum of Modern Art in New York. As his last work he prepared the text for the book \"Paris sans fin\", a sequence of 150 lithographs containing memories of all the places where he had lived.\n\nGiacometti died in 1966 of heart disease (pericarditis) and chronic bronchitis at the Kantonsspital in Chur, Switzerland. His body was returned to his birthplace in Borgonovo, where he was interred close to his parents. In May 2007 the executor of his widow's estate, former French foreign minister Roland Dumas, was convicted of illegally selling Giacometti's works to a top auctioneer, Jacques Tajan, who was also convicted. Both were ordered to pay €850,000 to the Alberto and Annette Giacometti Foundation.\n\nRegarding Giacometti's sculptural technique and according to the Metropolitan Museum of Art: \"The rough, eroded, heavily worked surfaces of Three Men Walking (II), 1949, typify his technique. Reduced, as they are, to their very core, these figures evoke lone trees in winter that have lost their foliage. Within this style, Giacometti would rarely deviate from the three themes that preoccupied him—the walking man; the standing, nude woman; and the bust—or all three, combined in various groupings\".\"\"\n\nIn a letter to Pierre Matisse, Giacometti wrote: \"Figures were never a compact mass but like a transparent construction\". In the letter, Giacometti writes about how he looked back at the realist, classical busts of his youth with nostalgia, and tells the story of the existential crisis which precipitated the style he became known for.\n\n\"[I rediscovered] the wish to make compositions with figures. For this I had to make (quickly I thought; in passing), one or two studies from nature, just enough to understand the construction of a head, of a whole figure, and in 1935 I took a model. This study should take, I thought, two weeks and then I could realize my compositions...I worked with the model all day from 1935 to 1940...Nothing was as I imagined. A head, became for me an object completely unknown and without dimensions.\"\n\nSince Giacometti achieved exquisite realism with facility when he was executing busts in his early adolescence, Giacometti's difficulty in re-approaching the figure as an adult is generally understood as a sign of existential struggle for meaning, rather than as a technical deficit.\n\nGiacometti was a key player in the Surrealist art movement, but his work resists easy categorization. Some describe it as formalist, others argue it is expressionist or otherwise having to do with what Deleuze calls \"blocs of sensation\" (as in Deleuze's analysis of Francis Bacon). Even after his excommunication from the Surrealist group, while the intention of his sculpting was usually imitation, the end products were an expression of his emotional response to the subject. He attempted to create renditions of his models the way he saw them, and the way he thought they ought to be seen. He once said that he was sculpting not the human figure but \"the shadow that is cast\".\n\nScholar William Barrett in \"Irrational Man: A Study in Existential Philosophy\" (1962), argues that the attenuated forms of Giacometti's figures reflect the view of 20th century modernism and existentialism that modern life is increasingly empty and devoid of meaning. \"All the sculptures of today, like those of the past, will end one day in pieces...So it is important to fashion ones work carefully in its smallest recess and charge every particle of matter with life.\"\n\nA new exhibition in Paris, since September 2011, shows how Giacometti strongly drew his inspiration for his work from Etruscan art.\n\nGiacometti's work has been the subject of numerous solo exhibitions including Pera Museum, Istanbul (2015) Pushkin Museum, Moscow (2008); “The Studio of Alberto Giacometti: Collection of the Fondation Alberto et Annette Giacometti”, Centre Pompidou, Paris (2007–2008); Kunsthal Rotterdam (2008); Fondation Beyeler, Basel (2009), Buenos Aires (2012); Kunsthalle Hamburg (2013), and the High Museum of Art, Atlanta (1970).\n\nThe National Portrait Gallery, London's first solo exhibition of Giacometti's work, \"Pure Presence\" opened to five star reviews on 13 October 2015 (to January 10, 2016, in honour of the fiftieth anniversary of the artist's death).\n\nGiacometti's work is displayed in numerous public collections, including:\n\nThe Fondation Alberto et Annette Giacometti, having received a bequest from Alberto Giacometti's widow Annette, holds a collection of circa 5,000 works, frequently displayed around the world through exhibitions and long-term loans. A public interest institution, the Foundation was created in 2003 and aims at promoting, disseminating, preserving and protecting Alberto Giacometti's work.\n\nThe Alberto Giacometti-Stiftung established in Zürich in 1965, holds a smaller collection of works acquired from the collection of the Pittsburgh industrialist G. David Thompson.\n\nIn November 2000 a Giacometti bronze, \"Grande Femme Debout I\", sold for $14.3 million. \"Grande Femme Debout II\" was bought by the Gagosian Gallery for $27.4 million at Christie's auction in New York City on May 6, 2008.\n\n\"L'Homme qui marche I\", a life-sized bronze sculpture of a man, became one of the most expensive works of art and the most expensive sculpture ever sold at auction on February 2, 2010, when it sold for £65 million (US$104.3 million) at Sotheby's, London. \"Grande tête mince\", a large bronze bust, sold for $53.3 million just three months later.\n\n\"L'Homme au doigt\" (\"Pointing Man\") sold for $126 million (£81314455.32), or $141.3 million with fees, in Christie's May 11, 2015 Looking Forward to the Past sale in New York, a record for a sculpture at auction. The work had been in the same private collection for 45 years.\n\nGiacometti created the monument on the grave of Gerda Taro at Père Lachaise Cemetery.\n\nIn 2001 he was included in the exhibition held at the National Portrait Gallery, London.\n\nGiacometti and his sculpture \"L'Homme qui marche I\" appear on the current 100 Swiss Franc banknote.\n\nAccording to a lecture by Michael Peppiatt at Cambridge University on July 8, 2010, Giacometti, who had a friendship with author/playwright Samuel Beckett, created a tree for the set of a 1961 Paris production of \"Waiting for Godot\".\n\n\n\n", "id": "2433", "title": "Alberto Giacometti"}
{"url": "https://en.wikipedia.org/wiki?curid=2439", "text": "Anthem\n\nAn anthem is a musical composition of celebration, usually used as a symbol for a distinct group, particularly the national anthems of countries. Originally, and in music theory and religious contexts, it also refers more particularly to short sacred choral work and still more particularly to a specific form of Anglican church music.\n\n\"Anthem\" is derived from the Greek (\"antíphōna\") via Old English . Both words originally referred to antiphons, a call-and-response style of singing. The adjectival form is \"anthemic\".\n\nAnthems were originally a form of liturgical music. In the Church of England, the rubric appoints them to follow the third collect at morning and evening prayer. Several anthems are included in the British coronation service. The words are selected from Holy Scripture or in some cases from the Liturgy and the music is generally more elaborate and varied than that of psalm or hymn tunes. Being written for a trained choir rather than the congregation, the Anglican anthem is analogous to the motet of the Roman Catholic and Lutheran Churches but represents an essentially English musical form. Anthems may be described as \"verse\", \"full\", or \"full with verse\", depending on whether they are intended for soloists, the full choir, or both.\n\nThe anthem developed as a replacement for the Catholic \"votive antiphon\" commonly sung as an appendix to the main office to the Blessed Virgin Mary or other saints. During the Elizabethan period, notable anthems were composed by Thomas Tallis, William Byrd, Tye, and Farrant but they were not mentioned in the Book of Common Prayer until 1662 when the famous rubric \"In quires and places where they sing here followeth the Anthem\" first appears. Early anthems tended to be simple and homophonic in texture, so that the words could be clearly heard. During the 17th century, notable anthems were composed by Orlando Gibbons, Henry Purcell, and John Blow, with the verse anthem becoming the dominant musical form of the Restoration. In the 18th century, famed anthems were composed by Croft, Boyce, James Kent, James Nares, Benjamin Cooke, and Samuel Arnold. In the 19th, Samuel Sebastian Wesley wrote anthems influenced by contemporary oratorio which stretch to several movements and last twenty minutes or longer. Later in the century, Charles Villiers Stanford used symphonic techniques to produce a more concise and unified structure. Many anthems have been composed since this time, generally by organists rather than professional composers and often in a conservative style. Major composers have usually composed anthems in response to commissions and for special occasions. Examples include Edward Elgar's 1912 \"Great is the Lord\" and 1914 \"Give unto the Lord\" (both with orchestral accompaniment), Benjamin Britten's 1943 \"Rejoice in the Lamb\" (a modern example of a multi-movement anthem, today heard mainly as a concert piece), and, on a much smaller scale, Ralph Vaughan Williams's 1952 \"O Taste and See\" written for the coronation of Queen Elizabeth II. With the relaxation of the rule, in England at least, that anthems should be only in English, the repertoire has been greatly enhanced by the addition of many works from the Latin repertoire.\n\nThe word \"anthem\" is now commonly used to describe any celebratory song or composition for a distinct group, as in national anthems. Many pop songs are used as sports anthems, notably including Queen's \"We Are the Champions\" and \"We Will Rock You\", and some sporting events have their own anthems, most notably including UEFA Champions League. Further, some songs are artistically styled as anthems, whether or not they are used as such, including Marilyn Manson's \"Irresponsible Hate Anthem\", Silverchair's \"Anthem for the Year 2000\", and Toto's \"Child's Anthem\".\n\n", "id": "2439", "title": "Anthem"}
{"url": "https://en.wikipedia.org/wiki?curid=2440", "text": "Albrecht Altdorfer\n\nAlbrecht Altdorfer (c. 1480 – February 12, 1538) was a German painter, engraver and architect of the Renaissance working in Regensburg. Along with Lucas Cranach the Elder and Wolf Huber he is regarded to be the main representative of the so-called Danube School setting biblical and historical subjects against landscape backgrounds of expressive colours. As an artist also making small intricate engravings he is seen to belong to the Nuremberg Little Masters.\n\nAltdorfer was born in Regensburg or Altdorf around 1480.\n\nHe acquired an interest in art from his father, Ulrich Altdorfer, who was a painter and miniaturist. At the start of his career, he won public attention by creating small, intimate modestly scaled works in unconventional media and with eccentric subject matter. He settled in the free imperial city of Regensburg, a town located on the Danube River in 1505, eventually becoming the town architect and a town councillor. His first signed works date to c. 1506, including engravings and drawings such the \"Stygmata of St. Francis\" and \"St. Jerome\". His models were niellos and copper engravings from the workshops of Jacopo de Barbari and Albrecht Dürer.\n\nAround 1511 or earlier, he travelled down the river and south into the Alps, where the scenery moved him so deeply that he became the first landscape painter in the modern sense, making him the leader of the Danube School, a circle that pioneered landscape as an independent genre, in southern Germany. From 1513 he was at the service of Maximilian I in Innsbruck, where he received several commissions from the imperial court. During the turmoil of the Protestant Reformation, he dedicated mostly to architecture; paintings of the period, showing his increasing attention to architecture, include the \"Nativity of the Virgin\".\n\nIn 1529 he executed \"The Battle of Alexander at Issus\" for Duke William IV of Bavaria. In the 1520s he returned to Regensburg as a wealthy man, and became a member of the city's council. He was also responsible for the fortifications of Regensburg.\n\nIn that period his works are influenced by artists such as Giorgione and Lucas Cranach, as shown by his \"Crucifixion\". In 1535 he was in Vienna. He died at Regensburg in 1538.\n\nThe remains of Altdorfer's surviving work comprises 55 panels, 120 drawings, 125 woodcuts, 78 engravings, 36 etchings, 24 paintings on parchment, and fragments from a mural for the bathhouse of the Kaiserhof in Regensburg. This production extends at least over the period 1504–1537. He signed and dated each one of his works.\n\nAltdorfer was the pioneer painter of pure landscape, making them the subject of the painting, as well as compositions dominated by their landscape; these comprise much of his oeuvre. He believed that the human figure should not disrupt nature, but rather participate in it or imitate its natural processes. Taking and developing the landscape style of Lucas Cranach the Elder, he shows the hilly landscape of the Danube valley with thick forests of drooping and crumbling firs and larches hung with moss, and often dramatic colouring from a rising or setting sun. His \"Landscape with Footbridge\" (National Gallery, London) of 1518–1520 is claimed to be the first pure landscape in oil. In this painting, Altdorfer places a large tree that is cut off by the margins at the center of the landscape, making it the central axis and focus within the piece. He uses anthropomorphism to give the tree human qualities such as the drapery of its limbs. He also made many fine finished drawings, mostly landscapes, in pen and watercolour such as the \"Landscape with the Woodcutter\" in 1522. The drawing opens at ground level on a clearing surrounding an enormous tree that is placed in the center, dominating the picture. It poses and gesticulates as if it was human, splaying its branches out in every corner. Halfway up the tree trunk, hangs a gabled shrine. At the time, a shrine like this might shelter an image of the Crucifixion or the Virgin Mary, but since it is turned away from the viewer, we are not sure what it truly is. At the bottom of the tree, a tiny figure of a seated man, crossed legged, holds a knife and axe, declaring his status in society/occupation.\n\nAlso, he often painted scenes of historical and biblical subjects, set in atmospheric landscapes. His best religious scenes are intense, with their glistening lights and glowing colours sometimes verging on the expressionistic. They often depict moments of intimacy between Christ and his mother, or various saints. His sacral masterpiece and one of the most famous religious works of art of the later Middle Ages is \"The Legend of St. Sebastian\" and \"The Passion of Christ\" of the so-called \"Sebastian Altar\" in \"St. Florian's Priory\" (\"Stift Sankt Florian\") near Linz, Upper Austria. When closed the altarpiece displayed the four panels of the legend of St. Sebastian’s Martyrdom, while the opened wings displayed the Stations of the Cross. Today the altarpiece is dismantled and the predellas depicting the two final scenes, \"Entombment\" and \"Resurrection\" were sold to Kunsthistorisches Museum in Vienna in 1923 and 1930. Both these paintings share a similar formal structure that consists of an open landscape that is seen beyond and through the opening of a dark grotto. The date of completion on the resurrection panel is 1518.\n\nAltdorfer often distorts perspective to subtle effect. His donor figures are often painted completely out of scale with the main scene, as in paintings of the previous centuries. He also painted some portraits; overall his painted oeuvre was not large. In his later works, Altdorfer moved more towards mannerism and began to depict the human form to the conformity of the Italian model, as well as dominate the picture with frank colors.\n\nHis rather atypical \"Battle of Issus\" (or of \"Alexander\") of 1529 was commissioned by William IV, Duke of Bavaria as part of a series of eight historical battle scenes destined to hang in the Residenz in Munich. Albrecht Altdorfer's depiction of the moment in 333 BCE when Alexander the Great routed Darius III for supremacy in Asia Minor is vast in ambition, sweeping in scope, vivid in imagery, rich in symbols, and obviously heroic—the Iliad of painting, as literary critic Friedrich Schlegel suggested In the painting, a swarming cast of thousands of soldiers surround the central action: Alexander on his white steed, leading two rows of charging cavalrymen, dashes after a fleeing Darius, who looks anxiously over his shoulder from a chariot. The opposing armies are distinguished by the colors of their uniforms: Darius' army in red and Alexander's in blue. The upper half of \"The Battle of Alexander\" expands with unreal rapidity into an arcing panorama comprehending vast coiling tracts of globe and sky. The victory also lies on the planar surface; The sun outshone the moon just as the Imperial and allied army successfully repel the Turks.\nBy making the mass number of soldiers blend within the landscape/painting, it shows that he believed that the usage and depiction of landscape was just as significant as a historical event, such as a war. He renounced the office of \"Mayor of Regensburg\" to accept the commission. Few of his other paintings resemble this apocalyptic scene of two huge armies dominated by an extravagant landscape seen from a very high viewpoint, which looks south over the whole Mediterranean from modern Turkey to include the island of Cyprus and the mouths of the Nile and the Red Sea (behind the isthmus to the left) on the other side. However his style here is a development of that of a number of miniatures of battle-scenes he had done much earlier for Maximilian I in his illuminated manuscript \"Triumphal Procession\" in 1512-14. It is thought to be the earliest painting to show the curvature of the Earth from a great height.\n\nThe \"Battle\" is now in the Alte Pinakothek, which has the best collection of Altdorfer's paintings, including also his small \"St. George and the Dragon\" (1510), in oil on parchment, where the two figures are tiny and almost submerged in the lush, dense forest that towers over them. Altdorfer seems to exaggerate the measurements of the forest in comparison to the figures: the leaves appear to be larger than the horse, showing the significance of nature and landscape. He also emphasizes line within the work, by displaying the upward growth of the forest with the vertical and diagonal lines of the trunks. There is a small opening of the forest on the lower right hand corner that provides a rest for your eyes. It serves to create depth within the painting and is the only place you can see the characters. The human form is completely absorbed by the thickness of the forest. Fantastic light effects provide a sense of mystery and dissolve the outline of objects. Without the contrast of light, the figures would blend in with its surrounding environment. Altdorfer's figures are invariably the complement of his romantic landscapes; for them he borrowed Albrecht Dürer's inventive iconography, but the panoramic setting is personal and has nothing to do with the fantasy landscapes of the Netherlands A \"\" (1526) set outside an Italianate skyscraper of a palace shows his interest in architecture. Another small oil on parchment, \"Danube Landscape with Castle Wörth\" (c. 1520) is one of the earliest accurate topographical paintings of a particular building in its setting, of a type that was to become a cliché in later centuries.\n\nAltdorfer was a significant printmaker, with numerous engravings and about ninety-three woodcuts. These included some for the \"Triumphs of Maximilian\", where he followed the overall style presumably set by Hans Burgkmair, although he was able to escape somewhat from this in his depictions of the more disorderly baggage-train, still coming through a mountain landscape. However most of his best prints are etchings, many of landscapes; in these he was able most easily to use his drawing style. He was one of the most successful early etchers, and was unusual for his generation of German printmakers in doing no book illustrations. He often combined etching and engraving techniques in a single plate, and produced about 122 intaglio prints altogether. Many of Altdorfer's prints are quite small in size, and he is considered to be of the main members of the group of artists known as the Little Masters. Arthur Mayger Hind considers his graphical work to be somewhat lacking in technical skill but with an \"intimate personal touch\", and notes his characteristic feeling for landscape.\n\nAs the superintendent of the municipal buildings Altdorfer had overseen the construction of several commercial structures, such as a slaughterhouse and a building for wine storage, possibly even designing them. He was considered to be an outstanding politician of his day. In 1517 he was a member of the \"Ausseren Rates\", the council on external affairs, and in this capacity was involved in the expulsion of the Jews, the destruction of the synagogue and in its place the construction of a church and shrine to the Schöne Maria that occurred in 1519. Altdorfer made etchings of the interior of the synagogue and designed a woodcut of the cult image of the Schöne Maria. In 1529–1530 he was also charged with reinforcing certain city fortifications in response to the Turkish threat.\n\nAlbrecht's brother, Erhard Altdorfer, was also a painter and printmaker in woodcut and engraving, and a pupil of Lucas Cranach the Elder.\n\n\n", "id": "2440", "title": "Albrecht Altdorfer"}
{"url": "https://en.wikipedia.org/wiki?curid=2441", "text": "House of Ascania\n\nThe House of Ascania () is a dynasty of German rulers. It is also known as the House of Anhalt, after Anhalt, its longest-held possession.\n\nThe Ascanians are named after Ascania (or Ascaria) Castle, \"Schloss Askanien\", which is located near and named after Aschersleben. The castle was seat of the County of Ascania, a title that was later subsumed into the titles of the princes of Anhalt.\n\nThe earliest known member of the house, Esiko, Count of Ballenstedt, first appears in a document of 1036, and is assumed to have been a grandson (through his mother) of Odo I, Margrave of the Saxon Ostmark. From Odo, the Ascanians inherited large properties in the Saxon Eastern March.\n\nEsiko's grandson was Otto, Count of Ballenstedt, who died in 1123. By Otto's marriage to Eilika, daughter of Magnus, Duke of Saxony, the Ascanians became heirs to half of the property of the House of Billung, former dukes of Saxony.\n\nOtto's son, Albert the Bear, became, with the help of his mother's inheritance, the first Ascanian duke of Saxony in 1139. But he lost control of Saxony soon to the rival House of Guelph.\n\nHowever, Albert inherited the Margraviate of Brandenburg from its last Wendish ruler, Pribislav, in 1157, and became the first Ascanian margrave. Albert, and his descendants of the House of Ascania, then made considerable progress in Christianizing and Germanizing the lands. As a borderland between German and Slavic cultures, the country was known as a march.\n\nIn 1237 and 1244 two towns, Cölln and Berlin were founded during the rule of Otto and Johann, grandsons of Margrave Albert the Bear (later they were united into one city, Berlin). The emblem of the House of Ascania, red eagle and bear, became the heraldic emblems of Berlin.\n\nIn 1320 the Brandenburg Ascanian line came to an end.\n\nAfter the Emperor had deposed the Guelph rulers of Saxony in 1180, Ascanians returned to rule the Duchy of Saxony, which had been reduced to its eastern half by the Emperor. However, even in eastern Saxony, the Ascanians could establish control only in limited areas, mostly near the River Elbe.\n\nIn the 13th century, the Principality of Anhalt was split off from the Duchy, and later, the remaining state was split into Saxe-Lauenburg and Saxe-Wittenberg. The Ascanian dynasties in the two Saxon states became extinct in 1689 and in 1422, respectively, but Ascanians continued to rule in the smaller state of Anhalt and its various subdivisions until monarchy was abolished in 1918.\n\nCatherine the Great, Empress of Russia from 1762–1796, was a member of the House of Ascania, herself the daughter of Christian August, Prince of Anhalt-Zerbst.\n\n\n\n", "id": "2441", "title": "House of Ascania"}
{"url": "https://en.wikipedia.org/wiki?curid=2443", "text": "Acceleration\n\nAcceleration, in physics, is the rate of change of velocity of an object with respect to time. An object's acceleration is the net result of any and all forces acting on the object, as described by Newton's Second Law. The SI unit for acceleration is metre per second squared Accelerations are vector quantities (they have magnitude and direction) and add according to the parallelogram law. As a vector, the calculated net force is equal to the product of the object's mass (a scalar quantity) and its acceleration.\n\nFor example, when a car starts from a standstill (zero relative velocity) and travels in a straight line at increasing speeds, it is accelerating in the direction of travel. If the car turns, there is an acceleration toward the new direction. In this example, we can call the forward acceleration of the car a \"linear acceleration\", which passengers in the car might experience as a force pushing them back into their seats. When changing direction, we might call this \"non-linear acceleration\", which passengers might experience as a sideways force. If the speed of the car decreases, this is an acceleration in the opposite direction from the direction of the vehicle, sometimes called deceleration. Passengers may experience deceleration as a force lifting them forwards. Mathematically, there is no separate formula for deceleration: both are changes in velocity. Each of these accelerations (linear, non-linear, deceleration) might be felt by passengers until their velocity (speed and direction) matches that of the car.\n\nAn object's average acceleration over a period of time is its change in velocity formula_1 divided by the duration of the period formula_2. Mathematically,\n\nInstantaneous acceleration, meanwhile, is the limit of the average acceleration over an infinitesimal interval of time. In the terms of calculus, instantaneous acceleration is the derivative of the velocity vector with respect to time:\n\nIt can be seen that the integral of the acceleration function is the velocity function ; that is, the area under the curve of an acceleration vs. time ( vs. ) graph corresponds to velocity.\n\nAs acceleration is defined as the derivative of velocity, , with respect to time and velocity is defined as the derivative of position, , with respect to time, acceleration can be thought of as the second derivative of with respect to :\n\nAcceleration has the dimensions of velocity (L/T) divided by time, i.e. L.T. The SI unit of acceleration is the metre per second squared (m s); or \"metre per second per second\", as the velocity in metres per second changes by the acceleration value, every second.\n\nAn object moving in a circular motion—such as a satellite orbiting the Earth—is accelerating due to the change of direction of motion, although its speed may be constant. In this case it is said to be undergoing \"centripetal\" (directed towards the center) acceleration.\n\nProper acceleration, the acceleration of a body relative to a free-fall condition, is measured by an instrument called an accelerometer.\n\nIn classical mechanics, for a body with constant mass, the (vector) acceleration of the body's center of mass is proportional to the net force vector (i.e. sum of all forces) acting on it (Newton's second law):\nwhere F is the net force acting on the body, \"m\" is the mass of the body, and a is the center-of-mass acceleration. As speeds approach the speed of light, relativistic effects become increasingly large.\n\nThe velocity of a particle moving on a curved path as a function of time can be written as:\n\nwith \"v\"(\"t\") equal to the speed of travel along the path, and\n\na unit vector tangent to the path pointing in the direction of motion at the chosen moment in time. Taking into account both the changing speed \"v(t)\" and the changing direction of u, the acceleration of a particle moving on a curved path can be written using the chain rule of differentiation for the product of two functions of time as:\n\nwhere u is the unit (inward) normal vector to the particle's trajectory (also called \"the principal normal\"), and r is its instantaneous radius of curvature based upon the osculating circle at time \"t\". These components are called the tangential acceleration and the normal or radial acceleration (or centripetal acceleration in circular motion, see also circular motion and centripetal force).\n\nGeometrical analysis of three-dimensional space curves, which explains tangent, (principal) normal and binormal, is described by the Frenet–Serret formulas.\n\n\"Uniform\" or \"constant\" acceleration is a type of motion in which the velocity of an object changes by an equal amount in every equal time period.\n\nA frequently cited example of uniform acceleration is that of an object in free fall in a uniform gravitational field. The acceleration of a falling body in the absence of resistances to motion is dependent only on the gravitational field strength \"g\" (also called \"acceleration due to gravity\"). By Newton's Second Law the force, \"F\", acting on a body is given by:\n\nBecause of the simple analytic properties of the case of constant acceleration, there are simple formulas relating the displacement, initial and time-dependent velocities, and acceleration to the time elapsed:\n\nwhere\n\nIn particular, the motion can be resolved into two orthogonal parts, one of constant velocity and the other according to the above equations. As Galileo showed, the net result is parabolic motion, which describes, e. g., the trajectory of a projectile in a vacuum near the surface of Earth.\n\nUniform circular motion, that is constant speed along a circular path, is an example of a body experiencing acceleration resulting in velocity of a constant magnitude but change of direction. In this case, because the direction of the object's motion is constantly changing, being tangential to the circle, the object's linear velocity vector also changes, but its speed does not. This acceleration is a radial acceleration since it is always directed toward the centre of the circle and takes the magnitude:\n\nwhere formula_24 is the object's linear speed along the circular path. Equivalently, the radial acceleration vector (formula_25) may be calculated from the object's angular velocity formula_26:\n\nwhere formula_28 is a vector directed from the centre of the circle and equal in magnitude to the radius. The negative shows that the acceleration vector is directed towards the centre of the circle (opposite to the radius).\n\nThe acceleration and the net force acting on a body in uniform circular motion are directed \"toward\" the centre of the circle; that is, it is centripetal. Whereas the so-called 'centrifugal force' appearing to act outward on the body is really a pseudo force experienced in the frame of reference of the body in circular motion, due to the body's linear momentum at a tangent to the circle.\n\nWith nonuniform circular motion, i.e., the speed along the curved path changes, a transverse acceleration is produced equal to the rate of change of the angular speed around the circle times the radius of the circle. That is,\n\nThe transverse (or tangential) acceleration is directed at right angles to the radius vector and takes the sign of the angular acceleration (formula_30).\n\nThe special theory of relativity describes the behavior of objects traveling relative to other objects at speeds approaching that of light in a vacuum. Newtonian mechanics is exactly revealed to be an approximation to reality, valid to great accuracy at lower speeds. As the relevant speeds increase toward the speed of light, acceleration no longer follows classical equations.\n\nAs speeds approach that of light, the acceleration produced by a given force decreases, becoming infinitesimally small as light speed is approached; an object with mass can approach this speed asymptotically, but never reach it.\n\nUnless the state of motion of an object is known, it is totally impossible to distinguish whether an observed force is due to gravity or to acceleration—gravity and inertial acceleration have identical effects. Albert Einstein called this the principle of equivalence, and said that only observers who feel no force at all—including the force of gravity—are justified in concluding that they are not accelerating.\n\n", "id": "2443", "title": "Acceleration"}
{"url": "https://en.wikipedia.org/wiki?curid=2444", "text": "Conservation-restoration of cultural heritage\n\nThe conservation-restoration of cultural heritage focuses on protection and care of tangible cultural heritage, including artworks, architecture, archaeology, and museum collections. Conservation activities include preventive conservation, examination, documentation, research, treatment, and education. This field is closely allied with conservation science, curators and registrars.\n\nConservation of cultural heritage involves protection and restoration using \"any methods that prove effective in keeping that property in as close to its original condition as possible for as long as possible.\" Conservation of cultural heritage is often associated with art collections and museums and involves collection care and management through tracking, examination, documentation, exhibition, storage, preventative conservation, and restoration.\n\nThe scope has widened from art conservation, involving protection and care of artwork and architecture, to conservation of cultural heritage, also including protection and care of a broad set of other cultural and historical works. Conservation of cultural heritage can be described as a type of ethical stewardship.\n\nConservation of cultural heritage applies simple ethical guidelines:\n\nOften there are compromises between preserving appearance, maintaining original design and material properties, and ability to reverse changes. Reversibility is now emphasized so as to reduce problems with future treatment, investigation, and use.\n\nIn order for conservators to decide upon an appropriate conservation strategy and apply their professional expertise accordingly, they must take into account views of the stakeholder, the values and meaning of the work, and the physical needs of the material.\n\nCesare Brandi in his \"Theory of Restoration\", describes restoration as \"the methodological moment in which the work of art is appreciated in its material form and in its historical and aesthetic duality, with a view to transmitting it to the future\".\n\nSome consider the tradition of conservation of cultural heritage in Europe to have begun in 1565 with the restoration of the Sistine Chapel frescoes, but more ancient examples include the work of Cassiodorus.\n\nThe care of cultural heritage has a long history, one that was primarily aimed at fixing and mending objects for their continued use and aesthetic enjoyment. Until the early 20th century, artists were normally the ones called upon to repair damaged artworks. During the 19th century, however, the fields of science and art became increasingly intertwined as scientists such as Michael Faraday began to study the damaging effects of the environment to works of art. Louis Pasteur carried out scientific analysis on paint as well. However, perhaps the first organized attempt to apply a theoretical framework to the conservation of cultural heritage came with the founding in the United Kingdom of the Society for the Protection of Ancient Buildings in 1877. The society was founded by William Morris and Philip Webb, both of whom were deeply influenced by the writings of John Ruskin. During the same period, a French movement with similar aims was being developed under the direction of Eugène Viollet-le-Duc, an architect and theorist, famous for his restorations of medieval buildings.\nConservation of cultural heritage as a distinct field of study initially developed in Germany, where in 1888 Friedrich Rathgen became the first chemist to be employed by a Museum, the Koniglichen Museen, Berlin (Royal Museums of Berlin). He not only developed a scientific approach to the care of objects in the collections, but disseminated this approach by publishing a Handbook of Conservation in 1898. The early development of conservation of cultural heritage in any area of the world is usually linked to the creation of positions for chemists within museums. In the United Kingdom, pioneering research into painting materials and conservation, ceramics, and stone conservation was conducted by Arthur Pillans Laurie, academic chemist and Principal of Heriot-Watt University from 1900. Laurie's interests were fostered by William Holman Hunt. In 1924 the chemist Harold Plenderleith began to work at the British Museum with Dr. Alexander Scott in the newly created Department of Scientific and Industrial Research, thus giving birth to the conservation profession in the UK. This department was created by the museum to address the deteriorating condition of objects in the collection, damages which were a result of their being stored in the London Underground tunnels during the First World War. The creation of this department moved the focus for the development of conservation theory and practice from Germany to Britain, and made the latter a prime force in this fledgling field. In 1956 Plenderleith wrote a significant handbook called The Conservation of Antiquities and Works of Art, which supplanted Rathgen's earlier tome and set new standards for the development of art and conservation science.\n\nIn the United States, the development of conservation of cultural heritage can be traced to the Fogg Art Museum, and Edward Waldo Forbes, its director from 1909 to 1944. He encouraged technical investigation, and was Chairman of the Advisory Committee for the first technical journal, Technical Studies in the Field of the Fine Arts, published by the Fogg from 1932 to 1942. Importantly he also brought onto the museum staff chemists. Rutherford John Gettens was the first of usch in the US to be permanently employed by an art museum. He worked with George L. Stout, the founder and first editor of Technical Studies. Gettens and Stout co-authored Painting Materials: A Short Encyclopaedia in 1942, reprinted in 1966. This compendium is still cited regularly. Only a few dates and descriptions in Gettens' and Stout's book are now outdated.\n\nGeorge T. Oliver, of Oliver Brothers Art Restoration and Art Conservation-Boston\n(Est. 1850 in New York City) invented the vacuum hot table for relining paintings in 1920s; he filed a patent for the table in 1937. Taylor's prototype table, which he designed and constructed, is still in operation. Oliver Brothers is believed to be the first and the oldest continuously operating art restoration company in the United States.\n\nThe focus of conservation development then accelerated in Britain and America, and it was in Britain that the first International Conservation Organisations developed. The International Institute for Conservation of Historic and Artistic Works (IIC) was incorporated under British law in 1950 as \"a permanent organization to co-ordinate and improve the knowledge, methods, and working standards needed to protect and preserve precious materials of all kinds.\" The rapid growth of conservation professional organizations, publications, journals, newsletters, both internationally and in localities, has spearheaded the development of the conservation profession, both practically and theoretically. Art historians and theorists such as Cesare Brandi have also played a significant role in developing conservation science theory. In recent years ethical concerns have been at the forefront of developments in conservation. Most significantly has been the idea of preventive conservation. This concept is based in part on the pioneering work by Garry Thomson CBE, and his book the Museum Environment, first published in 1978. Thomson was associated with the National Gallery in London; it was here that he established a set of guidelines or environmental controls for the best conditions in which objects could be stored and displayed within the museum environment. Although his exact guidelines are no longer rigidly followed, they did inspire this field of conservation.\n\nThe conservator's work is guided by ethical standards. These take the form of applied ethics. Ethical standards have been established across the world, and national and international ethical guidelines have been written. One such example is:\n\n\nConservation OnLine's Ethical issues in conservation provides a number of articles on ethical issues in conservation; example of codes of ethics and guidelines for professional conduct in conservation and allied fields; and charters and treaties pertaining to ethical issues involving the preservation of cultural property.\n\nAs well as standards of practice conservators deal with wider ethical concerns, such as the debates as to whether all art is worth preserving.\n\nMany cultural works are sensitive to environmental conditions such as temperature, humidity and exposure to visible light and ultraviolet radiation. These works must be protected in controlled environments where such variables are maintained within a range of damage-limiting levels. For example, watercolour paintings usually require shielding from sunlight to prevent fading of pigments.\n\nCollections care is an important element of museum policy. It is an essential responsibility of members of the museum profession to create and maintain a protective environment for the collections in their care, whether in store, on display, or in transit. A museum should carefully monitor the condition of collections to determine when an artifact requires conservation work and the services of a qualified conservator.\n\nA principal aim of a cultural conservator is to reduce the rate of deterioration of an object. Both non-interventive and interventive methodologies may be employed in pursuit of this goal. Interventive conservation refers to any direct interaction between the conservator and the material fabric of the object. Interventive actions are carried out for a variety of reasons, including aesthetic choices, stabilization needs for structural integrity, or cultural requirements for intangible continuity. Examples of interventive treatments include the removal of discolored varnish from a painting, the application of wax to a sculpture, and the washing and rebinding of a book. Ethical standards within the field require that the conservator fully justify interventive actions and carry out documentation before, during, and after the treatment.\n\nOne of the guiding principles of conservation of cultural heritage has traditionally been the idea of reversibility, that all interventions with the object should be fully reversible and that the object should be able to be returned to the state in which it was prior to the conservator's intervention. Although this concept remains a guiding principle of the profession, it has been widely critiqued within the conservation profession and is now considered by many to be \"a fuzzy concept.\" Another important principle of conservation is that all alterations should be well documented and should be clearly distinguishable from the original object.\n\nAn example of a highly publicized interventive conservation effort would be the conservation work conducted on the Sistine Chapel.\n\nConservators routinely use chemical and scientific analysis for the examination and treatment of cultural works. The modern conservation laboratory uses equipment such as microscopes, spectrometers, and various x-ray regime instruments to better understand objects and their components. The data thus collected helps in deciding the conservation treatments to be provided to the object.\n\nHeritage Preservation, in partnership with the Institute of Museum and Library Services, a U.S. federal agency, produced The Heritage Health Index. The results of this work was the report A Public Trust at Risk: The Heritage Health Index Report on the State of America's Collections, which was published in December 2005 and concluded that immediate action is needed to prevent the loss of 190 million artifacts that are in need of conservation treatment. The report made four recommendations:\n\nIn October 2006, the Department for Culture, Media and Sport, a governmental department, authored a document: \"Understanding the Future: Priorities for England's Museums\". This document was based on several years of consultation aimed to lay out the government's priorities for museums in the 21st century.\n\nThe document listed the following as priorities for the next decade:\n\n\nThe conservation profession response to this report was on the whole less than favourable, the Institute of Conservation (ICON) published their response under the title \"A Failure of Vision\". It had the following to say:\n\nConcluding: \n\nFurther to this the ICON website summary report lists the following specific recommendations:\n\n\nIn November 2008, the UK-based think tank Demos published an influential pamphlet entitled \"It's a material world: caring for the public realm\", in which they argue for integrating the public directly into efforts to conserve material culture, particularly that which is in the public, their argument, as stated on page 16, demonstrates their belief that society can benefit from conservation as a paradigm as well as a profession:\n\nTraining in conservation of cultural heritage for many years took the form of an apprenticeship, whereby an apprentice slowly developed the necessary skills to undertake their job. For some specializations within conservation this is still the case. However, it is more common in the field of conservation today that the training required to become a practicing conservator comes from a recognized university course in conservation of cultural heritage.\n\nThe University can rarely provide all the necessary training in first hand experience that an apprenticeship can, and therefore in addition to graduate level training the profession also tends towards encouraging conservation students to spend time as an intern.\n\nConservation of cultural heritage is an interdisciplinary field as conservators have backgrounds in the fine arts, sciences (including chemistry, biology, and materials science), and closely related disciplines, such as art history, archaeology, studio art, and anthropology. They also have design, fabrication, artistic, and other special skills necessary for the practical application of that knowledge.\n\nWithin the various schools that teach conservation of cultural heritage, the approach differs according to the educational and vocational system within the country, and the focus of the school itself. This is acknowledged by the American Institute for Conservation who advise \"Specific admission requirements differ and potential candidates are encouraged to contact the programs directly for details on prerequisites, application procedures, and program curriculum\".\n\nSocieties devoted to the care of cultural heritage have been in existence around the world for many years. One early example is the founding in 1877 of the Society for the Protection of Ancient Buildings in Britain to protect the built heritage, this society continues to be active today.\n\nThe built heritage was at the forefront of the growth of member based organizations in the United States. Preservation Virginia, founded in Richmond in 1889 as the Association for the Preservation of Virginia Antiquities, was the United States' first statewide historic preservation group.\n\nToday, professional conservators join and take part in the activities of numerous conservation associations and professional organizations with the wider field, and within their area of specialization.\n\nThese organizations exist to \"support the conservation professionals who preserve our cultural heritage\".\n\nThis involves upholding professional standards, promoting research and publications, providing educational opportunities, and fostering the exchange of knowledge among cultural conservators, allied professionals, and the public.\n\n\n\n\n\n\n\nExternal lists of international cultural heritage documents:\n", "id": "2444", "title": "Conservation-restoration of cultural heritage"}
{"url": "https://en.wikipedia.org/wiki?curid=2447", "text": "Anton Chekhov\n\nAnton Pavlovich Chekhov (; , ; 29 January 1860 – 15 July 1904) was a Russian playwright and short story writer, who is considered to be among the greatest writers of short fiction in history. His career as a playwright produced four classics and his best short stories are held in high esteem by writers and critics. Along with Henrik Ibsen and August Strindberg, Chekhov is often referred to as one of the three seminal figures in the birth of early modernism in the theatre. Chekhov practiced as a medical doctor throughout most of his literary career: \"Medicine is my lawful wife\", he once said, \"and literature is my mistress.\"\n\nChekhov renounced the theatre after the reception of \"The Seagull\" in 1896, but the play was revived to acclaim in 1898 by Konstantin Stanislavski's Moscow Art Theatre, which subsequently also produced Chekhov's \"Uncle Vanya\" and premiered his last two plays, \"Three Sisters\" and \"The Cherry Orchard\". These four works present a challenge to the acting ensemble as well as to audiences, because in place of conventional action Chekhov offers a \"theatre of mood\" and a \"submerged life in the text\".\n\nChekhov had at first written stories only for financial gain, but as his artistic ambition grew, he made formal innovations which have influenced the evolution of the modern short story. He made no apologies for the difficulties this posed to readers, insisting that the role of an artist was to ask questions, not to answer them.\n\nAnton Chekhov was born on the feast day of St. Anthony the Great (17 January Old Style) 29 January 1860, the third of six surviving children, in Taganrog, a port on the Sea of Azov in southern Russia. His father, Pavel Yegorovich Chekhov, the son of a former serf and his Ukrainian wife, were from the village Vilkhovatka near Kobeliaky (Poltava Region in modern-day Ukraine) and ran a grocery store. A director of the parish choir, devout Orthodox Christian, and physically abusive father, Pavel Chekhov has been seen by some historians as the model for his son's many portraits of hypocrisy. Chekhov's mother, Yevgeniya (Morozova), was an excellent storyteller who entertained the children with tales of her travels with her cloth-merchant father all over Russia. \"Our talents we got from our father,\" Chekhov remembered, \"but our soul from our mother.\"\nIn adulthood, Chekhov criticised his brother Alexander's treatment of his wife and children by reminding him of Pavel's tyranny: \"Let me ask you to recall that it was despotism and lying that ruined your mother's youth. Despotism and lying so mutilated our childhood that it's sickening and frightening to think about it. Remember the horror and disgust we felt in those times when Father threw a tantrum at dinner over too much salt in the soup and called Mother a fool.\"\n\nChekhov attended the Greek School in Taganrog and the Taganrog \"Gymnasium\" (since renamed the Chekhov Gymnasium), where he was kept down for a year at fifteen for failing an examination in Ancient Greek. He sang at the Greek Orthodox monastery in Taganrog and in his father's choirs. In a letter of 1892, he used the word \"suffering\" to describe his childhood and recalled:\n\nHe later became an atheist.\n\nIn 1876, Chekhov's father was declared bankrupt after overextending his finances building a new house, having been cheated by a contractor called Mironov. To avoid debtor's prison he fled to Moscow, where his two eldest sons, Alexander and Nikolay, were attending university. The family lived in poverty in Moscow, Chekhov's mother physically and emotionally broken by the experience. Chekhov was left behind to sell the family's possessions and finish his education.\n\nChekhov remained in Taganrog for three more years, boarding with a man called Selivanov who, like Lopakhin in \"The Cherry Orchard\", had bailed out the family for the price of their house. Chekhov had to pay for his own education, which he managed by private tutoring, catching and selling goldfinches, and selling short sketches to the newspapers, among other jobs. He sent every ruble he could spare to his family in Moscow, along with humorous letters to cheer them up. During this time, he read widely and analytically, including the works of Cervantes, Turgenev, Goncharov, and Schopenhauer, and wrote a full-length comic drama, \"Fatherless\", which his brother Alexander dismissed as \"an inexcusable though innocent fabrication.\" Chekhov also enjoyed a series of love affairs, one with the wife of a teacher.\n\nIn 1879, Chekhov completed his schooling and joined his family in Moscow, having gained admission to the medical school at I.M. Sechenov First Moscow State Medical University.\n\nChekhov now assumed responsibility for the whole family. To support them and to pay his tuition fees, he wrote daily short, humorous sketches and vignettes of contemporary Russian life, many under pseudonyms such as \"Antosha Chekhonte\" (Антоша Чехонте) and \"Man without a Spleen\" (Человек без селезенки). His prodigious output gradually earned him a reputation as a satirical chronicler of Russian street life, and by 1882 he was writing for \"Oskolki\" (\"Fragments\"), owned by Nikolai Leykin, one of the leading publishers of the time. Chekhov's tone at this stage was harsher than that familiar from his mature fiction.\n\nIn 1884, Chekhov qualified as a physician, which he considered his principal profession though he made little money from it and treated the poor free of charge.\n\nIn 1884 and 1885, Chekhov found himself coughing blood, and in 1886 the attacks worsened, but he would not admit his tuberculosis to his family or his friends. He confessed to Leykin, \"I am afraid to submit myself to be sounded by my colleagues.\" He continued writing for weekly periodicals, earning enough money to move the family into progressively better accommodations.\n\nEarly in 1886 he was invited to write for one of the most popular papers in St. Petersburg, \"Novoye Vremya\" (\"New Times\"), owned and edited by the millionaire magnate Alexey Suvorin, who paid a rate per line double Leykin's and allowed Chekhov three times the space. Suvorin was to become a lifelong friend, perhaps Chekhov's closest.\n\nBefore long, Chekhov was attracting literary as well as popular attention. The sixty-four-year-old Dmitry Grigorovich, a celebrated Russian writer of the day, wrote to Chekhov after reading his short story \"The Huntsman\" that \"You have \"real\" talent, a talent that places you in the front rank among writers in the new generation.\" He went on to advise Chekhov to slow down, write less, and concentrate on literary quality.\n\nChekhov replied that the letter had struck him \"like a thunderbolt\" and confessed, \"I have written my stories the way reporters write up their notes about fires — mechanically, half-consciously, caring nothing about either the reader or myself.\"\" The admission may have done Chekhov a disservice, since early manuscripts reveal that he often wrote with extreme care, continually revising. Grigorovich's advice nevertheless inspired a more serious, artistic ambition in the twenty-six-year-old. In 1888, with a little string-pulling by Grigorovich, the short story collection \"At Dusk\" (\"V Sumerkakh\") won Chekhov the coveted Pushkin Prize \"for the best literary production distinguished by high artistic worth.\"\n\nIn 1887, exhausted from overwork and ill health, Chekhov took a trip to Ukraine, which reawakened him to the beauty of the steppe. On his return, he began the novella-length short story \",\" which he called \"something rather odd and much too original,\" and which was eventually published in \"Severny Vestnik\" (\"The Northern Herald\"). In a narrative that drifts with the thought processes of the characters, Chekhov evokes a chaise journey across the steppe through the eyes of a young boy sent to live away from home, and his companions, a priest and a merchant. \"The Steppe\" has been called a \"dictionary of Chekhov's poetics\", and it represented a significant advance for Chekhov, exhibiting much of the quality of his mature fiction and winning him publication in a literary journal rather than a newspaper.\n\nIn autumn 1887, a theatre manager named Korsh commissioned Chekhov to write a play, the result being \"Ivanov\", written in a fortnight and produced that November. Though Chekhov found the experience \"sickening\" and painted a comic portrait of the chaotic production in a letter to his brother Alexander, the play was a hit and was praised, to Chekhov's bemusement, as a work of originality. Although Chekhov did not fully realize it at the time, Chekhov's plays, such as \"The Seagull\" (written in 1895), \"Uncle Vanya\" (written in 1897), \"The Three Sisters\" (written in 1900), and \"The Cherry Orchard\" (written in 1903) served as a revolutionary backbone to what is common sense to the medium of acting to this day: an effort to recreate and express the \"realism\" of how people truly act and speak with each other and translating it to the stage in order to manifest the human condition as accurately as possible in hopes to make the audience reflect upon their own definition of what it means to be human, warts and all.\n\nThis philosophy of approaching the art of acting has stood not only steadfast, but as the cornerstone of acting for much of the 20th century to this day. Mikhail Chekhov considered \"Ivanov\" a key moment in his brother's intellectual development and literary career. From this period comes an observation of Chekhov's that has become known as Chekhov's gun, a dramatic principle that requires that every element in a narrative be necessary and irreplaceable, and that everything else be removed.\nThe death of Chekhov's brother Nikolay from tuberculosis in 1889 influenced \"A Dreary Story\", finished that September, about a man who confronts the end of a life that he realises has been without purpose. Mikhail Chekhov, who recorded his brother's depression and restlessness after Nikolay's death, was researching prisons at the time as part of his law studies, and Anton Chekhov, in a search for purpose in his own life, himself soon became obsessed with the issue of prison reform.\n\nIn 1890, Chekhov undertook an arduous journey by train, horse-drawn carriage, and river steamer to the Russian Far East and the \"katorga\", or penal colony, on Sakhalin Island, north of Japan, where he spent three months interviewing thousands of convicts and settlers for a census. The letters Chekhov wrote during the two-and-a-half-month journey to Sakhalin are considered to be among his best. His remarks to his sister about Tomsk were to become notorious.\n\nThe inhabitants of Tomsk later retaliated by erecting a mocking statue of Chekhov.\n\nChekhov witnessed much on Sakhalin that shocked and angered him, including floggings, embezzlement of supplies, and forced prostitution of women. He wrote, \"There were times I felt that I saw before me the extreme limits of man's degradation.\" He was particularly moved by the plight of the children living in the penal colony with their parents. For example:\n\nChekhov later concluded that charity was not the answer, but that the government had a duty to finance humane treatment of the convicts. His findings were published in 1893 and 1894 as \"Ostrov Sakhalin\" (\"The Island of Sakhalin\"), a work of social science, not literature, that is worthy and informative rather than brilliant. Chekhov found literary expression for the \"Hell of Sakhalin\" in his long short story \",\" the last section of which is set on Sakhalin, where the murderer Yakov loads coal in the night while longing for home. Chekhov's writing on Sakhalin is the subject of brief comment and analysis in Haruki Murakami's novel 1Q84. It is also the subject of a poem by the Nobel Prize winner Seamus Heaney, \"Chekhov on Sakhalin\" (collected in the volume \"Station Island\").\n\nIn 1892, Chekhov bought the small country estate of Melikhovo, about forty miles south of Moscow, where he lived with his family until 1899 . \"It's nice to be a lord,\" he joked to his friend Ivan Leontyev (who wrote humorous pieces under the pseudonym Shcheglov), but he took his responsibilities as a landlord seriously and soon made himself useful to the local peasants. As well as organising relief for victims of the famine and cholera outbreaks of 1892, he went on to build three schools, a fire station, and a clinic, and to donate his medical services to peasants for miles around, despite frequent recurrences of his tuberculosis.\n\nMikhail Chekhov, a member of the household at Melikhovo, described the extent of his brother's medical commitments:\n\nChekhov's expenditure on drugs was considerable, but the greatest cost was making journeys of several hours to visit the sick, which reduced his time for writing. However, Chekhov's work as a doctor enriched his writing by bringing him into intimate contact with all sections of Russian society: for example, he witnessed at first hand the peasants' unhealthy and cramped living conditions, which he recalled in his short story \"Peasants\". Chekhov visited the upper classes as well, recording in his notebook: \"Aristocrats? The same ugly bodies and physical uncleanliness, the same toothless old age and disgusting death, as with market-women.\"\n\nIn 1894, Chekhov began writing his play \"The Seagull\" in a lodge he had built in the orchard at Melikhovo. In the two years since he had moved to the estate, he had refurbished the house, taken up agriculture and horticulture, tended the orchard and the pond, and planted many trees, which, according to Mikhail, he \"looked after ... as though they were his children. Like Colonel Vershinin in his \"Three Sisters\", as he looked at them he dreamed of what they would be like in three or four hundred years.\"\n\nThe first night of \"The Seagull\", at the Alexandrinsky Theatre in St. Petersburg on 17 October 1896, was a fiasco, as the play was booed by the audience, stinging Chekhov into renouncing the theatre. But the play so impressed the theatre director Vladimir Nemirovich-Danchenko that he convinced his colleague Konstantin Stanislavski to direct a new production for the innovative Moscow Art Theatre in 1898. Stanislavski's attention to psychological realism and ensemble playing coaxed the buried subtleties from the text, and restored Chekhov's interest in playwriting. The Art Theatre commissioned more plays from Chekhov and the following year staged \"Uncle Vanya\", which Chekhov had completed in 1896.\n\nIn March 1897, Chekhov suffered a major hemorrhage of the lungs while on a visit to Moscow. With great difficulty he was persuaded to enter a clinic, where the doctors diagnosed tuberculosis on the upper part of his lungs and ordered a change in his manner of life.\n\nAfter his father's death in 1898, Chekhov bought a plot of land on the outskirts of Yalta and built a villa, into which he moved with his mother and sister the following year. Though he planted trees and flowers, kept dogs and tame cranes, and received guests such as Leo Tolstoy and Maxim Gorky, Chekhov was always relieved to leave his \"hot Siberia\" for Moscow or travels abroad. He vowed to move to Taganrog as soon as a water supply was installed there. In Yalta he completed two more plays for the Art Theatre, composing with greater difficulty than in the days when he \"wrote serenely, the way I eat pancakes now\". He took a year each over \"Three Sisters\" and \"The Cherry Orchard\".\n\nOn 25 May 1901, Chekhov married Olga Knipper quietly, owing to his horror of weddings. She was a former protegée and sometime lover of Nemirovich-Danchenko whom he had first met at rehearsals for \"The Seagull\". Up to that point, Chekhov, known as \"Russia's most elusive literary bachelor,\" had preferred passing liaisons and visits to brothels over commitment. He had once written to Suvorin:\n\nThe letter proved prophetic of Chekhov's marital arrangements with Olga: he lived largely at Yalta, she in Moscow, pursuing her acting career. In 1902, Olga suffered a miscarriage; and Donald Rayfield has offered evidence, based on the couple's letters, that conception may have occurred when Chekhov and Olga were apart, although Russian scholars have rejected that claim. The literary legacy of this long-distance marriage is a correspondence that preserves gems of theatre history, including shared complaints about Stanislavski's directing methods and Chekhov's advice to Olga about performing in his plays.\n\nIn Yalta, Chekhov wrote one of his most famous stories, \"The Lady with the Dog\" (also translated from the Russian as \"Lady with Lapdog\"), which depicts what at first seems a casual liaison between a cynical married man and an unhappy married woman who meet while vacationing in Yalta. Neither expects anything lasting from the encounter. Unexpectedly though, they gradually fall deeply in love and end up risking scandal and the security of their family lives. The story masterfully captures their feelings for each other, the inner transformation undergone by the disillusioned male protagonist as a result of falling deeply in love, and their inability to resolve the matter by either letting go of their families or of each other.\n\nBy May 1904, Chekhov was terminally ill with tuberculosis. Mikhail Chekhov recalled that \"everyone who saw him secretly thought the end was not far off, but the nearer [he] was to the end, the less he seemed to realise it.\" On 3 June, he set off with Olga for the German spa town of Badenweiler in the Black Forest, from where he wrote outwardly jovial letters to his sister Masha, describing the food and surroundings, and assuring her and his mother that he was getting better. In his last letter, he complained about the way German women dressed.\n\nChekhov's death has become one of \"the great set pieces of literary history,\" retold, embroidered, and fictionalised many times since, notably in the short story \"Errand\" by Raymond Carver. In 1908, Olga wrote this account of her husband's last moments:\n\nChekhov's body was transported to Moscow in a refrigerated railway car meant for oysters, a detail that offended Gorky. Some of the thousands of mourners followed the funeral procession of a General Keller by mistake, to the accompaniment of a military band. Chekhov was buried next to his father at the Novodevichy Cemetery.\n\nA few months before he died, Chekhov told the writer Ivan Bunin that he thought people might go on reading his writings for seven years. \"Why seven?\" asked Bunin. \"Well, seven and a half,\" Chekhov replied. \"That's not bad. I've got six years to live.\"\n\nChekhov's posthumous reputation greatly exceeded his expectations. The ovations for the play \"The Cherry Orchard\" in the year of his death served to demonstrate the Russian public's acclaim for the writer, which placed him second in literary celebrity only to Tolstoy, who outlived him by six years. Tolstoy was an early admirer of Chekhov's short stories and had a series that he deemed \"first quality\" and \"second quality\" bound into a book. In the first category were: \"Children\", \"The Chorus Girl\", \"A Play\", \"Home\", \"Misery\", \"The Runaway\", \"In Court\", \"Vanka\", \"Ladies\", \"A Malefactor\", \"The Boys\", \"Darkness\", \"Sleepy\", \"The Helpmate\", and \"The Darling\"\"; in the second: \"A Transgression\", \"Sorrow\", \"The Witch\", \"Verochka\", \"In a Strange Land\", \"The Cook's Wedding\", \"A Tedious Business\", \"An Upheaval\", \"Oh! The Public!\", \"The Mask\", \"A Woman's Luck\", \"Nerves\", \"The Wedding\", \"A Defenseless Creature\", and \"Peasant Wives.\"\n\nIn Chekhov's lifetime, British and Irish critics generally did not find his work pleasing; E. J. Dillon thought \"the effect on the reader of Chekhov's tales was repulsion at the gallery of human waste represented by his fickle, spineless, drifting people\" and R. E. C. Long said \"Chekhov's characters were repugnant, and that Chekhov reveled in stripping the last rags of dignity from the human soul\". After his death, Chekhov was reappraised. Constance Garnett's translations won him an English-language readership and the admiration of writers such as James Joyce, Virginia Woolf, and Katherine Mansfield, whose story \"The Child Who Was Tired\" is similar to Chekhov's \"Sleepy\". The Russian critic D. S. Mirsky, who lived in England, explained Chekhov's popularity in that country by his \"unusually complete rejection of what we may call the heroic values.\" In Russia itself, Chekhov's drama fell out of fashion after the revolution, but it was later incorporated into the Soviet canon. The character of Lopakhin, for example, was reinvented as a hero of the new order, rising from a modest background so as eventually to possess the gentry's estates.\n\nOne of the first non-Russians to praise Chekhov's plays was George Bernard Shaw, who subtitled his \"Heartbreak House\" \"A Fantasia in the Russian Manner on English Themes,\" and pointed out similarities between the predicament of the British landed class and that of their Russian counterparts as depicted by Chekhov: \"the same nice people, the same utter futility.\"\n\nIn the United States, Chekhov's reputation began its rise slightly later, partly through the influence of Stanislavski's system of acting, with its notion of subtext: \"Chekhov often expressed his thought not in speeches,\" wrote Stanislavski, \"but in pauses or between the lines or in replies consisting of a single word ... the characters often feel and think things not expressed in the lines they speak.\" The Group Theatre, in particular, developed the subtextual approach to drama, influencing generations of American playwrights, screenwriters, and actors, including Clifford Odets, Elia Kazan and, in particular, Lee Strasberg. In turn, Strasberg's Actors Studio and the \"Method\" acting approach influenced many actors, including Marlon Brando and Robert De Niro, though by then the Chekhov tradition may have been distorted by a preoccupation with realism. In 1981, the playwright Tennessee Williams adapted \"The Seagull\" as \"The Notebook of Trigorin\". One of Anton's nephews, Michael Chekhov would also contribute heavily to modern theatre, particularly through his unique acting methods which developed Stanislavski's ideas further.\n\nDespite Chekhov's reputation as a playwright, William Boyd asserts that his short stories represent the greater achievement. Raymond Carver, who wrote the short story \"Errand\" about Chekhov's death, believed that Chekhov was the greatest of all short story writers:\n\nErnest Hemingway, another writer influenced by Chekhov, was more grudging: \"Chekhov wrote about six good stories. But he was an amateur writer.\" And Vladimir Nabokov criticized Chekhov's \"medley of dreadful prosaisms, ready-made epithets, repetitions.\" But he also declared \"The Lady with the Dog\" \"one of the greatest stories ever written\" in its depiction of a problematic relationship, and described Chekhov as writing \"the way one person relates to another the most important things in his life, slowly and yet without a break, in a slightly subdued voice.\"\n\nFor the writer William Boyd, Chekhov's historical accomplishment was to abandon what William Gerhardie called the \"event plot\" for something more \"blurred, interrupted, mauled or otherwise tampered with by life.\"\n\nVirginia Woolf mused on the unique quality of a Chekhov story in \"The Common Reader\" (1925):\n\nWhile a Professor of Comparative Literature at Princeton University, Michael Goldman presented his view on defining the elusive quality of Chekhov's comedies stating: \"Having learned that Chekhov is comic ... Chekhov is comic in a very special, paradoxical way. His plays depend, as comedy does, on the vitality of the actors to make pleasurable what would otherwise be painfully awkward -- inappropriate speeches, missed connections, \"faux pas\", stumbles, childishness -- but as part of a deeper pathos; the stumbles are not pratfalls but an energized, graceful dissolution of purpose.\"\n\nAlan Twigg, the chief editor and publisher of the Canadian book review magazine \"BC Bookworld wrote,\nChekhov has also influenced the work of Japanese playwrights including Shimizu Kunio, Yōji Sakate, and Ai Nagai. Critics have noted similarities in how Chekhov and Shimizu use a mixture of light humor as well as an intense depictions of longing. Sakate adapted several of Chekhov's plays and transformed them in the general style of \"nō\". Nagai also adapted Chekhov's plays, including \"Three Sisters\", and transformed his dramatic style into Nagai's style of satirical realism while emphasizing the social issues depicted on the play.\n\nChekhov's works have been adapted for the screen, including Sidney Lumet's \"Sea Gull\" and Louis Malle's \"Vanya on 42nd Street\". His work has also served as inspiration or been referenced in numerous films. In Andrei Tarkovsky's 1975 film \"The Mirror\", characters discuss his short story \"Ward No. 6\". Plays by Chekhov are also referenced in Francois Truffaut's 1980 drama film \"The Last Metro\", which is set in a theater. A portion of a stage production of \"Three Sisters\" appears in the 2014 drama film \"Still Alice\".\n\n\nBiographical\nWorks\n", "id": "2447", "title": "Anton Chekhov"}
{"url": "https://en.wikipedia.org/wiki?curid=2448", "text": "Action Against Hunger\n\nAction Against Hunger is a global humanitarian organization committed to ending world hunger. The organization helps malnourished children whilst providing communities with access to safe water and sustainable solutions to hunger.\n\nAction Against Hunger was established in 1979 by a group of French doctors, scientists, and writers. Nobel Prize-winning physicist Alfred Kastler served as the organization's first chairman.\n\nThe group initially provided assistance to Afghanistan refugees in Pakistan, famine-stricken Ugandan communities, and Cambodian refugees in Thailand. It expanded to address additional humanitarian concerns in Africa, the Middle East, Southeast Asia, the Balkans and elsewhere during the 1980s and 1990s. Action Against Hunger's Scientific Committee pioneered the therapeutic milk formula (F100), now used by all major humanitarian aid organizations to treat acute malnutrition. As a result, the global mortality rate of severely malnourished children under the age of five has been reduced from 25% to 5%. A few years later, therapeutic milk was repackaged as ready-to-use therapeutic foods (RUTFs), a peanut-based paste packaged like a power bar. These bars allow for the treatment of malnutrition at home, and do not require any preparation or refrigeration.\n\nAction Against Hunger – USA was established in 1997. The international network currently has headquarters in five countries – France, Spain, the United States, Canada, and the UK. Its four main areas of work include nutrition, food security, water and sanitation, and advocacy.\n\nAction Against Hunger's Restaurants Against Hunger Campaign partners with leaders from the food and beverage industry to bring attention to global hunger. Each year, the campaign raises funds and support for Action Against Hunger's programs.\n\n", "id": "2448", "title": "Action Against Hunger"}
{"url": "https://en.wikipedia.org/wiki?curid=2452", "text": "AW\n\nA&W, AW, Aw, aW or aw may refer to:\n\n\n\n\n\n\n", "id": "2452", "title": "AW"}
{"url": "https://en.wikipedia.org/wiki?curid=2457", "text": "Apoptosis\n\nApoptosis (from Ancient Greek ἀπόπτωσις \"falling off\") is a process of programmed cell death that occurs in multicellular organisms. Biochemical events lead to characteristic cell changes (morphology) and death. These changes include blebbing, cell shrinkage, nuclear fragmentation, chromatin condensation, chromosomal DNA fragmentation, and global mRNA decay. Between 50 and 70 billion cells die each day due to apoptosis in the average human adult. For an average child between the ages of 8 and 14, approximately 20 billion to 30 billion cells die a day.\n\nIn contrast to necrosis, which is a form of traumatic cell death that results from acute cellular injury, apoptosis is a highly regulated and controlled process that confers advantages during an organism's lifecycle. For example, the separation of fingers and toes in a developing human embryo occurs because cells between the digits undergo apoptosis. Unlike necrosis, apoptosis produces cell fragments called apoptotic bodies that phagocytic cells are able to engulf and quickly remove before the contents of the cell can spill out onto surrounding cells and cause damage to the neighboring cells.\n\nBecause apoptosis cannot stop once it has begun, it is a highly regulated process. Apoptosis can be initiated through one of two pathways. In the \"intrinsic pathway\" the cell kills itself because it senses cell stress, while in the \"extrinsic pathway\" the cell kills itself because of signals from other cells. Both pathways induce cell death by activating caspases, which are proteases, or enzymes that degrade proteins. The two pathways both activate initiator caspases, which then activate executioner caspases, which then kill the cell by degrading proteins indiscriminately.\n\nResearch on apoptosis has increased substantially since the early 1990s. In addition to its importance as a biological phenomenon, defective apoptotic processes have been implicated in a wide variety of diseases. Excessive apoptosis causes atrophy, whereas an insufficient amount results in uncontrolled cell proliferation, such as cancer.\nSome factors like Fas receptors and caspases promote apoptosis, while some members of the Bcl-2 family of proteins inhibit apoptosis.\n\nGerman scientist Karl Vogt was first to describe the principle of apoptosis in 1842. In 1885, anatomist Walther Flemming delivered a more precise description of the process of programmed cell death. However, it was not until 1965 that the topic was resurrected. While studying tissues using electron microscopy, John Foxton Ross Kerr at University of Queensland was able to distinguish apoptosis from traumatic cell death. Following the publication of a paper describing the phenomenon, Kerr was invited to join Alastair R Currie, as well as Andrew Wyllie, who was Currie's graduate student, at University of Aberdeen. In 1972, the trio published a seminal article in the British Journal of Cancer. Kerr had initially used the term programmed cell necrosis, but in the article, the process of natural cell death was called \"apoptosis\". Kerr, Wyllie and Currie credited James Cormack, a professor of Greek language at University of Aberdeen, with suggesting the term apoptosis. Kerr received the Paul Ehrlich and Ludwig Darmstaedter Prize on March 14, 2000, for his description of apoptosis. He shared the prize with Boston biologist H. Robert Horvitz.\n\nFor many years, the terms \"apoptosis\" and \"programmed cell death\" were not highly cited. What transformed cell death from obscurity to a major field of research were two things: the identification of components of the cell death control and effector mechanisms, and the linkage of abnormalities in cell death to human disease, in particular cancer.\n\nThe 2002 Nobel Prize in Medicine was awarded to Sydney Brenner, Horvitz and John E. Sulston for their work identifying genes that control apoptosis. The genes were identified by studies in the nematode \"C. elegans\" and homologues of these genes function in humans to regulate apoptosis.\nIn Greek, apoptosis translates to the \"falling off\" of leaves from a tree. Cormack, professor of Greek language, reintroduced the term for medical use as it had a medical meaning for the Greeks over two thousand years before. Hippocrates used the term to mean \"the falling off of the bones\". Galen extended its meaning to \"the dropping of the scabs\". Cormack was no doubt aware of this usage when he suggested the name. Debate continues over the correct pronunciation, with opinion divided between a pronunciation with the second \"p\" silent ( ) and the second \"p\" pronounced (), as in the original Greek. In English, the \"p\" of the Greek \"-pt-\" consonant cluster is typically silent at the beginning of a word (e.g. pterodactyl, Ptolemy), but articulated when used in combining forms preceded by a vowel, as in helicopter or the orders of insects: diptera, lepidoptera, etc.\n\nIn the original Kerr, Wyllie & Currie paper, there is a footnote regarding the pronunciation:\n\n\"We are most grateful to Professor James Cormack of the Department of Greek, University of Aberdeen, for suggesting this term. The word \"apoptosis\" () is used in Greek to describe the \"dropping off\" or \"falling off\" of petals from flowers, or leaves from trees. To show the derivation clearly, we propose that the stress should be on the penultimate syllable, the second half of the word being pronounced like \"ptosis\" (with the \"p\" silent), which comes from the same root \"to fall\", and is already used to describe the drooping of the upper eyelid.\"\n\nThe initiation of apoptosis is tightly regulated by activation mechanisms, because once apoptosis has begun, it inevitably leads to the death of the cell. The two best-understood activation mechanisms are the intrinsic pathway (also called the mitochondrial pathway) and the extrinsic pathway. The \"intrinsic pathway\" is activated by intracellular signals generated when cells are stressed and depends on the release of proteins from the intermembrane space of mitochondria. The \"extrinsic pathway\" is activated by extracellular ligands binding to cell-surface death receptors, which leads to the formation of the death-inducing signaling complex (DISC).\n\nA cell initiates intracellular apoptotic signaling in response to a stress, which may bring about cell suicide. The binding of nuclear receptors by glucocorticoids, heat, radiation, nutrient deprivation, viral infection, hypoxia and increased intracellular calcium concentration,\nfor example, by damage to the membrane, can all trigger the release of intracellular apoptotic signals by a damaged cell. A number of cellular components, such as poly ADP ribose polymerase, may also help regulate apoptosis.\n\nBefore the actual process of cell death is precipitated by enzymes, apoptotic signals must cause regulatory proteins to initiate the apoptosis pathway. This step allows those signals to cause cell death, or the process to be stopped, should the cell no longer need to die. Several proteins are involved, but two main methods of regulation have been identified: the targeting of mitochondria functionality, or directly transducing the signal via adaptor proteins to the apoptotic mechanisms. An extrinsic pathway for initiation identified in several toxin studies is an increase in calcium concentration within a cell caused by drug activity, which also can cause apoptosis via a calcium binding protease calpain.\n\nThe mitochondria are essential to multicellular life. Without them, a cell ceases to respire aerobically and quickly dies. This fact forms the basis for some apoptotic pathways. Apoptotic proteins that target mitochondria affect them in different ways. They may cause mitochondrial swelling through the formation of membrane pores, or they may increase the permeability of the mitochondrial membrane and cause apoptotic effectors to leak out. They are very closely related to intrinsic pathway, and tumors arise more frequently through intrinsic pathway than the extrinsic pathway because of sensitivity. There is also a growing body of evidence indicating that nitric oxide is able to induce apoptosis by helping to dissipate the membrane potential of mitochondria and therefore make it more permeable. Nitric oxide has been implicated in initiating and inhibiting apoptosis through its possible action as a signal molecule of subsequent pathways that activate apoptosis.\n\nMitochondrial proteins known as SMACs (second mitochondria-derived activator of caspases) are released into the cell's cytosol following the increase in permeability of the mitochondia membranes. SMAC binds to \"proteins that inhibit apoptosis\" (IAPs) thereby deactivating them, and preventing the IAPs from arresting the process and therefore allowing apoptosis to proceed. IAP also normally suppresses the activity of a group of cysteine proteases called caspases, which carry out the degradation of the cell. Therefore, the actual degradation enzymes can be seen to be indirectly regulated by mitochondrial permeability.\n\nCytochrome c is also released from mitochondria due to formation of a channel, the mitochondrial apoptosis-induced channel (MAC), in the outer mitochondrial membrane, and serves a regulatory function as it precedes morphological change associated with apoptosis. Once cytochrome c is released it binds with Apoptotic protease activating factor – 1 (\"Apaf-1\") and ATP, which then bind to \"pro-caspase-9\" to create a protein complex known as an apoptosome. The apoptosome cleaves the pro-caspase to its active form of caspase-9, which in turn activates the effector \"caspase-3\".\n\nMAC (not to be confused with the Membrane Attack Complex formed by complement activation, also commonly denoted as MAC), also called \"Mitochondrial Outer Membrane Permeabilization Pore\" is regulated by various proteins, such as those encoded by the mammalian Bcl-2 family of anti-apoptopic genes, the homologs of the \"ced-9\" gene found in \"C. elegans\". \"Bcl-2\" proteins are able to promote or inhibit apoptosis by direct action on MAC/MOMPP. Bax and/or Bak form the pore, while Bcl-2, Bcl-xL or Mcl-1 inhibit its formation.\n\nTwo theories of the direct initiation of apoptotic mechanisms in mammals have been suggested: the \"TNF-induced\" (tumor necrosis factor) model and the \"Fas-Fas ligand-mediated\" model, both involving receptors of the \"TNF receptor\" (TNFR) family coupled to extrinsic signals.\n\nTNF path\n\nTNF-alpha is a cytokine produced mainly by activated macrophages, and is the major extrinsic mediator of apoptosis. Most cells in the human body have two receptors for TNF-alpha: TNFR1 and TNFR2. The binding of TNF-alpha to TNFR1 has been shown to initiate the pathway that leads to caspase activation via the intermediate membrane proteins TNF receptor-associated death domain (TRADD) and Fas-associated death domain protein (FADD). cIAP1/2 can inhibit TNF-α signaling by binding to TRAF2. FLIP inhibits the activation of caspase-8. Binding of this receptor can also indirectly lead to the activation of transcription factors involved in cell survival and inflammatory responses. However, signalling through TNFR1 might also induce apoptosis in a caspase-independent manner. The link between TNF-alpha and apoptosis shows why an abnormal production of TNF-alpha plays a fundamental role in several human diseases, especially in autoimmune diseases.\n\nFas path\n\nThe fas receptor (First apoptosis signal) – (also known as \"Apo-1\" or \"CD95\") is a transmembrane protein of the TNF family which binds the Fas ligand (FasL). The interaction between Fas and FasL results in the formation of the \"death-inducing signaling complex\" (DISC), which contains the FADD, caspase-8 and caspase-10. In some types of cells (type I), processed caspase-8 directly activates other members of the caspase family, and triggers the execution of apoptosis of the cell. In other types of cells (type II), the \"Fas\"-DISC starts a feedback loop that spirals into increasing release of proapoptotic factors from mitochondria and the amplified activation of caspase-8.\n\nCommon components\n\nFollowing \"TNF-R1\" and \"Fas\" activation in mammalian cells a balance between proapoptotic (BAX, BID, BAK, or BAD) and anti-apoptotic (\"Bcl-Xl\" and \"Bcl-2\") members of the \"Bcl-2\" family is established. This balance is the proportion of proapoptotic homodimers that form in the outer-membrane of the mitochondrion. The proapoptotic homodimers are required to make the mitochondrial membrane permeable for the release of caspase activators such as cytochrome c and SMAC. Control of proapoptotic proteins under normal cell conditions of nonapoptotic cells is incompletely understood, but in general, Bax or Bak are activated by the activation of BH3-only proteins, part of the Bcl-2 family.\n\nCaspases\nCaspases play the central role in the transduction of ER apoptotic signals. Caspases are proteins that are highly conserved, cysteine-dependent aspartate-specific proteases. There are two types of caspases: initiator caspases, caspase 2,8,9,10,11,12, and effector caspases, caspase 3,6,7. The activation of initiator caspases requires binding to specific oligomeric activator protein. Effector caspases are then activated by these active initiator caspases through proteolytic cleavage. The active effector caspases then proteolytically degrade a host of intracellular proteins to carry out the cell death program.\n\nCaspase-independent apoptotic pathway\nThere also exists a caspase-independent apoptotic pathway that is mediated by AIF (apoptosis-inducing factor).\n\n Amphibian frog \"Xenopus laevis\" serves as an ideal model system for the study of the mechanisms of apoptosis. In fact, iodine and thyroxine also stimulate the spectacular apoptosis of the cells of the larval gills, tail and fins in amphibians metamorphosis, and stimulate the evolution of their nervous system transforming the aquatic, vegetarian tadpole into the terrestrial, carnivorous frog.\n\nMany pathways and signals lead to apoptosis, but these converge on a single mechanism that actually causes the death of the cell. After a cell receives stimulus, it undergoes organized degradation of cellular organelles by activated proteolytic caspases. In addition to the destruction of cellular organelles, mRNA is rapidly and globally degraded by a mechanism that is not yet fully characterized. mRNA decay is triggered very early in apoptosis.\nA cell undergoing apoptosis shows a characteristic morphology:\nApoptosis progresses quickly and its products are quickly removed, making it difficult to detect or visualize. During karyorrhexis, endonuclease activation leaves short DNA fragments, regularly spaced in size. These give a characteristic \"laddered\" appearance on agar gel after electrophoresis Tests for DNA laddering differentiate apoptosis from ischemic or toxic cell death.\n\nThe removal of dead cells by neighboring phagocytic cells has been termed efferocytosis.\nDying cells that undergo the final stages of apoptosis display phagocytotic molecules, such as phosphatidylserine, on their cell surface. Phosphatidylserine is normally found on the inner leaflet surface of the plasma membrane, but is redistributed during apoptosis to the extracellular surface by a protein known as scramblase. These molecules mark the cell for phagocytosis by cells possessing the appropriate receptors, such as macrophages. The removal of dying cells by phagocytes occurs in an orderly manner without eliciting an inflammatory response.\n\nMany knock-outs have been made in the apoptosis pathways to test the function of each of the proteins. Several caspases, in addition to APAF-1 and FADD, have been mutated to determine the new phenotype. In order to create a tumor necrosis factor (TNF) knockout, an exon containing the nucleotides 3704-5364 was removed from the gene. This exon encodes a portion of the mature TNF domain, as well as the leader sequence, which is a highly conserved region necessary for proper intracellular processing. TNF-/- mice develop normally and have no gross structural or morphological abnormalities. However, upon immunization with SRBC (sheep red blood cells), these mice demonstrated a deficiency in the maturation of an antibody response; they were able to generate normal levels of IgM, but could not develop specific IgG levels. Apaf-1 is the protein that turns on caspase 9 by cleavage to begin the caspase cascade that leads to apoptosis. Since a -/- mutation in the APAF-1 gene is embryonic lethal, a gene trap strategy was used in order to generate an APAF-1 -/- mouse. This assay is used to disrupt gene function by creating an intragenic gene fusion. When an APAF-1 gene trap is introduced into cells, many morphological changes occur, such as spina bifida, the persistence of interdigital webs, and open brain. In addition, after embryonic day 12.5, the brain of the embryos showed several structural changes. APAF-1 cells are protected from apoptosis stimuli such as irradiation. A BAX-1 knock-out mouse exhibits normal forebrain formation and a decreased programmed cell death in some neuronal populations and in the spinal cord, leading to an increase in motor neurons.\n\nThe caspase proteins are integral parts of the apoptosis pathway, so it follows that knock-outs made have varying damaging results. A caspase 9 knock-out leads to a severe brain malformation. A caspase 8 knock-out leads to cardiac failure and thus embryonic lethality. However, with the use of cre-lox technology, a caspase 8 knock-out has been created that exhibits an increase in peripheral T cells, an impaired T cell response, and a defect in neural tube closure. These mice were found to be resistant to apoptosis mediated by CD95, TNFR, etc. but not resistant to apoptosis caused by UV irradiation, chemotherapeutic drugs, and other stimuli. Finally, a caspase 3 knock-out was characterized by ectopic cell masses in the brain and abnormal apoptotic features such as membrane blebbing or nuclear fragmentation. A remarkable feature of these KO mice is that they have a very restricted phenotype: Casp3, 9, APAF-1 KO mice have deformations of neural tissue and FADD and Casp 8 KO showed defective heart development, however in both types of KO other organs developed normally and some cell types were still sensitive to apoptotic stimuli suggesting that unknown proapoptotic pathways exist.\n\nIn order to perform analysis of apoptotic versus necrotic (necroptotic) cells, one can do analysis of morphology by time-lapse microscopy, flow fluorocytometry, and transmission electron microscopy. There are also various biochemical techniques for analysis of cell surface markers (phosphatidylserine exposure versus cell permeability by flow fluorocytometry), cellular markers such as DNA fragmentation (flow cytometry), caspase activation, Bid cleavage, and cytochrome c release (Western blotting). It is important to know how primary and secondary necrotic cells can be distinguished by analysis of supernatant for caspases, HMGB1, and release of cytokeratin 18. However, no distinct surface or biochemical markers of necrotic cell death have been identified yet, and only negative markers are available. These include absence of apoptotic markers (caspase activation, cytochrome c release, and oligonucleosomal DNA fragmentation) and differential kinetics of cell death markers (phosphatidylserine exposure and cell membrane permeabilization). A selection of techniques that can be used to distinguish apoptosis from necroptotic cells could be found in these references.\n\nThe many different types of apoptotic pathways contain a multitude of different biochemical components, many of them not yet understood. As a pathway is more or less sequential in nature, removing or modifying one component leads to an effect in another. In a living organism, this can have disastrous effects, often in the form of disease or disorder. A discussion of every disease caused by modification of the various apoptotic pathways would be impractical, but the concept overlying each one is the same: The normal functioning of the pathway has been disrupted in such a way as to impair the ability of the cell to undergo normal apoptosis. This results in a cell that lives past its \"use-by-date\" and is able to replicate and pass on any faulty machinery to its progeny, increasing the likelihood of the cell's becoming cancerous or diseased.\n\nA recently described example of this concept in action can be seen in the development of a lung cancer called NCI-H460. The \"X-linked inhibitor of apoptosis protein\" (XIAP) is overexpressed in cells of the H460 cell line. XIAPs bind to the processed form of caspase-9, and suppress the activity of apoptotic activator cytochrome c, therefore overexpression leads to a decrease in the amount of proapoptotic agonists. As a consequence, the balance of anti-apoptotic and proapoptotic effectors is upset in favour of the former, and the damaged cells continue to replicate despite being directed to die.\n\nThe tumor-suppressor protein p53 accumulates when DNA is damaged due to a chain of biochemical factors. Part of this pathway includes alpha-interferon and beta-interferon, which induce transcription of the \"p53\" gene, resulting in the increase of p53 protein level and enhancement of cancer cell-apoptosis. p53 prevents the cell from replicating by stopping the cell cycle at G1, or interphase, to give the cell time to repair, however it will induce apoptosis if damage is extensive and repair efforts fail. Any disruption to the regulation of the \"p53\" or interferon genes will result in impaired apoptosis and the possible formation of tumors.\n\nInhibition of apoptosis can result in a number of cancers, autoimmune diseases, inflammatory diseases, and viral infections. It was originally believed that the associated accumulation of cells was due to an increase in cellular proliferation, but it is now known that it is also due to a decrease in cell death. The most common of these diseases is cancer, the disease of excessive cellular proliferation, which is often characterized by an overexpression of IAP family members. As a result, the malignant cells experience an abnormal response to apoptosis induction: Cycle-regulating genes (such as p53, ras or c-myc) are mutated or inactivated in diseased cells, and further genes (such as bcl-2) also modify their expression in tumors.\n\nApoptosis in HeLa cells is inhibited by proteins produced by the cell; these inhibitory proteins target retinoblastoma tumor-suppressing proteins. These tumor-suppressing proteins regulate the cell cycle, but are rendered inactive when bound to an inhibitory protein. HPV E6 and E7 are inhibitory proteins expressed by the human papillomavirus, HPV being responsible for the formation of the cervical tumor from which HeLa cells are derived. HPV E6 causes p53, which regulates the cell cycle, to become inactive. HPV E7 binds to retinoblastoma tumor suppressing proteins and limits its ability to control cell division. These two inhibitory proteins are partially responsible for HeLa cells' immortality by inhibiting apoptosis to occur. CDV (Canine Distemper Virus) is able to induce apoptosis despite the presence of these inhibitory proteins. This is an important oncolytic property of CDV: this virus is capable of killing canine lymphoma cells. Oncoproteins E6 and E7 still leave p53 inactive, but they are not able to avoid the activation of caspases induced from the stress of viral infection. These oncolytic properties provided a promising link between CDV and lymphoma apoptosis, which can lead to development of alternative treatment methods for both canine lymphoma and human non-Hodgkin lymphoma. Defects in the cell cycle are thought to be responsible for the resistance to chemotherapy or radiation by certain tumor cells, so a virus that can induce apoptosis despite defects in the cell cycle is useful for cancer treatment.\n\nThe main method of treatment for death from signaling-related diseases involves either increasing or decreasing the susceptibility of apoptosis in diseased cells, depending on whether the disease is caused by either the inhibition of or excess apoptosis. For instance, treatments aim to restore apoptosis to treat diseases with deficient cell death, and to increase the apoptotic threshold to treat diseases involved with excessive cell death. To stimulate apoptosis, one can increase the number of death receptor ligands (such as TNF or TRAIL), antagonize the anti-apoptotic Bcl-2 pathway, or introduce Smac mimetics to inhibit the inhibitor (IAPs). The addition of agents such as Herceptin, Iressa, or Gleevec works to stop cells from cycling and causes apoptosis activation by blocking growth and survival signaling further upstream. Finally, adding p53-MDM2 complexes displaces p53 and activates the p53 pathway, leading to cell cycle arrest and apoptosis. Many different methods can be used either to stimulate or to inhibit apoptosis in various places along the death signaling pathway.\n\nApoptosis is a multi-step, multi-pathway cell-death programme that is inherent in every cell of the body. In cancer, the apoptosis cell-division ratio is altered. Cancer treatment by chemotherapy and irradiation kills target cells primarily by inducing apoptosis.\n\nOn the other hand, loss of control of cell death (resulting in excess apoptosis) can lead to neurodegenerative diseases, hematologic diseases, and tissue damage. The progression of HIV is directly linked to excess, unregulated apoptosis. In a healthy individual, the number of CD4+ lymphocytes is in balance with the cells generated by the bone marrow; however, in HIV-positive patients, this balance is lost due to an inability of the bone marrow to regenerate CD4+ cells. In the case of HIV, CD4+ lymphocytes die at an accelerated rate through uncontrolled apoptosis, when stimulated.\n\nTreatments aiming to inhibit works to block specific caspases. Finally, the Akt protein kinase promotes cell survival through two pathways. Akt phosphorylates and inhibits Bas (a Bcl-2 family member), causing Bas to interact with the 14-3-3 scaffold, resulting in Bcl dissociation and thus cell survival. Akt also activates IKKα, which leads to NF-κB activation and cell survival. Active NF-κB induces the expression of anti-apoptotic genes such as Bcl-2, resulting in inhibition of apoptosis. NF-κB has been found to play both an antiapoptotic role and a proapoptotic role depending on the stimuli utilized and the cell type.\n\nThe progression of the human immunodeficiency virus infection into AIDS is due primarily to the depletion of CD4+ T-helper lymphocytes in a manner that is too rapid for the body's bone marrow to replenish the cells, leading to a compromised immune system. One of the mechanisms by which T-helper cells are depleted is apoptosis, which results from a series of biochemical pathways:\n\nCells may also die as direct consequences of viral infections. HIV-1 expression induces tubular cell G2/M arrest and apoptosis. The progression from HIV to AIDS is not immediate or even necessarily rapid; HIV's cytotoxic activity toward CD4+ lymphocytes is classified as AIDS once a given patient's CD4+ cell count falls below 200.\n\nViral induction of apoptosis occurs when one or several cells of a living organism are infected with a virus, leading to cell death. Cell death in organisms is necessary for the normal development of cells and the cell cycle maturation. It is also important in maintaining the regular functions and activities of cells.\n\nViruses can trigger apoptosis of infected cells via a range of mechanisms including:\nCanine distemper virus (CDV) is known to cause apoptosis in central nervous system and lymphoid tissue of infected dogs in vivo and in vitro.\nApoptosis caused by CDV is typically induced via the extrinsic pathway, which activates caspases that disrupt cellular function and eventually leads to the cells death. In normal cells, CDV activates caspase-8 first, which works as the initiator protein followed by the executioner protein caspase-3. However, apoptosis induced by CDV in HeLa cells does not involve the initiator protein caspase-8. HeLa cell apoptosis caused by CDV follows a different mechanism than that in vero cell lines. This change in the caspase cascade suggests CDV induces apoptosis via the intrinsic pathway, excluding the need for the initiator caspase-8. The executioner protein is instead activated by the internal stimuli caused by viral infection not a caspase cascade.\n\nThe Oropouche virus (OROV) is found in the family \"Bunyaviridae\". The study of apoptosis brought on by \"Bunyaviridae\" was initiated in 1996, when it was observed that apoptosis was induced by the La Crosse virus into the kidney cells of baby hamsters and into the brains of baby mice.\n\nOROV is a disease that is transmitted between humans by the biting midge (\"Culicoides paraensis\"). It is referred to as a zoonotic arbovirus and causes febrile illness, characterized by the onset of a sudden fever known as Oropouche fever.\n\nThe Oropouche virus also causes disruption in cultured cells – cells that are cultivated in distinct and specific conditions. An example of this can be seen in HeLa cells, whereby the cells begin to degenerate shortly after they are infected.\n\nWith the use of gel electrophoresis, it can be observed that OROV causes DNA fragmentation in HeLa cells. It can be interpreted by counting, measuring, and analyzing the cells of the Sub/G1 cell population. When HeLA cells are infected with OROV, the cytochrome C is released from the membrane of the mitochondria, into the cytosol of the cells. This type of interaction shows that apoptosis is activated via an intrinsic pathway.\n\nIn order for apoptosis to occur within OROV, viral uncoating, viral internalization, along with the replication of cells is necessary. Apoptosis in some viruses is activated by extracellular stimuli. However, studies have demonstrated that the OROV infection causes apoptosis to be activated through intracellular stimuli and involves the mitochondria.\n\nMany viruses encode proteins that can inhibit apoptosis. Several viruses encode viral homologs of Bcl-2. These homologs can inhibit proapoptotic proteins such as BAX and BAK, which are essential for the activation of apoptosis. Examples of viral Bcl-2 proteins include the Epstein-Barr virus BHRF1 protein and the adenovirus E1B 19K protein. Some viruses express caspase inhibitors that inhibit caspase activity and an example is the CrmA protein of cowpox viruses. Whilst a number of viruses can block the effects of TNF and Fas. For example, the M-T2 protein of myxoma viruses can bind TNF preventing it from binding the TNF receptor and inducing a response. Furthermore, many viruses express p53 inhibitors that can bind p53 and inhibit its transcriptional transactivation activity. As a consequence, p53 cannot induce apoptosis, since it cannot induce the expression of proapoptotic proteins. The adenovirus E1B-55K protein and the hepatitis B virus HBx protein are examples of viral proteins that can perform such a function.\n\nViruses can remain intact from apoptosis in particular in the latter stages of infection. They can be exported in the \"apoptotic bodies\" that pinch off from the surface of the dying cell, and the fact that they are engulfed by phagocytes prevents the initiation of a host response. This favours the spread of the virus.\n\nProgrammed cell death in plants has a number of molecular similarities to that of animal apoptosis, but it also has differences, notable ones being the presence of a cell wall and the lack of an immune system that removes the pieces of the dead cell. Instead of an immune response, the dying cell synthesizes substances to break itself down and places them in a vacuole that ruptures as the cell dies. Whether this whole process resembles animal apoptosis closely enough to warrant using the name \"apoptosis\" (as opposed to the more general \"programmed cell death\") is unclear.\n\nThe characterization of the caspases allowed the development of caspase inhibitors, which can be used to determine whether a cellular process involves active caspases. Using these inhibitors it was discovered that cells can die while displaying a morphology similar to apoptosis without caspase activation. Later studies linked this phenomenon to the release of AIF (apoptosis-inducing factor) from the mitochondria and its translocation into the nucleus mediated by its NLS (nuclear localization signal). Inside the mitochondria, AIF is anchored to the inner membrane. In order to be released, the protein is cleaved by a calcium-dependent calpain protease.\n\nIn 2003, a method was developed for predicting subcellular location of apoptosis proteins.\nSubsequent to this, various modes of Chou's pseudo amino acid composition were developed for improving the quality of predicting subcellular localization of apoptosis proteins based on their sequence information alone.\n\n", "id": "2457", "title": "Apoptosis"}
{"url": "https://en.wikipedia.org/wiki?curid=2459", "text": "Appomattox\n\nAppomattox may refer to:\n", "id": "2459", "title": "Appomattox"}
{"url": "https://en.wikipedia.org/wiki?curid=2460", "text": "Anal sex\n\nAnal sex or anal intercourse is generally the insertion and thrusting of the erect penis into a person's anus, or anus and rectum, for sexual pleasure. Other forms of anal sex include fingering, the use of sex toys for anal penetration, oral sex performed on the anus (anilingus), and pegging. Although the term \"anal sex\" most commonly means penile-anal penetration, sources sometimes use the term \"anal intercourse\" to refer exclusively to penile-anal penetration, and \"anal sex\" to refer to any form of anal sexual activity, especially between pairings as opposed to anal masturbation.\n\nWhile anal sex is commonly associated with male homosexuality, research shows that not all gay males engage in anal sex and that it is not uncommon in heterosexual relationships. Types of anal sex can also be a part of lesbian sexual practices. People may experience pleasure from anal sex by stimulation of the anal nerve endings, and orgasm may be achieved through anal penetration – by indirect stimulation of the prostate in men, indirect stimulation of the clitoris or an area of the vagina (sometimes termed \"the G-spot\") in women, and other sensory nerves (especially the pudendal nerve). However, people may also find anal sex painful, sometimes extremely so, which may be primarily due to psychological factors in some cases.\n\nAs with most forms of sexual activity, anal sex participants risk contracting sexually transmitted infections (STIs/STDs). Anal sex is considered a high-risk sexual practice because of the vulnerability of the anus and rectum. The anal and rectal tissues are delicate and do not provide lubrication like the vagina does, so they can easily tear and permit disease transmission, especially if a personal lubricant is not used. Anal sex without protection of a condom is considered the riskiest form of sexual activity, and therefore health authorities such as the World Health Organization (WHO) recommend safe sex practices for anal sex.\n\nStrong views are often expressed about anal sex. It is controversial in various cultures, especially with regard to religious prohibitions. This is commonly due to prohibitions against anal sex among males or teachings about the procreative purpose of sexual activity. It may be regarded as taboo or unnatural, and is a criminal offense in some countries, punishable by corporal or capital punishment; by contrast, people also regard anal sex as a natural and valid form of sexual activity that may be as fulfilling as other desired sexual expressions. They may regard it as an enhancing element of their sex lives or as their primary form of sexual activity.\n\nThe abundance of nerve endings in the anal region and rectum can make anal sex pleasurable for men or women. The internal and external sphincter muscles control the opening and closing of the anus; these muscles, which are sensitive membranes made up of many nerve endings, facilitate pleasure or pain during anal sex. The \"Human Sexuality: An Encyclopedia\" states that \"the inner third of the anal canal is less sensitive to touch than the outer two-thirds, but is more sensitive to pressure\" and that \"the rectum is a curved tube about eight or nine inches long and has the capacity, like the anus, to expand\".\n\nResearch indicates that anal sex occurs significantly less frequently than other sexual behaviors, but its association with dominance and submission, as well as taboo, makes it an appealing stimulus to people of all sexual orientations. In addition to sexual penetration by the penis, people may use sex toys such as butt plugs or anal beads, engage in fingering, anilingus, pegging, anal masturbation or fisting for anal sexual activity, and different sex positions may also be included. Fisting is the least practiced of the activities, partly because it is uncommon that people can relax enough to accommodate an object as big as a fist being inserted into the anus.\n\nIn a male receptive partner, being anally penetrated can produce a pleasurable sensation due to the inserted penis rubbing or brushing against the prostate (also known as the \"male G-spot\") through the anal wall. This can result in pleasurable sensations and can lead to an orgasm in some cases. Prostate stimulation can produce a \"deeper\" orgasm, sometimes described by men as more widespread and intense, longer-lasting, and allowing for greater feelings of ecstasy than orgasm elicited by penile stimulation only. The prostate is located next to the rectum and is the larger, more developed male homologue (variation) to the female Skene's glands. However, though the experiences are different, male orgasms by penile stimulation are also centered in the prostate gland. It is also typical for a man to not reach orgasm as a receptive partner solely from anal sex.\n\nGeneral statistics indicate that 70–80% of women require direct clitoral stimulation to achieve orgasm. The clitoris is composed of more than the externally visible glans (head). With its glans or body as a whole estimated to have around 8,000 sensory nerve endings, the clitoris surrounds the vagina and urethra, and may have a similar connection with the anus. The vagina is flanked on each side by the clitoral crura, the internal \"legs\" of the clitoris, which are highly sensitive and become engorged with blood when sexually aroused. In addition to nerve endings present within the anus and rectum, women may find anal stimulation pleasurable due to indirect stimulation of these \"legs\". Indirect stimulation of the clitoris through anal penetration may also be caused by the shared sensory nerves, especially the pudendal nerve, which gives off the inferior anal nerves and divides into two terminal branches: the perineal nerve and the dorsal nerve of the clitoris.\n\nThe Gräfenberg spot, or G-spot, is a debated area of female anatomy, particularly among doctors and researchers, but it is typically described as being located behind the female pubic bone surrounding the urethra and accessible through the anterior wall of the vagina; it and other areas of the vagina are considered to have tissue and nerves that are related to the clitoris. Besides the shared anatomy of the aforementioned sensory nerves, orgasm by indirect stimulation of the clitoris or G-spot area through anal penetration may be possible because of the close proximity between the vaginal cavity and the rectal cavity. Achieving orgasm solely by anal stimulation is rare among women. Direct stimulation of the clitoris, a G-spot area, or both, during anal sex can help some women enjoy the activity and reach orgasm from it.\n\nStimulation from anal sex can additionally be affected by popular perception or portrayals of the activity, such as erotica or pornography. In pornography, anal sex is commonly portrayed as a desirable, painless routine that does not require personal lubricant; this can result in couples performing anal sex without care, and men and women believing that it is unusual for women, as receptive partners, to find discomfort or pain instead of pleasure from the activity. By contrast, each person's sphincter muscles react to penetration differently, the anal sphincters have tissues that are more prone to tearing, and the anus and rectum do not provide lubrication for sexual penetration like the vagina does. Researchers say adequate application of a personal lubricant, relaxation, and communication between sexual partners are crucial to avoid pain or damage to the anus or rectum. Additionally, ensuring that the anal area is clean and the bowel is empty, for both aesthetics and practicality, may be desired by participants.\n\nThe anal sphincters are usually tighter than the pelvic muscles of the vagina, which can enhance the sexual pleasure for the inserting male during male-to-female anal intercourse because of the pressure applied to the penis. Men may also enjoy the penetrative role during anal sex because of its association with dominance, because it is made more alluring by a female partner or society in general insisting that it is forbidden, or because it presents an additional option for penetration.\n\nWhile some women find being a receptive partner during anal intercourse painful or uncomfortable, or only engage in the act to please a male sexual partner, other women find the activity pleasurable or prefer it to vaginal intercourse. The vaginal walls contain significantly fewer nerve endings than the clitoris and anus, and therefore intense sexual pleasure, including orgasm, from vaginal sexual stimulation is less likely to occur than from direct clitoral stimulation in the majority of women. However, anal sexual stimulation is not necessarily more likely to result in orgasm than vaginal sexual stimulation; the types of nerves and how they interact with each other are factors. The belief that there is complete separation between the vagina and clitoris is a misconception aided by misunderstandings of what and how big the clitoris actually is.\n\nIn a 2010 clinical review article of heterosexual anal sex, the term \"anal intercourse\" is used to refer specifically to penile-anal penetration, and \"anal sex\" is used to refer to any form of anal sexual activity. The review suggests that anal sex is exotic among the sexual practices of some heterosexuals and that \"for a certain number of heterosexuals, anal intercourse is pleasurable, exciting, and perhaps considered more intimate than vaginal sex\".\n\nAnal intercourse is sometimes used as a substitute for vaginal intercourse during menstruation. The likelihood of pregnancy occurring during anal sex is greatly reduced, as anal sex alone cannot lead to pregnancy unless sperm is somehow transported to the vaginal opening. Because of this, some couples practice anal intercourse as a form of contraception, often in the absence of a condom.\n\nMale-to-female anal sex is commonly viewed as a way of preserving female virginity because it is non-procreative and does not tear the hymen; a person, especially a teenage girl or woman, who engages in anal sex or other sexual activity with no history of having engaged in vaginal intercourse is often regarded among heterosexuals and researchers as not having yet experienced virginity loss. This is sometimes termed \"technical virginity.\" Heterosexuals may view anal sex as \"fooling around\" or as foreplay; scholar Laura M. Carpenter stated that this view \"dates to the late 1600s, with explicit 'rules' appearing around the turn of the twentieth century, as in marriage manuals defining petting as 'literally every caress known to married couples but does not include complete sexual intercourse.'\"\n\nBecause most research on anal intercourse addresses men who have sex with men, little data exists on the prevalence of anal intercourse among heterosexual couples. In Kimberly R. McBride's 2010 clinical review on heterosexual anal intercourse and other forms of anal sexual activity, it is suggested that changing norms may affect the frequency of heterosexual anal sex. McBride and her colleagues investigated the prevalence of non-intercourse anal sex behaviors among a sample of men (n=1,299) and women (n=1,919) compared to anal intercourse experience and found that 51% of men and 43% of women had participated in at least one act of oral–anal sex, manual–anal sex, or anal sex toy use. The report states the majority of men (n=631) and women (n=856) who reported heterosexual anal intercourse in the past 12 months were in exclusive, monogamous relationships: 69% and 73%, respectively. The review added that because \"relatively little attention [is] given to anal intercourse and other anal sexual behaviors between heterosexual partners\", this means that it is \"quite rare\" to have research \"that specifically differentiates the anus as a sexual organ or addresses anal sexual function or dysfunction as legitimate topics. As a result, we do not know the extent to which anal intercourse differs qualitatively from coitus.\"\n\nAccording to a 2010 study from the National Survey of Sexual Health and Behavior (NSSHB) that was authored by Debby Herbenick et al., although anal intercourse is reported by fewer women than other partnered sex behaviors, partnered women in the age groups between 18–49 are significantly more likely to report having anal sex in the past 90 days. Women engaged in anal intercourse less commonly than men. Vaginal intercourse was practiced more than insertive anal intercourse among men, but 13% to 15% of men aged 25 to 49 practiced insertive anal intercourse.\n\nWith regard to adolescents, limited data also exists. This may be because of the taboo nature of anal sex and that teenagers and caregivers subsequently avoid talking to one another about the topic. It is also common for subject review panels and schools to avoid the subject. A 2000 study found that 22.9% of college students who self-identified as virgins had anal sex. They used condoms during anal sex 20.9% of the time as compared with 42.9% of the time with vaginal intercourse.\n\nAnal sex being more common among heterosexuals today than it was previously has been linked to the increase in consumption of anal pornography among men, especially among those who view it on a regular basis. Seidman et al. argued that \"cheap, accessible and, especially, interactive media have enabled many more people to produce as well as consume pornography\", and that this modern way of producing pornography, in addition to the buttocks and anus having become more eroticized, has led to a significant interest in or obsession with anal sex among men.\n\nHistorically, anal sex has been commonly associated with male homosexuality. However, many gay men and men who have sex with men in general (those who identify as gay, bisexual, heterosexual or have not identified their sexual identity) do not engage in anal sex. Among men who have anal sex with other men, the insertive partner may be referred to as the \"top\" and the one being penetrated may be referred to as the \"bottom\". Those who enjoy either role may be referred to as \"versatile\".\n\nGay men who prefer anal sex may view it as their version of intercourse and a natural expression of intimacy that is capable of providing pleasure. The notion that it might resonate with gay men with the same emotional significance that vaginal sex resonates with heterosexuals has also been considered. Some men who have sex with men, however, believe that being a receptive partner during anal sex questions their masculinity.\n\nMen who have sex with men may also prefer to engage in frot or other forms of mutual masturbation because they find it more pleasurable or more affectionate, to preserve technical virginity, or as safe sex alternatives to anal sex, while other frot advocates denounce anal sex as degrading to the receptive partner and unnecessarily risky.\n\nReports regarding the prevalence of anal sex among gay men and other men who have sex with men vary. A survey in \"The Advocate\" in 1994 indicated that 46% of gay men preferred to penetrate their partners, while 43% preferred to be the receptive partner. Other sources suggest that roughly three-fourths of gay men have had anal sex at one time or another, with an equal percentage participating as tops and bottoms. A 2012 NSSHB sex survey in the U.S. suggests high lifetime participation in anal sex among gay men: 83.3% report ever taking part in anal sex in the insertive position and 90% in the receptive position, even if only between a third and a quarter self-report very recent engagement in the practice, defined as 30 days or less.\n\nOral sex and mutual masturbation are more common than anal stimulation among men in sexual relationships with other men. According to Weiten et al., anal intercourse is generally more popular among gay male couples than among heterosexual couples, but \"it ranks behind oral sex and mutual masturbation\" among both sexual orientations in prevalence. Wellings et al. reported that \"the equation of 'homosexual' with 'anal' sex among men is common among lay and health professionals alike\" and that \"yet an Internet survey of 180,000 MSM across Europe (EMIS, 2011) showed that oral sex was most commonly practised, followed by mutual masturbation, with anal intercourse in third place\".\n\nWomen may sexually stimulate a man's anus by fingering the exterior or interior areas of the anus; they may also stimulate the perineum (which, for males, is between the base of the scrotum and the anus), massage the prostate or engage in anilingus. Sex toys, such as a dildo, may also be used. The practice of a woman penetrating a man's anus with a strap-on dildo for sexual activity is called pegging.\n\nCommonly, heterosexual men reject the idea of being receptive partners during anal sex because they believe it is a feminine act, can make them vulnerable, or contradicts their sexual orientation (for example, that it is indicative that they are gay). The \"BMJ\" stated in 1999, however:There are little published data on how many heterosexual men would like their anus to be sexually stimulated in a heterosexual relationship. Anecdotally, it is a substantial number. What data we do have almost all relate to penetrative sexual acts, and the superficial contact of the anal ring with fingers or the tongue is even less well documented but may be assumed to be a common sexual activity for men of all sexual orientations.\n\nReece et al. reported in 2010 that receptive anal intercourse is infrequent among men overall, stating that \"an estimated 7% of men 14 to 94 years old reported being a receptive partner during anal intercourse\".\n\nWith regard to lesbian sexual practices, anal sex includes fingering, use of a dildo or other sex toys, or anilingus. Some lesbians do not like anal sex, and anilingus is less often practiced among female same-sex couples.\n\nThere is less research on anal sexual activity among women who have sex with women compared to couples of other sexual orientations. In 1987, a non-scientific study (Munson) was conducted of more than 100 members of a lesbian social organization in Colorado. When asked what techniques they used in their last ten sexual encounters, lesbians in their 30s were twice as likely as other age groups to engage in anal stimulation (with a finger or dildo). While author Tom Boellstorff, when particularly examining anal sex among gay and lesbian individuals in Indonesia, stated that he had not heard of oral-anal contact or anal penetration as recognized forms of lesbian sexuality but assume they take place, author Felice Newman cites anal sex as a part of lesbian sexual practices. A 2014 study of partnered lesbian women in Canada and the U.S. found that 7% engaged in anal stimulation or penetration at least once a week; about 10% did so monthly and 70% did not at all.\n\nAnal sex can expose its participants to two principal dangers: infections due to the high number of infectious microorganisms not found elsewhere on the body, and physical damage to the anus and rectum due to their fragility. Unprotected penile-anal penetration, colloquially known as \"barebacking\", carries a higher risk of passing on sexually transmitted infections (STIs/STDs) because the anal sphincter is a delicate, easily torn tissue that can provide an entry for pathogens. The high concentration of white blood cells around the rectum, together with the risk of tearing and the colon's function to absorb fluid, are what place those who engage in anal sex at high risk of STIs. Use of condoms, ample lubrication to reduce the risk of tearing, and safer sex practices in general, reduce the risk of STI transmission. However, a condom can break or otherwise come off during anal sex, and this is more likely to happen with anal sex than with other sex acts because of the tightness of the anal sphincters during friction.\n\nUnprotected receptive anal sex (with an HIV positive partner) is the sex act most likely to result in HIV transmission. Other infections that can be transmitted by unprotected anal sex are human papillomavirus (HPV) (which can increase risk of anal cancer); typhoid fever; amoebiasis; chlamydia; cryptosporidiosis; E. coli infections; giardiasis; gonorrhea; hepatitis A; hepatitis B; hepatitis C; herpes simplex; Kaposi's sarcoma-associated herpesvirus (HHV-8); lymphogranuloma venereum; Mycoplasma hominis; Mycoplasma genitalium; pubic lice; salmonellosis; shigella; syphilis; tuberculosis; and Ureaplasma urealyticum.\n\nAs with other sexual practices, people without sound knowledge about the sexual risks involved are susceptible to STIs. Because of the view that anal sex is not \"real sex\" and therefore does not result in virginity loss, or pregnancy, teenagers and other young people may consider vaginal intercourse riskier than anal intercourse and believe that a STI can only result from vaginal intercourse. It may be because of these views that condom use with anal sex is often reported to be low and inconsistent across all groups in various countries.\n\nAlthough anal sex alone does not lead to pregnancy, pregnancy can still occur with anal sex or other forms of sexual activity if the penis is near the vagina (such as during intercrural sex or other genital-genital rubbing) and its sperm is deposited near the vagina's entrance and travels along the vagina's lubricating fluids; the risk of pregnancy can also occur without the penis being near the vagina because sperm may be transported to the vaginal opening by the vagina coming in contact with fingers or other non-genital body parts that have come in contact with semen.\n\nThere are a variety of factors that make male-to-female anal intercourse riskier for a female than for a male. For example, besides the risk of HIV transmission being higher for anal intercourse than for vaginal intercourse, the risk of injury to the woman during anal intercourse is significantly higher than the risk of injury to her during vaginal intercourse because of the durability of the vaginal tissues compared to the anal tissues. Additionally, if a man moves from anal intercourse immediately to vaginal intercourse without a condom or without changing it, infections can arise in the vagina (or urinary tract) due to bacteria present within the anus; these infections can also result from switching between vaginal sex and anal sex by the use of fingers or sex toys.\n\nPain during receptive anal sex among gay men (or men who have sex with men) is formally known as \"anodyspareunia.\" In one study, 61% of gay or bisexual men said they experienced painful receptive anal sex and that it was the most frequent sexual difficulty they had experienced. By contrast, 24% of gay or bisexual men stated that they always experienced some degree of pain during anal sex, and about 12% of gay men find it too painful to pursue receptive anal sex; it was concluded that the perception of anal sex as painful is as likely to be psychologically or emotionally based as it is to be physically based. Factors predictive of pain during anal sex include inadequate lubrication, feeling tense or anxious, lack of stimulation, as well as lack of social ease with being gay and being closeted. Research has found that psychological factors can in fact be the primary contributors to the experience of pain during anal intercourse and that adequate communication between sexual partners can prevent it, countering the notion that pain is always inevitable during anal sex.\n\nAnal sex can exacerbate hemorrhoids and therefore result in bleeding; in other cases, the formation of a hemorrhoid is attributed to anal sex. If bleeding occurs as a result of anal sex, it may also be because of a tear in the anal or rectal tissues (an anal fissure) or perforation (a hole) in the colon, the latter of which being a serious medical issue that should be remedied by immediate medical attention. Because of the rectum's lack of elasticity, the anal mucous membrane being thin, and small blood vessels being present directly beneath the mucous membrane, tiny tears and bleeding in the rectum usually result from penetrative anal sex, though the bleeding is usually minor and therefore usually not visible. By contrast to other anal sexual behaviors, anal fisting poses a more serious danger of damage due to the deliberate stretching of the anal and rectal tissues; anal fisting injuries include anal sphincter lacerations and rectal and sigmoid colon (rectosigmoid) perforation, which might result in death.\n\nRepetitive penetrative anal sex may result in the anal sphincters becoming weakened, which may cause rectal prolapse or affect the ability to hold in feces (a condition known as fecal incontinence). Rectal prolapse is relatively uncommon, however, especially in men, and its causes are not well understood. Kegel exercises have been used to strengthen the anal sphincters and overall pelvic floor, and may help prevent or remedy fecal incontinence.\n\nMost cases of anal cancer are related to infection with the human papilloma virus (HPV). Anal sex alone does not cause anal cancer; the risk of anal cancer through anal sex is attributed to HPV infection, which is often contracted through unprotected anal sex. Anal cancer is relatively rare, and significantly less common than cancer of the colon or rectum (colorectal cancer); the American Cancer Society states that it affects approximately 7,060 people (4,430 in women and 2,630 in men) and results in approximately 880 deaths (550 in women and 330 in men) in the United States, and that, though anal cancer has been on the rise for many years, it is mainly diagnosed in adults, \"with an average age being in the early 60s\" and it \"affects women somewhat more often than men.\" Though anal cancer is serious, treatment for it is \"often very effective\" and most anal cancer patients can be cured of the disease; the American Cancer Society adds that \"receptive anal intercourse also increases the risk of anal cancer in both men and women, particularly in those younger than the age of 30. Because of this, men who have sex with men have a high risk of this cancer.\"\n\nDifferent cultures have had different views on anal sex throughout human history, with some cultures more positive about the activity than others. Historically, anal sex has been restricted or condemned, especially with regard to religious beliefs; it has also commonly been used as a form of domination, usually with the active partner (the one who is penetrating) representing masculinity and the passive partner (the one who is being penetrated) representing femininity. A number of cultures have especially recorded the practice of anal sex between males, and anal sex between males has been especially stigmatized or punished. In some societies, if discovered to have engaged in the practice, the individuals involved were put to death, such as by decapitation, burning, or even mutilation.\n\nAnal sex has been more accepted in modern times; it is often considered a natural, pleasurable form of sexual expression. Some people, men in particular, are only interested in anal sex for sexual satisfaction, which has been partly attributed to the buttocks and anus being more eroticized in modern culture, including via pornography. Engaging in anal sex is still, however, punished in some societies. For example, regarding LGBT rights in Iran, Iran's Penal Code states in Article 109 that \"both men involved in same-sex penetrative (anal) or non-penetrative sex will be punished\" and \"Article 110 states that those convicted of engaging in anal sex will be executed and that the manner of execution is at the discretion of the judge\".\n\nThe term \"Greek love\" has long been used to refer to anal intercourse, and in modern times, \"doing it the Greek way\" is sometimes used as slang for anal sex. Ancient Greeks accepted romantic or sexual relationships between males as a balanced sex life (having males and women as lovers), and they considered this \"normal (as long as one partner was an adult and the other was aged between twelve and fifteen)\".\n\nMale-male anal sex was not a universally accepted practice in Ancient Greece; it was the target of jokes in some Athenian comedies. Aristophanes, for instance, mockingly alludes to the practice, claiming, \"Most citizens are \"europroktoi\" (wide-arsed) now.\" The terms \"kinaidos\", \"europroktoi\", and \"katapygon\" were used by Greek residents to categorize men who chronically practiced passive anal intercourse. While pedagogic pederasty was an essential element in the education of male youths, these relationships, at least in Athens and Sparta, were expected to steer clear of penetrative sex of any kind. Greek artwork of sexual interaction between men and boys usually depicted fondling or intercrural sex, which was not condemned for violating or feminizing boys, while male-male anal intercourse was usually depicted between males of the same age-group. Intercrural sex was not considered penetrative and two males engaging in it was considered a \"clean\" act. Some sources explicitly state that anal sex between men and boys was criticized as shameful and seen as a form of hubris. Evidence suggests, however, that the younger partner in pederastic relationships (i.e., the \"eromenos\") did engage in receptive anal intercourse so long as no one accused him of being 'feminine'.\n\nIn later Roman-era Greek poetry, anal sex became a common literary convention, represented as taking place with \"eligible\" youths: those who had attained the proper age but had not yet become adults. Seducing those not of proper age (for example, non-adolescent children) into the practice was considered very shameful for the adult, and having such relations with a male who was no longer adolescent was considered more shameful for the young male than for the one mounting him; Greek courtesans, or hetaerae, are said to have frequently practiced male-female anal intercourse as a means of preventing pregnancy.\n\nA male citizen taking the passive (or receptive) role in anal intercourse (\"paedicatio\" in Latin) was condemned in Rome as an act of \"impudicitia\" (immodesty or unchastity); free men, however, frequently took the active role with a young male slave, known as a \"catamite\" or \"puer delicatus\". The latter was allowed because anal intercourse was considered equivalent to vaginal intercourse in this way; men were said to \"take it like a woman\" (muliebria pati, \"to undergo womanly things\") when they were anally penetrated, but when a man performed anal sex on a woman, she was thought of as playing the boy's role. Likewise, women were believed to only be capable of anal sex or other sex acts with women if they possessed an exceptionally large clitoris or a dildo. The passive partner in any of these cases was always considered a woman or a boy because being the one who penetrates was characterized as the only appropriate way for an adult male citizen to engage in sexual activity, and he was therefore considered unmanly if he was the one who was penetrated; slaves could be considered \"non-citizen\". Although Roman men often availed themselves of their own slaves or others for anal intercourse, Roman comedies and plays presented Greek settings and characters for explicit acts of anal intercourse, and this may be indicative that the Romans thought of anal sex as something specifically \"Greek\".\n\nIn Japan, records (including detailed shunga) show that some males engaged in penetrative anal intercourse with males, and evidence suggestive of widespread male-female anal intercourse in a pre-modern culture can be found in the erotic vases, or stirrup-spout pots, made by the Moche people of Peru; in a survey, of a collection of these pots, it was found that 31 percent of them depicted male-female anal intercourse significantly more than any other sex act. Moche pottery of this type belonged to the world of the dead, which was believed to be a reversal of life. Therefore, the reverse of common practices was often portrayed. The Larco Museum houses an erotic gallery in which this pottery is showcased.\n\n19th century anthropologist Richard Francis Burton theorized that there is a geographical Sotadic zone wherein penetrative intercourse between males is particularly prevalent and accepted; moreover he was one of the first writers to advance the premise that such an orientation is biologically determined.\n\nIn many western countries, anal sex has generally been taboo since the Middle Ages, when heretical movements were sometimes attacked by accusations that their members practiced anal sex among themselves. At that time, celibate members of the Christian clergy were accused of engaging in \"sins against nature\", including anal sex.\n\nThe term \"buggery\" originated in medieval Europe as an insult used to describe the rumored same-sex sexual practices of the heretics from a sect originating in Bulgaria, where its followers were called \"bogomils\"; when they spread out of the country, they were called \"buggres\" (from the ethnonym \"Bulgars\"). Another term for the practice, more archaic, is \"pedicate\" from the Latin \"pedicare\", with the same meaning.\n\nThe Renaissance poet Pietro Aretino advocated anal sex in his \"Sonetti Lussuriosi\" (Lust Sonnets). While men who engaged in homosexual relationships were generally suspected of engaging in anal sex, many such individuals did not. Among these, in recent times, have been André Gide, who found it repulsive; and Noël Coward, who had a horror of disease, and asserted when young that \"I'd never do anything – well the disgusting thing they do – because I know I could get something wrong with me\".\n\nThe Mishneh Torah, a text considered authoritative by Orthodox Jewish sects, states \"since a man’s wife is permitted to him, he may act with her in any manner whatsoever. He may have intercourse with her whenever he so desires and kiss any organ of her body he wishes, and he may have intercourse with her naturally or unnaturally [traditionally, \"unnaturally\" refers to anal and oral sex], provided that he does not expend semen to no purpose. Nevertheless, it is an attribute of piety that a man should not act in this matter with levity and that he should sanctify himself at the time of intercourse.\"\n\nChristian texts may sometimes euphemistically refer to anal sex as the \"peccatum contra naturam\" (the sin against nature, after Thomas Aquinas) or \"Sodomitica luxuria\" (sodomitical lusts, in one of Charlemagne's ordinances), or \"peccatum illud horribile, inter christianos non nominandum\" (that horrible sin that among Christians is not to be named).\n\n\"Liwat\", or the sin of Lot's people, which has come to be interpreted as referring generally to same-sex sexual activity, is commonly officially prohibited by Islamic sects; there are parts of the Quran which talk about smiting on Sodom and Gomorrah, and this is thought to be a reference to unnatural sex, and so there are hadith and Islamic laws which prohibit it. While, concerning Islamic belief, it is objectionable to use the words \"al-Liwat\" and \"luti\" to refer to homosexuality because it is blasphemy toward the prophet of Allah, and therefore the terms \"sodomy\" and \"homosexuality\" are preferred, same-sex male practitioners of anal sex are called \"luti\" or \"lutiyin\" in plural and are seen as criminals in the same way that a thief is a criminal, meaning that they are giving in to a universal temptation.\n\nThe most common formulation of Buddhist ethics is the Five Precepts. These precepts take the form of voluntary, personal undertakings, not divine mandate or instruction. The third of the Precepts is \"To refrain from committing sexual misconduct\". However, \"sexual misconduct\" (Sanskrit: \"Kāmesu micchācāra\", literally \"sense gratifications arising from the 5 senses\") is subject to interpretation relative to the social norms of the followers. Buddhism, in its fundamental form, does not define what is right and what is wrong in absolute terms for lay followers. Therefore, the interpretation of what kinds of sexual activity are acceptable for a layman is not a religious matter as far as Buddhism is concerned.\n\nAlthough Hindu society does not formally acknowledge sexuality between men, it formally acknowledges and gives space to sexuality between men and third genders as a variation of male-female sex (meaning a part of heterosexuality, rather than homosexuality, if analyzed in western terms). Hijras, Alis, Kotis, etc. (the various forms of third gender that exist in India today) are all characterized by the gender role of having receptive anal and oral sex with men. However, sexuality between males (as distinct from third genders) has thrived, mostly unspoken and informally, without being seen as different in the way it is seen in the west; young men involved in \"such relationships do not consider themselves to be 'homosexual' but conceive their behavior in terms of sexual desire, opportunity and pleasure\".\n\n\nNotes\nFurther reading\n\n", "id": "2460", "title": "Anal sex"}
{"url": "https://en.wikipedia.org/wiki?curid=2466", "text": "Aarau\n\nAarau (, locally [ˈɑːræʊ]) is a town, a municipality, and the capital of the northern Swiss canton of Aargau. The town is also the capital of the district of Aarau. It is German-speaking and predominantly Protestant. Aarau is situated on the Swiss plateau, in the valley of the Aare, on the river's right bank, and at the southern foot of the Jura mountains, and is west of Zürich, and northeast of Bern. The municipality borders directly on the canton of Solothurn to the west. It is the second-largest town in Aargau after Wettingen. At the beginning of 2010 Rohr became a suburb of Aarau.\n\nThe official language of Aarau is Swiss Standard German, but the main spoken language is the local variant of the Alemannic Swiss German dialect.\n\nThe old city of Aarau is situated on a rocky outcrop at a narrowing of the Aare river valley, at the southern foot of the Jura mountains. Newer districts of the city lie to the south and east of the outcrop, as well as higher up the mountain, and in the valley on both sides of the Aare.\nThe neighboring municipalities are Küttigen to the north, Rohr and Buchs to the east, Suhr to the south-east, Unterentfelden to the south, and Eppenberg-Wöschnau and Erlinsbach to the west.\nAarau and the nearby neighboring municipalities have grown together and now form an interconnected agglomeration. The only exception is Unterentfelden whose settlements are divided from Aarau by the extensive forests of Gönhard and Zelgli.\nApproximately nine-tenths of the city is south of the Aar, and one tenth is to the north. It has an area, , of . Of this area, 6.3% is used for agricultural purposes, while 34% is forested. Of the rest of the land, 55.2% is settled (buildings or roads) and the remainder (4.5%) is non-productive (rivers or lakes). The lowest elevation, , is found at the banks of the Aar, and the highest elevation, at , is the Hungerberg on the border with Küttigen.\n\nA few artifacts from the Neolithic period were found in Aarau. Near the location of the present train station, the ruins of a settlement from the Bronze Age (about 1000 BC) have been excavated. The Roman road between Salodurum (Solothurn) and Vindonissa passed through the area, along the route now covered by the Bahnhofstrasse. In 1976 divers in the Aare found part of a seven-meter wide wooden bridge from the late Roman times.\n\nAarau was founded around AD 1240 by the counts of Kyburg. Aarau is first mentioned in 1248 as \"Arowe\". Around 1250 it was mentioned as \"Arowa\". However the first mention of a city sized settlement was in 1256. The town was ruled from the \"Rore\" tower, which has been incorporated into the modern city hall.\n\nIn 1273 the counts of Kyburg died out. Agnes of Kyburg, who had no male relations, sold the family's lands to King Rudolf I von Habsburg. He granted Aarau its city rights in 1283. In the 14th century the city was expanded in two stages, and a second defensive wall was constructed. A deep ditch separated the city from its \"suburb;\" its location is today marked by a wide street named \"Graben\" (meaning Ditch).\n\nIn 1415 Bern invaded lower Aargau with the help of Solothurn. Aarau capitulated after a short resistance, and was forced to swear allegiance to the new rulers. In the 16th century, the rights of the lower classes were abolished.\nIn March 1528 the citizens of Aarau allowed the introduction of Protestantism at the urging of the Bernese. A growth in population during the 16th Century led to taller buildings and denser construction methods. Early forms of industry developed at this time; however, unlike in other cities, no guilds were formed in Aarau.\n\nOn 11 August 1712, the Peace of Aarau was signed into effect. This granted each canton the right to choose their own religion thereby ending Catholicism's control. Starting in the early 18th century, the textile industry was established in Aarau. German immigration contributed to the city's favorable conditions, in that they introduced the cotton and silk factories. These highly educated immigrants were also responsible for educational reform and the enlightened, revolutionary spirit that developed in Aarau.\n\nOn 27 December 1797, the last Tagsatzung of the Old Swiss Confederacy was held in Aarau. Two weeks later a French envoy continued to foment the revolutionary opinions of the city. The contrast between a high level of education and a low level of political rights was particularly great in Aarau, and the city refused to send troops to defend the Bernese border. By Mid-March 1798 Aarau was occupied by French troops.\n\nOn 22 March 1798 Aarau was declared the capital of the Helvetic Republic. It is therefore the first capital of a unified Switzerland. Parliament met in the city hall. On 20 September, the capital was moved to Lucerne.\n\nIn 1803, Napoleon ordered the fusion of the cantons of Aargau, Baden and Fricktal. Aarau was declared the capital of the new, enlarged canton of Aargau. In 1820 the city wall was torn down, with the exception of the individual towers and gates, and the defensive ditches were filled in.\n\nThe wooden bridge, dating from the Middle Ages, across the Aare was destroyed by floods three times in thirty years, and was replaced with a steel suspension bridge in 1851. This was replaced by a concrete bridge in 1952. The city was linked up to the Swiss Central Railway in 1856.\n\nThe textile industry in Aarau broke down in about 1850 because of the protectionist tariff policies of neighboring states. Other industries had developed by that time to replace it, including the production of mathematical instruments, shoes and cement. Beginning in 1900, numerous electrical enterprises developed. By the 1960s, more citizens worked in service industries or for the canton-level government than in manufacturing. During the 1980s many of the industries left Aarau completely.\n\nIn 1802 the Canton School was established; it was the first non-parochial high school in Switzerland. It developed a good reputation, and was home to Nobel Prize winners Albert Einstein, Paul Karrer, and Werner Arber, as well as several Swiss politicians and authors.\n\nThe purchase of a manuscript collection in 1803 laid the foundation for what would become the Cantonal Library, which contains a Bible annotated by Huldrych Zwingli, along with the manuscripts and incunabula. More newspapers developed in the city, maintaining the revolutionary atmosphere of Aarau. Beginning in 1820, Aarau has been a refuge for political refugees.\n\nThe urban educational and cultural opportunities of Aarau were extended through numerous new institutions. A Theatre and Concert Hall was constructed in 1883, which was renovated and expanded in 1995–96. The Aargau Nature Museum opened in 1922. A former cloth warehouse was converted into a small theatre in 1974, and the alternative culture center KIFF (Culture in the fodder factory) was established in a former animal fodder factory.\n\nThe earliest use of the place name was in 1248 (in the form Arowe), and probably referred to the settlement in the area before the founding of the city. It comes, along with the name of the River Aare (which was called Arula, Arola, and Araris in early times), from the German Au, meaning floodplain.\n\nThe historic old town forms an irregular square, consisting of four parts (called \"Stöcke\"). To the south lies the Laurenzenvorstadt, that is, the part of the town formerly outside the city wall. One characteristic of the city is its painted gables, for which Aarau is sometimes called the \"City of beautiful Gables\". The old town, Laurenzenvorstadt, government building, cantonal library, state archive and art museum are all listed as heritage sites of national significance.\n\nThe buildings in the old city originate, on the whole, from building projects during the 16th century, when nearly all the Middle Age period buildings were replaced or expanded. The architectural development of the city ended in the 18th century, when the city began to expand beyond its (still existing) wall. Most of the buildings in the \"suburb\" date from this time.\n\nThe \"Schlössli\" (small Castle), Rore Tower and the upper gate tower have remained nearly unchanged since the 13th century. The \"Schlössli\" is the oldest building in the city. It was already founded at the time of the establishment of the city shortly after 1200; the exact date is not known. City hall was built around Rore Tower in 1515.\nThe upper gate tower stands beside the southern gate in the city wall, along the road to Lucerne and Bern. The jail has been housed in it since the Middle Ages. A Carillon was installed in the tower in the middle of the 20th century, the bells for which were provided by the centuries-old bell manufacturers of Aarau.\n\nThe town church was built between 1471 and 1478. During the Reformation, in 1528, its twelve altars and accompanying pictures were destroyed. The \"Justice fountain\" (Gerechtskeitbrunnen) was built in 1634, and is made of French limestone; it includes a statue of Lady Justice made of sandstone, hence the name. It was originally in the street in front of city hall, but was moved to its present location in front of the town church in 1905 due to increased traffic.\n\n, Aarau had an unemployment rate of 2.35%. , there were 48 people employed in the primary economic sector and about 9 businesses involved in this sector. 4,181 people are employed in the secondary sector and there are 164 businesses in this sector. 20,186 people are employed in the tertiary sector, with 1,461 businesses in this sector. This is a total of over 24,000 jobs, since Aarau's population is about 16,000 it draws workers from many surrounding communities. there were 8,050 total workers who lived in the municipality. Of these, 4,308 or about 53.5% of the residents worked outside Aarau while 17,419 people commuted into the municipality for work. There were a total of 21,161 jobs (of at least 6 hours per week) in the municipality.\n\nThe largest employer in Aarau is the cantonal government, the offices of which are distributed across the entire city at numerous locations. One of the two head offices of the \"Aargauer Zeitung\", Switzerland's fifth largest newspaper, is located in Aarau, as are the Tele M1 television channel studios, and several radio stations.\n\nKern & Co., founded in 1819, was an internationally known geodetic instrument manufacturer based in Aarau. However, it was taken over by Wild Leitz in 1988, and was closed in 1991.\n\nMore than half of the workers in Aarau live in the city's suburbs, or farther away in the surrounding area. This leads to a busy rush hour, and regular traffic jams. Statistically, Aarau has the most jobs per capita of any Swiss city.\n\nThe small scale of Aarau causes it to continually expand the borders of its growth. The urban center lies in the middle of the \"Golden Triangle\" between Zürich, Bern, and Basel, and Aarau is having increasing difficulty in maintaining the independence of its economic base from the neighboring large cities. The idea of merging Aarau with its neighboring suburbs has been recently discussed in the hope of arresting the slowly progressing losses.\n\nManufacture include bells, mathematical instruments, electrical goods, cotton textiles, cutlery, chemicals, shoes, and other products. Aarau is famous for the quality of their instruments, cutlery and their bells.\n\nEvery Saturday morning there is a vegetable market in the \"Graben\" at the edge of the Old City. It is supplied with regional products. In the last week of September the MAG (Market of Aarauer Tradesmen) takes place there, with regional companies selling their products. The \"Rüeblimärt\" is held in the same place on the first Wednesday in November, which is a Carrot fair. The Aarau fair is held at the ice skating rink during the Spring.\n\nAarau railway station is a terminus of the S-Bahn Zürich on the line S3.\n\nThe town is also served with public transport provided by Busbetrieb Aarau AG.\n\nThe population of Aarau grew continuously from 1800 until about 1960, when the city reached a peak population of 17,045, more than five times its population in 1800. However, since 1960 the population has fallen by 8%. There are three reasons for this population loss: firstly, since the completion of Telli (a large apartment complex), the city has not had any more considerable land developments. Secondly, the number of people per household has fallen; thus, the existing dwellings do not hold as many people. Thirdly, population growth was absorbed by neighboring municipalities in the regional urban area, and numerous citizens of Aarau moved into the countryside. This trend might have stopped since the turn of the 21st century. Existing industrial developments are being used for new purposes instead of standing empty.\n\nAarau has a population (as of ) of . , 19.8% of the population was made up of foreign nationals. Over the last 10 years the population has grown at a rate of 1%. Most of the population () speaks German (84.5%), with Italian being second most common ( 3.3%) and Serbo-Croatian being third ( 2.9%).\n\nThe age distribution, , in Aarau is; 1,296 children or 8.1% of the population are between 0 and 9 years old and 1,334 teenagers or 8.4% are between 10 and 19. Of the adult population, 2,520 people or 15.8% of the population are between 20 and 29 years old. 2,518 people or 15.8% are between 30 and 39, 2,320 people or 14.6% are between 40 and 49, and 1,987 people or 12.5% are between 50 and 59. The senior population distribution is 1,588 people or 10.0% of the population are between 60 and 69 years old, 1,219 people or 7.7% are between 70 and 79, there are 942 people or 5.9% who are between 80 and 89,and there are 180 people or 1.1% who are 90 and older.\n\n, there were 1,365 homes with 1 or 2 persons in the household, 3,845 homes with 3 or 4 persons in the household, and 2,119 homes with 5 or more persons in the household. The average number of people per household was 1.99 individuals. there were 1,594 single family homes (or 18.4% of the total) out of a total of 8,661 homes and apartments.\n\nIn Aarau about 74.2% of the population (between age 25–64) have completed either non-mandatory upper secondary education or additional higher education (either university or a \"Fachhochschule\"). Of the school age population (), there are 861 students attending primary school, there are 280 students attending secondary school, there are 455 students attending tertiary or university level schooling, there are 35 students who are seeking a job after school in the municipality.\nThe football club FC Aarau play in the Stadion Brügglifeld. From 1981 until 2010 they played in the top tier of the Swiss football league system when they were relegated to the Swiss Challenge League. In the 2013/2014 they climbed back to the highest tier only to be relegated again. In the 2016/17 season they will play in the Swiss Challenge League. They won the Swiss Cup in 1985 and were three times Swiss football champions, in 1912, in 1914 and in 1993.\n\nAarau is home to a number of sites that are listed as Swiss heritage sites of national significance. The list includes three churches; the Christian Catholic parish house, the Catholic parish house, and the Reformed \"City Church\". There are five government buildings on the list; the Cantonal Library, which contains many pieces important to the nation's history, and Art Gallery, the old Cantonal School, the Legislature, the Cantonal Administration building, and the archives. Three gardens or parks are on the list; \"Garten Schmidlin\", \"Naturama Aargau\" and the \"Schlossgarten\". The remaining four buildings on the list are; the former Rickenbach Factory, the Crematorium, the \"Haus zum Erker\" at Rathausgasse 10 and the \"Restaurant Zunftstube\" at Pelzgasse.\n\nThe Bally Shoe company has a unique shoe museum in the city. There is also the Trade Museum which contain stained glass windows from Muri Convent and paintings.\n\nFrom the , 4,473 or 28.9% are Roman Catholic, while 6,738 or 43.6% belonged to the Swiss Reformed Church. Of the rest of the population, there are 51 individuals (or about 0.33% of the population) who belong to the Christian Catholic i.e. Old Catholic faith.\n\nIn place of a town meeting, a town assembly (\"Einwohnerrat\") of 50 members is elected by the citizens, and follows the policy of proportional representation. It is responsible for approving tax levels, preparing the annual account, and the business report. In addition, it can issue regulations. The term of office is four years. In the last two elections the parties had the following representation:\n\nAt the district level, some elements of the government remain a direct democracy. There are optional and obligatory referendums, and the population retains the right to establish an initiative.\n\nThe executive authority is the town council (\"Stadtrat\"). The term of office is four years, and its members are elected by a plurality voting system. It leads and represents the municipality. It carries out the resolutions of the assembly, and those requested by the canton and national level governments.\n\nThe seven members (and their party) for the period 2006–2009 are:\n\nIn the 2007 federal election the most popular party was the SP which received 27.9% of the vote. The next three most popular parties were the SVP (22.1%), the FDP (17.5%) and the Green Party (11.8%).\n\nThe blazon of the municipal coat of arms is \"Argent an Eagle displayed Sable beaked langued and membered Gules and a Chief of the last.\"\n\n\nAarau is twinned with:\n\n\n\n", "id": "2466", "title": "Aarau"}
{"url": "https://en.wikipedia.org/wiki?curid=2467", "text": "Aargau\n\nThe canton of Aargau (German \"Kanton\" ; sometimes anglicized Argovia; see also other names) is one of the more northerly cantons of Switzerland. It is situated by the lower course of the Aare, which is why the canton is called Aar-gau (meaning \"Aare province\"). It is one of the most densely populated regions of Switzerland.\n\nThe area of Aargau and the surrounding areas were controlled by the Helvetians, a member of the Celts, as far back as 200 BC, eventually being occupied by the Romans and then by the 6th century, the Franks. The Romans built a major settlement called Vindonissa, near the present location of Brugg.\n\nIn early medieval times, the Aargau was a disputed border region between the duchies of Alamannia and Burgundy. A line of the von Wetterau (Conradines) intermittently held the countship of Aargau from 750 until about 1030, when they lost it (having in the meantime taken the name von Tegerfelden). From the extinction in 1254 of the Hohenstaufen dynasty until 1415, the area was ruled by the Habsburgs, and many castles from that time still stand (examples include Habsburg, Lenzburg, Tegerfelden, Bobikon, Stin and Wildegg). The Habsburgs founded a number of monasteries (with some structures enduring, e.g., in Wettingen and Muri), the closing of which by the government in 1841 was a contributing factor to the outbreak of the Swiss civil war – the \"Sonderbund War\" – in 1847.\n\nWhen Frederick IV of Habsburg sided with Antipope John XXIII at the Council of Constance, Emperor Sigismund placed him under the Imperial ban. In July 1414, the Pope visited Bern and received assurances from them, that they would move against the Habsburgs. A few months later the Swiss Confederation denounced the Treaty of 1412. Shortly thereafter in 1415, Bern and the rest of the Swiss Confederation used the ban as a pretext to invade the Aargau. The Confederation was able to quickly conquer the towns of Aarau, Lenzburg, Brugg and Zofingen along with most of the Habsburg castles. Bern kept the southwest portion (Zofingen, Aarburg, Aarau, Lenzburg, and Brugg), northward to the confluence of the Aare and Reuss. The important city of Baden was taken by a united Swiss army and governed by all 8 members of the Confederation. Some districts, named the \"Freie Ämter\" (\"free bailiwicks\") – Mellingen, Muri, Villmergen, and Bremgarten, with the countship of Baden – were governed as \"subject lands\" by all or some of the Confederates. Shortly after the conquest of the Aargau by the Swiss, Frederick humbled himself to the Pope. The Pope reconciled with him and ordered all of the taken lands to be returned. The Swiss refused and years later after no serious attempts at re-acquisition, the Duke officially relinquished rights to the Swiss.\n\nBern's portion of the Aargau came to be known as the Unteraargau, though can also be called the Berner or Bernese Aargau. In 1514 Bern expanded north into the Jura and so came into possession of several strategically important mountain passes into the Austrian Fricktal. This land was added to the Unteraargau and was directly ruled from Bern. It was divided into seven rural bailiwicks and four administrative cities, Aarau, Zofingen, Lenzburg and Brugg. While the Habsburgs were driven out, many of their minor nobles were allowed to keep their lands and offices, though over time they lost power to the Bernese government. The bailiwick administration was based on a very small staff of officials, mostly made up of Bernese citizens, but with a few locals.\n\nWhen Bern converted during the Protestant Reformation in 1528, the Unteraargau also converted. At the beginning of the 16th century a number of anabaptists migrated into the upper Wynen and Rueder valleys from Zürich. Despite pressure from the Bernese authorities in the 16th and 17th centuries anabaptism never entirely disappeared from the Unteraargau.\n\nBern used the Aargau bailiwicks mostly as a source of grain for the rest of the city-state. The administrative cities remained economically only of regional importance. However, in the 17th and 18th centuries Bern encouraged industrial development in Unteraargau and by the late 18th century it was the most industrialized region in the city-state. The high industrialization led to high population growth in the 18th century, for example between 1764 and 1798, the population grew by 35%, far more than in other parts of the canton. In 1870 the proportion of farmers in Aarau, Lenzburg, Kulm, and Zofingen districts was 34–40%, while in the other districts it was 46–57%.\n\nThe rest of the Freie Ämter were collectively administered as subject territories by the rest of the Confederation. Muri \"Amt\" was assigned to Zürich, Lucerne, Schwyz, Unterwalden, Zug and Glarus, while the \"Ämter\" of Meienberg, Richensee and Villmergen were first given to Lucerne alone. The final boundary was set in 1425 by an arbitration tribunal and Lucerne had to give the three \"Ämter\" to be collectively ruled. The four \"Ämter\" were then consolidated under a single Confederation bailiff into what was known in the 15th century as the \"Waggental\" Bailiwick (). In the 16th century, it came to be known as the \"Vogtei der Freien Ämter\". While the \"Freien Ämter\" often had independent lower courts, they were forced to accept the Confederation's sovereignty. Finally, in 1532, the canton of Uri became part of the collective administration of the Freien Ämter.\n\nAt the time of Reformation, the majority of the Ämter converted to the new faith. In 1529, a wave of iconoclasm swept through the area and wiped away much of the old religion. After the defeat of Zürich in the second Battle of Kappel in 1531, the victorious five Catholic cantons marched their troops into the Freie Ämter and reconverted them to Catholicism.\n\nIn the First War of Villmergen, in 1656, and the Toggenburg War (or Second War of Villmergen), in 1712, the Freie Ämter became the staging ground for the warring Reformed and Catholic armies. While the peace after the 1656 war did not change the status quo, the fourth Peace of Aarau in 1712 brought about a reorganization of power relations. The victory gave Zürich the opportunity to force the Catholic cantons out of the government in the county of Baden and the adjacent area of the Freie Ämter. The Freie Ämter were then divided in two by a line drawn from the gallows in Fahrwangen to the Oberlunkhofen church steeple. The northern part, the so-called Unteren Freie Ämter (lower Freie Ämter), which included the districts of Boswil (in part) and Hermetschwil and the Niederamt, were ruled by Zürich, Bern and Glarus. The southern part, the Oberen Freie Ämter (upper Freie Ämter), were ruled by the previous seven cantons but Bern was added to make an eighth.\n\nDuring the Helvetic Republic (1798–1803), the county of Baden, the Freie Ämter and the area known as the Kelleramt were combined into the canton of Baden.\n\nThe County of Baden was a shared condominium of the entire Old Swiss Confederacy. After the Confederacy conquest in 1415, they retained much of the Habsburg legal structure, which caused a number of problems. The local nobility had the right to hold the low court in only about one fifth of the territory. There were over 30 different nobles who had the right to hold courts scattered around the surrounding lands. All these overlapping jurisdictions caused numerous conflicts, but gradually the Confederation was able to acquire these rights in the County. The cities of Baden, Bremgarten and Mellingen became the administrative centers and held the high courts. Together with the courts, the three administrative centers had considerable local autonomy, but were ruled by a governor who was appointed by the \"Acht Orte\" every two years. After the Protestant victory at the Second Battle of Villmergen, the administration of the County changed slightly. Instead of the \"Acht Orte\" appointing a bailiff together, Zürich and Bern each appointed the governor for 7 out of 16 years while Glarus appointed him for the remaining 2 years.\n\nThe chaotic legal structure and fragmented land ownership combined with a tradition of dividing the land among all the heirs in an inheritance prevented any large scale reforms. The governor tried in the 18th century to reform and standardize laws and ownership across the County, but with limited success. With an ever-changing administration, the County lacked a coherent long-term economic policy or support for reforms. By the end of the 18th century there were no factories or mills and only a few small cottage industries along the border with Zürich. Road construction first became a priority after 1750, when Zürich and Bern began appointing a governor for seven years.\n\nDuring the Protestant Reformation, some of the municipalities converted to the new faith. However, starting in 1531, some of the old parishes were converted back to the old faith. The governors were appointed from both Catholic and Protestant cantons and since they changed every two years, neither faith gained a majority in the County.\n\nThe County was the only federal condominium in the 17th century where Jews were tolerated. In 1774, they were restricted to just two towns, Endingen and Lengnau. While the rural upper class tried several times to finally expel the Jews, the financial interests of the authorities prevented this. The Jews were directly subordinate to the governor starting in 1696 when they were forced to buy a protecting and shielding letter every 16 years from the governor.\n\nAfter the French invasion, on 19 March 1798, the governments of Zürich and Bern agreed to the creation of the short lived canton of Baden in the Helvetic Republic. With the Act of Mediation in 1803, the canton of Baden was dissolved. Portions of the lands of the former County of Baden now became the District of Baden in the newly created canton of Aargau. After World War II, this formerly agrarian region saw striking growth and became the district with the largest and densest population in the canton (110,000 in 1990, 715 persons per km).\n\nThe contemporary canton of Aargau was formed in 1803, a canton of the Swiss Confederation as a result of the Act of Mediation. It was a combination of three short-lived cantons of the Helvetic Republic: Aargau (1798–1803), Baden (1798–1803) and Fricktal (1802–1803). Its creation is therefore rooted in the Napoleonic era. In the year 2003, the canton of Aargau celebrated its 200th anniversary.\n\nFrench forces occupied the Aargau from 10 March to 18 April 1798; thereafter the Bernese portion became the canton of Aargau and the remainder formed the canton of Baden. Aborted plans to merge the two halves came in 1801 and 1802, and they were eventually united under the name Aargau, which was then admitted as a full member of the reconstituted Confederation following the Act of Mediation. Some parts of the canton of Baden at this point were transferred to other cantons: the \"Amt\" of Hitzkirch to Lucerne, whilst Hüttikon, Oetwil an der Limmat, Dietikon and Schlieren went to Zürich. In return, Lucerne's \"Amt\" of Merenschwand was transferred to Aargau (district of Muri).\n\nThe Fricktal, ceded in 1802 by Austria via Napoleonic France to the Helvetic Republic, was briefly a separate canton of the Helvetic Republic (the canton of Fricktal) under a \"Statthalter\" ('Lieutenant'), but on 19 March 1803 (following the Act of Mediation) was incorporated into the canton of Aargau.\n\nThe former cantons of Baden and Fricktal can still be identified with the contemporary districts – the canton of Baden is covered by the districts of Zurzach, Baden, Bremgarten, and Muri (albeit with the gains and losses of 1803 detailed above); the canton of Fricktal by the districts of Rheinfelden and Laufenburg (except for Hottwil which was transferred to that district in 2010).\n\nThe chief magistracy of Aargau changed its style repeatedly:\n\nIn the 17th century, Jews were banished from Switzerland. However, a few families were permitted to live in two villages, Endingen and Lengnau, in Aargau which became the Jewish ghetto in Switzerland. During this period, Jews and Christians were not allowed to live under the same roof, neither were Jews allowed to own land or houses. They were taxed at a much higher rate than others and, in 1712, the Lengnau community was \"pillaged.\" In 1760, they were further restricted regarding marriages and multiplying. This remained the case until the 19th century. In 1799, all special tolls were abolished, and, in 1802, the poll tax was removed. On 5 May 1809, they were declared citizens and given broad rights regarding trade and farming. They were still restricted to Endingen and Lengnau until 7 May 1846, when their right to move and reside freely within the canton of Aargau was granted. On 24 September 1856, the Swiss Federal Council granted them full political rights within Aargau, as well as broad business rights; however the majority Christian population did not abide by these new liberal laws fully. The time of 1860 saw the canton government voting to grant suffrage in all local rights and to give their communities autonomy. Before the law was enacted, it was repealed due to vocal opposition led by the Ultramonte Party. Finally, the federal authorities in July 1863, granted all Jews full rights of citizens. However, they did not receive all of the rights in Endingen and Lengn until a resolution of the Grand Council, on 15 May 1877, granted citizens' rights to the members of the Jewish communities of those places, giving them charters under the names of New Endingen and New Lengnau. The Swiss Jewish Kulturverein was instrumental in this fight from its founding in 1862 until it was dissolved 20 years later. During this period of diminished rights, they were not even allowed to bury their dead in Swiss soil and had to bury their dead on an island called \"Judenäule\" (Jews' Isle) on the Rhine near Waldshut. Beginning in 1603, the deceased Jews of the Surbtal communities were buried on the river island which was leased by the Jewish community. As the island was repeatedly flooded and devastated, in 1750 the Surbtal Jews asked the \"Tagsatzung\" to establish the Endingen cemetery in the vicinity of their communities.\n\nThe capital of the canton is Aarau, which is located on its western border, on the Aare. The canton borders Germany (Baden-Württemberg) to the north, the Rhine forming the border. To the west lie the Swiss cantons of Basel-Landschaft, Solothurn and Bern; the canton of Lucerne lies south, and Zürich and Zug to the east. Its total area is . It contains both large rivers, the Aare and the Reuss.\n\nThe canton of Aargau is one of the least mountainous Swiss cantons, forming part of a great table-land, to the north of the Alps and the east of the Jura, above which rise low hills. The surface of the country is beautifully diversified, undulating tracts and well-wooded hills alternating with fertile valleys watered mainly by the Aare and its tributaries. The valleys alternate with pleasant hills, most of which are full of woods. Slightly over one-third of the canton is wooded (), while nearly half is used from farming (). or about 2.4% of the canton is considered unproductive, mostly lakes (notably Lake Hallwil) and streams. With a population density of 450/km (1,200/sq mi), the canton has a relatively high amount of land used for human development, with or about 15% of the canton developed for housing or transportation.\n\nIt contains the famous hot sulphur springs of Baden and Schinznach-Bad, while at Rheinfelden there are very extensive saline springs. Just below Brugg the Reuss and the Limmat join the Aar, while around Brugg are the ruined castle of Habsburg, the old convent of Königsfelden (with fine painted medieval glass) and the remains of the Roman settlement of \"Vindonissa\" (Windisch).\n\nFahr Abbey forms a small exclave of the canton, otherwise surrounded by the canton of Zürich, and since 2008 is part of the Aargau municipality of Würenlos.\n\nAargau is divided into 11 districts:\n\nThe most recent change in district boundaries occurred in 2010 when Hottwil transferred from Brugg to Laufenburg, following its merger with other municipalities, all of which were in Laufenburg.\n\nThere are (as of 2014) 213 municipalities in the canton of Aargau. As with most Swiss cantons there has been a trend since the early 2000s for municipalities to merge, though mergers in Aargau have so far been less radical than in other cantons.\n\nThe blazon of the coat of arms is \"Per pale, dexter: sable, a fess wavy argent, charged with two cotises wavy azure; sinister: sky blue, three mullets of five argent.\"\n\nThe flag and arms of Aargau date to 1803 and are an original design by Samuel Ringier-Seelmatter; the current official design, specifying the stars as five-pointed, dates to 1930.\n\nAargau has a population () of . , 21.5% of the population are resident foreign nationals. Over the last 10 years (2000–2010) the population has changed at a rate of 11%. Migration accounted for 8.7%, while births and deaths accounted for 2.8%. Most of the population () speaks German (477,093 or 87.1%) as their first language, Italian is the second most common (17,847 or 3.3%) and Serbo-Croatian is the third (10,645 or 1.9%). There are 4,151 people who speak French and 618 people who speak Romansh.\n\nOf the population in the canton, 146,421 or about 26.7% were born in Aargau and lived there in 2000. There were 140,768 or 25.7% who were born in the same canton, while 136,865 or 25.0% were born somewhere else in Switzerland, and 107,396 or 19.6% were born outside of Switzerland.\n\n, children and teenagers (0–19 years old) make up 24.3% of the population, while adults (20–64 years old) make up 62.3% and seniors (over 64 years old) make up 13.4%.\n\n, there were 227,656 people who were single and never married in the canton. There were 264,939 married individuals, 27,603 widows or widowers and 27,295 individuals who are divorced.\n\n, there were 224,128 private households in the canton, and an average of 2.4 persons per household. There were 69,062 households that consist of only one person and 16,254 households with five or more people. , the construction rate of new housing units was 6.5 new units per 1000 residents. The vacancy rate for the canton, , was 1.54%.\n\nThe majority of the population is centered on one of three areas: the Aare Valley, the side branches of the Aare Valley, or along the Rhine.\n\nThe historical population is given in the following chart:\n\nIn the 2011 federal election, the most popular party was the SVP which received 34.7% of the vote. The next three most popular parties were the SP/PS (18.0%), the FDP (11.5%) and the CVP (10.6%).\n\nThe SVP received about the same percentage of the vote as they did in the 2007 Federal election (36.2% in 2007 vs 34.7% in 2011). The SPS retained about the same popularity (17.9% in 2007), the FDP retained about the same popularity (13.6% in 2007) and the CVP retained about the same popularity (13.5% in 2007).\n\nFrom the , 219,800 or 40.1% were Roman Catholic, while 189,606 or 34.6% belonged to the Swiss Reformed Church. Of the rest of the population, there were 11,523 members of an Orthodox church (or about 2.10% of the population), there were 3,418 individuals (or about 0.62% of the population) who belonged to the Christian Catholic Church, and there were 29,580 individuals (or about 5.40% of the population) who belonged to another Christian church. There were 342 individuals (or about 0.06% of the population) who were Jewish, and 30,072 (or about 5.49% of the population) who were Islamic. There were 1,463 individuals who were Buddhist, 2,089 individuals who were Hindu and 495 individuals who belonged to another church. 57,573 (or about 10.52% of the population) belonged to no church, are agnostic or atheist, and 15,875 individuals (or about 2.90% of the population) did not answer the question.\n\nIn Aargau about 212,069 or (38.7%) of the population have completed non-mandatory upper secondary education, and 70,896 or (12.9%) have completed additional higher education (either university or a \"Fachhochschule\"). Of the 70,896 who completed tertiary schooling, 63.6% were Swiss men, 20.9% were Swiss women, 10.4% were non-Swiss men and 5.2% were non-Swiss women.\n\n, Aargau had an unemployment rate of 3.6%. , there were 11,436 people employed in the primary economic sector and about 3,927 businesses involved in this sector. 95,844 people were employed in the secondary sector and there were 6,055 businesses in this sector. 177,782 people were employed in the tertiary sector, with 21,530 businesses in this sector.\n\nOf the working population, 19.5% used public transportation to get to work, and 55.3% used a private car. Public transportation – bus and train – is provided by Busbetrieb Aarau AG.\n\nThe farmland of the canton of Aargau is some of the most fertile in Switzerland. Dairy farming, cereal and fruit farming are among the canton's main economic activities. The canton is also industrially developed, particularly in the fields of electrical engineering, precision instruments, iron, steel, cement and textiles.\n\nThree of Switzerland's five nuclear power plants are in the canton of Aargau (Beznau I + II and Leibstadt). Additionally, the many rivers supply enough water for numerous hydroelectric power plants throughout the canton. The canton of Aargau is often called \"the energy canton\".\n\nA significant number of people commute into the financial center of the city of Zürich, which is just across the cantonal border. As such the per capita cantonal income (in 2005) is 49,209 CHF.\n\nTourism is significant, particularly for the hot springs at Baden and Schinznach-Bad, the ancient castles, the landscape, and the many old museums in the canton. Hillwalking is another tourist attraction but is of only limited significance.\n\n\n\n", "id": "2467", "title": "Aargau"}
{"url": "https://en.wikipedia.org/wiki?curid=2470", "text": "Aba\n\nAba may refer to:\n\n\n\n\n\n\n", "id": "2470", "title": "Aba"}
{"url": "https://en.wikipedia.org/wiki?curid=2471", "text": "Ababda people\n\nThe Ababda or Ababde – the Gebadei of Pliny, and possibly the Troglodytes of other classical writers – are nomads living in the area between the Nile and the Red Sea, in the vicinity of Aswan in Egypt and north Sudan. They are a subgroup of the Beja people who are bilingual in Beja and Arabic.\n\nThe Ababda extend from the Nile at Aswan to the Red Sea, and reach northward to the Qena-Quseir road, thus occupying the southern border of Egypt east of the Nile. They call themselves \"sons of the Jinns.\" With some of the clans of the Bisharin and possibly the Hadendoa, they represent the Blemmyes of classic geographers, and their location today is almost identical with that assigned them in Roman times.\n\nThey were constantly at war with the Romans, who eventually conquered them. In the Middle Ages, they were known as Beja, and convoyed pilgrims from the Nile valley to Aidhab, the port of embarkation for Jeddah. From time immemorial, they have acted as guides to caravans through the Nubian desert and up the Nile valley as far as Sennar. They intermarried with the Nubians, and settled in small colonies at Shendi and elsewhere up to Muhammad Ali's conquest of the region in the early 19th century. They are still great trade carriers, and visit very distant districts.\n\n\n", "id": "2471", "title": "Ababda people"}
{"url": "https://en.wikipedia.org/wiki?curid=2472", "text": "American Quarter Horse\n\nThe American Quarter Horse is an American breed of horse that excels at sprinting short distances. Its name came from its ability to outdistance other horse breeds in races of a quarter mile or less; some have been clocked at speeds up to 55 mph (88.5 km/h). The American Quarter Horse is the most popular breed in the United States today, and the American Quarter Horse Association is the largest breed registry in the world, with almost 3 million American Quarter Horses currently registered.\n\nThe American Quarter Horse is well known both as a race horse and for its performance in rodeos, horse shows and as a working ranch horse. The compact body of the American Quarter Horse is well-suited to the intricate and speedy maneuvers required in reining, cutting, working cow horse, barrel racing, calf roping, and other western riding events, especially those involving live cattle. The American Quarter Horse is also shown in English disciplines, driving, and many other equestrian activities.\n\nIn the 17th century, colonists on the eastern seaboard of what today is the United States began to cross imported English Thoroughbred horses with assorted \"native\" horses such as the Chickasaw horse, which was a breed developed by Native American people from horses descended from Spain, developed from Iberian, Arabian and Barb stock brought to what is now the Southeastern United States by the Conquistadors.\n\nOne of the most famous of these early imports was Janus, a Thoroughbred who was the grandson of the Godolphin Arabian. He was foaled in 1746, and imported to colonial Virginia in 1756. The influence of Thoroughbreds like Janus contributed genes crucial to the development of the colonial \"Quarter Horse\". The breed is sometimes referred to as the \"Famous American Quarter Running Horse\". The resulting horse was small, hardy, and quick, and was used as a work horse during the week and a race horse on the weekends.\n\nAs flat racing became popular with the colonists, the Quarter Horse gained even more popularity as a sprinter over courses that, by necessity, were shorter than the classic racecourses of England, and were often no more than a straight stretch of road or flat piece of open land. When matched against a Thoroughbred, local sprinters often won. As the Thoroughbred breed became established in America, many colonial Quarter Horses were included in the original American stud books, starting a long association between the Thoroughbred breed and what would later become officially known as the \"Quarter Horse\", named after the race distance at which it excelled. with some individuals being clocked at up to 55 mph.\n\nIn the 19th century, pioneers heading West needed a hardy, willing horse. On the Great Plains, settlers encountered horses that descended from the Spanish stock Hernán Cortés and other Conquistadors had introduced into the viceroyalty of New Spain, which today includes the Southwestern United States and Mexico. These horses of the west included herds of feral animals known as Mustangs, as well as horses domesticated by Native Americans, including the Comanche, Shoshoni and Nez Perce tribes. As the colonial Quarter Horse was crossed with these western horses, the pioneers found that the new crossbred had innate \"cow sense\", a natural instinct for working with cattle, making it popular with cattlemen on ranches.\n\nEarly foundation sires of Quarter horse type included Steel Dust, foaled 1843; Shiloh (or Old Shiloh), foaled 1844; Old Cold Deck (1862); Lock's Rondo, one of many \"Rondo\" horses, foaled in 1880; Old Billy—again, one of many \"Billy\" horses—foaled circa 1880; Traveler, a stallion of unknown breeding, known to have been in Texas by 1889; and Peter McCue, foaled 1895, registered as a Thoroughbred but of disputed pedigree.\n\nThe main duty of the ranch horse in the American West was working cattle. Even after the invention of the automobile, horses were still irreplaceable for handling livestock on the range. Thus, major Texas cattle ranches, such as the King Ranch, the 6666 (Four Sixes) Ranch, and the Waggoner Ranch played a significant role in the development of the modern Quarter Horse. The skills needed by cowboys and their horses became the foundation of the rodeo, a contest which began with informal competition between cowboys and expanded to become a major competitive event throughout the west. To this day, the Quarter Horse dominates the sport both in speed events and in competition that emphasizes the handling of live cattle.\n\nHowever, sprint races were also popular weekend entertainment and racing became a source of economic gain for breeders as well. As a result, more Thoroughbred blood was added back into the developing American Quarter Horse breed. The American Quarter Horse also benefitted from the addition of Arabian, Morgan and even Standardbred bloodlines.\n\nIn 1940, the American Quarter Horse Association (AQHA) was formed by a group of horsemen and ranchers from the southwestern United States dedicated to preserving the pedigrees of their ranch horses. The horse honored with the first registration number, P-1, was Wimpy, a descendant of the King Ranch foundation sire Old Sorrel. Other sires alive at the founding of the AQHA were given the earliest registration numbers Joe Reed P-3, Chief P-5, Oklahoma Star P-6, Cowboy P-12, and Waggoner's Rainy Day P-13. The Thoroughbred race horse Three Bars, alive in the early years of the AQHA, is recognized by the American Quarter Horse Hall of Fame as one of the significant foundation sires for the Quarter Horse breed. Other significant Thoroughbred sires seen in early AQHA pedigrees include Rocket Bar, Top Deck and Depth Charge.\n\nSince the American Quarter Horse formally established itself as a breed, the AQHA stud book has remained open to additional Thoroughbred blood via a performance standard. An \"Appendix\" American Quarter Horse is a first generation cross between a registered Thoroughbred and an American Quarter Horse or a cross between a \"numbered\" American Quarter Horse and an \"appendix\" American Quarter Horse. The resulting offspring is registered in the \"appendix\" of the American Quarter Horse Association's studbook, hence the nickname. Horses listed in the appendix may be entered in competition, but offspring are not initially eligible for full AQHA registration. If the Appendix horse meets certain conformational criteria and is shown or raced successfully in sanctioned AQHA events, the horse can earn its way from the appendix into the permanent studbook, making its offspring eligible for AQHA registration\n\nSince Quarter Horse/Thoroughbred crosses continue to enter the official registry of the American Quarter Horse breed, this creates a continual gene flow from the Thoroughbred breed into the American Quarter Horse breed, which has altered many of the characteristics that typified the breed in the early years of its formation. Some breeders, who argue that the continued infusion of Thoroughbred bloodlines is beginning to compromise the integrity of the breed standard, favor the earlier style of horse and have created several separate organizations to promote and register \"Foundation\" Quarter Horses.\n\nThe American Quarter Horse is best known today as a show horse, race horse, reining and cutting horse, rodeo competitor, ranch horse, and all-around family horse. Quarter horses compete well in rodeo events such as barrel racing, calf roping and team roping; and gymkhana or O-Mok-See. Other stock horse events such as cutting and reining are open to all breeds but also dominated by American Quarter Horse. Large purses allow top competitors to earn over a million dollars in some of these events.\n\nThe breed is not only well-suited for western riding and cattle work. Many race tracks offer Quarter Horses a wide assortment of pari-mutuel horse racing with purses in the millions. Quarter Horses have also been trained to compete in dressage and can be good jumpers. They are also used for recreational trail riding and in mounted police units.\n\nThe American Quarter Horse has also been exported worldwide. European nations such as Germany and Italy have imported large numbers of Quarter Horses. Next to the American Quarter Horse Association (which also encompasses Quarter Horses from Canada), the second largest registry of Quarter Horses is in Brazil, followed by Australia. With the internationalization of the discipline of reining and its acceptance as one of the official seven events of the World Equestrian Games, there is a growing international interest in Quarter Horses. Countries like Japan, Switzerland and Israel that did not have traditional stock horse industries have begun to compete with American Quarter Horses in their own nations and internationally. The American Quarter Horse is the most popular breed in the United States today, and the American Quarter Horse Association is the largest breed registry in the world, with over 5 million American Quarter Horses registered worldwide.\n\nThe modern Quarter Horse has a small, short, refined head with a straight profile, and a strong, well-muscled body, featuring a broad chest and powerful, rounded hindquarters. They usually stand between high, although some Halter-type and English hunter-type horses may grow as tall as .\n\nThere are two main body types: the stock type and the hunter or racing type. The stock horse type is shorter, more compact, stocky and well muscled, yet agile. The racing and hunter type Quarter Horses are somewhat taller and smoother muscled than the stock type, more closely resembling the Thoroughbred.\n\nQuarter Horses come in nearly all colors. The most common color is sorrel, a brownish red, part of the color group called chestnut by most other breed registries. Other recognized colors include bay, black, brown, buckskin, palomino, gray, dun, red dun, grullo (also occasionally referred to as blue dun), red roan, blue roan, bay roan, perlino, cremello, and white. In the past, spotted color patterns were excluded, but now with the advent of DNA testing to verify parentage, the registry accepts all colors as long as both parents are registered.\n\nA stock horse is a horse of a type that is well suited for working with livestock, particularly cattle. Reining and cutting horses are smaller in stature, with quick, agile movements and very powerful hindquarters. Western pleasure show horses are often slightly taller, with slower movements, smoother gaits, and a somewhat more level topline – though still featuring the powerful hindquarters characteristic of the Quarter Horse. \n\nHorses shown in-hand in Halter competition are larger yet, with a very heavily muscled appearance, while retaining small heads with wide jowls and refined muzzles. There is controversy amongst owners, breeder and veterinarians regarding the health effects of the extreme muscle mass that is currently fashionable in the specialized halter horse, which typically is and weighs in at over when fitted for halter competition. Not only are there concerns about the weight to frame ratio on the horse's skeletal system, but the massive build is also linked to HYPP. (See \"Genetic diseases\" below))\n\nQuarter Horse race horses are bred to sprint short distances ranging from 220 to 870 yards. Thus, they have long legs and are leaner than their stock type counterparts, but are still characterized by muscular hindquarters and powerful legs. Quarter horses race primarily against other Quarter horses, and their sprinting ability has earned them the nickname, \"the world's fastest athlete.\" The show hunter type is slimmer, even more closely resembling a Thoroughbred, usually reflecting a higher percentage of appendix breeding. They are shown in hunter/jumper classes at both breed shows and in open USEF-rated horse show competition.\n\nThere are several genetic diseases of concern to Quarter Horse breeders:\n\n\n", "id": "2472", "title": "American Quarter Horse"}
{"url": "https://en.wikipedia.org/wiki?curid=2473", "text": "Abacá\n\nAbacá ( ; ), binomial name Musa textilis, is a species of banana native to the Philippines, grown as a commercial crop in the Philippines, Ecuador, and Costa Rica. The plant, also known as Manila hemp, has great economic importance, being harvested for its fiber, also called Manila hemp, extracted from the leaf-stems. The plant grows to , and averages about . The fiber was originally used for making twines and ropes; now most is pulped and used in a variety of specialized paper products including tea bags, filter paper and banknotes. It is classified as a hard fiber, along with coir, henequin and sisal.\n\nThe abacá plant is stoloniferous, meaning that the plant produces runners or shoots along the ground that then root at each segment. Cutting and transplanting rooted runners is the primary technique for creating new plants, since seed growth is substantially slower. Abacá has a \"false trunk\" or pseudostem about in diameter. The leaf stalks (petioles) are expanded at the base to form sheaths that are tightly wrapped together to form the pseudostem. There are from 12 to 25 leaves, dark green on the top and pale green on the underside, sometimes with large brown patches. They are oblong in shape with a deltoid base. They grow in succession. The petioles grow to at least in length. When the plant is mature, the flower stalk grows up inside the pseudostem. The male flower has 5 petals, each about long. The leaf sheaths contain the valuable fiber. After harvesting, the coarse fibers range in length from long. They are composed primarily of cellulose, lignin, and pectin.\n\nThe fruit, which is inedible and is rarely seen as harvesting occurs before the plant fruits, grows to about in length and in diameter. It has black turbinate seeds that are in diameter.\n\nThe abacá plant belongs to the banana family, Musaceae; it resembles the closely related wild seeded bananas, \"Musa acuminata\" and \"Musa balbisiana\". Its scientific name is \"Musa textilis\". Within the genus \"Musa\", it is placed in section \"Callimusa\" (now including the former section \"Australimusa\"), members of which have a diploid chromosome number of 2n = 20.\n\nBefore synthetic textiles came into use, \"M. textilis\" was a major source of high quality fiber: soft, silky and fine. Ancestors of the modern abaca are thought to have originated from the Eastern Philippines where there are lot of rains (no pronounced dry season), in fact wild type of abaca can still be found in the interior forests of Catanduanes Island which is often not cultivated. Today, Catanduanes has many other modern kinds of abaca which are more competitive. For many years, breeders from various research institutions have made the cultivated varieties of Catanduanes Island even more competitive in local and international markets. This results in the optimum production of the island which had a consistent highest production throughout the archipelago.\n\nEuropeans first came into contact with Abaca fibre when Magellan made land in the Philippines in 1521, as the natives were cultivating it and utilizing it in bulk for textiles already. By 1897, the Philippines were exporting almost 100,000 tons of abacá, and it was one of the three biggest cash crops, along with tobacco and sugar. In fact, from 1850 through the end of the 19th century, sugar or abacá alternated with each other as the biggest export crop of the Philippines. This 19th century trade was predominantly with the United States and the making of ropes was done mainly in New England, although in time the rope-making was moved back to the Philippines. Excluding the Philippines, abacá was first cultivated on a large scale in Sumatra in 1925 under the Dutch, who had observed its cultivation in the Philippines for cordage since the nineteenth century, followed up by plantings in Central America in 1929 sponsored by the U.S. Department of Agriculture. It also was transplanted into India and Guam. Commercial planting began in 1930 in British North Borneo; with the commencement of World War II, the supply from the Philippines was eliminated by the Japanese. \n\nIn the early 1900s, a train running from Danao to Argao would transport Philippine abaca from the plantations to Cebu city for export. The train and tracks were destroyed during the Second world war, however the Abaca plantations continue and are now transported to Cebu by road. \n\nAfter the war, the U.S. Department of Agriculture started production in Panama, Costa Rica, Honduras, and Guatemala. Today, abacá is produced primarily in the Philippines and Ecuador. The Philippines produces between 85% and 95% of the world's abacá, and the production employs 1.5 million people. Production has declined because of virus diseases.\nDue to its strength, it is a sought after product and is the strongest of the natural fibers. It is used by the paper industry for such specialty uses such as tea bags, banknotes and decorative papers. It can be used to make handcrafts such as bags, carpets, clothing and furniture. Abacá rope is very durable, flexible and resistant to salt water damage, allowing its use in hawsers, ship's lines and fishing nets. A rope can require to break. Abacá fiber was once used primarily for rope, but this application is now of minor significance. Lupis is the finest quality of abacá. Sinamay is woven chiefly from abacá.\n\nThe inner fibers are used in the making of hats, including the \"Manila hats,\" hammocks, matting, cordage, ropes, coarse twines, and types of canvas. It is called Manila hemp in the market although it is unlike true hemp, and is also known as Cebu hemp and Davao hemp. Abacá cloth is found in museum collections around the world, like the Boston Museum of Fine Arts and the Textile Museum of Canada.\n\nThe plant is normally grown in well-drained loamy soil, using rhizomes planted at the start of the rainy season. In addition, new plants can be started by seeds. Growers harvest abacá fields every three to eight months after an initial growth period of 12–25 months. Harvesting is done by removing the leaf-stems after flowering but before fruit appears. The plant loses productivity between 15 and 40 years. The slopes of volcanoes provide a preferred growing environment. Harvesting generally includes several operations involving the leaf sheaths:\n\nWhen the processing is complete, the bundles of fiber are pale and lustrous with a length of .\n\nIn Costa Rica, more modern harvest and drying techniques are being developed to accommodate the very high yields obtained there.\n\nAccording to the Philippine Fiber Industry Development Authority, the Philippines provided 87.4% of the world's abaca in 2014, earning the Philippines US$111.33 million. The demand is still greater than the supply. The remainder came from Ecuador (12.5%) and Costa Rica (0.1%). The Bicol region in the Philippines produced 27,885 metric tons of abaca in 2014, the largest of any Philippine region. The Philippine Rural Development Program (PRDP) and the Department of Agriculture reported that in 2009-2013, Bicol Region had 39% share of Philippine abaca producution while overwhelming 92% comes from Catanduanes Island. Eastern Visayas, the second largest producer had 24% and the Davao Region, the third largest producer had 11% of the total production. Around 42 percent of the total abaca fiber shipments from the Philippines went to the United Kingdom in 2014, making it the top importer. Germany imported 37.1 percent abaca pulp from the Philippines, importing around 7,755 metric tons (MT). Sales of abaca cordage surged 20 percent in 2014 to a total of 5,093 MT from 4,240 MT, with the United States holding around 68 percent of the market.\n\nAbacá is vulnerable to a number of pathogens, notably abaca bunchy top virus and abaca bract mosaic virus.\n\n\n\n", "id": "2473", "title": "Abacá"}
{"url": "https://en.wikipedia.org/wiki?curid=2474", "text": "Abaddon\n\nThe Hebrew term Abaddon (, \"\"), and its Greek equivalent Apollyon (, \"Apollyon\"), appears in the Bible as a place of destruction. In the Hebrew Bible, \"abaddon\" often appears alongside the place שאול (\"sheol\"), meaning the realm of the dead. In the New Testament Book of Revelation, an angel called Abaddon is described as the king of an army of locusts; his name is first transcribed in Greek (Revelation 9:11—\"whose name in Hebrew is Abaddon, The Angel of Death.\" (Ἀβαδδὼν), and then translated (\"which in Greek means the Destroyer\" (Ἀπολλύων, \"Apollyon\"))). The Latin Vulgate and the Douay Rheims Bible have additional notes (not present in the Greek text), \"in Latin Exterminans\", \"exterminans\" being the Latin word for \"destroyer\".\n\nAccording to the Brown Driver Briggs lexicon, the Hebrew \"abaddon\" (Hebrew: אבדון; \"avadon\") is an intensive form of the Semitic root and verb stem \"abad\" (אָבַד) \"perish\" (transitive \"destroy\"), which occurs 184 times in the Hebrew Bible. The Septuagint, an early Greek translation of the Hebrew Bible, renders \"abaddon\" as \"ἀπώλεια\", while the Greek \"Apollyon\" comes from \"apollumi\" (ἀπόλλυμι), \"to destroy\". The Greek term \"Apollyon\" (Ἀπολλύων, \"the destroyer\"), is the active participle of \"apollumi\" (ἀπόλλυμι, \"to destroy\"), and is not used as a name in classical Greek texts.\n\nThe term \"abaddon\" appears six times in the Masoretic text of the Hebrew Bible; \"abaddon\" means destruction or \"place of destruction\", or the realm of the dead, and is accompanied by Sheol. \n\nThe text of the Thanksgiving Hymns—which was found in the Dead Sea Scrolls—tells of \"the Sheol of Abaddon\" and of the \"torrents of Belial [that] burst into Abaddon\". The \"Biblical Antiquities\" (misattributed to Philo) mentions Abaddon as a place (destruction) rather than an individual. Abaddon is also one of the compartments of Gehenna. By extension, it can mean an underworld abode of lost souls, or Gehenna.\n\nIn some legends, Abaddon is identified as a realm where the damned lie in fire and snow, one of the places in Gehenna that Moses visited.\n\nThe Christian scriptures contain the first known depiction of \"Abaddon\" as an individual entity instead of a place.\nIn Revelation 9:11, Abaddon is described as \"Destroyer\", the angel of the abyss, and as the king of a plague of locusts resembling horses with crowned human faces, women's hair, lions' teeth, wings, iron breast-plates, and a tail with a scorpion's stinger that torments for five months anyone who does not have the seal of God on their foreheads.\n\nThe symbolism of Revelation 9:11 leaves the identity of Abaddon open to interpretation. Protestant commentator Matthew Henry (1708) believed Abaddon to be the Antichrist, whereas the Jamieson-Fausset-Brown Commentary (1871) and Henry H. Halley (1922) identified the angel as Satan. Latter-Day Saints believe that the use of \"Abaddon\" in Revelation 9 refers to the devil.\n\nIn contrast, the Methodist publication \"The Interpreter's Bible\" states: \"Abaddon, however, is an angel not of Satan but of God, performing his work of destruction at God's bidding\", citing the context at Revelation chapter 20, verses 1 through 3.\n\nJehovah's Witnesses as well cite Revelation 20:1-3 where the angel having \"the key of the abyss\" is actually shown to be a representative of God, one from heaven, and, rather than being \"satanic\", is the one that binds Satan and hurls him into the abyss; concluding that \"Abaddon\" is another name for Jesus Christ after his resurrection. To give further understanding, the book \"Insight from The Scriptures, Vol. 1 presents the following information: \n\nIn the 3rd century Acts of Thomas, Abaddon is the name of a demon, or the devil himself.\n\nAbaddon is given particularly important roles in two sources, a homily entitled \"The Enthronement of Abbaton\" by pseudo-Timothy of Alexandria, and the Apocalypse of Bartholomew. In the homily by Timothy, Abbaton was first named \"Muriel\", and had been given the task by God of collecting the earth that would be used in the creation of Adam. Upon completion of this task, the angel was appointed as a guardian. Everyone, including the angels, demons, and corporeal entities feared him. Abbaton was promised that any who venerated him in life could be saved. Abaddon is also said to have a prominent role in the Last Judgement, as the one who will take the souls to the Valley of Josaphat. He is described in the Apocalypse of Bartholomew as being present in the Tomb of Jesus at the moment of his resurrection.\n\n\n", "id": "2474", "title": "Abaddon"}
{"url": "https://en.wikipedia.org/wiki?curid=2475", "text": "Abadeh\n\nAbadeh (, also Romanized as Ābādeh) is a city in and the capital of Abadeh County, in Fars Province, Iran. Abadeh is situated at an elevation of in a fertile plain on the high road between Isfahan and Shiraz, from the former and from the latter. At the 2006 census, its population was 52,042, in 14,184 families. As of 2009, the population was estimated to be 59042.\n\nIt is the largest city in the Northern Fars Region (South Central-Iran), which is famed for its carved wood-work, made of the wood of pear and box trees. Sesame oil, castor oil, grain, and various fruits are also produced there. The area is famous for its Abadeh rugs.\n\nAn interesting fact is that Abadeh is closer, road-distance-wise to 4 provincial capitals of Isfahan (193 km), Yasuj (197 km), Yazd (217 km), and Shahrekord (237 km) compared to the distance to the provincial capital of its corresponding province, Shiraz (260 km).\n\nAbadeh historical monuments include Emirate Kolah Farangi, Tymcheh Sarafyan and Khaje tomb, located in the Khoja mountains.\nAbadeh crafts can be embroidered in cotton. The town also produces Abadeh rugs.\n\nThe rugs tend to be based on a cotton warp and have a thin, tightly knotted pile. Most Abadeh rugs are closely cut making them very flat. Although some of the older Abadehs vary in style, many of the new designs are easily recognisable. These new designs, known as Heybatlu consist of a single diamond shaped medallion in the centre with smaller medallions on each corner. The pattern is typically geometrical flowers or animals and the main colours are light reds or burnt orange on top of a dark blue background with strong green details. The corners or borders are generally ivory in colour. Although some Abadeh and Shiraz rugs appear similar Abadeh can normally be differentiated by their higher knot counts as well as the fact that the warp is invariably cotton. The rugs are almost always exclusively medium in size and the KPSI of an average Abadeh is around 90. As always in the rug-world you get what you pay for however in general Abadeh are well made and fairly popular items, particularly in modern interiors or those with a Mediterranean or North African style.\n\nExpressway 65 passes through Abadeh. This situation helps Abadeh to improve its capabilities compared to the neighboring city, Eqlid. Road 78 makes connections from Abadeh to Abarkuh, Yazd Eqlid and Yasuj. It has a junction with Abadeh Shiraz Expressway 24 km south of the city. A road starts from Abadeh Ring Road to Soqad and Semirom, Road 55.\n\nThe railroad from Isfahan to Shiraz passes Abadeh and there are train services at Abadeh Railway Station to Shiraz, Esfahan, Tehran and Mashad. Abadeh Airport (OISA) was planned to be built in the mid 1990s.\n\nAbadeh's main sport is Football, like the rest of the country. The main stadium is Takhti Stadium located in Mo'allem Square. The main team in Abadeh is Behineh Rahbar Abadeh F.C. which is currently playing in Iran Football's 3rd Division after finishing first in Fars Provincial League (FPL) last year. It played in Hazfi Cup 2010-11 reaching the fourth round.\n\nIran announced in 2012 the construction of the largest air defense site in the southern Iranian city of Abadeh.\n\nAbadeh features a continental semi-arid climate (Köppen \"BSk\") with extreme heat and dryness over summer, and cold (extreme at times) and wet winter, with huge variations between daytime and nighttime throughout the year.\n", "id": "2475", "title": "Abadeh"}
{"url": "https://en.wikipedia.org/wiki?curid=2476", "text": "Abae\n\nAbae (, \"Abai\") is an ancient town in the northeastern corner of Phocis, in Greece. It was famous in antiquity for its oracle of Apollo Abaeus, one of those consulted by Croesus, king of Lydia, and Mardonius, among others.\n\nIt was rich in treasures, but was destroyed by the Persians in the invasion of Xerxes in 480 BCE, and a second time by the Boeotians and remained in a ruined state.It was rebuilt by Hadrian.\n\nThe oracle was, however, still consulted, e.g. by the Thebans before Leuctra in 371 BCE. The temple, along with the village of the same name, may have escaped destruction during the Third Sacred War (355–346 BCE), due to the respect given to the inhabitants; however it was in a very dilapidated state when seen by Pausanias in the 2nd century CE, though some restoration, as well as the building of a new temple, was undertaken by Emperor Hadrian.\n\nThe sanctity of the shrine ensured certain privileges to the people of Abae, and these were confirmed by the Romans. The Persians did not reflect this opinion and would destroy all the temples that they overcame, Abae included. The Greek pledged to not rebuild them as a memorial of the ravages of the Persians.\n\nAmong the most exciting recent archaeological discoveries in Greece is the recognition that the sanctuary site near the modern village of Kalapodi is not only the site of the oracle of Apollon at Abai but that it was in constant use for cult practices from early Mycenaean times to the Roman period. It is thus the first site where the archaeology confirms the continuity of Mycenaean and Classical Greek religion, which has been inferred from the presence of the names of Classical Greek divinities on Linear B texts from Pylos and Knossos.\n\nThe fortified site described below, originally identified as Abae by Colonel William Leake in the 19th century, is much more likely to be that of the Sanctuary of Artemis at Hyampolis.\n\nThe polygonal walls of the acropolis may still be seen in a fair state of preservation on a circular hill standing about above the little plain of Exarcho; one gateway remains, and there are also traces of town walls below. The temple site was on a low spur of the hill, below the town. An early terrace wall supports a precinct in which are a stoa and some remains of temples; these were excavated by the British School at Athens in 1894, but little was found.\n\n", "id": "2476", "title": "Abae"}
