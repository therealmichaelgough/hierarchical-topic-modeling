{"url": "https://en.wikipedia.org/wiki?curid=6198", "text": "Convention on Biological Diversity\n\nThe Convention on Biological Diversity (CBD), known informally as the Biodiversity Convention, is a multilateral treaty. The Convention has three main goals including: the conservation of biological diversity (or biodiversity); the sustainable use of its components; and the fair and equitable sharing of benefits arising from genetic resources.\n\nIn other words, its objective is to develop national strategies for the conservation and sustainable use of biological diversity. It is often seen as the key document regarding sustainable development. The Convention was opened for signature at the Earth Summit in Rio de Janeiro on 5 June 1992 and entered into force on 29 December 1993. At the 2010 10th Conference of Parties (COP) to the Convention on Biological Diversity in October in Nagoya, Japan, the Nagoya Protocol was adopted.\n\nThe notion of an international convention on biological diversity was conceived at a United Nations Environment Programme (UNEP) Ad Hoc Working Group of Experts on Biological Diversity in November 1988. The subsequent year, the Ad Hoc Working Group of Technical and Legal Experts was established for the drafting of a legal text which addressed the conservation and sustainable use of biological diversity, as well as the sharing of benefits arising from their utilization with sovereign states and local communities.\nIn 1991, an intergovernmental negotiating committee was established, tasked with finalizing the convention's text.\n\nA Conference for the Adoption of the Agreed Text of the Convention on Biological Diversity was held in Nairobi, Kenya, in 1992, and its conclusions were distilled in the Nairobi Final Act. The Convention's text was opened for signature on 5 June 1992 at the United Nations Conference on Environment and Development (the Rio \"Earth Summit\"). By its closing date, 4 June 1993, the convention had received 168 signatures. It entered into force on 29 December 1993.\n\nThe convention recognized for the first time in international law that the conservation of biological conservation of biodiversity is \"a common concern of humankind\" and is an integral part of the development process. The agreement covers all ecosystems, species, and genetic resources. It links traditional conservation efforts to the economic goal of using biological resources sustainably. It sets principles for the fair and equitable sharing of the benefits arising from the use of genetic resources, notably those destined for commercial use. It also covers the rapidly expanding field of biotechnology through its Cartagena Protocol on Biosafety, addressing technology development and transfer, benefit-sharing and biosafety issues. Importantly, the Convention is legally binding; countries that join it ('Parties') are obliged to implement its provisions.\n\nThe convention reminds decision-makers that natural resources are not infinite and sets out a philosophy of sustainable use. While past conservation efforts were aimed at protecting particular species and habitats, the Convention recognizes that ecosystems, species and genes must be used for the benefit of humans. However, this should be done in a way and at a rate that does not lead to the long-term decline of biological diversity.\n\nThe convention also offers decision-makers guidance based on the precautionary principle which demands that where there is a threat of significant reduction or loss of biological diversity, lack of full scientific certainty should not be used as a reason for postponing measures to avoid or minimize such a threat. The Convention acknowledges that substantial investments are required to conserve biological diversity. It argues, however, that conservation will bring us significant environmental, economic and social benefits in return.\n\nThe Convention on Biological Diversity of 2010 banned some forms of geoengineering.\n\nSome of the many issues dealt with under the convention include:\n\n\nThe Cartagena Protocol on Biosafety of the Convention, also known as the Biosafety Protocol, was adopted in January 2000. The Biosafety Protocol seeks to protect biological diversity from the potential risks posed by living modified organisms resulting from modern biotechnology.\n\nThe Biosafety Protocol makes clear that products from new technologies must be based on the precautionary principle and allow developing nations to balance public health against economic benefits. It will for example let countries ban imports of a genetically modified organism if they feel there is not enough scientific evidence the product is safe and requires exporters to label shipments containing genetically modified commodities such as corn or cotton.\n\nThe required number of 50 instruments of ratification/accession/approval/acceptance by countries was reached in May 2003. In accordance with the provisions of its Article 37, the Protocol entered into force on 11 September 2003.\n\nIn April 2002, the parties of the UN CBD adopted the recommendations of the Gran Canaria Declaration Calling for a Global Plant Conservation Strategy, and adopted a 16-point plan aiming to slow the rate of plant extinctions around the world by 2010.\n\nAs of 2016, the Convention has 196 parties, which includes 195 states and the European Union. All UN member states—with the exception of the United States—have ratified the treaty. Non-UN member states that have ratified are the Cook Islands, Niue, and the State of Palestine. The Holy See and the states with limited recognition are non-parties. The US has signed but not ratified the treaty, and has not announced plans to ratify it.\n\nConference of the parties:\nThe convention's governing body is the Conference of the parties (COP), consisting of all governments (and regional economic integration organizations) that have ratified the treaty. This ultimate authority reviews progress under the Convention, identifies new priorities, and sets work plans for members. The COP can also make amendments to the Convention, create expert advisory bodies, review progress reports by member nations, and collaborate with other international organizations and agreements.\n\nThe Conference of the Parties uses expertise and support from several other bodies that are established by the Convention. In addition to committees or mechanisms established on an ad hoc basis, two main organs are:\n\nSecretariat:\nThe CBD Secretariat, based in Montreal, operates under the United Nations Environment Programme. Its main functions are to organize meetings, draft documents, assist member governments in the implementation of the programme of work, coordinate with other international organizations, and collect and disseminate information.\n\nSubsidiary body for Scientific, Technical and Technological Advice (SBSTTA):\nThe Subsidiary Body on Scientific, Technical and Technological Advice (SBSTTA). The SBSTTA is a committee composed of experts from member governments competent in relevant fields. It plays a key role in making recommendations to the COP on scientific and technical issues. 13th Meeting of the Subsidiary Body on Scientific, Technical and Technological Advice (SBSTTA-13) held from 18 to 22 February 2008 in the Food and Agriculture Organization at Rome, Italy. SBSTTA-13 delegates met in the Committee of the Whole in the morning to finalize and adopt recommendations on the in-depth reviews of the work programmes on agricultural and forest biodiversity and SBSTTA's modus operandi for the consideration of new and emerging issues. The closing plenary convened in the afternoon to adopt recommendations on inland waters biodiversity, marine biodiversity, invasive alien species and biodiversity and climate change. The current chairperson of the SBSTTA is Dr. Senka Barudanovic.\n\n\"National Biodiversity Strategies and Action Plans (NBSAPs) are the principal instruments for implementing the Convention at the national level (Article 6). The Convention requires countries to prepare a national biodiversity strategy (or equivalent instrument) and to ensure that this strategy is mainstreamed into the planning and activities of all those sectors whose activities can have an impact (positive and negative) on biodiversity. To date [2012-02-01], 173 Parties have developed NBSAPs in line with Article 6.\"\n\nFor example, the United Kingdom, New Zealand and Tanzania have carried out elaborate responses to conserve individual species and specific habitats. The United States of America, a signatory who has not yet ratified the treaty, has produced one of the most thorough implementation programs through species Recovery Programs and other mechanisms long in place in the USA for species conservation.\n\nSingapore has also established a detailed \"National Biodiversity Strategy and Action Plan\". The \"National Biodiversity Centre\" of Singapore represents Singapore in the Convention for Biological Diversity.\n\nIn accordance with Article 26 of the Convention, Parties prepare national reports on the status of implementation of the Convention.\n\nThe current executive secretary is Cristiana Pașca Palmer, who took up this post on 17 March 2017. Braulio Ferreira de Souza Dias was the previous executive secretary.\n\nThe Nagoya Protocol on Access to Genetic Resources and the Fair and Equitable Sharing of Benefits Arising from their Utilization to the Convention on Biological Diversity is a supplementary agreement to the Convention on Biological Diversity. It provides a transparent legal framework for the effective implementation of one of the three objectives of the CBD: the fair and equitable sharing of benefits arising out of the utilization of genetic resources. The Protocol was adopted on 29 October 2010 in Nagoya, Aichi Province, Japan, and entered into force on 12 October 2014. Its objective is the fair and equitable sharing of benefits arising from the utilization of genetic resources, thereby contributing to the conservation and sustainable use of biodiversity.\n\nThe first ordinary meeting of the parties to the convention took place in November and December 1994, in Nassau, Bahamas.\n\nThe second ordinary meeting of the parties to the convention took place in November 1995, in Jakarta, Indonesia.\n\nThe third ordinary meeting of the parties to the convention took place in November 1996, in Buenos Aires, Argentina.\n\nThe fourth ordinary meeting of the parties to the convention took place in May 1998, in Bratislava, Slovakia.\n\nThe First Extraordinary Meeting of the Conference of the Parties took place in February 1999, in Cartagena, Colombia.\n\nThe fifth ordinary meeting of the parties to the convention took place in May 2000, in Nairobi, Kenya.\n\nThe sixth ordinary meeting of the parties to the convention took place in April 2002, in The Hague, Netherlands.\n\nThe seventh ordinary meeting of the parties to the convention took place in February 2004, in Kuala Lumpur, Malaysia.\n\nThe eighth ordinary meeting of the parties to the convention took place in March 2006, in Curitiba, Brazil.\n\nThe ninth ordinary meeting of the parties to the convention took place in May 2008, in Bonn, Germany.\n\nThe tenth ordinary meeting of the parties to the convention took place in October 2010, in Nagoya, Japan.\n\nLeading up to the Conference of the Parties (COP 11) meeting on biodiversity in Hyderabad, India 2012, preparations for a World Wide Views on Biodiversity has begun, involving old and new partners and building on the experiences from the World Wide Views on Global Warming.\n\nUnder the theme, \"Biodiversity for Sustainable Development,\" thousands of representatives of governments, NGOs, indigenous peoples, scientists and the private sector gathered in Pyeongchang, Republic of Korea in October 2014 for the 12th meeting of the Conference of the Parties to the Convention on Biological Diversity (COP 12).\n\nFrom 6–17 October 2014, Parties discussed the implementation of the Strategic Plan for Biodiversity 2011-2020 and its Aichi Biodiversity Targets, which are to be achieved by the end of this decade. The results of Global Biodiversity Outlook 4, the flagship assessment report of the CBD informed the discussions.\n\nThe conference gave a mid-term evaluation to the UN Decade on Biodiversity (2011-2020) initiative, which aims to promote the conservation and sustainable use of nature.\nAt the end of the meeting, the meeting adopted the \"Pyeongchang Road Map,\" which addresses ways to achieve biodiversity through technology cooperation, funding and strengthening the capacity of developing countries.\n\nThe thirteenth ordinary meeting of the parties to the convention is taking place between 2 and 17 December 2016 in Cancun, Mexico.\n\n2010 was the International Year of Biodiversity. The Secretariat of the Convention on Biological Diversity is the focal point for the International Year of Biodiversity. On 22 December 2010, the UN declared the period from 2011 to 2020 as the United Nations Decade on Biodiversity. They, hence, followed a recommendation of the CBD signatories during COP10 at Nagoya in October 2010.\n\nAlthough the convention explicitly states that all forms of life are covered by its provisions, examination of reports and of national biodiversity strategies and action plans submitted by participating countries shows that in practice this is not happening. The fifth report of the European Union, for example, makes frequent reference to animals (particularly fish) and plants, but does not mention bacteria, fungi or protists at all. The International Society for Fungal Conservation has assessed more than 100 of these CBD documents for their coverage of fungi using defined criteria to place each in one of six categories. No documents were assessed as good or adequate, less than 10% as nearly adequate or poor, and the rest as deficient, seriously deficient or totally deficient.\n\n\n\"This article is partly based on the relevant entry in the CIA World Factbook, edition.\"\n\n\n", "id": "6198", "title": "Convention on Biological Diversity"}
{"url": "https://en.wikipedia.org/wiki?curid=6199", "text": "Convention on Fishing and Conservation of the Living Resources of the High Seas\n\nThe Convention on Fishing and Conservation of Living Resources of the High Seas is an agreement that was designed to solve through international cooperation the problems involved in the conservation of living resources of the high seas, considering that because of the development of modern technology some of these resources are in danger of being overexploited.\n\n\"opened for signature -\" 29 April 1958\n\n\"entered into force -\" 20 March 1966\n\n\"parties -\" (39) Australia, Belgium, Bosnia and Herzegovina, Burkina Faso, Cambodia, Colombia, Republic of the Congo, Denmark, Dominican Republic, Fiji, Finland, France, Haiti, Indonesia, Jamaica, Kenya, Lesotho, Madagascar, Malawi, Malaysia, Mauritius, Mexico, Netherlands, Nigeria, Portugal, Senegal, Serbia, Sierra Leone, Solomon Islands, South Africa, Spain, Switzerland, Thailand, Tonga, Trinidad and Tobago, Uganda, United Kingdom, United States, Venezuela\n\n\"countries that have signed, but not yet ratified -\" (20) Afghanistan, Argentina, Bolivia, Canada, Costa Rica, Cuba, Ghana, Iceland, Iran, Ireland, Israel, Lebanon, Liberia, Nepal, New Zealand, Pakistan, Panama, Sri Lanka, Tunisia, Uruguay\n\nSource:\n\n\n", "id": "6199", "title": "Convention on Fishing and Conservation of the Living Resources of the High Seas"}
{"url": "https://en.wikipedia.org/wiki?curid=6200", "text": "Convention on Long-Range Transboundary Air Pollution\n\nThe Convention on Long-Range Transboundary Air Pollution, often abbreviated as Air Pollution or CLRTAP, is intended to protect the human environment against air pollution and to gradually reduce and prevent air pollution, including long-range transboundary air pollution. It is implemented by the European Monitoring and Evaluation Programme (EMEP), directed by the United Nations Economic Commission for Europe (UNECE).\n\nThe convention opened for signature on 1979-11-13 and entered into force on 1983-03-16.\n\nThe Convention, which now has 51 Parties, identifies the Executive Secretary of the United Nations Economic Commission for Europe (UNECE) as its secretariat. The current parties to the Convention are shown on the map.\n\nThe Convention is implemented by the European Monitoring and Evaluation Programme (EMEP) (short for \"Co-operative Programme for Monitoring and Evaluation of the Long-range Transmission of Air Pollutants in Europe\"). Results of the EMEP programme are published on the EMEP website, www.emep.int.\n\nSince 1979 the Convention on Long-range Transboundary Air Pollution has addressed some of the major environmental problems of the UNECE region through scientific collaboration and policy negotiation. The Convention has been extended by eight protocols that identify specific measures to be taken by Parties to cut their emissions of air pollutants:\n\n\nThe aim of the Convention is that Parties shall endeavour to limit and, as far as possible, gradually reduce and prevent air pollution including long-range transboundary air pollution. Parties develop policies and strategies to combat the discharge of air pollutants through exchanges of information, consultation, research and monitoring.\n\nThe Parties meet annually at sessions of the Executive Body to review ongoing work and plan future activities including a workplan for the coming year. The three main subsidiary bodies - the Working Group on Effects, the Steering Body to EMEP and the Working Group on Strategies and Review - as well as the Convention's Implementation Committee, report to the Executive Body each year.\n\nCurrently, the Convention's priority activities include review and possible revision of its most recent protocols, implementation of the Convention and its protocols across the entire UNECE region (with special focus on Eastern Europe, the Caucasus and Central Asia and South-East Europe) and sharing its knowledge and information with other regions of the world.\n\n\n", "id": "6200", "title": "Convention on Long-Range Transboundary Air Pollution"}
{"url": "https://en.wikipedia.org/wiki?curid=6201", "text": "CITES\n\nCITES (the Convention on International Trade in Endangered Species of Wild Fauna and Flora, also known as the Washington Convention) is a multilateral treaty to protect endangered plants and animals. It was drafted as a result of a resolution adopted in 1963 at a meeting of members of the International Union for Conservation of Nature (IUCN). The convention was opened for signature in 1973 and CITES entered into force on 1 July 1975. Its aim is to ensure that international trade in specimens of wild animals and plants does not threaten the survival of the species in the wild, and it accords varying degrees of protection to more than 35,000 species of animals and plants. In order to ensure that the General Agreement on Tariffs and Trade (GATT) was not violated, the Secretariat of GATT was consulted during the drafting process.\n\n, Secretary-General of the CITES Secretariat is John E. Scanlon.\n\nCITES is one of the largest and oldest conservation and sustainable use agreements in existence. Participation is voluntary, and countries that have agreed to be bound by the Convention are known as Parties. Although CITES is legally binding on the Parties, it does not take the place of national laws. Rather it provides a framework respected by each Party, which must adopt their own domestic legislation to implement CITES at the national level. Often, domestic legislation is either non-existent (especially in Parties that have not ratified it), or with penalties with the gravity of the crime and insufficient deterrents to wildlife traders. As of 2002, 50% of Parties lacked one or more of the four major requirements for a Party: designation of Management and Scientific Authorities; laws prohibiting the trade in violation of CITES; penalties for such trade; laws providing for the confiscation of specimens.\n\nFunding for the activities of the Secretariat and Conference of the Parties (CoP) meetings comes from a Trust Fund derived from Party contributions. Trust Fund money is not available to Parties to improve implementation or compliance. These activities, and all those outside Secretariat activities (training, species specific programmes such as Monitoring the Illegal Killing of Elephants - MIKE) must find external funding, mostly from donor countries and regional organizations such as the European Union.\n\nAlthough the Convention itself does not provide for arbitration or dispute in the case of noncompliance, 36 years of CITES in practice has resulted in several strategies to deal with infractions by Parties. The Secretariat, when informed of an infraction by a Party, will notify all other parties. The Secretariat will give the Party time to respond to the allegations and may provide technical assistance to prevent further infractions. Other actions the Convention itself does not provide for but that derive from subsequent COP resolutions may be taken against the offending Party. These include:\nBilateral sanctions have been imposed on the basis of national legislation (e.g. the USA used certification under the Pelly Amendment to get Japan to revoke its reservation to hawksbill turtle products in 1991, thus reducing the volume of its exports).\n\nInfractions may include negligence with respect to permit issuing, excessive trade, lax enforcement, and failing to produce annual reports (the most common).\n\nOriginally, CITES addressed depletion resulting from demand for luxury goods such as furs in Western countries, but with the rising wealth of Asia, particularly in China, the focus changed to products demanded there, particularly those used for luxury goods such as ivory or shark fins or for superstitious purposes such as rhinoceros horn. As of 2013 the demand was massive and had expanded to include thousands of species previously considered unremarkable and in no danger of extinction such as manta rays or pangolins.\n\nThe text of the Convention was finalized at a meeting of representatives of 80 countries in Washington, D.C., United States, on 3 March 1973. It was then open for signature until 31 December 1974. It entered into force after the 10th ratification by a signatory country, on 1 July 1975. Countries that signed the Convention become Parties by ratifying, accepting or approving it. By the end of 2003, all signatory countries had become Parties. States that were not signatories may become Parties by acceding to the Convention. As of October 2016, the Convention has 183 parties, including 182 states and the European Union.\n\nThe CITES Convention includes provisions and rules for trade with non-Parties. All member states of the United Nations are party to the treaty, with the exception of Andorra, Democratic People's Republic of Korea, Federated States of Micronesia, Haiti, Kiribati, Marshall Islands, Nauru, South Sudan, Timor-Leste, Tonga, Turkmenistan, and Tuvalu. UN observer the Holy See is also not a member. The Faroe Islands, an autonomous country in the Kingdom of Denmark, is also treated as a non-Party to CITES (both the Danish mainland and Greenland are part of CITES).\n\nAn amendment to the text of the Convention, known as the Gaborone Amendment allows regional economic integration organizations (REIO), such as the European Union, to have the status of a member state and to be a Party to the Convention. The REIO can vote at CITES meetings with the number of votes representing the number of members in the REIO, but it does not have an additional vote.\n\nIn accordance with Article XVII, paragraph 3, of the CITES Convention, the Gaborone Amendment entered into force on 29 November 2013, 60 days after 54 (two-thirds) of the 80 States that were party to CITES on 30 April 1983 deposited their instrument of acceptance of the amendment. At that time it entered into force only for those States that had accepted the amendment. The amended text of the Convention will apply automatically to any State that becomes a Party after 29 November 2013. For States that became party to the Convention before that date and have not accepted the amendment, it will enter into force 60 days after they accept it.\n\nCITES works by subjecting international trade in specimens of selected species to certain controls. All import, export, re-export and introduction from the sea of species covered by the Convention has to be authorized through a licensing system. According to Article IX of the Convention, Management and Scientific Authorities, each Party to the Convention must designate one or more Management Authorities in charge of administering that licensing system and one or more Scientific Authorities to advise them on the effects of trade on the status of CITES-listed species.\n\nRoughly 5,000 species of animals and 29,000 species of plants are protected by CITES against over-exploitation through international trade. Each protected species or population is included in one of three lists, called appendices (explained below). The Appendix that lists a species or population reflects the extent of the threat to it and the controls that apply to the trade.\n\nSpecies may be split-listed meaning that some populations of a species are on one Appendix, while some are on another. Some people argue that this is risky as specimens from a more protected population could be ‘laundered’ through the borders of a Party whose population is not as strictly protected. The African bush elephant (\"Loxodonta africana\") is currently split-listed, with all populations except those of Botswana, Namibia, South Africa and Zimbabwe listed in Appendix I. Those of Botswana, Namibia, South Africa and Zimbabwe are listed in Appendix II. Listing the species over the whole of its range would prevent such ‘laundering’ but also restricts trade in wildlife products by range states with good management practices. There are also species that have only some populations listed in an Appendix. One example is the pronghorn (\"Antilocapra americana\"), a ruminant native to North America. Its Mexican population is listed in Appendix I, but its U.S. and Canadian populations are not listed (though certain U.S. populations in Arizona are nonetheless protected under the Endangered Species Act).\n\nSpecies are proposed for inclusion in or deletion from the Appendices at meetings of the Conference of the Parties (CoP), which are held approximately once every three years, the most recent of which was CoP (CoP 17) in Johannesburg, South Africa from 24 September to 5 October 2016 at the Sandton Convention Center.\n\nSpecies in the Appendices may be proposed for addition, change of Appendix, or de-listing (i.e., deletion) by any Party, whether or not it is a range State and changes may be made despite objections by range States if there is sufficient (2/3 majority) support for the listing. These discussions are usually among the most contentious at CoP meetings.\n\nThere has been increasing willingness within the Parties to allow for trade in products from well-managed populations. For instance, sales of the South African white rhino have generated revenues that helped pay for protection. Listing the species on Appendix I increased the price of rhino horn (which fueled more poaching), but the species survived wherever there was adequate on-the-ground protection. Thus field protection may be the primary mechanism that saved the population, but it is likely that field protection would not have been increased without CITES protection.\n\nAppendix I, about 1200 species, are species that are threatened with extinction and are or may be affected by trade. Commercial trade in wild-caught specimens of these species is illegal (permitted only in exceptional licensed circumstances). Captive-bred animals or cultivated plants of Appendix I species are considered Appendix II specimens, with concomitant requirements (see below and Article VII). The Scientific Authority of the exporting country must make a non-detriment finding, assuring that export of the individuals will not adversely affect the wild population. Any trade in these species requires export and import permits. The Management Authority of the exporting state is expected to check that an import permit has been secured and that the importing state is able to care for the specimen adequately. Notable animal species listed in Appendix I include the red panda (\"Ailurus fulgens\"), western gorilla (\"Gorilla gorilla\"), the chimpanzee species (\"Pan spp.\"), tigers (\"Panthera tigris\" subspecies), Asiatic lion (\"Panthera leo persica\"), leopards (\"Panthera pardus\"), jaguar (\"Panthera onca\"), cheetah (\"Acinonyx jubatus\"), Asian elephant (\"Elephas maximus\"), some populations of African bush elephant (\"Loxodonta africana\"), the dugong and manatees (Sirenia), and all rhinoceros species (except some Southern African subspecies populations).\n\nAppendix II, about 21,000 species, are species that are not necessarily threatened with extinction, but may become so unless trade in specimens of such species is subject to strict regulation in order to avoid utilization incompatible with the survival of the species in the wild. In addition, Appendix II can include species similar in appearance to species already listed in the Appendices. International trade in specimens of Appendix II species may be authorized by the granting of an export permit or re-export certificate. In practice, many hundreds of thousands of Appendix II animals are traded annually. No import permit is necessary for these species under CITES, although some Parties do require import permits as part of their stricter domestic measures. A non-detriment finding and export permit are required by the exporting Party.\n\nIn addition, Article VII of CITES states that specimens of animals listed in Appendix I that are bred in captivity for commercial purposes are treated as Appendix II. The same applies for specimens of Appendix I plants artificially propagated for commercial purposes.\n\nExamples of species listed on Appendix II are the great white shark (\"Carcharodon carcharias\"), the American black bear (\"Ursus americanus\"), Hartmann's mountain zebra (\"Equus hartmannae\"), green iguana (\"Iguana iguana\"), queen conch (\"Strombus gigas\"), Emperor scorpion (\"Pandinus imperator\"), Mertens' water monitor (\"Varanus mertensi\"), bigleaf mahogany (\"Swietenia macrophylla\") and lignum vitae \"ironwood\" (\"Guaiacum officinale\").\n\nAppendix III, about 170 species, are species that are listed after one member country has asked other CITES Parties for assistance in controlling trade in a species. The species are not necessarily threatened with extinction globally. In all member countries, trade in these species is only permitted with an appropriate export permit and a certificate of origin from the state of the member country who has listed the species.\n\nExamples of species listed on Appendix III and the countries that listed them are the two-toed sloth (\"Choloepus hoffmanni\") by Costa Rica, African civet (\"Civettictis civetta\") by Botswana, and the alligator snapping turtle (\"Macrochelys temminckii\") by the USA.\n\nAmendments to the Convention must be supported by a two-thirds majority who are \"present and voting\" and can be made during an extraordinary meeting of the COP if one-third of the Parties are interested in such a meeting. The Gaborone Amendment (1983) allows regional economic blocs to accede to the treaty. Reservations (Article XXIII) can be made by any Party with respect to any species, which considerably weakens the treaty (see for current reservations). Trade with non-Party states is allowed, although permits and certificates are recommended to be issued by exporters and sought by importers.\n\nNotable reservations include those by Iceland, Japan and Norway on various baleen whale species and those on Falconiformes by Saudi Arabia.\n\nGeneral limitations about the structure and philosophy of CITES include: by design and intent it focuses on trade at the species level and does not address habitat loss, ecosystem approaches to conservation, or poverty; it seeks to prevent unsustainable use rather than promote sustainable use (which generally conflicts with the Convention on Biological Diversity), although this has been changing (see Nile crocodile, African elephant, South African white rhino case studies in Hutton and Dickinson 2000). It does not explicitly address market demand. Funding does not provide for increased on-the-ground enforcement (it must apply for bilateral aid for most projects of this nature).\n\nBy design, CITES regulates and monitors trade in the manner of a \"negative list\" such that trade in all species is permitted and unregulated \"unless\" the species in question appears on the Appendices or looks very much like one of those taxa. Then and only then, trade is regulated or constrained. Because the remit of the Convention covers millions of species of plants and animals, and tens of thousands of these taxa are potentially of economic value, in practice this negative list approach effectively forces CITES signatories to expend limited resources on just a select few, leaving many species to be traded with neither constraint nor review. For example, recently several bird classified as threatened with extinction appeared in the legal wild bird trade because the CITES process never considered their status. If a \"positive list\" approach were taken, only species evaluated and approved for the positive list would be permitted in trade, thus lightening the review burden for member states and the Secretariat, and also preventing inadvertent legal trade threats to poorly known species.\n\nSpecific weaknesses in the text include: it does not stipulate guidelines for the 'non-detriment' finding required of national Scientific Authorities; non-detriment findings require copious amounts of information; the 'household effects' clause is often not rigid enough/specific enough to prevent CITES violations by means of this Article (VII); non-reporting from Parties means Secretariat monitoring is incomplete; and it has no capacity to address domestic trade in listed species.\n\nSuggestions for improvement in the operation of CITES include: more regular missions by the Secretariat (not reserved just for high-profile species); improvement of national legislation and enforcement; better reporting by Parties (and the consolidation of information from all sources-NGOs, TRAFFIC, the wildlife trade monitoring network and Parties); more emphasis on enforcement-including a technical committee enforcement officer; the development of CITES Action Plans (akin to Biodiversity Action Plans related to the Convention on Biological Diversity) including: designation of Scientific/Management Authorities and national enforcement strategies; incentives for reporting and timelines for both Action Plans and reporting. CITES would benefit from access to Global Environment Faculty (GEF), funds-although this is difficult given the GEFs more ecosystem approach-or other more regular funds. Development of a future mechanism similar to that of the Montreal Protocol (developed nations contribute to a fund for developing nations) could allow more funds for non-Secretariat activities.\n\nOn 15 July 2008, the Committee of Environmental Insecticides that oversees the administration of the convention between meetings of all the Parties granted China and Japan permission to import elephant ivory from four African government stockpiles, the ivory being sold at a single auction in each country. The amounts to be sold comprise approximately 44 tons from Botswana, 9 tons from Namibia, 51 tons from South Africa, and 4 tons from Zimbabwe. The Chinese government in 2003 acknowledged that it had lost track of 121 tons of ivory between 1991 and 2002.\n\nFrom 2005 – 2009 the legal trade corresponded with these numbers\nIn the 1990s the annual trade of legal animal products was $160 billion annually. In 2009 the estimated value almost doubled to $300 billion.\n\nThe Conference of the Parties (CoP) is held once every three years. The last Conference of the Parties (CoP 17) was held in Johannesburg, South Africa, and the one before it (CoP 16) was held in Bangkok, Thailand, in 2013. The next one (CoP 18) will be in Sri Lanka in 2019. The location of the next CoP is chosen at the close of each CoP by a secret ballot vote.\n\nThe CITES Committees (Animals Committee, Plants Committee and Standing Committee) hold meetings during each year that does not have a CoP, while the Standing committee meets also in years with a CoP. The Committee meetings take place in Geneva, Switzerland (where the Secretariat of the CITES Convention is located), unless another country offers to host the meeting. The Animals and Plants Committees have sometimes held joint meetings. The previous joint meeting was held in March 2012 in Dublin, Ireland, and the latest one was held in Veracruz, Mexico in May 2014.\n\nA current list of upcoming meetings appears on the CITES calendar at http://www.cites.org/eng/news/calendar.php.\n\n\n\n\n\n", "id": "6201", "title": "CITES"}
{"url": "https://en.wikipedia.org/wiki?curid=6203", "text": "Environmental Modification Convention\n\nThe Environmental Modification Convention (ENMOD), formally the Convention on the Prohibition of Military or Any Other Hostile Use of Environmental Modification Techniques is an international treaty prohibiting the military or other hostile use of environmental modification techniques having widespread, long-lasting or severe effects. It opened for signature on 18 May 1977 in Geneva and entered into force on 5 October 1978.\n\nThe Convention bans weather warfare, which is the use of weather modification techniques for the purposes of inducing damage or destruction. The Convention on Biological Diversity of 2010 would also ban some forms of weather modification or geoengineering.\n\nMany states do not regard this as a complete ban on the use of herbicides in warfare, such as Agent Orange, but it does require case-by-case consideration.\n\nThe Convention was signed by 48 states; 16 of the signatories have not ratified. As of June 2015, the Convention has 77 state parties.\n\nThe problem of artificial modification of the environment for military or other hostile purposes was brought to the international agenda in the early 1970s. Following the US decision of July 1972 to renounce the use of climate modification techniques for hostile purposes, the 1973 resolution by the US Senate calling for an international agreement \"prohibiting the use of any environmental or geophysical modification activity as a weapon of war\", and an in-depth review by the Department of Defense of the military aspects of weather and other environmental modification techniques, US decided to seek agreement with the Soviet Union to explore the possibilities of an international agreement.\n\nIn July 1974, US and USSR agreed to hold bilateral discussions on measures to overcome the danger of the use of environmental modification techniques for military purposes and three subsequent rounds of discussions in 1974 and 1975. In August 1975, US and USSR tabled identical draft texts of a convention at the Conference of the Committee on Disarmament (CCD), Conference on Disarmament, where intensive negotiations resulted in a modified text and understandings regarding four articles of this Convention in 1976.\n\nThe Convention was approved by Resolution 31/72 of the General Assembly of the United Nations on 10 December 1976, by 96 to 8 votes with 30 abstentions.\n\nEnvironmental Modification Technique includes any technique for changing – through the deliberate manipulation of natural processes – the dynamics, composition or structure of the earth, including its biota, lithosphere, hydrosphere and atmosphere, or of outer space.\n\nThe Convention contains ten articles and one Annex on the Consultative Committee of Experts. Integral part of the Convention are also the Understandings relating to articles I, II, III and VIII. These Understandings are not incorporated into the Convention but are part of the negotiating record and were included in the report transmitted by the Conference of the Committee on Disarmament to the United Nations General Assembly in September 1976 Report of the Conference of the Committee on Disarmament, Volume I, General Assembly Official records: Thirty-first session, Supplement No. 27 (A/31/27), New York, United Nations, 1976, pp. 91–92.\n\n\n", "id": "6203", "title": "Environmental Modification Convention"}
{"url": "https://en.wikipedia.org/wiki?curid=6205", "text": "Chaitin's constant\n\nIn the computer science subfield of algorithmic information theory, a Chaitin constant (Chaitin omega number) or halting probability is a real number that, informally speaking, represents the probability that a randomly constructed program will halt. These numbers are formed from a construction due to Gregory Chaitin.\n\nAlthough there are infinitely many halting probabilities, it is common to use the letter Ω to refer to them as if there were only one. Because Ω depends on the program encoding used, it is sometimes called Chaitin's construction instead of Chaitin's constant when not referring to any specific encoding.\n\nEach halting probability is a normal and transcendental real number that is not computable, which means that there is no algorithm to compute its digits. Indeed, each halting probability is Martin-Löf random, meaning there is not even any algorithm which can reliably guess its digits.\n\nThe definition of a halting probability relies on the existence of prefix-free universal computable functions. Such a function, intuitively, represents a programming language with the property that no valid program can be obtained as a proper extension of another valid program.\n\nSuppose that \"F\" is a partial function that takes one argument, a finite binary string, and possibly returns a single binary string as output. The function \"F\" is called computable if there is a Turing machine that computes it (in the sense that for any finite binary string \"x\" such that \"F(x) = y\" the Turing machine halts with \"y\" on its tape when given the input \"x\").\n\nThe function \"F\" is called universal if the following property holds: for every computable function \"f\" of a single variable there is a string \"w\" such that for all \"x\", \"F\"(\"w\" \"x\") = \"f\"(\"x\"); here \"w\" \"x\" represents the concatenation of the two strings \"w\" and \"x\". This means that \"F\" can be used to simulate any computable function of one variable. Informally, \"w\" represents a \"script\" for the computable function \"f\", and \"F\" represents an \"interpreter\" that parses the script as a prefix of its input and then executes it on the remainder of input.\n\nThe domain of \"F\" is the set of all inputs \"p\" on which it is defined. For \"F\" that are universal, such a \"p\" can generally be seen both as the concatenation of a program part and a data part, as a single program for the function \"F\".\n\nThe function \"F\" is called prefix-free if there are no two elements \"p\", \"p′\" in its domain such that \"p′\" is a proper extension of \"p\". This can be rephrased as: the domain of \"F\" is a prefix-free code (instantaneous code) on the set of finite binary strings. A simple way to enforce prefix-free-ness is to use machines whose means of input is a binary stream from which bits can be read one at a time. There is no end-of-stream marker; the end of input is determined by when the universal machine decides to stop reading more bits. Here, the difference between the two notions of program mentioned in the last paragraph becomes clear; one is easily recognized by some grammar, while the other requires arbitrary computation to recognize.\n\nThe domain of any universal computable function is a computably enumerable set but never a computable set. The domain is always Turing equivalent to the halting problem.\n\nLet \"P\" be the domain of a prefix-free universal computable function \"F\". The constant Ω is then defined as\nwhere formula_2 denotes the length of a string \"p\".\nThis is an infinite sum which has one summand for every \"p\" in the domain of \"F\". The requirement that the domain be prefix-free, together with Kraft's inequality, ensures that this sum converges to a real number between 0 and 1. If \"F\" is clear from context then Ω may be denoted simply Ω, although different prefix-free universal computable functions lead to different values of Ω.\n\nKnowing the first \"N\" bits of Ω, one could calculate the halting problem for all programs of a size up to \"N\". Let the program \"p\" for which the halting problem is to be solved be \"N\" bits long. In dovetailing fashion, all programs of all lengths are run, until enough have halted to jointly contribute enough probability to match these first \"N\" bits. If the program \"p\" hasn't halted yet, then it never will, since its contribution to the halting probability would affect the first \"N\" bits. Thus, the halting problem would be solved for \"p\".\n\nBecause many outstanding problems in number theory, such as Goldbach's conjecture are equivalent to solving the halting problem for special programs (which would basically search for counter-examples and halt if one is found), knowing enough bits of Chaitin's constant would also imply knowing the answer to these problems. But as the halting problem is not generally solvable, and therefore calculating any but the first few bits of Chaitin's constant is not possible, this just reduces hard problems to impossible ones, much like trying to build an oracle machine for the halting problem would be.\n\nThe Cantor space is the collection of all infinite sequences of 0s and 1s. A halting probability can be interpreted as the measure of a certain subset of Cantor space under the usual probability measure on Cantor space. It is from this interpretation that halting probabilities take their name.\n\nThe probability measure on Cantor space, sometimes called the fair-coin measure, is defined so that for any binary string \"x\" the set of sequences that begin with \"x\" has measure 2. This implies that for each natural number \"n\", the set of sequences \"f\" in Cantor space such that \"f\"(\"n\") = 1 has measure 1/2, and the set of sequences whose \"n\"th element is 0 also has measure 1/2.\n\nLet \"F\" be a prefix-free universal computable function. The domain \"P\" of \"F\" consists of an infinite set of binary strings\nEach of these strings \"p\" determines a subset \"S\" of Cantor space; the set \"S\" contains all sequences in cantor space that begin with \"p\". These sets are disjoint because \"P\" is a prefix-free set. The sum\nrepresents the measure of the set \n\nIn this way, Ω represents the probability that a randomly selected infinite sequence of 0s and 1s begins with a bit string (of some finite length) that is in the domain of \"F\". It is for this reason that Ω is called a halting probability.\n\nEach Chaitin constant Ω has the following properties:\n\nNot every set that is Turing equivalent to the halting problem is a halting probability. A finer equivalence relation, Solovay equivalence, can be used to characterize the halting probabilities among the left-c.e. reals.\n\nA real number is called computable if there is an algorithm which, given \"n\", returns the first \"n\" digits of the number. This is equivalent to the existence of a program that enumerates the digits of the real number.\n\nNo halting probability is computable. The proof of this fact relies on an algorithm which, given the first \"n\" digits of Ω, solves Turing's halting problem for programs of length up to \"n\". Since the halting problem is undecidable, Ω cannot be computed.\n\nThe algorithm proceeds as follows. Given the first \"n\" digits of Ω and a \"k\"≤\"n\", the algorithm enumerates the domain of \"F\" until enough elements of the domain have been found so that the probability they represent is within 2 of Ω. After this point, no additional program of length \"k\" can be in the domain, because each of these would add 2 to the measure, which is impossible. Thus the set of strings of length \"k\" in the domain is exactly the set of such strings already enumerated.\n\nA real number is random if the binary sequence representing the real number is an algorithmically random sequence. \nCalude, Hertling, Khoussainov, and Wang showed\nthat a recursively enumerable real number is an algorithmically random sequence if and only if it is a Chaitin's Ω number.\n\nFor each specific consistent effectively represented axiomatic system for the natural numbers, such as Peano arithmetic, there exists a constant \"N\" such that no bit of Ω after the \"N\"th can be proven to be 1 or 0 within that system. The constant \"N\" depends on how the formal system is effectively represented, and thus does not directly reflect the complexity of the axiomatic system. This incompleteness result is similar to Gödel's incompleteness theorem in that it shows that no consistent formal theory for arithmetic can be complete.\n\nAs mentioned above, the first n bits of Gregory Chaitin's constant Ω are random or incompressible in the sense that we cannot compute them by a halting algorithm with fewer than n-O(1) bits. However, consider the short but never halting algorithm which systematically lists and runs all possible programs; whenever one of them halts its probability gets added to the output (initialized by zero). After finite time the first n bits of the output will never change any more (it does not matter that this time itself is not computable by a halting program). So there is a short non-halting algorithm whose output converges (after finite time) onto the first n bits of Ω. In other words, the enumerable first n bits of Ω are highly compressible in the sense that they are limit-computable by a very short algorithm; they are not random with respect to the set of enumerating algorithms. Jürgen Schmidhuber (2000) constructed a limit-computable \"Super Ω\" which in a sense is much more random than the original limit-computable Ω, as one cannot significantly compress the Super Ω by any enumerating non-halting algorithm.\n\nFor an alternative \"Super Ω\", the universality probability of a prefix-free Universal Turing Machine (UTM) - namely, the probability that it remains universal even when every input of it (as a binary string) is prefixed by a random binary string - can be seen as the non-halting probability of a machine with oracle the third iteration of the halting problem\n\n\n\n", "id": "6205", "title": "Chaitin's constant"}
{"url": "https://en.wikipedia.org/wiki?curid=6206", "text": "Computable number\n\nIn mathematics, computable numbers are the real numbers that can be computed to within any desired precision by a finite, terminating algorithm. They are also known as the recursive numbers or the computable reals or recursive reals.\n\nEquivalent definitions can be given using μ-recursive functions, Turing machines, or λ-calculus as the formal representation of algorithms. The computable numbers form a real closed field and can be used in the place of real numbers for many, but not all, mathematical purposes.\n\nIn the following, Marvin Minsky defines the numbers to be computed in a manner similar to those defined by Alan Turing in 1936; i.e., as \"sequences of digits interpreted as decimal fractions\" between 0 and 1:\n\nThe key notions in the definition are (1) that some \"n\" is specified at the start, (2) for any \"n\" the computation only takes a finite number of steps, after which the machine produces the desired output and terminates.\n\nAn alternate form of (2) – the machine successively prints all n of the digits on its tape, halting after printing the n – emphasizes Minsky's observation: (3) That by use of a Turing machine, a \"finite\" definition – in the form of the machine's table – is being used to define what is a potentially-\"infinite\" string of decimal digits.\n\nThis is however not the modern definition which only requires the result be accurate to within any given accuracy. The informal definition above is subject to a rounding problem called the table-maker's dilemma whereas the modern definition is not.\n\nA real number \"a\" is computable if it can be approximated by some computable function formula_1 in the following manner: given any positive integer \"n\", the function produces an integer \"f\"(\"n\") such that:\n\nThere are two similar definitions that are equivalent:\n\nThere is another equivalent definition of computable numbers via computable Dedekind cuts. A computable Dedekind cut is a computable function formula_8 which when provided with a rational number formula_9 as input returns formula_10 or formula_11, satisfying the following conditions:\nAn example is given by a program \"D\" that defines the cube root of 3. Assuming formula_15 this is defined by:\n\nA real number is computable if and only if there is a computable Dedekind cut \"D\" converging to it. The function \"D\" is unique for each irrational computable number (although of course two different programs may provide the same function).\n\nA complex number is called computable if its real and imaginary parts are computable.\n\nWhile the set of real numbers is uncountable, the set of computable numbers is only countable and thus almost all real numbers are not computable. That the computable numbers are at most countable intuitively comes from the fact that they are produced by Turing machines, of which there are only countably many. More precisely, assigning a Gödel number to each Turing machine definition produces a subset formula_18 of the natural numbers corresponding to the computable numbers and identifies a surjection from formula_18 to the computable numbers, which shows that the computable numbers are subcountable. Moreover, for any computable number formula_20 the well ordering principle provides that there is a minimal element in formula_18 which corresponds to formula_22, and therefore there exists a subset formula_23 consisting of the minimal elements, on which the map is a bijection. The inverse of this bijection is an injection into the natural numbers of the computable numbers, proving that they are countable.\n\nThe set formula_18 of Gödel numbers, however, is not computably enumerable (nor consequently is formula_25), even though the computable reals are themselves ordered. This is because there is no algorithm to determine which Gödel numbers correspond to Turing machines that produce computable reals. In order to produce a computable real, a Turing machine must compute a total function, but the corresponding decision problem is in Turing degree 0′′. Consequently, there is no surjective computable function from the natural numbers to the computable reals, and Cantor's diagonal argument cannot be used constructively to demonstrate uncountably many of them.\n\nThe arithmetical operations on computable numbers are themselves computable in the sense that whenever real numbers \"a\" and \"b\" are computable then the following real numbers are also computable: \"a + b\", \"a - b\", \"ab\", and \"a/b\" if \"b\" is nonzero.\nThese operations are actually \"uniformly computable\"; for example, there is a Turing machine which on input (\"A\",\"B\",formula_26) produces output \"r\", where \"A\" is the description of a Turing machine approximating \"a\", \"B\" is the description of a Turing machine approximating \"b\", and \"r\" is an formula_26 approximation of \"a\"+\"b\".\n\nThe fact that computable real numbers form a field was first proved by Henry Gordon Rice (1954).\n\nComputable reals do not form however a computable field, because the definition of the latter notion requires effective equality.\n\nThe order relation on the computable numbers is not computable. Let \"A\" be the description of a Turing machine approximating the number formula_6. Then there is no Turing machine which on input \"A\" outputs \"YES\" if formula_29 and \"NO\" if formula_30. The reason: suppose the machine described by \"A\" keeps outputting 0 as formula_26 approximations. It is not clear how long to wait before deciding that the machine will \"never\" output an approximation which forces \"a\" to be positive. Thus the machine will eventually have to guess that the number will equal 0, in order to produce an output; the sequence may later become different from 0. This idea can be used to show that the machine is incorrect on some sequences if it computes a total function. A similar problem occurs when the computable reals are represented as Dedekind cuts. The same holds for the equality relation : the equality test is not computable.\n\nWhile the full order relation is not computable, the restriction of it to pairs of unequal numbers is computable. That is, there is a program that takes as input two Turing machines \"A\" and \"B\" approximating numbers \"a\" and \"b\", where \"a\" ≠ \"b\", and outputs whether formula_32 or formula_33. It is sufficient to use ε-approximations where formula_34 so by taking increasingly small ε (with a limit to 0), one eventually can decide whether formula_32 or formula_33.\n\nThe computable real numbers do not share all the properties of the real numbers used in analysis. For example, the least upper bound of a bounded increasing computable sequence of computable real numbers need not be a computable real number (Bridges and Richman, 1987:58). A sequence with this property is known as a Specker sequence, as the first construction is due to E. Specker (1949). Despite the existence of counterexamples such as these, parts of calculus and real analysis can be developed in the field of computable numbers, leading to the study of computable analysis.\n\nEvery computable number is definable, but not vice versa. There are many definable, noncomputable real numbers, including:\nBoth of these examples in fact define an infinite set of definable, uncomputable numbers, one for each Universal Turing machine.\nA real number is computable if and only if the set of natural numbers it represents (when written in binary and viewed as a characteristic function) is computable.\n\nEvery computable number is arithmetical.\n\nThe set of computable real numbers (as well as every countable, densely ordered subset of computable reals without ends) is order-isomorphic to the set of rational numbers.\n\nTuring's original paper defined computable numbers as follows:\n\nTuring was aware that this definition is equivalent to the formula_26-approximation definition given above. The argument proceeds as follows: if a number is computable in the Turing sense, then it is also computable in the formula_26 sense: if formula_42, then the first \"n\" digits of the decimal expansion for \"a\" provide an formula_26 approximation of \"a\". For the converse, we pick an formula_26 computable real number \"a\" and generate increasingly precisce approximations until the \"n\"th digit after the decimal point is certain. This always generates a decimal expansion equal to \"a\" but it may improperly end in an infinite sequence of 9's in which case it must have a finite (and thus computable) proper decimal expansion.\n\nUnless certain topological properties of the real numbers are relevant it is often more convenient to deal with elements of formula_45 (total 0,1 valued functions) instead of reals numbers in formula_46. The members of formula_45 can be identified with binary decimal expansions but since the decimal expansions formula_48 and formula_49 denote the same real number the interval formula_46 can only be bijectively (and homeomorphically under the subset topology) identified with the subset of formula_45 not ending in all 1's.\n\nNote that this property of decimal expansions means it's impossible to effectively identify computable real numbers defined in terms of a decimal expansion and those defined in the formula_26 approximation sense. Hirst has shown there is no algorithm which takes as input the description of a Turing machine which produces formula_26 approximations for the computable number \"a\", and produces as output a Turing machine which enumerates the digits of \"a\" in the sense of Turing's definition (see Hirst 2007). Similarly it means that the arithmetic operations on the computable reals are not effective on their decimal representations as when adding decimal numbers, in order to produce one digit it may be necessary to look arbitrarily far to the right to determine if there is a carry to the current location. This lack of uniformity is one reason that the contemporary definition of computable numbers uses formula_26 approximations rather than decimal expansions.\n\nHowever, from a computational or measure theoretic perspective the two structures formula_45 and formula_46 are essentially identical. and computability theorists often refer to members of formula_45 as reals. While formula_46 formula_45 is totally disconnected for questions about formula_60 classes or randomness it's much less messy to work in formula_45.\n\nElements of formula_62 are sometimes called reals as well and though containing a homeomorphic image of formula_63 formula_62 in addition to being totally disconnected isn't even locally compact. This leads to genuine differences in the computational properties. For instance the formula_65 satisfying formula_66 with formula_67 quantifier free must be computable while the unique formula_68 satisfying a universal formula can be arbitrarily high in the hyperarithmetic hierarchy.\n\nThe computable numbers include many of the specific real numbers which appear in practice, including all real algebraic numbers, as well as \"e\", formula_69, and many other transcendental numbers. Though the computable reals exhaust those reals we can calculate or approximate, the assumption that all reals are computable leads to substantially different conclusions about the real numbers. The question naturally arises of whether it is possible to dispose of the full set of reals and use computable numbers for all of mathematics. This idea is appealing from a constructivist point of view, and has been pursued by what Bishop and Richman call the \"Russian school\" of constructive mathematics.\n\nTo actually develop analysis over computable numbers, some care must be taken. For example, if one uses the classical definition of a sequence, the set of computable numbers is not closed under the basic operation of taking the supremum of a bounded sequence (for example, consider a Specker sequence). This difficulty is addressed by considering only sequences which have a computable modulus of convergence. The resulting mathematical theory is called computable analysis.\n\nThere are some computer packages that work with computable real numbers,\nrepresenting the real numbers as programs computing approximations.\nOne example is the RealLib package (reallib home page).\n\n\n\nComputable numbers were defined independently by Turing, Post and Church. See \"The Undecidable\", ed. Martin Davis, for further original papers.\n", "id": "6206", "title": "Computable number"}
{"url": "https://en.wikipedia.org/wiki?curid=6207", "text": "Electric current\n\nAn electric current is a flow of electric charge. In electric circuits this charge is often carried by moving electrons in a wire. It can also be carried by ions in an electrolyte, or by both ions and electrons such as in an ionised gas (plasma).\n\nThe SI unit for measuring an electric current is the ampere, which is the flow of electric charge across a surface at the rate of one coulomb per second. Electric current is measured using a device called an ammeter.\n\nElectric currents cause Joule heating, which creates light in incandescent light bulbs. They also create magnetic fields, which are used in motors, inductors and generators.\n\nThe particles that carry the charge in an electric current are called charge carriers. In metals, one or more electrons from each atom are loosely bound to the atom, and can move freely about within the metal. These conduction electrons are the charge carriers in metal conductors.\n\nThe conventional symbol for current is , which originates from the French phrase \"intensité de courant\", meaning \"current intensity\". Current intensity is often referred to simply as \"current\". The symbol was used by André-Marie Ampère, after whom the unit of electric current is named, in formulating the eponymous Ampère's force law, which he discovered in 1820. The notation travelled from France to Great Britain, where it became standard, although at least one journal did not change from using to until 1896.\n\nIn a conductive material, the moving charged particles which constitute the electric current are called charge carriers. In metals, which make up the wires and other conductors in most electrical circuits, the positively charged atomic nuclei are held in a fixed position, and the negatively charged electrons are free to move, carrying their charge from one place to another. In other materials, notably the semiconductors, the charge carriers can be positive \"or\" negative, depending on the dopant used. Positive and negative charge carriers may even be present at the same time, as happens in an electrochemical cell.\n\nA flow of positive charges gives the same electric current, and has the same effect in a circuit, as an equal flow of negative charges in the opposite direction. Since current can be the flow of either positive or negative charges, or both, a convention is needed for the direction of current that is independent of the type of charge carriers. The direction of \"conventional current\" is arbitrarily defined as the same direction as positive charges flow.\n\nThe consequence of this convention is that electrons, the charge carriers in metal wires and most other parts of electric circuits, flow in the opposite direction of conventional current flow in an electrical circuit.\n\nSince the current in a wire or component can flow in either direction, when a variable is defined to represent that current, the direction representing positive current must be specified, usually by an arrow on the circuit schematic diagram. This is called the \"reference direction\" of current . If the current flows in the opposite direction, the variable has a negative value.\n\nWhen analyzing electrical circuits, the actual direction of current through a specific circuit element is usually unknown. Consequently, the reference directions of currents are often assigned arbitrarily. When the circuit is solved, a negative value for the variable means that the actual direction of current through that circuit element is opposite that of the chosen reference direction.\nIn electronic circuits, the reference current directions are often chosen so that all currents are toward ground. This often corresponds to the actual current direction, because in many circuits the power supply voltage is positive with respect to ground.\n\nOhm's law states that the current through a conductor between two points is directly proportional to the potential difference across the two points. Introducing the constant of proportionality, the resistance, one arrives at the usual mathematical equation that describes this relationship:\n\nwhere \"I\" is the current through the conductor in units of amperes, \"V\" is the potential difference measured \"across\" the conductor in units of volts, and \"R\" is the resistance of the conductor in units of ohms. More specifically, Ohm's law states that the \"R\" in this relation is constant, independent of the current.\n\nIn alternating current (AC) systems, the movement of electric charge periodically reverses direction. AC is the form of electric power most commonly delivered to businesses and residences. The usual waveform of an AC power circuit is a sine wave. Certain applications use different waveforms, such as triangular or square waves. Audio and radio signals carried on electrical wires are also examples of alternating current. An important goal in these applications is recovery of information encoded (or \"modulated\") onto the AC signal.\n\nIn contrast, direct current (DC) is the unidirectional flow of electric charge, or a system in which the movement of electric charge is in one direction only. Direct current is produced by sources such as batteries, thermocouples, solar cells, and commutator-type electric machines of the dynamo type. Direct current may flow in a conductor such as a wire, but can also flow through semiconductors, insulators, or even through a vacuum as in electron or ion beams. The electric charge flows in a constant direction, distinguishing it from AC. A term formerly used for direct current was \"galvanic current\".\n\nNatural observable examples of electrical current include lightning, static electricity, and the solar wind, the source of the polar auroras.\n\nMan-made occurrences of electric current include the flow of conduction electrons in metal wires such as the overhead power lines that deliver electrical energy across long distances and the smaller wires within electrical and electronic equipment. Eddy currents are electric currents that occur in conductors exposed to changing magnetic fields. Similarly, electric currents occur, particularly in the surface, of conductors exposed to electromagnetic waves. When oscillating electric currents flow at the correct voltages within radio antennas, radio waves are generated.\n\nIn electronics, other forms of electric current include the flow of electrons through resistors or through the vacuum in a vacuum tube, the flow of ions inside a battery or a neuron, and the flow of holes within a semiconductor.\n\nCurrent can be measured using an ammeter.\n\nAt the circuit level, there are various techniques that can be used to measure current:\n\nJoule heating, also known as \"ohmic heating\" and \"resistive heating\", is the process by which the passage of an electric current through a conductor releases heat. It was first studied by James Prescott Joule in 1841. Joule immersed a length of wire in a fixed mass of water and measured the temperature rise due to a known current through the wire for a 30 minute period. By varying the current and the length of the wire he deduced that the heat produced was proportional to the square of the current multiplied by the electrical resistance of the wire.\n\nThis relationship is known as Joule's First Law. The SI unit of energy was subsequently named the joule and given the symbol \"J\". The commonly known unit of power, the watt, is equivalent to one joule per second.\n\nIn an electromagnet a coil, of a large number of circular turns of insulated wire, wrapped on a cylindrical core, behaves like a magnet when an electric current flows through it. When the current is switched off, the coil loses its magnetism immediately. We call such a device as an electromagnet.\nElectric current produces a magnetic field. The magnetic field can be visualized as a pattern of circular field lines surrounding the wire that persists as long as there is current.\n\nMagnetism can also produce electric currents. When a changing magnetic field is applied to a conductor, an Electromotive force (EMF) is produced, and when there is a suitable path, this causes current.\n\nElectric current can be directly measured with a galvanometer, but this method involves breaking the electrical circuit, which is sometimes inconvenient. Current can also be measured without breaking the circuit by detecting the magnetic field associated with the current. Devices used for this include Hall effect sensors, current clamps, current transformers, and Rogowski coils.\n\nWhen an electric current flows in a suitably shaped conductor at radio frequencies radio waves can be generated. These travel at the speed of light and can cause electric currents in distant conductors.\n\nIn metallic solids, electric charge flows by means of electrons, from lower to higher electrical potential. In other media, any stream of charged objects (ions, for example) may constitute an electric current. To provide a definition of current independent of the type of charge carriers, \"conventional current\" is defined as moving in the same direction as the positive charge flow. So, in metals where the charge carriers (electrons) are negative, conventional current is in the opposite direction as the electrons. In conductors where the charge carriers are positive, conventional current is in the same direction as the charge carriers.\n\nIn a vacuum, a beam of ions or electrons may be formed. In other conductive materials, the electric current is due to the flow of both positively and negatively charged particles at the same time. In still others, the current is entirely due to positive charge flow. For example, the electric currents in electrolytes are flows of positively and negatively charged ions. In a common lead-acid electrochemical cell, electric currents are composed of positive hydrogen ions (protons) flowing in one direction, and negative sulfate ions flowing in the other. Electric currents in sparks or plasma are flows of electrons as well as positive and negative ions. In ice and in certain solid electrolytes, the electric current is entirely composed of flowing ions.\n\nIn a metal, some of the outer electrons in each atom are not bound to the individual atom as they are in insulating materials, but are free to move within the metal lattice. These conduction electrons can serve as charge carriers, carrying a current. Metals are particularly conductive because there are a large number of these free electrons, typically one per atom in the lattice. With no external electric field applied, these electrons move about randomly due to thermal energy but, on average, there is zero net current within the metal. At room temperature, the average speed of these random motions is 10 metres per second. Given a surface through which a metal wire passes, electrons move in both directions across the surface at an equal rate. As George Gamow wrote in his popular science book, \"One, Two, Three...Infinity\" (1947), \"The metallic substances differ from all other materials by the fact that the outer shells of their atoms are bound rather loosely, and often let one of their electrons go free. Thus the interior of a metal is filled up with a large number of unattached electrons that travel aimlessly around like a crowd of displaced persons. When a metal wire is subjected to electric force applied on its opposite ends, these free electrons rush in the direction of the force, thus forming what we call an electric current.\"\n\nWhen a metal wire is connected across the two terminals of a DC voltage source such as a battery, the source places an electric field across the conductor. The moment contact is made, the free electrons of the conductor are forced to drift toward the positive terminal under the influence of this field. The free electrons are therefore the charge carrier in a typical solid conductor.\n\nFor a steady flow of charge through a surface, the current \"I\" (in amperes) can be calculated with the following equation:\nwhere \"Q\" is the electric charge transferred through the surface over a time \"t\". If \"Q\" and \"t\" are measured in coulombs and seconds respectively, \"I\" is in amperes.\n\nMore generally, electric current can be represented as the rate at which charge flows through a given surface as:\n\nElectric currents in electrolytes are flows of electrically charged particles (ions). For example, if an electric field is placed across a solution of Na and Cl (and conditions are right) the sodium ions move towards the negative electrode (cathode), while the chloride ions move towards the positive electrode (anode). Reactions take place at both electrode surfaces, absorbing each ion.\n\nWater-ice and certain solid electrolytes called proton conductors contain positive hydrogen ions (\"protons\") that are mobile. In these materials, electric currents are composed of moving protons, as opposed to the moving electrons in metals.\n\nIn certain electrolyte mixtures, brightly coloured ions are the moving electric charges. The slow progress of the colour makes the current visible.\n\nIn air and other ordinary gases below the breakdown field, the dominant source of electrical conduction is via relatively few mobile ions produced by radioactive gases, ultraviolet light, or cosmic rays. Since the electrical conductivity is low, gases are dielectrics or insulators. However, once the applied electric field approaches the breakdown value, free electrons become sufficiently accelerated by the electric field to create additional free electrons by colliding, and ionizing, neutral gas atoms or molecules in a process called avalanche breakdown. The breakdown process forms a plasma that contains enough mobile electrons and positive ions to make it an electrical conductor. In the process, it forms a light emitting conductive path, such as a spark, arc or lightning.\n\nPlasma is the state of matter where some of the electrons in a gas are stripped or \"ionized\" from their molecules or atoms. A plasma can be formed by high temperature, or by application of a high electric or alternating magnetic field as noted above. Due to their lower mass, the electrons in a plasma accelerate more quickly in response to an electric field than the heavier positive ions, and hence carry the bulk of the current. The free ions recombine to create new chemical compounds (for example, breaking atmospheric oxygen into single oxygen [O → 2O], which then recombine creating ozone [O]).\n\nSince a \"perfect vacuum\" contains no charged particles, it normally behaves as a perfect insulator. However, metal electrode surfaces can cause a region of the vacuum to become conductive by injecting free electrons or ions through either field electron emission or thermionic emission. Thermionic emission occurs when the thermal energy exceeds the metal's work function, while field electron emission occurs when the electric field at the surface of the metal is high enough to cause tunneling, which results in the ejection of free electrons from the metal into the vacuum. Externally heated electrodes are often used to generate an electron cloud as in the filament or indirectly heated cathode of vacuum tubes. Cold electrodes can also spontaneously produce electron clouds via thermionic emission when small incandescent regions (called cathode spots or anode spots) are formed. These are incandescent regions of the electrode surface that are created by a localized high current. These regions may be initiated by field electron emission, but are then sustained by localized thermionic emission once a vacuum arc forms. These small electron-emitting regions can form quite rapidly, even explosively, on a metal surface subjected to a high electrical field. Vacuum tubes and sprytrons are some of the electronic switching and amplifying devices based on vacuum conductivity.\n\nSuperconductivity is a phenomenon of exactly zero electrical resistance and expulsion of magnetic fields occurring in certain materials when cooled below a characteristic critical temperature. It was discovered by Heike Kamerlingh Onnes on April 8, 1911 in Leiden. Like ferromagnetism and atomic spectral lines, superconductivity is a quantum mechanical phenomenon. It is characterized by the Meissner effect, the complete ejection of magnetic field lines from the interior of the superconductor as it transitions into the superconducting state. The occurrence of the Meissner effect indicates that superconductivity cannot be understood simply as the idealization of \"perfect conductivity\" in classical physics.\n\nIn a semiconductor it is sometimes useful to think of the current as due to the flow of positive \"holes\" (the mobile positive charge carriers that are places where the semiconductor crystal is missing a valence electron). This is the case in a p-type semiconductor. A semiconductor has electrical conductivity intermediate in magnitude between that of a conductor and an insulator. This means a conductivity roughly in the range of 10 to 10 siemens per centimeter (S⋅cm).\n\nIn the classic crystalline semiconductors, electrons can have energies only within certain bands (i.e. ranges of levels of energy). Energetically, these bands are located between the energy of the ground state, the state in which electrons are tightly bound to the atomic nuclei of the material, and the free electron energy, the latter describing the energy required for an electron to escape entirely from the material. The energy bands each correspond to a large number of discrete quantum states of the electrons, and most of the states with low energy (closer to the nucleus) are occupied, up to a particular band called the \"valence band\". Semiconductors and insulators are distinguished from metals because the valence band in any given metal is nearly filled with electrons under usual operating conditions, while very few (semiconductor) or virtually none (insulator) of them are available in the \"conduction band\", the band immediately above the valence band.\n\nThe ease of exciting electrons in the semiconductor from the valence band to the conduction band depends on the band gap between the bands. The size of this energy band gap serves as an arbitrary dividing line (roughly 4 eV) between semiconductors and insulators.\n\nWith covalent bonds, an electron moves by hopping to a neighboring bond. The Pauli exclusion principle requires that the electron be lifted into the higher anti-bonding state of that bond. For delocalized states, for example in one dimension – that is in a nanowire, for every energy there is a state with electrons flowing in one direction and another state with the electrons flowing in the other. For a net current to flow, more states for one direction than for the other direction must be occupied. For this to occur, energy is required, as in the semiconductor the next higher states lie above the band gap. Often this is stated as: full bands do not contribute to the electrical conductivity. However, as a semiconductor's temperature rises above absolute zero, there is more energy in the semiconductor to spend on lattice vibration and on exciting electrons into the conduction band. The current-carrying electrons in the conduction band are known as \"free electrons\", though they are often simply called \"electrons\" if that is clear in context.\n\nCurrent density is a measure of the density of an electric current. It is defined as a vector whose magnitude is the electric current per cross-sectional area. In SI units, the current density is measured in amperes per square metre.\n\nwhere \"formula_6\" is current in the conductor, formula_7 is the current density, and formula_8 is the differential cross-sectional area vector.\n\nThe current density (current per unit area) \"formula_7\" in materials with finite resistance is directly proportional to the electric field formula_10 in the medium. The proportionality constant is called the conductivity \"formula_11\" of the material, whose value depends on the material concerned and, in general, is dependent on the temperature of the material:\n\nThe reciprocal of the conductivity \"formula_11\" of the material is called the resistivity \"formula_14\" of the material and the above equation, when written in terms of resistivity becomes:\n\nConduction in semiconductor devices may occur by a combination of drift and diffusion, which is proportional to diffusion constant formula_17 and charge density formula_18. The current density is then:\n\nwith formula_20 being the elementary charge and formula_21 the electron density. The carriers move in the direction of decreasing concentration, so for electrons a positive current results for a positive density gradient. If the carriers are holes, replace electron density formula_21 by the negative of the hole density formula_23.\n\nIn linear anisotropic materials, \"σ\", \"ρ\" and \"D\" are tensors.\n\nIn linear materials such as metals, and under low frequencies, the current density across the conductor surface is uniform. In such conditions, Ohm's law states that the current is directly proportional to the potential difference between two ends (across) of that metal (ideal) resistor (or other ohmic device):\n\nwhere formula_6 is the current, measured in amperes; formula_26 is the potential difference, measured in volts; and formula_27 is the resistance, measured in ohms. For alternating currents, especially at higher frequencies, skin effect causes the current to spread unevenly across the conductor cross-section, with higher density near the surface, thus increasing the apparent resistance.\n\nThe mobile charged particles within a conductor move constantly in random directions, like the particles of a gas. (More accurately, a Fermi gas.) To create a net flow of charge, the particles must also move together with an average drift rate. Electrons are the charge carriers in metals and they follow an erratic path, bouncing from atom to atom, but generally drifting in the opposite direction of the electric field. The speed they drift at can be calculated from the equation:\nwhere\nTypically, electric charges in solids flow slowly. For example, in a copper wire of cross-section 0.5 mm, carrying a current of 5 A, the drift velocity of the electrons is on the order of a millimetre per second. To take a different example, in the near-vacuum inside a cathode ray tube, the electrons travel in near-straight lines at about a tenth of the speed of light.\n\nAny accelerating electric charge, and therefore any changing electric current, gives rise to an electromagnetic wave that propagates at very high speed outside the surface of the conductor. This speed is usually a significant fraction of the speed of light, as can be deduced from Maxwell's Equations, and is therefore many times faster than the drift velocity of the electrons. For example, in AC power lines, the waves of electromagnetic energy propagate through the space between the wires, moving from a source to a distant load, even though the electrons in the wires only move back and forth over a tiny distance.\n\nThe ratio of the speed of the electromagnetic wave to the speed of light in free space is called the velocity factor, and depends on the electromagnetic properties of the conductor and the insulating materials surrounding it, and on their shape and size.\n\nThe magnitudes (but, not the natures) of these three velocities can be illustrated by an analogy with the three similar velocities associated with gases.\n", "id": "6207", "title": "Electric current"}
{"url": "https://en.wikipedia.org/wiki?curid=6208", "text": "Charles Ancillon\n\nCharles Ancillon (28 July 1659 – 5 July 1715) was a French jurist and diplomat.\n\nAncillon was born in Metz into a distinguished family of Huguenots. His father, David Ancillon (1617–1692), was obliged to leave France on the revocation of the Edict of Nantes, and became pastor of the French Protestant community in Berlin.\n\nAncillon studied law at Marburg, Geneva and Paris, where he was called to the bar. At the request of the Huguenots at Metz, he pleaded its cause at the court of King Louis XIV, urging that it should be excepted in the revocation of the Edict of Nantes, but his efforts were unsuccessful, and he joined his father in Berlin. He was at once appointed by Elector Frederick III \"\"juge et directeur de colonie de Berlin\".\" Before this, he had published several works on the revocation of the Edict of Nantes and its consequences, but his literary capacity was mediocre, his style stiff and cold, and it was his personal character rather than his reputation as a writer that earned him the confidence of the elector.\n\nIn 1687 Ancillon was appointed head of the so-called \"Academie des nobles,\" the principal educational establishment of the state; later on, as councillor of embassy, he took part in the negotiations which led to the assumption of the title of \"King in Prussia\" by the elector. In 1699 he succeeded Samuel Pufendorf as historiographer to the elector, and the same year replaced his uncle Joseph Ancillon as judge of all the French refugees in the Margraviate of Brandenburg.\n\nAncillon is mainly remembered for what he did for education in Brandenburg-Prussia, and the share he took, in co-operation with Gottfried Leibniz, in founding the Academy of Berlin. Of his fairly numerous works the one of the most value is the \"\"Histoire de l'etablissement des Francais refugies dans les etats de Brandebourg\"\" published in Berlin in 1690.\n\n\n\n", "id": "6208", "title": "Charles Ancillon"}
{"url": "https://en.wikipedia.org/wiki?curid=6210", "text": "Clark Ashton Smith\n\nClark Ashton Smith (January 13, 1893 – August 14, 1961) was a self-educated American poet, sculptor, painter and author of fantasy, horror and science fiction short stories. He achieved early local recognition, largely through the enthusiasm of George Sterling, for traditional verse in the vein of Swinburne. As a poet, Smith is grouped with the West Coast Romantics alongside Ambrose Bierce, Joaquin Miller, Sterling, Nora May French, and remembered as \"The Last of the Great Romantics\" and \"The Bard of Auburn\".\n\nSmith was one of \"the big three of \"Weird Tales\", with Robert E. Howard and H. P. Lovecraft\", but some readers objected to his morbidness and violation of pulp traditions. The fantasy critic L. Sprague de Camp said of him that \"nobody since Poe has so loved a well-rotted corpse.\" Smith was a member of the Lovecraft circle and his literary friendship with Lovecraft lasted from 1922 until Lovecraft's death in 1937. His work is marked by an extraordinarily rich and ornate vocabulary, a cosmic perspective and a vein of sardonic and sometimes ribald humor.\n\nOf his writing style, Smith stated that: \"My own conscious ideal has been to delude the reader into accepting an impossibility, or series of impossibilities, by means of a sort of verbal black magic, in the achievement of which I make use of prose-rhythm, metaphor, simile, tone-color, counter-point, and other stylistic resources, like a sort of incantation.\"\n\nSmith was born January 13, 1893, in Long Valley, California, of English and New England parentage. He spent most of his life in the small town of Auburn, California, living in a small cabin built by his parents, Fanny and Timeus Smith. His formal education was limited: he suffered from psychological disorders including a fear of crowds, and although admitted to high school after attending eight years of grammar school (Long Valley School, whence dates the earliest known photo of him), he never went to high school. His parents decided it was better for him to be educated at home.\n\nHowever, he was an insatiable reader, and continued to teach himself after he left school. His education began with the reading of \"Robinson Crusoe\" (unabridged), \"Gulliver's Travels\", the fairy tales of Hans Christian Andersen and Madame d'Aulnoy, the \"Arabian Nights\" and (at the age of 13) the poems of Edgar Allan Poe. He read an unabridged dictionary (the 13th edition of Webster's) through, word for word, studying not only the definitions of the words but also their derivations from ancient languages. Having an extraordinary eidetic memory, he seems to have retained most or all of it.\n\nThe other main course in Smith's self-education was to read the 11th edition of the \"Encyclopædia Britannica\" through at least twice. Smith later taught himself French and Spanish in order to translate verse out of those languages. Smith professed to hate the provinciality of the small town of Auburn but rarely left it until he married late in life.\n\nHis first literary efforts, at the age of 11, took the form of fairy tales and imitations of the Arabian Nights. Later, he wrote long adventure novels dealing with Oriental life. By 14 he had already written a short adventure novel called \"The Black Diamonds\" which was lost for years until published in 2002. Another juvenile novel was written in his teenaged years—\"The Sword of Zagan\" (unpublished until 2004). Like \"The Black Diamonds\", it uses a medieval, \"Arabian Nights\"-like setting, and the \"Arabian Nights\", like the fairy tales of the Brothers Grimm and the works of Edgar Allan Poe, are known to have strongly influenced Smith's early writing, as did William Beckford's \"Vathek\".\n\nAt age 17, he sold several tales to \"The Black Cat\", a magazine which specialized in unusual tales. He also published some tales in the \"Overland Monthly\" in this brief foray into fiction which preceded his poetic career.\n\nHowever, it was primarily poetry that motivated the young Smith and he confined his efforts to poetry for more than a decade. In his later youth, Smith made the acquaintance of the San Francisco poet George Sterling through a member of the local Auburn Monday Night Club, where he read several of his poems with considerable success. On a month-long visit to Sterling in Carmel, California, Smith was introduced by Sterling to the poetry of Baudelaire.\n\nHe became Sterling's protégé and Sterling helped him to publish his first volume of poems, \"The Star-Treader and Other Poems\", at the age of 19. Smith received international acclaim for the collection. \"The Star-Treader\" was received very favorably by American critics, one of whom named Smith \"the Keats of the Pacific\". Smith briefly moved among the circle that included Ambrose Bierce and Jack London, but his early fame soon faded away.\n\nA little later, Smith's health broke down and for eight years his literary production was intermittent, though he produced his best poetry during this period. A small volume, \"Odes and Sonnets\", was brought out in 1918. Smith came into contact with literary figures who would later form part of H.P. Lovecraft's circle of correspondents; Smith knew them far earlier than Lovecraft. These figures include poet Samuel Loveman and bookman George Kirk. It was Smith who in fact later introduced Donald Wandrei to Lovecraft. For this reason, it has been suggested that Lovecraft might as well be referred to as a member of a \"Smith\" circle as Smith was a member of a Lovecraft one.\n\nIn 1920 Smith composed a celebrated long poem in blank verse, \"The Hashish Eater, or The Apocalypse of Evil\" which was published in \"Ebony and Crystal\" (1922). This was followed by a fan letter from H. P. Lovecraft, which was the beginning of 15 years of friendship and correspondence. With studied playfulness, Smith and Lovecraft borrowed each other's coinages of place names and the names of strange gods for their stories, though so different is Smith's treatment of the Lovecraft theme that it has been dubbed the \"Clark Ashton Smythos.\"\n\nIn 1925 Smith published \"Sandalwood\", which was partly funded by a gift of $50 from Donald Wandrei. He wrote little fiction in this period with the exception of some imaginative vignettes or prose poems. Smith was poor for most of his life and often did hard manual jobs such as fruit picking and woodcutting in order to support himself and his parents. He was an able cook and made many kinds of wine. He also did well digging, typing and journalism, as well as contributing a column to \"The Auburn Journal\" and sometimes worked as its night editor.\n\nOne of Smith's artistic patrons and frequent correspondents was San Francisco businessman Albert M. Bender.\n\nAt the beginning of the Depression in 1929, with his aged parents' health weakening, Smith resumed fiction writing and turned out more than a hundred short stories between 1929 and 1934, nearly all of which can be classed as weird horror or science fiction. Like Lovecraft, he drew upon the nightmares that had plagued him during youthful spells of sickness. Brian Stableford has written that the stories written during this brief phase of hectic productivity \"constitute one of the most remarkable oeuvres in imaginative literature\".\n\nHe published at his own expense a volume containing six of his best stories, \"The Double Shadow and Other Fantasies\", in an edition of 1000 copies printed by the \"Auburn Journal\". The theme of much of his work is egotism and its supernatural punishment; his weird fiction is generally macabre in subject matter, gloatingly preoccupied with images of death, decay and abnormality.\n\nMost of Smith's weird fiction falls into four series set variously in Hyperborea, Poseidonis, Averoigne and Zothique. Hyperborea, which is a lost continent of the Miocene period, and Poseidonis, which is a remnant of Atlantis, are much the same, with a magical culture characterized by bizarreness, cruelty, death and postmortem horrors. Averoigne is Smith's version of pre-modern France, comparable to James Branch Cabell's Poictesme. Zothique exists millions of years in the future. It is \"the last continent of earth, when the sun is dim and tarnished\". These tales have been compared to the \"Dying Earth\" sequence of Jack Vance.\n\nIn 1933 Smith began corresponding with Robert E. Howard, the Texan creator of Conan the Barbarian. From 1933 to 1936, Smith, Howard and Lovecraft were the leaders of the Weird Tales school of fiction and corresponded frequently, although they never met. The writer of oriental fantasies E. Hoffmann Price is the only man known to have met all three in the flesh.\n\nCritic Steve Behrends has suggested that the frequent theme of 'loss' in Smith's fiction (many of his characters attempt to recapture a long-vanished youth, early love, or picturesque past) may reflect Smith's own feeling that his career had suffered a \"fall from grace\":\n\nIn September 1935, Smith's mother Fanny died. Smith spent the next two months nursing his father through his last illness. Timeus died in December 1937. Aged 44, Smith now virtually ceased writing fiction. He had been severely affected by several tragedies occurring in a short period of time: Robert E. Howard's death by suicide (1936), Lovecraft's death from cancer (1937) and the deaths of his parents, which left him exhausted. As a result, he withdrew from the scene, marking the end of \"Weird Tales\"' Golden Age. He began sculpting and resumed the writing of poetry. However, Smith was visited by many writers at his cabin, including Fritz Leiber, Rah Hoffman, Francis T. Laney and others.\n\nIn 1942, three years after August Derleth founded Arkham House for the purpose of preserving the work of H.P. Lovecraft, Derleth published the first of several major collections of Smith's fiction, \"Out of Space and Time\" (1942). This was followed by \"Lost Worlds\" (1944). The books sold slowly, went out of print and became costly rarities. Derleth published five more volumes of Smith's prose and two of his verse, and at his death in 1971 had a large volume of Smith's poems in press.\n\nIn 1953 Smith suffered a coronary attack. Aged 61, he married Carol(yn) Jones Dorman on November 10, 1954. Dorman had much experience in Hollywood and radio public relations. After honeymooning at the Smith cabin, they moved to Pacific Grove, California, where he set up a household with their children. (Carol had been married before and had three children). For several years he alternated between the house on Indian Ridge and his wife's house in Pacific Grove. Having sold most of his father's tract, in 1957 the old house burned—the Smiths believed by arson, others said by accident.\n\nSmith now reluctantly did gardening for other residents at Pacific Grove, and grew a goatee. He spent much time shopping and walking near the seafront but despite Derleth's badgering, resisted the writing of more fiction. In 1961 he suffered strokes. In August 1961 he quietly died in his sleep, aged 68. After Smith's death Carol remarried (becoming Carolyn Wakefield) and subsequently died of cancer.\n\nThe poet's ashes were buried beside, or beneath, a boulder to the immediate west of where his childhood home (destroyed by fire in 1957) stood; some were also scattered in a stand of blue oaks near the boulder. There was no marker. In more recent times a plaque to his memory has been erected at the Auburn, California, Placer County Library.\n\nBookseller Roy A. Squires was appointed Smith's \"west coast executor\", with Jack L. Chalker as his \"east coast executor\". Squires published many letterpress editions of individual Smith poems.\n\nSmith's literary estate is represented by his stepson, Prof William Dorman, director of CASiana Literary Enterprises. Arkham House owns the copyright to many Smith stories, though some are now in the public domain.\n\nFor 'posthumous collaborations' of Smith (stories completed by Lin Carter), see the entry on Lin Carter.\n\nWhile Smith was always an artist who worked in several very different media, it is possible to identify three distinct periods in which one form of art had precedence over the others.\n\nSmith published most of his volumes of poetry in this period, including the aforementioned \"The Star-Treader and Other Poems\", as well as \"Odes and Sonnets\" (1918), \"Ebony and Crystal\" (1922) and \"Sandalwood\" (1925). His long poem \"The Hashish-Eater; Or, the Apocalypse of Evil\" was written in 1920.\n\nSmith wrote most of his weird fiction and Cthulhu Mythos stories, partially inspired by H. P. Lovecraft. Creatures of his invention include Aforgomon, Rlim-Shaikorth, Mordiggian, Tsathoggua, the wizard Eibon, and various others. In an homage to his friend, Lovecraft referred in \"The Whisperer in Darkness\" and \"The Battle That Ended the Century\" (written in collaboration with R. H. Barlow) to an Atlantean high-priest, \"Klarkash-Ton.\"\n\nSmith's weird stories form several cycles, called after the lands in which they are set: Averoigne, Hyperborea, Mars, Poseidonis, Zothique. To some extent Smith was influenced in his vision of such lost worlds by the teachings of Theosophy and the writings of Helena Blavatsky. Stories set in Zothique belong to the Dying Earth subgenre. Amongst Smith's science fiction tales are stories set on Mars and the invented planet of Xiccarph.\n\nHis short stories originally appeared in the magazines \"Weird Tales\", \"Strange Tales\", \"Astounding Stories\", \"Stirring Science Stories\" and \"Wonder Stories\".\n\nClark Ashton Smith was the third member of the great triumvirate of \"Weird Tales\", with Lovecraft and Robert E. Howard.\n\nMany of Smith's stories were published in six hardcover volumes by August Derleth under his Arkham House imprint. For a full bibliography to 1978, see Sidney-Fryer, \"Emperor of Dreams\" (cited below). S.T. Joshi is working with other scholars to produce an updated bibliography of Smith's work.\n\nA selection of Smith's best-known tales includes:\n\nBy this time his interest in writing fiction began to lessen and he turned to creating sculptures from soft rock such as soapstone. Smith also made hundreds of fantastic paintings and drawings.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "6210", "title": "Clark Ashton Smith"}
{"url": "https://en.wikipedia.org/wiki?curid=6211", "text": "Context-sensitive grammar\n\nA context-sensitive grammar (CSG) is a formal grammar in which the left-hand sides and right-hand sides of any production rules may be surrounded by a context of terminal and nonterminal symbols. Context-sensitive grammars are more general than context-free grammars, in the sense that there are languages that can be described by CSG but not by context-free grammars. Context-sensitive grammars are less general (in the same sense) than unrestricted grammars. Thus, CSG are positioned between context-free and unrestricted grammars in the Chomsky hierarchy.\n\nA formal language that can be described by a context-sensitive grammar, or, equivalently, by a noncontracting grammar or a linear bounded automaton, is called a context-sensitive language. Some textbooks actually define CSGs as non-contracting, although this is not how Noam Chomsky defined them in 1959. This choice of definition makes no difference in terms of the languages generated (i.e. the two definitions are weakly equivalent), but it does make a difference in terms of what grammars are structurally considered context-sensitive; the later issue was analyzed by Chomsky in 1963.\n\nChomsky introduced context-sensitive grammars as a way to describe the syntax of natural language where it is often the case that a word may or may not be appropriate in a certain place depending on the context. Walter Savitch has criticized the terminology \"context-sensitive\" as misleading and proposed \"non-erasing\" as better explaining the distinction between a CSG and an unrestricted grammar.\n\nAlthough it is well-known that certain features of languages (e.g. cross-serial dependency) are not context-free, it is an open question how much of CSG's expressive power is needed to capture the context sensitivity found in natural languages. Subsequent research in this area has focused on the more computationally tractable mildly context-sensitive languages.\n\nA formal grammar \"G\" = (\"N\", Σ, \"P\", \"S\"), where \"N\" is a set of nonterminal symbols, Σ is a set of terminal symbols, \"P\" is a set of production rules, and \"S\" is the start symbol, is context-sensitive if all rules in \"P\" are of the form\nwhere \"A\" ∈ \"N\", α,β ∈ (\"N\"∪Σ) and γ ∈ (\"N\"∪Σ).\n\nA string \"u\" ∈ (\"N\"∪Σ) directly yields, or directly derives to, a string \"v\" ∈ (\"N\"∪Σ), denoted as \"u\" ⇒ \"v\", if \"u\" can be written as \"l\"α\"A\"β\"r\", and \"v\" can be written as \"l\"αγβ\"r\", for some production rule (α\"A\"β→αγβ) ∈ \"P\", and some context strings \"l\", \"r\" ∈ (\"N\"∪Σ).\nMore generally, \"u\" is said to yield, or derive to, \"v\", denoted as \"u\" ⇒ \"v\", if \"u\" = \"u\" ⇒ ... ⇒ \"u\" = \"v\" for some \"n\"≥0 and some strings \"u\", ..., \"u\" (\"N\"∪Σ). That is, the relation (⇒) is the reflexive transitive closure of the relation (⇒).\n\nThe language of the grammar \"G\" is the set of all terminal symbol strings derivable from its start symbol, formally: \"L\"(\"G\") = { \"w\" ∈ Σ: \"S\" ⇒ \"w\" }.\nDerivations that do not end in a string composed of terminal symbols only are possible, but don't contribute to \"L\"(\"G\").\n\nThe only difference between this definition of Chomsky and that of unrestricted grammars is that γ can be empty in the unrestricted case.\n\nSome definitions of a context-sensitive grammar only require that for any production rule of the form u → v, the length of u shall be less than or equal to the length of v. This seemingly weaker requirement is in fact weakly equivalent, see Noncontracting grammar#Transforming into context-sensitive grammar.\n\nIn addition, a rule of the form\nwhere λ represents the empty string and \"S\" does not appear on the right-hand side of any rule is permitted. The addition of the empty string allows the statement that the context sensitive languages are a proper superset of the context-free languages, rather than having to make the weaker statement that all context-free grammars with no →λ productions are also context sensitive grammars.\n\nThe name \"context-sensitive\" is explained by the α and β that form the context of \"A\" and determine whether \"A\" can be replaced with γ or not. This is different from a context-free grammar where the context of a nonterminal is not taken into consideration. Indeed, every production of a context-free grammar is of the form \"V\" → \"w\" where \"V\" is a \"single\" nonterminal symbol, and \"w\" is a string of terminals and/or nonterminals; \"w\" can be empty.\n\nIf the possibility of adding the empty string to a language is added to the strings recognized by the noncontracting grammars (which can never include the empty string) then the languages in these two definitions are identical.\n\nThe left-context- and right-context-sensitive grammars are defined by restricting the rules to just the form α\"A\" → αγ and to just \"A\"β → γβ, respectively. The languages generated by these grammars are also the full class of context-sensitive languages. The equivalence was established by Penttonen normal form.\n\nThe following grammar, with start symbol \"S\", generates the canonical non-context-free language { \"a\"\"b\"\"c\" : \"n\" ≥ 1 } :\n\nRules 1 and 2 allow for blowing-up \"S\" to \"a\"\"BC\"(\"BC\"); rules 3 to 6 allow for successively exchanging each \"CB\" to \"BC\" (four rules are needed for that since a rule \"CB\" → \"BC\" wouldn't fit into the scheme α\"A\"β → αγβ); rules 7–10 allow replacing a non-terminals \"B\" and \"C\" with its corresponding terminals \"b\" and \"c\" respectively, provided it is in the right place.\nA generation chain for \"aaabbbccc\" is:\n\nMore complicated grammars can be used to parse { \"a\"\"b\"\"c\"\"d\": \"n\" ≥ 1 }, and other languages with even more letters.\n\nA context-sensitive grammar for the language { \"a\" : i ≥ 1 } is constructed in Example 9.5 (p. 224) of (Hopcroft, Ullman, 1979).\n\nEvery context-sensitive grammar which does not generate the empty string can be transformed into a weakly equivalent one in Kuroda normal form. \"Weakly equivalent\" here means that the two grammars generate the same language. The normal form will not in general be context-sensitive, but will be a noncontracting grammar.\n\nThe Kuroda normal form is an actual normal form for non-contracting grammars.\n\nA formal language can be described by a context-sensitive grammar if and only if it is accepted by some linear bounded automaton (LBA). In some textbooks this result is attributed solely to Landweber and Kuroda. Others call it the Myhill-Landweber-Kuroda Theorem. (Myhill introduced the concept of deterministic LBA in 1960. Peter S. Landweber published in 1963 that the language accepted by a deterministic LBA is context sensitive. Kuroda introduced the notion of non-deterministic LBA and the equivalence between LBA and CSGs in 1964.)\n\nContext-sensitive languages are closed under complement. This 1988 result is known as the Immerman–Szelepcsényi theorem.\nMoreover, they are closed under union, intersection, concatenation, substitution, inverse homomorphism, and Kleene plus.\n\nEvery recursively enumerable language \"L\" can be written as \"h\"(\"L\") for some context-sensitive language \"L\" and some string homomorphism \"h\".\n\nThe decision problem that asks whether a certain string \"s\" belongs to the language of a given context-sensitive grammar \"G\", is PSPACE-complete. Morever, there are context-sensitive grammars whose languages are PSPACE-complete. In other words, there is a context-sensitive grammar \"G\" such that deciding whether a certain string \"s\" belongs to the language of \"G\" is PSPACE-complete (so \"G\" is fixed and only \"s\" is part of the input of the problem).\n\nThe emptiness problem for context-sensitive grammars (given a context-sensitive grammar \"G\", is \"L\"(\"G\")=∅ ?) is undecidable.\n\nThe LuZc parser is a working example of a program which can parse Context-sensitive grammars.\n\nSavitch has proven the following theoretical result, on which he bases his criticism of CSGs as basis for natural language: for any recursively enumerable set \"R\", there exists a context-sensitive language/grammar \"G\" which can be used as a sort of proxy to test membership in \"R\" in the following way: given a string \"s\", \"s\" is in \"R\" if and only if there exists a positive integer \"n\" for which \"sc\" is in G, where \"c\" is an arbitrary symbol not part of \"R\".\n\nIt has been shown that nearly all natural languages may in general be characterized by context-sensitive grammars, but the whole class of CSG's seems to be much bigger than natural languages. Worse yet, since the aforementioned decision problem for CSG's is PSPACE-complete, that makes them totally unworkable for practical use, as a polynomial-time algorithm for a PSPACE-complete problem would imply P=NP.\n\nIt was proven that some natural languages are not context-free, based on identifying so-called cross-serial dependencies and unbounded scrambling phenomena. However this does not necessarily imply that all the class CSG is necessary to capture \"context sensitivity\" in the colloquial sense of these terms in natural languages. For example, the strictly weaker (than CSG) linear context-free rewriting systems (LCFRS) can account for the phenomenon of cross-serial dependencies; one can write a LCFRS grammar for {\"abcd\" | \"n\" ≥ 1} for example.\n\nOngoing research on computational linguistics has focused on formulating other classes of languages that are \"mildly context-sensitive\" whose decision problems are feasible, such as tree-adjoining grammars, combinatory categorial grammars, coupled context-free languages, and linear context-free rewriting systems. The languages generated by these formalisms properly lie between the context-free and context-sensitive languages.\n\nMore recently, the class PTIME has been identified with range concatenation grammars, which are now considered to be the most expressive of the mild-context sensitive languages.\n\n\n", "id": "6211", "title": "Context-sensitive grammar"}
{"url": "https://en.wikipedia.org/wiki?curid=6212", "text": "Context-sensitive language\n\nIn theoretical computer science, a context-sensitive language is a formal language that can be defined by a context-sensitive grammar (and equivalently by a noncontracting grammar). Context-sensitive is one of the four types of grammars in the Chomsky hierarchy.\n\nComputationally, a context-sensitive language is equivalent with a linear bounded nondeterministic Turing machine, also called a linear bounded automaton. That is a non-deterministic Turing machine with a tape of only \"kn\" cells, where \"n\" is the size of the input and \"k\" is a constant associated with the machine. This means that every formal language that can be decided by such a machine is a context-sensitive language, and every context-sensitive language can be decided by such a machine.\n\nThis set of languages is also known as NLINSPACE or NSPACE(\"O\"(\"n\")), because they can be accepted using linear space on a non-deterministic Turing machine. The class LINSPACE (or DSPACE(\"O\"(\"n\"))) is defined the same, except using a deterministic Turing machine. Clearly LINSPACE is a subset of NLINSPACE, but it is not known whether LINSPACE=NLINSPACE.\n\nOne of the simplest context-sensitive but not context-free languages is formula_1: the language of all strings consisting of \"n\" occurrences of the symbol \"a\", then \"n\" \"b\"'s, then \"n\" \"c\"'s (abc, aabbcc, aaabbbccc, etc.). A superset of this language, called the Bach language, is defined as the set of all strings where \"a\", \"b\" and \"c\" (or any other set of three symbols) occurs equally often (aabccb, baabcaccb, etc.) and is also context-sensitive.\n\n\"L\" can be shown to be a context-sensitive language by constructing a linear bounded automaton which accepts \"L\". The language can easily be shown to be neither regular nor context free by applying the respective pumping lemmas for each of the language classes to \"L\".\n\nAn example of recursive language that is not context-sensitive is any recursive language whose decision is an EXPSPACE-hard problem, say, the set of pairs of equivalent regular expressions with exponentiation.\n\n\n\n", "id": "6212", "title": "Context-sensitive language"}
{"url": "https://en.wikipedia.org/wiki?curid=6216", "text": "Chinese room\n\nThe Chinese room argument holds that a program cannot give a computer a \"mind\", \"understanding\" or \"consciousness\", regardless of how intelligently or human-like the program may make the computer behave. The argument was first presented by philosopher John Searle in his paper, \"Minds, Brains, and Programs\", published in \"Behavioral and Brain Sciences\" in 1980. It has been widely discussed in the years since. The centerpiece of the argument is a thought experiment known as the Chinese room.\n\nThe argument is directed against the philosophical positions of functionalism and computationalism, which hold that the mind may be viewed as an information-processing system operating on formal symbols. Specifically, the argument refutes a position Searle calls Strong AI:\nThe appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\n\nAlthough it was originally presented in reaction to the statements of artificial intelligence (AI) researchers, it is not an argument against the goals of AI research, because it does not limit the amount of intelligence a machine can display. The argument applies only to digital computers running programs and does not apply to machines in general.\n\nSearle's thought experiment begins with this hypothetical premise: suppose that artificial intelligence research has succeeded in constructing a computer that behaves as if it understands Chinese. It takes Chinese characters as input and, by following the instructions of a computer program, produces other Chinese characters, which it presents as output. Suppose, says Searle, that this computer performs its task so convincingly that it comfortably passes the Turing test: it convinces a human Chinese speaker that the program is itself a live Chinese speaker. To all of the questions that the person asks, it makes appropriate responses, such that any Chinese speaker would be convinced that they are talking to another Chinese-speaking human being.\n\nThe question Searle wants to answer is this: does the machine \"literally\" \"understand\" Chinese? Or is it merely \"simulating\" the ability to understand Chinese? Searle calls the first position \"strong AI\" and the latter \"weak AI\".\n\nSearle then supposes that he is in a closed room and has a book with an English version of the computer program, along with sufficient paper, pencils, erasers, and filing cabinets. Searle could receive Chinese characters through a slot in the door, process them according to the program's instructions, and produce Chinese characters as output. If the computer had passed the Turing test this way, it follows, says Searle, that he would do so as well, simply by running the program manually.\n\nSearle asserts that there is no essential difference between the roles of the computer and himself in the experiment. Each simply follows a program, step-by-step, producing a behavior which is then interpreted as demonstrating intelligent conversation. However, Searle would not be able to understand the conversation. (\"I don't speak a word of Chinese\", he points out.) Therefore, he argues, it follows that the computer would not be able to understand the conversation either.\n\nSearle argues that, without \"understanding\" (or \"intentionality\"), we cannot describe what the machine is doing as \"thinking\" and, since it does not think, it does not have a \"mind\" in anything like the normal sense of the word. Therefore, he concludes that \"strong AI\" is false.\n\nGottfried Leibniz made a similar argument in 1714 against mechanism (the position that the mind is a machine and nothing more). Leibniz used the thought experiment of expanding the brain until it was the size of a mill. Leibniz found it difficult to imagine that a \"mind\" capable of \"perception\" could be constructed using only mechanical processes. In 1974, Lawrence Davis imagined duplicating the brain using telephone lines and offices staffed by people, and in 1978 Ned Block envisioned the entire population of China involved in such a brain simulation. This thought experiment is called the China brain, also the \"Chinese Nation\" or the \"Chinese Gym\".\n\nThe Chinese Room Argument was introduced in Searle's 1980 paper \"Minds, Brains, and Programs\", published in \"Behavioral and Brain Sciences\". It eventually became the journal's \"most influential target article\", generating an enormous number of commentaries and responses in the ensuing decades, and Searle has continued to defend and refine the argument in many papers, popular articles and books. David Cole writes that \"the Chinese Room argument has probably been the most widely discussed philosophical argument in cognitive science to appear in the past 25 years\".\n\nMost of the discussion consists of attempts to refute it. \"The overwhelming majority,\" notes \"BBS\" editor Stevan Harnad, \"still think that the Chinese Room Argument is dead wrong.\" The sheer volume of the literature that has grown up around it inspired Pat Hayes to comment that the field of cognitive science ought to be redefined as \"the ongoing research program of showing Searle's Chinese Room Argument to be false\".\n\nSearle's argument has become \"something of a classic in cognitive science,\" according to Harnad. Varol Akman agrees, and has described the original paper as \"an exemplar of philosophical clarity and purity\".\n\nAlthough the Chinese Room argument was originally presented in reaction to the statements of AI researchers, philosophers have come to view it as an important part of the philosophy of mind. It is a challenge to functionalism and the computational theory of mind, and is related to such questions as the mind–body problem, the problem of other minds, the symbol-grounding problem, and the hard problem of consciousness.\n\nSearle identified a philosophical position he calls \"strong AI\":\nThe appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\nThe definition hinges on the distinction between \"simulating\" a mind and \"actually having\" a mind. Searle writes that \"according to Strong AI, the correct simulation really is a mind. According to Weak AI, the correct simulation is a model of the mind.\"\n\nThe position is implicit in some of the statements of early AI researchers and analysts. For example, in 1955, AI founder Herbert A. Simon declared that \"there are now in the world machines that think, that learn and create\" and claimed that they had \"solved the venerable mind–body problem, explaining how a system composed of matter can have the properties of mind.\" John Haugeland wrote that \"AI wants only the genuine article: \"machines with minds\", in the full and literal sense. This is not science fiction, but real science, based on a theoretical conception as deep as it is daring: namely, we are, at root, \"computers ourselves\".\"\n\nSearle also ascribes the following positions to advocates of strong AI:\n\nIn more recent presentations of the Chinese room argument, Searle has identified \"strong AI\" as \"computer functionalism\" (a term he attributes to Daniel Dennett). Functionalism is a position in modern philosophy of mind that holds that we can define mental phenomena (such as beliefs, desires, and perceptions) by describing their functions in relation to each other and to the outside world. Because a computer program can accurately represent functional relationships as relationships between symbols, a computer can have mental phenomena if it runs the right program, according to functionalism.\n\nStevan Harnad argues that Searle's depictions of strong AI can be reformulated as \"recognizable tenets of \"computationalism\", a position (unlike \"strong AI\") that is actually held by many thinkers, and hence one worth refuting.\" Computationalism is the position in the philosophy of mind which argues that the mind can be accurately described as an information-processing system.\n\nEach of the following, according to Harnad, is a \"tenet\" of computationalism:\n\nSearle holds a philosophical position he calls \"biological naturalism\": that consciousness and understanding require specific biological machinery that is found in brains. He writes \"brains cause minds\" and that \"actual human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains\". Searle argues that this machinery (known to neuroscience as the \"neural correlates of consciousness\") must have some (unspecified) \"causal powers\" that permit the human experience of consciousness. Searle's faith in the existence of these powers has been criticized.\n\nSearle does not disagree with the notion that machines can have consciousness and understanding, because, as he writes, \"we are precisely such machines\". Searle holds that the brain is, in fact, a machine, but that the brain gives rise to consciousness and understanding using machinery that is non-computational. If neuroscience is able to isolate the mechanical process that gives rise to consciousness, then Searle grants that it may be possible to create machines that have consciousness and understanding. However, without the specific machinery required, Searle does not believe that consciousness can occur.\n\nBiological naturalism implies that one cannot determine if the experience of consciousness is occurring merely by examining how a system functions, because the specific machinery of the brain is essential. Thus, biological naturalism is directly opposed to both behaviorism and functionalism (including \"computer functionalism\" or \"strong AI\"). Biological naturalism is similar to identity theory (the position that mental states are \"identical to\" or \"composed of\" neurological events); however, Searle has specific technical objections to identity theory. Searle's biological naturalism and strong AI are both opposed to Cartesian dualism, the classical idea that the brain and mind are made of different \"substances\". Indeed, Searle accuses strong AI of dualism, writing that \"strong AI only makes sense given the dualistic assumption that, where the mind is concerned, the brain doesn't matter.\"\n\nSearle's original presentation emphasized \"understanding\"—that is, mental states with what philosophers call \"intentionality\"—and did not directly address other closely related ideas such as \"consciousness\". However, in more recent presentations Searle has included consciousness as the real target of the argument.\n\nDavid Chalmers writes \"it is fairly clear that consciousness is at the root of the matter\" of the Chinese room.\n\nColin McGinn argues that the Chinese room provides strong evidence that the hard problem of consciousness is fundamentally insoluble. The argument, to be clear, is not about whether a machine can be conscious, but about whether it (or anything else for that matter) can be shown to be conscious. It is plain that any other method of probing the occupant of a Chinese room has the same difficulties in principle as exchanging questions and answers in Chinese. It is simply not possible to divine whether a conscious agency or some clever simulation inhabits the room.\n\nSearle argues that this is only true for an observer \"outside\" of the room. The whole point of the thought experiment is to put someone \"inside\" the room, where they can directly observe the operations of consciousness. Searle claims that from his vantage point within the room there is nothing he can see that could imaginably give rise to consciousness, other than himself, and clearly he does not have a mind that can speak Chinese.\n\nPatrick Hew used the Chinese Room argument to deduce requirements from military command and control systems if they are to preserve a commander's moral agency. He drew an analogy between a commander in their command center and the person in the Chinese Room, and analyzed it under a reading of Aristotle’s notions of 'compulsory' and 'ignorance'. Information could be 'down converted' from meaning to symbols, and manipulated symbolically, but moral agency could be undermined if there was inadequate 'up conversion' into meaning. Hew cited examples from the USS \"Vincennes\" incident.\n\nThe Chinese room argument is primarily an argument in the philosophy of mind, and both major computer scientists and artificial intelligence researchers consider it irrelevant to their fields. However, several concepts developed by computer scientists are essential to understanding the argument, including symbol processing, Turing machines, Turing completeness, and the Turing test.\n\nSearle's arguments are not usually considered an issue for AI research. Stuart Russell and Peter Norvig observe that most AI researchers \"don't care about the strong AI hypothesis—as long as the program works, they don't care whether you call it a simulation of intelligence or real intelligence.\" The primary mission of artificial intelligence research is only to create useful systems that \"act\" intelligently, and it does not matter if the intelligence is \"merely\" a simulation.\n\nSearle does not disagree that AI research can create machines that are capable of highly intelligent behavior. The Chinese room argument leaves open the possibility that a digital machine could be built that \"acts\" more intelligently than a person, but does not have a mind or intentionality in the same way that brains do. Indeed, Searle writes that \"the Chinese room argument ... assumes complete success on the part of artificial intelligence in simulating human cognition.\"\nSearle's \"strong AI\" should not be confused with \"strong AI\" as defined by Ray Kurzweil and other futurists, who use the term to describe machine intelligence that rivals or exceeds human intelligence. Kurzweil is concerned primarily with the \"amount\" of intelligence displayed by the machine, whereas Searle's argument sets no limit on this. Searle argues that even a super-intelligent machine would not necessarily have a mind and consciousness.\nThe Chinese room implements a version of the Turing test. Alan Turing introduced the test in 1950 to help answer the question \"can machines think?\" In the standard version, a human judge engages in a natural language conversation with a human and a machine designed to generate performance indistinguishable from that of a human being. All participants are separated from one another. If the judge cannot reliably tell the machine from the human, the machine is said to have passed the test.\n\nTuring then considered each possible objection to the proposal \"machines can think\", and found that there are simple, obvious answers if the question is de-mystified in this way. He did not, however, intend for the test to measure for the presence of \"consciousness\" or \"understanding\". He did not believe this was relevant to the issues that he was addressing. He wrote:\nTo Searle, as a philosopher investigating in the nature of mind and consciousness, these are the relevant mysteries. The Chinese room is designed to show that the Turing test is insufficient to detect the presence of consciousness, even if the room can behave or function as a conscious mind would.\n\nThe Chinese room (and all modern computers) manipulate physical objects in order to carry out calculations and do simulations. AI researchers Allen Newell and Herbert A. Simon called this kind of machine a physical symbol system. It is also equivalent to the formal systems used in the field of mathematical logic.\n\nSearle emphasizes the fact that this kind of symbol manipulation is syntactic (borrowing a term from the study of grammar). The computer manipulates the symbols using a form of syntax rules, without any knowledge of the symbol's semantics (that is, their meaning).\n\nNewell and Simon had conjectured that a physical symbol system (such as a digital computer) had all the necessary machinery for \"general intelligent action\", or, as it is known today, artificial general intelligence. They framed this as a philosophical position, the physical symbol system hypothesis: \"A physical symbol system has the necessary and sufficient means for general intelligent action.\" The Chinese room argument does not refute this, because it is framed in terms of \"intelligent action\", i.e. the external behavior of the machine, rather than the presence or absence of understanding, consciousness and mind.\n\nThe Chinese room has a design analogous to that of a modern computer. It has a Von Neumann architecture, which consists of a program (the book of instructions), some memory (the papers and file cabinets), a CPU which follows the instructions (the man), and a means to write symbols in memory (the pencil and eraser). A machine with this design is known in theoretical computer science as \"Turing complete\", because it has the necessary machinery to carry out any computation that a Turing machine can do, and therefore it is capable of doing a step-by-step simulation of any other digital machine, given enough memory and time. Alan Turing writes, \"all digital computers are in a sense equivalent.\" The widely accepted Church-Turing thesis holds that any function computable by an effective procedure is computable by a Turing machine.\n\nThe Turing completeness of the Chinese room implies that it can do whatever any other digital computer can do (albeit much, much more slowly). Thus, if the Chinese room does not or can not contain a Chinese-speaking mind, then no other digital computer can contain a mind. Some replies to Searle begin by arguing that the room, as described, cannot have a Chinese-speaking mind. Arguments of this form, according to Stevan Harnad, are \"no refutation (but rather an affirmation)\" of the Chinese room argument, because these arguments actually imply that \"no\" digital computers can have a mind.\n\nThere are some critics, such as Hanoch Ben-Yami, who argue that the Chinese room cannot simulate all the abilities of a digital computer, such as being able to determine the current time.\n\nSearle has produced a more formal version of the argument of which the Chinese Room forms a part. He presented the first version in 1984. The version given below is from 1990. The only part of the argument which should be controversial is A3 and it is this point which the Chinese room thought experiment is intended to prove.\n\nHe begins with three axioms:\n\nSearle posits that these lead directly to this conclusion:\n\nThis much of the argument is intended to show that artificial intelligence can never produce a machine with a mind by writing programs that manipulate symbols. The remainder of the argument addresses a different issue. Is the human brain running a program? In other words, is the computational theory of mind correct? He begins with an axiom that is intended to express the basic modern scientific consensus about brains and minds:\n\nSearle claims that we can derive \"immediately\" and \"trivially\" that:\n\nAnd from this he derives the further conclusions:\n\nReplies to Searle's argument may be classified according to what they claim to show:\n\nSome of the arguments (robot and brain simulation, for example) fall into multiple categories.\n\nThese replies attempt to answer the question: since the man in the room doesn't speak Chinese, \"where\" is the \"mind\" that does? These replies address the key ontological issues of mind vs. body and simulation vs. reality. All of the replies that identify the mind in the room are versions of \"the systems reply\".\n\n\nMore sophisticated versions of the systems reply try to identify more precisely what \"the system\" is and they differ in exactly how they describe it. According to these replies, the \"mind that speaks Chinese\" could be such things as: the \"software\", a \"program\", a \"running program\", a simulation of the \"neural correlates of consciousness\", the \"functional system\", a \"simulated mind\", an \"emergent property\", or \"a virtual mind\" (Marvin Minsky's version of the systems reply, described below).\n\nFrom mathematics, the theory of computation and Turing machines upholds part of the systems reply by accounting for the two computations that are known to be occurring within the room, namely (1) the computation for universal programmability (which is the function instantiated by the person and note-taking materials \"independently\" from any particular program contents) and (2) the computation of the Turing machine that is described by the program (which is instantiated by everything \"including\" the specific program). (To better see the second computation, just imagine that the program describes the algorithm for integer addition. The person would still execute their own universal computation in exactly the same automatic, rote, formal way, oblivious to this program's overall function. Yet, now we know two things: (1) the computation of integer addition is actually occurring in the room and (2) the person is not the primary thing responsible for it.)\n\nThe theory of computation thus formally explains the open possibility that the second computation in the Chinese Room could entail a human-equivalent semantic understanding of the Chinese inputs. It does not prove that such an understanding exists because the theory does not address the Turing Test. But it does show why the focus belongs on the program's Turing machine rather than on the person's.\n\n\nThese replies provide an explanation of exactly who it is that understands Chinese. If there is something \"besides\" the man in the room that can understand Chinese, Searle can't argue that (1) the man doesn't understand Chinese, therefore (2) nothing in the room understands Chinese. This, according to those who make this reply, shows that Searle's argument fails to prove that \"strong AI\" is false.\n\nHowever, the replies, by themselves, do not prove that strong AI is \"true\", either: they provide no evidence that the system (or the virtual mind) understands Chinese, other than the hypothetical premise that it passes the Turing Test. As Searle writes \"the systems reply simply begs the question by insisting that system must understand Chinese.\"\n\nAs far as the person in the room is concerned, the symbols are just meaningless \"squiggles.\" But if the Chinese room really \"understands\" what it is saying, then the symbols must get their meaning from somewhere. These arguments attempt to connect the symbols to the things they symbolize. These replies address Searle's concerns about intentionality, symbol grounding and syntax vs. semantics.\n\n\n\n\nTo each of these suggestions, Searle's response is the same: no matter how much knowledge is written into the program and no matter how the program is connected to the world, he is still in the room manipulating symbols according to rules. His actions are syntactic and this can never explain to him what the symbols stand for. Searle writes \"syntax is insufficient for semantics.\"\n\nHowever, for those who accept that Searle's actions simulate a mind, separate from his own, the important question is not what the symbols mean \"to Searle\", what is important is what they mean \"to the virtual mind.\" While Searle is trapped in the room, the virtual mind is not: it is connected to the outside world through the Chinese speakers it speaks to, through the programmers who gave it world knowledge, and through the cameras and other sensors that roboticists can supply.\n\nThese arguments are all versions of the systems reply that identify a particular \"kind\" of system as being important; they identify some special technology that would create conscious understanding in a machine. (Note that the \"robot\" and \"commonsense knowledge\" replies above also specify a certain kind of system as being important.)\n\n\n[I]magine that instead of a monolingual man in a room shuffling symbols we have the man operate an elaborate set of water pipes with valves connecting them. When the man receives the Chinese symbols, he looks up in the program, written in English, which valves he has to turn on and off. Each water connection corresponds to a synapse in the Chinese brain, and the whole system is rigged up so that after doing all the right firings, that is after turning on all the right faucets, the Chinese answers pop out at the output end of the series of pipes.\n\nNow where is the understanding in this system? It takes Chinese as input, it simulates the formal structure of the synapses of the Chinese brain, and it gives Chinese as output. But the man certainly doesn't understand Chinese, and neither do the water pipes, and if we are tempted to adopt what I think is the absurd view that somehow the conjunction of man and water pipes understands, remember that in principle the man can internalize the formal structure of the water pipes and do all the \"neuron firings\" in his imagination.\n\n\n\n\nThese arguments (and the robot or commonsense knowledge replies) identify some special technology that would help create conscious understanding in a machine. They may be interpreted in two ways: either they claim (1) this technology is required for consciousness, the Chinese room does not or cannot implement this technology, and therefore the Chinese room cannot pass the Turing test or (even if it did) it would not have conscious understanding. Or they may be claiming that (2) it is easier to see that the Chinese room has a mind if we visualize this technology as being used to create it.\n\nIn the first case, where features like a robot body or a connectionist architecture are required, Searle claims that strong AI (as he understands it) has been abandoned. The Chinese room has all the elements of a Turing complete machine, and thus is capable of simulating any digital computation whatsoever. If Searle's room can't pass the Turing test then there is no other digital technology that could pass the Turing test. If Searle's room \"could\" pass the Turing test, but still does not have a mind, then the Turing test is not sufficient to determine if the room has a \"mind\". Either way, it denies one or the other of the positions Searle thinks of as \"strong AI\", proving his argument.\n\nThe brain arguments in particular deny strong AI if they assume that there is no simpler way to describe the mind than to create a program that is just as mysterious as the brain was. He writes \"I thought the whole idea of strong AI was that we don't need to know how the brain works to know how the mind works.\" If computation does not provide an \"explanation\" of the human mind, then strong AI has failed, according to Searle.\n\nOther critics hold that the room as Searle described it does, in fact, have a mind, however they argue that it is difficult to see—Searle's description is correct, but \"misleading.\" By redesigning the room more realistically they hope to make this more obvious. In this case, these arguments are being used as appeals to intuition (see next section).\n\nIn fact, the room can just as easily be redesigned to \"weaken\" our intuitions. Ned Block's \"blockhead\" argument suggests that the program could, in theory, be rewritten into a simple lookup table of rules of the form \"if the user writes \"S\", reply with \"P\" and goto X\". At least in principle, any program can be rewritten (or \"refactored\") into this form, even a brain simulation. In the blockhead scenario, the entire mental state is hidden in the letter X, which represents a memory address—a number associated with the next rule. It is hard to visualize that an instant of one's conscious experience can be captured in a single large number, yet this is exactly what \"strong AI\" claims. On the other hand, such a lookup table would be ridiculously large (to the point of being physically impossible), and the states could therefore be \"extremely\" specific.\n\nSearle argues that however the program is written or however the machine is connected to the world, the mind is being \"simulated\" by a simple step by step digital machine (or machines). These machines are always just like the man in the room: they understand nothing and don't speak Chinese. They are merely manipulating symbols without knowing what they mean. Searle writes: \"I can have any formal program you like, but I still understand nothing.\"\n\nThe following arguments (and the intuitive interpretations of the arguments above) do not directly explain how a Chinese speaking mind could exist in Searle's room, or how the symbols he manipulates could become meaningful. However, by raising doubts about Searle's intuitions they support other positions, such as the system and robot replies. These arguments, if accepted, prevent Searle from claiming that his conclusion is obvious by undermining the intuitions that his certainty requires.\n\nSeveral critics believe that Searle's argument relies entirely on intuitions. Ned Block writes \"Searle's argument depends for its force on intuitions that certain entities do not think.\" Daniel Dennett describes the Chinese room argument as a misleading \"intuition pump\" and writes \"Searle's thought experiment depends, illicitly, on your imagining too simple a case, an irrelevant case, and drawing the 'obvious' conclusion from it.\"\n\nSome of the arguments above also function as appeals to intuition, especially those that are intended to make it seem more plausible that the Chinese room contains a mind, which can include the robot, commonsense knowledge, brain simulation and connectionist replies. Several of the replies above also address the specific issue of complexity. The connectionist reply emphasizes that a working artificial intelligence system would have to be as complex and as interconnected as the human brain. The commonsense knowledge reply emphasizes that any program that passed a Turing test would have to be \"an extraordinarily supple, sophisticated, and multilayered system, brimming with 'world knowledge' and meta-knowledge and meta-meta-knowledge\", as Daniel Dennett explains.\n\n\nAn especially vivid version of the speed and complexity reply is from Paul and Patricia Churchland. They propose this analogous thought experiment:\n\n\nStevan Harnad is critical of speed and complexity replies when they stray beyond addressing our intuitions. He writes \"Some have made a cult of speed and timing, holding that, when accelerated to the right speed, the computational may make a phase transition into the mental. It should be clear that is not a counterargument but merely an \"ad hoc\" speculation (as is the view that it is all just a matter of ratcheting up to the right degree of 'complexity.')\"\n\nSearle argues that his critics are also relying on intuitions, however his opponents' intuitions have no empirical basis. He writes that, in order to consider the \"system reply\" as remotely plausible, a person must be \"under the grip of an ideology\". They system reply only makes sense (to Searle) if one assumes that any \"system\" can have consciousness, just by virtue of being a system with the right behavior and functional parts. This assumption, he argues, is not tenable given our experience of consciousness.\n\nSeveral replies argue that Searle's argument is irrelevant because his assumptions about the mind and consciousness are faulty. Searle believes that human beings directly experience their consciousness, intentionality and the nature of the mind every day, and that this experience of consciousness is not open to question. He writes that we must \"presuppose the reality and knowability of the mental.\" These replies question whether Searle is justified in using his own experience of consciousness to determine that it is more than mechanical symbol processing. In particular, the other minds reply argues that we cannot use our experience of consciousness to answer questions about other minds (even the mind of a computer), and the epiphenomena reply argues that Searle's consciousness does not \"exist\" in the sense that Searle thinks it does.\n\n\n\nDaniel Dennett provides this extension to the \"epiphenomena\" argument.\n\nSearle disagrees with this analysis and argues that \"the study of the mind starts with such facts as that humans have beliefs, while thermostats, telephones, and adding machines don't ... what we wanted to know is what distinguishes the mind from thermostats and livers.\" He takes it as obvious that we can detect the presence of consciousness and dismisses these replies as being off the point.\n\n\nThe Chinese room argument is a central concept in Peter Watts' novels \"Blindsight\" and (to a lesser extent) \"Echopraxia\". It is also briefly mentioned in the video game Virtue's Last Reward. In Season 4 of the American crime drama \"Numb3rs\" there is a brief reference to the Chinese room.\n\nThe Chinese Room is also the name of a British independent video game development studio best known for working on experimental first-person games, such as \"Everybody's Gone to the Rapture\", or \"Dear Esther\".\n\n\n\n\n", "id": "6216", "title": "Chinese room"}
{"url": "https://en.wikipedia.org/wiki?curid=6217", "text": "Charon\n\nCharon may refer to:\n\n\n\nAlso an Eve Online Freighter\n\n\n", "id": "6217", "title": "Charon"}
{"url": "https://en.wikipedia.org/wiki?curid=6220", "text": "Circle\n\nA circle is a simple closed shape in Euclidean geometry. It is the set of all points in a plane that are at a given distance from a given point, the centre; equivalently it is the curve traced out by a point that moves so that its distance from a given point is constant. The distance between any of the points and the centre is called the radius.\n\nA circle is a simple closed curve which divides the plane into two regions: an interior and an exterior. In everyday use, the term \"circle\" may be used interchangeably to refer to either the boundary of the figure, or to the whole figure including its interior; in strict technical usage, the circle is only the boundary and the whole figure is called a disc.\n\nA circle may also be defined as a special kind of ellipse in which the two foci are coincident and the eccentricity is 0, or the two-dimensional shape enclosing the most area per unit perimeter squared, using calculus of variations. \n\n\nThe word \"circle\" derives from the Greek κίρκος/κύκλος (\"kirkos/kuklos\"), itself a metathesis of the Homeric Greek κρίκος (\"krikos\"), meaning \"hoop\" or \"ring\". The origins of the words \"circus\" and \"circuit\" are closely related.\n\nThe circle has been known since before the beginning of recorded history. Natural circles would have been observed, such as the Moon, Sun, and a short plant stalk blowing in the wind on sand, which forms a circle shape in the sand. The circle is the basis for the wheel, which, with related inventions such as gears, makes much of modern machinery possible. In mathematics, the study of the circle has helped inspire the development of geometry, astronomy and calculus.\n\nEarly science, particularly geometry and astrology and astronomy, was connected to the divine for most medieval scholars, and many believed that there was something intrinsically \"divine\" or \"perfect\" that could be found in circles.\n\nSome highlights in the history of the circle are:\n\n\nThe ratio of a circle's circumference to its diameter is (pi), an irrational constant approximately equal to 3.141592654. Thus the length of the circumference \"C\" is related to the radius \"r\" and diameter \"d\" by:\n\nAs proved by Archimedes, in his Measurement of a Circle, the area enclosed by a circle is equal to that of a triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, which comes to multiplied by the radius squared:\n\nEquivalently, denoting diameter by \"d\",\n\nthat is, approximately 79% of the circumscribing square (whose side is of length \"d\").\n\nThe circle is the plane curve enclosing the maximum area for a given arc length. This relates the circle to a problem in the calculus of variations, namely the isoperimetric inequality.\n\nIn an \"x\"–\"y\" Cartesian coordinate system, the circle with centre coordinates (\"a\", \"b\") and radius \"r\" is the set of all points (\"x\", \"y\") such that\n\nThis equation, known as the Equation of the Circle, follows from the Pythagorean theorem applied to any point on the circle: as shown in the adjacent diagram, the radius is the hypotenuse of a right-angled triangle whose other sides are of length |\"x\" − \"a\"| and |\"y\" − \"b\"|. If the circle is centred at the origin (0, 0), then the equation simplifies to\n\nThe equation can be written in parametric form using the trigonometric functions sine and cosine as\nwhere \"t\" is a parametric variable in the range 0 to 2, interpreted geometrically as the angle that the ray from (\"a\", \"b\") to (\"x\", \"y\") makes with the positive \"x\"-axis.\n\nAn alternative parametrisation of the circle is:\n\nIn this parametrisation, the ratio of \"t\" to \"r\" can be interpreted geometrically as the stereographic projection of the line passing through the centre parallel to the \"x\"-axis (see Tangent half-angle substitution). However, this parametrisation works only if t is made to range not only through all reals but also to a point at infinity; otherwise, the bottom-most point of the circle would be omitted.\n\nIn homogeneous coordinates each conic section with the equation of a circle has the form\n\nIt can be proven that a conic section is a circle exactly when it contains (when extended to the complex projective plane) the points \"I\"(1: \"i\": 0) and \"J\"(1: −\"i\": 0). These points are called the circular points at infinity.\n\nIn polar coordinates the equation of a circle is:\n\nwhere \"a\" is the radius of the circle, formula_12 is the polar coordinate of a generic point on the circle, and formula_13 is the polar coordinate of the centre of the circle (i.e., \"r\" is the distance from the origin to the centre of the circle, and \"φ\" is the anticlockwise angle from the positive \"x\"-axis to the line connecting the origin to the centre of the circle). For a circle centred at the origin, i.e. \"r\" = 0, this reduces to simply . When , or when the origin lies on the circle, the equation becomes\n\nIn the general case, the equation can be solved for \"r\", giving\nNote that without the ± sign, the equation would in some cases describe only half a circle.\n\nIn the complex plane, a circle with a centre at \"c\" and radius (\"r\") has the equation formula_16. In parametric form this can be written formula_17.\n\nThe slightly generalised equation formula_18 for real \"p\", \"q\" and complex \"g\" is sometimes called a generalised circle. This becomes the above equation for a circle with formula_19, since formula_20. Not all generalised circles are actually circles: a generalised circle is either a (true) circle or a line.\n\nThe tangent line through a point \"P\" on the circle is perpendicular to the diameter passing through \"P\". If and the circle has centre (\"a\", \"b\") and radius \"r\", then the tangent line is perpendicular to the line from (\"a\", \"b\") to (\"x\", \"y\"), so it has the form . Evaluating at (\"x\", \"y\") determines the value of \"c\" and the result is that the equation of the tangent is\nor\n\nIf then the slope of this line is\n\nThis can also be found using implicit differentiation.\n\nWhen the centre of the circle is at the origin then the equation of the tangent line becomes\nand its slope is\n\n\n\n\n\nAn inscribed angle (examples are the blue and green angles in the figure) is exactly half the corresponding central angle (red). Hence, all inscribed angles that subtend the same arc (pink) are equal. Angles inscribed on the arc (brown) are supplementary. In particular, every inscribed angle that subtends a diameter is a right angle (since the central angle is 180 degrees).\n\n\nAnother proof of this result which relies only on two chord properties given above is as follows. Given a chord of length \"y\" and with sagitta of length \"x\", since the sagitta intersects the midpoint of the chord, we know it is part of a diameter of the circle. Since the diameter is twice the radius, the \"missing\" part of the diameter is () in length. Using the fact that one part of one chord times the other part is equal to the same product taken along a chord intersecting the first chord, we find that (. Solving for \"r\", we find the required result.\n\nThere are many compass-and-straightedge constructions resulting in circles.\n\nThe simplest and most basic is the construction given the centre of the circle and a point on the circle. Place the fixed leg of the compass on the centre point, the movable leg on the point on the circle and rotate the compass.\n\n\n\nApollonius of Perga showed that a circle may also be defined as the set of points in a plane having a constant \"ratio\" (other than 1) of distances to two fixed foci, \"A\" and \"B\". (The set of points where the distances are equal is the perpendicular bisector of \"A\" and \"B\", a line.) That circle is sometimes said to be drawn \"about\" two points.\n\nThe proof is in two parts. First, one must prove that, given two foci \"A\" and \"B\" and a ratio of distances, any point \"P\" satisfying the ratio of distances must fall on a particular circle. Let \"C\" be another point, also satisfying the ratio and lying on segment \"AB\". By the angle bisector theorem the line segment \"PC\" will bisect the interior angle \"APB\", since the segments are similar:\n\nAnalogously, a line segment \"PD\" through some point \"D\" on \"AB\" extended bisects the corresponding exterior angle \"BPQ\" where \"Q\" is on \"AP\" extended. Since the interior and exterior angles sum to 180 degrees, the angle \"CPD\" is exactly 90 degrees, i.e., a right angle. The set of points \"P\" such that angle \"CPD\" is a right angle forms a circle, of which \"CD\" is a diameter.\n\nSecond, see for a proof that every point on the indicated circle satisfies the given ratio.\n\nA closely related property of circles involves the geometry of the cross-ratio of points in the complex plane. If \"A\", \"B\", and \"C\" are as above, then the circle of Apollonius for these three points is the collection of points \"P\" for which the absolute value of the cross-ratio is equal to one:\n\nStated another way, \"P\" is a point on the circle of Apollonius if and only if the cross-ratio [\"A\",\"B\";\"C\",\"P\"] is on the unit circle in the complex plane.\n\nIf \"C\" is the midpoint of the segment \"AB\", then the collection of points \"P\" satisfying the Apollonius condition\n\nis not a circle, but rather a line.\n\nThus, if \"A\", \"B\", and \"C\" are given distinct points in the plane, then the locus of points \"P\" satisfying the above equation is called a \"generalised circle.\" It may either be a true circle or a line. In this sense a line is a generalised circle of infinite radius.\n\nIn every triangle a unique circle, called the incircle, can be inscribed such that it is tangent to each of the three sides of the triangle.\n\nAbout every triangle a unique circle, called the circumcircle, can be circumscribed such that it goes through each of the triangle's three vertices.\n\nA tangential polygon, such as a tangential quadrilateral, is any convex polygon within which a circle can be inscribed that is tangent to each side of the polygon.\n\nA cyclic polygon is any convex polygon about which a circle can be circumscribed, passing through each vertex. A well-studied example is the cyclic quadrilateral.\n\nA hypocycloid is a curve that is inscribed in a given circle by tracing a fixed point on a smaller circle that rolls within and tangent to the given circle.\n\nThe circle can be viewed as a limiting case of each of various other figures:\n\nSquaring the circle is the problem, proposed by ancient geometers, of constructing a square with the same area as a given circle by using only a finite number of steps with compass and straightedge.\n\nIn 1882, the task was proven to be impossible, as a consequence of the Lindemann–Weierstrass theorem which proves that pi () is a transcendental number, rather than an algebraic irrational number; that is, it is not the root of any polynomial with rational coefficients.\n\n\n\n\n\n\n\n\n\n\n", "id": "6220", "title": "Circle"}
{"url": "https://en.wikipedia.org/wiki?curid=6221", "text": "Cardinal (Catholic Church)\n\nA cardinal (, literally \"Cardinal of the Holy Roman Church\") is a senior ecclesiastical leader, considered a Prince of the Church, and usually (now always for those created when still within the voting age-range) an ordained bishop of the Roman Catholic Church. The cardinals of the Church are collectively known as the College of Cardinals. The duties of the cardinals include attending the meetings of the College and making themselves available individually or in groups to the Pope as requested. Most have additional duties, such as leading a diocese or archdiocese or managing a department of the Roman Curia. A cardinal's primary duty is electing the pope when the see becomes vacant. During the \"sede vacante\" (the period between a pope's death or resignation and the election of his successor), the day-to-day governance of the Holy See is in the hands of the College of Cardinals. The right to enter the conclave of cardinals where the pope is elected is limited to those who have not reached the age of 80 years by the day the vacancy occurs.\n\nIn 1059, the right of electing the pope was reserved to the principal clergy of Rome and the bishops of the seven suburbicarian sees. In the 12th century the practice of appointing ecclesiastics from outside Rome as cardinals began, with each of them assigned a church in Rome as his titular church or linked with one of the suburbicarian dioceses, while still being incardinated in a diocese other than that of Rome.\n\nThe term \"cardinal\" at one time applied to any priest permanently assigned or incardinated to a church, or specifically to the senior priest of an important church, based on the Latin \"cardo\" (hinge), meaning \"principal\" or \"chief\". The term was applied in this sense as early as the ninth century to the priests of the \"tituli\" (parishes) of the diocese of Rome. The Church of England retains an instance of this origin of the title, which is held by the two senior members of the College of Minor Canons of St Paul's Cathedral.\n\nThere is disagreement about the origin of the term, but general consensus that \"\"cardinalis\"\" from the word \"cardo\" (meaning 'pivot' or 'hinge') was first used in late antiquity to designate a bishop or priest who was incorporated into a church for which he had not originally been ordained. In Rome the first persons to be called cardinals were the deacons of the seven regions of the city at the beginning of the 6th century, when the word began to mean \"principal,\" \"eminent,\" or \"superior.\" The name was also given to the senior priest in each of the \"title\" churches (the parish churches) of Rome and to the bishops of the seven sees surrounding the city. By the 8th century the Roman cardinals constituted a privileged class among the Roman clergy. They took part in the administration of the church of Rome and in the papal liturgy. By decree of a synod of 769, only a cardinal was eligible to become pope. In 1059, during the pontificate of Nicholas II, cardinals were given the right to elect the pope under the Papal Bull \"In nomine Domini\". For a time this power was assigned exclusively to the cardinal bishops, but the Third Lateran Council in 1179 gave back the right to the whole body of cardinals. Cardinals were granted the privilege of wearing the red hat by Pope Innocent IV in 1244.\n\nIn cities other than Rome, the name cardinal began to be applied to certain church men as a mark of honour. The earliest example of this occurs in a letter sent by Pope Zacharias in 747 to Pippin III (the Short), ruler of the Franks, in which Zacharias applied the title to the priests of Paris to distinguish them from country clergy. This meaning of the word spread rapidly, and from the 9th century various episcopal cities had a special class among the clergy known as cardinals. The use of the title was reserved for the cardinals of Rome in 1567 by Pius V.\n\nIn the year 1563 the influential Ecumenical Council of Trent, headed by Pope Pius IV, wrote about the importance of selecting good Cardinals. According to this historic council \"nothing is more necessary to the Church of God than that the holy Roman pontiff apply that solicitude which by the duty of his office he owes the universal Church in a very special way by associating with himself as cardinals the most select persons only, and appoint to each church most eminently upright and competent shepherds; and this the more so, because our Lord Jesus Christ will require at his hands the blood of the sheep of Christ that perish through the evil government of shepherds who are negligent and forgetful of their office.\"\n\nThe earlier influence of temporal rulers, notably the French kings, reasserted itself through the influence of cardinals of certain nationalities or politically significant movements. Traditions even developed entitling certain monarchs, including those of Austria, Spain, and Portugal, to nominate one of their trusted clerical subjects to be created cardinal, a so-called \"crown-cardinal\".\n\nIn early modern times, cardinals often had important roles in secular affairs. In some cases, they took on powerful positions in government. In Henry VIII's England, his chief minister was Cardinal Wolsey. Cardinal Richelieu's power was so great that he was for many years effectively the ruler of France. Richelieu's successor was also a cardinal, Jules Mazarin. Guillaume Dubois and André-Hercule de Fleury complete the list of the \"four great\" cardinals to have ruled France. In Portugal, due to a succession crisis, one cardinal, Henry, King of Portugal, was crowned king, the only example of a cardinal-king.\n\nPope Sixtus V limited the number of cardinals to 70, comprising six cardinal bishops, 50 cardinal priests, and 14 cardinal deacons. Starting in the pontificate of Pope John XXIII, that limit has been exceeded. At the start of 1971, Pope Paul VI set the number of cardinal electors at a maximum of 120, but set no limit on the number of cardinals generally. He also established a maximum age of eighty years for electors. His action deprived twenty-five living cardinals, including the three living cardinals elevated by Pope Pius XI, of the right to participate in a conclave. Popes can dispense from church laws and have sometimes brought the number of cardinals under the age of 80 to more than 120. Pope Paul VI also increased the number of cardinal bishops by giving that rank to patriarchs of the Eastern Catholic Churches.\n\nEach cardinal takes on a titular church, either a church in the city of Rome or one of the suburbicarian sees. The only exception is for patriarchs of Eastern Catholic Churches. Nevertheless, cardinals possess no power of governance nor are they to intervene in any way in matters which pertain to the administration of goods, discipline, or the service of their titular churches. They are allowed to celebrate Mass and hear confessions and lead visits and pilgrimages to their titular churches, in coordination with the staff of the church. They often support their churches monetarily, and many Cardinals do keep in contact with the pastoral staffs of their titular churches.\n\nThe Dean of the College of Cardinals in addition to such a titular church also receives the titular bishopric of Ostia, the primary suburbicarian see. Cardinals governing a particular Church retain that church.\n\nIn 1630, Pope Urban VIII decreed their title to be \"Eminence\" (previously, it had been \"illustrissimo\" and \"reverendissimo\") and decreed that their secular rank would equate to Prince, making them secondary only to the Pope and crowned monarchs.\n\nIn accordance with tradition, they sign by placing the title \"Cardinal\" (abbreviated \"Card.\") after their personal name and before their surname as, for instance, \"John Card(inal) Doe\" or, in Latin, \"Ioannes Card(inalis) Cognomen\". Some writers, such as James-Charles Noonan, hold that, in the case of cardinals, the form used for signatures should be used also when referring to them in English. Official sources such as the Archdiocese of Milwaukee and Catholic News Service say that the correct form for referring to a cardinal in English is normally as \"Cardinal [First name] [Surname]\". This is the rule given also in stylebooks not associated with the Catholic Church. This style is also generally followed on the websites of the Holy See and episcopal conferences. Oriental Patriarchs who are created Cardinals customarily use \"Sanctae Ecclesiae Cardinalis\" as their full title, probably because they do not belong to the Roman clergy.\n\nIn Latin, on the other hand, the [First name] Cardinal [Surname] order is used in the proclamation of the election of a new pope by the cardinal protodeacon: \"\"Annuntio vobis gaudium magnum; habemus Papam: Eminentissimum ac Reverendissimum Dominum, Dominum (first name) Sanctae Romanae Ecclesiae Cardinalem (last name), ...\"\" (Meaning: \"I announce to you a great joy; we have a Pope: The Most Eminent and Most Reverend Lord, Lord (first name) Cardinal of the Holy Roman Church (last name), ...\") This assumes that the new pope had been a cardinal just before becoming pope; the most recent election of a non-cardinal as pope was in 1378.\n\nWhile the incumbents of some sees are regularly made cardinals, and some countries are entitled to at least one cardinal by concordate (usually earning its primate the cardinal's hat), no see carries an actual right to the cardinalate, not even if its bishop is a Patriarch.\n\nCardinal bishops (cardinals of the episcopal order) are among the most senior prelates of the Catholic Church. Though in modern times most cardinals are also bishops, the term \"cardinal bishop\" only refers to the cardinals who are titular bishops of one of the \"suburbicarian\" sees.\n\nIn early times, the privilege of papal election was not reserved to the cardinals, and for centuries the person elected was customarily a Roman priest and never a bishop from elsewhere. To preserve apostolic succession the rite of consecrating him a bishop had to be performed by someone who was already a bishop. The rule remains that, if the person elected Pope is not yet a bishop, he is consecrated by the Dean of the College of Cardinals, the Cardinal Bishop of Ostia.\n\nThere are seven suburbicarian sees: Ostia, Albano, Porto and Santa Rufina, Palestrina, Sabina and Mentana, Frascati and Velletri. Velletri was united with Ostia from 1150 until 1914, when Pope Pius X separated them again, but decreed that whichever cardinal bishop became Dean of the College of Cardinals would keep the suburbicarian see he already held, adding to it that of Ostia, with the result that there continued to be only six cardinal bishops.\n\nSince 1962, the cardinal bishops have only a titular relationship with the suburbicarian sees, with no powers of governance over them. Each see has its own bishop, with the exception of Ostia, in which the Cardinal Vicar of the see of Rome is apostolic administrator.\n\nThe current cardinal bishops of the suburbicarian dioceses are:\n\nFor a period ending in the mid-20th century, long-serving cardinal priests were entitled to fill vacancies that arose among the cardinal bishops, just as cardinal deacons of ten years' standing are still entitled to become cardinal priests. Since then, cardinals have been advanced to cardinal bishop exclusively by papal appointment.\n\nThe Dean of the College of Cardinals, or Cardinal-dean, is the \"primus inter pares\" of the College of Cardinals, elected by the cardinal bishops holding suburbicarian sees from among their own number, an election, however, that must be approved by the Pope. Formerly the position of dean belonged by right to the longest-serving of the cardinal bishops.\n\nIn 1965, Pope Paul VI decreed in his \"motu proprio\" \"Ad Purpuratorum Patrum Collegium\" that patriarchs of the Eastern Catholic Churches who were named cardinals (i.e., patriarch cardinals) would also be part of the episcopal order, ranking after the six cardinal bishops of the suburbicarian sees (who had been relieved of direct responsibilities for those sees by Pope John XXIII three years earlier). Patriarch cardinals do not receive title of a suburbicarian see, and as such they cannot elect the dean or become dean. There are currently three Eastern Patriarchs who are cardinal bishops:\n\nIf a Latin Rite titular patriarch (notably of Venice or Lisbon) is made a cardinal, he ranks as a cardinal priest, not as a cardinal bishop.\n\nCardinal priests are the most numerous of the three orders of cardinals in the Catholic Church, ranking above the cardinal deacons and below the cardinal bishops. Those who are named cardinal priests today are generally bishops of important dioceses throughout the world, though some hold Curial positions.\n\nIn modern times, the name \"cardinal priest\" is interpreted as meaning a cardinal who is of the order of priests. Originally, however, this referred to certain key priests of important churches of the Diocese of Rome, who were recognized as the \"cardinal\" priests, the important priests chosen by the pope to advise him in his duties as Bishop of Rome (the Latin \"cardo\" means \"hinge\"). Certain clerics in many dioceses at the time, not just that of Rome, were said to be the key personnel—the term gradually became exclusive to Rome to indicate those entrusted with electing the bishop of Rome, the pope.\nWhile the cardinalate has long been expanded beyond the Roman pastoral clergy and Roman Curia, every cardinal priest has a titular church in Rome, though they may be bishops or archbishops elsewhere, just as cardinal bishops are given one of the suburbicarian dioceses around Rome. Pope Paul VI abolished all administrative rights cardinals had with regard to their titular churches, though the cardinal's name and coat of arms are still posted in the church, and they are expected to celebrate mass and preach there if convenient when they are in Rome.\n\nWhile the number of cardinals was small from the times of the Roman Empire to the Renaissance, and frequently smaller than the number of recognized churches entitled to a cardinal priest, in the 16th century the College expanded markedly. In 1587, Pope Sixtus V sought to arrest this growth by fixing the maximum size of the College at 70, including 50 cardinal priests, about twice the historical number. This limit was respected until 1958, and the list of titular churches modified only on rare occasions, generally when a building fell into disrepair. When Pope John XXIII abolished the limit, he began to add new churches to the list, which Popes Paul VI and John Paul II continued to do. Today there are close to 150 titular churches, out of over 300 churches in Rome.\n\nThe cardinal who is the longest-serving member of the order of cardinal priests is titled \"cardinal protopriest\". He had certain ceremonial duties in the conclave that have effectively ceased because he would generally have already reached age 80, at which cardinals are barred from the conclave. The current cardinal protopriest is Michael Michai Kitbunchu of Thailand.\n\nThe cardinal deacons are the lowest-ranking cardinals. Cardinals elevated to the diaconal order are either officials of the Roman Curia or priests elevated after their 80th birthday. Bishops with diocesan responsibilities, however, are created cardinal priests.\n\nCardinal deacons derive originally from the seven deacons in the Papal Household and the seven deacons who supervised the Church's works in the districts of Rome during the early Middle Ages, when church administration was effectively the government of Rome and provided all social services. Cardinal deacons are given title to one of these deaconries.\n\nCardinals elevated to the diaconal order are mainly officials of the Roman Curia holding various posts in the church administration. Their number and influence has varied through the years. While historically predominantly Italian the group has become much more internationally diverse in later years. While in 1939 about half were Italian by 1994 the number was reduced to one third. Their influence in the election of the Pope has been considered important, they are better informed and connected than the dislocated cardinals but their level of unity has been varied. Under the 1587 decree of Pope Sixtus V, which fixed the maximum size of the College of Cardinals, there were 14 cardinal deacons. Later the number increased. As late as 1939 almost half of the cardinals were members of the curia. Pius XII reduced this percentage to 24 percent. John XXIII brought it back up to 37 percent but Paul VI brought it down to 27 percent where John Paul II maintained this ratio.\n\nAs of 2005, there were over 50 churches recognized as cardinalatial deaconries, though there were only 30 cardinals of the order of deacons. Cardinal deacons have long enjoyed the right to \"opt for the order of cardinal priests\" (\"optazione\") after they have been cardinal deacons for 10 years. They may on such elevation take a vacant \"title\" (a church allotted to a cardinal priest as the church in Rome with which he is associated) or their diaconal church may be temporarily elevated to a cardinal priest's \"title\" for that occasion. When elevated to cardinal priests, they take their precedence according to the day they were first made cardinal deacons (thus ranking above cardinal priests who were elevated to the college after them, regardless of order).\n\nWhen not celebrating Mass but still serving a liturgical function, such as the semiannual \"Urbi et Orbi\" papal blessing, some Papal Masses and some events at Ecumenical Councils, cardinal deacons can be recognized by the dalmatics they would don with the simple white mitre (so called \"mitra simplex\").\n\nThe cardinal protodeacon, the senior cardinal deacon in order of appointment to the College of Cardinals, has the privilege of announcing a new pope's election and name (once he has been ordained to the episcopate) from the central balcony of St. Peter's Basilica in Vatican City. In the past, during papal coronations, the proto-deacon also had the honor of bestowing the pallium on the new pope and crowning him with the papal tiara. However, in 1978 Pope John Paul I chose not to be crowned and opted for a simpler papal inauguration ceremony, and his three successors followed that example. As a result, the cardinal protodeacon's privilege of crowning a new pope has effectively ceased although it could be revived if a future pope were to restore a coronation ceremony. However, the proto-deacon still has the privilege of bestowing the pallium on a new pope at his papal inauguration. \"Acting in the place of the Roman Pontiff, he also confers the pallium upon metropolitan bishops or gives the pallium to their proxies.\" The current cardinal proto-deacon is Renato Raffaele Martino.\n\n\n<nowiki>*</nowiki>Ceased to be protodeacon upon being raised to the order of cardinal-priest\n<br>†Was protodeacon at time of death\n\nThe Cardinal Camerlengo of the Holy Roman Church, assisted by the Vice-Camerlengo and the other prelates of the office known as the Apostolic Camera, has functions that in essence are limited to a period of \"sede vacante\" of the papacy. He is to collate information about the financial situation of all administrations dependent on the Holy See and present the results to the College of Cardinals, as they gather for the papal conclave.\n\nUntil 1917, it was possible for someone who was not a priest, but only in minor orders, to become a cardinal (see \"lay cardinals\", below), but they were enrolled only in the order of cardinal deacons. For example, in the 16th century, Reginald Pole was a cardinal for 18 years before he was ordained a priest. In 1917 it was established that all cardinals, even cardinal deacons, had to be priests, and, in 1962, Pope John XXIII set the norm that all cardinals be ordained as bishops, even if they are only priests at the time of appointment. As a consequence of these two changes, canon 351 of the 1983 Code of Canon Law requires that a cardinal be at least in the order of priesthood at his appointment, and that those who are not already bishops must receive episcopal consecration. Several cardinals aged over 80 or close to it when appointed have obtained dispensation from the rule of having to be a bishop. These were all appointed cardinal-deacons, but Roberto Tucci and Albert Vanhoye lived long enough to exercise the right of option and be promoted to the rank of cardinal-priest.\n\nA cardinal who is not a bishop is still entitled to wear and use the episcopal vestments and other pontificalia (episcopal regalia: mitre, crozier, zucchetto, pectoral cross and ring). Even if not a bishop, any cardinal has both actual and honorary precedence over non-cardinal patriarchs, as well as the archbishops and bishops who are not cardinals, but he cannot perform the functions reserved solely to bishops, such as ordination. The prominent priests who since 1962 were not ordained bishops on their elevation to the cardinalate were over the age of 80 or near to it, and so no cardinal who was not a bishop has participated in recent papal conclaves.\n\nAt various times, there have been cardinals who had only received first tonsure and minor orders but not yet been ordained as deacons or priests. Though clerics, they were inaccurately called \"lay cardinals\". Teodolfo Mertel was among the last of the lay cardinals. When he died in 1899 he was the last surviving cardinal who was not at least ordained a priest. With the revision of the Code of Canon Law promulgated in 1917 by Pope Benedict XV, only those who are already priests or bishops may be appointed cardinals. Since the time of Pope John XXIII a priest who is appointed a cardinal must be consecrated a bishop, unless he obtains a dispensation.\n\nIn addition to the named cardinals, the pope may name secret cardinals or cardinals \"in pectore\" (Latin for \"in the breast\").\n\nDuring the Western Schism, many cardinals were created by the contending popes. Beginning with the reign of Pope Martin V, cardinals were created without publishing their names until later, termed \"creati et reservati in pectore\".\n\nA cardinal named \"in pectore\" is known only to the pope; not even the cardinal so named is necessarily aware of his elevation, and in any event cannot function as a cardinal while his appointment is \"in pectore\". Today, cardinals are named \"in pectore\" to protect them or their congregations from reprisals if their identities were known.\n\nIf conditions change, so that the pope judges it safe to make the appointment public, he may do so at any time. The cardinal in question then ranks in precedence with those raised to the cardinalate at the time of his \"in pectore\" appointment. If a pope dies before revealing the identity of an \"in pectore\" cardinal, the cardinalate expires.\n\nOf the 232 cardinals that Pope John Paul II elevated, four were named \"in pectore\". The identities of three of these were subsequently revealed:\n\nWhen in choir dress, a Latin-rite cardinal wears scarlet garments — the blood-like red symbolizes a cardinal's willingness to die for his faith. Excluding the rochet — which is always white — the scarlet garments include the cassock, mozzetta, and biretta (over the usual scarlet zucchetto). The biretta of a cardinal is distinctive not merely for its scarlet color, but also for the fact that it does not have a pompon or tassel on the top as do the birettas of other prelates. Until the 1460s, it was customary for cardinals to wear a violet or blue cape unless granted the privilege of wearing red when acting on papal business. His normal-wear cassock is black but has scarlet piping and a scarlet fascia (sash). Occasionally, a cardinal wears a scarlet \"ferraiolo\" which is a cape worn over the shoulders, tied at the neck in a bow by narrow strips of cloth in the front, without any 'trim' or piping on it. It is because of the scarlet color of cardinals' vesture that the bird of the same name has become known as such.\n\nEastern Catholic cardinals continue to wear the normal dress appropriate to their liturgical tradition, though some may line their cassocks with scarlet and wear scarlet fascias, or in some cases, wear Eastern-style cassocks entirely of scarlet.\n\nIn previous times, at the consistory at which the pope named a new cardinal, he would bestow upon him a distinctive wide-brimmed hat called a galero. This custom was discontinued in 1969 and the investiture now takes place with the scarlet biretta. In ecclesiastical heraldry, however, the scarlet galero is still displayed on the cardinal's coat of arms. Cardinals had the right to display the galero in their cathedral, and when a cardinal died, it would be suspended from the ceiling above his tomb. Some cardinals will still have a galero made, even though it is not officially part of their apparel.\n\nTo symbolize their bond with the papacy, the pope gives each newly appointed cardinal a gold ring, which is traditionally kissed by Catholics when greeting a cardinal (as with a bishop's episcopal ring). Before the new uniformity imposed by John Paul II, each cardinal was given a ring, the central piece of which was a gem, usually a sapphire, with the pope's stemma engraved on the inside. There is now no gemstone, and the pope chooses the image on the outside: under Pope Benedict XVI it was a modern depiction of the crucifixion of Jesus, with Mary and John to each side. The ring includes the pope's coat of arms on the inside.\n\nCardinals have in canon law a \"privilege of forum\" (i.e., exemption from being judged by ecclesiastical tribunals of ordinary rank): only the pope is competent to judge them in matters subject to ecclesiastical jurisdiction (cases that refer to matters that are spiritual or linked with the spiritual, or with regard to infringement of ecclesiastical laws and whatever contains an element of sin, where culpability must be determined and the appropriate\necclesiastical penalty imposed). The pope either decides the case himself or delegates the decision to a tribunal, usually one of the tribunals or congregations of the Roman Curia. Without such delegation, no ecclesiastical court, even the Roman Rota, is competent to judge a canon law case against a cardinal. Cardinals are, however, subject to the civil and criminal law like everybody else.\n\n\n\n", "id": "6221", "title": "Cardinal (Catholic Church)"}
{"url": "https://en.wikipedia.org/wiki?curid=6225", "text": "Cantigas de Santa Maria\n\nThe Cantigas de Santa Maria (\"Canticles of Holy Mary\"; ), , are 420 poems with musical notation, written in the Medieval Galician language during the reign of Alfonso X \"El Sabio\" (1221–1284) and often attributed to him.\n\nIt is one of the largest collections of monophonic (solo) songs from the Middle Ages and is characterized by the mention of the Virgin Mary in every song, while every tenth song is a hymn.\n\nThe \"Cantigas\" have survived in four manuscript codices: two at El Escorial, one at Madrid's National Library, and one in Florence, Italy. The E codex from El Escorial is illuminated with colored miniatures showing pairs of musicians playing a wide variety of instruments. The \"Códice Rico\" (T) from El Escorial and the one in the Biblioteca Nazionale Centrale of Florence (F) are richly illuminated with narrative vignettes.\n\nThe Cantigas are written in Galician-Portuguese, fashionable as a lyrical language in Castile at the time. The Cantigas are composed of 420 poems, 356 of which are in a narrative format relating to Marian miracles; the rest of them, except an introduction and two prologues, are of \"lore\" or involve Marian festivities. The Cantigas depict the Virgin Mary in a very humanized way, often having her play a role in earthly episodes.\n\nThe authors are unknown, although several studies have suggested that Galician poet Airas Nunes might have been the author of a large number of the Cantiga poems. King Alfonso X — named as Affonso in the Cantigas — is also believed to be an author of some of them as he refers himself in first person. Support for this theory can be found in the prologue of the Cantigas. Also, many sources credit Alfonso owing to his influence on other works within the poetic tradition, including his introduction on religious song. Although King Alfonso X's authorship is debatable, his influence is not. While the other major works that came out of Alfonso's workshops, including histories and other prose texts, were in Castilian, the Cantigas are in Galician-Portuguese, and reflect the popularity in the Castilian court of other poetic corpuses such as the cantigas d'amigo and cantigas d'amor.\nThe metrics are extraordinarily diverse: 280 different formats for the 420 Cantigas. The most common are the \"virelai\" and the \"rondeau\". The length of the lines varies between two and 24 syllables. The narrative voice in many of the songs describes an erotic relationship, in the troubadour fashion, with the Divine.\nThe music is written in notation which is similar to that used for chant, but also contains some information about the length of the notes. Several transcriptions exist. The Cantigas are frequently recorded and performed by Early Music groups, and quite a few CDs featuring music from the Cantigas are available.\n\nThe Cantigas are preserved in four manuscripts: \"To\" (\"códice de Toledo,\" Biblioteca Nacional de España, MS 10069), \"T\" (Biblioteca de El Escorial, MS T.I.1), \"F\" (\"códice de Florencia,\" Florence, Biblioteca Nazionale, MS b.r. 20) and \"E\" (\"códice de los músicos,\" Biblioteca de El Escorial MS B.I.2). \"E\" contains the largest number of songs (406 Cantigas, plus the Introduction and the Prologue); it contains 41 carefully detailed miniatures and many illuminated letters. \"To\" is the earliest collection and contains 129 songs. Although not illustrated, it is richly decorated with pen flourished initials, and great care has been taken over its construction. The \"T\" and \"F\" manuscripts are sister volumes. \"T\" contains 195 surviving cantigas (8 are missing due to loss of folios) which roughly correspond in order to the first two hundred in \"E\", each song being illustrated with either 6 or 12 miniatures that depict scenes from the cantiga. \"F\" follows the same format but has only 111 cantigas, of which 7 have no text, only miniatures. These are basically a subset of those found in the second half of \"E\", but are presented here in a radically different order. \"F\" was never finished, and so no music was ever added. Only the empty staves display the intention to add musical notation to the codex at a later date. It is generally thought that the codices were constructed during Alfonso's lifetime, \"To\" perhaps in the 1270s, and \"T\"/\"F\" and \"E\" in the early 1280s up until the time of his death in 1284.\n\nThe musical forms within the Cantigas, and there are many, are still being studied. There have been many false leads, and there is little beyond pitch value that is very reliable. Mensuration is a particular problem in the Cantigas, and most attempts at determining meaningful rhythmic schemes have tended, with some exceptions, to be unsatisfactory. This remains a lively topic of debate and study. Progress, while on-going, has nevertheless been significant over the course of the last 20 years.\n\n\n\n", "id": "6225", "title": "Cantigas de Santa Maria"}
{"url": "https://en.wikipedia.org/wiki?curid=6226", "text": "Claudio Monteverdi\n\nClaudio Giovanni Antonio Monteverdi (; 15 May 1567 (baptized) – 29 November 1643) was an Italian composer, gambist, singer, and Catholic priest.\n\nMonteverdi is considered a crucial transitional figure between the Renaissance and the Baroque periods of music history. While he worked extensively in the tradition of earlier Renaissance polyphony, such as in his madrigals, he also made great developments in form and melody and began employing the basso continuo technique, distinctive of the Baroque. Monteverdi wrote one of the earliest operas, \"L'Orfeo\", which is the earliest surviving opera still regularly performed.\n\nClaudio Monteverdi was born in 1567 in Cremona, Duchy of Milan (now Lombardy, Italy). His father was Baldassare Monteverdi, a doctor, apothecary and amateur surgeon. He was the oldest of five children. During his childhood, he was taught by Marc'Antonio Ingegneri, the \"maestro di cappella\" at the Cathedral of Cremona. The Maestro’s job was to conduct important worship services in accordance with the liturgy of the Catholic Church. Monteverdi learned about music as a member of the cathedral choir. He also studied at the University of Cremona. His first music was written for publication, including some motets and sacred madrigals, in 1582 and 1583. His first five publications were: \"Sacrae cantiunculae\", 1582 (a collection of miniature motets); \"Madrigali Spirituali\", 1583 (a volume of which only the bass partbook is extant); \"Canzonette a tre voci\", 1584 (a collection of three-voice canzonettes); and the five-part madrigals Book I, 1587, and Book II, 1590. He worked at the court of Vincenzo I of Gonzaga in Mantua as a vocalist and viol player, then as music director. In 1602, he was working as the court conductor and Vincenzo appointed him \"master of music\" on the death of Benedetto Pallavicino.\n\nIn 1599 Monteverdi married the court singer Claudia Cattaneo, who died in September 1607. They had two sons (Francesco and Massimilino) and a daughter (Leonora). Another daughter died shortly after birth. In 1610 he moved to Rome, arriving in secret, hoping to present his music to Pope Paul V. His Vespers were printed the same year, but his planned meeting with the Pope never took place.\n\nIn 1612 Vincenzo died and was succeeded by his eldest son Francesco. Heavily in debt, due to the profligacy of his father, Francesco sacked Monteverdi and he spent a year in Mantua without any paid employment. His 1607 opera L'Orfeo was dedicated to Francesco. The title page of the opera bears the dedication \"Al serenissimo signor D. Francesco Gonzaga, Prencipe di Mantoua, & di Monferato, &c.\"\n\nBy 1613, he had moved to San Marco in Venice where, as conductor. he quickly restored the musical standard of both the choir and the instrumentalists. The musical standard had declined due to the financial mismanagement of his predecessor, Giulio Cesare Martinengo. The managers of the basilica were relieved to have such a distinguished musician in charge, as the music had been declining since the death of Giovanni Croce in 1609.\n\nIn 1632, he became a priest. During the last years of his life, when he was often ill, he composed his two last masterpieces: \"Il ritorno d'Ulisse in patria\" (\"The Return of Ulysses\", 1641), and the historic opera \"L'incoronazione di Poppea\" (\"The Coronation of Poppea\", 1642), based on the life of the Roman emperor Nero. \"L'incoronazione\" especially is considered a culminating point of Monteverdi's work. It contains tragic, romantic, and comic scenes (a new development in opera), a more realistic portrayal of the characters, and warmer melodies than previously heard. It requires a smaller orchestra, and has a less prominent role for the choir. For a long period of time, Monteverdi's operas were merely regarded as a historical or musical interest. Since the 1960s, \"The Coronation of Poppea\" has re-entered the repertoire of major opera companies worldwide.\n\nMonteverdi died, aged 76, in Venice on 29 November 1643 and was buried at the church of the Frari.\n\nMonteverdi's works are split into three categories: madrigals, operas, and church-music.\n\nUntil the age of forty, Monteverdi worked primarily on madrigals, composing a total of nine books. It took Monteverdi about four years to finish his first book of twenty-one madrigals for five voices. As a whole, the first eight books of madrigals show the enormous development from Renaissance polyphonic music to the monodic style typical of Baroque music.\n\nThe titles of his Madrigal books are:\n\nThe \"Fifth Book of Madrigals\" shows the shift from the late Renaissance style of music to the early Baroque. The \"Quinto Libro\" (Fifth Book), published in 1605, was at the heart of the controversy between Monteverdi and Giovanni Artusi. Artusi attacked the \"crudities\" and \"license\" of the modern style of composing, centering his attacks on madrigals (including \"Cruda Amarilli\", composed around 1600) from the fourth book. Monteverdi made his reply in the introduction to the fifth book, with a proposal of the division of musical practice into two streams, which he called \"prima pratica\", and \"seconda pratica\". \"Prima pratica\" was described as the previous polyphonic ideal of the sixteenth century, with flowing strict counterpoint, prepared dissonance, and equality of voices. \"Seconda pratica\" used much freer counterpoint with an increasing hierarchy of voices, emphasizing soprano and bass. In \"Prima pratica\" the harmony controls the words. In \"seconda pratica\" the words should be in control of the harmonies. This represented a move towards the new style of monody. The introduction of continuo in many of the madrigals was a further self-consciously modern feature. In addition, the fifth book showed the beginnings of conscious functional tonality.\n\nWhile in Venice, Monteverdi also finished his sixth (1614), seventh (1619), and eighth (1638) books of madrigals. The eighth is the largest, containing works written over a thirty-year period. Originally the work was to be dedicated to Ferdinand II, but because of his ill health, his son was made king in December 1636. When the work was first published in 1638 Monteverdi rededicated it to the new King Ferdinand III. The eighth book includes the so-called \"Madrigali dei guerrieri et amorosi\" (\"Madrigals of War and Love\").\n\nThe important preface of Monteverdi’s eighth madrigal book seems to be connected with his \"seconda pratica.\" He claims to have invented a new \"agitated\" style (\"genere concitato\", later called \"stile concitato\").\nThe book is divided into sections of War and Love each containing madrigals, a piece in dramatic form (\"genere rappresentativo\"), and a ballet. In the \"Madrigals of War,\" Monteverdi has organized poetry that describes the pursuits of love through the allegory of war; the hunt for love, and the battle to find love. In the second half of the book, the \"Madrigals of Love,\" Monteverdi organized poetry that describes the unhappiness of being in love, unfaithfulness, and ungrateful lovers who feel no shame. In his previous madrigal collections, Monteverdi usually set poetry from one or two poets he was in contact with through the court where he was employed. The \"Madrigals of War and Love\" represent an overview of the poets he has dealt with throughout his life; the classical poetry of Petrarch, poetry by his contemporaries (Tasso, Guarini, Marino, Rinuccini, Testi and Strozzi), or anonymous poets who Monteverdi found and adapted to his needs.\n\nMadrigals of War\n\n\nMadrigals of Love\n\nThe ninth book of madrigals, published posthumously in 1651, contains lighter pieces such as canzonettas which were probably composed throughout Monteverdi's lifetime representing both styles.\n\nMonteverdi was often ill during the last years of his life. During this time, he composed his two last masterpieces: \"Il ritorno d'Ulisse in patria\" (\"The Return of Ulysses\", 1640), and the historic opera, \"L'incoronazione di Poppea \"(\"The Coronation of Poppea\", 1642), based on an episode in the life of the Roman emperor Nero. The libretto for \"Il ritorno d'Ulisse\" was written by Giacomo Badoarro and for \"L'incoronazione di Poppea\" by Giovanni Busenello.\n\nMonteverdi composed at least eighteen operas, but only \"L'Orfeo\", \"Il ritorno d'Ulisse in patria\", \"L'incoronazione di Poppea\", and the famous aria, \"Lamento\", from his second opera \"L'Arianna\" have survived. From monody (with melodic lines, intelligible text and placid accompanying music), it was a logical step for Monteverdi to begin composing opera. In 1607, his first opera, \"L'Orfeo\", premiered in Mantua. \"L'Orfeo\" was not the first opera, but it was the first mature opera, or one that realized all of its potential. It was normal at that time for composers to create works on demand for special occasions, and this piece was part of the ducal celebrations of carnival. (Monteverdi was later to write for the first opera houses supported by ticket sales which opened in Venice). \"L'Orfeo\" has dramatic power and lively orchestration. \"L'Orfeo\" is arguably the first example of a composer assigning specific instruments to parts in operas. It is also one of the first large compositions for which the exact instrumentation of the premiere is still known. The plot is described in vivid musical pictures and the melodies are linear and clear. With this opera, Monteverdi created an entirely new style of music, the \"dramma per la musica\" or musical drama.\n\n\"L'Arianna\" was the second opera written by Monteverdi. It is one of the most influential and famous specimens of early Baroque opera. It was first performed in Mantua in 1608. Its subject matter was the ancient Greek legend of Ariadne and Theseus. Italian composer Ottorino Respighi famously orchestrated the \"Lamento di Arianna\" in 1908, and the work was premiered by the Berlin Philharmonic the same year under conductor Arthur Nikisch. The manuscript was restored and published as a critical edition in 2013 by Italian composer/conductor Salvatore Di Vittorio under publisher Edizioni Panastudio. A later completion of the \"Lamento\" from \"L'Arianna\" by Scottish composer Gareth Wilson (b. 1976) was performed at King's College, London University on 29 November 2013, the 370th anniversary of Monteverdi's death.\n\nMonteverdi's first church music publication was the archaic Mass \"In illo tempore\" to which the \"Vesper Psalms\" of 1610 were added. The \"Vesper Psalms\" of 1610 are also one of the best examples of early repetition and contrast, with many of the parts having a clear \"ritornello\". The published work is on a very grand scale and there has been some controversy as to whether all the movements were intended to be performed in a single service. However, there are various indications of internal unity. In its scope, it foreshadows such summits of Baroque music as Handel's \"Messiah\", and J.S. Bach's \"St Matthew Passion\". Each part (there are twenty-five in total) is fully developed in both a musical and dramatic sense – the instrumental textures are used to precise dramatic and emotional effect, in a way that had not been seen before.\n\n\n\nIn 1607, Aquilino Coppini published in Milan his \"\"Musica tolta da i Madrigali di Claudio Monteverde, e d'altri autori ... e fatta spirituale\"\" for 5 and 6 voices, in which many of Monteverdi's madrigals (especially from the third, fourth and fifth books) are presented with the original secular texts replaced with sacred Latin \"contrafacta\" carefully prepared by Coppini in order to fit the music in every aspect.\n\n\nNotes\nCited sources\n\nOther sources\n\n", "id": "6226", "title": "Claudio Monteverdi"}
{"url": "https://en.wikipedia.org/wiki?curid=6229", "text": "Colossus computer\n\nColossus was a set of computers developed by British codebreakers in 1943–1945 to help in the cryptanalysis of the Lorenz cipher. Colossus used thermionic valves (vacuum tubes) to perform Boolean and counting operations. Colossus is thus regarded as the world's first programmable, electronic, digital computer, although it was programmed by switches and plugs and not by a stored program.\n\nColossus was designed by research telephone engineer Tommy Flowers to solve a problem posed by mathematician Max Newman at the Government Code and Cypher School (GC&CS) at Bletchley Park. Alan Turing's use of probability in cryptanalysis contributed to its design. It has sometimes been erroneously stated that Turing designed Colossus to aid the cryptanalysis of the Enigma. Turing's machine that helped decode Enigma was the electromechanical Bombe, not Colossus.\n\nThe prototype, Colossus Mark 1, was shown to be working in December 1943 and was operational at Bletchley Park on 5 February 1944. An improved Colossus Mark 2 that used shift registers to quintuple the processing speed, first worked on 1 June 1944, just in time for the Normandy Landings on D-Day. Ten Colossi were in use by the end of the war and an eleventh was being commissioned. Bletchley Park's use of these machines allowed the Allies to obtain a vast amount of high-level military intelligence from intercepted radiotelegraphy messages between the German High Command (OKW) and their army commands throughout occupied Europe.\n\nThe destruction of the Colossus machines and documents, as part of the effort to maintain the secrecy of the project (maintained into the 1970s), deprived most of those involved with Colossus of the credit for pioneering electronic digital computing during their lifetimes. A functioning replica of a Colossus computer was completed in 2007 and is on display at The National Museum of Computing at Bletchley Park.\n\nThe Colossus computers were used to help decipher intercepted radio teleprinter messages that had been encrypted using an unknown device. The British called encrypted German teleprinter traffic \"Fish\", and the unknown machine and its intercepted messages \"Tunny\". Before the Germans increased the security of their operating procedures, British cryptanalysts diagnosed how the unseen machine functioned and built an imitation of it called \"British Tunny\".\n\nIt was deduced that the machine had twelve wheels and used a Vernam ciphering technique on message characters in the standard 5-bit ITA2 telegraph code. It did this by combining the plaintext characters with a stream of key characters using the XOR Boolean function to produce the ciphertext.\n\nIn August 1941, a blunder by German operators led to the transmission of two versions of the same message with identical machine settings. These were intercepted and worked on at Bletchley Park. First, John Tiltman, a very talented GC&CS cryptanalyst, derived a key stream of almost 4000 characters. Then Bill Tutte, a newly arrived member of the Research Section, used this key stream to work out the logical structure of the Lorenz machine. He deduced that the twelve wheels consisted of two groups of five, which he named the χ (\"chi\") and ψ (\"psi\") wheels, the remaining two he called μ (\"mu\") or \"motor\" wheels. The \"chi\" wheels stepped regularly with each letter that was encrypted, while the \"psi\" wheels stepped irregularly, under the control of the motor wheels.\n\nWith a sufficiently random key stream, a Vernam cipher removes the natural language property of a plaintext message of having an uneven frequency distribution of the different characters, to produce a uniform distribution in the ciphertext. The Tunny machine did this well. However, the cryptanalysts worked out that by examining the frequency distribution of the character-to-character changes in the ciphertext, instead of the plain characters, there was a departure from uniformity which provided a way into the system. This was achieved by \"differencing\" in which each bit or character was XOR-ed with its successor. After Germany surrendered, allied forces captured a Tunny machine and discovered that it was the electromechanical Lorenz SZ (\"Schlüsselzusatzgerät\", cipher attachment) in-line cipher machine.\n\nIn order to decrypt the transmitted messages, two tasks had to be performed. The first was \"wheel breaking\", which was the discovery of the cam patterns for all the wheels. These patterns were set up on the Lorenz machine and then used for a fixed period of time for a succession of different messages. Each transmission, which often contained more than one message, was enciphered with a different start position of the wheels. Alan Turing invented a method of wheel-breaking that became known as Turingery. Turing's technique was further developed into \"Rectangling\", for which Colossus could produce tables for manual analysis. Colossi 2, 4, 6, 7 and 9 had a \"gadget\" to aid this process.\n\nThe second task was \"wheel setting\", which worked out the start positions of the wheels for a particular message, and could only be attempted once the cam patterns were known. It was this task for which Colossus was initially designed. To discover the start position of the \"chi\" wheels for a message, Colossus compared two character streams, counting statistics from the evaluation of programmable Boolean functions. The two streams were the ciphertext, which was read at high speed from a paper tape, and the key stream, which was generated internally, in a simulation of the unknown German machine. After a succession of different Colossus runs to discover the likely \"chi\"-wheel settings, they were checked by examining the frequency distribution of the characters in processed ciphertext. Colossus produced these frequency counts.\n\nBy using differencing and knowing that the \"psi\" wheels did not advance with each character, Tutte worked out that trying just two differenced bits (impulses) of the \"chi\"-stream against the differenced ciphertext would produce a statistic that was non-random. This became known as Tutte's \"1+2 break in\". It involved calculating the following Boolean function:\nand counting the number of times it yielded \"false\" (zero). If this number exceeded a pre-defined threshold value known as the \"set total\", it was printed out. The cryptanalyst would examine the printout to determine which of the putative start positions was most likely to be the correct one for the \"chi\"-1 and \"chi\"-2 wheels.\n\nThis technique would then be applied to other pairs of, or single, impulses to determine the likely start position of all five \"chi\" wheels. From this, the de-\"chi\" (D) of a ciphertext could be obtained, from which the \"psi\" component could be removed by manual methods. If the frequency distribution of characters in the de-\"chi\" version of the ciphertext was within certain bounds, \"wheel setting\" of the \"chi\" wheels was considered to have been achieved, and the message settings and de-\"chi\" were passed to the \"Testery\". This was the section at Bletchley Park led by Major Ralph Tester where the bulk of the decrypting work was done by manual and linguistic methods.\n\nColossus could also derive the start position of the \"psi\" and motor wheels, but this was not much done until the last few months of the war, when there were plenty of Colossi available and the number of Tunny messages had declined.\n\nColossus was developed for the \"Newmanry\", the section headed by the mathematician Max Newman that was responsible for machine methods against the Lorenz machine. The Colossus design arose out of a prior project that produced a counting machine dubbed \"Heath Robinson\". The main problems with Heath Robinson were the relative slowness of electro-mechanical parts and the difficulty of synchronising two paper tapes, one punched with the enciphered message, and the other representing the key stream of the Lorenz machine. Heath Robinson tapes tended to stretch when being read, at some 2000 characters per second, resulting in unreliable answers.\nTommy Flowers, who had been appointed MBE in June 1943, was a senior electrical engineer and Head of the Switching Group at the Post Office Research Station at Dollis Hill. Prior to his work on Colossus, he had been involved with GC&CS at Bletchley Park from February 1941 in an attempt to improve the Bombes that were used in the cryptanalysis of the German Enigma cipher machine. He was recommended to Max Newman by Alan Turing, who had been impressed by his work on the Bombes. The main components of Colossus's predecessor, Heath Robinson were as follows.\n\nFlowers had been brought in to design the Heath Robinson's combining unit. He was not impressed by the system of a key tape that had to be kept synchronised with the message tape and, on his own initiative, he designed an electronic machine which eliminated the need for the key tape by having an electronic analogue of the Lorenz (Tunny) machine. He presented this design to Max Newman in February 1943, but the idea that the one to two thousand thermionic valves (vacuum tubes and thyratrons) proposed, could work together reliably, was greeted with great scepticism, so more Robinsons were ordered from Dollis Hill. Flowers, however, knew from his pre-war work that most thermionic valve failures occurred as a result of the thermal stresses at power up, so not powering a machine down reduced failure rates to very low levels. Flowers persisted with the idea and obtained support from the Director of the Research Station, W Gordon Radley. Flowers and his team of some fifty people in the switching group spent eleven months from early February 1943 designing and building a machine that dispensed with the second tape of the Heath Robinson, by generating the wheel patterns electronically.\n\nThis prototype, Mark 1 Colossus, performed satisfactorily at Dollis Hill on 8 December 1943 and was taken apart and shipped to Bletchley Park, where it was delivered on 18 January and re-assembled by Harry Fensom and Don Horwood. It attacked its first message on 5 February 1944. As it was a large structure it was quickly dubbed Colossus by the WRNS operators. This machine contained 1600 thermionic valves (tubes). and was soon followed by an improved production Mark 2 machine. Nine of this version of the machine were constructed, the first being commissioned on 1 June 1944, after which Allen Coombs took over leadership of Colossus production. The original Mark 1 machine was converted into a Mark 2 and an eleventh Colossus was essentially finished when the war in Europe ended.\nThe main units of the Mark 2 design were as follows.\n\nMost of the design of the electronics was the work of Tommy Flowers, assisted by William Chandler, Sidney Broadhurst and Allen Coombs; and Erie Speight and Arnold Lynch developing the photoelectric reading mechanism. Coombs remembered Flowers, having produced a rough draft of his design, tearing it into pieces that he handed out to his colleagues for them to do the detailed design and get their team to manufacture it. Work on the Mark 2 design started while Mark 1 was being constructed. It contained 2400 valves and was both 5 times faster and simpler to operate than the original version.\n\nThe design overcame the problem of synchronizing the electronics with the message tape by generating a clock signal from the reading of the sprocket holes of the message tape. The speed of operation was thus limited by the mechanics of reading the tape. The tape reader was tested up to 9700 characters per second (53 mph) before the tape disintegrated. So 5000 characters/second () was settled on as the speed for regular use.\n\nFlowers designed shift registers, one being used for each of the five channels of the punched tape. For each circuit of the tape, the shift register stored successive bits from each of the tape channels and delivered five successive characters (either Z or ΔZ according to switch selection) to the processors. The five-way parallelism enabled five simultaneous tests and counts to be performed giving an effective processing speed of 25,000 characters per second. \n\nThe Newmanry was staffed by cryptanalysts, operators from the Women's Royal Naval Service (WRNS) – known as “Wrens” – and engineers who were permanently on hand to repair the Colossi. The first job in operating Colossus for a new message, was to prepare the paper tape loop. This was performed by the Wren operators who stuck the two ends together using Bostik, ensuring that there was a 150-character length of blank tape between the end and the start of the message. Using a special hand punch they inserted a start hole between the third and fourth channels at end of the blank section, and a stop hole between the fourth and fifth channels at the end of the characters of the message. These were read by specially positioned photocells and indicated to the processor when the message was about to start and when it ended. The operator then threaded the paper tape through the gate and around the pulleys of the bedstead and adjusted the tension. The two-tape bedstead design had been carried on from Heath Robinson so that one tape could be loaded whilst the previous one was being run. A switch on the Selection Panel specified the “near“ or the “far” tape.\n\nAfter performing various resetting and zeroizing tasks, the Wren operator would set the twelve wheel patterns that had been determined by the wheel breaking process and the start positions for the current run. Then, under instruction from the cryptanalyst, she would operate the “set total” decade switches and the switches and plugs to achieve the desired algorithm. She would then start the bedstead tape motor and lamp, and when the tape was up to speed operate the master start switch.\n\nHoward Campaigne, a mathematician and cryptanalyst from the US Navy's OP-20-G, wrote the following in a foreword to Flowers' 1983 paper \"The Design of Colossus\".\n\nColossus was not a stored program computer. The input data for the five parallel processors was read from the looped message paper tape and the electronic pattern generators for the \"chi\", \"psi\" and motor wheels. The programs for the processors were set and held on the switches and jack panel connections. Each processor could evaluate a Boolean function and count and display the number of times it yielded the specified value of \"false\" (0) or \"true\" (1) for each pass of the message tape.\n\nInput to the processors came from two sources, the shift registers from tape reading and the thyratron rings that emulated the wheels of the Tunny machine. The characters on the paper tape were called Z and the characters from the Tunny emulator were referred to by the Greek letters that Bill Tutte had given them when working out the logical structure of the machine. On the selection panel, switches specified either Z or ΔZ, either formula_1 or Δformula_1 and either formula_5 or Δformula_5 for the data to be passed to the jack field and 'K2 switch panel'. These signals from the wheel simulators could be specified as stepping on with each new pass of the message tape or not.\n\nThe K2 switch panel had a group of switches on the left hand side to specify the algorithm. The switches on the right hand side selected the counter to which the result was fed. The plugboard allowed less specialized conditions to be imposed. Overall the K2 switch panel switches and the plugboard allowed about five billion different combinations of the selected variables. \n\nAs an example: a set of runs for a message tape might initially involve two \"chi\" wheels, as in Tutte's 1+2 algorithm. Such a two-wheel run was called a long run, taking on average eight minutes unless the parallelism was utilised to cut the time by a factor of five. The subsequent runs might only involve setting one \"chi\" wheel, giving a short run taking about two minutes. Initially, after the initial long run, the choice of next algorithm to be tried was specified by the cryptanalyst. Experience showed, however, that decision trees for this iterative process could be produced for use by the Wren operators in a proportion of cases.\n\nAlthough the Colossus was the first of the electronic digital machines with programmability, albeit limited by modern standards, it was not a general-purpose machine, being designed for a range of cryptanalytic tasks, most involving counting the results of evaluating Boolean algorithms.\n\nA Colossus computer was thus not a fully Turing complete machine. However, University of San Francisco professor Benjamin Wells has shown that if all ten Colossus machines made were rearranged in a specific cluster, then the entire set of computers could have simulated a universal Turing machine, and thus be Turing complete. The notion of a computer as a general purpose machine — that is, as more than a calculator devoted to solving difficult but specific problems — did not become prominent until after World War II.\n\nColossus and the reasons for its construction were highly secret, and remained so for 30 years after the War. Consequently, it was not included in the history of computing hardware for many years, and Flowers and his associates were deprived of the recognition they were due. Colossi 1 to 10 were dismantled after the war and parts returned to the Post Office. Some parts, sanitised as to their original purpose, were taken to Max Newman's Royal Society Computing Machine Laboratory at Manchester University. Tommy Flowers was ordered to destroy all documentation and burnt them in a furnace at Dollis Hill. He later said of that order:\n\nA small number of people who were associated with Colossus—and knew that large-scale, reliable, high-speed electronic digital computing devices were feasible—played significant roles in early computer work in the UK and probably in the US. However, being so secret, it had little direct influence on the development of later computers; it was EDVAC that was the seminal computer architecture of the time. In 1972 Herman Goldstine, who was unaware of Colossus and its legacy to the projects of people such as Alan Turing (ACE), Max Newman (Manchester computers) and Harry Huskey (Bendix G-15), wrote that:\nProfessor Brian Randell, who unearthed information about Colossus in the 1970s, commented on this, saying that:\nRandell's efforts started to bear fruit in the mid-1970s, after the secrecy about Bletchley Park was broken when Group Captain Winterbotham published his 1974 book \"The Ultra Secret\". In October 2000, a 500-page technical report on the Tunny cipher and its cryptanalysis—entitled \"General Report on Tunny\"—was released by GCHQ to the national Public Record Office, and it contains a fascinating paean to Colossus by the cryptographers who worked with it:\nConstruction of a fully functional replica of a Colossus Mark 2 was undertaken by a team led by Tony Sale. In spite of the blueprints and hardware being destroyed, a surprising amount of material survived, mainly in engineers' notebooks, but a considerable amount of it in the U.S. The optical tape reader might have posed the biggest problem, but Dr. Arnold Lynch, its original designer, was able to redesign it to his own original specification. The reconstruction is on display, in the historically correct place for Colossus No. 9, at The National Museum of Computing, in H Block Bletchley Park in Milton Keynes, Buckinghamshire.\n\nIn November 2007, to celebrate the project completion and to mark the start of a fundraising initiative for The National Museum of Computing, a Cipher Challenge pitted the rebuilt Colossus against radio amateurs worldwide in being first to receive and decode three messages enciphered using the Lorenz SZ42 and transmitted from radio station DL0HNF in the \"Heinz Nixdorf MuseumsForum\" computer museum. The challenge was easily won by radio amateur Joachim Schüth, who had carefully prepared for the event and developed his own signal processing and code-breaking code using Ada. The Colossus team were hampered by their wish to use World War II radio equipment, delaying them by a day because of poor reception conditions. Nevertheless, the victor's 1.4 GHz laptop, running his own code, took less than a minute to find the settings for all 12 wheels. The German codebreaker said: \"My laptop digested ciphertext at a speed of 1.2 million characters per second—240 times faster than Colossus. If you scale the CPU frequency by that factor, you get an equivalent clock of 5.8 MHz for Colossus. That is a remarkable speed for a computer built in 1944.\"\n\nThe Cipher Challenge verified the successful completion of the rebuild project. \"On the strength of today's performance Colossus is as good as it was six decades ago\", commented Tony Sale. \"We are delighted to have produced a fitting tribute to the people who worked at Bletchley Park and whose brainpower devised these fantastic machines which broke these ciphers and shortened the war by many months.\"\n\nThere was a fictional computer named \"Colossus\" in the 1970 movie \"\" which was based on the 1966 novel \"Colossus\" by D. F. Jones. This was sheer coincidence as it pre-dates the public release of information about Colossus, or even its name.\n\nNeal Stephenson's novel \"Cryptonomicon\" (1999) also contains a fictional treatment of the historical role played by Turing and Bletchley Park.\n\n\n\n", "id": "6229", "title": "Colossus computer"}
{"url": "https://en.wikipedia.org/wiki?curid=6230", "text": "Canadian Shield\n\nThe Canadian Shield, also called the Laurentian Plateau, or \"\" (French), is a large area of exposed Precambrian igneous and high-grade metamorphic rocks (geological shield) that forms the ancient geological core of the North American continent (the North American Craton or Laurentia). Composed of igneous rock resulting from its long volcanic history, the area is covered by a thin layer of soil. With a deep, common, joined bedrock region in eastern and central Canada, it stretches north from the Great Lakes to the Arctic Ocean, covering over half of Canada; it also extends south into the northern reaches of the United States. Human population is sparse, and industrial development is minimal, while mining is prevalent.\n\nThe Canadian Shield is a physiographic division, consisting of five smaller, physiographic provinces: the Laurentian Upland, Kazan Region, Davis, Hudson and James. The shield extends into the United States as the Adirondack Mountains (connected by the Frontenac Axis) and the Superior Upland. The Canadian Shield is U-shaped and is a subsection of the Laurentia craton signifying the area of greatest glacial impact (scraping down to bare rock) creating the thin soils. The Canadian Shield is more than 3.96 billion years old. The Canadian Shield once had jagged peaks, higher than any of today's mountains, but millions of years of erosion have changed these mountains to rolling hills.\n\nThe Canadian Shield is a collage of Archean plates and accreted juvenile arc terranes and sedimentary basins of the Proterozoic Eon that were progressively amalgamated during the interval 2.45 to 1.24 Ga, with the most substantial growth period occurring during the Trans-Hudson orogeny, between ca. 1.90 to 1.80 Ga. The Canadian Shield was the first part of North America to be permanently elevated above sea level and has remained almost wholly untouched by successive encroachments of the sea upon the continent. It is the Earth's greatest area of exposed Archean rock. The metamorphic base rocks are mostly from the Precambrian Supereon (between 4.5 billion and 540 million years ago), and have been repeatedly uplifted and eroded. Today it consists largely of an area of low relief above sea level with a few monadnocks and low mountain ranges (including the Torngat and Laurentian Mountains) probably eroded from the plateau during the Cenozoic Era. During the Pleistocene Epoch, continental ice sheets depressed the land surface (see Hudson Bay), scooped out thousands of lake basins, and carried away much of the region's soil.\n\nWhen the Greenland section is included, the Shield is approximately circular, bounded on the northeast by the northeast edge of Greenland, with Hudson Bay in the middle. It covers much of Greenland, Labrador, most of Quebec north of the St. Lawrence River, much of Ontario including northern sections of the southern peninsula between the Great Lakes, the Adirondack Mountains of New York, the northernmost part of Lower Michigan and all of Upper Michigan, northern Wisconsin, northeastern Minnesota, the central/northern portions of Manitoba away from Hudson Bay, northern Saskatchewan, a small portion of northeastern Alberta, and the mainland northern Canadian territories to the east of a line extended north from the Saskatchewan/Alberta border (Northwest Territories and Nunavut). In total, the exposed area of the Shield covers approximately . The true extent of the Shield is greater still and stretches from the Western Cordillera in the west to the Appalachians in the east and as far south as Texas, but these regions are overlaid with much younger rocks and sediment. The underlying rock structure also includes Hudson Bay.\n\nThe Canadian Shield is among the oldest on earth, with regions dating from 2.5 to 4.2 billion years. \nThe multitude of rivers and lakes in the entire region is caused by the watersheds of the area being so young and in a state of sorting themselves out with the added effect of post-glacial rebound. The Shield was originally an area of very large, very tall mountains (about ) with much volcanic activity, but over hundreds of millions of years, the area has been eroded to its current topographic appearance of relatively low relief. It has some of the oldest (extinct) volcanoes on the planet. It has over 150 volcanic belts (now deformed and eroded down to nearly flat plains) whose bedrock ranges from 600 to 1200 million years old.\n\nEach belt probably grew by the coalescence of accumulations erupted from numerous vents, making the tally of volcanoes reach the hundreds. Many of Canada's major ore deposits are associated with Precambrian volcanoes.\n\nThe Sturgeon Lake Caldera in Kenora District, Ontario, is one of the world's best preserved mineralized Neoarchean caldera complexes, which is 2.7 billion years old. The Canadian Shield also contains the Mackenzie dike swarm, which is the largest dike swarm known on Earth.\n\nMountains have deep roots and float on the denser mantle much like an iceberg at sea. As mountains erode, their roots rise and are eroded in turn. The rocks that now form the surface of the Shield were once far below the Earth's surface.\n\nThe high pressures and temperatures at those depths provided ideal conditions for mineralization. Although these mountains are now heavily eroded, many large mountains still exist in Canada's far north called the Arctic Cordillera. This is a vast deeply dissected mountain range, stretching from northernmost Ellesmere Island to the northernmost tip of Labrador. The range's highest peak is Nunavut's Barbeau Peak at above sea level. Precambrian rock is the major component of the bedrock.\n\nThe North American craton is the bedrock forming the heart of the North American continent and the Canadian Shield is the largest exposed part of the craton's bedrock.\n\nThe Canadian Shield is part of an ancient continent called Arctica, which was formed about 2.5 billion years ago during the Neoarchean era. It was split into Greenland, Laurentia, Scotland and Siberia and is now roughly situated in the Arctic around the current North Pole.\n\nThe current surface expression of the Shield is one of very thin soil lying on top of the bedrock, with many bare outcrops. This arrangement was caused by severe glaciation during the ice age, which covered the Shield and scraped the rock clean.\n\nThe lowlands of the Canadian Shield have a very dense soil that is not suitable for forestation; it also contains many marshes and bogs (muskegs). The rest of the region has coarse soil that does not retain moisture well and is frozen with permafrost throughout the year. Forests are not as dense in the north.\n\nThe Shield is covered in parts by vast boreal forests in the south that support natural ecosystems as well as a major logging industry. This boreal forest area includes ecoregions such as the Eastern Canadian Shield taiga that covers northern Quebec and most of Labrador, and the Midwestern Canadian Shield forests that run westwards from Northwestern Ontario. Hydrographical drainage is generally poor, the soil compacting effects of glaciation being one of the many causes. Tundra typically prevails in the northern regions. Many mammals such as caribou, white-tailed deer, moose, wolves, wolverines, weasels, mink, otters, grizzly bear, polar bears and black bears are present. In the case of polar bears (\"Ursus maritimus\") the Shield area contains many of the denning locations such as the Wapusk National Park.\n\nThe Canadian Shield is one of the world's richest areas in terms of mineral ores. It is filled with substantial deposits of nickel, gold, silver, and copper. Throughout the Shield there are many mining towns extracting these minerals. The largest, and one of the best known, is Sudbury, Ontario. Sudbury is an exception to the normal process of forming minerals in the Shield since the Sudbury Basin is an ancient meteorite impact crater. Ejecta from the meteorite impact was found in the Rove Formation in May 2007. The nearby, but less known Temagami Magnetic Anomaly, has striking similarities to the Sudbury Basin. This suggests it could be a second metal-rich impact crater.\n\nIn northeastern Quebec, the giant Manicouagan Reservoir is the site of an extensive hydroelectric project (Manic-cinq, or Manic-5). This is one of the largest-known meteorite impact craters on Earth.\n\nThe Flin Flon greenstone belt in central Manitoba and east-central Saskatchewan is one of the largest Paleoproterozoic volcanic-hosted massive sulfide (VMS) districts in the world, containing 27 copper-zinc-(gold) deposits from which more than 183 million tons of sulfide have been mined.\n\nThe Shield, particularly the portion in the Northwest Territories, has recently been the site of several major diamond discoveries. The kimberlite pipes in which the diamonds are found are closely associated with cratons, which provide the deep lithospheric mantle required to stabilize diamond as a mineral. The kimberlite eruptions then bring the diamonds from over depth to the surface. Currently the Ekati and Diavik mines are actively mining kimberlite diamonds.\n\n\n", "id": "6230", "title": "Canadian Shield"}
{"url": "https://en.wikipedia.org/wiki?curid=6231", "text": "Comic book\n\nA comic book or comicbook, also called comic magazine or simply comic, is a publication that consists of comic art in the form of sequential juxtaposed panels that represent individual scenes. Panels are often accompanied by brief descriptive prose and written narrative, usually dialog contained in word balloons emblematic of the comics art form. Although some origins in 18th century Japan and 1830s Europe, comic books were first popularized in the United States during the 1930s. The first modern comic book, \"Famous Funnies\", was released in the United States in 1933 and was a reprinting of earlier newspaper humor comic strips, which had established many of the story-telling devices used in comics. The term \"comic book\" derives from American comic books once being a compilation of comic strips of a humorous tone; however, this practice was replaced by featuring stories of all genres, usually not humorous in tone.\n\nComic books are reliant on their organization and appearance. Authors largely focus on the frame of the page, size, orientation, and panel positions. These characteristic aspects of comic books are necessary in conveying the content and messages of the author. The key elements of comic books include panels, balloons (speech bubbles), text (lines), and characters. Balloons are usually convex spatial containers of information that are related to a character using a tail element. The tail has an origin, path, tip, and pointed direction.\n\nThere are many technological formulas used to create comic books, including directions, axes, data, and metrics. Following these key formatting procedures is the writing, drawing, and coloring.\n\nComics as a print medium have existed in America since the printing of \"The Adventures of Mr. Obadiah Oldbuck\" in 1842 in hardcover, making it the first known American prototype comic book. Proto-comics periodicals began appearing early in the 20th century, with historians generally citing Dell Publishing's 36-page \"Famous Funnies: A Carnival of Comics\" as the first true American comic book; Goulart, for example, calls it \"the cornerstone for one of the most lucrative branches of magazine publishing\". The introduction of Jerry Siegel and Joe Shuster's Superman in 1938 turned comic books into a major industry, and ushered the Golden Age of Comics. The Golden Age originated the archetype of the superhero.\n\nHistorians generally divide the timeline of the American comic book into eras. The Golden Age of Comic Books began with the introduction of Superman in 1938, spurring a period of high sales. The Silver Age of comic books is generally considered to date from the first successful revival of the then-dormant superhero form, with the debut of the Flash in \"Showcase\" #4 (Oct. 1956). The Silver Age lasted through the late 1960s or early 1970s, during which time Marvel Comics revolutionized the medium with such naturalistic superheroes as Stan Lee and Jack Kirby's Fantastic Four and Lee and Steve Ditko's Spider-Man. The demarcation between the Silver Age and the following era, the Bronze Age of Comic Books, is less well-defined, with the Bronze Age running from the very early 1970s through the mid-1980s. The Modern Age of Comic Books runs from the mid-1980s to the present day.\n\nA notable event in the history of the American comic book came with psychiatrist Fredric Wertham's criticisms of the medium in his book \"Seduction of the Innocent\" (1954), which prompted the American Senate Subcommittee on Juvenile Delinquency to investigate comic books. In response to attention from the government and from the media, the U.S. comic book industry set up the Comics Magazine Association of America. The CMAA instilled the Comics Code Authority in 1954 and drafted the self-censorship Comics Code that year, which required all comic books to go through a process of approval. It was not until the 1970s that comic books could be published without passing through the inspection of the CMAA.\n\nIn the early 1970s, a surge of creativity emerged in what became known as underground comix. Published and distributed independently of the established comics industry, most of such comics reflected the youth counterculture and drug culture of the time. Many had an uninhibited, often irreverent style; their frank depictions of nudity, sex, profanity, and politics had no parallel outside their precursors, the pornographic and even more obscure \"Tijuana bibles\". Underground comics were almost never sold at newsstands, but rather in such youth-oriented outlets as head shops and record stores, as well as by mail order.\n\nFrank Stack's \"The Adventures of Jesus\", published under the name Foolbert Sturgeon, has been credited as the first underground comic.\n\nThe rise of comic book specialty stores in the late 1970s created/paralleled a dedicated market for \"independent\" or \"alternative comics\" in the U.S. The first such comics included the anthology series \"Star Reach\", published by comic-book writer Mike Friedrich from 1974 to 1979, and Harvey Pekar's \"American Splendor\", which continued sporadic publication into the 21st century and which Shari Springer Berman and Robert Pulcini adapted into a 2003 film. Some independent comics continued in the tradition of underground comics. While their content generally remained less explicit, others resembled the output of mainstream publishers in format and genre, but were published by smaller artist-owned companies or by single artists. A few (notably \"RAW\") represented experimental attempts to bring comics closer to the status of fine art.\n\nDuring the 1970s the \"small press\" culture grew and diversified. By the 1980s, several independent publishers - such as Pacific, Eclipse, First, Comico, and Fantagraphics - had started releasing a wide range of styles and formats—from color-superhero, detective, and science-fiction comic books to black-and-white magazine-format stories of Latin American magical realism.\n\nA number of small publishers in the 1990s changed the format and distribution of their comics to more closely resemble non-comics publishing. The \"minicomics\" form, an extremely informal version of self-publishing, arose in the 1980s and became increasingly popular among artists in the 1990s, despite reaching an even more limited audience than the small press.\n\nSmall publishers regularly releasing titles include Avatar Comics, Hyperwerks, Raytoons, and Terminal Press, buoyed by such advances in printing technology as digital print-on-demand.\n\nIn 1964, Richard Kyle coined the term \"graphic novel\".. Precursors of the form existed by the 1920s, which saw a revival of the medieval woodcut tradition by Belgian Frans Masereel, American Lynd Ward and others, including Stan Lee.\nIn 1950, St. John Publications produced the digest-sized, adult-oriented \"picture novel\" \"It Rhymes with Lust\", a 128-page digest by pseudonymous writer \"Drake Waller\" (Arnold Drake and Leslie Waller), penciler Matt Baker and inker Ray Osrin, touted as \"an original full-length novel\" on its cover. In 1971, writer-artist Gil Kane and collaborators devised the paperback \"comics novel\" \"Blackmark\". Will Eisner popularized the term \"graphic novel\" when he used it on the cover of the paperback edition of his work \"A Contract with God, and Other Tenement Stories\" in 1978.\n\nThe 1970s saw the advent of specialty comic book stores. Initially, comic books were marketed by publishers to children because comic books were perceived as children's entertainment. However, with increasing recognition of comics as an art form and the growing pop culture presence of comic book conventions, they are now embraced by many adults.\n\nComic book collectors are often lifelong enthusiasts of the comic book stories and they usually focus on particular heroes and attempt to assemble the entire run of a title. Comics are published with a sequential number. The very first issue of the Marvel magazine 'The Amazing Spider-Man' was number 1 and that was followed by number 2 until the end of the run which ran into the hundreds. Number 1 is commonly the rarest and most desirable to collectors.\n\nHowever, the first appearance of a character might be in an existing title. For example, Spider-Man's first appearance was in Amazing Fantasy number 15. New characters were often introduced this way, and did not receive their own titles until there was a proven audience for the hero. As a result, comics that feature the first appearance of an important character will sometimes be even harder to find than the number 1 issue of a character's own title.\n\nSome rare comic books include copies of the unreleased \"Motion Picture Funnies Weekly\" #1 from 1939. Eight copies, plus one without a cover, emerged in the estate of the deceased publisher in 1974. The \"Pay Copy\" of this book sold for $43,125 in a 2005 Heritage auction.\n\nThe most valuable American comics have combined rarity and quality with the first appearances of popular and enduring characters. Four comic books have sold for over $1 million USD as of December 2010, including two examples of Action Comics #1, the first appearance of Superman, both sold privately through online dealer ComicConnect.com in 2010, and Detective Comics #27, the first appearance of Batman, via public auction.\n\nUpdating the above price obtained for Action Comics #1, the first appearance of Superman, the highest sale on record for this book is $3.2 million, for a 9.0 copy. \nMisprints, promotional comic-dealer incentive printings, and issues with extremely low distribution also generally have scarcity value. The rarest modern comic books include the original press run of \"The League of Extraordinary Gentlemen\" #5, which DC executive Paul Levitz recalled and pulped due to the appearance of a vintage Victorian era advertisement for \"Marvel Douche\", which the publisher considered offensive; only 100 copies exist, most of which have been CGC graded. (See Recalled comics for more pulped, recalled, and erroneous comics.)\n\nIn 2000, a company named CGC began to \"slab\" comics, encasing them in a thick plastic and giving them a numeric grade. As of 2014, there are two companies that provide third party grading of comic book condition. Because condition is so important to the value of rare comics, the idea of grading by a company that does not buy or sell comics seems like a good one. However, there is some controversy about whether this grading service is worth the high cost, and whether it is a positive development for collectors, or if it primarily services speculators who wish to make a quick profit trading in comics as one might trade in stocks or fine art. Comic grading has created valuation standards that online price guides such as GoCollect and GPAnalysis have used to report on real-time market values.\n\nThe original artwork pages from comic books are also collected, and these are perhaps the rarest of all comic book collector's items, as there is only one unique page of artwork for each page that was printed and published. These were created by a writer, who created the story; a pencil artist, who laid out the sequential panels on the page; an ink artist, who went over the pencil with pen and black ink; a letterer, who provided the dialogue and narration of the story by hand lettering each word; and finally a colorist, who added color as the last step before the finished pages went to the printer.\n\nWhen the original pages of artwork are returned by the printer, they are typically given back to the artists, who sometimes sell them at comic book conventions, or in galleries and art shows related to comic book art. The original pages of the first appearances of such legendary characters as Superman, Batman, Wonder Woman and Spider-man are considered priceless.\n\n \nFrance and Belgium have a long tradition in comics and comic books, called \"BDs\" (an abbreviation of \"bande dessinées\") in French and \"strips\" in Dutch. Belgian comic books originally written in Dutch show the influence of the Francophone \"Franco-Belgian\" comics, but have their own distinct style.\n\nThe name \"bande dessinée\" derives from the original description of the art form as drawn strips (the phrase literally translates as \"the drawn strip\"), analogous to the sequence of images in a film strip. As in its English equivalent, the word \"bande\" can be applied to both film and comics. Significantly, the French-language term contains no indication of subject-matter, unlike the American terms \"comics\" and \"funnies\", which imply an art form not to be taken seriously. The distinction of comics as \"le neuvième art\" (literally, \"the ninth art\") is prevalent in French scholarship on the form, as is the concept of comics criticism and scholarship itself. Relative to the respective size of their populations, the innumerable authors in France and Belgium publish a high volume of comic books. In North America, the more serious Franco-Belgian comics are often seen as equivalent to graphic novels, but whether they are long or short, bound or in magazine format, in Europe there is no need for a more sophisticated term, as the art's name does not itself imply something frivolous.\n\nIn France, authors control the publication of most comics. The author works within a self-appointed time-frame, and it is common for readers to wait six months or as long as two years between installments. Most books first appear in print as a hardcover book, typically with 48, 56, or 64 pages.\n\nAlthough \"Ally Sloper's Half Holiday\" (1884), the first comic published in Britain, aimed at an adult market, publishers quickly targeted a younger demographic, which has led to most publications being for children and has created an association in the public's mind of comics as somewhat juvenile. British comics in the early 20th century typically evolved from illustrated penny dreadfuls of the Victorian era (featuring Sweeney Todd, Dick Turpin and \"Varney the Vampire\"). \n\nThe two most popular British comic books, \"The Beano\" and \"The Dandy\", were released by DC Thomson in the 1930s. By 1950 the weekly circulation of both reached two million. Explaining the enormous popularity of comics in British popular culture during this period, Anita O’Brien, director curator at London’s Cartoon Museum, states: “When comics like the Beano and Dandy were invented back in the 1930s - and through really to the 1950s and 60s - these comics were almost the only entertainment available to children.\"\n\nIn 1954, \"Tiger\" comics introduced \"Roy of the Rovers\", the hugely popular football based strip recounting the life of Roy Race and the team he played for, Melchester Rovers. The stock media phrase \"real 'Roy of the Rovers' stuff\" is often used by football writers, commentators and fans when describing displays of great skill, or surprising results that go against the odds, in reference to the dramatic storylines that were the strip's trademark. Other comic books such as \"Eagle\", \"Valiant\", \"Warrior\", \"Viz\" and \"2000 AD\" also flourished. Some comics, such as \"Judge Dredd\" and other \"2000 AD\" titles, have been published in a tabloid form. Underground comics and \"small press\" titles have also appeared in the UK, notably \"Oz\" and \"Escape Magazine\".\n\nThe content of \"Action\", another title aimed at children and launched in the mid-1970s, became the subject of discussion in the House of Commons. Although on a smaller scale than similar investigations in the U.S., such concerns led to a moderation of content published within British comics. Such moderation never became formalized to the extent of promulgating a code, nor did it last long. The UK has also established a healthy market in the reprinting and repackaging of material, notably material originating in the U.S. The lack of reliable supplies of American comic books led to a variety of black-and-white reprints, including Marvel's monster comics of the 1950s, Fawcett's Captain Marvel, and other characters such as Sheena, Mandrake the Magician, and the Phantom. Several reprint companies became involved in repackaging American material for the British market, notably the importer and distributor Thorpe & Porter. Marvel Comics established a UK office in 1972. DC Comics and Dark Horse Comics also opened offices in the 1990s. The repackaging of European material has occurred less frequently, although \"The Adventures of Tintin\" and \"Asterix\" serials have been successfully translated and repackaged in softcover books.\n\nIn the 1980s, a resurgence of British writers and artists gained prominence in mainstream comic books, which was dubbed the \"British Invasion\" in comic book history. These writers and artists brought with them their own mature themes and philosophy such as anarchy, controversy and politics common in British media. These elements would pave the way for mature and \"darker and edgier\" comic books and jump start the Modern Age of Comics. Writers included Alan Moore, famous for his \"V for Vendetta\", \"From Hell\", \"Watchmen\", \"Marvelman\", and \"The League of Extraordinary Gentlemen\"; Neil Gaiman with \"The Sandman\" mythos and \"Books of Magic\"; Warren Ellis, creator of \"Transmetropolitan\" and \"Planetary\"; and others such as Mark Millar, creator of \"Wanted\" and \"Kick-Ass\". The comic book series \"Hellblazer\", which is largely set in Britain and starring the magician John Constantine, paved the way for British writers such as Jamie Delano.\n\nAt Christmas time, publishers repackage and commission material for comic annuals, printed and bound as hardcover A4-size books; \"Rupert\" supplies a famous example of the British comic annual. DC Thomson also repackages \"The Broons\" and \"Oor Wullie\" strips in softcover A4-size books for the holiday season.\n\nOn 19 March 2012, the British postal service, the Royal Mail, released a set of stamps depicting British comic-book characters and series. The collection featured \"The Beano\", \"The Dandy\", \"Eagle\", \"The Topper\", \"Roy of the Rovers\", \"Bunty\", \"Buster\", \"Valiant\", \"Twinkle\" and \"2000 AD\".\n\nIn Italy, comics (known in Italian as \"fumetti\") made their debut as humor strips at the end of the 19th century, and later evolved into adventure stories. After World War II, however, artists like Hugo Pratt and Guido Crepax exposed Italian comics to an international audience. Popular comic books such as \"Diabolik\" or the \"Bonelli\" line—namely \"Tex Willer\" or \"Dylan Dog\"—remain best-sellers.\n\nMainstream comics are usually published on a monthly basis, in a black-and-white digest size format, with approximately 100 to 132 pages. Collections of classic material for the most famous characters, usually with more than 200 pages, are also common. Author comics are published in the French BD format, with an example being Pratt's \"Corto Maltese\".\n\nItalian cartoonists show the influence of comics from other countries, including France, Belgium, Spain, and Argentina. Italy is also famous for being one of the foremost producers of Walt Disney comic stories outside the U.S. Donald Duck's superhero alter ego, Paperinik, known in English as Superduck, was created in Italy.\n\n\"Čtyřlístek\" (in English translated as Lucky Four or Four-Leaf Clover) is one of the most well-known comics for children published in the Czech Republic.\n\nThe first comic books in Japan appeared during the 18th century in the form of woodblock-printed booklets containing short stories drawn from folk tales, legends, and historical accounts, told in a simple visual-verbal idiom. Known as , , and , these were written primarily for less literate readers. However, with the publication in 1775 of Koikawa Harumachi's comic book , an evolved form of comic book originated, which required greater literacy and cultural sophistication. This was known as the . Published in thousands of copies, the \"kibyōshi\" may have been the earliest fully realized comic book for adults in world literary history. Approximately 2,000 titles remain extant.\n\nModern comic books in Japan developed from a mixture of these earlier comic books and of woodblock prints with Western styles of drawing. They took their current form shortly after World War II. They are usually published in black-and-white, except for the covers, which are usually printed in four colors, although occasionally, the first few pages may also be printed in full color. The term \"manga\" means \"random (or whimsical) pictures\", and first came into common usage in the late 18th century with the publication of such works as Santō Kyōden's picturebook (1798) and Aikawa Minwa's \"Comic Sketches of a Hundred Women\" (1798). During the Meiji period, the term \"Akahon\" was also common.\n\nWestern artists were brought over to teach their students such concepts as line, form, and color; things which had not been regarded as conceptually important in \"ukiyo-e\", as the idea behind the picture was of paramount importance. Manga at this time was referred to as \"Ponchi-e\" (Punch-picture) and, like its British counterpart \"Punch\" magazine, mainly depicted humor and political satire in short one- or four-picture format.\n\nDr. Osamu Tezuka (1928–1989) further developed this form. Seeing an animated war propaganda film titled inspired Tezuka to become a comic artist. He introduced episodic storytelling and character development in comic format, in which each story is part of larger story arc. The only text in Tezuka's comics was the characters' dialogue and this further lent his comics a cinematic quality. Inspired by the work of Walt Disney, Tezuka also adopted a style of drawing facial features in which a character's eyes, nose, and mouth are drawn in an extremely exaggerated manner. This style created immediately recognizable expressions using very few lines, and the simplicity of this style allowed Tezuka to be prolific. Tezuka's work generated new interest in the \"ukiyo-e\" tradition, in which the image is a representation of an idea, rather than a depiction of reality.\n\nThough a close equivalent to the American comic book, manga has historically held a more important place in Japanese culture than comics have in American culture. Japanese society shows a wide respect for manga, both as an art form and as a form of popular literature. Many manga become television shows or short films. As with its American counterpart, some manga has been criticized for its sexuality and violence, although in the absence of official or even industry restrictions on content, artists have freely created manga for every age group and for every topic.\n\nManga magazines—also known as \"anthologies\"—often run several series concurrently, with approximately 20 to 40 pages allocated to each series per issue. These magazines range from 200 to more than 850 pages each. Manga magazines also contain one-shot comics and a variety of four-panel yonkoma (equivalent to comic strips). Manga series may continue for many years if they are successful, with stories often collected and reprinted in book-sized volumes called , the equivalent of the American trade paperbacks. These volumes use higher-quality paper and are useful to readers who want to be brought up to date with a series, or to readers who find the cost of the weekly or monthly publications to be prohibitive. Deluxe versions are printed as commemorative or collectible editions.\n\n, fan-made Japanese comics operate in a far larger market in Japan than the American \"underground comics\" market; the largest doujinshi fair, Comiket, attracts 500,000 visitors twice a year.\n\nDistribution has historically been a problem for the comic book industry with many mainstream retailers declining to carry extensive stocks of the most interesting and popular comics. The smartphone and the tablet have turned out to be an ideal medium for online distribution.\n\nOn November 13, 2007, Marvel Comics launched Marvel Digital Comics Unlimited, a subscription service allowing readers to read many comics from Marvel's history online. The service also includes periodic release new comics not available elsewhere. With the release of \"Avenging Spider-Man\" Marvel also became the first publisher to provide free digital copies as part of the print copy of the comic book.\n\nWith the growing popularity of smartphones and tablets, many major publishers have begun releasing titles in digital form. The most popular platform is comiXology. Some platforms, such as Graphicly, have shut down,\n\nMany libraries have extensive collections of comics in the form of graphic novels. This is a convenient way for many in the public to become familiar with the medium.\n\nThe largest comic book ever published was on the 30th of August 2014 in Fremont, California, USA. It was chapter one of the graphic novel CruZader™: Agent of the Vatican by Omar Morales and it measured at 60.96 cm by 94.46 cm (2 ft by 3 ft 1.19 in).\n\n\n\n", "id": "6231", "title": "Comic book"}
{"url": "https://en.wikipedia.org/wiki?curid=6233", "text": "Connected space\n\nIn topology and related branches of mathematics, a connected space is a topological space that cannot be represented as the union of two or more disjoint nonempty open subsets. Connectedness is one of the principal topological properties that are used to distinguish topological spaces.\n\nA subset of a topological space \"X\" is a connected set if it is a connected space when viewed as a subspace of \"X\".\n\nA topological space \"X\" is said to be disconnected if it is the union of two disjoint nonempty open sets. Otherwise, \"X\" is said to be connected. A subset of a topological space is said to be connected if it is connected under its subspace topology. Some authors exclude the empty set (with its unique topology) as a connected space, but this article does not follow that practice.\n\nFor a topological space \"X\" the following conditions are equivalent:\n\n\nThe maximal connected subsets (ordered by inclusion) of a nonempty topological space are called the connected components of the space.\nThe components of any topological space \"X\" form a partition of \"X\": they are disjoint, nonempty, and their union is the whole space.\nEvery component is a closed subset of the original space. It follows that, in the case where their number is finite, each component is also an open subset. However, if their number is infinite, this might not be the case; for instance, the connected components of the set of the rational numbers are the one-point sets (singletons), which are not open.\n\nLet formula_1 be the connected component of \"x\" in a topological space \"X\", and formula_2 be the intersection of all clopen sets containing \"x\" (called quasi-component of \"x\".) Then formula_3 where the equality holds if \"X\" is compact Hausdorff or locally connected.\n\nA space in which all components are one-point sets is called totally disconnected. Related to this property, a space \"X\" is called totally separated if, for any two distinct elements \"x\" and \"y\" of \"X\", there exist disjoint open neighborhoods \"U\" of \"x\" and \"V\" of \"y\" such that \"X\" is the union of \"U\" and \"V\". Clearly any totally separated space is totally disconnected, but the converse does not hold. For example take two copies of the rational numbers Q, and identify them at every point except zero. The resulting space, with the quotient topology, is totally disconnected. However, by considering the two copies of zero, one sees that the space is not totally separated. In fact, it is not even Hausdorff, and the condition of being totally separated is strictly stronger than the condition of being Hausdorff.\n\n\nAn example of a space that is not connected is a plane with an infinite line deleted from it. Other examples of disconnected spaces (that is, spaces which are not connected) include the plane with an annulus removed, as well as the union of two disjoint closed disks, where all examples of this paragraph bear the subspace topology induced by two-dimensional Euclidean space.\n\nA path-connected space is a stronger notion of connectedness, requiring the structure of a path. A path from a point \"x\" to a point \"y\" in a topological space \"X\" is a continuous function \"f\" from the unit interval [0,1] to \"X\" with \"f\"(0) = \"x\" and \"f\"(1) = \"y\". A path-component of \"X\" is an equivalence class of \"X\" under the equivalence relation which makes \"x\" equivalent to \"y\" if there is a path from \"x\" to \"y\". The space \"X\" is said to be path-connected (or pathwise connected or 0-connected) if there is exactly one path-component, i.e. if there is a path joining any two points in \"X\". Again, many authors exclude the empty space.\n\nEvery path-connected space is connected. The converse is not always true: examples of connected spaces that are not path-connected include the extended long line \"L\"* and the \"topologist's sine curve\".\n\nSubsets of the real line R are connected if and only if they are path-connected; these subsets are the intervals of R.\nAlso, open subsets of R or C are connected if and only if they are path-connected.\nAdditionally, connectedness and path-connectedness are the same for finite topological spaces.\n\nA space \"X\" is said to be arc-connected or arcwise connected if any two distinct points can be joined by an \"arc\", that is a path \"f\" which is a homeomorphism between the unit interval [0, 1] and its image \"f\"([0, 1]). It can be shown any Hausdorff space which is path-connected is also arc-connected. An example of a space which is path-connected but not arc-connected is provided by adding a second copy 0' of 0 to the nonnegative real numbers <nowiki>[</nowiki>0, ∞<nowiki>)</nowiki>. One endows this set with a partial order by specifying that 0'<\"a\" for any positive number \"a\", but leaving 0 and 0' incomparable. One then endows this set with the \"order topology\", that is one takes the open intervals\n(\"a\", \"b\") = {\"x\" | \"a\" < \"x\" < \"b\"} and the half-open intervals <nowiki>[</nowiki>0, \"a\"<nowiki>)</nowiki> = {\"x\" | 0 ≤ x < \"a\"}, <nowiki>[</nowiki>0', \"a\"<nowiki>)</nowiki> = {\"x\" | 0' ≤ \"x\" < \"a\"} as a base for the topology. The resulting space is a T space but not a Hausdorff space. Clearly 0 and 0' can be connected by a path but not by an arc in this space.\n\nA topological space is said to be locally connected at a point \"x\" if every neighbourhood of \"x\" contains a connected open neighbourhood. It is locally connected if it has a base of connected sets. It can be shown that a space \"X\" is locally connected if and only if every component of every open set of \"X\" is open. The topologist's sine curve is an example of a connected space that is not locally connected.\n\nSimilarly, a topological space is said to be if it has a base of path-connected sets.\nAn open subset of a locally path-connected space is connected if and only if it is path-connected.\nThis generalizes the earlier statement about R and C, each of which is locally path-connected. More generally, any topological manifold is locally path-connected.\n\nNeither local connectedness nor local path connectedness necessarily implies connectedness or path connectedness. For example, the space formula_7 is locally connected and locally path connected but neither connected nor path connected.\n\nThe intersection of connected sets is not necessarily connected.\n\nThe union of connected sets is not necessarily connected. Consider a collection formula_8 of connected sets whose union is formula_9. If formula_10 is disconnected and formula_11 is a separation of formula_10 (with formula_13 disjoint and open in formula_10), then each formula_15 must be entirely contained in either formula_16 or formula_17, since otherwise, formula_18 and formula_19 (which are disjoint and open in formula_15) would be a separation of formula_15, contradicting the assumption that it is connected.\n\nThis means that, if the union formula_10 is disconnected, then the collection formula_8 can be partitioned to two sub-collections, such that the unions of the sub-collections are disjoint and open in formula_10 (see picture). This implies that in several cases, a union of connected sets \"is\" necessarily connected. In particular:\n\n\nThe set difference of connected sets is not necessarily connected. However, if \"X\"⊇\"Y\" and their difference \"X\"\\\"Y\" is disconnected (and thus can be written as a union of two open sets \"X1\" and \"X2\"), then the union of \"Y\" with each such component is connected (i.e. \"Y\"∪\"Xi\" is connected for all \"i\"). Proof: By contradiction, suppose \"Y\"∪\"X1\" is not connected. So it can be written as the union of two disjoint open sets, e.g. \"Y\"∪\"X1\" = \"Z1\"∪\"Z2\". Because \"Y\" is connected, it must be entirely contained in one of these components, say \"Z1\", and thus \"Z2\" is contained in \"X1\". Now we know that:\nThe two sets in the last union are disjoint and open in \"X\", so there is a separation of \"X\", contradicting the fact that \"X\" is connected.\n\n\nGraphs have path connected subsets, namely those subsets for which every pair of points has a path of edges joining them.\nBut it is not always possible to find a topology on the set of points which induces the same connected sets. The 5-cycle graph (and any \"n\"-cycle with \"n\">3 odd) is one such example.\n\nAs a consequence, a notion of connectedness can be formulated independently of the topology on a space. To wit, there is a category of connective spaces consisting of sets with collections of connected subsets satisfying connectivity axioms; their morphisms are those functions which map connected sets to connected sets . Topological spaces and graphs are special cases of connective spaces; indeed, the finite connective spaces are precisely the finite graphs.\n\nHowever, every graph can be canonically made into a topological space, by treating vertices as points and edges as copies of the unit interval (see topological graph theory#Graphs as topological spaces). Then one can show that the graph is connected (in the graph theoretical sense) if and only if it is connected as a topological space.\n\nThere are stronger forms of connectedness for topological spaces, for instance: \n\nIn general, note that any path connected space must be connected but there exist connected spaces that are not path connected. The deleted comb space furnishes such an example, as does the above-mentioned topologist's sine curve.\n\n\n", "id": "6233", "title": "Connected space"}
{"url": "https://en.wikipedia.org/wiki?curid=6235", "text": "Cell nucleus\n\nIn cell biology, the nucleus (pl. \"nuclei\"; from Latin or , meaning \"kernel\" or \"seed\") is a membrane-enclosed organelle found in eukaryotic cells. Eukaryotes usually have a single nucleus, but a few cell types, such as mammalian red blood cells, have no nuclei, and a few others have many.\n\nCell nuclei contain most of the cell's genetic material, organized as multiple long linear DNA molecules in complex with a large variety of proteins, such as histones, to form chromosomes. The genes within these chromosomes are the cell's nuclear genome and are structured in such a way to promote cell function. The nucleus maintains the integrity of genes and controls the activities of the cell by regulating gene expression—the nucleus is, therefore, the control center of the cell. The main structures making up the nucleus are the nuclear envelope, a double membrane that encloses the entire organelle and isolates its contents from the cellular cytoplasm, and the nuclear matrix (which includes the nuclear lamina), a network within the nucleus that adds mechanical support, much like the cytoskeleton, which supports the cell as a whole.\n\nBecause the nuclear membrane is impermeable to large molecules, nuclear pores are required to regulate nuclear transport of molecules across the envelope. The pores cross both nuclear membranes, providing a channel through which larger molecules must be actively transported by carrier proteins while allowing free movement of small molecules and ions. Movement of large molecules such as proteins and RNA through the pores is required for both gene expression and the maintenance of chromosomes. Although the interior of the nucleus does not contain any membrane-bound sub compartments, its contents are not uniform, and a number of \"sub-nuclear bodies\" exist, made up of unique proteins, RNA molecules, and particular parts of the chromosomes. The best-known of these is the nucleolus, which is mainly involved in the assembly of ribosomes. After being produced in the nucleolus, ribosomes are exported to the cytoplasm where they translate mRNA.\n\nThe nucleus was the first organelle to be discovered. What is most likely the oldest preserved drawing dates back to the early microscopist Antonie van Leeuwenhoek (1632–1723). He observed a \"lumen\", the nucleus, in the red blood cells of salmon. Unlike mammalian red blood cells, those of other vertebrates still contain nuclei.\n\nThe nucleus was also described by Franz Bauer in 1804 and in more detail in 1831 by Scottish botanist Robert Brown in a talk at the Linnean Society of London. Brown was studying orchids under microscope when he observed an opaque area, which he called the \"areola\" or \"nucleus\", in the cells of the flower's outer layer.\n\nHe did not suggest a potential function. In 1838, Matthias Schleiden proposed that the nucleus plays a role in generating cells, thus he introduced the name \"cytoblast\" (cell builder). He believed that he had observed new cells assembling around \"cytoblasts\". Franz Meyen was a strong opponent of this view, having already described cells multiplying by division and believing that many cells would have no nuclei. The idea that cells can be generated de novo, by the \"cytoblast\" or otherwise, contradicted work by Robert Remak (1852) and Rudolf Virchow (1855) who decisively propagated the new paradigm that cells are generated solely by cells (\"Omnis cellula e cellula\"). The function of the nucleus remained unclear.\n\nBetween 1877 and 1878, Oscar Hertwig published several studies on the fertilization of sea urchin eggs, showing that the nucleus of the sperm enters the oocyte and fuses with its nucleus. This was the first time it was suggested that an individual develops from a (single) nucleated cell. This was in contradiction to Ernst Haeckel's theory that the complete phylogeny of a species would be repeated during embryonic development, including generation of the first nucleated cell from a \"monerula\", a structureless mass of primordial mucus (\"Urschleim\"). Therefore, the necessity of the sperm nucleus for fertilization was discussed for quite some time. However, Hertwig confirmed his observation in other animal groups, including amphibians and molluscs. Eduard Strasburger produced the same results for plants in 1884. This paved the way to assign the nucleus an important role in heredity. In 1873, August Weismann postulated the equivalence of the maternal and paternal germ \"cells\" for heredity. The function of the nucleus as carrier of genetic information became clear only later, after mitosis was discovered and the Mendelian rules were rediscovered at the beginning of the 20th century; the chromosome theory of heredity was therefore developed.\n\nThe nucleus is the largest cellular organelle in animal cells.\nIn mammalian cells, the average diameter of the nucleus is approximately 6 micrometres (µm), which occupies about 10% of the total cell volume. The viscous liquid within it is called nucleoplasm (or karyolymph), and is similar in composition to the cytosol found outside the nucleus. It appears as a dense, roughly spherical or irregular organelle. The composition by dry weight of the nucleus is approximately: DNA 9%, RNA 1%, Histone Protein 11%, Residual Protein 14%, Acidic Proteins 65%.\n\nThe nuclear envelope, otherwise known as nuclear membrane, consists of two cellular membranes, an inner and an outer membrane, arranged parallel to one another and separated by 10 to 50 nanometres (nm). The nuclear envelope completely encloses the nucleus and separates the cell's genetic material from the surrounding cytoplasm, serving as a barrier to prevent macromolecules from diffusing freely between the nucleoplasm and the cytoplasm. The outer nuclear membrane is continuous with the membrane of the rough endoplasmic reticulum (RER), and is similarly studded with ribosomes. The space between the membranes is called the perinuclear space and is continuous with the RER lumen.\n\nNuclear pores, which provide aqueous channels through the envelope, are composed of multiple proteins, collectively referred to as nucleoporins. The pores are about 125 million daltons in molecular weight and consist of around 50 (in yeast) to several hundred proteins (in vertebrates). The pores are 100 nm in total diameter; however, the gap through which molecules freely diffuse is only about 9 nm wide, due to the presence of regulatory systems within the center of the pore. This size selectively allows the passage of small water-soluble molecules while preventing larger molecules, such as nucleic acids and larger proteins, from inappropriately entering or exiting the nucleus. These large molecules must be actively transported into the nucleus instead. The nucleus of a typical mammalian cell will have about 3000 to 4000 pores throughout its envelope, each of which contains an eightfold-symmetric ring-shaped structure at a position where the inner and outer membranes fuse. Attached to the ring is a structure called the \"nuclear basket\" that extends into the nucleoplasm, and a series of filamentous extensions that reach into the cytoplasm. Both structures serve to mediate binding to nuclear transport proteins.\n\nMost proteins, ribosomal subunits, and some DNAs are transported through the pore complexes in a process mediated by a family of transport factors known as karyopherins. Those karyopherins that mediate movement into the nucleus are also called importins, whereas those that mediate movement out of the nucleus are called exportins. Most karyopherins interact directly with their cargo, although some use adaptor proteins. Steroid hormones such as cortisol and aldosterone, as well as other small lipid-soluble molecules involved in intercellular signaling, can diffuse through the cell membrane and into the cytoplasm, where they bind nuclear receptor proteins that are trafficked into the nucleus. There they serve as transcription factors when bound to their ligand; in the absence of a ligand, many such receptors function as histone deacetylases that repress gene expression.\n\nIn animal cells, two networks of intermediate filaments provide the nucleus with mechanical support: The nuclear lamina forms an organized meshwork on the internal face of the envelope, while less organized support is provided on the cytosolic face of the envelope. Both systems provide structural support for the nuclear envelope and anchoring sites for chromosomes and nuclear pores.\n\nThe nuclear lamina is composed mostly of lamin proteins. Like all proteins, lamins are synthesized in the cytoplasm and later transported to the nucleus interior, where they are assembled before being incorporated into the existing network of nuclear lamina. Lamins found on the cytosolic face of the membrane, such as emerin and nesprin, bind to the cytoskeleton to provide structural support. Lamins are also found inside the nucleoplasm where they form another regular structure, known as the \"nucleoplasmic veil\", that is visible using fluorescence microscopy. The actual function of the veil is not clear, although it is excluded from the nucleolus and is present during interphase. Lamin structures that make up the veil, such as LEM3, bind chromatin and disrupting their structure inhibits transcription of protein-coding genes.\n\nLike the components of other intermediate filaments, the lamin monomer contains an alpha-helical domain used by two monomers to coil around each other, forming a dimer structure called a coiled coil. Two of these dimer structures then join side by side, in an antiparallel arrangement, to form a tetramer called a \"protofilament\". Eight of these protofilaments form a lateral arrangement that is twisted to form a ropelike \"filament\". These filaments can be assembled or disassembled in a dynamic manner, meaning that changes in the length of the filament depend on the competing rates of filament addition and removal.\n\nMutations in lamin genes leading to defects in filament assembly cause a group of rare genetic disorders known as \"laminopathies\". The most notable laminopathy is the family of diseases known as progeria, which causes the appearance of premature aging in its sufferers. The exact mechanism by which the associated biochemical changes give rise to the aged phenotype is not well understood.\n\nThe cell nucleus contains the majority of the cell's genetic material in the form of multiple linear DNA molecules organized into structures called chromosomes. Each human cell contains roughly two meters of DNA. During most of the cell cycle these are organized in a DNA-protein complex known as chromatin, and during cell division the chromatin can be seen to form the well-defined chromosomes familiar from a karyotype. A small fraction of the cell's genes are located instead in the mitochondria.\n\nThere are two types of chromatin. Euchromatin is the less compact DNA form, and contains genes that are frequently expressed by the cell. The other type, heterochromatin, is the more compact form, and contains DNA that is infrequently transcribed. This structure is further categorized into \"facultative\" heterochromatin, consisting of genes that are organized as heterochromatin only in certain cell types or at certain stages of development, and \"constitutive\" heterochromatin that consists of chromosome structural components such as telomeres and centromeres. During interphase the chromatin organizes itself into discrete individual patches, called \"chromosome territories\". Active genes, which are generally found in the euchromatic region of the chromosome, tend to be located towards the chromosome's territory boundary.\n\nAntibodies to certain types of chromatin organization, in particular, nucleosomes, have been associated with a number of autoimmune diseases, such as systemic lupus erythematosus. These are known as anti-nuclear antibodies (ANA) and have also been observed in concert with multiple sclerosis as part of general immune system dysfunction. As in the case of progeria, the role played by the antibodies in inducing the symptoms of autoimmune diseases is not obvious.\n\nThe nucleolus is a discrete densely stained structure found in the nucleus. It is not surrounded by a membrane, and is sometimes called a \"suborganelle\". It forms around tandem repeats of rDNA, DNA coding for ribosomal RNA (rRNA). These regions are called nucleolar organizer regions (NOR). The main roles of the nucleolus are to synthesize rRNA and assemble ribosomes. The structural cohesion of the nucleolus depends on its activity, as ribosomal assembly in the nucleolus results in the transient association of nucleolar components, facilitating further ribosomal assembly, and hence further association. This model is supported by observations that inactivation of rDNA results in intermingling of nucleolar structures.\n\nIn the first step of ribosome assembly, a protein called RNA polymerase I transcribes rDNA, which forms a large pre-rRNA precursor. This is cleaved into the subunits 5.8S, 18S, and 28S rRNA. The transcription, post-transcriptional processing, and assembly of rRNA occurs in the nucleolus, aided by small nucleolar RNA (snoRNA) molecules, some of which are derived from spliced introns from messenger RNAs encoding genes related to ribosomal function. The assembled ribosomal subunits are the largest structures passed through the nuclear pores.\n\nWhen observed under the electron microscope, the nucleolus can be seen to consist of three distinguishable regions: the innermost \"fibrillar centers\" (FCs), surrounded by the \"dense fibrillar component\" (DFC), which in turn is bordered by the \"granular component\" (GC). Transcription of the rDNA occurs either in the FC or at the FC-DFC boundary, and, therefore, when rDNA transcription in the cell is increased, more FCs are detected. Most of the cleavage and modification of rRNAs occurs in the DFC, while the latter steps involving protein assembly onto the ribosomal subunits occur in the GC.\n\nBesides the nucleolus, the nucleus contains a number of other non-membrane-delineated bodies. These include Cajal bodies, Gemini of coiled bodies, polymorphic interphase karyosomal association (PIKA), promyelocytic leukaemia (PML) bodies, paraspeckles, and splicing speckles. Although little is known about a number of these domains, they are significant in that they show that the nucleoplasm is not a uniform mixture, but rather contains organized functional subdomains.\n\nOther subnuclear structures appear as part of abnormal disease processes. For example, the presence of small intranuclear rods has been reported in some cases of nemaline myopathy. This condition typically results from mutations in actin, and the rods themselves consist of mutant actin as well as other cytoskeletal proteins.\n\nA nucleus typically contains between 1 and 10 compact structures called Cajal bodies or coiled bodies (CB), whose diameter measures between 0.2 µm and 2.0 µm depending on the cell type and species. When seen under an electron microscope, they resemble balls of tangled thread and are dense foci of distribution for the protein coilin. CBs are involved in a number of different roles relating to RNA processing, specifically small nucleolar RNA (snoRNA) and small nuclear RNA (snRNA) maturation, and histone mRNA modification.\n\nSimilar to Cajal bodies are Gemini of Cajal bodies, or gems, whose name is derived from the Gemini constellation in reference to their close \"twin\" relationship with CBs. Gems are similar in size and shape to CBs, and in fact are virtually indistinguishable under the microscope. Unlike CBs, gems do not contain small nuclear ribonucleoproteins (snRNPs), but do contain a protein called survival of motor neuron (SMN) whose function relates to snRNP biogenesis. Gems are believed to assist CBs in snRNP biogenesis, though it has also been suggested from microscopy evidence that CBs and gems are different manifestations of the same structure. Later ultrastructural studies have shown gems to be twins of Cajal bodies with the difference being in the coilin component; Cajal bodies are SMN positive and coilin positive, and gems are SMN positive and coilin negative.\n\nRAFA domains, or polymorphic interphase karyosomal associations, were first described in microscopy studies in 1991. Their function remains unclear, though they were not thought to be associated with active DNA replication, transcription, or RNA processing. They have been found to often associate with discrete domains defined by dense localization of the transcription factor PTF, which promotes transcription of small nuclear RNA (snRNA).\n\nPromyelocytic leukaemia bodies (PML bodies) are spherical bodies found scattered throughout the nucleoplasm, measuring around 0.1–1.0 µm. They are known by a number of other names, including nuclear domain 10 (ND10), Kremer bodies, and PML oncogenic domains. PML bodies are named after one of their major components, the promyelocytic leukemia protein (PML). They are often seen in the nucleus in association with Cajal bodies and cleavage bodies. PML bodies belong to the nuclear matrix, an ill-defined super-structure of the nucleus proposed to anchor and regulate many nuclear functions, including DNA replication, transcription, or epigenetic silencing. The PML protein is the key organizer of these domains that recruits an ever-growing number of proteins, whose only common known feature to date is their ability to be SUMOylated. Yet, pml-/- mice (which have their PML gene deleted) cannot assemble nuclear bodies, develop normally and live well, demonstrating that PML bodies are dispensable for most basic biological functions.\n\nSpeckles are subnuclear structures that are enriched in pre-messenger RNA splicing factors and are located in the interchromatin regions of the nucleoplasm of mammalian cells. At the fluorescence-microscope level they appear as irregular, punctate structures, which vary in size and shape, and when examined by electron microscopy they are seen as clusters of interchromatin granules. Speckles are dynamic structures, and both their protein and RNA-protein components can cycle continuously between speckles and other nuclear locations, including active transcription sites. Studies on the composition, structure and behaviour of speckles have provided a model for understanding the functional compartmentalization of the nucleus and the organization of the gene-expression machinery\nsplicing snRNPs and other splicing proteins necessary for pre-mRNA processing. Because of a cell's changing requirements, the composition and location of these bodies changes according to mRNA transcription and regulation via phosphorylation of specific proteins.\nThe splicing speckles are also known as nuclear speckles (nuclear specks), splicing factor compartments (SF compartments), interchromatin granule clusters (IGCs), B snurposomes.\nB snurposomes are found in the amphibian oocyte nuclei and in \"Drosophila melanogaster\" embryos. B snurposomes appear alone or attached to the Cajal bodies in the electron micrographs of the amphibian nuclei.\nIGCs function as storage sites for the splicing factors.\n\nDiscovered by Fox et al. in 2002, paraspeckles are irregularly shaped compartments in the nucleus' interchromatin space. First documented in HeLa cells, where there are generally 10–30 per nucleus, paraspeckles are now known to also exist in all human primary cells, transformed cell lines, and tissue sections. Their name is derived from their distribution in the nucleus; the \"para\" is short for parallel and the \"speckles\" refers to the splicing speckles to which they are always in close proximity.\n\nParaspeckles are dynamic structures that are altered in response to changes in cellular metabolic activity. They are transcription dependent and in the absence of RNA Pol II transcription, the paraspeckle disappears and all of its associated protein components (PSP1, p54nrb, PSP2, CFI(m)68, and PSF) form a crescent shaped perinucleolar cap in the nucleolus. This phenomenon is demonstrated during the cell cycle. In the cell cycle, paraspeckles are present during interphase and during all of mitosis except for telophase. During telophase, when the two daughter nuclei are formed, there is no RNA Pol II transcription so the protein components instead form a perinucleolar cap.\n\nPerichromatin fibrils are visible only under electron microscope. They are located next to the transcriptionally active chromatin and are hypothesized to be the sites of active pre-mRNA processing.\n\nThe nucleus provides a site for genetic transcription that is segregated from the location of translation in the cytoplasm, allowing levels of gene regulation that are not available to prokaryotes. The main function of the cell nucleus is to control gene expression and mediate the replication of DNA during the cell cycle.\n\nThe nucleus is an organelle found in eukaryotic cells. Inside its fully enclosed nuclear membrane, it contains the majority of the cell's genetic material. This material is organized as DNA molecules, along with a variety of proteins, to form chromosomes.\n\nThe nuclear envelope allows the nucleus to control its contents, and separate them from the rest of the cytoplasm where necessary. This is important for controlling processes on either side of the nuclear membrane. In most cases where a cytoplasmic process needs to be restricted, a key participant is removed to the nucleus, where it interacts with transcription factors to downregulate the production of certain enzymes in the pathway. This regulatory mechanism occurs in the case of glycolysis, a cellular pathway for breaking down glucose to produce energy. Hexokinase is an enzyme responsible for the first the step of glycolysis, forming glucose-6-phosphate from glucose. At high concentrations of fructose-6-phosphate, a molecule made later from glucose-6-phosphate, a regulator protein removes hexokinase to the nucleus, where it forms a transcriptional repressor complex with nuclear proteins to reduce the expression of genes involved in glycolysis.\n\nIn order to control which genes are being transcribed, the cell separates some transcription factor proteins responsible for regulating gene expression from physical access to the DNA until they are activated by other signaling pathways. This prevents even low levels of inappropriate gene expression. For example, in the case of NF-κB-controlled genes, which are involved in most inflammatory responses, transcription is induced in response to a signal pathway such as that initiated by the signaling molecule TNF-α, binds to a cell membrane receptor, resulting in the recruitment of signalling proteins, and eventually activating the transcription factor NF-κB. A nuclear localisation signal on the NF-κB protein allows it to be transported through the nuclear pore and into the nucleus, where it stimulates the transcription of the target genes.\n\nThe compartmentalization allows the cell to prevent translation of unspliced mRNA. Eukaryotic mRNA contains introns that must be removed before being translated to produce functional proteins. The splicing is done inside the nucleus before the mRNA can be accessed by ribosomes for translation. Without the nucleus, ribosomes would translate newly transcribed (unprocessed) mRNA, resulting in malformed and nonfunctional proteins.\n\nGene expression first involves transcription, in which DNA is used as a template to produce RNA. In the case of genes encoding proteins, that RNA produced from this process is messenger RNA (mRNA), which then needs to be translated by ribosomes to form a protein. As ribosomes are located outside the nucleus, mRNA produced needs to be exported.\n\nSince the nucleus is the site of transcription, it also contains a variety of proteins that either directly mediate transcription or are involved in regulating the process. These proteins include helicases, which unwind the double-stranded DNA molecule to facilitate access to it, RNA polymerases, which bind to the DNA promoter to synthesize the growing RNA molecule, topoisomerases, which change the amount of supercoiling in DNA, helping it wind and unwind, as well as a large variety of transcription factors that regulate expression.\n\nNewly synthesized mRNA molecules are known as primary transcripts or pre-mRNA. They must undergo post-transcriptional modification in the nucleus before being exported to the cytoplasm; mRNA that appears in the cytoplasm without these modifications is degraded rather than used for protein translation. The three main modifications are 5' capping, 3' polyadenylation, and RNA splicing. While in the nucleus, pre-mRNA is associated with a variety of proteins in complexes known as heterogeneous ribonucleoprotein particles (hnRNPs). Addition of the 5' cap occurs co-transcriptionally and is the first step in post-transcriptional modification. The 3' poly-adenine tail is only added after transcription is complete.\n\nRNA splicing, carried out by a complex called the spliceosome, is the process by which introns, or regions of DNA that do not code for protein, are removed from the pre-mRNA and the remaining exons connected to re-form a single continuous molecule. This process normally occurs after 5' capping and 3' polyadenylation but can begin before synthesis is complete in transcripts with many exons. Many pre-mRNAs, including those encoding antibodies, can be spliced in multiple ways to produce different mature mRNAs that encode different protein sequences. This process is known as alternative splicing, and allows production of a large variety of proteins from a limited amount of DNA.\n\nThe entry and exit of large molecules from the nucleus is tightly controlled by the nuclear pore complexes. Although small molecules can enter the nucleus without regulation, macromolecules such as RNA and proteins require association karyopherins called importins to enter the nucleus and exportins to exit. \"Cargo\" proteins that must be translocated from the cytoplasm to the nucleus contain short amino acid sequences known as nuclear localization signals, which are bound by importins, while those transported from the nucleus to the cytoplasm carry nuclear export signals bound by exportins. The ability of importins and exportins to transport their cargo is regulated by GTPases, enzymes that hydrolyze the molecule guanosine triphosphate to release energy. The key GTPase in nuclear transport is Ran, which can bind either GTP or GDP (guanosine diphosphate), depending on whether it is located in the nucleus or the cytoplasm. Whereas importins depend on RanGTP to dissociate from their cargo, exportins require RanGTP in order to bind to their cargo.\n\nNuclear import depends on the importin binding its cargo in the cytoplasm and carrying it through the nuclear pore into the nucleus. Inside the nucleus, RanGTP acts to separate the cargo from the importin, allowing the importin to exit the nucleus and be reused. Nuclear export is similar, as the exportin binds the cargo inside the nucleus in a process facilitated by RanGTP, exits through the nuclear pore, and separates from its cargo in the cytoplasm.\n\nSpecialized export proteins exist for translocation of mature mRNA and tRNA to the cytoplasm after post-transcriptional modification is complete. This quality-control mechanism is important due to these molecules' central role in protein translation. Mis-expression of a protein due to incomplete excision of exons or mis-incorporation of amino acids could have negative consequences for the cell; thus, incompletely modified RNA that reaches the cytoplasm is degraded rather than used in translation.\n\nDuring its lifetime, a nucleus may be broken down or destroyed, either in the process of cell division or as a consequence of apoptosis (the process of programmed cell death). During these events, the structural components of the nucleus — the envelope and lamina — can be systematically degraded.\nIn most cells, the disassembly of the nuclear envelope marks the end of the prophase of mitosis. However, this disassembly of the nucleus is not a universal feature of mitosis and does not occur in all cells. Some unicellular eukaryotes (e.g., yeasts) undergo so-called closed mitosis, in which the nuclear envelope remains intact. In closed mitosis, the daughter chromosomes migrate to opposite poles of the nucleus, which then divides in two. The cells of higher eukaryotes, however, usually undergo open mitosis, which is characterized by breakdown of the nuclear envelope. The daughter chromosomes then migrate to opposite poles of the mitotic spindle, and new nuclei reassemble around them.\n\nAt a certain point during the cell cycle in open mitosis, the cell divides to form two cells. In order for this process to be possible, each of the new daughter cells must have a full set of genes, a process requiring replication of the chromosomes as well as segregation of the separate sets. This occurs by the replicated chromosomes, the sister chromatids, attaching to microtubules, which in turn are attached to different centrosomes. The sister chromatids can then be pulled to separate locations in the cell. In many cells, the centrosome is located in the cytoplasm, outside the nucleus; the microtubules would be unable to attach to the chromatids in the presence of the nuclear envelope. Therefore, the early stages in the cell cycle, beginning in prophase and until around prometaphase, the nuclear membrane is dismantled. Likewise, during the same period, the nuclear lamina is also disassembled, a process regulated by phosphorylation of the lamins by protein kinases such as the CDC2 protein kinase. Towards the end of the cell cycle, the nuclear membrane is reformed, and around the same time, the nuclear lamina are reassembled by dephosphorylating the lamins.\n\nHowever, in dinoflagellates, the nuclear envelope remains intact, the centrosomes are located in the cytoplasm, and the microtubules come in contact with chromosomes, whose centromeric regions are incorporated into the nuclear envelope (the so-called closed mitosis with extranuclear spindle). In many other protists (e.g., ciliates, sporozoans) and fungi, the centrosomes are intranuclear, and their nuclear envelope also does not disassemble during cell division.\n\nApoptosis is a controlled process in which the cell's structural components are destroyed, resulting in death of the cell. Changes associated with apoptosis directly affect the nucleus and its contents, for example, in the condensation of chromatin and the disintegration of the nuclear envelope and lamina. The destruction of the lamin networks is controlled by specialized apoptotic proteases called caspases, which cleave the lamin proteins and, thus, degrade the nucleus' structural integrity. Lamin cleavage is sometimes used as a laboratory indicator of caspase activity in assays for early apoptotic activity. Cells that express mutant caspase-resistant lamins are deficient in nuclear changes related to apoptosis, suggesting that lamins play a role in initiating the events that lead to apoptotic degradation of the nucleus. Inhibition of lamin assembly itself is an inducer of apoptosis.\n\nThe nuclear envelope acts as a barrier that prevents both DNA and RNA viruses from entering the nucleus. Some viruses require access to proteins inside the nucleus in order to replicate and/or assemble. DNA viruses, such as herpesvirus replicate and assemble in the cell nucleus, and exit by budding through the inner nuclear membrane. This process is accompanied by disassembly of the lamina on the nuclear face of the inner membrane.\n\nInitially, it has been suspected that immunoglobulins in general and autoantibodies in particular do not enter the nucleus. Now there is a body of evidence that under pathological conditions (e.g. lupus erythematosus) IgG can enter the nucleus.\n\nMost eukaryotic cell types usually have a single nucleus, but some have no nuclei, while others have several. This can result from normal development, as in the maturation of mammalian red blood cells, or from faulty cell division.\n\nAn anucleated cell contains no nucleus and is, therefore, incapable of dividing to produce daughter cells. The best-known anucleated cell is the mammalian red blood cell, or erythrocyte, which also lacks other organelles such as mitochondria, and serves primarily as a transport vessel to ferry oxygen from the lungs to the body's tissues. Erythrocytes mature through erythropoiesis in the bone marrow, where they lose their nuclei, organelles, and ribosomes. The nucleus is expelled during the process of differentiation from an erythroblast to a reticulocyte, which is the immediate precursor of the mature erythrocyte. The presence of mutagens may induce the release of some immature \"micronucleated\" erythrocytes into the bloodstream. Anucleated cells can also arise from flawed cell division in which one daughter lacks a nucleus and the other has two nuclei.\n\nIn flowering plants, this condition occurs in sieve tube elements.\n\nMultinucleated cells contain multiple nuclei. Most acantharean species of protozoa and some fungi in mycorrhizae have naturally multinucleated cells. Other examples include the intestinal parasites in the genus \"Giardia\", which have two nuclei per cell. In humans, skeletal muscle cells, called myocytes and syncytium, become multinucleated during development; the resulting arrangement of nuclei near the periphery of the cells allows maximal intracellular space for myofibrils. Multinucleated and binucleated cells can also be abnormal in humans; for example, cells arising from the fusion of monocytes and macrophages, known as giant multinucleated cells, sometimes accompany inflammation and are also implicated in tumor formation.\n\nA number of dinoflagellates are known to have two nuclei. Unlike other multinucleated cells these nuclei contain two distinct lineages of DNA: one from the dinoflagellate and the other from a symbiotic diatom. The mitochondria and the plastids of the diatom somehow remain functional.\n\nAs the major defining characteristic of the eukaryotic cell, the nucleus' evolutionary origin has been the subject of much speculation. Four major hypotheses have been proposed to explain the existence of the nucleus, although none have yet earned widespread support.\n\nThe first model known as the \"syntrophic model\" proposes that a symbiotic relationship between the archaea and bacteria created the nucleus-containing eukaryotic cell. (Organisms of the Archaea and Bacteria domain have no cell nucleus.) It is hypothesized that the symbiosis originated when ancient archaea, similar to modern methanogenic archaea, invaded and lived within bacteria similar to modern myxobacteria, eventually forming the early nucleus. This theory is analogous to the accepted theory for the origin of eukaryotic mitochondria and chloroplasts, which are thought to have developed from a similar endosymbiotic relationship between proto-eukaryotes and aerobic bacteria. The archaeal origin of the nucleus is supported by observations that archaea and eukarya have similar genes for certain proteins, including histones. Observations that myxobacteria are motile, can form multicellular complexes, and possess kinases and G proteins similar to eukarya, support a bacterial origin for the eukaryotic cell.\n\nA second model proposes that proto-eukaryotic cells evolved from bacteria without an endosymbiotic stage. This model is based on the existence of modern planctomycetes bacteria that possess a nuclear structure with primitive pores and other compartmentalized membrane structures. A similar proposal states that a eukaryote-like cell, the chronocyte, evolved first and phagocytosed archaea and bacteria to generate the nucleus and the eukaryotic cell.\n\nThe most controversial model, known as \"viral eukaryogenesis\", posits that the membrane-bound nucleus, along with other eukaryotic features, originated from the infection of a prokaryote by a virus. The suggestion is based on similarities between eukaryotes and viruses such as linear DNA strands, mRNA capping, and tight binding to proteins (analogizing histones to viral envelopes). One version of the proposal suggests that the nucleus evolved in concert with phagocytosis to form an early cellular \"predator\". Another variant proposes that eukaryotes originated from early archaea infected by poxviruses, on the basis of observed similarity between the DNA polymerases in modern poxviruses and eukaryotes. It has been suggested that the unresolved question of the evolution of sex could be related to the viral eukaryogenesis hypothesis.\n\nA more recent proposal, the \"exomembrane hypothesis\", suggests that the nucleus instead originated from a single ancestral cell that evolved a second exterior cell membrane; the interior membrane enclosing the original cell then became the nuclear membrane and evolved increasingly elaborate pore structures for passage of internally synthesized cellular components such as ribosomal subunits.\n\n\n", "id": "6235", "title": "Cell nucleus"}
{"url": "https://en.wikipedia.org/wiki?curid=6237", "text": "Christmas\n\nChristmas or Christmas Day (, meaning \"Christ's Mass\") is an annual festival commemorating the birth of Jesus Christ, observed most commonly on December 25 as a religious and cultural celebration among billions of people around the world. A feast central to the Christian liturgical year, it is prepared for by the season of Advent or the Nativity Fast and initiates the season of Christmastide, which historically in the West lasts twelve days and culminates on Twelfth Night; in some traditions, Christmastide includes an Octave. The traditional Christmas narrative, the Nativity of Jesus, delineated in the New Testament says that Jesus was born in Bethlehem, in accordance with messianic prophecies; when Joseph and Mary arrived in the city, the inn had no room and so they were offered a stable where the Christ Child was soon born, with angels proclaiming this news to shepherds who then disseminated the message furthermore. Christmas Day is a public holiday in many of the world's nations, is celebrated religiously by the vast majority of Christians, as well as culturally by a number of non-Christian people, and is an integral part of the holiday season, while some Christian groups reject the celebration. In several countries, celebrating Christmas Eve on December 24 has the main focus rather than December 25, with gift-giving and sharing a traditional meal with the family.\n\nAlthough the month and date of Jesus' birth are unknown, by the early-to-mid fourth century the Western Christian Church had placed Christmas on December 25, a date that was later adopted in the East. Today, most Christians celebrate on December 25 in the Gregorian calendar, which has been adopted almost universally in the civil calendars used in countries throughout the world. However, some Eastern Christian Churches celebrate Christmas on December 25 of the older Julian calendar, which currently corresponds to January 7 in the Gregorian calendar, the day after the Western Christian Church celebrates the Epiphany. This is not a disagreement over the date of Christmas as such, but rather a preference of which calendar should be used to determine the day that is December 25. In the Council of Tours of 567, the Church, with its desire to be universal, \"declared the twelve days between Christmas and Epiphany to be one unified festal cycle\", thus giving significance to both the Western and Eastern dates of Christmas. Moreover, for Christians, the belief that God came into the world in the form of man to atone for the sins of humanity, rather than the exact birth date, is considered to be the primary purpose in celebrating Christmas.\n\nAlthough it is not known why December 25 became a date of celebration, there are several factors that may have influenced the choice. December 25 was the date the Romans marked as the winter solstice, the shortest, and therefore darkest day of the year. Jesus was identified with the Sun based on an Old Testament verse. The date is exactly nine months following Annunciation, when the conception of Jesus is celebrated. Finally, the Romans had a series of pagan festivals near the end of the year, so Christmas may have been scheduled at this time to appropriate, or compete with, one or more of these festivals. Other scholars disagree with this claim and state that the Roman Emperor Aurelian placed a pagan celebration on December 25 in order to compete with the growing rate of the Christian Church, which had already been celebrating Christmas on that date.\n\nThe celebratory customs associated in various countries with Christmas have a mix of pre-Christian, Christian, and secular themes and origins. Popular modern customs of the holiday include gift giving, completing an Advent calendar or Advent wreath, Christmas music and caroling, lighting a Christingle, viewing a Nativity play, an exchange of Christmas cards, church services, a special meal, and the display of various Christmas decorations, including Christmas trees, Christmas lights, nativity scenes, garlands, wreaths, mistletoe, and holly. In addition, several closely related and often interchangeable figures, known as Santa Claus, Father Christmas, Saint Nicholas, and Christkind, are associated with bringing gifts to children during the Christmas season and have their own body of traditions and lore. Because gift-giving and many other aspects of the Christmas festival involve heightened economic activity, the holiday has become a significant event and a key sales period for retailers and businesses. The economic impact of Christmas has grown steadily over the past few centuries in many regions of the world.\n\n\"Christmas\" is a shortened form of \"Christ's mass\". It is derived from the Middle English \"Cristemasse\", which is from Old English \"Crīstesmæsse\", a phrase first recorded in 1038 followed by the word \"Cristes-messe\" in 1131. \"Crīst\" (genitive \"Crīstes\") is from Greek \"Khrīstos\" (Χριστός), a translation of Hebrew \"Māšîaḥ\" (מָשִׁיחַ), \"Messiah\", meaning \"anointed\"; and \"mæsse\" is from Latin \"missa\", the celebration of the Eucharist. The form \"Christenmas\" was also historically used, but is now considered archaic and dialectal; it derives from Middle English \"Cristenmasse\", literally \"Christian mass\". \"Xmas\" is an abbreviation of \"Christmas\" found particularly in print, based on the initial letter chi (Χ) in Greek \"Khrīstos\" (Χριστός), \"Christ\", though numerous style guides discourage its use; it has precedent in Middle English \"Χρ̄es masse\" (where \"Χρ̄\" is an abbreviation for Χριστός).\n\nIn addition to \"Christmas\", the holiday has been known by various other names throughout its history. The Anglo-Saxons referred to the feast as \"midwinter\", or, more rarely, as \"Nātiuiteð\" (from Latin \"nātīvitās\" below). \"Nativity\", meaning \"birth\", is from Latin \"nātīvitās\". In Old English, \"Gēola\" (\"Yule\") referred to the period corresponding to December and January, which was eventually equated with Christian Christmas. \"Noel\" (or \"Nowel\") entered English in the late 14th century and is from the Old French \"noël\" or \"naël\", itself ultimately from the Latin \"nātālis (diēs)\", \"birth (day)\".\n\nThe canonical gospels of Luke and Matthew both describe Jesus as being born in Bethlehem in Judea, to a virgin mother. In the Gospel of Luke account, Joseph and Mary travel from Nazareth to Bethlehem for the census, and Jesus is born there and laid in a manger. It says that angels proclaimed him a savior for all people, and shepherds came to adore him. In the Matthew account, magi follow a star to Bethlehem to bring gifts to Jesus, born the king of the Jews. King Herod orders the massacre of all the boys less than two years old in Bethlehem, but the family flees to Egypt and later settles in Nazareth.\n\nThe Nativity stories of Matthew and Luke are prominent in the gospels and early Christian writers suggested various dates for the anniversary. The first recorded Christmas celebration was in Rome in 336. Christmas played a role in the Arian controversy of the fourth century, but was overshadowed by Epiphany in the early Middle Ages. The feast regained prominence after 800, when Charlemagne was crowned emperor on Christmas Day. Associating it with drunkenness and other misbehavior, the Puritans banned Christmas. It was restored as a legal holiday in 1660, but remained disreputable. In the early 19th century, Christmas was revived with the start of the Oxford Movement in the Anglican Church, which ushered in \"the development of richer and more symbolic forms of worship, the building of neo-Gothic churches, and the revival and increasing centrality of the keeping of Christmas itself as a Christian festival\" as well as \"special charities for the poor\" in addition to \"special services and musical events\". Charles Dickens and other writers helped in this revival of the holiday by \"changing consciousness of Christmas and the way in which it was celebrated\" as they emphasized family, religion, gift-giving, and social reconciliation as opposed to the historic revelry common in some places.\n\nThe early church was concerned with the death, resurrection and life of Christ. They essentially ignored the birth of Christ until Docetism and Gnostics asserted that Christ did not have a physical body. To assist in combating what the church considered heresy, the Roman church established a date to celebrate Christ's birth, sometime in the 4th century. Other Christian churches had done so or would do within a century. The church's assertion of a physical body was also supported by the celebration of the Epiphany, established around the same time.\n\nIn the 3rd century, the date of birth of Jesus was the subject of both great interest and great uncertainly. Around AD 200, Clement of Alexandria wrote:\n\nIn other writing of this time, May 20, April 18 or 19, March 25, January 2, November 17, and November 20 are all suggested. Various factors contributed to the selection of December 25 as a date of celebration: it was the date of the winter solstice on the Roman calendar; it was about nine months after March 25, the date of the vernal equinox and a date linked to the conception of Jesus; and it was the date of a Roman pagan festival in honor of the Sun god Sol Invictus.\n\nDecember 25 was the date of the winter solstice on the Roman calendar. Jesus chose to be born on the shortest day of the year for symbolic reasons, according to an early sermon by Augustine: \"Hence it is that He was born on the day which is the shortest in our earthly reckoning and from which subsequent days begin to increase in length. He, therefore, who bent low and lifted us up chose the shortest day, yet the one whence light begins to increase.\"\n\nLinking Jesus to the Sun was supported by various Biblical passages. Jesus was considered to be the \"Sun of righteousness\" prophesied by Malachi. John describes him as \"the light of the world.\"\n\nSuch solar symbolism could support more than one date of birth. An anonymous work known as \"De Pascha Computus\" (243) linked the idea that creation began at the spring equinox, on March 25, with the conception or birth (the word \"nascor\" can mean either) of Jesus on March 28, the day of the creation of the sun in the Genesis account. One translation reads: \"O the splendid and divine providence of the Lord, that on that day, the very day, on which the sun was made, the 28 March, a Wednesday, Christ should be born. For this reason Malachi the prophet, speaking about him to the people, fittingly said, 'Unto you shall the sun of righteousness arise, and healing is in his wings.'\"\n\nIn the 17th century, Isaac Newton argued that the date of Christmas was selected to correspond with the solstice.\n\nAccording to Steven Hijmans of the University of Alberta, \"It is cosmic symbolism ... which inspired the Church leadership in Rome to elect the southern solstice, December 25, as the birthday of Christ, and the northern solstice as that of John the Baptist, supplemented by the equinoxes as their respective dates of conception.\"\n\nThe Calculation hypothesis suggests that an earlier holiday held on March 25 became associated with the Incarnation. Modern scholars refer to this feast as the Quartodecimal. Christmas was then calculated as nine months later. The Calculation hypothesis was proposed by French writer Louis Duchesne in 1889.\n\nIn modern times, March 25 is celebrated as Annunciation. This holiday was created in the seventh century and was assigned to a date that is nine months before Christmas, in addition to being the traditional date of the equinox. It is unrelated to the Quartodecimal, which had been forgotten by this time.\n\nEarly Christians celebrated the life of Jesus on a date considered equivalent to 14 Nisan (Passover) on the local calendar. Because Passover was held on the 14th of the month, this feast is referred to as the Quartodecimal. All the major events of Christ's life, especially the passion, were celebrated on this date. In his letter to the Corinthians, Paul mentions Passover, presumably celebrated according to the local calendar in Corinth. Tertullian (d. 220), who lived in Latin-speaking North Africa, gives the date of passion celebration as March 25. The date of the passion was moved to Good Friday in 165 when Pope Soter created Easter by reassigning the Resurrection to a Sunday. According to the Calculation hypothesis, celebration of the quartodecimal continued in some areas and the feast became associated with Incarnation.\n\nThe Calculation hypothesis is considered academically to be \"a thoroughly viable hypothesis\", though not certain. It was a traditional Jewish belief that great men lived a whole number of years, without fractions, so that Jesus was considered to have been conceived on March 25, as he died on March 25, which was calculated to have coincided with 14 Nisan.\n\nA passage in \"Commentary on the Prophet Daniel\" (204) by Hippolytus of Rome identifies December 25 as the date of the nativity. This passage is generally considered a late interpellation. The manuscript includes another passage, one that is more likely to be authentic, that gives the passion as March 25.\n\nIn 221, Sextus Julius Africanus (c. 160 – c. 240) gave March 25 as the day of creation and of the conception of Jesus in his universal history. This conclusion was based on solar symbolism, with March 25 the date of the equinox. As this implies a birth in December, it is sometimes claimed to be the earliest identification of December 25 as the nativity. However, Africanus was not such an influential writer that it is likely he determined the date of Christmas.\n\nThe tractate \"De solstitia et aequinoctia conceptionis et nativitatis Domini nostri Iesu Christi et Iohannis Baptistae,\" falsely attributed to John Chrysostom, also argued that Jesus was conceived and crucified on the same day of the year and calculated this as March 25. This anonymous tract also states: \"But Our Lord, too, is born in the month of December ... the eight before the calends of January [25 December] ..., But they call it the 'Birthday of the Unconquered'. Who indeed is so unconquered as Our Lord...? Or, if they say that it is the birthday of the Sun, He is the Sun of Justice.\"\n\nThe rival \"History of Religions\" hypothesis suggests that the Church selected December 25 date to appropriate festivities held by the Romans in honor of the Sun god Sol Invictus. This feast was established by Aurelian in 274.\n\nAn explicit expression of this theory appears in an annotation of uncertain date added to a manuscript of a work by 12th-century Syrian bishop Jacob Bar-Salibi. The scribe who added it wrote: \"It was a custom of the Pagans to celebrate on the same 25 December the birthday of the Sun, at which they kindled lights in token of festivity. In these solemnities and revelries the Christians also took part. Accordingly when the doctors of the Church perceived that the Christians had a leaning to this festival, they took counsel and resolved that the true Nativity should be solemnised on that day.\" \n\nIn 1743, German Protestant Paul Ernst Jablonski argued Christmas was placed on December 25 to correspond with the Roman solar holiday \"Dies Natalis Solis Invicti\" and was therefore a \"paganization\" that debased the true church. It has been argued that, on the contrary, the Emperor Aurelian, who in 274 instituted the holiday of the \"Dies Natalis Solis Invicti\", did so partly as an attempt to give a pagan significance to a date already important for Christians in Rome.\n\nHermann Usener and others proposed that the Christians chose this day because it was the Roman feast celebrating the birthday of Sol Invictus. Modern scholar S. E. Hijmans, however, states that \"While they were aware that pagans called this day the 'birthday' of Sol Invictus, this did not concern them and it did not play any role in their choice of date for Christmas.\" Moreover, Thomas J. Talley holds that the Roman Emperor Aurelian placed a Sol Invictus on December 25 in order to compete with the growing rate of the Christian Church, which had already been celebrating Christmas on that date first.\n\nIn the judgement of the Church of England Liturgical Commission, the History of Religions hypothesis has been challenged by a view based on an old tradition, according to which the date of Christmas was fixed at nine months after , the date of the vernal equinox, on which the Annunciation was celebrated.\n\nWith regard to a December religious feast of the sun as a god (Sol), as distinct from a solstice feast of the (re)birth of the astronomical sun, one scholar has commented that, \"while the winter solstice on or around December 25 was well established in the Roman imperial calendar, there is no evidence that a religious celebration of Sol on that day antedated the celebration of Christmas\". \"Thomas Talley has shown that, although the Emperor Aurelian's dedication of a temple to the sun god in the Campus Martius (C.E. 274) probably took place on the 'Birthday of the Invincible Sun' on December 25, the cult of the sun in pagan Rome ironically did not celebrate the winter solstice nor any of the other quarter-tense days, as one might expect.\" The \"Oxford Companion to Christian Thought\" remarks on the uncertainty about the order of precedence between the religious celebrations of the Birthday of the Unconquered Sun and of the birthday of Jesus, stating that the hypothesis that December 25 was chosen for celebrating the birth of Jesus on the basis of the belief that his conception occurred on March 25 \"potentially establishes 25 December as a Christian festival before Aurelian's decree, which, when promulgated, might have provided for the Christian feast both opportunity and challenge\".\n\nAs Christmas was unknown to the early Christian writers, it must have been introduced sometime after 300. Irenaeus and Tertullian omit it from their lists of feasts, and Origen writes that in the Scriptures sinners alone, not saints, celebrate their birthday. Arnobius can still ridicule the \"birthdays\" of the gods. The first recorded Christmas celebration was in Rome in 336. The feast was introduced to the Eastern Roman Empire after the death of Emperor Valens, who favored the Arian heresy, in 378.\n\nIn 245, Origen of Alexandria, writing about , commented that Scripture mentions only sinners as \"celebrating\" their birthdays, namely Pharaoh, who then had his chief baker hanged (), and Herod, who then had John the Baptist beheaded (), and mentions saints as \"cursing\" the day of their birth, namely Jeremiah () and Job (). In 303, Arnobius ridiculed the idea of celebrating the birthdays of gods, a passage cited as evidence that Arnobius was unaware of any nativity celebration. Since Christmas does not celebrate Christ's birth \"as God\" but \"as man\", this does not necessarily show that Christmas was not a feast at this time.\n\nThe fact the Donatists of North Africa celebrated Christmas suggests that the feast was established by the time that church was created in 311. The earliest known Christmas celebration is recorded in a fourth-century manuscript compiled in Rome. This manuscript is thought to record a celebration that occurred in 336. It was prepared privately for Filocalus, a Roman aristocrat, in 354. The reference in question states, \"VIII kal. ian. natus Christus in Betleem Iudeæ\". This reference is in a section of the manuscript that was copied from earlier source material. The document also contains the earliest known reference to the feast of Sol Invictus.\n\nIn Eastern Christianity the birth of Jesus was already celebrated in connection with the Epiphany on January 6. Epiphany emphasized celebration of the baptism of Jesus. December 25 celebration was imported into the East later: in Antioch by John Chrysostom towards the end of the fourth century, probably in 388, and in Alexandria only in the following century. Even in the West, January 6 celebration of the nativity of Jesus seems to have continued until after 380.\n\nIn the East, early Christians celebrated the birth of Christ as part of Epiphany (January 6), although Christmas was promoted in the Christian East as part of the revival of Nicene Christianity following the death of the pro-Arian Emperor Valens at the Battle of Adrianople in 378. The feast was introduced at Constantinople in 379, and at Antioch in about 380. The feast disappeared after Gregory of Nazianzus resigned as bishop in 381, although it was reintroduced by John Chrysostom in about 400.\n\nMany popular customs associated with Christmas developed independently of the commemoration of Jesus' birth, with certain elements having origins in pre-Christian festivals that were celebrated around the winter solstice by pagan populations who were later converted to Christianity. These elements, including the Yule log from Yule and gift giving from Saturnalia, became syncretized into Christmas over the centuries. The prevailing atmosphere of Christmas has also continually evolved since the holiday's inception, ranging from a sometimes raucous, drunken, carnival-like state in the Middle Ages, to a tamer family-oriented and children-centered theme introduced in a 19th-century transformation. Additionally, the celebration of Christmas was banned on more than one occasion within certain Protestant groups, such as the Puritans, due to concerns that it was too pagan or unbiblical. Jehovah's Witnesses also reject the celebration of Christmas.\n\nPrior to and through the early Christian centuries, winter festivals—especially those centered on the winter solstice—were the most popular of the year in many European pagan cultures. Reasons included the fact that less agricultural work needed to be done during the winter, as well as an expectation of better weather as spring approached. Many modern Christmas customs have been directly influenced by such festivals, including gift-giving and merrymaking from the Roman Saturnalia, greenery, lights, and charity from the Roman New Year, and Yule logs and various foods from Germanic feasts. The Egyptian deity Horus, son to goddess Isis, was celebrated at the winter solstice. Horus was often depicted being fed by his mother, which also influenced the symbolism of the Virgin Mary with baby Christ.\n\nThe pre-Christian Germanic peoples—including the Anglo-Saxons and the Norse—celebrated a winter festival called Yule, held in the late December to early January period, yielding modern English \"yule\", today used as a synonym for \"Christmas\". In Germanic language-speaking areas, numerous elements of modern Christmas folk custom and iconography stem from Yule, including the Yule log, Yule boar, and the Yule goat. Often leading a ghostly procession through the sky (the Wild Hunt), the long-bearded god Odin is referred to as \"the Yule one\" and \"Yule father\" in Old Norse texts, whereas the rest of the gods are referred to as \"Yule beings\".\n\nIn eastern Europe also, old pagan traditions were incorporated into Christmas celebrations, an example being the Koleda, which was incorporated into the Christmas carol.\n\nIn the Early Middle Ages, Christmas Day was overshadowed by Epiphany, which in western Christianity focused on the visit of the magi. But the medieval calendar was dominated by Christmas-related holidays. The forty days before Christmas became the \"forty days of St. Martin\" (which began on November 11, the feast of St. Martin of Tours), now known as Advent. In Italy, former Saturnalian traditions were attached to Advent. Around the 12th century, these traditions transferred again to the Twelve Days of Christmas (December 25 – January 5); a time that appears in the liturgical calendars as Christmastide or Twelve Holy Days.\n\nThe prominence of Christmas Day increased gradually after Charlemagne was crowned Emperor on Christmas Day in 800. King Edmund the Martyr was anointed on Christmas in 855 and King William I of England was crowned on Christmas Day 1066.\n\nBy the High Middle Ages, the holiday had become so prominent that chroniclers routinely noted where various magnates celebrated Christmas. King Richard II of England hosted a Christmas feast in 1377 at which twenty-eight oxen and three hundred sheep were eaten. The Yule boar was a common feature of medieval Christmas feasts. Caroling also became popular, and was originally a group of dancers who sang. The group was composed of a lead singer and a ring of dancers that provided the chorus. Various writers of the time condemned caroling as lewd, indicating that the unruly traditions of Saturnalia and Yule may have continued in this form. \"Misrule\"—drunkenness, promiscuity, gambling—was also an important aspect of the festival. In England, gifts were exchanged on New Year's Day, and there was special Christmas ale.\n\nChristmas during the Middle Ages was a public festival that incorporated ivy, holly, and other evergreens. Christmas gift-giving during the Middle Ages was usually between people with legal relationships, such as tenant and landlord. The annual indulgence in eating, dancing, singing, sporting, and card playing escalated in England, and by the 17th century the Christmas season featured lavish dinners, elaborate masques, and pageants. In 1607, King James I insisted that a play be acted on Christmas night and that the court indulge in games. It was during the Reformation in 16th–17th-century Europe that many Protestants changed the gift bringer to the Christ Child or \"Christkindl\", and the date of giving gifts changed from December 6 to Christmas Eve.\n\nFollowing the Protestant Reformation, many of the new denominations, including the Anglican Church and Lutheran Church, continued to celebrate Christmas. In 1629, the Anglican poet John Milton penned \"On the Morning of Christ's Nativity\", a poem that has since been read by many during Christmastide. Donald Heinz, a professor at California State University, states that Martin Luther \"inaugurated a period in which Germany would produce a unique culture of Christmas, much copied in North America.\" Among the congregations of the Dutch Reformed Church, Christmas was celebrated as one of the principal evangelical feasts.\n\nHowever, in 17th century England, some groups such as the Puritans, strongly condemned the celebration of Christmas, considering it a Catholic invention and the \"trappings of popery\" or the \"rags of the Beast\". In contrast, the established Anglican Church \"pressed for a more elaborate observance of feasts, penitential seasons, and saints' days. The calendar reform became a major point of tension between the Anglican party and the Puritan party.\" The Catholic Church also responded, promoting the festival in a more religiously oriented form. King Charles I of England directed his noblemen and gentry to return to their landed estates in midwinter to keep up their old-style Christmas generosity. Following the Parliamentarian victory over Charles I during the English Civil War, England's Puritan rulers banned Christmas in 1647.\n\nProtests followed as pro-Christmas rioting broke out in several cities and for weeks Canterbury was controlled by the rioters, who decorated doorways with holly and shouted royalist slogans. The book, \"The Vindication of Christmas\" (London, 1652), argued against the Puritans, and makes note of Old English Christmas traditions, dinner, roast apples on the fire, card playing, dances with \"plow-boys\" and \"maidservants\", old Father Christmas and carol singing.\nThe Restoration of King Charles II in 1660 ended the ban, but many Calvinist clergymen still disapproved of Christmas celebration. As such, in Scotland, the Presbyterian Church of Scotland discouraged the observance of Christmas, and though James VI commanded its celebration in 1618, attendance at church was scant. The Parliament of Scotland officially abolished the observance of Christmas in 1640, claiming that the church had been \"purged of all superstitious observation of days\". It was not until 1958 that Christmas again became a Scottish public holiday.\n\nFollowing the Restoration of Charles II, \"Poor Robin's Almanack\" contained the lines: \"Now thanks to God for Charles return, / Whose absence made old Christmas mourn. / For then we scarcely did it know, / Whether it Christmas were or no.\" The diary of James Woodforde, from the latter half of the 18th century, details the observance of Christmas and celebrations associated with the season over a number of years.\n\nIn Colonial America, the Pilgrims of New England shared radical Protestant disapproval of Christmas. The Plymouth Pilgrims put their loathing for the day into practice in 1620 when they spent their first Christmas Day in the New World working – thus demonstrating their complete contempt for the day. Non-Puritans in New England deplored the loss of the holidays enjoyed by the laboring classes in England. Christmas observance was outlawed in Boston in 1659. The ban by the Puritans was revoked in 1681 by English governor Edmund Andros, however it was not until the mid-19th century that celebrating Christmas became fashionable in the Boston region.\n\nAt the same time, Christian residents of Virginia and New York observed the holiday freely. Pennsylvania German Settlers, pre-eminently the Moravian settlers of Bethlehem, Nazareth and Lititz in Pennsylvania and the Wachovia Settlements in North Carolina, were enthusiastic celebrators of Christmas. The Moravians in Bethlehem had the first Christmas trees in America as well as the first Nativity Scenes. Christmas fell out of favor in the United States after the American Revolution, when it was considered an English custom.\nGeorge Washington attacked Hessian (German) mercenaries on the day after Christmas during the Battle of Trenton on December 26, 1776, Christmas being much more popular in Germany than in America at this time.\n\nWith the atheistic Cult of Reason in power during the era of Revolutionary France, Christian Christmas religious services were banned and the three kings cake was renamed the \"equality cake\" under anticlerical government policies.\n\nIn the UK, Christmas Day became a bank holiday in 1834, Boxing Day was added in 1871.\n\nIn the early-19th century, writers imagined Tudor Christmas as a time of heartfelt celebration. In 1843, Charles Dickens wrote the novel \"A Christmas Carol\" that helped revive the \"spirit\" of Christmas and seasonal merriment. Its instant popularity played a major role in portraying Christmas as a holiday emphasizing family, goodwill, and compassion.\n\nDickens sought to construct Christmas as a family-centered festival of generosity, linking \"worship and feasting, within a context of social reconciliation.\" Superimposing his humanitarian vision of the holiday, in what has been termed \"Carol Philosophy\", Dickens influenced many aspects of Christmas that are celebrated today in Western culture, such as family gatherings, seasonal food and drink, dancing, games, and a festive generosity of spirit. A prominent phrase from the tale, \"Merry Christmas\", was popularized following the appearance of the story. This coincided with the appearance of the Oxford Movement and the growth of Anglo-Catholicism, which led a revival in traditional rituals and religious observances.\nThe term Scrooge became a synonym for miser, with \"Bah! Humbug!\" dismissive of the festive spirit. In 1843, the first commercial Christmas card was produced by Sir Henry Cole. The revival of the Christmas Carol began with William Sandys's \"Christmas Carols Ancient and Modern\" (1833), with the first appearance in print of \"The First Noel\", \"I Saw Three Ships\", \"Hark the Herald Angels Sing\" and \"God Rest Ye Merry, Gentlemen\", popularized in Dickens' \"A Christmas Carol\".\n\nIn Britain, the Christmas tree was introduced in the early 19th century following the personal union with the Kingdom of Hanover by Charlotte of Mecklenburg-Strelitz, wife of King George III. In 1832, the future Queen Victoria wrote about her delight at having a Christmas tree, hung with lights, ornaments, and presents placed round it. After her marriage to her German cousin Prince Albert, by 1841 the custom became more widespread throughout Britain.\n\nAn image of the British royal family with their Christmas tree at Windsor Castle created a sensation when it was published in the \"Illustrated London News\" in 1848. A modified version of this image was published in the United States in 1850. By the 1870s, putting up a Christmas tree had become common in America.\n\nIn America, interest in Christmas had been revived in the 1820s by several short stories by Washington Irving which appear in his \"The Sketch Book of Geoffrey Crayon, Gent.\" and \"Old Christmas\". Irving's stories depicted harmonious warm-hearted English Christmas festivities he experienced while staying in Aston Hall, Birmingham, England, that had largely been abandoned, and he used the tract \"Vindication of Christmas\" (1652) of Old English Christmas traditions, that he had transcribed into his journal as a format for his stories.\n\nIn 1822, Clement Clarke Moore wrote the poem \"A Visit From St. Nicholas\" (popularly known by its first line: \"Twas the Night Before Christmas\").\nThe poem helped popularize the tradition of exchanging gifts, and seasonal Christmas shopping began to assume economic importance.\nThis also started the cultural conflict between the holiday's spiritual significance and its associated commercialism that some see as corrupting the holiday. In her 1850 book \"The First Christmas in New England\", Harriet Beecher Stowe includes a character who complains that the true meaning of Christmas was lost in a shopping spree.\n\nWhile the celebration of Christmas was not yet customary in some regions in the U.S., Henry Wadsworth Longfellow detected \"a transition state about Christmas here in New England\" in 1856. \"The old puritan feeling prevents it from being a cheerful, hearty holiday; though every year makes it more so.\"\nIn Reading, Pennsylvania, a newspaper remarked in 1861, \"Even our presbyterian friends who have hitherto steadfastly ignored Christmas—threw open their church doors and assembled in force to celebrate the anniversary of the Savior's birth.\"\n\nThe First Congregational Church of Rockford, Illinois, \"although of genuine Puritan stock\", was 'preparing for a grand Christmas jubilee', a news correspondent reported in 1864. By 1860, fourteen states including several from New England had adopted Christmas as a legal holiday. In 1875, Louis Prang introduced the Christmas card to Americans. He has been called the \"father of the American Christmas card\". On June 28, 1870, Christmas was formally declared a United States federal holiday.\n\nUp to the 1950s, in the UK, many Christmas customs were restricted to the upper classes and better-off families. The mass of the population had not adopted many of the Christmas rituals that later became general. The Christmas tree was rare. Christmas dinner might be beef—certainly not turkey. In their stockings children might get an apple, orange and sweets. Full celebration of a family Christmas with all the trimmings only became widespread with increased prosperity from the 1950s. National papers were published on Christmas Day until 1912. Post was still delivered on Christmas Day until 1961. League football matches continued in Scotland until the 1970s while in England they ceased at the end of the 1950s.\n\nUnder the state atheism of the Soviet Union, after its foundation in 1917, Christmas celebrations—along with other Christian holidays—were prohibited in public. During the 1920s, 30s and 40s, the League of Militant Atheists encouraged school pupils to campaign against Christmas traditions, such as the Christmas tree, as well as other Christian holidays, including Easter; the League established an antireligious holiday to be the 31st of each month as a replacement. At the height of this persecution, in 1929, on Christmas Day, children in Moscow were encouraged to spit on crucifixes as a protest against the holiday. It was not until the dissolution of the Soviet Union in 1991 that the persecution ended and Orthodox Christmas became a state holiday again for the first time in Russia after seven decades.\n\nEuropean History Professor Joseph Perry wrote that likewise, in Nazi Germany, \"because Nazi ideologues saw organized religion as an enemy of the totalitarian state, propagandists sought to deemphasize—or eliminate altogether—the Christian aspects of the holiday\" and that \"Propagandists tirelessly promoted numerous Nazified Christmas songs, which replaced Christian themes with the regime's racial ideologies.\"\n\nAs Christmas celebrations began to be held around the world even outside traditional Christian cultures in the 20th century, some Muslim-majority countries have banned the practice of Christmas, claiming it undermines Islam.\n\nChristmas Day is celebrated as a major festival and public holiday in countries around the world, including many whose populations are mostly non-Christian. In some non-Christian areas, periods of former colonial rule introduced the celebration (e.g. Hong Kong); in others, Christian minorities or foreign cultural influences have led populations to observe the holiday. Countries such as Japan, where Christmas is popular despite there being only a small number of Christians, have adopted many of the secular aspects of Christmas, such as gift-giving, decorations, and Christmas trees.\n\nCountries in which Christmas is not a formal public holiday include Afghanistan, Algeria, Azerbaijan, Bahrain, Bhutan, Cambodia, China (excepting Hong Kong and Macao), Comoros, Iran, Israel, Japan, Kuwait, Laos, Libya, Maldives, Mauritania, Mongolia, Morocco, North Korea, Oman, Pakistan, Qatar, Sahrawi Arab Democratic Republic, Saudi Arabia, Somalia, Tajikistan, Thailand, Tunisia, Turkey, Turkmenistan, United Arab Emirates, Uzbekistan, Vietnam, and Yemen. Christmas celebrations around the world can vary markedly in form, reflecting differing cultural and national traditions.\n\nAmong countries with a strong Christian tradition, a variety of Christmas celebrations have developed that incorporate regional and local cultures. For Christians, participating in a religious service plays an important part in the recognition of the season. Christmas, along with Easter, is the period of highest annual church attendance. In Catholic countries, people hold religious processions or parades in the days preceding Christmas. In other countries, secular processions or parades featuring Santa Claus and other seasonal figures are often held. Family reunions and the exchange of gifts are a widespread feature of the season. Gift giving takes place on Christmas Day in most countries. Others practice gift giving on December 6, Saint Nicholas Day, and January 6, Epiphany.\n\nThe practice of putting up special decorations at Christmas has a long history. In the 15th century, it was recorded that in London it was the custom at Christmas for every house and all the parish churches to be \"decked with holm, ivy, bays, and whatsoever the season of the year afforded to be green\". The heart-shaped leaves of ivy were said to symbolize the coming to earth of Jesus, while holly was seen as protection against pagans and witches, its thorns and red berries held to represent the Crown of Thorns worn by Jesus at the crucifixion and the blood he shed.\n\nNativity scenes are known from 10th-century Rome. They were popularised by Saint Francis of Asissi from 1223, quickly spreading across Europe. Different types of decorations developed across the Christian world, dependent on local tradition and available resources, and can vary from simple representations of the crib to far more elaborate sets – renowned manger scene traditions include the colourful \"Kraków szopka\" in Poland, which imitate Kraków's historical buildings as settings, the elaborate Italian \"presepi\" (, and ), or the Provençal crèches in southern France, using hand-painted terracotta figurines called \"santons\". In certain parts of the world, notably Sicily, living nativity scenes following the tradition of Saint Francis are a popular alternative to static crèches. The first commercially produced decorations appeared in Germany in the 1860s, inspired by paper chains made by children. In countries where a representation of the Nativity scene is very popular, people are encouraged to compete and create the most original or realistic ones. Within some families, the pieces used to make the representation are considered a valuable family heirloom.\n\nThe traditional colors of Christmas decorations are red, green, and gold. Red symbolizes the blood of Jesus, which was shed in his crucifixion, while green symbolizes eternal life, and in particular the evergreen tree, which does not lose its leaves in the winter, and gold is the first color associated with Christmas, as one of the three gifts of the Magi, symbolizing royalty.\n\nThe Christmas tree is considered by some as Christianisation of pagan tradition and ritual surrounding the Winter Solstice, which included the use of evergreen boughs, and an adaptation of pagan tree worship; according to eighth-century biographer Æddi Stephanus, Saint Boniface (634–709), who was a missionary in Germany, took an axe to an oak tree dedicated to Thor and pointed out a fir tree, which he stated was a more fitting object of reverence because it pointed to heaven and it had a triangular shape, which he said was symbolic of the Trinity. The English language phrase \"Christmas tree\" is first recorded in 1835 and represents an importation from the German language. The modern Christmas tree tradition is believed to have begun in Germany in the 18th century though many argue that Martin Luther began the tradition in the 16th century.\n\nFrom Germany the custom was introduced to Britain, first via Queen Charlotte, wife of George III, and then more successfully by Prince Albert during the reign of Queen Victoria. By 1841 the Christmas tree had become even more widespread throughout Britain. By the 1870s, people in the United States had adopted the custom of putting up a Christmas tree. Christmas trees may be decorated with lights and ornaments.\n\nSince the 19th century, the poinsettia, a native plant from Mexico, has been associated with Christmas. Other popular holiday plants include holly, mistletoe, red amaryllis, and Christmas cactus. Along with a Christmas tree, the interior of a home may be decorated with these plants, along with garlands and evergreen foliage. The display of Christmas villages has also become a tradition in many homes during this season. The outside of houses may be decorated with lights and sometimes with illuminated sleighs, snowmen, and other Christmas figures.\n\nOther traditional decorations include bells, candles, candy canes, stockings, wreaths, and angels. Both the displaying of wreaths and candles in each window are a more traditional Christmas display. The concentric assortment of leaves, usually from an evergreen, make up Christmas wreaths and are designed to prepare Christians for the Advent season. Candles in each window are meant to demonstrate the fact that Christians believe that Jesus Christ is the ultimate light of the world.\n\nChristmas lights and banners may be hung along streets, music played from speakers, and Christmas trees placed in prominent places. It is common in many parts of the world for town squares and consumer shopping areas to sponsor and display decorations. Rolls of brightly colored paper with secular or religious Christmas motifs are manufactured for the purpose of wrapping gifts. In some countries, Christmas decorations are traditionally taken down on Twelfth Night, the evening of January 5.\n\nThe earliest extant specifically Christmas hymns appear in fourth-century Rome. Latin hymns such as \"Veni redemptor gentium\", written by Ambrose, Archbishop of Milan, were austere statements of the theological doctrine of the Incarnation in opposition to Arianism. \"Corde natus ex Parentis\" (\"Of the Father's love begotten\") by the Spanish poet Prudentius (d. 413) is still sung in some churches today.\n\nIn the 9th and 10th centuries, the Christmas \"Sequence\" or \"Prose\" was introduced in North European monasteries, developing under Bernard of Clairvaux into a sequence of rhymed stanzas. In the 12th century the Parisian monk Adam of St. Victor began to derive music from popular songs, introducing something closer to the traditional Christmas carol.\n\nBy the 13th century, in France, Germany, and particularly, Italy, under the influence of Francis of Asissi, a strong tradition of popular Christmas songs in the native language developed. Christmas carols in English first appear in a 1426 work of John Awdlay, a Shropshire chaplain, who lists twenty-five \"caroles of Cristemas\", probably sung by groups of wassailers, who went from house to house.\nThe songs we know specifically as carols were originally communal folk songs sung during celebrations such as \"harvest tide\" as well as Christmas. It was only later that carols began to be sung in church. Traditionally, carols have often been based on medieval chord patterns, and it is this that gives them their uniquely characteristic musical sound. Some carols like \"Personent hodie\", \"Good King Wenceslas\", and \"The Holly and the Ivy\" can be traced directly back to the Middle Ages. They are among the oldest musical compositions still regularly sung. \"Adeste Fideles\" (O Come all ye faithful) appears in its current form in the mid-18th century, although the words may have originated in the 13th century.\n\nSinging of carols initially suffered a decline in popularity after the Protestant Reformation in northern Europe, although some Reformers, like Martin Luther, wrote carols and encouraged their use in worship. Carols largely survived in rural communities until the revival of interest in popular songs in the 19th century. The 18th-century English reformer Charles Wesley understood the importance of music to worship. In addition to setting many psalms to melodies, which were influential in the Great Awakening in the United States, he wrote texts for at least three Christmas carols. The best known was originally entitled \"Hark! How All the Welkin Rings\", later renamed \"Hark! the Herald Angels Sing\".\nFelix Mendelssohn wrote a melody adapted to fit Wesley's words. In Austria in 1818 Mohr and Gruber made a major addition to the genre when they composed \"Silent Night\" for the St. Nicholas Church, Oberndorf. William Sandys' \"Christmas Carols Ancient and Modern\" (1833) contained the first appearance in print of many now-classic English carols, and contributed to the mid-Victorian revival of the festival.\n\nCompletely secular Christmas seasonal songs emerged in the late 18th century. \"Deck the Halls\" dates from 1784, and the American \"Jingle Bells\" was copyrighted in 1857. In the 19th and 20th century, African American spirituals and songs about Christmas, based in their tradition of spirituals, became more widely known. An increasing number of seasonal holidays songs were commercially produced in the 20th century, including jazz and blues variations. In addition, there was a revival of interest in early music, from groups singing folk music, such as The Revels, to performers of early medieval and classical music.\n\nA special Christmas family meal is traditionally an important part of the holiday's celebration, and the food that is served varies greatly from country to country. Some regions, such as Sicily, have special meals for Christmas Eve, when 12 kinds of fish are served. In the United Kingdom and countries influenced by its traditions, a standard Christmas meal includes turkey, goose or other large bird, gravy, potatoes, vegetables, sometimes bread and cider. Special desserts are also prepared, such as Christmas pudding, mince pies, fruit cake and Yule log cake.\n\nIn Poland and other parts of eastern Europe and Scandinavia, fish often is used for the traditional main course, but richer meat such as lamb is increasingly served. In Sweden it is common with a special variety of smörgåsbord, where ham, meatballs and herring play a prominent role. In Germany, France, and Austria, goose and pork are favored. Beef, ham, and chicken in various recipes are popular throughout the world. The Maltese traditionally serve \"Imbuljuta tal-Qastan\", a chocolate and chestnuts beverage, after Midnight Mass and throughout the Christmas season. Slovaks prepare the traditional Christmas bread potica, \"bûche de Noël\" in France, \"panettone\" in Italy, and elaborate tarts and cakes. The eating of sweets and chocolates has become popular worldwide, and sweeter Christmas delicacies include the German \"stollen\", marzipan cake or candy, and Jamaican rum fruit cake. As one of the few fruits traditionally available to northern countries in winter, oranges have been long associated with special Christmas foods. Eggnog is a sweetened dairy-based beverage traditionally made with milk, cream, sugar, and whipped eggs (which gives it a frothy texture). Spirits such as brandy, rum or bourbon are often added. The finished serving is often garnished with a sprinkling of ground cinnamon or nutmeg.\n\nChristmas cards are illustrated messages of greeting exchanged between friends and family members during the weeks preceding Christmas Day. The traditional greeting reads \"wishing you a Merry Christmas and a Happy New Year\", much like that of the first commercial Christmas card, produced by Sir Henry Cole in London in 1843. The custom of sending them has become popular among a wide cross-section of people with the emergence of the modern trend towards exchanging E-cards.\n\nChristmas cards are purchased in considerable quantities, and feature artwork, commercially designed and relevant to the season. The content of the design might relate directly to the Christmas narrative, with depictions of the Nativity of Jesus, or Christian symbols such as the Star of Bethlehem, or a white dove, which can represent both the Holy Spirit and Peace on Earth. Other Christmas cards are more secular and can depict Christmas traditions, mythical figures such as Santa Claus, objects directly associated with Christmas such as candles, holly and baubles, or a variety of images associated with the season, such as Christmastide activities, snow scenes and the wildlife of the northern winter. There are even humorous cards and genres depicting nostalgic scenes of the past such as crinolined shoppers in idealized 19th-century streetscapes.\n\nSome prefer cards with a poem, prayer, or Biblical verse; while others distance themselves from religion with an all-inclusive \"Season's greetings\".\n\nA number of nations have issued commemorative stamps at Christmastide. Postal customers will often use these stamps to mail Christmas cards, and they are popular with philatelists. These stamps are regular postage stamps, unlike Christmas seals, and are valid for postage year-round. They usually go on sale some time between early October and early December, and are printed in considerable quantities.\n\nIn 1898 a Canadian stamp was issued to mark the inauguration of the Imperial Penny Postage rate. The stamp features a map of the globe and bears an inscription \"XMAS 1898\" at the bottom. In 1937, Austria issued two \"Christmas greeting stamps\" featuring a rose and the signs of the zodiac. In 1939, Brazil issued four semi-postal stamps with designs featuring the three kings and a star of Bethlehem, an angel and child, the Southern Cross and a child, and a mother and child.\n\nBoth the US Postal Service and the United Kingdom's Royal Mail regularly issue Christmas-themed stamps each year.\n\nThe exchanging of gifts is one of the core aspects of the modern Christmas celebration, making it the most profitable time of year for retailers and businesses throughout the world. On Christmas, people exchange gifts based on the Christian tradition associated with Saint Nicholas, and the gifts of gold, frankincense, and myrrh which were given to the baby Jesus by the Magi. The practice of gift giving in the Roman celebration of Saturnalia may have influenced Christian Christian customs, but on the other hand the Christian \"core dogma of the Incarnation, however, solidly established the giving and receiving of gifts as the structural principle of that recurrent yet unique event\", because it was the Biblical Magi, \"together with all their fellow men, who received the gift of God through man's renewed participation in the divine life.\"\n\nA number of figures are associated with Christmas and the seasonal giving of gifts. Among these are Father Christmas, also known as Santa Claus (derived from the Dutch for Saint Nicholas), Père Noël, and the Weihnachtsmann; Saint Nicholas or Sinterklaas; the Christkind; Kris Kringle; Joulupukki; tomte; Babbo Natale; Saint Basil; and Ded Moroz. The Scandinavian tomte is sometimes depicted as a gnome instead of Santa Claus.\n\nThe best known of these figures today is red-dressed Santa Claus, of diverse origins. The name Santa Claus can be traced back to the Dutch \"Sinterklaas\", which means simply Saint Nicholas. Nicholas was a 4th-century Greek bishop of Myra, a city in the Roman province of Lycia, whose ruins are from modern Demre in southwest Turkey. Among other saintly attributes, he was noted for the care of children, generosity, and the giving of gifts. His feast day, December 6, came to be celebrated in many countries with the giving of gifts.\n\nSaint Nicholas traditionally appeared in bishop's attire, accompanied by helpers, inquiring about the behaviour of children during the past year before deciding whether they deserved a gift or not. By the 13th century, Saint Nicholas was well known in the Netherlands, and the practice of gift-giving in his name spread to other parts of central and southern Europe. At the Reformation in 16th–17th-century Europe, many Protestants changed the gift bringer to the Christ Child or \"Christkindl\", corrupted in English to Kris Kringle, and the date of giving gifts changed from December 6 to Christmas Eve.\n\nThe modern popular image of Santa Claus, however, was created in the United States, and in particular in New York. The transformation was accomplished with the aid of notable contributors including Washington Irving and the German-American cartoonist Thomas Nast (1840–1902). Following the American Revolutionary War, some of the inhabitants of New York City sought out symbols of the city's non-English past. New York had originally been established as the Dutch colonial town of New Amsterdam and the Dutch Sinterklaas tradition was reinvented as Saint Nicholas.\n\nIn 1809, the New-York Historical Society convened and retroactively named \"Sancte Claus\" the patron saint of Nieuw Amsterdam, the Dutch name for New York City. At his first American appearance in 1810, Santa Claus was drawn in bishops' robes. However, as new artists took over, Santa Claus developed more secular attire. Nast drew a new image of \"Santa Claus\" annually, beginning in 1863. By the 1880s, Nast's Santa had evolved into the modern vision of the figure, perhaps based on the English figure of Father Christmas. The image was standardized by advertisers in the 1920s and continues through the present day.\n\nFather Christmas, a jolly, stout, bearded man who typified the spirit of good cheer at Christmas, predates the Santa Claus character. He is first recorded in early 17th century England, but was associated with holiday merrymaking and drunkenness rather than the bringing of gifts. In Victorian Britain, his image was remade to match that of Santa. The French Père Noël evolved along similar lines, eventually adopting the Santa image. In Italy, Babbo Natale acts as Santa Claus, while La Befana is the bringer of gifts and arrives on the eve of the Epiphany. It is said that La Befana set out to bring the baby Jesus gifts, but got lost along the way. Now, she brings gifts to all children. In some cultures Santa Claus is accompanied by Knecht Ruprecht, or Black Peter. In other versions, elves make the toys. His wife is referred to as Mrs. Claus.\nThere has been some opposition to the narrative of the American evolution of Saint Nicholas into the modern Santa. It has been claimed that the Saint Nicholas Society was not founded until 1835, almost half a century after the end of the American War of Independence. Moreover, a study of the \"children's books, periodicals and journals\" of New Amsterdam by Charles Jones revealed no references to Saint Nicholas or Sinterklaas. However, not all scholars agree with Jones's findings, which he reiterated in a book-length study in 1978; Howard G. Hageman, of New Brunswick Theological Seminary, maintains that the tradition of celebrating Sinterklaas in New York was alive and well from the early settlement of the Hudson Valley on.\n\nCurrent tradition in several Latin American countries (such as Venezuela and Colombia) holds that while Santa makes the toys, he then gives them to the Baby Jesus, who is the one who actually delivers them to the children's homes, a reconciliation between traditional religious beliefs and the iconography of Santa Claus imported from the United States.\n\nIn South Tyrol (Italy), Austria, Czech Republic, Southern Germany, Hungary, Liechtenstein, Slovakia, and Switzerland, the Christkind (Ježíšek in Czech, Jézuska in Hungarian and Ježiško in Slovak) brings the presents. Greek children get their presents from Saint Basil on New Year's Eve, the eve of that saint's liturgical feast. The German St. Nikolaus is not identical with the Weihnachtsmann (who is the German version of Santa Claus / Father Christmas). St. Nikolaus wears a bishop's dress and still brings small gifts (usually candies, nuts, and fruits) on December 6 and is accompanied by Knecht Ruprecht. Although many parents around the world routinely teach their children about Santa Claus and other gift bringers, some have come to reject this practice, considering it deceptive.\n\nSome jurisdictions of the Eastern Orthodox Church, including those of Russia, Georgia, Ukraine, Macedonia, Montenegro, Serbia, and Jerusalem, mark feasts using the older Julian calendar. As of , there is a difference of 13 days between the Julian calendar and the modern Gregorian calendar, which is used internationally for most secular purposes. As a result, December 25 on the Julian calendar currently corresponds to January 7 on the calendar used by most governments and people in everyday life. Therefore, the aforementioned Orthodox Christians mark December 25 (and thus Christmas) on the day that is internationally considered to be January 7.\n\nHowever, other Orthodox Christians, such as those belonging to the jurisdictions of Bulgaria, Greece, Romania, Constantinople, Antioch, Alexandria, Albania, Cyprus, Finland, and the Orthodox Church in America, among others, began using the Revised Julian calendar in the early 20th century, which at present corresponds exactly to the Gregorian calendar. Therefore, these Orthodox Christians mark December 25 (and thus Christmas) on the same day that is internationally considered to be December 25, and which is also the date of Christmas among Western Christians.\n\nA further complication is added by the fact that the Armenian Apostolic Church continues the original ancient Eastern Christian practice of celebrating the birth of Christ not as a separate holiday, but on the same day as the celebration of his baptism (Theophany), which is on January 6. This is a public holiday in Armenia, and it is held on the same day that is internationally considered to be January 6, because the Armenian Church in Armenia uses the Gregorian calendar.\n\nHowever, there is also a small Armenian Patriarchate of Jerusalem, which maintains the traditional Armenian custom of celebrating the birth of Christ on the same day as Theophany (January 6), but uses the \"Julian\" calendar for the determination of that date. As a result, this church celebrates \"Christmas\" (more properly called Theophany) on the day that is considered January 19 on the Gregorian calendar in use by the majority of the world.\n\nIn summary, there are four different dates used by different Christian groups to mark the birth of Christ, given in the table below.\n\nChristmas is typically a peak selling season for retailers in many nations around the world. Sales increase dramatically as people purchase gifts, decorations, and supplies to celebrate. In the U.S., the \"Christmas shopping season\" starts as early as October. In Canada, merchants begin advertising campaigns just before Halloween (October 31), and step up their marketing following Remembrance Day on November 11. In the UK and Ireland, the Christmas shopping season starts from mid-November, around the time when high street Christmas lights are turned on. In the United States, it has been calculated that a quarter of all personal spending takes place during the Christmas/holiday shopping season. Figures from the U.S. Census Bureau reveal that expenditure in department stores nationwide rose from $20.8 billion in November 2004 to $31.9 billion in December 2004, an increase of 54 percent. In other sectors, the pre-Christmas increase in spending was even greater, there being a November–December buying surge of 100 percent in bookstores and 170 percent in jewelry stores. In the same year employment in American retail stores rose from 1.6 million to 1.8 million in the two months leading up to Christmas. Industries completely dependent on Christmas include Christmas cards, of which 1.9 billion are sent in the United States each year, and live Christmas Trees, of which 20.8 million were cut in the U.S. in 2002. In the UK in 2010, up to £8 billion was expected to be spent online at Christmas, approximately a quarter of total retail festive sales.\nIn most Western nations, Christmas Day is the least active day of the year for business and commerce; almost all retail, commercial and institutional businesses are closed, and almost all industries cease activity (more than any other day of the year), whether laws require such or not. In England and Wales, the Christmas Day (Trading) Act 2004 prevents all large shops from trading on Christmas Day. Scotland is currently planning similar legislation. Film studios release many high-budget movies during the holiday season, including Christmas films, fantasy movies or high-tone dramas with high production values to hopes of maximizing the chance of nominations for the Academy Awards.\n\nOne economist's analysis calculates that, despite increased overall spending, Christmas is a deadweight loss under orthodox microeconomic theory, because of the effect of gift-giving. This loss is calculated as the difference between what the gift giver spent on the item and what the gift receiver would have paid for the item. It is estimated that in 2001, Christmas resulted in a $4 billion deadweight loss in the U.S. alone. Because of complicating factors, this analysis is sometimes used to discuss possible flaws in current microeconomic theory. Other deadweight losses include the effects of Christmas on the environment and the fact that material gifts are often perceived as white elephants, imposing cost for upkeep and storage and contributing to clutter.\n\nChristmas has at times been the subject of controversy and attacks from various sources. Historically it was prohibited by Puritans when they briefly held power in England during the English Interregnum (1649–1660), and in Colonial America where the Puritans outlawed the celebration of Christmas in 1659. The Parliament of Scotland, which was dominated by Presbyterians, passed a series of acts outlawing the observance of Christmas between 1637 and 1690; Christmas Day did not become a public holiday in Scotland until 1958. Christmas celebrations have also been prohibited by atheist states such as the Soviet Union and more recently majority Muslim states such as Somalia, Tajikistan and Brunei.\n\nModern scholars such as E. P. Sanders, Geza Vermes and Marcus Borg consider both Gospel narratives of the birth of Jesus to be non-historical, arguing that there are contradictions between them. Many biblical scholars view the discussion of historicity as secondary, given that gospels were primarily written as theological documents rather than historical accounts.\n\nSome Christians and organizations such as Pat Robertson's American Center for Law and Justice cite alleged attacks on Christmas (dubbing them a \"war on Christmas\"). Such groups claim that any specific mention of the term \"Christmas\" or its religious aspects is being increasingly censored, avoided, or discouraged by a number of advertisers, retailers, government (prominently schools), and other public and private organizations. One controversy is the occurrence of Christmas trees being renamed Holiday trees. In the U.S. there has been a tendency to replace the greeting \"Merry Christmas\" with \"Happy Holidays\", which is considered inclusive at the time of the Jewish celebration of Hanukkah. In the U.S. and Canada, where the use of the term \"Holidays\" is most prevalent, opponents have denounced its usage and avoidance of using the term \"Christmas\" as being politically correct. Groups such as the American Civil Liberties Union have initiated court cases to bar the display of images and other material referring to Christmas from public property, including schools. Such groups argue that government-funded displays of Christmas imagery and traditions violate the First Amendment to the United States Constitution, which prohibits the establishment by Congress of a national religion. In 1984, the U.S. Supreme Court ruled in \"Lynch v. Donnelly\" that a Christmas display (which included a Nativity scene) owned and displayed by the city of Pawtucket, Rhode Island, did not violate the First Amendment. In November 2009, the federal appeals court in Philadelphia upheld a school district's ban on the singing of Christmas carols. The Supreme Court of the United States declined to hear an appeal.\n\nAmerican Muslim scholar Abdul Malik Mujahid has said that Muslims must treat Christmas with respect, even if they disagree with it.\n\n\n", "id": "6237", "title": "Christmas"}
{"url": "https://en.wikipedia.org/wiki?curid=6239", "text": "Contraction mapping\n\nIn mathematics, a contraction mapping, or contraction or contractor, on a metric space \"(M,d)\" is a function \"f\" from \"M\" to itself, with the property that there is some nonnegative real number formula_1 such that for all \"x\" and \"y\" in \"M\",\nThe smallest such value of \"k\" is called the Lipschitz constant of \"f\". Contractive maps are sometimes called Lipschitzian maps. If the above condition is instead satisfied for\n\"k\" ≤ 1, then the mapping is said to be a non-expansive map.\n\nMore generally, the idea of a contractive mapping can be defined for maps between metric spaces. Thus, if (\"M\",\"d\") and (\"N\",\"d\"') are two metric spaces, and formula_3, then there is a constant formula_4 such that\nfor all \"x\" and \"y\" in \"M\".\n\nEvery contraction mapping is Lipschitz continuous and hence uniformly continuous (for a Lipschitz continuous function, the constant \"k\" is no longer necessarily less than 1).\n\nA contraction mapping has at most one fixed point. Moreover, the Banach fixed point theorem states that every contraction mapping on a nonempty complete metric space has a unique fixed point, and that for any \"x\" in \"M\" the iterated function sequence \"x\", \"f\" (\"x\"), \"f\" (\"f\" (\"x\")), \"f\" (\"f\" (\"f\" (\"x\"))), ... converges to the fixed point. This concept is very useful for iterated function systems where contraction mappings are often used. Banach's fixed point theorem is also applied in proving the existence of solutions of ordinary differential equations, and is used in one proof of the inverse function theorem.\n\nA non-expansive mapping with formula_6 can be strengthened to a firmly non-expansive mapping in a Hilbert space \"H\" if the following holds for all \"x\" and \"y\" in \"H\":\nwhere\n\nThis is a special case of formula_9 averaged nonexpansive operators with formula_10. A firmly non-expansive mapping is always non-expansive, via the Cauchy–Schwarz inequality.\n\nA subcontraction map or subcontractor is a map \"f\" on a metric space (\"M\",\"d\") such that\n\nIf the image of a subcontractor \"f\" is compact, then \"f\" has a fixed point.\n\n\n", "id": "6239", "title": "Contraction mapping"}
{"url": "https://en.wikipedia.org/wiki?curid=6246", "text": "Covalent bond\n\nA covalent bond, also called a molecular bond, is a chemical bond that involves the sharing of electron pairs between atoms. These electron pairs are known as shared pairs or bonding pairs, and the stable balance of attractive and repulsive forces between atoms, when they share electrons, is known as covalent bonding. For many molecules, the sharing of electrons allows each atom to attain the equivalent of a full outer shell, corresponding to a stable electronic configuration.\n\nCovalent bonding includes many kinds of interactions, including σ-bonding, π-bonding, metal-to-metal bonding, agostic interactions, bent bonds, and three-center two-electron bonds. The term \"covalent bond\" dates from 1939. The prefix \"co-\" means \"jointly, associated in action, partnered to a lesser degree, \" etc.; thus a \"co-valent bond\", in essence, means that the atoms share \"valence\", such as is discussed in valence bond theory.\n\nIn the molecule , the hydrogen atoms share the two electrons via covalent bonding. Covalency is greatest between atoms of similar electronegativities. Thus, covalent bonding does not necessarily require that the two atoms be of the same elements, only that they be of comparable electronegativity. Covalent bonding that entails sharing of electrons over more than two atoms is said to be delocalized.\n\nThe term \"covalence\" in regard to bonding was first used in 1919 by Irving Langmuir in a \"Journal of the American Chemical Society\" article entitled \"The Arrangement of Electrons in Atoms and Molecules\". Langmuir wrote that \"we shall denote by the term \"covalence\" the number of pairs of electrons that a given atom shares with its neighbors.\"\n\nThe idea of covalent bonding can be traced several years before 1919 to Gilbert N. Lewis, who in 1916 described the sharing of electron pairs between atoms. He introduced the \"Lewis notation\" or \"electron dot notation\" or \"Lewis dot structure\", in which valence electrons (those in the outer shell) are represented as dots around the atomic symbols. Pairs of electrons located between atoms represent covalent bonds. Multiple pairs represent multiple bonds, such as double bonds and triple bonds. An alternative form of representation, not shown here, has bond-forming electron pairs represented as solid lines.\n\nLewis proposed that an atom forms enough covalent bonds to form a full (or closed) outer electron shell. In the diagram of methane shown here, the carbon atom has a valence of four and is, therefore, surrounded by eight electrons (the octet rule), four from the carbon itself and four from the hydrogens bonded to it. Each hydrogen has a valence of one and is surrounded by two electrons (a duet rule) – its own one electron plus one from the carbon. The numbers of electrons correspond to full shells in the quantum theory of the atom; the outer shell of a carbon atom is the \"n\" = 2 shell, which can hold eight electrons, whereas the outer (and only) shell of a hydrogen atom is the \"n\" = 1 shell, which can hold only two.\n\nWhile the idea of shared electron pairs provides an effective qualitative picture of covalent bonding, quantum mechanics is needed to understand the nature of these bonds and predict the structures and properties of simple molecules. Walter Heitler and Fritz London are credited with the first successful quantum mechanical explanation of a chemical bond (molecular hydrogen) in 1927. Their work was based on the valence bond model, which assumes that a chemical bond is formed when there is good overlap between the atomic orbitals of participating atoms.\n\nAtomic orbitals (except for s orbitals) have specific directional properties leading to different types of covalent bonds. Sigma (σ) bonds are the strongest covalent bonds and are due to head-on overlapping of orbitals on two different atoms. A single bond is usually a σ bond. Pi (π) bonds are weaker and are due to lateral overlap between p (or d) orbitals. A double bond between two given atoms consists of one σ and one π bond, and a triple bond is one σ and two π bonds.\n\nCovalent bonds are also affected by the electronegativity of the connected atoms which determines the chemical polarity of the bond. Two atoms with equal electronegativity will make nonpolar covalent bonds such as H–H. An unequal relationship creates a polar covalent bond such as with H−Cl. However polarity also requires geometric asymmetry, or else dipoles may cancel out resulting in a non-polar molecule.\n\nThere are several types of structures for covalent substances, including individual molecules, molecular structures, macromolecular structures and giant covalent structures. Individual molecules have strong bonds that hold the atoms together, but there are negligible forces of attraction between molecules. Such covalent substances are usually gases, for example, HCl, SO, CO, and CH. In molecular structures, there are weak forces of attraction. Such covalent substances are low-boiling-temperature liquids (such as ethanol), and low-melting-temperature solids (such as iodine and solid CO). Macromolecular structures have large numbers of atoms linked by covalent bonds in chains, including synthetic polymers such as polyethylene and nylon, and biopolymers such as proteins and starch. Network covalent structures (or giant covalent structures) contain large numbers of atoms linked in sheets (such as graphite), or 3-dimensional structures (such as diamond and quartz). These substances have high melting and boiling points, are frequently brittle, and tend to have high electrical resistivity. Elements that have high electronegativity, and the ability to form three or four electron pair bonds, often form such large macromolecular structures.\n\nBonds with one or three electrons can be found in radical species, which have an odd number of electrons. The simplest example of a 1-electron bond is found in the dihydrogen cation, . One-electron bonds often have about half the bond energy of a 2-electron bond, and are therefore called \"half bonds\". However, there are exceptions: in the case of dilithium, the bond is actually stronger for the 1-electron than for the 2-electron Li. This exception can be explained in terms of hybridization and inner-shell effects.\nThe simplest example of three-electron bonding can be found in the helium dimer cation, . It is considered a \"half bond\" because it consists of only one shared electron (rather than two); in molecular orbital terms, the third electron is in an anti-bonding orbital which cancels out half of the bond formed by the other two electrons. Another example of a molecule containing a 3-electron bond, in addition to two 2-electron bonds, is nitric oxide, NO. The oxygen molecule, O can also be regarded as having two 3-electron bonds and one 2-electron bond, which accounts for its paramagnetism and its formal bond order of 2. Chlorine dioxide and its heavier analogues bromine dioxide and iodine dioxide also contain three-electron bonds.\n\nMolecules with odd-electron bonds are usually highly reactive. These types of bond are only stable between atoms with similar electronegativities.\n\nThere are situations whereby a single Lewis structure is insufficient to explain the electron configuration in a molecule, hence a superposition of structures are needed. The same two atoms in such molecules can be bonded differently in different structures (a single bond in one, a double bond in another, or even none at all), resulting in a non-integer bond order. The nitrate ion is one such example with three equivalent structures. The bond between the nitrogen and each oxygen is a double bond in one structure and a single bond in the other two, so that the average bond order for each N–O interaction is = .\n\nIn organic chemistry, when a molecule with a planar ring obeys Hückel's rule, where the number of π electrons fit the formula 4\"n\" + 2 (where \"n\" is an integer), it attains extra stability and symmetry. In benzene, the prototypical aromatic compound, there are 6 π bonding electrons (\"n\" = 1, 4\"n\" + 2 = 6). These occupy three delocalized π molecular orbitals (molecular orbital theory) or form conjugate π bonds in two resonance structures that linearly combine (valence bond theory), creating a regular hexagon exhibiting a greater stabilization than the hypothetical 1,3,5-cyclohexatriene.\n\nIn the case of heterocyclic aromatics and substituted benzenes, the electronegativity differences between different parts of the ring may dominate the chemical behaviour of aromatic ring bonds, which otherwise are equivalent.\n\nCertain molecules such as xenon difluoride and sulfur hexafluoride have higher co-ordination numbers than would be possible due to strictly covalent bonding according to the octet rule. This is explained by the three-center four-electron bond (\"3c–4e\") model which interprets the molecular wavefunction in terms of non-bonding highest occupied molecular orbitals in molecular orbital theory and ionic-covalent resonance in valence bond theory.\n\nIn three-center two-electron bonds (\"3c–2e\") three atoms share two electrons in bonding. This type of bonding occurs in electron deficient compounds like diborane. Each such bond (2 per molecule in diborane) contains a pair of electrons which connect the boron atoms to each other in a banana shape, with a proton (nucleus of a hydrogen atom) in the middle of the bond, sharing electrons with both boron atoms. In certain cluster compounds, so-called four-center two-electron bonds also have been postulated.\n\nAfter the development of quantum mechanics, two basic theories were proposed to provide a quantum description of chemical bonding: valence bond (VB) theory and molecular orbital (MO) theory. A more recent quantum description is given in terms of atomic contributions to the electronic density of states.\n\nIn COOP, COHP and BCOOP, evaluation of bond covalency is dependent on the basis set. To overcome this issue, an alternative formulation of the bond covalency can be provided in this way.\n\nThe center mass of an atomic orbital ,\nwith quantum numbers , for atom A is defined as\n\nwhere is the contribution of the atomic orbital of the atom A to the total electronic density of states of the solid\n\nwhere the outer sum runs over all atoms A of the unit cell. The energy window is chosen in such a way that it encompasses all relevant bands participating in the bond. If the range to select is unclear, it can be identified in practice by examining the molecular orbitals that describe the electron density along the considered bond.\n\nThe relative position of the center mass of levels of atom A with respect to the center mass of levels of atom B is given as\n\nwhere the contributions of the magnetic and spin quantum numbers are summed. According to this definition, the relative position of the A levels with respect to the B levels is\n\nwhere, for simplicity, we may omit the dependence from the principal quantum number in the notation referring to .\n\nIn this formalism, the greater the value of , the higher the overlap of the selected atomic bands, and thus the electron density described by those orbitals gives a more covalent A–B bond. The quantity is denoted as the \"covalency\" of the A–B bond, which is specified in the same units of the energy .\n\n\n", "id": "6246", "title": "Covalent bond"}
{"url": "https://en.wikipedia.org/wiki?curid=6247", "text": "Condensation polymer\n\nCondensation polymers are any kind of polymers formed through a condensation reaction—where molecules join together—\"losing\" small molecules as byproducts such as water or methanol, as opposed to addition polymers which involve the reaction of unsaturated monomers. Types of condensation polymers include polyamides, polyacetals and [p\nCondensation polymerization, a form of step-growth polymerization, is a process by which two molecules join together, resulting in loss of small molecules which are often water. The type of end product resulting from a condensation polymerization is dependent on\nMonomers with only one reactive group terminate a growing chain, and thus give end products with a lower molecular weight. Linear polymers are created using monomers with two reactive end groups and monomers with more than two end groups give three-dimensional polymers which are crosslinked.\n\nDehydration synthesis often involves joining monomers with an -OH (hydroxyl) group and a freely ionized -H on either end (such as a hydrogen from the -NH in nylon or proteins). Normally, two or more different monomers are used in the reaction. The bonds between the hydroxyl group, the hydrogen atom and their respective atoms break forming water from the hydroxyl and hydrogen, and the polymer.\n\nPolyester is created through ester linkages between monomers, which involve the functional groups carboxyl and hydroxyl (an organic acid and an alcohol monomer).\n\nNylon is another common condensation polymer. It can be manufactured by reacting di-amines with carboxyl derivatives. In this example the derivative is a di-carboxylic acid, but di-acyl chlorides are also used. Another approach used is the reaction of di-functional monomers, with one amine and one carboxylic acid group on the same molecule:\n\nThe carboxylic acids and amines link to form peptide bonds, also known as amide groups. Proteins are condensation polymers made from amino acid monomers. Carbohydrates are also condensation polymers made from sugar monomers such as glucose (i.e. cellulose or glycogen) and galactose.\n\nCondensation polymerization is occasionally used to form simple hydrocarbons. This method, however, is expensive and inefficient, so the addition polymer of ethene (polyethylene) is generally used.\n\nCondensation polymers, unlike addition polymers, may be biodegradable. The peptide or ester bonds between monomers can be hydrolysed by acid catalysts or bacterial enzymes breaking the polymer chain into smaller pieces.\n\nThe most commonly known condensation polymers are proteins, fabrics such as nylon, silk, or polyester.\n\n\nPolymers (and condensation polymers) - Virtual Text of Organic Chemistry, William Reusch\n", "id": "6247", "title": "Condensation polymer"}
{"url": "https://en.wikipedia.org/wiki?curid=6249", "text": "Timeline of computing\n\nTimeline of computing presents events in the history of computing organized by year and grouped into six topic areas: predictions and concepts, first use and inventions, hardware systems and processors, operating systems, programming languages, and new application areas.\n\nDetailed computing timelines: 2400 BC–1949, 1950–1979, 1980–1989, 1990–1999, 2000-2009, 2010-\n\n\n\n", "id": "6249", "title": "Timeline of computing"}
{"url": "https://en.wikipedia.org/wiki?curid=6250", "text": "Colorado Springs, Colorado\n\nColorado Springs is a home rule municipality that is the county seat and the most populous municipality of El Paso County, Colorado, United States. Colorado Springs is located in the east central portion of the state. It is situated on Fountain Creek and is located south of the Colorado State Capitol in Denver.\n\nAt the city stands over above sea level, though some areas of the city are significantly higher and lower. Colorado Springs is situated near the base of one of the most famous American mountains, Pikes Peak, rising above on the eastern edge of the Southern Rocky Mountains. The city is home to 24 national governing bodies of sport, the United States Olympic Committee and the United States Olympic Training Center.\n\nThe city had an estimated population of 456,568 in 2015,<ref name=\"http://quickfacts.census.gov/\"> United States Census Bureau. Accessed May 28, 2014.</ref> ranking as the second most populous city in the state of Colorado, behind Denver, and the 40th most populous city in the United States. The Colorado Springs, CO Metropolitan Statistical Area had an estimated population of 712,327 in 2016. The city is included in the Front Range Urban Corridor, an oblong region of urban population along the Front Range of the Rocky Mountains in Colorado and Wyoming, generally following the path of Interstate 25 in both states.\n\nThe city covers , making it the most extensive municipality in Colorado. Colorado Springs was ranked number five by U.S. News & World Report on the list of 2016 Best Places to Live in the USA.\nThe Ute, Arapaho and Cheyenne peoples were the first to inhabit the area which would become Colorado Springs. Part of the territory included in the United States' 1803 Louisiana Purchase, the current city area was designated part of the 1854 Kansas Territory. In 1859, after the first local settlement was established, it became part of the Jefferson Territory on October24 and of El Paso County on November28. Colorado City at the Front Range confluence of Fountain and Camp creeks was \"formally organized on August13, 1859\" during the Pike's Peak Gold Rush. It served as the capital of the Colorado Territory from November5, 1861, until August14, 1862, when the capital was moved to Denver.\nIn 1871 the Colorado Springs Company laid out the towns of La Font (later called Manitou Springs) and Fountain Colony, upstream and downstream respectively, of Colorado City. Within a year, Fountain Colony would be renamed \"Colorado Springs\", and was officially incorporated. The El Paso County seat shifted from Colorado City in 1873 to the Town of Colorado Springs. On December1, 1880, Colorado Springs expanded northward with two annexations. \n\nThe second period of annexations was during 188990, and included Seavey's Addition, West Colorado Springs, East End, and another North End addition. In 1891 the Broadmoor Land Company built the Broadmoor suburb, which included the Broadmoor Casino, and by December12, 1895, the city had \"four Mining Exchanges and 275 mining brokers.\" By 1898, the city was designated into quadrants by the north-south Cascade Avenue and the east-west Washington/Pike's Peak avenues.\n\nFrom 1899 to 1901 Tesla Experimental Station operated on Knob Hill, and aircraft flights to the Broadmoor's neighboring fields began in 1919. Alexander Airport north of the city opened in 1925, and in 1927 the original Colorado Springs Municipal Airport land was purchased east of the city.\nIn World War II the United States Army Air Forces leased land adjacent to the municipal airfield, naming it \"Peterson Field\" in December 1942. This was only one of several military presences in and around Colorado Springs during the war.\n\nIn November 1950, Ent Air Force Base was selected as the Cold War headquarters for Air Defense Command (ADC). The former WWII Army Air Base, Peterson Field, which had been inactivated at the end of the war, was re-opened in 1951 as a U.S. Air Force base. The 1950s through 1970s saw a continued expansion of the military presence in the area, with the establishment of NORAD's headquarters in the city, as well as the ADCOM headquarters.\n\nBetween 1965 and 1968 the University of Colorado Colorado Springs, Pikes Peak Community College and Colorado Technical University were established in or near the city. In 1977 most of the former Ent AFB became a US Olympic training center. The Libertarian Party was founded within the city in the 1970s.\n\nOn October 1, 1981, the Broadmoor Addition, Cheyenne Canon, Ivywild, Skyway, and Stratton Meadows were annexed after the Colorado Supreme Court \"overturned a district court decision that voided the annexation\". Further annexations expanding the city include the Nielson Addition and Vineyard Commerce Park Annexation in September 2008. \n\nThe city lies in a high desert with the Southern Rocky Mountains to the west, the Palmer Divide to the north, high plains further east, and high desert lands to the south when leaving Fountain and approaching Pueblo.\n\nAccording to the United States Census Bureau, the city has a total area of , of which is land and , or 0.19%, is water.\n\nColorado Springs has many features of a modern urban area, such as parks, bike trails, and urban open-area spaces. However, it is not exempt from problems that typically plague cities that experience tremendous growth, such as overcrowded roads and highways, crime, sprawl, and government budget issues. Many of the problems are indirectly or directly caused by the city's difficulty in coping with the large population growth experienced in the last twenty years, and the annexation of the Banning Lewis Ranch area to accommodate further population growth of 175,000 future residents.\n\nColorado Springs has a semi-arid climate (Köppen \"BSk\"), and its location just east of the Rocky Mountains affords it the rapid warming influence from chinook winds during winter but also subjects it to drastic day-to-day variability in weather conditions. The city has abundant sunshine year-round, averaging 243 sunny days per year, and receives approximately of annual precipitation. Due to unusually low precipitation for several years after flooding in 1999, Colorado Springs enacted lawn water restrictions in 2002. These were lifted in 2005.\n\nColorado Springs is one of the most active lightning strike areas in the United States. This natural phenomenon led Nikola Tesla to select Colorado Springs as the preferred location to build his lab and study electricity.\n\nWinters range from mild to moderately cold, with December, the coldest month, averaging ; historically January has been the coldest month, but, in recent years, December has had both lower daily maxima and minima. Typically, there are 5.2 nights with sub- lows and 23.6 days where the high does not rise above freezing, and extended sub-zero (°F) cold snaps are possible but infrequent.\n\nSnowfall is usually moderate and remains on the ground briefly because of direct sun, with the city receiving per season, although the mountains to the west often receive in excess of triple that amount; March is the snowiest month in the region, both by total accumulation and number of days with measurable snowfall. In addition, 8 of the top 10 heaviest 24-hour snowfalls have occurred from March to May. Summers are warm, with July, the warmest month, averaging , and 18 days of + highs annually. Due to the high elevation and aridity, nights are usually relatively cool and rarely does the low remain above . Dry weather generally prevails, but brief afternoon thunderstorms are common, especially in July and August when the city receives the majority of its annual rainfall, due to the North American Monsoon.\n\nThe first autumn freeze and the last freeze in the spring, on average, occur on October 2 and May 6, respectively; the average window for measurable snowfall (≥) is October 21 through April 25. Extreme temperatures range from on June 26, 2012 and most recently on June 21, 2016, down to on February 1, 1951 and December 9, 1919.\n\nAs of the 2010 census, the population of Colorado Springs was 416,427 (40th most populous U.S. city), and the population of the Colorado Springs Metropolitan Statistical Area was 645,613 in 2010 (84th most populous MSA), and the population of the Front Range Urban Corridor in Colorado was an estimated 4,166,855.\n\nAs of the April 2010 census: 78.8% White, 16.1% Hispanic or Latino (of any race), 6.3% Black or African American, 3.0% Asian, 1.0% Native American, 0.3% Native Hawaiian and Other Pacific Islander, \n5.5% Some other race, 5.1% Two or more races. Mexican Americans made up 14.6% of the city's population. The median age in the city was 35 years. Non-Hispanic Whites were 70.7% of the population, compared to 86.6% in 1970.\n\nColorado Springs' economy is driven primarily by the military, the high-tech industry, and tourism, in that order. The city is currently experiencing some growth mainly in the service sectors. The unemployment rate for the city as of October 2015 was 3.9% compared to 4.8% in October 2014 and 7.3% in November 2013 and compared to 3.8% for the state and 5.0% for the nation.\n\nThe defense industry plays a major role in the Colorado Springs economy, with some of the city's largest employers coming from the sector. A large segment of this industry is dedicated to the development and operation of various projects for missile defense. With its close ties to defense, the aerospace industry has also influenced the Colorado Springs economy.\n\nAlthough some defense corporations have left or downsized city campuses, a slight growth trend is still recorded. Significant defense corporations in the city include Boeing, General Dynamics, Harris Corporation, SAIC, ITT, L-3 Communications, Lockheed Martin, and Northrop Grumman. The Space Foundation is based in Colorado Springs.\n\nA large percentage of Colorado Springs' economy is based on manufacturing high tech and complex electronic equipment. The high tech sector in the Colorado Springs area has decreased its overall presence from 2000 to 2006 (from around 21,000 down to around 8,000), with notable reductions in information technology and complex electronic equipment. Due to a slowing in tourism, the high tech sector still remains second to the military in terms of total revenue generated and employment. Current trends project the high tech employment ratio will continue to decrease in the near future.\n\nHigh tech corporations with connections to the city include:\n\nVerizon Business, a telecommunications firm, had nearly 1300 employees in 2008. Hewlett-Packard has a large sales, support, and SAN storage engineering center for the computer industry.\n\nStorage Networking Industry Association is the home of the SNIA Technology Center. Agilent, spun off from HP in 1999 as an independent, publicly traded company. Intel had 250 employees in 2009. The facility is now used for the centralized unemployment and social services complex.\n\nBroadcom (formerly LSI Corporation) designs semiconductors and software that accelerate storage and networking in datacenters and mobile networks. Microchip Technology (formerly Atmel), is a chip fabrication organization. Cypress Semiconductor Colorado Design Center is a chip fabrication research and development site. The Apple Inc. facility was sold to Sanmina-SCI in 1996.\n\nThe city's location at the base of Pikes Peak and the Rocky Mountains makes it a popular tourism destination. Tourism is the third largest employer in the Pikes Peak region, accounting for more than 16,000 jobs. Nearly 5 million visitors come to the area annually, contributing $1.35 billion in revenue.\n\nColorado Springs has more than 55 attractions and activities in the area, including Garden of the Gods, United States Air Force Academy, the ANA Money Museum, Cheyenne Mountain Zoo, Colorado Springs Fine Arts Center, Old Colorado City and the U.S. Olympic Training Center.\n\nThe downtown Colorado Springs Visitor Information Center offers free area information to leisure and business travelers. The Cultural Office of the Pikes Peak Region (COPPeR), also located downtown, supports and advocates for the arts throughout the Pikes Peak Region. It operates the PeakRadar website to communicate city events.\n\nAlthough houses of worship of almost every major world religion can be found in the city, Colorado Springs has in particular attracted a large influx of Evangelical Christians and Christian organizations in recent years. At one time Colorado Springs was counted to be the national headquarters for 81 different religious organizations, earning the city the tongue-in-cheek nicknames \"the Evangelical Vatican\" and \"The Christian Mecca.\" Religious groups with regional or international headquarters in Colorado Springs include:\n\nAlthough Colorado voters approved Colorado Amendment 64, a constitutional amendment in 2013 legalizing retail sales of marijuana for recreational purposes, the Colorado Springs city council voted not to permit retail shops in the city, as was allowed in the amendment. Medical marijuana outlets continue to operate in Colorado Springs. As of 2015, there were 91 medical marijuana clinics in the city, which reported sales of $59.6 million in 2014, up 11 percent from the previous year but without recreational marijuana shops. On April 26, 2016 Colorado Springs city council decided to extend the current six-month moratorium to eighteen months with no new licenses to be granted until May 2017.\n\nColorado Springs has been the subject of or setting for many books, movies and television shows, and is a frequent backdrop for political thrillers and military-themed stories because of its many military installations and vital importance to the United States' continental defense. Notable television series using the city as a setting include \"Dr. Quinn, Medicine Woman\" and the \"Stargate\" series \"Stargate SG-1\", as well as the films \"WarGames\" and \"The Prestige\".\n\nIn a North Korean propaganda video released in April 2013, Colorado Springs was inexplicably singled out as one of four targets for a missile strike. The video failed to pinpoint Colorado Springs on the map, instead showing a spot somewhere in Louisiana.\n\nThe television show Homicide Hunter where Joseph Kenda recounts cases of homicide from his career is set in Colorado Springs.\n\nColorado Springs, dubbed Olympic City USA, is home to the United States Olympic Training Center and the headquarters of the United States Olympic Committee and the United States Anti-Doping Agency. In addition, 24 of the United States' national federations for individual Olympic sports have their headquarters in Colorado Springs, including: United States or USA bobsled, fencing, figure skating, basketball, boxing, cycling, judo, field hockey, hockey, swimming, shooting, table tennis, taekwondo, triathlon, volleyball, pentathlon, handball, and wrestling associations and organizations.\n\nFurther, over 50 national sports organizations (non-Olympic) headquarter in Colorado Springs. Among them, the National Strength and Conditioning Association, Sports Incubator, a host of non-Olympic Sports, and more.\n\nColorado Springs and Denver hosted the 1962 World Ice Hockey Championships.\n\nThe city has a particularly long association with the sport of figure skating, having hosted the U.S. Figure Skating Championships six times and the World Figure Skating Championships five times. It is home to the World Figure Skating Museum and Hall of Fame and the Broadmoor Skating Club, a notable training center for the sport. In recent years, the World Arena has hosted skating events such as Skate America and the Four Continents Figure Skating Championships.\n\nThe Pikes Peak International Hill Climb (PPIHC), also known as The Race to the Clouds, is an annual invitational automobile and motorcycle hill climb to the summit of Pikes Peak, every year on the last Sunday of June. The first running of the Pikes Peak Hill Climb was promoted by Spencer Penrose. Penrose had finished widening the narrow carriage road into a much wider \"Pikes Peak Highway.\" He decided to encourage tourists to visit by creating a race to the clouds.\n\nThe PPIHC takes place on a 12.42 mile (19.99 km) public toll-road boasting 156 turns, while competitors climb 4,720 ft. (1,440 m.) from the 9,390 ft. (2,862 m.) Start Line at Mile 7 marker on the Pikes Peak Highway to the 14,115 ft. (4,300 m) Finish Line at the mountain's summit. As the drivers climb toward the summit, the thin air slows reflexes and saps competitor's mental and muscle strength in addition to robbing internal combustion engines of up to 30% of the power they are capable of at the Start Line. Competitors and vehicles must be in top shape and condition simply to finish, let alone win.\n\nThe race is self-sanctioned and is the most diverse one day motorsports event in the world with everything from Sidecars, Motorcycles, Semi-Trucks, and 1,400+hp EV & Unlimited Racers being able to compete in the same event. The highway wasn't completely paved until 2011.\n\nThe local colleges feature many sports teams. Notable among them are the following nationally competitive NCAA Division I teams: United States Air Force Academy (Falcons) Football, Basketball and Hockey, Colorado College (Tigers) Hockey, and Women's Soccer.\n\nThe Mountain West Conference and the National Collegiate Hockey Conference is based in Colorado Springs.\n\nColorado Springs is home to the Pro Rodeo Hall of Fame and the headquarters of the Professional Rodeo Cowboys Association.\n\nColorado Springs was the original headquarters of the Professional Bull Riders (PBR) from its founding in 1992 until 2005, when the organization was moved to Pueblo; the PBR used to hold an annual Built Ford Tough Series event at the World Arena from 2001 until 2005 when the organization made the move to Pueblo.\n\nThere are 136 neighborhood, 8 community, 7 regional parks and 5 sports complexes totaling 9,000 acres managed by the city's Parks, Recreation and Cultural Services. They also manage 500 acres of trails, which are 160 miles of park trails and 105 miles of urban trails. There are 5,000 acres of open spaces in 48 open space areas.\n\nOne of the most popular areas in Colorado Springs is the park on its western edge, Garden of the Gods, considered by many to be the most beautiful park in the world. It is a National Natural Landmark with 300 foot sandstone rock formations often viewed against a backdrop of the snow-capped mountains of Pikes Peak. The park offers a variety of annual events, one of the most popular of which is the Starlight Spectacular; a recreational bike ride held every summer to benefit the Trails and Open Space Coalition of Colorado Springs.\n\nColorado Springs has several major parks, such as Palmer Park, America the Beautiful Park (Confluence Park), Memorial Park, and Monument Valley Park. The Austin Bluffs Park also affords a place of recreation in eastern Colorado Springs.\n\nThree trails, the New Santa Fe Regional Trail, Pikes Peak Greenway and Fountain Creek Regional Trail, form a continuous path from Palmer Lake, through Colorado Springs, to Fountain, Colorado. The majority of the trail between Palmer Lake and Fountain is a soft surface breeze gravel trail. A major segment of the trail within the Colorado Springs city limits is paved.\n\nThe Urban Trail system \"within Colorado Springs\" consists of more than 110 miles of multi-use trail for biking, jogging, roller blading and walking.\n\nThe trails, except Monument Valley Park trails, may be used for equestrian traffic. Motorized vehicles are not allowed on the trails. Many of the trails are interconnected, having main \"spine\" trails, like the Pikes Peak Greenway, that lead to secondary trails.\n\nOn November 2, 2010, Colorado Springs voters adopted a council-strong mayor form of government. The City of Colorado Springs transitioned to the new system of government in 2011. Under the council-strong mayor system of government, the mayor is the chief executive and the city council is the legislative branch. The mayor is a full-time elected position and not a member of the city council. The city council has nine members total, six of which represent one of six equally populated districts each. The remaining three members are elected \"at-large\". The mayor has veto authority, with the city council having the ability to override a mayoral veto by a two-thirds majority vote (6 out of 9).\n\nColorado Springs City Hall was built from 1902 to 1904 on land donated by W. S. Stratton.\n\n\nPublic schools\nThe city's public schools are divided into several districts: \n\nPrivate schools\nBachelors and graduate degree programs are offered at these colleges and universities in the city:\n\nThe United States Air Force Academy is a military school for officer candidates.\n\nIntelliTec College is a technical training school. Pikes Peak Community College offers a two-year degree program.\n\nIn March 2016 there were six newspapers actively publishing in Colorado Springs including the newspaper with the largest circulation in the state. Colorado-Pueblo MSA is the 90th largest broadcast market in the USA. There are 24 digital television stations in Colorado Springs and 34 radio stations.\n\nColorado Springs is primarily served by two interstate highways. I-25 runs north and south through Colorado, and traverses the city for nearly , entering the city south of Circle Drive and exiting north of North Gate Blvd. In El Paso County it is known as Ronald Reagan Highway. US 24 runs across the central mountains, through the city, and onto the plains. From west to east in Colorado Springs, US 24 follows the western portion of Cimarron Street and the Midland Expressway, a 2-mile concurrent section with I-25/US 87 between exits 139 and 141, part of Fountain Blvd, an expressway called the Martin Luther King Bypass, part of South Powers Blvd (where it is concurrent with Colorado 21), and the easternmost portion of Platte Avenue out of the city.\n\nA number of state highways serve the city. State Highway 21 is a major east side semi-expressway from Black Forest to Fountain. It is widely known as Powers Boulevard. State Highway 83 runs north-south from Denver to northern Colorado Springs. State Highway 94 runs east-west from western Cheyenne County to eastern Colorado Springs. State Highway 115 begins in Cañon City and runs up Nevada Avenue. US 85 and SH 115 are concurrent between Lake Avenue and I-25. US 85 enters the city at Fountain and was signed at Venetucci Blvd, Lake Avenue, and Nevada Avenue.\n\nIn November 2015, voters in Colorado Springs overwhelmingly passed ballot measure 2C, dedicating funds from a temporary sales tax increase to much needed road and infrastructure improvements over five years. This temporary increase is estimated to bring in approximately $50M annually, which will be used solely to improve roads and infrastructure. The Ballot measure passed by a margin of approximately 65%-35%, and was championed by newly elected Mayor John Suthers.\n\nIn 2004, the voters of Colorado Springs and El Paso County established the Pikes Peak Rural Transportation Authority and adopted a 1% sales tax dedicated to improving the region's transportation infrastructure. Together with state funding for the Colorado Springs Metro Interstate Expansion (COSMIX) (2007 completion) and the I-25 interchange with Highway 16 (2008 completion), significant progress has been made since 2003 in addressing the transportation needs of the area.\n\nIn early 2010, the city of Colorado Springs approved an expansion of the northernmost part of Powers Boulevard in order to create an Interstate 25 bypass commonly referred to as the Copper Ridge Expansion.\n\nA 2011 study by Walk Score ranked Colorado Springs 34th most walkable of fifty largest U.S. cities.\n\nMountain Metropolitan Transit (MMT) is the primary source of clean, safe, and economical public transportation services in the Pikes Peak region providing over 11,000 one-way trips per day. In addition to bus routes within the City of Colorado Springs, Mountain Metro Transit provides service into Manitou Springs, north to the Chapel Hills Mall, east to Peterson Air Force Base and south into the Widefield area.\n\nMountain Metro Mobility is an Americans with Disabilities Act (ADA) federally mandated complementary ADA paratransit service, which provides demand-response service for individuals with mobility needs that prevent them from using the fixed-route bus system.\n\nMountain Metro Rides offers alternative transportation options to residents of the Pikes Peak Region. The program is designed to reduce congestion and pollution by encouraging people to commute by carpool, vanpool, bicycling or walking.\n\nSister cities of Colorado Springs include:\n\nColorado Springs' sister city organization began when Colorado Springs became partners with Fujiyoshida. The \"torii\" gate erected to commemorate the relationship stands at the corner of Bijou Street and Nevada Avenue, and is one of the city's most recognizable landmarks. The \"torii\" gate, crisscrossed bridge and shrine, located in the median between Platte and Bijou Streets in downtown Colorado Springs, were a gift to Colorado Springs, erected in 1966 by the Rotary Club of Colorado Springs to celebrate the friendship between the two communities. A plaque near the \"torii\" gate states that \"the purpose of the sister city relationship is to promote understanding between the people of our two countries and cities\". The Fujiyoshida Student exchange program has become an annual event.\n\nTo strengthen relations between the two cities, the Colorado Springs Youth Symphony regularly invites the Taiko drummers from the city to participate in a joint concert in the Pikes Peak Center. The orchestra played in Bankstown, Australia, in 2002 and again in June 2006 as part of their tours to Australia and New Zealand.\n\nAlso, in 2006 and 2010, the Bankstown TAP (Talent Advancement Program), performed with the Youth Symphony, and the Colorado Springs Children's Chorale, as a part of the annual \"In Harmony\" program.\n\nA notable similarity between Colorado Springs and its sister cities are their geographic positions: three of the seven cities are also located near the base of a major mountain or mountain range.\n\n\n", "id": "6250", "title": "Colorado Springs, Colorado"}
{"url": "https://en.wikipedia.org/wiki?curid=6251", "text": "Professional certification\n\nProfessional certification, trade certification, or professional designation, often called simply \"certification\" or \"qualification\", is a designation earned by a person to assure qualification to perform a job or task. Not all certifications that use post-nominal letters are an acknowledgement of educational achievement, or an agency appointed to safeguard the public interest.\n\nCertifications are earned from a professional society, university, a certification body, or from a private certifier, for some specific certifications (e.g., Microsoft, Cisco, etc.). Some certifications must be renewed periodically, or may be valid for a specific period of time (e.g., the lifetime of the product upon which the individual is certified). As a part of a complete renewal of an individual's certification, it is common for the individual to show evidence of continued learning—often falsely termed continuing education—or earning continuing education units (CEU).\n\nMany certification programs are created, sponsored, or affiliated with professional associations, trade organizations, or private vendors interested in raising standards. Many of those programs completely independent from membership organizations enjoy association support and endorsement.\n\nCertifications are usually earned from a professional society or educational institute, not the government. However, a government agency can decree a certification is required \"by law\" for a person to be allowed to perform a task or job. Certification is different from professional licensure. In the United States, professional licenses are usually issued by state agencies, having as a requirement the university title for that profession. In other countries, licensing is granted by the professional society or college, but you need to certificate after some years (usually three to five) and so on thereafter. The certification assessment process, for some organizations, is very similar or even the same as licensure and may differ only in terms of legal status, while in other organizations, can be quite different and more comprehensive than that of licensure.\n\nThe American National Standards Institute (ANSI), Standard 1100, defines the requirements of meeting the ANSI standard for being a certifying organization. According to ANSI Standard 1100, a professional certifying organization must meet two requirements:\n\nCertifications are very common in aviation, construction, technology, environment, and other industrial sectors, as well as health care, business, Real estate broker and finance. In the United States, the Federal Aviation Administration regulates aviator certifications.\n\nThe Institute for Credentialing Excellence (ICE) is a U.S.-based organization that sets rigorous standards for accreditation of certification programs based on the Standards for Educational and Psychological Testing (APA, AERA, NCME). Many members of the Association of Test Publishers (ATP) are also certification organizations.\n\nThere are three general types of certification. Listed in order of development level and portability, they are: corporate (internal), product-specific, and profession-wide.\n\nCorporate, or \"internal\" certifications, are made by a corporation or low-stakes organization for internal purposes. For example, a corporation might require a one-day training course for all sales personnel, after which they receive a certificate. While this certificate has limited portability – to other corporations, for example – it is the most simple to develop.\n\nProduct-specific certifications are more involved, and are intended to be referenced to a product across all applications. This approach is very prevalent in the information technology (IT) industry, where personnel are certified on a version of software or hardware. This type of certification is portable across locations (for example, different corporations that use that software), but not across other products. Another example could be the certifications issued for shipping personnel, which are under international standards even for the recognition of the certification body, under the International Maritime Organization (IMO).\n\nThe most general type of certification is profession-wide. Certification in the medical profession is often offered by particular specialties. In order to apply professional standards, increase the level of practice, and protect the public, a professional organization might establish a certification. This is intended to be portable to all places a certified professional might work. Of course, this generalization increases the cost of such a program; the process to establish a legally defensible assessment of an entire profession is very extensive. An example of this is a Certified Public Accountant (CPA), which would not be certified for just one corporation or one piece of accountancy software but for general work in the profession.\n\nMany universities grant professional certificates as an award for the completion of an educational program. The curriculum of a professional certificate is most often in a focused subject matter. Many professional certificates have the same curriculum as master's degrees in the same subject. Many other professional certificates offer the same courses as master's degrees in the same subject, but require the student to take fewer total courses to complete the program. Some professional certificates have a curriculum that more closely resembles a baccalaureate major in the same field. The typical professional certificate program is between 200-300 class-hours in size. It is uncommon for a program to be larger or smaller than that. Most professional certificate programs are open enrollment, but some have admissions processes. A few universities put some of their professional certificates into a subclass they refer to as advanced professional certificates.\n\nSome of the more commonly offered professional certificates include:\n\n\"Advanced professional certificates\" are professional credentials designed to help professionals enhance their job performance and marketability in their respective fields. In many other countries, certificates are qualifications in higher education. In the United States, a certificate may be offered by an institute of higher education. These certificates usually signify that a student has reached a standard of knowledge of a certain vocational subject. Certificate programs can be completed more quickly than associate degrees and often do not have general education requirements.\n\nAn advanced professional certificate is a result of an educational process designed for individuals. Certificates are designed for both newcomers to the industry as well as seasoned professionals. Certificates are awarded by an educational program or academic institution. Completion of a certificate program indicates completion of a course or series of courses with a specific concentration that is different from an educational degree program. Course content for an advanced certificate is set forth through a variety of sources i.e. faculty, committee, instructors, and other subject matter experts in a related field. The end goal of an advanced professional certificate is so that professionals may demonstrate knowledge of course content at the end of a set period in time.\n\nInstitutions that offer advance professional certificates in various fields and industries include:\n\nThere are many professional bodies for accountants and auditors throughout the world; some of them are legally recognized in their jurisdictions.\nPublic accountants are the accountancy and control experts that are legally certified in different jurisdictions to work in public practices, certifying accounts as statutory auditors, eventually selling advice and services to other individuals and businesses. Today, however, many work within private corporations, financial industry, and government bodies.\n\nCf. Accountancy qualifications and regulation\n\n\nIn 1951, the International Association of Administrative Professionals (IAAP) administered the first Certified Professional Secretary (CPS) exam, which has evolved through the years into a four-part certification test called the Certified Administrative Professional - Organizational Management (CAP-OM). IAAP also offers the Certified Administrative Professional - Technology Applications (CAP-TA) exam, focusing on the Microsoft Office suite of products. Depending upon an individual's level of higher education, an applicant needs between two and four years of verifiable working experience as an administrative professional to sit for the exams.\n\n\n\n\n\n\n\nAviators are certified through theoretical and in-flight examinations. Requirements for certifications are quite equal in most countries and are regulated by each National Aviation Authority. The existing certificates or pilot licenses are:\n\nLicensing in these categories require not only examinations but also a minimum number of flight hours. All categories are available for Fixed-Wing Aircraft (airplanes) and Rotatory-Wing Aircraft (helicopters). Within each category, aviators may also obtain certifications in:\nUsually, aviators must be certified also in their log books for the type and model of aircraft they are allowed to fly. Currency checks as well as regular medical check-ups with a frequency of 6 months, 12 months, or 36 months, depending on the type of flying permitted, are obligatory. An aviator can fly only if holding:\n\nIn Europe, the ANSP, ATCO & ANSP technicians are certified according to ESARRs (according to EU regulation 2096/2005 \"Common Requirements\").\n\n\nIn the United States, several communications certifications are conferred by the Electronics Technicians Association.\n\nCertification is often used in the professions of software engineering and information technology.\n\nIn the U.S., CERA (Certified Elections/Registration Administrator) is the highest level of certification available for election administrators. It is conferred by the National Association of Election Officials.\n\nIn the United States, several electronics certifications are provided by the Electronics Technicians Association.\n\nThe Federal Emergency Management Agency's EMI offers credentials and training opportunities for United States Citizens. Note that students do not have to be employed by FEMA or be a federal employee for some of the programs.\n\nProfessional Engineering is any act of planning, designing, composing, measuring, evaluating, inspecting, advising, reporting, directing or supervising, or managing any of the foregoing, that requires the application of engineering principles and that concerns the safeguarding of life, health, property, economic interests, the public interest or the environment.\n\nFacility management can be defined as an aspect of engineering management science that deals with the planning, designing, coordination of space and maintenance of a built environment to enhance quality service management system. Service Quality System includes activities like security, maintenance, catering, and external as well as internal cleaning. In general, it is also the coordination and harmonization of various specialist disciplines to create the best possible working environment for staff.\n\nFacility management is an interdisciplinary field devoted to the coordination of space, infrastructure, people and organization, often associated with the administration of office blocks, arenas, schools, convention centers, shopping complexes, hospitals, hotels, etc. However, FM facilitates on a wider range of activities than just business services and these are referred to as non-core functions.\n\n\nA warehouse management system (WMS) is a key part of the supply chain and primarily aims to control the movement and storage of materials within a warehouse and process the associated transactions, including shipping, receiving, putaway and picking. The systems also direct and optimize stock putaway based on real-time information about the status of bin utilization. A WMS monitors the progress of products through the warehouse. It involves the physical warehouse infrastructure, tracking systems, and communication between product stations.\n\nMore precisely, warehouse management involves the receipt, storage and movement of goods, (normally finished goods), to intermediate storage locations or to a final customer. In the multi-echelon model for distribution, there may be multiple levels of warehouses. This includes a central warehouse, a regional warehouses (serviced by the central warehouse) and potentially retail warehouses (serviced by the regional warehouses).\n\n\n\n\n\n\nIECEx IEC System for Certification to Standards Relating to Equipment for Use in Explosive Atmospheres covers the highly specialized field of explosion protection associated with the use of equipment in areas where flammable gases, liquids and combustible dusts may be present. This System provides the assurance that equipment is manufactured to meet safety standards, and that services such as installation, repair and overhaul also comply with IEC International Standards on safety. The United Nations, via UNECE (United Nations Economic Commission for Europe), recommends the IEC and IECEx as the world’s best practice model for the verification of conformity to International Standards. It published a “Common Regulatory Framework” encompassing the use of IEC International Standards developed by IEC TC (Technical Committee) 31: Equipment for explosive atmospheres, with proof of compliance demonstrated by IECEx.\n\n\nAG (Accredited Genealogist) conferred by the International Commission for the Accreditation of Professional Genealogists (ICAPGen).\nCG (Certified Genealogist) conferred by the Board for Certification of Genealogists (BCG).\nCGL (Certified Genealogical Lecturer) conferred by the Board for Certification of Genealogists (BCG).\n\n\n\n\n\n\n\n\nIn the United States, insurance professionals are licensed separately by each state. Many individuals seek one or more certifications to distinguish themselves from their peers. The most recognizable certifications are issued by five organizations:\n\nAmerican Institute For Chartered Property Casualty Underwriters (AICPCU)\n\nAmerican College of Financial Services\n\nInternational Center for Captive Insurance Education (ICCIE)\n\nNational Alliance for Insurance Education & Research\n\nNational Association of Insurance and Financial Advisors in partnership with the College of Financial Planning\n\nNational Association of Mutual Insurance Companies\n\nNational Registry of Workers' Compensation Specialists\n\nProfessional Liability Underwriting Society (PLUS)\n\nTESOL is a large field of employment with widely varying degrees of regulation. Most provision worldwide is through the state school system of each individual country, and as such, the instructors tend to be trained primary- or secondary school teachers who are native speakers of the language of their pupils, and not of English. Though native speakers of English have been working in non-English speaking countries in this capacity for years, it was not until the last twenty-five years or so that there was any widespread focus on training particularly for this field. Previously, workers in this sort of job were anyone from backpackers hoping to earn some extra travel money to well-educated professionals in other fields doing volunteer work, or retired people. These sort of people are certainly still to be found, but there are many who consider TESOL their main profession.\n\nOne of the problems facing these full-time teachers is the absence of an international governing body for the certification or licensure of English language teachers. However, Cambridge University and its subsidiary body UCLES are pioneers in trying to get some degree of accountability and quality control to consumers of English courses, through their CELTA and DELTA programs. Trinity College London has equivalent programs, the CertTESOL and the LTCL DipTESOL. They offer initial certificates in teaching, in which candidates are trained in language awareness and classroom techniques, and given a chance to practice teaching, after which feedback is reported. Both institutions have as a follow-up a professional diploma, usually taken after a year or two in the field. Although the initial certificate is available to anyone with a high school education, the diploma is meant to be a post-graduate qualification and in fact can be incorporated into a master's degree program.\n\nAn increasing number of attorneys are choosing to be recognized as having special expertise in certain fields of law. According to the American Bar Association, a lawyer who is a certified specialist has been recognized by an independent professional certifying organization as having an enhanced level of skill and expertise, as well as substantial involvement in an established legal specialty. These organizations require a lawyer to demonstrate special training, experience and knowledge to ensure that the lawyer's recognition is meaningful and reliable. Lawyer conduct with regard to specialty certification is regulated by the states.\n\nNBLSC is an American Bar Association (ABA) accredited organization providing Board Certification for US Lawyers. Board Certification is a rigorous testing and approval process that officially recognizes the extensive education and courtroom experience of attorneys. NBLSC provides Board Certification for Trial Lawyers & Trial Attorneys, Civil Lawyers, Criminal Lawyers, Family Lawyers and Social Security Disability Lawyers.\n\nLogistician is the Profession in the logistics & transport sectors, including sea, air, land and rail modes. Professional qualification for logisticians usually carries post-nominal letters. Common examples include:\n (CSCB),\n\n\n\nChurches have their own process of who may use various religious titles. Protestant churches typically require a Masters of Divinity, accreditation by the denomination and ordination by the local church in order for a minister to become a \"Reverend\". Those qualifications may or may not also give government authorization to solemnize marriages\n\nBoard certification is the process by which a physician in the United States documents by written, practical or computer based testing, illustrating a mastery of knowledge and skills that define a particular area of medical specialization. The American Board of Medical Specialties, a not-for-profit organization, assists 24 approved medical specialty boards in the development and use of standards in the ongoing evaluation and certification of physicians.\n\nMedical specialty certification in the United States is a voluntary process. While medical licensure sets the minimum competency requirements to diagnose and treat patients, it is not specialty specific. Board certification demonstrates a physician’s exceptional expertise in a particular specialty or sub-specialty of medical practice.\n\nPatients, physicians, health care providers, insurers and quality organizations regard certification as an important measure of a physician’s knowledge, experience and skills to provide quality health care within a given specialty.\n\nOther professional certifications include certifications such as medical licenses, Membership of the Royal College of Physicians, Fellowship of the Royal College of Physicians and Surgeons of Canada, nursing board certification, diplomas in social work. The Commission for Certification in Geriatric Pharmacy certifies pharmacists that are knowledgeable about principles of geriatric pharmacotherapy and the provision of pharmaceutical care to the elderly. Additional certifying bodies relating to the medical field include:\n\n\n\nNCPRP stands for “National Certified Peer Recovery Professional”, and the NCPRP credential and exam were developed in collaboration with the International Certification Board of Recovery Professionals (ICBRP) and is currently being administered by PARfessionals.\n\nPARfessionals is a professional organization and all of the available courses are professional development and pre-certification courses.\n\nThe NCPRP credential and exam focus primarily on the concept of peer recovery through mental health and addiction recovery. It has the main purpose of training student-candidates on how to become peer recovery professionals who can provide guidance, knowledge or assistance for individuals who have had similar experiences.\n\nThrough the support of the SJM Family Foundation, PARfessionals has developed the first globally recognized online training program for peer recovery professionals.\n\nEach student-candidate must complete several key steps which include initial registration; the pre-certification review course; and all applicable sections of the official application in order to become eligible to complete the final step, which is the NCPRP certification exam.\n\nThe NCPRP credential is obtained once a participant successfully passes the NCPRP certification exam by the second attempt and is valid for five years.\n\n\n\nCertification is of significant importance in the project management (PM) industry. Certification refers to the evaluation and recognition of the skills, knowledge and competence of a practitioner in the field.\n\nProject management certifications come in a variety of flavors:\n\nCombination of Competence-based, Knowledge-based, and Experience-based\n\nKnowledge-based\n\nThere are 15 professional associations from around the world offering the ' Accredited in Public Relations (APR) designation and one offering the 'Accredited Business Communicator (ABC) designation. \n\n\n\n\n\n\n\nCustomer relationship management (CRM) is a system for managing a company’s interactions with current and future customers. It often involves using technology to organize, automate and synchronize sales, marketing, customer service, and technical support.\n\n\n\nConferred by the National Speakers Association, the Certified Speaking Professional® (CSP) is the speaking profession's international measure of professional platform competence. This certification is awarded by the National Speakers Association Only about 10% of the speakers who belong to the Global Speakers Federation (GSF) hold this designation. Those who have earned their certification have done so by demonstrating a track record of experience and expertise.\n\nSupply chain management (SCM) is the management of the flow of goods. It includes the movement and storage of raw materials, work-in-process inventory, and finished goods from point of origin to point of consumption. Interconnected or interlinked networks, channels and node businesses are involved in the provision of products and services required by end customers in a supply chain.[2] Supply chain management has been defined as the \"design, planning, execution, control, and monitoring of supply chain activities with the objective of creating net value, building a competitive infrastructure, leveraging worldwide logistics, synchronizing supply with demand and measuring performance globally.\n\nSCM draws heavily from the areas of operations management, logistics, procurement, and information technology, and strives for an integrated approach.\n\n\nAustralian Institute of Certified Practising Trainers administers the Certified Practising Trainer (CPT).\nConferred by the Australian Institute of Certified Practising Trainers, this certification is the hallmark for professional trainers.\n\n\nMany political commentators, often criticize professional or occupational licensing, especially medical and legal licensing, for restricting the supply of services and therefore making them more expensive, often putting them out of reach of the poor.\n\nThe current proliferation of IT certifications (both offered and attained), like the FSI's IT baseline protection certification, has led some technologists to question their value. Proprietary content that has been distributed on the Internet allows some to gain credentials without the implied depth or breadth of expertise. Certifying agencies have responded in various ways: Some now incorporate hands-on elements, anti-cheating methodologies or have expanded their content. Others have expired and restructured their certificate programs or raised their fees to deter abuse.\n\nCertification programs that take into account length of service and demonstrated experience via industry peer and employer recommendation avoid some of the issues associated with purely passing an examination; however, certification remains a contentious issue.\n\nAlso, some professional certifications require a criminal record check before the certification can be approved. The presence of a criminal history when applying for certification may be grounds for denial of certification.\n\n\n", "id": "6251", "title": "Professional certification"}
{"url": "https://en.wikipedia.org/wiki?curid=6255", "text": "Carl Menger\n\nCarl Menger (; February 23, 1840 – February 26, 1921) was an Austrian economist and the founder of the Austrian School of economics. Menger contributed to the development of the theory of marginalism, (marginal utility), which rejected the cost-of-production theories of value, such as were developed by the classical economists such as Adam Smith and David Ricardo. Menger used his “Subjective Theory of Value” to arrive at what he considered one of the most powerful insights in economics: both sides gain from exchange.\n\nMenger was born in the city of Neu-Sandez in Austrian Galicia, which is now Nowy Sącz in Poland. He was the son of a wealthy family of minor nobility; his father, Anton, was a lawyer. His mother, Caroline, was the daughter of a wealthy Bohemian merchant. He had two brothers, Anton and Max, both prominent as lawyers. His son, Karl Menger, was a mathematician who taught for many years at Illinois Institute of Technology.\n\nAfter attending \"Gymnasium\" he studied law at the Universities of Prague and Vienna and later received a doctorate in jurisprudence from the Jagiellonian University in Kraków. In the 1860s Menger left school and enjoyed a stint as a journalist reporting and analyzing market news, first at the \"Lemberger Zeitung\" in Lwów, Ukraine and later at the \"Wiener Zeitung\" in Vienna.\n\nDuring the course of his newspaper work he noticed a discrepancy between what the classical economics he was taught in school said about price determination and what real world market participants believed. In 1867 Menger began a study of political economy which culminated in 1871 with the publication of his \"Principles of Economics\" \"(Grundsätze der Volkswirtschaftslehre),\" thus becoming the father of the Austrian School of economic thought. It was in this work that he challenged classical cost-based theories of value with his theory of marginality – that price is determined at the margin.\n\nIn 1872 Menger was enrolled into the law faculty at the University of Vienna and spent the next several years teaching finance and political economy both in seminars and lectures to a growing number of students. In 1873 he received the university's chair of economic theory at the very young age of 33.\n\nIn 1876 Menger began tutoring Archduke Rudolf von Habsburg, the Crown Prince of Austria in political economy and statistics. For two years Menger accompanied the prince in his travels, first through continental Europe and then later through the British Isles. He is also thought to have assisted the crown prince in the composition of a pamphlet, published anonymously in 1878, which was highly critical of the higher Austrian aristocracy. His association with the prince would last until Rudolf's suicide in 1889 (see the Mayerling Affair).\n\nIn 1878 Rudolf's father, Emperor Franz Josef, appointed Menger to the chair of political economy at Vienna. The title of \"Hofrat\" was conferred on him, and he was appointed to the Austrian \"Herrenhaus\" in 1900.\n\nEnsconced in his professorship he set about refining and defending the positions he took and methods he utilized in \"Principles,\" the result of which was the 1883 publication of \"Investigations into the Method of the Social Sciences with Special Reference to Economics (Untersuchungen über die Methode der Socialwissenschaften und der politischen Oekonomie insbesondere).\" The book caused a firestorm of debate, during which members of the Historical school of economics began to derisively call Menger and his students the \"Austrian School\" to emphasize their departure from mainstream economic thought in Germany – the term was specifically used in an unfavorable review by Gustav von Schmoller.\n\nIn 1884 Menger responded with the pamphlet \"The Errors of Historicism in German Economics\" and launched the infamous \"Methodenstreit,\" or methodological debate, between the Historical School and the Austrian School. During this time Menger began to attract like-minded disciples who would go on to make their own mark on the field of economics, most notably Eugen von Böhm-Bawerk, and Friedrich von Wieser.\n\nIn the late 1880s Menger was appointed to head a commission to reform the Austrian monetary system. Over the course of the next decade he authored a plethora of articles which would revolutionize monetary theory, including \"The Theory of Capital\" (1888) and \"Money\" (1892). Largely due to his pessimism about the state of German scholarship, Menger resigned his professorship in 1903 to concentrate on study.\n\nMenger used his “Subjective Theory of Value” to arrive at what he considered one of the most powerful insights in economics: both sides gain from exchange.\nUnlike William Jevons, Menger did not believe that goods provide “utils,” or units of utility. Rather, he wrote, goods are valuable because they serve various uses whose importance differs. Menger also came up with an explanation of how money develops that is still accepted by some schools of thought today.\n\n\n\n", "id": "6255", "title": "Carl Menger"}
{"url": "https://en.wikipedia.org/wiki?curid=6256", "text": "List of cartoonists\n\nThis is a list of cartoonists, visual artists who specialize in drawing cartoons. This list includes only notable cartoonists and is not meant to be exhaustive.\n", "id": "6256", "title": "List of cartoonists"}
{"url": "https://en.wikipedia.org/wiki?curid=6258", "text": "Civilization\n\nA civilization (UK and US) or civilisation (British English variant) is any complex society characterized by urban development, social stratification, symbolic communication forms (typically, writing systems) and a perceived separation from and domination over the natural environment by a cultural elite.\n\nCivilizations are intimately associated with and often further defined by other socio-politico-economic characteristics, including centralization, the domestication of both humans and other organisms, specialization of labour, culturally ingrained ideologies of progress and supremacism, monumental architecture, taxation, societal dependence upon farming as an agricultural practice and expansionism. Historically, a civilization was a so-called \"advanced\" culture in contrast to more supposedly primitive cultures. In this broad sense, a civilization contrasts with non-centralized tribal societies, including the cultures of nomadic pastoralists, egalitarian horticultural subsistence neolithic societies or hunter-gatherers. As an uncountable noun, civilization also refers to the process of a society developing into a centralized, urbanized, stratified structure. Civilizations are organized in densely populated settlements divided into hierarchical social classes with a ruling elite and subordinate urban and rural populations, which engage in intensive agriculture, mining, small-scale manufacture and trade. Civilization concentrates power, extending human control over the rest of nature, including over other human beings.\n\nThe earliest emergence of civilizations is generally associated with the final stages of the Neolithic Revolution, culminating in the relatively rapid process of urban revolution and state formation, a political development associated with the appearance of a governing elite. The earlier neolithic technology and lifestyle was established first in the Middle East (for example at Göbekli Tepe, from about 9,130 BCE), and later in the Yangtze and Yellow River basins in China (for example the Pengtoushan culture from 7,500 BCE), and later spread. Similar pre-civilized \"neolithic revolutions\" also began independently from 7,000 BCE in such places as northwestern South America (the Norte Chico civilization) and Mesoamerica. These were among the six civilizations worldwide that arose independently. Mesopotamia is the site of the earliest developments of the Neolithic Revolution from around 10,000 BCE, with civilizations developing from 6,500 years ago. This area has been identified as having \"inspired some of the most important developments in human history including the invention of the wheel, the development of cursive script, mathematics, astronomy and agriculture.\"\n\nThe civilized urban revolution in turn was dependent upon the development of sedentarism, the domestication of grains and animals and development of lifestyles that facilitated economies of scale and accumulation of surplus production by certain social sectors. The transition from \"complex cultures\" to \"civilizations\", while still disputed, seems to be associated with the development of state structures, in which power was further monopolized by an elite ruling class who practised human sacrifice. Towards the end of the Neolithic period, various elitist Chalcolithic civilizations began to rise in various \"cradles\" from around 3300 BCE. Chalcolithic civilizations, as defined above, also developed in Pre-Columbian Americas and, despite an early start in Egypt, Axum and Kush, much later in Iron Age sub-Saharan Africa. The Bronze Age collapse was followed by the Iron Age around 1200 BCE, during which a number of new civilizations emerged, culminating in a period from the 8th to the 3rd century BCE which German psychiatrist and philosopher Karl Jaspers termed the Axial Age, and which he claimed was a critical transitional phase leading to Classical civilization. A major technological and cultural transition to modernity began approximately 1500 CE in Western Europe, and from this beginning new approaches to science and law spread rapidly around the world, incorporating earlier cultures into the industrial and technological civilization of the present.\n\nThe English word \"civilization\" comes from the 16th-century French \"civilisé\" (\"civilized\"), from Latin \"civilis\" (\"civil\"), related to \"civis\" (\"citizen\") and \"civitas\" (\"city\"). The fundamental treatise is Norbert Elias's \"The Civilizing Process\" (1939), which traces social mores from medieval courtly society to the Early Modern period. In \"The Philosophy of Civilization\" (1923), Albert Schweitzer outlines two opinions: one purely material and the other material and ethical. He said that the world crisis was from humanity losing the ethical idea of civilization, \"the sum total of all progress made by man in every sphere of action and from every point of view in so far as the progress helps towards the spiritual perfecting of individuals as the progress of all progress\".\n\nAdjectives like \"civility\" developed in the mid-16th century. The abstract noun \"civilization\", meaning \"civilized condition\", came in the 1760s, again from French. The first known use in French is in 1757, by Victor Riqueti, marquis de Mirabeau, and the first use in English is attributed to Adam Ferguson, who in his 1767 \"Essay on the History of Civil Society\" wrote, \"Not only the individual advances from infancy to manhood, but the species itself from rudeness to civilisation\". The word was therefore opposed to barbarism or rudeness, in the active pursuit of progress characteristic of the Age of Enlightenment.\n\nIn the late 1700s and early 1800s, during the French revolution, \"civilization\" was used in the singular, never in the plural, and meant the progress of humanity as a whole. This is still the case in French. The use of \"civilizations\" as a countable noun was in occasional use in the 19th century, but has become much more common in the later 20th century, sometimes just meaning culture (itself in origin an uncountable noun, made countable in the context of ethnography). Only in this generalized sense does it become possible to speak of a \"medieval civilization\", which in Elias's sense would have been an oxymoron.\n\nAlready in the 18th century, civilization was not always seen as an improvement. One historically important distinction between culture and civilization is from the writings of Rousseau, particularly his work about education, \"\". Here, civilization, being more rational and socially driven, is not fully in accord with human nature, and \"human wholeness is achievable only through the recovery of or approximation to an original prediscursive or prerational natural unity\" (see noble savage). From this, a new approach was developed, especially in Germany, first by Johann Gottfried Herder, and later by philosophers such as Kierkegaard and Nietzsche. This sees cultures as natural organisms, not defined by \"conscious, rational, deliberative acts\", but a kind of pre-rational \"folk spirit\". Civilization, in contrast, though more rational and more successful in material progress, is unnatural and leads to \"vices of social life\" such as guile, hypocrisy, envy and avarice. In World War II, Leo Strauss, having fled Germany, argued in New York that this opinion of civilization was behind Nazism and German militarism and nihilism.\n\nSocial scientists such as V. Gordon Childe have named a number of traits that distinguish a civilization from other kinds of society. Civilizations have been distinguished by their means of subsistence, types of livelihood, settlement patterns, forms of government, social stratification, economic systems, literacy and other cultural traits. Andrew Nikiforuk argues that \"civilizations relied on shackled human muscle. It took the energy of slaves to plant crops, clothe emperors, and build cities\" and considers slavery to be a common feature of pre-modern civilizations.\n\nAll civilizations have depended on agriculture for subsistence. Grain farms can result in accumulated storage and a surplus of food, particularly when people use intensive agricultural techniques such as artificial fertilization, irrigation and crop rotation. It is possible but more difficult to accumulate horticultural production, and so civilizations based on horticultural gardening have been very rare. Grain surpluses have been especially important because they can be stored for a long time. A surplus of food permits some people to do things besides produce food for a living: early civilizations included soldiers, artisans, priests and priestesses, and other people with specialized careers. A surplus of food results in a division of labour and a more diverse range of human activity, a defining trait of civilizations. However, in some places hunter-gatherers have had access to food surpluses, such as among some of the indigenous peoples of the Pacific Northwest and perhaps during the Mesolithic Natufian culture. It is possible that food surpluses and relatively large scale social organization and division of labour predates plant and animal domestication.\n\nCivilizations have distinctly different settlement patterns from other societies. The word \"civilization\" is sometimes simply defined as \"'living in cities'\". Non-farmers tend to gather in cities to work and to trade.\n\nCompared with other societies, civilizations have a more complex political structure, namely the state. State societies are more stratified than other societies; there is a greater difference among the social classes. The ruling class, normally concentrated in the cities, has control over much of the surplus and exercises its will through the actions of a government or bureaucracy. Morton Fried, a conflict theorist and Elman Service, an integration theorist, have classified human cultures based on political systems and social inequality. This system of classification contains four categories\n\nEconomically, civilizations display more complex patterns of ownership and exchange than less organized societies. Living in one place allows people to accumulate more personal possessions than nomadic people. Some people also acquire landed property, or private ownership of the land. Because a percentage of people in civilizations do not grow their own food, they must trade their goods and services for food in a market system, or receive food through the levy of tribute, redistributive taxation, tariffs or tithes from the food producing segment of the population. Early human cultures functioned through a gift economy supplemented by limited barter systems. By the early Iron Age, contemporary civilizations developed money as a medium of exchange for increasingly complex transactions. In a village, the potter makes a pot for the brewer and the brewer compensates the potter by giving him a certain amount of beer. In a city, the potter may need a new roof, the roofer may need new shoes, the cobbler may need new horseshoes, the blacksmith may need a new coat and the tanner may need a new pot. These people may not be personally acquainted with one another and their needs may not occur all at the same time. A monetary system is a way of organizing these obligations to ensure that they are fulfilled. From the days of the earliest monetarized civilizations, monopolistic controls of monetary systems have benefited the social and political elites.\n\nWriting, developed first by people in Sumer, is considered a hallmark of civilization and \"appears to accompany the rise of complex administrative bureaucracies or the conquest state\". Traders and bureaucrats relied on writing to keep accurate records. Like money, writing was necessitated by the size of the population of a city and the complexity of its commerce among people who are not all personally acquainted with each other. However, writing is not always necessary for civilization, as shown the Inca civilization of the Andes, which did not use writing at all except from a complex recording system consisting of cords and nodes instead: the \"Quipus\", whose still functioned as a civilized society.\n\nAided by their division of labour and central government planning, civilizations have developed many other diverse cultural traits. These include organized religion, development in the arts, and countless new advances in science and technology.\n\nThrough history, successful civilizations have spread, taking over more and more territory, and assimilating more and more previously-uncivilized people. Nevertheless, some tribes or people remain uncivilized even to this day. These cultures are called by some \"primitive\", a term that is regarded by others as pejorative. \"Primitive\" implies in some way that a culture is \"first\" (Latin = \"primus\"), that it has not changed since the dawn of humanity, though this has been demonstrated not to be true. Specifically, as all of today's cultures are contemporaries, today's so-called primitive cultures are in no way antecedent to those we consider civilized. Anthropologists today use the term \"non-literate\" to describe these peoples.\n\nCivilization has been spread by colonization, invasion, religious conversion, the extension of bureaucratic control and trade, and by introducing agriculture and writing to non-literate peoples. Some non-civilized people may willingly adapt to civilized behaviour. But civilization is also spread by the technical, material and social dominance that civilization engenders.\n\nAssessments of what level of civilization a polity has reached are based on comparisons of the relative importance of agricultural as opposed to trade or manufacturing capacities, the territorial extensions of its power, the complexity of its division of labour, and the carrying capacity of its urban centres. Secondary elements include a developed transportation system, writing, standardized measurement, currency, contractual and tort-based legal systems, art, architecture, mathematics, scientific understanding, metallurgy, political structures and organized religion.\n\nTraditionally, polities that managed to achieve notable military, ideological and economic power defined themselves as \"civilized\" as opposed to other societies or human groupings outside their sphere of influence—calling the latter barbarians, savages, and primitives. In a modern-day context, \"civilized people\" have been contrasted with indigenous people or tribal societies.\n\n\"Civilization\" can also refer to the culture of a complex society, not just the society itself. Every society, civilization or not, has a specific set of ideas and customs, and a certain set of manufactures and arts that make it unique. Civilizations tend to develop intricate cultures, including a state-based decision making apparatus, a literature, professional art, architecture, organized religion and complex customs of education, coercion and control associated with maintaining the elite.\n\nThe intricate culture associated with civilization has a tendency to spread to and influence other cultures, sometimes assimilating them into the civilization (a classic example being Chinese civilization and its influence on nearby civilizations such as Korea, Japan and Vietnam). Many civilizations are actually large cultural spheres containing many nations and regions. The civilization in which someone lives is that person's broadest cultural identity.\n\nMany historians have focused on these broad cultural spheres and have treated civilizations as discrete units. Early twentieth-century philosopher Oswald Spengler, uses the German word \"Kultur\", \"culture\", for what many call a \"civilization\". Spengler believes a civilization's coherence is based on a single primary cultural symbol. Cultures experience cycles of birth, life, decline and death, often supplanted by a potent new culture, formed around a compelling new cultural symbol. Spengler states civilization is the beginning of the decline of a culture as \"the most external and artificial states of which a species of developed humanity is capable\".\n\nThis \"unified culture\" concept of civilization also influenced the theories of historian Arnold J. Toynbee in the mid-twentieth century. Toynbee explored civilization processes in his multi-volume \"A Study of History,\" which traced the rise and, in most cases, the decline of 21 civilizations and five \"arrested civilizations\". Civilizations generally declined and fell, according to Toynbee, because of the failure of a \"creative minority\", through moral or religious decline, to meet some important challenge, rather than mere economic or environmental causes.\n\nSamuel P. Huntington defines civilization as \"the highest cultural grouping of people and the broadest level of cultural identity people have short of that which distinguishes humans from other species\". Huntington's theories about civilizations are discussed below.\n\nAnother group of theorists, making use of systems theory, looks at a civilization as a complex system, i.e., a framework by which a group of objects can be analysed that work in concert to produce some result. Civilizations can be seen as networks of cities that emerge from pre-urban cultures and are defined by the economic, political, military, diplomatic, social and cultural interactions among them. Any organization is a complex social system and a civilization is a large organization. Systems theory helps guard against superficial but misleading analogies in the study and description of civilizations.\n\nSystems theorists look at many types of relations between cities, including economic relations, cultural exchanges and political/diplomatic/military relations. These spheres often occur on different scales. For example, trade networks were, until the nineteenth century, much larger than either cultural spheres or political spheres. Extensive trade routes, including the Silk Road through Central Asia and Indian Ocean sea routes linking the Roman Empire, Persian Empire, India and China, were well established 2000 years ago, when these civilizations scarcely shared any political, diplomatic, military, or cultural relations. The first evidence of such long distance trade is in the ancient world. During the Uruk period, Guillermo Algaze has argued that trade relations connected Egypt, Mesopotamia, Iran and Afghanistan. Resin found later in the Royal Cemetery at Ur is suggested was traded northwards from Mozambique.\n\nMany theorists argue that the entire world has already become integrated into a single \"world system\", a process known as globalization. Different civilizations and societies all over the globe are economically, politically, and even culturally interdependent in many ways. There is debate over when this integration began, and what sort of integration – cultural, technological, economic, political, or military-diplomatic – is the key indicator in determining the extent of a civilization. David Wilkinson has proposed that economic and military-diplomatic integration of the Mesopotamian and Egyptian civilizations resulted in the creation of what he calls the \"Central Civilization\" around 1500 BCE. Central Civilization later expanded to include the entire Middle East and Europe, and then expanded to a global scale with European colonization, integrating the Americas, Australia, China and Japan by the nineteenth century. According to Wilkinson, civilizations can be culturally heterogeneous, like the Central Civilization, or homogeneous, like the Japanese civilization. What Huntington calls the \"clash of civilizations\" might be characterized by Wilkinson as a clash of cultural spheres within a single global civilization. Others point to the Crusades as the first step in globalization. The more conventional viewpoint is that networks of societies have expanded and shrunk since ancient times, and that the current globalized economy and culture is a product of recent European colonialism. \n\nHistorically civilizations were assumed by writers such as Aristotle to be the natural state of humanity, so no origin for the Greek polis was considered to be needed. The Sumerian King List for instance, sees the origin of their civilization as descending from heaven. However the great age of maritime discovery exposed the states of Western Europe to hunter-gatherer and simple horticultural cultures that were not civilized. To explain the differences observed, early theorists turned to racist theories of cultural superiority, theories of geographic determinism, or accidents of culture. After the Second World War, these theories were rejected on various grounds and other explanations sought. Four schools have developed in the modern period.\n\nThe process of sedentarization is first thought to have occurred around 12,000 BCE in the Levant region of southwest Asia though other regions around the world soon followed. The emergence of civilization is generally associated with the Neolithic, or Agricultural Revolution, which occurred in various locations between 8,000 and 5,000 BCE, specifically in southwestern/southern Asia, northern/central Africa and Central America. At first, the Neolithic was associated with shifting subsistence cultivation, where continuous farming led to the depletion of soil fertility resulting in the requirement to cultivate fields further and further removed from the settlement, eventually compelling the settlement itself to move. In major semi-arid river valleys, annual flooding renewed soil fertility every year, with the result that population densities could rise significantly. This encouraged a secondary products revolution in which people used domesticated animals not just for meat, but also for milk, wool, manure and pulling ploughs and carts—a development that spread through the Eurasian Oecumene. The 8.2 Kiloyear Arid Event and the 5.9 Kiloyear Interpluvial saw the drying out of semiarid regions and a major spread of deserts. This climate change shifted the cost-benefit ratio of endemic violence between communities, which saw the abandonment of unwalled village communities and the appearance of walled cities, associated with the first civilizations. This \"urban revolution\" marked the beginning of the accumulation of transferrable surpluses, which helped economies and cities develop. It was associated with the state monopoly of violence, the appearance of a soldier class and endemic warfare, rapid development of hierarchies, the appearance of human sacrifice and a fall in the status of women.\n\n\nThe Iron Age is the period generally occurring after the Bronze Age, marked by the prevalent use of iron. The early period of the age is characterized by the widespread use of iron or steel. The adoption of such material coincided with other changes in society, including differing agricultural practices, religious beliefs and artistic styles. The Iron Age as an archaeological term indicates the condition as to civilization and culture of a people using iron as the material for their cutting tools and weapons. The Iron Age is the third principal period of the three-age system created by Christian Thomsen (1788–1865) for classifying ancient societies and prehistoric stages of progress.\n\nKarl Jaspers, the German historical philosopher, proposed that the ancient civilizations were affected greatly by an Axial Age in the period between 800 BCE–200 BCE during which a series of male sages, prophets, religious reformers and philosophers, from China, India, Iran, Israel and Greece, changed the direction of civilizations. William Hardy McNeill proposed that this period of history was one in which culture contact between previously separate civilizations saw the \"closure of the oecumene\" and led to accelerated social change from China to the Mediterranean, associated with the spread of coinage, larger empires and new religions. This view has recently been championed by Christopher Chase-Dunn and other world systems theorists.\n\nThe spread of the Higher Religions, beginning with Zoroastrianism, Confucianism and Buddhism was linked to the developments of the Axial Age. Principal amongst this was the creation of large militaristic territorial states, which saw an increase in the state as a powerful unit monopolizing the use of violence. It was also linked with the spread of coinage and monetary economies, which had the effect of dissolving the previous local community traditions. The rise of the confessional religious brought the ability to unify larger states than had existed previously.\n\n\n\nCivilizations have generally ended in one of two ways; either through being incorporated into another expanding civilization (e.g. As Ancient Egypt was incorporated into Hellenistic Greek, and subsequently Roman civilizations), or by collapse and reversion to a simpler form, as happens in what are called Dark Ages.\n\nThere have been many explanations put forward for the collapse of civilization. Some focus on historical examples, and others on general theory.\n\nPolitical scientist Samuel Huntington has argued that the defining characteristic of the 21st century will be a clash of civilizations. According to Huntington, conflicts between civilizations will supplant the conflicts between nation-states and ideologies that characterized the 19th and 20th centuries. These views have been strongly challenged by others like Edward Said, Muhammed Asadi and Amartya Sen. Ronald Inglehart and Pippa Norris have argued that the \"true clash of civilizations\" between the Muslim world and the West is caused by the Muslim rejection of the West's more liberal sexual values, rather than a difference in political ideology, although they note that this lack of tolerance is likely to lead to an eventual rejection of (true) democracy. In \"Identity and Violence\" Sen questions if people should be divided along the lines of a supposed \"civilization\", defined by religion and culture only. He argues that this ignores the many others identities that make up people and leads to a focus on differences.\n\nCultural Historian Morris Berman suggests in \"Dark Ages America: the End of Empire\" that in the corporate consumerist United States, the very factors that once propelled it to greatness―extreme individualism, territorial and economic expansion, and the pursuit of material wealth―have pushed the United States across a critical threshold where collapse is inevitable. Politically associated with over-reach, and as a result of the environmental exhaustion and polarization of wealth between rich and poor, he concludes the current system is fast arriving at a situation where continuation of the existing system saddled with huge deficits and a hollowed-out economy is physically, socially, economically and politically impossible. Although developed in much more depth, Berman's thesis is similar in some ways to that of Urban Planner, Jane Jacobs who argues that five pillars of United States culture that are in serious decay: community and family; higher education; the effective practice of science; taxation and government; and the self-regulation of the learned professions. The corrosion of these pillars, Jacobs argues, is linked to societal ills such as environmental crisis, racism and the growing gulf between rich and poor.\n\nSome environmental scientists also see the world entering a Planetary Phase of Civilization, characterized by a shift away from independent, disconnected nation-states to a world of increased global connectivity with worldwide institutions, environmental challenges, economic systems, and consciousness. In an attempt to better understand what a Planetary Phase of Civilization might look like in the current context of declining natural resources and increasing consumption, the Global scenario group used scenario analysis to arrive at three archetypal futures: Barbarization, in which increasing conflicts result in either a fortress world or complete societal breakdown; Conventional Worlds, in which market forces or Policy reform slowly precipitate more sustainable practices; and a Great Transition, in which either the sum of fragmented Eco-Communalism movements add up to a sustainable world or globally coordinated efforts and initiatives result in a new sustainability paradigm.\n\nCultural critic and author Derrick Jensen argues that modern civilization is directed towards the domination of the environment and humanity itself in an intrinsically harmful, unsustainable, and self-destructive fashion. Defending his definition both linguistically and historically, he defines civilization as \"a culture... that both leads to and emerges from the growth of cities\", with \"cities\" defined as \"people living more or less permanently in one place in densities high enough to require the routine importation of food and other necessities of life\". This need for civilizations to import ever more resources, he argues, stems from their over-exploitation and diminution of their own local resources. Therefore, civilizations inherently adopt imperialist and expansionist policies and, to maintain these, highly militarized, hierarchically structured, and coercion-based cultures and lifestyles.\n\nThe Kardashev scale classifies civilizations based on their level of technological advancement, specifically measured by the amount of energy a civilization is able to harness. The Kardashev scale makes provisions for civilizations far more technologically advanced than any currently known to exist (see also: Civilizations and the Future and Space civilization).\n\n\n", "id": "6258", "title": "Civilization"}
{"url": "https://en.wikipedia.org/wiki?curid=6259", "text": "Civilization (video game)\n\nSid Meier's Civilization is the first in a series of turn-based \"4X\"-type strategy video game created by Sid Meier and Bruce Shelley for MicroProse in 1991. The game's objective is to \"Build an empire to stand the test of time\": it begins in 4000 BC and the players attempt to expand and develop their empires through the ages from the ancient era until modern and near-future times.\n\n\"Civilization\" was originally developed for DOS running on a PC. It has undergone numerous revisions for various platforms (including Windows, Macintosh, Amiga, Atari ST, Super NES, Sega Saturn, PlayStation and N-Gage) and now exists in several versions. A multiplayer remake, Sid Meier's CivNet was released for the PC in 1995. The N-Gage version was the 17th game released for the system in North America.\n\n\"Civilization\" is a turn-based single- or multiplayer strategy game. The player takes on the role of the ruler of a civilization, starting with one (or occasionally two) settler units, and attempts to build an empire in competition with two to seven other civilizations. The game requires a fair amount of micromanagement (although less than other simulation games). Along with the larger tasks of exploration, warfare and diplomacy, the player has to make decisions about where to build new cities, which improvements or units to build in each city, which advances in knowledge should be sought (and at what rate), and how to transform the land surrounding the cities for maximum benefit. From time to time the player's towns may be harassed by barbarians, units with no specific nationality and no named leader. These threats only come from unclaimed land or sea, so that over time there are fewer and fewer places from which barbarians will emanate.\n\nBefore the game begins, the player chooses which historical or current civilization to play. In contrast to later games in the \"Civilization\" series, this is largely a cosmetic choice, affecting titles, city names, musical heralds, and color. The choice does affect their starting position on the \"Play on Earth\" map, and thus different resources in one's initial cities, but has no effect on starting position when starting a random world game or a customized world game. The player's choice of civilization also prevents the computer from being able to play as that civilization or the other civilization of the same color, and since computer-controlled opponents display certain traits of their civilizations this affects gameplay as well. The Aztecs are both fiercely expansionist and generally extremely wealthy, for example. Other civilizations include the Americans, the Mongols, and Romans. Each civilization is led by a famous historical figure, such as Mohandas K. Gandhi for India.\n\nThe scope of \"Civilization\" is larger than most other games. The game begins in 4000 BC, before the Bronze Age, and can last through to AD 2100 (on the easiest setting) with Space Age and \"future technologies\". At the start of the game there are no cities anywhere in the world: the player controls one or two settler units, which can be used to found new cities in appropriate sites (and those cities may build other settler units, which can go out and found new cities, thus expanding the empire). Settlers can also alter terrain, build improvements such as mines and irrigation, build roads to connect cities, and later in the game they can construct railroads which offer unlimited movement.\n\nAs time advances, new technologies are developed; these technologies are the primary way in which the game changes and grows. At the start, players choose from advances such as pottery, the wheel, and the alphabet to, near the end of the game, nuclear fission and spaceflight. Players can gain a large advantage if their civilization is the first to learn a particular technology (the secrets of flight, for example) and put it to use in a military or other context. Most advances give access to new units, city improvements or derivative technologies: for example, the chariot unit becomes available after the wheel is developed, and the granary building becomes available to build after pottery is developed. The whole system of advancements from beginning to end is called the technology tree, or simply the Tech tree; this concept has been adopted in many other strategy games. Since only one tech may be \"researched\" at any given time, the order in which technologies are chosen makes a considerable difference in the outcome of the game and generally reflects the player's preferred style of gameplay.\n\nPlayers can also build \"Wonders of the World\" in each of the epochs of the game, subject only to obtaining the prerequisite knowledge. These wonders are important achievements of society, science, culture and defense, ranging from the Pyramids and the Great Wall in the Ancient age, to Copernicus' Observatory and Magellan's Expedition in the middle period, up to the Apollo program, the United Nations, and the Manhattan Project in the modern era. Each wonder can only be built once in the world, and requires a lot of resources to build, far more than most other city buildings or units. Wonders provide unique benefits to the controlling civilization. For example, Magellan's Expedition increases the movement rate of naval units. Wonders typically affect either the city in which they are built (for example, the Colossus), every city on the continent (for example, J.S. Bach's Cathedral), or the civilization as a whole (for example, Darwin's Voyage). Some wonders are made obsolete by new technologies.\n\nThe game can be won by conquering all other civilizations or by winning the space race by reaching the star system of Alpha Centauri.\n\nBritish designer Francis Tresham released his \"Civilization\" board game in 1980 under his company Hartland Trefoil. Avalon Hill had obtained the rights to publish it in the United States in 1981.\n\nThere were at least two attempts to make a computerized version of Tresham's game prior to 1990. Danielle Bunten Berry planned to start work on the game after completing \"M.U.L.E.\" in 1983, and again in 1985, after completing \"The Seven Cities of Gold\" at Electronic Arts. In 1983 Bunten and producer Joe Ybarra opted to first do \"Seven Cities of Gold\". The success of \"Seven Cities\" in 1985 in turn led to a sequel, \"Heart of Africa\". Bunten never returned to the idea of \"Civilization\". Don Daglow, designer of \"Utopia\", the first simulation game, began work programming a version of \"Civilization\" in 1987. He dropped the project, however, when he was offered an executive position at Brøderbund, and never returned to the game.\n\nSid Meier and Bill Stealey co-founded MicroProse in 1982 to develop flight simulators and other military strategy video games based on Stealey's past experiences as a United States Air Force pilot. Around 1989, Meier wanted to expand his repertoire beyond these types of games, as just having finished \"F-19 Stealth Fighter\" (1988, 1990), he said \"Everything I thought was cool about a flight simulator had gone into that game.\" He took to heart the success of the new god game genre in particular \"SimCity\" (1989) and \"Populous\" (1989). Specifically with \"SimCity\", Meier recognized that video games could still be entertaining based on building something up. By then, Meier was not an official employee of MicroProse but worked under contract where the company paid him upfront for game development, a large payment on delivery of the game, and additional royalties on each game of his sold.\n\nMicroProse had hired a number of Avalon Hill game designers, including Bruce Shelley. Among other works, Shelley had been responsible for adapting the railroad-based \"1829\" board game developed by Tresham into \"\". Shelley had joined MicroProse finding that the board game market was weakening in contrast to the video game market, and initially worked on \"F-19 Stealth Fighter\". Meier recognized Shelley's abilities and background in game design and took him on as personal assistant designer to brainstorm new game ideas. The two initially worked on ideas for \"Sid Meier's Covert Action\", but had put these aside when they came up with the concepts for \"Railroad Tycoon\" (1990), based loosely on the \"1829\"/\"1830\" board games. \"Railroad Tycoon\" was generally well received at its release, but the title did not fit within the nature of flight simulators and military strategy from MicroProse's previous catalog. Meier and Shelley had started a sequel to \"Railroad Tycoon\" shortly after its release, but Stealey canceled the project.\n\nOne positive aspect both had taken from \"Railroad Tycoon\" was the idea of multiple smaller systems working together at the same time and the player having to manage them. Both Meier and Shelley recognized that the complex interactions between these systems led players to \"make a lot of interesting decisions\", and that ruling a whole civilization would readily work well with these underlying systems. Some time later, both discussed their love of the original \"Empire\" computer games, and Meier challenged Shelley to give him ten things he'd change about \"Empire\"; Shelley provided him with twelve. Around May 1990, Meier presented Shelley with a 5-1/4\" floppy disk which contained the first prototype of \"Civilization\" based on their past discussions and Shelley's list. \n\nMeier's prototype took elements from \"Empire\", \"Railroad Tycoon\", \"SimCity\" and the \"Civilization\" board game. This initial version of this game was a real-time simulation, with the player defining zones for their population to grow similar to zoning in \"SimCity\". Meier and Shelley went back and forth with this, with Shelley providing suggestions based on his playthrough and acting as the game's producer, and Meier coding and reworking the game to address these points, and otherwise without involvement of other MicroProse staff. During this period, Stealey and the other managers became concerned that this game did not fit MicroProse's general catalog as computer strategies games had yet proven successful. A few months into the development, Stealey requested them to put the project on hold and complete \"Covert Action\", after which they could go back to their new game. Meier and Shelley completed \"Covert Action\" which was published in 1990.\nOnce \"Covert Action\" was released, Meier and Shelley returned to the prototype. The time away from the project allowed them to recognize that the real-time aspect was not working well, and reworked the game to become turn-based and dropped the zoning aspect. They incorporated elements of city management and military aspect from \"Empire\", including creating individual military units as well as settler units that replaced the functionality of the zoning approach. Meier felt adding military and combat to the game was necessary as \"The game really isn't about being civilized. The competition is what makes the game fun and the players play their best. At times, you have to make the player uncomfortable for the good of the player\". Meier also opted to include a technology tree that would help to open the game to many more choices to the player as it continued, creating a non-linear experience. Meier felt players would be able to use the technology tree to adopt a style of play and from which they could use technologies to barter with the other opponents. While the game relies on established recorded history, Meier admitted he did not spend much time in research, usually only to assure the proper chronology or spellings; Shelley noted that they wanted to design for fun, not accuracy, and that \"Everything we needed was pretty much available in the children’s section of the library.\"\n\nMeier eliminated the potential for any civilization to fall on its own, believing this would be punishing to the player. Meier omitted multiplayer alliances because the computer used them too effectively, causing players to think that it was cheating. He said that by contrast, minefields and minesweepers caused the computer to do \"stupid things ... If you've got a feature that makes the AI look stupid, take it out. It's more important not to have stupid AI than to have good AI\". Meier also omitted jets and helicopters because he thought players would not find obtaining new technologies in the endgame useful, and online multiplayer support because of the small number of online players (\"if you had friends, you wouldn't need to play computer games\"); he also did not believe that online play worked well with turn-based play. The game was developed for the IBM PC platform, which at the time had support for both 16-color EGA to 256-color VGA; Meier opted to stay with the basic EGA support to allow the game to run on both EGA and VGA systems.\n\nMeier and Shelley neared the end of their development and started presenting the game to the rest of MicroProse for feedback towards publication. This process was slowed by the current vice president of development, who had taken over Meier's former position at the company. This vice president did not receive any financial bonuses for successful publication of Meier's games due to Meier's contract terms, forgoing any incentive to provide the needed resources to finish the game. The management had also expressed issue with the lack of a firm completion date, as according to Shelley, Meier would consider a game completed only when he felt he had completed it. Eventually the two got the required help for publication, with Shelley overseeing these processes and Meier making the necessary coding changes. Playtesting revealed that their chosen map size was too large and made for boring and repetitive gameplay. The size was reduced and other automated features, like city management, were made to require more player involvement. They also eliminated a large branch of their technology tree and spent time reworking the existing technologies and units to make sure they felt appropriate and did not break the game. Most of the game was originally developed with art crafted by Meier, and MicroProse's art department helped to create most of the final assets, though some of Meier's original art was used. Shelley wrote out the \"Civilopedia\" entries for all the elements of the game and the game's large manual.\n\nThe name \"Civilization\" came late in the development process. MicroProse recognized at this point the 1980 \"Civilization\" board game may conflict with their video game, as it shared a similar theme including the technology tree. Meier had noted the board game's influence but considered it not as great as \"Empire\" or \"SimCity\", while others have noted significant differences that made the video game far different from the board game such as the non-linearity introduced by Meier's technology tree. To avoid any potential legal issues, MicroProse negotiated a license to use the \"Civilization\" name from Avalon Hill.\n\n\"Civilization\" was released in early 1991. Because of the animosity that MicroProse's management had towards Meier's games, there was very little promotion of the title, though interest in the game through word-of-mouth helped to boost sales. Following the release on the IBM PC, the game was ported to other platforms; Meier and Shelley provided this code to contractors hired by MicroProse to complete the ports.\n\n\"Civilization\" was released with only single-player support, with the player working against multiple computer opponents. In 1991, Internet or online gaming was still in its infancy, so this option was not considered in \"Civilization\"s release. Over the next few years, as home Internet accessibility took off, MicroProse looked to develop an online version of \"Civilization\". This led to the 1995 release of \"Sid Meier's CivNet\". \"CivNet\" allowed for up to eight players to play the game, with computer opponents available to obtain up to eight active civilizations. Games could be played either on a turn-based mode, or in a simultaneous mode where each player took their turn at the same time and only progressing to the next turn once all players have confirmed being finished that turn. The game, in addition to better support for Windows 3.1 and Windows 95, supported connectivity through LAN, primitive Internet play, modem, and direct serial link, and included a local hotseat mode. \"CivNet\" also included a map editor and a \"king builder\" to allow a player to customize the names and looks of their civilization as seen by other players.\n\nAccording to Brian Reynolds, who led the development of \"Civilization II\", MicroProse \"sincerely believed that \"CivNet\" was going to be a much more important product\" than the next single-player \"Civilization\" game that he and Jeff Briggs had started working on. Reynolds said that because their project was seen as a side effort with little risk, they were able to innovate new ideas into \"Civilization II\". As a net result, \"CivNet\" was generally overshadowed by \"Civilization II\" which was released in the following year.\n\n\"Civilization\"s critical success created a \"golden period of MicroProse\" where there was more potential for similar strategy games to succeed, according to Meier. This put stress on the company's direction and culture. Stealey wanted to continue to pursue the military-themed titles, while Meier wanted to continue his success with simulation games. Shelley left MicroProse in 1992 and joined Ensemble Studios, where he used his experience with \"Civilization\" to design the \"Age of Empire\" games. Stealey had pushed MicroProse to develop console and arcade-based versions of their games, but this put the company into debt, and Stealey eventually sold the company to Spectrum HoloByte in 1993; Spectrum HoloByte kept MicroProse as a separate company on acquisition.\n\nMeier would continue and develop \"Civilization II\" along with Brian Reynolds, who served in a similar role to Shelley as design assistant, as well as help from Jeff Briggs and Douglas Kaufman. This game was released in early 1996, and is considered the first sequel of any Sid Meier game. Stealey eventually sold his shares in MicroProse and left the company, and Spectrum HoloByte opted to consolidate the two companies under the name MicroProse in 1996, eliminating numerous positions at MicroProse in the process. As a result, Meier, Briggs, and Reynolds all opted to leave the company and founded Firaxis, which by 2005 became a subsidiary of Take-Two. After a number of acquisitions and legal actions, the \"Civilization\" brand (both as a board game and video game) is now owned by Take-Two, and Firaxis, under Meier's oversight, continues to develop games in the \"Civilization\" series.\n\n\"Civilization\" has been called one of the most important strategy games of all time, and has a loyal following of fans. This high level of interest has led to the creation of a number of free and open source versions and inspired similar games by other commercial developers.\n\nThe game was reviewed in 1992 in \"Dragon\" #183 by Hartley, Patricia, and Kirk Lesser in \"The Role of Computers\" column. The reviewers gave the game 5 out of 5 stars. They commented: \"\"Civilization\" is one of the highest dollar-to-play-ratio entertainments we've enjoyed. The scope is enormous, the strategies border on being limitless, the excitement is genuinely high, and the experience is worth every dime of the game's purchase price.\"\n\n\"Civilization\" won the Origins Award in the category Best Military or Strategy Computer Game of 1991. A 1992 \"Computer Gaming World\" survey of wargames with modern settings gave the game five stars out of five, describing it as \"more addictive than crack ... so rich and textured that the documentation is incomplete\". In 1992 the magazine named it the Overall Game of the Year, in 1993 added the game to its Hall of Fame, and in 1996 chose \"Civilization\" as the best game of all time:\n\nA critic for \"Next Generation\" judged the Super NES version to be a disappointing port, with a cumbersome menu system (particularly that the \"City\" and \"Production\" windows are on separate screens), an unintuitive button configuration, and ugly scaled down graphics. However, he gave it a positive recommendation due to the strong gameplay and strategy of the original game: \"if you've never taken a crack at this game before, be prepared to lose hours, even days, trying to conquer those pesky Babylonians.\"\n\nIn 2000, GameSpot rated \"Civilization\" as the seventh most influential video game of all time. It was also ranked at fourth place on IGN's 2000 list of the top PC games of all time. In 2004, readers of \"Retro Gamer\" voted it as the 29th top retro game. In 2007, it was named one of the 16 most influential games in history at a German technology and games trade show Telespiele. In Poland, it was included in the retrospective lists of the best Amiga games by Wirtualna Polska (ranked ninth) and \"CHIP\" (ranked fifth). In 2012, \"Time\" named it one of the 100 greatest video games of all time.\n\nOn March 12, 2007, \"The New York Times\" reported on a list of the ten most important video games of all time, the so-called game canon, which included \"Civilization\".\n\nBy the release of \"Civilization II\" in 1996, \"Civilization\" had sold over 850,000 copies. Shelley stated in a 2016 interview that \"Civilization\" had sold 1.5 million copies.\n\nThere have been several sequels to \"Civilization\", including \"Civilization II\" (1996), \"Civilization III\" (2001), \"Civilization IV\" (2005), \"Civilization Revolution\" (2008), \"Civilization V\" (2010), and \"Civilization VI\" in 2016. In 1994, Meier produced a similar game titled \"Colonization\". As an easter egg in these latter games referencing an integer overflow bug in \"Civilization\", the computer-controlled Gandhi, normally run in a highly-peaceful manner, becomes a nuclear warmonger once this technology was unlocked. The original game had set Gandhi's \"aggressiveness\" to 1 out of a maximum 255 possible for a 8-bit unsigned integer, making the opponent extremely peaceful. However, once a player achieved the Democracy government, this reduced all aggression levels by 2; Gandhi's \"1\" would be reduced to \"-1\" which actually wraps around to \"255\", making him the most aggressive opponent in the game. Another relic of \"Civilization\" was the nature of combat where a military unit from earlier civilization periods could remain in play through modern times, gaining combat bonuses due to veteran proficiency, leading to these primitive units easily beating out modern technology against all common sense, with the common example of a veteran spearmen unit able to fend off a battleship. Meier noted that this resulted from not anticipating how players would use units, expecting them to have used their forces more like a war-based board game to protect borders and maintain zones of control rather than creating \"stacks of doom\". Future civilization games have had many changes in combat systems to prevent such oddities, though these games do allow for such random victories.\n\nThe 1999 game \"Sid Meier's Alpha Centauri\" was also created by Meier and is in the same genre, but with a futuristic/space theme; many of the interface and gameplay innovations in this game eventually made their way into \"Civilization III\" and \"IV\". \"Alpha Centauri\" is not actually a sequel to \"Civilization\", despite beginning with the same event that ends \"Civilization\" and \"Civilization II\": a manned spacecraft from Earth arrives in the Alpha Centauri star system. Firaxis' 2014 game \"\", although bearing the name of the main series, is a reimagining of \"Alpha Centauri\" running on the engine of \"Civilization V\".\n\nIn 1994, MicroProse published \"Master of Magic\", a similar game but embedded in a medieval-fantasy setting where instead of technologies the player (a powerful wizard) develops spells, among other things. The game also shared many things with the popular fantasy card-trading game \"\". In 1999, Activision released \"\", a sequel of sorts to \"Civilization II\" but created by a completely different design team. \"Call to Power\" spawned a sequel in 2000, but by then Activision had lost the rights to the \"Civilization\" name and could only call it \"Call to Power II\".\n\nAn open source clone of \"Civilization\" has been developed under the name of \"Freeciv\", with the slogan \"'Cause civilization should be free.\" This game can be configured to match the rules of either \"Civilization\" or \"Civilization II\". Another game that partially clones Civilization is a public domain game called \"C-evo\".\n\n\n", "id": "6259", "title": "Civilization (video game)"}
{"url": "https://en.wikipedia.org/wiki?curid=6260", "text": "Claude Debussy\n\nAchille-Claude Debussy (, 22 August 1862 – 25 March 1918), known since the 1890s as Claude-Achille Debussy or Claude Debussy, was a French composer. He and Maurice Ravel were the most prominent figures associated with Impressionist music, though Debussy disliked the term when applied to his compositions. He was made Chevalier of the Legion of Honour in 1903. He was among the most influential composers of the late 19th and early 20th centuries, and his use of non-traditional scales and chromaticism influenced many composers who followed.\n\nDebussy's music is noted for its sensory content and frequent usage of nontraditional tonalities. The prominent French literary style of his period was known as Symbolism, and this movement directly inspired Debussy both as a composer and as an active cultural participant.\n\nDebussy, the oldest of five children, was born Achille-Claude Debussy (he later reversed his forenames) on 22 August 1862 in Saint-Germain-en-Laye, France. His father, Manuel-Achille Debussy, owned a china shop there; his mother, Victorine Manoury Debussy, was a seamstress. The family moved to Paris in 1867, but in 1870 Debussy's pregnant mother fled with Claude to his paternal aunt's home in Cannes to escape the Franco-Prussian War. At the age of seven, he began piano lessons with an Italian violinist in his early 40s named Jean Cerutti, and his aunt paid for his lessons. In 1871 he drew the attention of Marie Mauté de Fleurville, who claimed to have been a pupil of Frédéric Chopin. Debussy always believed her, although there is no independent evidence to support her claim. His talents soon became evident, and in 1872, at age ten, Debussy entered the Paris Conservatoire, where he spent the next 11 years. During his time there he studied composition with Ernest Guiraud, music history/theory with Louis-Albert Bourgault-Ducoudray, harmony with Émile Durand, piano with Antoine François Marmontel, organ with César Franck, and solfège with Albert Lavignac, as well as other significant figures of the era. He also became a lifelong friend of fellow student and distinguished pianist Isidor Philipp. After Debussy's death, many pianists sought Philipp's advice on playing his works.\n\nDebussy was experimental from the outset, favouring dissonances and intervals that were not taught at the Academy. Like Georges Bizet, he was a brilliant pianist and an outstanding sight reader, who could have had a professional career had he so wished. The pieces he played in public at this time included sonata movements by Beethoven, Schumann and Weber, and Chopin's Ballade No. 2, a movement from the Piano Concerto No. 1, and the \"Allegro de concert\".\n\nDuring the summers of 1880, 1881, and 1882, he accompanied Nadezhda von Meck, the wealthy patroness of Pyotr Ilyich Tchaikovsky, as she travelled with her family in Europe. The young composer's many musical activities during these vacations included playing four-hand pieces with von Meck at the piano, giving music lessons to her children, and performing in private concerts with some of her musician friends. Despite von Meck's closeness to Tchaikovsky, the Russian master appears to have had minimal effect on Debussy. In September 1880 she sent his \"Danse bohémienne\" for Tchaikovsky's perusal; a month later Tchaikovsky wrote back to her: \"It is a very pretty piece, but it is much too short. Not a single idea is expressed fully, the form is terribly shriveled, and it lacks unity.\" Debussy did not publish the piece, and the manuscript remained in the von Meck family; it was eventually sold to B. Schott's Sohne in Mainz, and published by them in 1932.\n\nA greater influence was Debussy's close friendship with Marie-Blanche Vasnier, a singer he met when he began working as an accompanist to earn some money, embarking on an eight-year affair together. She and her husband, Parisian civil servant Henri, gave Debussy emotional and professional support. Henri Vasnier introduced him to the writings of influential French writers of the time, which gave rise to his first songs, settings of poems by Paul Verlaine (the son-in-law of his former teacher Mme. Mauté de Fleurville).\nAs the winner of the 1884 Prix de Rome with his composition \"L'enfant prodigue\", he received a scholarship to the Académie des Beaux-Arts, which included a four-year residence at the Villa Medici, the French Academy in Rome, to further his studies (1885–1887). According to letters to Marie-Blanche Vasnier, perhaps in part designed to gain her sympathy, he found the artistic atmosphere stifling, the company boorish, the food bad, and the monastic quarters \"abominable\". Neither did he delight in Italian opera, as he found the operas of Donizetti and Verdi not to his taste. Debussy was often depressed and unable to compose, but he was inspired by Franz Liszt, whose command of the keyboard he found admirable. In June 1885, he wrote of his desire to follow his own way, saying, \"I am sure the Institute would not approve, for, naturally it regards the path which it ordains as the only right one. But there is no help for it! I am too enamoured of my freedom, too fond of my own ideas!\"\n\nDebussy finally composed four pieces that were sent to the Academy: the symphonic ode \"Zuleima\" (based on a text by Heinrich Heine); the orchestral piece \"Printemps\"; the cantata \"La damoiselle élue\" (1887–1888) (which was criticized by the Academy as \"bizarre\", although it was the first piece in which the stylistic features of his later style began to emerge); and the \"Fantaisie\" for piano and orchestra, which was heavily based on César Franck's music and therefore eventually withdrawn by Debussy. The Academy chided him for \"courting the unusual\" and hoped for something better from the gifted student. Although Debussy's works showed the influence of Jules Massenet, Massenet concluded, \"He is an enigma.\"\n\nDuring his visits to Bayreuth in 1888–9, Debussy was exposed to Wagnerian opera, which would have a lasting impact on his work. Like many young musicians of the time, he responded positively to Richard Wagner's sensuousness, mastery of form, and striking harmonies. Wagner's extroverted emotionalism was not to be Debussy's way, but the German composer's influence is evident in \"La damoiselle élue\" and the 1889 piece \"Cinq poèmes de Charles Baudelaire\". Other songs of the period, notably the settings of Verlaine – \"Ariettes oubliées\", \"Trois mélodies\", and \"Fêtes galantes\" – are all in a more capricious style.\n\nAround this time he met Erik Satie, who proved a kindred spirit in his experimental approach to composition and to naming his pieces. Both musicians were bohemians during this period, enjoying the same cafe society and struggling to stay afloat financially.\n\nIn 1889, at the Exposition Universelle in Paris, Debussy first heard Javanese gamelan music. He incorporated gamelan scales, melodies, rhythms, and ensemble textures into some of his compositions, most notably \"Pagodes\" from his piano collection \"Estampes\".\n\nDebussy's private life was often turbulent. At the age of 18 he began an eight-year affair with Marie-Blanche Vasnier, the wife of Parisian civil servant Henri Vasnier. The relationship eventually faltered following his winning of the Prix de Rome in 1884 and obligatory residence in Rome.\n\nOn his permanent return to Paris and his parents' home on the rue de Berlin (now rue de Liège) he began a tempestuous relationship with Gabrielle ('Gaby') Dupont, a tailor's daughter from Lisieux, soon living with her on the rue de Londres, and later the rue Gustave Doré. During this time he also had an affair with the singer Thérèse Roger, to whom he was briefly engaged. Such cavalier behaviour was widely condemned, and precipitated the end of his long friendship with Ernest Chausson.\n\nHe ultimately left Dupont for her friend Rosalie ('Lilly') Texier, a fashion model whom he married in 1899, after threatening suicide if she refused him. However, although Texier was affectionate, practical, straightforward, and well liked by Debussy's friends and associates, he became increasingly irritated by her intellectual limitations and lack of musical sensitivity. Moreover, her looks had prematurely aged, and she was unable to bear children.\n\nIn 1904 Debussy was introduced to Emma Bardac, wife of Parisian banker Sigismond Bardac, by her son Raoul, who was one of his students. In contrast to Texier, Bardac was a sophisticate, a brilliant conversationalist, and an accomplished singer. After dispatching Lilly to her father's home at Bichain in Villeneuve-la-Guyard on 15 July 1904, Debussy secretly took Bardac to Jersey for a holiday. On their return to France, he wrote to Texier on 11 August from Dieppe, informing her that their marriage was over, but still making no mention of Bardac. He briefly moved to an apartment at 10 avenue Alphand. On 14 October, five days before their fifth wedding anniversary, Texier attempted suicide, shooting herself in the chest with a revolver while standing in the Place de la Concorde; she survived, although the bullet remained lodged in her vertebrae for the rest of her life. The ensuing scandal was to alienate Debussy from many of his friends, whilst Bardac was disowned by her family.\n\nIn the spring of 1905, finding the hostility towards them intolerable, Debussy and Bardac (now pregnant) fled to England, via Jersey. Bardac's divorce was finalized in May. The couple settled at the Grand Hotel, Eastbourne, from 24 July to 30 August 1905, where Debussy corrected proofs to his symphonic suite \"La mer\", celebrating his divorce from Texier on 2 August.\n\nAfter a brief visit to London, the couple returned to Paris in September, buying a house in a courtyard development off the Avenue du Bois de Boulogne (now Avenue Foch) where Debussy resided for the rest of his life. Their daughter (the composer's only child) Claude-Emma was born there on 30 October. Her parents eventually married in 1908, their troubled union enduring until Debussy's death in 1918. Claude-Emma, more affectionately known as 'Chouchou', was a great musical inspiration to the composer (she was the dedicatee of his \"Children's Corner\" suite). Claude-Emma outlived her father by scarcely a year, succumbing to the diphtheria epidemic of 1919 after her doctor administered the wrong treatment.\n\nMary Garden, who played the part of Melisande in the original production of \"Pelléas et Mélisande\" in 1902, was to write of him: \"I honestly don’t know if Debussy ever loved anybody really. He loved his music – and perhaps himself. I think he was wrapped up in his genius... He was a very, very strange man.\" \n\nDebussy died of rectal cancer at his Paris home on 25 March 1918, at the age of 55. He had been diagnosed with the cancer in 1909 after experiencing bleeding, and in December 1915 underwent one of the earliest colostomy operations ever performed. The operation achieved only a temporary respite, and occasioned him considerable frustration (he was to liken dressing in the morning to \"all the labours of Hercules in one\"). His death occurred in the midst of the aerial and artillery bombardment of Paris during the German Spring Offensive of World War I. The funeral procession made its way through deserted streets to Père Lachaise Cemetery as the German guns bombarded the city. The military situation in France was critical, and did not permit the honour of a public funeral with ceremonious graveside orations. His body was reinterred the following year in the small Passy Cemetery sequestered behind the Trocadéro, fulfilling his wish to rest \"among the trees and the birds\"; his wife and daughter are buried with him.\n\nRudolph Reti points out the following features of Debussy's music, which \"established a new concept of tonality in European music\":\nHe concludes that Debussy's achievement was the synthesis of monophonic based \"melodic tonality\" with harmonies, albeit different from those of \"harmonic tonality\".\n\nThe application of the term \"Impressionist\" to Debussy and the music he influenced is a matter of intense debate within academic circles. One side argues that the term is a misnomer, an inappropriate label which the composer himself opposed. In a letter of 1908 he wrote: \"I am trying to do 'something different' – an effect of reality... what the imbeciles call 'impressionism', a term which is as poorly used as possible, particularly by the critics, since they do not hesitate to apply it to [J.M.W.] Turner, the finest creator of mysterious effects in all the world of art.\"\n\n\nFrom the 1890s Debussy began to develop his own musical language, which was largely independent of Wagner's style, coloured in part from the dreamy, sometimes morbid romanticism of the Symbolist movement. He became a frequent participant at Stéphane Mallarmé's Symbolist gatherings, where Wagnerism dominated the discussion. However, in contrast to the enormous works of Wagner and other late romantic composers around this time, he chose to write in smaller, more accessible forms.\nThe \"Deux arabesques\" is an example of one of his earliest works, already developing his musical language. \"Suite bergamasque\" (1890) recalls rococo decorousness with a modern cynicism and puzzlement, and contains one of his most popular pieces, \"Clair de Lune\". His String Quartet in G minor (1893) paved the way for his later more daring harmonic exploration, using the Phrygian mode as well as less standard scales such as the whole-tone, which creates a sense of floating, ethereal harmony. He was beginning to employ a single, continuous theme, breaking away from the traditional A–B–A form with its restatements and amplifications, which had been a mainstay of classical music since Haydn.\n\nDebussy wrote one of his most famous works under the influence of Mallarmé, the revolutionary \"Prélude à l'après-midi d'un faune\", which is truly original in form and execution. In contrast to the large orchestras so favoured by late romanticism, he wrote this piece for a smaller ensemble, emphasizing instrumental colour and timbre. Despite Mallarmé himself and colleague and friend Paul Dukas having been impressed by the piece, it was controversial at its premiere, but nevertheless established Debussy as one of the leading composers of the era.\n\nThe three \"Nocturnes\" (1899) include characteristic studies: in \"Nuages\", using veiled harmony and texture; \"Fêtes\", in exuberance; and \"Sirènes\", using whole-tones. Debussy's only complete opera \"Pelléas et Mélisande\" premiered in 1902, after ten years of work, and contrasted sharply with Wagnerian opera. Based on the play by Maurice Maeterlinck, the opera proved to be an immediate success and immensely influential to younger French composers, including Maurice Ravel. These works brought a fluidity of rhythm and colour quite new to Western music.\n\n\"La mer\" (1903–1905) essays a more symphonic form, with a finale that works themes from the first movement, although the middle movement, \"Jeux de vagues\", proceeds much less directly and with more variety of colour. The reviews were once again sharply divided. Some critics thought the treatment to be less subtle and less mysterious than his previous works, and even a step backward, with Pierre Lalo complaining \"I neither hear, nor see, nor feel the sea.\" Others extolled its \"power and charm\", its \"extraordinary verve and brilliant fantasy\", and its strong colors and definite lines.\n\nHe wrote much for the piano during this period. His first volume of \"Images pour piano\" (1904–1905) combines harmonic innovation with poetic suggestion: \"Reflets dans l'eau\" is a musical description of rippling water, while the second piece \"Hommage à Rameau\" is slow and yearningly nostalgic, taking a melody from Jean-Philippe Rameau's 1737 \"Castor et Pollux\" as its inspiration.\n\nThe evocative \"Estampes\" for piano (1903) give impressions of exotic locations. Debussy came into contact with Javanese gamelan music during the 1889 Paris \"Exposition Universelle\". \"Pagodes\" is the directly inspired result, aiming for an evocation of the pentatonic structures employed by Javanese music.\n\nHe wrote his famous \"Children's Corner Suite\" (1908) for his beloved daughter, Claude-Emma, whom he nicknamed \"Chouchou\". The suite recalls classicism – the opening piece \"Doctor Gradus ad Parnassum\" refers to Muzio Clementi's collection of instructional piano compositions \"Gradus ad Parnassum\" – as well as a new wave of American ragtime music. In the popular final piece of the suite, \"Golliwogg's Cakewalk\", Debussy also pokes fun at Richard Wagner by mimicking the opening bars of Wagner's prelude to \"Tristan und Isolde\".\nThe first book of \"Préludes\" (1910), twelve in total, proved to be his most successful work for piano. The Preludes are frequently compared to those of Chopin. Debussy's preludes are replete with rich, unusual and daring harmonies. They include the popular \"La fille aux cheveux de lin\" (The Girl with the Flaxen Hair) and \"La Cathédrale Engloutie\" (The Engulfed Cathedral), although since he wanted people to respond intuitively to these pieces, their titles were placed at the end of each one in the hope that listeners would not make stereotype images as they listened.\n\nLarger scale works included his orchestral piece \"Iberia\" (1907), a triptych medley of Spanish allusions and fleeting impressions which was begun as a work for two pianos, and also the music for Gabriele D'Annunzio's mystery play \"Le martyre de Saint Sébastien\" (1911). A lush and dramatic work, written in only two months, it is remarkable in sustaining a late antique modal atmosphere that was otherwise touched only in relatively short piano pieces.\n\nAs Debussy's popularity increased, he was often engaged as a conductor throughout Europe during this period, most often performing \"Pelléas\", \"La Mer\", and \"Prélude à l'après-midi d'un faune\". He was also an occasional music critic, to supplement his conducting fees and piano lessons, writing under the pseudonym \"Monsieur Croche\". He avoided analytical dissection and attempts to force images from music, saying \"Let us at all costs preserve this magic peculiar to music, since of all the arts it is most susceptible to magic.\" He could be caustic and witty, sometimes sloppy and ill-informed. He was for the most part enthusiastic about Richard Strauss and Stravinsky, and worshipful of Chopin and Bach, the latter being acknowledged as \"the one great master.\" His relationship to Beethoven was a complex one; he was said to refer to him as \"\"le vieux sourd\"\" (the old deaf one) and adjured one young pupil never to play Beethoven's music for \"it is like somebody dancing on my grave.\" It was said that \"Debussy liked Mozart, and he believed that Beethoven had terrifically profound things to say, but that he did not know how to say them, because he was imprisoned in a web of incessant restatement and of German aggressiveness.\" He also admired the works of Charles-Valentin Alkan. Schubert and Mendelssohn fared much worse, the latter being described as a \"facile and elegant notary\".\n\nDebussy's harmonies and chord progressions frequently exploit dissonances without any formal resolution. Unlike in his earlier work, he no longer hides discords in lush harmonies, and the forms are far more irregular and fragmented. These chords that seemingly had no resolution were described by Debussy himself as \"floating chords\", and were used to set tone and mood in many of his works. The whole tone scale dominates much of his late music.\n\nHis two final volumes of works for the piano, the \"Études\" (1915), interpret similar varieties of style and texture purely as pianistic exercises, and include pieces that develop irregular form to an extreme, as well as others influenced by the young Igor Stravinsky (a presence too in the suite \"En blanc et noir\" for two pianos, 1915). The rarefaction of these works is a feature of the last set of songs, the \"Trois poèmes de Mallarmé\" (1913), and of the Sonata for flute, viola and harp (1915), though the sonata and its companions also recapture the inquisitive Verlainian classicism.\nWith the sonatas of 1915–1917 there is a sudden shift in the style. These works recall Debussy's earlier music in part, but also look forward, with leaner, simpler structures. Despite the thinner textures of the Violin Sonata (1917), there remains an undeniable richness in the chords themselves. This shift parallels the movement commonly known as neo-classicism, which became popular after his death in 1918. He planned a set of six sonatas, but had only completed three (cello, flute-viola-harp, and violin) before he died.\n\nThe final orchestral work by Debussy, the ballet \"Jeux\" (1912) written for Sergei Diaghilev's Ballets Russes, contains some of his strangest harmonies and textures in a form that moves freely over its own field of motivic connection. At first, \"Jeux\" was overshadowed by Igor Stravinsky's \"The Rite of Spring\", which was composed in the same year as \"Jeux\", and was premiered only two weeks later by the same ballet company. Decades later, composers such as Pierre Boulez and Jean Barraqué pointed out parallels to Anton Webern's serialism in this work.\n\nOther late stage works, including the ballets \"Khamma\" (1912) and \"La boîte à joujoux\" (1913), were left with the orchestration incomplete, and were later completed by Charles Koechlin and André Caplet, who also helped him with the orchestration of \"Gigues\" (from \"Images pour orchestre\") and \"Le martyre de St. Sébastien\".\n\nThe second set of \"Préludes\" for piano (1913) features Debussy at his most avant-garde, where he uses dissonant harmonies to evoke specific moods and images. He consciously gives titles to each prelude which amplify the preludes' tonal ambiguity and dissonance. He uses scales such as the whole tone scale, musical modes, and the octatonic scale in his preludes which exaggerate this tonal ambiguity, making the key of each prelude almost indistinguishable at times. The second book of Preludes for piano represents his strong interest in the indefinite and esoteric.\nAlthough \"Pelléas\" was Debussy's only completed opera, he began several opera projects which remained unfinished, perhaps due to his fading concentration, increasing procrastination, and failing health. He had finished some partial musical sketches and some unpublished libretti for operas based on Poe's \"The Devil in the Belfry\" (\"Le diable dans le beffroi\", 1902–?1912) and \"The Fall of the House of Usher\" (\"La chute de la maison Usher\", 1908–1917) as well as considering projects for operas based on Shakespeare's \"As You Like It\" and Joseph Bedier's \"La Legende de Tristan\".\n\nFurther plans, such as an American tour, more ballet scores, and revisions of Chopin and Bach works for re-publication, were all cut short by poor health and the outbreak of World War I.\n\nSome people have claimed that Debussy structured parts of his music mathematically. Roy Howat, for instance, has published a book contending that Debussy's works are structured around mathematical models even while using an apparent classical structure such as sonata form. Howat suggests that some of Debussy's pieces can be divided into sections that reflect the golden ratio, frequently by using the numbers of the standard Fibonacci sequence.\n\nDebussy's influences were wide-ranging. He acquired a taste for parallel motion in fifths, fourths and octaves from medieval music, and an appreciation for figuration and arabesque from the Baroque masters. He especially had a great love for the French clavier composers Couperin and Rameau, as well as J. S. Bach. Chopin and Liszt were also powerful influences, not only in terms of pianistic layout and harmonic ingenuity, but also because of their willingness to create new forms to accommodate their material.\n\nAmong the Russian composers of his time, the most prominent influences were Tchaikovsky, Balakirev, Rimsky-Korsakov, Borodin and Mussorgsky. It can be inferred that from the Russians \"Debussy acquired his taste for ancient and oriental modes and for vivid colorations, and a certain disdain for academic rules\". Mussorgsky's opera \"Boris Godunov\" directly influenced one of Debussy's most famous works, \"Pelléas et Mélisande\". In addition to the Russian composers, one of Debussy's biggest influences was Richard Wagner. According to Pierre Louys, Debussy \"did not see 'what anyone can do beyond Tristan.\nAfter Debussy's Wagner phase, he started to become immensely interested in non-Western music and its unorthodox approaches to composition. Specifically, he was drawn to the Javanese Gamelan: a musical ensemble from the island of Java that played an array of unique instrumentation, including gongs and metallophones. He first heard the gamelan at the 1889 Paris Exposition. He was not interested in directly quoting his non-Western influences, but instead allowed this non-Western aesthetic to generally influence his own musical work, for example, by frequently using quiet, unresolved dissonances, coupled with the damper pedal, to emulate the \"shimmering\" effect created by a gamelan ensemble.\n\nDebussy was just as influenced by other art forms as he was by music, if not more so. He took a strong interest in literature and visual art, and used these mediums to help shape his unique musical style. He was heavily influenced by the French symbolist movement of the 1880s, which encompassed poetry, visual art, and theatre. He shared the movement's interest in the esoteric and indefinite and their rejection of naturalism and realism. Specifically, \"the development of free verse in poetry and the disappearance of the subject or model in painting influenced him to think about issues of musical form.\" He became personally acquainted with writers and painters of the movement, and based some of his own works on those of the symbolists. The poet Stéphane Mallarmé was a major influence, who in talking of \"a 'musicalization' of poetry\" laid claim to a strong connection between music and his own poetry. His \"Prélude à l'après-midi d'un faune\" was directly influenced by Mallarmé's poem \"Afternoon of a Faun\". Like the symbolists in respect to their own art forms, Debussy aimed to reject common techniques and approaches to composition and attempted to evoke more of a sensorial experience for the listener with his works. Since his time at the Paris Conservatoire, he believed he had much more to learn from artists than from musicians, who were primarily interested in their musical careers.\n\nAbove all, Debussy was inspired by nature and the impression it made on the mind, making a pantheistic profession of faith when he called \"mysterious Nature\" his religion. 'I do not practice religion in accordance with the sacred rites. I have made mysterious Nature my religion. I do not believe that a man is any nearer to God for being clad in priestly garments, nor that one place in a town is better adapted to meditation than another. When I gaze at a sunset sky and spend hours contemplating its marvellous ever-changing beauty, an extraordinary emotion overwhelms me. Nature in all its vastness is truthfully reflected in my sincere though feeble soul. Around me are the trees stretching up their branches to the skies, the perfumed flowers gladdening the meadow, the gentle grass-carpeted earth, ... and my hands unconsciously assume an attitude of adoration. ... To feel the supreme and moving beauty of the spectacle to which Nature invites her ephemeral guests! ... that is what I call prayer.'\n\nContemporary painter James Abbott McNeill Whistler (who lived in France between 1855 and 1859) had a profound influence on the composer. In 1894, Debussy wrote to violinist Eugène Ysaÿe describing his \"Nocturnes\" as \"an experiment in the different combinations that can be obtained from one color – what a study in grey would be in painting.\"\n\nDebussy is widely regarded as one of the most influential composers of the 20th century. His innovative harmonies were influential to almost every major composer of the 20th century, particularly Maurice Ravel, Igor Stravinsky, Olivier Messiaen, Béla Bartók, Pierre Boulez, Heitor Villa-Lobos, Henri Dutilleux, Ned Rorem, George Gershwin, and the minimalist music of Steve Reich and Philip Glass as well as the influential Japanese composer Toru Takemitsu. He also influenced many jazz musicians, including Duke Ellington, Bix Beiderbecke, Branford Marsalis, and Steve Kuhn. He also had a profound impact on contemporary soundtrack composers such as John Williams, because Debussy's colourful and evocative style translated easily into an emotional language for use in motion picture scores.\n\nA number of posthumous discoveries bear Debussy's name. These include:\n\nIn 1904, Debussy participated in a handful of recordings made together with soprano Mary Garden. He also made some piano rolls for Welte-Mignon in 1913.\n\n\n\n", "id": "6260", "title": "Claude Debussy"}
{"url": "https://en.wikipedia.org/wiki?curid=6261", "text": "Charles Baxter (author)\n\nCharles Baxter (born May 13, 1947) is an American novelist, essayist, and poet.\n\nBaxter was born in Minneapolis, Minnesota, to John and Mary Barber (Eaton) Baxter. He graduated from Macalester College in Saint Paul. In 1974 he received his PhD in English from the University at Buffalo with a thesis on Djuna Barnes, Malcolm Lowry, and Nathanael West.\n\nBaxter taught high school in Pinconning, Michigan for a year before beginning his university teaching career at Wayne State University in Detroit, Michigan. He then moved to the University of Michigan, where for many years he directed the Creative Writing MFA program. He currently teaches at the University of Minnesota and in the Warren Wilson College MFA Program for Writers.\n\n\n\n\n\n\n\n", "id": "6261", "title": "Charles Baxter (author)"}
{"url": "https://en.wikipedia.org/wiki?curid=6262", "text": "Ceres\n\nCeres commonly refers to:\n\nCeres may also refer to:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "6262", "title": "Ceres"}
{"url": "https://en.wikipedia.org/wiki?curid=6267", "text": "Cultural imperialism\n\nCultural imperialism comprises the cultural aspects of imperialism. Imperialism here refers to the creation and maintenance of unequal relationships between civilizations, favoring the more powerful civilization. Thus, cultural imperialism is the practice of promoting and imposing a culture, usually that of a politically powerful nation, over a less powerful society; in other words, the cultural hegemony of industrialized or economically influential countries which determine general cultural values and standardize civilizations throughout the world. The term is employed especially in the fields of history, cultural studies, and postcolonial theory. It is usually used in a pejorative sense, often in conjunction with calls to reject such influence. Cultural imperialism can take various forms, such as an attitude, a formal policy, or military action, insofar as it reinforces cultural hegemony.\n\nAlthough the \"Oxford English Dictionary\" has a 1921 reference to the \"cultural imperialism of the Russians\", John Tomlinson, in his book on the subject, writes that the term emerged in the 1960s and has been a focus of research since at least the 1970s. Terms such as \"media imperialism\", \"structural imperialism\", \"cultural dependency and domination\", \"cultural synchronization\", \"electronic colonialism\", \"ideological imperialism\", and \"economic imperialism\" have all been used to describe the same basic notion of cultural imperialism.\n\nVarious academics give various definitions of the term. American media critic Herbert Schiller wrote: \"The concept of cultural imperialism today [1975] best describes the sum of the processes by which a society is brought into the modern world system and how its dominating stratum is attracted, pressured, forced, and sometimes bribed into shaping social institutions to correspond to, or even promote, the values and structures of the dominating centre of the system. The public media are the foremost example of operating enterprises that are used in the penetrative process. For penetration on a significant scale the media themselves must be captured by the dominating/penetrating power. This occurs largely through the commercialization of broadcasting.\"\n\nTom McPhail defined \"Electronic colonialism as the dependency relationship established by the importation of communication hardware, foreign-produced software, along with engineers, technicians, and related information protocols, that vicariously establish a set of foreign norms, values, and expectations which, in varying degrees, may alter the domestic cultures and socialization processes.\" Sui-Nam Lee observed that \"communication imperialism can be defined as the process in which the ownership and control over the hardware and software of mass media as well as other major forms of communication in one country are singly or together subjugated to the domination of another country with deleterious effects on the indigenous values, norms and culture.\" Ogan saw \"media imperialism often described as a process whereby the United States and Western Europe produce most of the media products, make the first profits from domestic sales, and then market the products in Third World countries at costs considerably lower than those the countries would have to bear to produce similar products at home.\"\n\nDowning and Sreberny-Mohammadi state: \"Imperialism is the conquest and control of one country by a more powerful one. Cultural imperialism signifies the dimensions of the process that go beyond economic exploitation or military force. In the history of colonialism, (i.e., the form of imperialism in which the government of the colony is run directly by foreigners), the educational and media systems of many Third World countries have been set up as replicas of those in Britain, France, or the United States and carry their values. Western advertising has made further inroads, as have architectural and fashion styles. Subtly but powerfully, the message has often been insinuated that Western cultures are superior to the cultures of the Third World.\"\nNeedless to say, all these authors agree that cultural imperialism promotes the interests of certain circles within the imperial powers, often to the detriment of the target societies.\n\nThe issue of cultural imperialism emerged largely from communication studies. However, cultural imperialism has been used as a framework by scholars to explain phenomena in the areas of international relations, anthropology, education, science, history, literature, and sports.\n\nMany of today's academics that employ the term, \"cultural imperialism,\" are heavily informed by the work of Foucault, Derrida, Said, and other poststructuralist and postcolonialist theorists. Within the realm of postcolonial discourse, \"cultural imperialism\" can be seen as the cultural legacy of colonialism, or forms of social action contributing to the continuation of Western hegemony. To some outside of the realm of this discourse, the term is critiqued as being unclear, unfocused, and/or contradictory in nature.\n\nThe work of French philosopher and social theorist Michel Foucault has heavily influenced use of the term \"cultural imperialism,\" particularly his philosophical interpretation of power and his concept of governmentality.\n\nFollowing an interpretation of power similar to that of Machiavelli, Foucault defines power as immaterial, as a \"certain type of relation between individuals\" that has to do with complex strategic social positions that relate to the subject's ability to control its environment and influence those around itself. According to Foucault, power is intimately tied with his conception of truth. \"Truth,\" as he defines it, is a \"system of ordered procedures for the production, regulation, distribution, circulation, and operation of statements\" which has a \"circular relation\" with systems of power. Therefore, inherent in systems of power, is always \"truth,\" which is culturally specific, inseparable from ideology which often coincides with various forms of hegemony. \"Cultural imperialism\" may be an example of this.\n\nFoucault's interpretation of governance is also very important in constructing theories of transnational power structure. In his lectures at the Collège de France, Foucault often defines governmentality as the broad art of \"governing,\" which goes beyond the traditional conception of governance in terms of state mandates, and into other realms such as governing \"a household, souls, children, a province, a convent, a religious order, a family\". This relates directly back to Machiavelli's The Prince, and Foucault's aforementioned conceptions of truth and power. (i.e. various subjectivities are created through power relations that are culturally specific, which lead to various forms of culturally specific governmentality such as neoliberal governmentality.)\n\nInformed by the works of Noam Chomsky, Foucault, and Antonio Gramsci, Edward Saïd is a founding figure of postcolonialism, established with the book \"Orientalism\" (1978), a humanist critique of The Enlightenment, which criticizes Western knowledge of \"The East\" — specifically the English and the French constructions of what is and what is not \"Oriental\". Whereby said \"knowledge\" then led to cultural tendencies towards a binary opposition of the Orient vs. the Occident, wherein one concept is defined in opposition to the other concept, and from which they emerge as of unequal value. In \"Culture and Imperialism\" (1993), the sequel to \"Orientalism\", Saïd proposes that, despite the formal end of the “age of empire” after the Second World War (1939–45), colonial imperialism left a cultural legacy to the (previously) colonized peoples, which remains in their contemporary civilizations; and that said \"cultural imperialism\" is very influential in the international systems of power.\n\nA self-described \"practical Marxist-feminist-deconstructionist\" Gayatri Chakravorty Spivak has published a number of works challenging the \"legacy of colonialism\" including \"A Critique of Postcolonial Reason: Towards a History of the Vanishing Present\" (1999), \"Other Asias\" (2005), and \"Can the Subaltern Speak?\" (1988).\n\nIn \"Can the Subaltern Speak?\" Spivak critiques common representations in the West of the Sati, as being controlled by authors other than the participants (specifically English colonizers and Hindu leaders). Because of this, Spivak argues that the subaltern, referring to the communities that participate in the Sati, are not able to represent themselves through their own voice. Spivak says that cultural imperialism has the power to disqualify or erase the knowledge and mode of education of certain populations that are low on the social hierarchy.\n\nThroughout \"Can the Subaltern Speak?\", Spivak is cites the works of Karl Marx, Michel Foucault, Walter Benjamin, Louis Althusser, Jacques Derrida, and Edward Said, among others.\n\nIn \"A critique of Postcolonial Reason\", Spivak argues that Western philosophy has a history of not only exclusion of the subaltern from discourse, but also does not allow them to occupy the space of a fully human subject.\n\n\"Cultural imperialism\" can refer to either the forced acculturation of a subject population, or to the voluntary embracing of a foreign culture by individuals who do so of their own free will. Since these are two very different referents, the validity of the term has been called into question.\n\nCultural influence can be seen by the \"receiving\" culture as either a threat to or an enrichment of its cultural identity. It seems therefore useful to distinguish between cultural imperialism as an (active or passive) attitude of superiority, and the position of a culture or group that seeks to complement its own cultural production, considered partly deficient, with imported products.\n\nThe imported products or services can themselves represent, or be associated with, certain values (such as consumerism). According to one argument, the \"receiving\" culture does not necessarily perceive this link, but instead absorbs the foreign culture passively through the use of the foreign goods and services. Due to its somewhat concealed, but very potent nature, this hypothetical idea is described by some experts as \"\"banal imperialism\".\" For example, it is argued that while \"American companies are accused of wanting to control 95 percent of the world's consumers\", \"cultural imperialism involves much more than simple consumer goods; it involved the dissemination of American principles such as freedom and democracy\", a process which \"may sound appealing\" but which \"masks a frightening truth: many cultures around the world are disappearing due to the overwhelming influence of corporate and cultural America\".\n\nSome believe that the newly globalised economy of the late 20th and early 21st century has facilitated this process through the use of new information technology. This kind of cultural imperialism is derived from what is called \"soft power\". The theory of electronic colonialism extends the issue to global cultural issues and the impact of major multi-media conglomerates, ranging from Viacom, Time-Warner, Disney, News Corp, to Google and Microsoft with the focus on the hegemonic power of these mainly United States-based communication giants.\n\nOne of the reasons often given for opposing any form of cultural imperialism, voluntary or otherwise, is the preservation of cultural diversity, a goal seen by some as analogous to the preservation of ecological diversity. Proponents of this idea argue either that such diversity is valuable in itself, to preserve human historical heritage and knowledge, or instrumentally valuable because it makes available more ways of solving problems and responding to catastrophes, natural or otherwise.\n\nOf all the areas of the world that scholars have claimed to be adversely affected by imperialism, Africa is probably the most notable. In the expansive \"age of imperialism\" of the nineteenth century, scholars have argued that European colonization in Africa has led to the elimination of many various cultures, worldviews, and epistemologies. This, arguably has led to uneven development, and further informal forms of social control having to do with culture and imperialism. A variety of factors, scholars argue, lead to the elimination of cultures, worldviews, and epistemologies, such as \"de-linguicization\" (replacing native African languages with European ones) and devaluing ontologies that are not explicitly individualistic. One scholar, Ali A. Obdi, claims that imperialism inherently \"involve[s] extensively interactive regimes and heavy contexts of identity deformation, misrecognition, loss of self-esteem, and individual and social doubt in self-efficacy.\"(2000: 12) Therefore, all imperialism would always, already be cultural.\n\nNeoliberalism is often critiqued by sociologists, anthropologists, and cultural studies scholars as being culturally imperialistic. Critics of neoliberalism, at times, claim that it is the newly predominant form of imperialism. Other Scholars, such as Elizabeth Dunn and Julia Elyachar have claimed that neoliberalism requires and creates its own form of governmentality.\n\nIn Dunn's work, \"Privatizing Poland\", she argues that the expansion of the multinational corporation, Gerber, into Poland in the 1990s imposed Western, neoliberal governmentality, ideologies, and epistemologies upon the post-soviet persons hired. Cultural conflicts occurred most notably the company's inherent individualistic policies, such as promoting competition among workers rather than cooperation, and in its strong opposition to what the company owners claimed was bribery.\n\nIn Elyachar's work, \"Markets of Dispossession\", she focuses on ways in which, in Cairo, NGOs along with INGOs and the state promoted neoliberal governmentality through schemas of economic development that relied upon \"youth microentrepreneurs.\" Youth microentrepreneurs would receive small loans to build their own businesses, similar to the way that microfinance supposedly operates. Elyachar argues though, that these programs not only were a failure, but that they shifted cultural opinions of value (personal and cultural) in a way that favored Western ways of thinking and being.\n\nOften, methods of promoting development and social justice to are critiqued as being imperialistic, in a cultural sense. For example, Chandra Mohanty has critiqued Western feminism, claiming that it has created a misrepresentation of the \"third world woman\" as being completely powerless, unable to resist male dominance. Thus, this leads to the often critiqued narrative of the \"white man\" saving the \"brown woman\" from the \"brown man.\" Other, more radical critiques of development studies, have to do with the field of study itself. Some scholars even question the intentions of those developing the field of study, claiming that efforts to \"develop\" the Global South were never about the South itself. Instead, these efforts, it is argued, were made in order to advance Western development and reinforce Western hegemony.\n\nThe core of cultural imperialism thesis is integrated with the political-economy traditional approach in media effects research. Critics of cultural imperialism commonly claim that non-Western cultures, particularly from the Third World, will forsake their traditional values and lose their cultural identities when they are solely exposed to Western media. Nonetheless, Michael B. Salwen, in his book \"Critical Studies in Mass Communication\" (1991), claims that cross-consideration and integration of empirical findings on cultural imperialist influences is very critical in terms of understanding mass media in the international sphere. He recognizes both of contradictory contexts on cultural imperialist impacts. \nThe first context is where cultural imperialism imposes socio-political disruptions on developing nations. Western media can distort images of foreign cultures and provoke personal and social conflicts to developing nations in some cases. \nAnother context is that peoples in developing nations resist to foreign media and preserve their cultural attitudes. Although he admits that outward manifestations of Western culture may be adopted, but the fundamental values and behaviors remain still. Furthermore, positive effects might occur when male-dominated cultures adopt the “liberation” of women with exposure to Western media and it stimulates ample exchange of cultural exchange.\n\nCritics of scholars who discuss cultural imperialism have a number of critiques. \"Cultural imperialism\" is a term that is only used in discussions where cultural relativism and constructivism are generally taken as true. (One cannot critique promoting Western values if one believes that said values are absolutely correct. Similarly, one cannot argue that Western epistemology is unjustly promoted in non-Western societies if one believes that those epistemologies are absolutely correct.) Therefore, those who disagree with cultural relativism and/or constructivism may critique the employment of the term, \"cultural imperialism\" on those terms.\n\nJohn Tomlinson provides a critique of cultural imperialism theory and reveals major problems in the way in which the idea of cultural, as opposed to economic or political, imperialism is formulated. In his book \"Cultural Imperialism: A Critical Introduction\", he delves into the much debated “media imperialism” theory. Summarizing research on the Third World’s reception of American television shows, he challenges the cultural imperialism argument, conveying his doubts about the degree to which US shows in developing nations actually carry US values and improve the profits of US companies. Tomlinson suggests that cultural imperialism is growing in some respects, but local transformation and interpretations of imported media products propose that cultural diversification is not at an end in global society. He explains that one of the fundamental conceptual mistakes of cultural imperialism is to take for granted that the distribution of cultural goods can be considered as cultural dominance. He thus supports his argument highly criticizing the concept that Americanization is occurring through global overflow of American television products. He points to a myriad of examples of television networks who have managed to dominate their domestic markets and that domestic programs generally top the ratings. He also doubts the concept that cultural agents are passive receivers of information. He states that movement between cultural/geographical areas always involves translation, mutation, adaptation, and the creation of hybridity.\n\nOther major critiques are that the term is not defined well, and employs further terms that are not defined well, and therefore lacks explanatory power, that \"cultural imperialism\" is hard to measure, and that the theory of a legacy of colonialism is not always true.\n\nDavid Rothkopf, managing director of Kissinger Associates and an adjunct professor of international affairs at Columbia University (who also served as a senior US Commerce Department official in the Clinton Administration), wrote about cultural imperialism in his provocatively titled \"In Praise of Cultural Imperialism?\" in the summer 1997 issue of \"Foreign Policy\" magazine. Rothkopf says that the United States should embrace \"cultural imperialism\" as in its self-interest. But his definition of cultural imperialism stresses spreading the values of tolerance and openness to cultural change in order to avoid war and conflict between cultures as well as expanding accepted technological and legal standards to provide free traders with enough security to do business with more countries. Rothkopf's definition almost exclusively involves allowing individuals in other nations to accept or reject foreign cultural influences. He also mentions, but only in passing, the use of the English language and consumption of news and popular music and film as cultural dominance that he supports. Rothkopf additionally makes the point that globalization and the Internet are accelerating the process of cultural influence.\n\nCulture is sometimes used by the organizers of society — politicians, theologians, academics, and families — to impose and ensure order, the rudiments of which change over time as need dictates. One need only look at the 20th century's genocides. In each one, leaders used culture as a political front to fuel the passions of their armies and other minions and to justify their actions among their people.\n\nRothkopf then cites genocide and s in Armenia, Russia, the Holocaust, Cambodia, Bosnia and Herzegovina, Rwanda and East Timor as examples of culture (in some cases expressed in the ideology of \"political culture\" or religion) being misused to justify violence. He also acknowledges that cultural imperialism in the past has been guilty of forcefully eliminating the cultures of natives in the Americas and in Africa, or through use of the Inquisition, \"\"and during the expansion of virtually every empire.\"\".The most important way to deal with cultural influence in any nation, according to Rothkopf, is to promote tolerance and allow, or even promote, cultural diversities that are compatible with tolerance and to eliminate those cultural differences that cause violent conflict:\n\nAlthough the term was popularized in the 1960s, and was used by its original proponents to refer to cultural hegemonies in a post-colonial world, cultural imperialism has also been used to refer to times further in the past.\n\nThe Roman empire has been seen as an early example of cultural imperialism.\n\nEarly Rome, in its conquest of Italy, assimilated the people of Etruria by replacing the Etruscan language with Latin, which led to the demise of that language and many aspects of Etruscan civilization.\n\nCultural Romanization was imposed on many parts of Rome's empire by \"many regions receiving Roman culture unwillingly, as a form of cultural imperialism.\" For example, when Greece was conquered by the Roman armies, Rome set about altering the culture of Greece to conform with Roman ideals. For instance, the Greek habit of stripping naked, in public, for exercise, was looked on askance by Roman writers, who considered the practice to be a cause of the Greeks' effeminacy and enslavement.\n\nThe Pax Romana was secured in the empire, in part, by the \"forced acculturation of the culturally diverse populations that Rome had conquered.\"\n\nBritish worldwide expansion in the eighteenth and nineteenth centuries was an economic and political phenomenon. However, \"there was also a strong social and cultural dimension to it, which Rudyard Kipling termed the 'white man's burden'.\" One of the ways this was carried out was by religious proselytizing, by, amongst others, the London Missionary Society, which was \"an agent of British cultural imperialism.\" Another way, was by the imposition of educational material on the colonies for an \"imperial curriculum\". Morag Bell writes, \"The promotion of empire through books, illustrative materials, and educational syllabuses was widespread, part of an education policy geared to cultural imperialism\". This was also true of science and technology in the empire. Douglas M. Peers and Nandini Gooptu note that \"Most scholars of colonial science in India now prefer to stress the ways in which science and technology worked in the service of colonialism, as both a 'tool of empire' in the practical sense and as a vehicle for cultural imperialism. In other words, science developed in India in ways that reflected colonial priorities, tending to benefit Europeans at the expense of Indians, while remaining dependent on and subservient to scientific authorities in the colonial metropolis.\"\n\nThe analysis of cultural imperialism carried out by Edward Said drew principally from a study of the British empire. According to Danilo Raponi, the cultural imperialism of the British in the nineteenth century had a much wider effect than only in the British empire. He writes, \"To paraphrase Said, I see cultural imperialism as a complex cultural hegemony of a country, Great Britain, that in the nineteenth century had no rivals in terms of its ability to project its power across the world and to influence the cultural, political and commercial affairs of most countries. It is the 'cultural hegemony' of a country whose power to export the most fundamental ideas and concepts at the basis of its understanding of 'civilisation' knew practically no bounds.\" In this, for example, Raponi includes Italy.\n\nThe New Cambridge Modern History writes about the cultural imperialism of Napoleonic France. Napoleon used the Institut de France \"as an instrument for transmuting French universalism into cultural imperialism.\" Members of the Institute (who included Napoleon), descended upon Egypt in 1798. \"Upon arrival they organised themselves into an Institute of Cairo. The Rosetta Stone is their most famous find. The science of Egyptology is their legacy.\"\n\nAfter the First World War, Germans were worried about the extent of French influence in the annexed Rhineland, with the French occupation of the Ruhr Valley in 1923. An early use of the term appeared in an essay by Paul Ruhlmann (as \"Peter Hartmann\") at that date, entitled \"French Cultural Imperialism on the Rhine\".\n\n\"Cultural imperialism\" has also been used in connection with the expansion of German influence under the Nazis in the middle of the twentieth century. Alan Steinweis and Daniel Rogers note that even before the Nazis came to power, \"Already in the Weimar Republic, German academic specialists on eastern Europe had contributed through their publications and teaching to the legitimization Of German territorial revanchism and cultural imperialism. These scholars operated primarily in the disciplines Of history, economics, geography, and literature.\"\n\nIn the area of music, Michael Kater writes that during the WWII German occupation of France, Hans Rosbaud, a German conductor based by the Nazi regime in Strasbourg, became \"at least nominally, a servant of Nazi cultural imperialism directed against the French.\"\n\nIn Italy during the war, Germany pursued \"a European cultural front that gravitates around German culture\". The Nazi propaganda minister Joseph Goebbels set up the European Union of Writers, \"one of Goebbels's most ambitious projects for Nazi cultural hegemony. Presumably a means of gathering authors from Germany, Italy, and the occupied countries to plan the literary life of the new Europe, the union soon emerged as a vehicle of German cultural imperialism.\"\n\nFor other parts of Europe, Robert Gerwarth, writing about cultural imperialism and Reinhard Heydrich, states that the \"Nazis' Germanization project was based on a historically unprecedented programme of racial stock-taking, theft, expulsion and murder.\" Also, \"The full integration of the [Czech] Protectorate into this New Order required the complete Germanization of the Protectorate's cultural life and the eradication of indigenous Czech and Jewish culture.\"\n\nThe actions by Nazi Germany reflect on the notion of race and culture playing a significant role in imperialism. The idea that there is a distinction between the Germans and the Jews has created the illusion of Germans believing they were superior to the Jewish inferiors, the notion of us/them and self/others.\n\n\n\n", "id": "6267", "title": "Cultural imperialism"}
{"url": "https://en.wikipedia.org/wiki?curid=6271", "text": "Chemical reaction\n\nA chemical reaction is a process that leads to the transformation of one set of chemical substances to another. Classically, chemical reactions encompass changes that only involve the positions of electrons in the forming and breaking of chemical bonds between atoms, with no change to the nuclei (no change to the elements present), and can often be described by a chemical equation. Nuclear chemistry is a sub-discipline of chemistry that involves the chemical reactions of unstable and radioactive elements where both electronic and nuclear changes can occur.\n\nThe substance (or substances) initially involved in a chemical reaction are called reactants or reagents. Chemical reactions are usually characterized by a chemical change, and they yield one or more products, which usually have properties different from the reactants. Reactions often consist of a sequence of individual sub-steps, the so-called elementary reactions, and the information on the precise course of action is part of the reaction mechanism. Chemical reactions are described with chemical equations, which symbolically present the starting materials, end products, and sometimes intermediate products and reaction conditions.\n\nChemical reactions happen at a characteristic reaction rate at a given temperature and chemical concentration. Typically, reaction rates increase with increasing temperature because there is more thermal energy available to reach the activation energy necessary for breaking bonds between atoms.\n\nReactions may proceed in the forward or reverse direction until they go to completion or reach equilibrium. Reactions that proceed in the forward direction to approach equilibrium are often described as spontaneous, requiring no input of free energy to go forward. Non-spontaneous reactions require input of free energy to go forward (examples include charging a battery by applying an external electrical power source, or photosynthesis driven by absorption of electromagnetic radiation in the form of sunlight).\n\nDifferent chemical reactions are used in combinations during chemical synthesis in order to obtain a desired product. In biochemistry, a consecutive series of chemical reactions (where the product of one reaction is the reactant of the next reaction) form metabolic pathways. These reactions are often catalyzed by protein enzymes. Enzymes increase the rates of biochemical reactions, so that metabolic syntheses and decompositions impossible under ordinary conditions can occur at the temperatures and concentrations present within a cell.\n\nThe general concept of a chemical reaction has been extended to reactions between entities smaller than atoms, including nuclear reactions, radioactive decays, and reactions between elementary particles as described by quantum field theory.\n\nChemical reactions such as combustion in fire, fermentation and the reduction of ores to metals were known since antiquity. Initial theories of transformation of materials were developed by Greek philosophers, such as the Four-Element Theory of Empedocles stating that any substance is composed of the four basic elements – fire, water, air and earth. In the Middle Ages, chemical transformations were studied by Alchemists. They attempted, in particular, to convert lead into gold, for which purpose they used reactions of lead and lead-copper alloys with sulfur.\n\nThe production of chemical substances that do not normally occur in nature has long been tried, such as the synthesis of sulfuric and nitric acids attributed to the controversial alchemist Jābir ibn Hayyān. The process involved heating of sulfate and nitrate minerals such as copper sulfate, alum and saltpeter. In the 17th century, Johann Rudolph Glauber produced hydrochloric acid and sodium sulfate by reacting sulfuric acid and sodium chloride. With the development of the lead chamber process in 1746 and the Leblanc process, allowing large-scale production of sulfuric acid and sodium carbonate, respectively, chemical reactions became implemented into the industry. Further optimization of sulfuric acid technology resulted in the contact process in the 1880s, and the Haber process was developed in 1909–1910 for ammonia synthesis.\n\nFrom the 16th century, researchers including Jan Baptist van Helmont, Robert Boyle and Isaac Newton tried to establish theories of the experimentally observed chemical transformations. The phlogiston theory was proposed in 1667 by Johann Joachim Becher. It postulated the existence of a fire-like element called \"phlogiston\", which was contained within combustible bodies and released during combustion. This proved to be false in 1785 by Antoine Lavoisier who found the correct explanation of the combustion as reaction with oxygen from the air.\n\nJoseph Louis Gay-Lussac recognized in 1808 that gases always react in a certain relationship with each other. Based on this idea and the atomic theory of John Dalton, Joseph Proust had developed the law of definite proportions, which later resulted in the concepts of stoichiometry and chemical equations.\n\nRegarding the organic chemistry, it was long believed that compounds obtained from living organisms were too complex to be obtained synthetically. According to the concept of vitalism, organic matter was endowed with a \"vital force\" and distinguished from inorganic materials. This separation was ended however by the synthesis of urea from inorganic precursors by Friedrich Wöhler in 1828. Other chemists who brought major contributions to organic chemistry include Alexander William Williamson with his synthesis of ethers and Christopher Kelk Ingold, who, among many discoveries, established the mechanisms of substitution reactions.\n\nChemical equations are used to graphically illustrate chemical reactions. They consist of chemical or structural formulas of the reactants on the left and those of the products on the right. They are separated by an arrow (→) which indicates the direction and type of the reaction; the arrow is read as the word \"yields\". The tip of the arrow points in the direction in which the reaction proceeds. A double arrow () pointing in opposite directions is used for equilibrium reactions. Equations should be balanced according to the stoichiometry, the number of atoms of each species should be the same on both sides of the equation. This is achieved by scaling the number of involved molecules (<ce>A, B, C</ce> and <ce>D</ce> in a schematic example below) by the appropriate integers \"a, b, c\" and \"d\".\n\nMore elaborate reactions are represented by reaction schemes, which in addition to starting materials and products show important intermediates or transition states. Also, some relatively minor additions to the reaction can be indicated above the reaction arrow; examples of such additions are water, heat, illumination, a catalyst, etc. Similarly, some minor products can be placed below the arrow, often with a minus sign.\nRetrosynthetic analysis can be applied to design a complex synthesis reaction. Here the analysis starts from the products, for example by splitting selected chemical bonds, to arrive at plausible initial reagents. A special arrow (⇒) is used in retro reactions.\n\nThe elementary reaction is the smallest division into which a chemical reaction can be decomposed, it has no intermediate products. Most experimentally observed reactions are built up from many elementary reactions that occur in parallel or sequentially. The actual sequence of the individual elementary reactions is known as reaction mechanism. An elementary reaction involves a few molecules, usually one or two, because of the low probability for several molecules to meet at a certain time.\nThe most important elementary reactions are unimolecular and bimolecular reactions. Only one molecule is involved in a unimolecular reaction; it is transformed by an isomerization or a dissociation into one or more other molecules. Such reactions require the addition of energy in the form of heat or light. A typical example of a unimolecular reaction is the cis–trans isomerization, in which the cis-form of a compound converts to the trans-form or vice versa.\n\nIn a typical dissociation reaction, a bond in a molecule splits (ruptures) resulting in two molecular fragments. The splitting can be homolytic or heterolytic. In the first case, the bond is divided so that each product retains an electron and becomes a neutral radical. In the second case, both electrons of the chemical bond remain with one of the products, resulting in charged ions. Dissociation plays an important role in triggering chain reactions, such as hydrogen–oxygen or polymerization reactions.\n\nFor bimolecular reactions, two molecules collide and react with each other. Their merger is called chemical synthesis or an addition reaction.\nAnother possibility is that only a portion of one molecule is transferred to the other molecule. This type of reaction occurs, for example, in redox and acid-base reactions. In redox reactions, the transferred particle is an electron, whereas in acid-base reactions it is a proton. This type of reaction is also called metathesis.\nfor example\n\nMost chemical reactions are reversible, that is they can and do run in both directions. The forward and reverse reactions are competing with each other and differ in reaction rates. These rates depend on the concentration and therefore change with time of the reaction: the reverse rate gradually increases and becomes equal to the rate of the forward reaction, establishing the so-called chemical equilibrium. The time to reach equilibrium depends on such parameters as temperature, pressure and the materials involved, and is determined by the minimum free energy. In equilibrium, the Gibbs free energy must be zero. The pressure dependence can be explained with the Le Chatelier's principle. For example, an increase in pressure due to decreasing volume causes the reaction to shift to the side with the fewer moles of gas.\n\nThe reaction yield stabilizes at equilibrium, but can be increased by removing the product from the reaction mixture or changed by increasing the temperature or pressure. A change in the concentrations of the reactants does not affect the equilibrium constant, but does affect the equilibrium position.\n\nChemical reactions are determined by the laws of thermodynamics. Reactions can proceed by themselves if they are exergonic, that is if they release energy. The associated free energy of the reaction is composed of two different thermodynamic quantities, enthalpy and entropy:\n\nReactions can be exothermic, where ΔH is negative and energy is released. Typical examples of exothermic reactions are precipitation and crystallization, in which ordered solids are formed from disordered gaseous or liquid phases. In contrast, in endothermic reactions, heat is consumed from the environment. This can occur by increasing the entropy of the system, often through the formation of gaseous reaction products, which have high entropy. Since the entropy increases with temperature, many endothermic reactions preferably take place at high temperatures. On the contrary, many exothermic reactions such as crystallization occur at low temperatures. Changes in temperature can sometimes reverse the sign of the enthalpy of a reaction, as for the carbon monoxide reduction of molybdenum dioxide:\nThis reaction to form carbon dioxide and molybdenum is endothermic at low temperatures, becoming less so with increasing temperature. ΔH° is zero at , and the reaction becomes exothermic above that temperature.\n\nChanges in temperature can also reverse the direction tendency of a reaction. For example, the water gas shift reaction\nis favored by low temperatures, but its reverse is favored by high temperature. The shift in reaction direction tendency occurs at .\n\nReactions can also be characterized by the internal energy which takes into account changes in the entropy, volume and chemical potential. The latter depends, among other things, on the activities of the involved substances.\n\nThe speed at which reactions takes place is studied by reaction kinetics. The rate depends on various parameters, such as:\n\n\nSeveral theories allow calculating the reaction rates at the molecular level. This field is referred to as reaction dynamics. The rate \"v\" of a first-order reaction, which could be disintegration of a substance A, is given by:\n\nIts integration yields:\n\nHere k is first-order rate constant having dimension 1/time, [A](t) is concentration at a time \"t\" and [A] is the initial concentration. The rate of a first-order reaction depends only on the concentration and the properties of the involved substance, and the reaction itself can be described with the characteristic half-life. More than one time constant is needed when describing reactions of higher order. The temperature dependence of the rate constant usually follows the Arrhenius equation:\n\nwhere E is the activation energy and k is the Boltzmann constant. One of the simplest models of reaction rate is the collision theory. More realistic models are tailored to a specific problem and include the transition state theory, the calculation of the potential energy surface, the Marcus theory and the Rice–Ramsperger–Kassel–Marcus (RRKM) theory.\n\nIn a synthesis reaction, two or more simple substances combine to form a more complex substance. These reactions are in the general form:\n\nTwo or more reactants yielding one product is another way to identify a synthesis reaction. One example of a synthesis reaction is the combination of iron and sulfur to form iron(II) sulfide:\n\nAnother example is simple hydrogen gas combined with simple oxygen gas to produce a more complex substance, such as water.\n\nA decomposition reaction is when a more complex substance breaks down into its more simple parts. It is thus the opposite of a synthesis reaction, and can be written as\n\nOne example of a decomposition reaction is the electrolysis of water to make oxygen and hydrogen gas:\n\nIn a single replacement reaction, a single uncombined element replaces another in a compound; in other words, one element trades places with another element in a compound These reactions come in the general form of:\n\nOne example of a single displacement reaction is when magnesium replaces hydrogen in water to make magnesium hydroxide and hydrogen gas:\n\nIn a double replacement reaction, the anions and cations of two compounds switch places and form two entirely different compounds. These reactions are in the general form:\n\nFor example, when barium chloride (BaCl) and magnesium sulfate (MgSO) react, the SO anion switches places with the 2Cl anion, giving the compounds BaSO and MgCl.\n\nAnother example of a double displacement reaction is the reaction of lead(II) nitrate with potassium iodide to form lead(II) iodide and potassium nitrate:\n\n \nRedox reactions can be understood in terms of transfer of electrons from one involved species (reducing agent) to another (oxidizing agent). In this process, the former species is \"oxidized\" and the latter is \"reduced\". Though sufficient for many purposes, these descriptions are not precisely correct. Oxidation is better defined as an increase in oxidation state, and reduction as a decrease in oxidation state. In practice, the transfer of electrons will always change the oxidation state, but there are many reactions that are classed as \"redox\" even though no electron transfer occurs (such as those involving covalent bonds).\n\nIn the following redox reaction, hazardous sodium metal reacts with toxic chlorine gas to form the ionic compound sodium chloride, or common table salt:\n\nIn the reaction, sodium metal goes from an oxidation state of 0 (as it is a pure element) to +1: in other words, the sodium lost one electron and is said to have been oxidized. On the other hand, the chlorine gas goes from an oxidation of 0 (it is also a pure element) to −1: the chlorine gains one electron and is said to have been reduced. Because the chlorine is the one reduced, it is considered the electron acceptor, or in other words, induces oxidation in the sodium – thus the chlorine gas is considered the oxidizing agent. Conversely, the sodium is oxidized or is the electron donor, and thus induces reduction in the other species and is considered the \"reducing agent\".\n\nWhich of the involved reactants would be reducing or oxidizing agent can be predicted from the electronegativity of their elements. Elements with low electronegativity, such as most metals, easily donate electrons and oxidize – they are reducing agents. On the contrary, many ions with high oxidation numbers, such as , , , , can gain one or two extra electrons and are strong oxidizing agents.\n\nThe number of electrons donated or accepted in a redox reaction can be predicted from the electron configuration of the reactant element. Elements try to reach the low-energy noble gas configuration, and therefore alkali metals and halogens will donate and accept one electron respectively. Noble gases themselves are chemically inactive.\n\nAn important class of redox reactions are the electrochemical reactions, where electrons from the power supply are used as the reducing agent. These reactions are particularly important for the production of chemical elements, such as chlorine or aluminium. The reverse process in which electrons are released in redox reactions and can be used as electrical energy is possible and used in batteries.\n\nIn complexation reactions, several ligands react with a metal atom to form a coordination complex. This is achieved by providing lone pairs of the ligand into empty orbitals of the metal atom and forming dipolar bonds. The ligands are Lewis bases, they can be both ions and neutral molecules, such as carbon monoxide, ammonia or water. The number of ligands that react with a central metal atom can be found using the 18-electron rule, saying that the valence shells of a transition metal will collectively accommodate 18 electrons, whereas the symmetry of the resulting complex can be predicted with the crystal field theory and ligand field theory. Complexation reactions also include ligand exchange, in which one or more ligands are replaced by another, and redox processes which change the oxidation state of the central metal atom.\n\nIn the Brønsted–Lowry acid–base theory, an acid-base reaction involves a transfer of protons (H) from one species (the acid) to another (the base). When a proton is removed from an acid, the resulting species is termed that acid's conjugate base. When the proton is accepted by a base, the resulting species is termed that base's conjugate acid. In other words, acids act as proton donors and bases act as proton acceptors according to the following equation:\n\nThe reverse reaction is possible, and thus the acid/base and conjugated base/acid are always in equilibrium. The equilibrium is determined by the acid and base dissociation constants (\"K\" and \"K\") of the involved substances. A special case of the acid-base reaction is the neutralization where an acid and a base, taken at exactly same amounts, form a neutral salt.\n\nAcid-base reactions can have different definitions depending on the acid-base concept employed. Some of the most common are:\n\nPrecipitation is the formation of a solid in a solution or inside another solid during a chemical reaction. It usually takes place when the concentration of dissolved ions exceeds the solubility limit and forms an insoluble salt. This process can be assisted by adding a precipitating agent or by removal of the solvent. Rapid precipitation results in an amorphous or microcrystalline residue and slow process can yield single crystals. The latter can also be obtained by recrystallization from microcrystalline salts.\n\nReactions can take place between two solids. However, because of the relatively small diffusion rates in solids, the corresponding chemical reactions are very slow in comparison to liquid and gas phase reactions. They are accelerated by increasing the reaction temperature and finely dividing the reactant to increase the contacting surface area.\n\nReaction can take place at the solid|gas interface, surfaces at very low pressure such as ultra-high vacuum. Via scanning tunneling microscopy, it is possible to observe reactions at the solid|gas interface in real space, if the time scale of the reaction is in the correct range. Reactions at the solid|gas interface are in some cases related to catalysis.\n\nIn photochemical reactions, atoms and molecules absorb energy (photons) of the illumination light and convert into an excited state. They can then release this energy by breaking chemical bonds, thereby producing radicals. Photochemical reactions include hydrogen–oxygen reactions, radical polymerization, chain reactions and rearrangement reactions.\n\nMany important processes involve photochemistry. The premier example is photosynthesis, in which most plants use solar energy to convert carbon dioxide and water into glucose, disposing of oxygen as a side-product. Humans rely on photochemistry for the formation of vitamin D, and vision is initiated by a photochemical reaction of rhodopsin. In fireflies, an enzyme in the abdomen catalyzes a reaction that results in bioluminescence. Many significant photochemical reactions, such as ozone formation, occur in the Earth atmosphere and constitute atmospheric chemistry.\n\nIn catalysis, the reaction does not proceed directly, but through reaction with a third substance known as catalyst. Although the catalyst takes part in the reaction, it is returned to its original state by the end of the reaction and so is not consumed. However, it can be inhibited, deactivated or destroyed by secondary processes. Catalysts can be used in a different phase (heterogeneous) or in the same phase (homogeneous) as the reactants. In heterogeneous catalysis, typical secondary processes include coking where the catalyst becomes covered by polymeric side products. Additionally, heterogeneous catalysts can dissolve into the solution in a solid–liquid system or evaporate in a solid–gas system. Catalysts can only speed up the reaction – chemicals that slow down the reaction are called inhibitors. Substances that increase the activity of catalysts are called promoters, and substances that deactivate catalysts are called catalytic poisons. With a catalyst, a reaction which is kinetically inhibited by a high activation energy can take place in circumvention of this activation energy.\n\nHeterogeneous catalysts are usually solids, powdered in order to maximize their surface area. Of particular importance in heterogeneous catalysis are the platinum group metals and other transition metals, which are used in hydrogenations, catalytic reforming and in the synthesis of commodity chemicals such as nitric acid and ammonia. Acids are an example of a homogeneous catalyst, they increase the nucleophilicity of carbonyls, allowing a reaction that would not otherwise proceed with electrophiles. The advantage of homogeneous catalysts is the ease of mixing them with the reactants, but they may also be difficult to separate from the products. Therefore, heterogeneous catalysts are preferred in many industrial processes.\n\nIn organic chemistry, in addition to oxidation, reduction or acid-base reactions, a number of other reactions can take place which involve covalent bonds between carbon atoms or carbon and heteroatoms (such as oxygen, nitrogen, halogens, etc.). Many specific reactions in organic chemistry are name reactions designated after their discoverers.\n\nIn a substitution reaction, a functional group in a particular chemical compound is replaced by another group. These reactions can be distinguished by the type of substituting species into a nucleophilic, electrophilic or radical substitution.\nIn the first type, a nucleophile, an atom or molecule with an excess of electrons and thus a negative charge or partial charge, replaces another atom or part of the \"substrate\" molecule. The electron pair from the nucleophile attacks the substrate forming a new bond, while the leaving group departs with an electron pair. The nucleophile may be electrically neutral or negatively charged, whereas the substrate is typically neutral or positively charged. Examples of nucleophiles are hydroxide ion, alkoxides, amines and halides. This type of reaction is found mainly in aliphatic hydrocarbons, and rarely in aromatic hydrocarbon. The latter have high electron density and enter nucleophilic aromatic substitution only with very strong electron withdrawing groups. Nucleophilic substitution can take place by two different mechanisms, S1 and S2. In their names, S stands for substitution, N for nucleophilic, and the number represents the kinetic order of the reaction, unimolecular or bimolecular.\nThe S1 reaction proceeds in two steps. First, the leaving group is eliminated creating a carbocation. This is followed by a rapid reaction with the nucleophile.\n\nIn the S2 mechanism, the nucleophile forms a transition state with the attacked molecule, and only then the leaving group is cleaved. These two mechanisms differ in the stereochemistry of the products. S1 leads to the non-stereospecific addition and does not result in a chiral center, but rather in a set of geometric isomers (\"cis/trans\"). In contrast, a reversal (Walden inversion) of the previously existing stereochemistry is observed in the S2 mechanism.\n\nElectrophilic substitution is the counterpart of the nucleophilic substitution in that the attacking atom or molecule, an electrophile, has low electron density and thus a positive charge. Typical electrophiles are the carbon atom of carbonyl groups, carbocations or sulfur or nitronium cations. This reaction takes place almost exclusively in aromatic hydrocarbons, where it is called electrophilic aromatic substitution. The electrophile attack results in the so-called σ-complex, a transition state in which the aromatic system is abolished. Then, the leaving group, usually a proton, is split off and the aromaticity is restored. An alternative to aromatic substitution is electrophilic aliphatic substitution. It is similar to the nucleophilic aliphatic substitution and also has two major types, S1 and S2\n\nIn the third type of substitution reaction, radical substitution, the attacking particle is a radical. This process usually takes the form of a chain reaction, for example in the reaction of alkanes with halogens. In the first step, light or heat disintegrates the halogen-containing molecules producing the radicals. Then the reaction proceeds as an avalanche until two radicals meet and recombine.\n\nThe addition and its counterpart, the elimination, are reactions which change the number of substitutents on the carbon atom, and form or cleave multiple bonds. Double and triple bonds can be produced by eliminating a suitable leaving group. Similar to the nucleophilic substitution, there are several possible reaction mechanisms which are named after the respective reaction order. In the E1 mechanism, the leaving group is ejected first, forming a carbocation. The next step, formation of the double bond, takes place with elimination of a proton (deprotonation). The leaving order is reversed in the E1cb mechanism, that is the proton is split off first. This mechanism requires participation of a base. Because of the similar conditions, both reactions in the E1 or E1cb elimination always compete with the S1 substitution.\n\nThe E2 mechanism also requires a base, but there the attack of the base and the elimination of the leaving group proceed simultaneously and produce no ionic intermediate. In contrast to the E1 eliminations, different stereochemical configurations are possible for the reaction product in the E2 mechanism, because the attack of the base preferentially occurs in the anti-position with respect to the leaving group. Because of the similar conditions and reagents, the E2 elimination is always in competition with the S2-substitution.\nThe counterpart of elimination is the addition where double or triple bonds are converted into single bonds. Similar to the substitution reactions, there are several types of additions distinguished by the type of the attacking particle. For example, in the electrophilic addition of hydrogen bromide, an electrophile (proton) attacks the double bond forming a carbocation, which then reacts with the nucleophile (bromine). The carbocation can be formed on either side of the double bond depending on the groups attached to its ends, and the preferred configuration can be predicted with the Markovnikov's rule. This rule states that \"In the heterolytic addition of a polar molecule to an alkene or alkyne, the more electronegative (nucleophilic) atom (or part) of the polar molecule becomes attached to the carbon atom bearing the smaller number of hydrogen atoms.\"\n\nIf the addition of a functional group takes place at the less substituted carbon atom of the double bond, then the electrophilic substitution with acids is not possible. In this case, one has to use the hydroboration–oxidation reaction, where in the first step, the boron atom acts as electrophile and adds to the less substituted carbon atom. At the second step, the nucleophilic hydroperoxide or halogen anion attacks the boron atom.\n\nWhile the addition to the electron-rich alkenes and alkynes is mainly electrophilic, the nucleophilic addition plays an important role for the carbon-heteroatom multiple bonds, and especially its most important representative, the carbonyl group. This process is often associated with an elimination, so that after the reaction the carbonyl group is present again. It is therefore called addition-elimination reaction and may occur in carboxylic acid derivatives such as chlorides, esters or anhydrides. This reaction is often catalyzed by acids or bases, where the acids increase by the electrophilicity of the carbonyl group by binding to the oxygen atom, whereas the bases enhance the nucleophilicity of the attacking nucleophile.\n\nNucleophilic addition of a carbanion or another nucleophile to the double bond of an alpha, beta unsaturated carbonyl compound can proceed via the Michael reaction, which belongs to the larger class of conjugate additions. This is one of the most useful methods for the mild formation of C–C bonds.\n\nSome additions which can not be executed with nucleophiles and electrophiles, can be succeeded with free radicals. As with the free-radical substitution, the radical addition proceeds as a chain reaction, and such reactions are the basis of the free-radical polymerization.\n\nIn a rearrangement reaction, the carbon skeleton of a molecule is rearranged to give a structural isomer of the original molecule. These include hydride shift reactions such as the Wagner-Meerwein rearrangement, where a hydrogen, alkyl or aryl group migrates from one carbon to a neighboring carbon. Most rearrangements are associated with the breaking and formation of new carbon-carbon bonds. Other examples are sigmatropic reaction such as the Cope rearrangement.\n\nCyclic rearrangements include cycloadditions and, more generally, pericyclic reactions, wherein two or more double bond-containing molecules form a cyclic molecule. An important example of cycloaddition reaction is the Diels–Alder reaction (the so-called [4+2] cycloaddition) between a conjugated diene and a substituted alkene to form a substituted cyclohexene system.\n\nWhether a certain cycloaddition would proceed depends on the electronic orbitals of the participating species, as only orbitals with the same sign of wave function will overlap and interact constructively to form new bonds. Cycloaddition is usually assisted by light or heat. These perturbations result in different arrangement of electrons in the excited state of the involved molecules and therefore in different effects. For example, the [4+2] Diels-Alder reactions can be assisted by heat whereas the [2+2] cycloaddition is selectively induced by light. Because of the orbital character, the potential for developing stereoisomeric products upon cycloaddition is limited, as described by the Woodward–Hoffmann rules.\n\nBiochemical reactions are mainly controlled by enzymes. These proteins can specifically catalyze a single reaction, so that reactions can be controlled very precisely. The reaction takes place in the active site, a small part of the enzyme which is usually found in a cleft or pocket lined by amino acid residues, and the rest of the enzyme is used mainly for stabilization. The catalytic action of enzymes relies on several mechanisms including the molecular shape (\"induced fit\"), bond strain, proximity and orientation of molecules relative to the enzyme, proton donation or withdrawal (acid/base catalysis), electrostatic interactions and many others.\n\nThe biochemical reactions that occur in living organisms are collectively known as metabolism. Among the most important of its mechanisms is the anabolism, in which different DNA and enzyme-controlled processes result in the production of large molecules such as proteins and carbohydrates from smaller units. Bioenergetics studies the sources of energy for such reactions. An important energy source is glucose, which can be produced by plants via photosynthesis or assimilated from food. All organisms use this energy to produce adenosine triphosphate (ATP), which can then be used to energize other reactions.\n\nChemical reactions are central to chemical engineering where they are used for the synthesis of new compounds from natural raw materials such as petroleum and mineral ores. It is essential to make the reaction as efficient as possible, maximizing the yield and minimizing the amount of reagents, energy inputs and waste. Catalysts are especially helpful for reducing the energy required for the reaction and increasing its reaction rate.\n\nSome specific reactions have their niche applications. For example, the thermite reaction is used to generate light and heat in pyrotechnics and welding. Although it is less controllable than the more conventional oxy-fuel welding, arc welding and flash welding, it requires much less equipment and is still used to mend rails, especially in remote areas.\n\nMechanisms of monitoring chemical reactions depend strongly on the reaction rate. Relatively slow processes can be analyzed in situ for the concentrations and identities of the individual ingredients. Important tools of real time analysis are the measurement of pH and analysis of optical absorption (color) and emission spectra. A less accessible but rather efficient method is introduction of a radioactive isotope into the reaction and monitoring how it changes over time and where it moves to; this method is often used to analyze redistribution of substances in the human body. Faster reactions are usually studied with ultrafast laser spectroscopy where utilization of femtosecond lasers allows short-lived transition states to be monitored at time scaled down to a few femtoseconds.\n\n\n", "id": "6271", "title": "Chemical reaction"}
{"url": "https://en.wikipedia.org/wiki?curid=6272", "text": "Charleston\n\nCharleston most commonly refers to:\n\n\nCharleston may also refer to:\n\nIn Australia:\nIn Canada:\n\nIn New Zealand:\n\nIn the United Kingdom:\n\nIn the United States:\n\n\n\n\n\n\n\n", "id": "6272", "title": "Charleston"}
{"url": "https://en.wikipedia.org/wiki?curid=6276", "text": "Casiquiare canal\n\nThe Casiquiare river is a distributary of the upper Orinoco flowing southward into the Rio Negro, in Venezuela, South America. As such, it forms a unique natural canal between the Orinoco and Amazon river systems. It is the world's largest river of the kind that links two major river systems, a so-called bifurcation. The area forms a water divide, more dramatically at regional flood stage.\n\nIn 1744 a Jesuit priest named Father Roman, while ascending the Orinoco River, met some Portuguese slave-traders from the settlements on the Rio Negro. He accompanied them on their return, by way of the Casiquiare canal, and afterwards retraced his route to the Orinoco. Charles Marie de La Condamine, seven months later, was able to give to the \"Académie française\" an account of Father Roman's voyage, and thus confirm the existence of this waterway, first reported by Father Acuña in 1639.\n\nLittle credence was given to Father Roman's statement until it was verified, in 1756, by the Spanish Boundary-line Commission of Yturriaga and Solano. In 1800 German scientist Alexander von Humboldt and French botanist Aimé Bonpland explored the river. During a 1924–25 expedition, Alexander H. Rice, Jr. of Harvard University traveled up the Orinoco, traversed the Casiquiare canal, and descended the Rio Negro to the Amazon at Manaus. It was the first expedition to use aerial photography and shortwave radio for mapping of the region. In 1968 the Casiquiare was navigated by an SRN6 hovercraft during a National Geographic expedition.\n\nThe origin of the Casiquiare, at the River Orinoco, is below the mission of La Esmeralda at , and about above sea level. Its mouth at the Rio Negro, an affluent of the Amazon River, is near the town of San Carlos and is above sea level.\n\nThe general course is south-west, and its length, including windings, is about . Its width, at its bifurcation with the Orinoco, is approximately , with a current towards the Rio Negro of . However, as it gains in volume from the very numerous tributary streams, large and small, that it receives en route, its velocity increases, and in the wet season reaches , even in certain stretches. It broadens considerably as it approaches its mouth, where it is about wide. The volume of water the Casiquiare captures from the Orinoco is small in comparison to what it accumulates in its course.\n\nIn flood time, it is said to have a second connection with the Rio Negro by a branch, which it throws off to the westward, called the Itinivini, which leaves it at a point about above its mouth. In the dry season, it has shallows, and is obstructed by sandbanks, a few rapids and granite rocks. Its shores are densely wooded, and the soil more fertile than that along the Rio Negro. The general slope of the plains through which the canal runs is south-west, but those of the Rio Negro slope south-east.\n\nThe Casiquiare is not a sluggish canal on a flat tableland, but a great, rapid river which, if its upper waters had not found contact with the Orinoco, perhaps by cutting back, would belong entirely to the Negro branch of the Amazon.\n\nTo the west of the Casiquiare, there is a much shorter and easier portage between the Orinoco and Amazon basins, called the isthmus of Pimichin, which is reached by ascending the Terni branch of the Atabapo River, an affluent of the Orinoco. Although the Terni is somewhat obstructed, it is believed that it could easily be made navigable for small craft. The isthmus is across, with undulating ground, nowhere over high, with swamps and marshes. It is much used for the transit of large canoes, which are hauled across it from the Terni river, and which reach the Rio Negro by the little stream called the Pimichin.\n\nThe Casiquiare canal – Orinoco River hydrographic divide is a representation of the hydrographic water divide that delineates the separation between the Orinoco Basin and the Amazon Basin. (The Orinoco Basin flows west–north–northeast into the Caribbean; the Amazon Basin flows east into the western Atlantic in the extreme northeast of Brazil.)\n\nEssentially the river divide is a west-flowing, upriver section of Venezuela's Orinoco River with an outflow to the south into the Amazon Basin. This named outflow is the Casiquiare canal, which, as it heads downstream (southerly), picks up speed and also accumulates water volume.\n\nThe greatest manifestation of the divide is during floods. During flood stage, the Casiquiare's main outflow point into the Rio Negro is supplemented by an overflow that is a second, and more minor, entry river bifurcation into the Rio Negro and upstream from its major, common low-water entry confluence with the Rio Negro. At flood, the river becomes an area flow source, far more than a narrow confined river.\n\nThe Casiquiare canal connects the upper Orinoco, below the mission of Esmeraldas, with the Rio Negro affluent of the Amazon River near the town of San Carlos.\n\nThe simplest description (besides the entire area-floodplain) of the water divide is a \"south-bank Orinoco River strip\" at the exit point of the Orinoco, also the origin of the Casiquiare canal. However during the Orinoco's flood stage, that single, simply defined \"origin of the canal\" is turned into a region, and an entire strip along the southern bank of the Orinoco River.\n\n\n\n", "id": "6276", "title": "Casiquiare canal"}
{"url": "https://en.wikipedia.org/wiki?curid=6279", "text": "Capetian dynasty\n\nThe Capetian dynasty , also known as the House of France, is a dynasty of Frankish origin, founded by Hugh Capet. It is among the largest and oldest royal houses in Europe and the world, and consisting of Hugh Capet's male-line descendants. The senior line ruled in France as the House of Capet from the election of Hugh Capet in 987 until the death of Charles IV in 1328. They were succeeded by cadet branches, the Houses of Valois and Bourbon, which ruled until the French Revolution.\n\nThe dynasty had a crucial role in the formation of the French state. Initially obeyed only in their own demesne, the Île-de-France, the Capetian kings slowly but steadily increased their power and influence until it grew to cover the entirety of their realm. For a detailed narration on the growth of French royal power, see \"Crown lands of France\".\n\nMembers of the dynasty were traditionally Catholic. The early Capetians had an alliance with the Church. The French were also the most active participants in the Crusades, culminating in a series of five Crusader Kings – Louis VII, Philip Augustus, Louis VIII, Saint Louis, and Philip III. The Capetian alliance with the papacy suffered a severe blow after the disaster of the Aragonese Crusade. Philip III's son and successor, Philip IV, humiliated a pope and brought the papacy under French control. The later Valois, starting with Francis I, ignored religious differences and allied with the Ottoman Sultan to counter the growing power of the Holy Roman Empire. Henry IV was a Protestant at the time of his accession, but realized the necessity of conversion after four years of religious warfare.\n\nThe Capetians generally enjoyed a harmonious family relationship. By tradition, younger sons and brothers of the King of France are given appanages for them to maintain their rank and to dissuade them from claiming the French crown itself. When Capetian cadets did aspire for kingship, their ambitions were directed not at the French throne, but at foreign thrones. Through this, the Capetians spread widely over Europe.\n\nIn modern times, both King Felipe VI of Spain and Grand Duke Henri of Luxembourg are members of this family, both through the Bourbon branch of the dynasty. Along with the House of Habsburg, it was one of the two most powerful continental European royal families, dominating European politics for nearly five centuries.\n\nThe name of the dynasty derives from its founder, Hugh, who was known as \"Hugh Capet\". The meaning of \"Capet\" (a nickname rather than a surname of the modern sort) is unknown. While folk etymology identifies it with \"cape\", other suggestions suggest it to be connected to the Latin word \"caput\" (\"head\"), and thus explain it as meaning \"chief\" or \"head\".\n\nHistorians in the 19th century (see House of France) came to apply the name \"Capetian\" to both the ruling house of France and to the wider-spread male-line descendants of Hugh Capet. It was not a contemporary practice. The name \"Capet\" has also been used as a surname for French royalty, particularly but not exclusively those of the House of Capet. One notable use was during the French Revolution, when the dethroned King Louis XVI (a member of the House of Bourbon and a direct male-line descendant of Hugh Capet) and Queen Marie Antoinette (a member of the House of Habsburg-Lorraine) were referred to as \"Louis and Antoinette Capet\" (the queen being addressed as \"the Widow Capet\" after the execution of her husband).\n\nThe dynastic surname now used to describe Hugh Capet's family prior to his election as King of France is \"Robertians\" or \"Robertines.\" The name is derived from the family's first certain ancestor, Robert the Strong (b. 820), the count of Paris. Robert was probably son of Robert III of Worms (b. 800) and grandson of Robert of Hesbaye (b. 770). The Robertians probably originated in the county Hesbaye, around Tongeren in modern-day Belgium.\n\nThe sons of Robert the Strong were Odo and Robert, who both ruled as king of Western Francia. The family became Counts of Paris under Odo and Dukes of the Franks under Robert, possessing large parts of Neustria.\n\nThe Carolingian dynasty ceased to rule France upon the death of Louis V. After the death of Louis V, the son of Hugh the Great, Hugh Capet, was elected by the nobility as king of France. Hugh was crowned at Noyon on 3 July 987 with the full support from Holy Roman Emperor Otto III. With Hugh's coronation, a new era began for France, and his descendants came to be named the \"Capetians,\" with the Capetian dynasty ruling France for more than 800 years (987–1848, with some interruptions).\n\n\nOver the succeeding centuries, Capetians spread throughout Europe, ruling every form of provincial unit from kingdoms to manors.\n\nSalic law, reestablished during the Hundred Years' War from an ancient Frankish tradition, caused the French monarchy to permit only male (agnatic) descendants of Hugh to succeed to the throne of France.\n\nWithout Salic law, upon the death of John I, the crown would have passed to his half-sister, Joan (later Joan II of Navarre). However, Joan's paternity was suspect due to her mother's adultery in the Tour de Nesle Affair; the French magnates adopted Salic law to avoid the succession of a possible bastard.\n\nIn 1328, King Charles IV of France died without male heirs, as his brothers did before him. Philip of Valois, the late king's first cousin acted as regent, pending the birth of the king's posthumous child, which proved to be a girl. Isabella of France, sister of Charles IV, claimed the throne for her son, Edward III of England. The English king did not find support among the French lords, who made Philip of Valois their king. From then on the French succession not only excluded females, but also rejected claims based on the female line of descent.\n\nThus the French crown passed from the House of Capet after the death of Charles IV to Philip VI of France of the House of Valois, a cadet branch of the Capetian dynasty,\n\nThis did not affect monarchies not under that law such as Portugal, Spain, Navarre, and various smaller duchies and counties. Therefore, many royal families appear and disappear in the French succession or become cadet branches upon marriage. A complete list of the senior-most line of Capetians is available below.\n\nThe Capetian Dynasty has been broken many times into (sometimes rival) cadet branches. A cadet branch is a line of descent from another line than the senior-most. This list of cadet branches shows most of the Capetian cadet lines and designating their royal French progenitor, although some sub-branches are not shown.\n\n\n\n\n\n\n\n\nThroughout most of history, the Senior Capet and the King of France were synonymous terms. Only in the time before Hugh Capet took the crown for himself and after the reign of Charles X is the term necessary to identify which. However, since primogeniture and the Salic law provided for the succession of the French throne for most of French history, here is a list of all the predecessors of the French monarchy, all the French kings from Hugh until Charles, and all the Legitimist pretenders thereafter. All dates are for seniority, not reign. It is important to note that historians class the predecessors of Hugh Capet as \"Robertians\", not \"Capetians\".\n\nNoblemen in Neustria and their descendants (dates uncertain):\n\nCount in the Upper Rhine Valley and Wormgau:\n\nKing of France:\n\nCount of Paris:\n\nKing of France:\n\nDuke of Angoulême:\n\nCount of Chambord:\n\nCount of Montizón:\nDuke of Madrid:\nDuke of Anjou and Madrid:\nDuke of San Jaime:\nKing of Spain:\nDuke of Anjou and Segovia:\nDuke of Anjou and Cádiz:\nDuke of Anjou:\n\nMany years have passed since the Capetian monarchs ruled a large part of Europe; however, they still remain as kings, as well as other titles. Currently two Capetian monarchs still rule in Spain and Luxembourg. In addition, seven pretenders represent exiled dynastic monarchies in Brazil, France, Spain, Portugal, Parma and Two Sicilies. The current legitimate, senior family member is Louis-Alphonse de Bourbon, known by his supporters as Duke of Anjou, who also holds the Legitimist (\"Blancs d'Espagne\") claim to the French throne. Overall, dozens of branches of the Capetian dynasty still exist throughout Europe.\n\nExcept for the House of Braganza (founded by an illegitimate son of King John I of Portugal, who was himself illegitimate), all current major Capetian branches are of the Bourbon cadet branch. Within the House of Bourbon, many of these lines are themselves well-defined cadet lines of the House.\n\n\n\nIt is estimated that the agnatic descendants of the Capetian dynasty consists of 6,500 people (dead and alive).\n\nThe small number of agnatic descendants of the kings of France, compared with a theoretical number, is explained by the frequent marriages between Capetian cousins between the 12th and 20th centuries. Some examples of considerable inbreeding among descendants of the kings of France are:\n\n\n\n", "id": "6279", "title": "Capetian dynasty"}
{"url": "https://en.wikipedia.org/wiki?curid=6280", "text": "Cuboctahedron\n\nIn geometry, a cuboctahedron is a polyhedron with 8 triangular faces and 6 square faces. A cuboctahedron has 12 identical vertices, with 2 triangles and 2 squares meeting at each, and 24 identical edges, each separating a triangle from a square. As such, it is a quasiregular polyhedron, i.e. an Archimedean solid that is not only vertex-transitive but also edge-transitive.\n\nIts dual polyhedron is the rhombic dodecahedron.\n\nThe cuboctahedron was probably known to Plato: Heron's \"Definitiones\" quotes Archimedes as saying that Plato knew of a solid made of 8 triangles and 6 squares.\n\n\nThe area \"A\" and the volume \"V\" of the cuboctahedron of edge length \"a\" are:\n\nThe \"cuboctahedron\" has four special orthogonal projections, centered on a vertex, an edge, and the two types of faces, triangular and square. The last two correspond to the B and A Coxeter planes. The skew projections show a square and hexagon passing through the center of the cuboctahedron.\nThe cuboctahedron can also be represented as a spherical tiling, and projected onto the plane via a stereographic projection. This projection is conformal, preserving angles but not areas or lengths. Straight lines on the sphere are projected as circular arcs on the plane.\nThe Cartesian coordinates for the vertices of a cuboctahedron (of edge length ) centered at the origin are:\n\nAn alternate set of coordinates can be made in 4-space, as 12 permutations of:\n\nThis construction exists as one of 16 orthant facets of the cantellated 16-cell.\n\nThe cuboctahedron's 12 vertices can represent the root vectors of the simple Lie group A. With the addition of 6 vertices of the octahedron, these vertices represent the 18 root vectors of the simple Lie group B.\n\nThe \"cuboctahedron\" can be dissected into two triangular cupolas by a common hexagon passing through the center of the cuboctahedron. If these two triangular cupolas are twisted so triangles and squares line up, Johnson solid J, the triangular orthobicupola, is created.\n\nThe cuboctahedron can also be dissected into 6 square pyramids and 8 tetrahedra meeting at a central point. This dissection is expressed in the alternated cubic honeycomb where pairs of square pyramids are combined into octahedra.\n\nA cuboctahedron can be obtained by taking an appropriate cross section of a four-dimensional 16-cell.\n\nA cuboctahedron has octahedral symmetry. Its first stellation is the compound of a cube and its dual octahedron, with the vertices of the cuboctahedron located at the midpoints of the edges of either.\n\nThe cuboctahedron is a rectified cube and also a rectified octahedron.\n\nIt is also a cantellated tetrahedron. With this construction it is given the Wythoff symbol: . \n\nA skew cantellation of the tetrahedron produces a solid with faces parallel to those of the cuboctahedron, namely eight triangles of two sizes, and six rectangles. While its edges are unequal, this solid remains \"vertex-uniform\": the solid has the full tetrahedral symmetry group and its vertices are equivalent under that group.\n\nThe edges of a cuboctahedron form four regular hexagons. If the cuboctahedron is cut in the plane of one of these hexagons, each half is a triangular cupola, one of the Johnson solids; the cuboctahedron itself thus can also be called a triangular gyrobicupola, the simplest of a series (other than the gyrobifastigium or \"digonal gyrobicupola\"). If the halves are put back together with a twist, so that triangles meet triangles and squares meet squares, the result is another Johnson solid, the triangular orthobicupola, also called an anticuboctahedron.\n\nBoth triangular bicupolae are important in sphere packing. The distance from the solid's center to its vertices is equal to its edge length. Each central sphere can have up to twelve neighbors, and in a face-centered cubic lattice these take the positions of a cuboctahedron's vertices. In a hexagonal close-packed lattice they correspond to the corners of the triangular orthobicupola. In both cases the central sphere takes the position of the solid's center.\n\nCuboctahedra appear as cells in three of the convex uniform honeycombs and in nine of the convex uniform 4-polytopes.\n\nThe volume of the cuboctahedron is of that of the enclosing cube and of that of the enclosing octahedron.\n\nThe cuboctahedron shares its edges and vertex arrangement with two nonconvex uniform polyhedra: the cubohemioctahedron (having the square faces in common) and the octahemioctahedron (having the triangular faces in common). It also serves as a cantellated tetrahedron, as being a rectified tetratetrahedron.\n\nThe cuboctahedron 2-covers the tetrahemihexahedron, which accordingly has the same abstract vertex figure (two triangles and two squares: 3.4.3.4) and half the vertices, edges, and faces. (The actual vertex figure of the tetrahemihexahedron is 3.4..4, with the factor due to the cross.)\nThe cuboctahedron is one of a family of uniform polyhedra related to the cube and regular octahedron.\nThe cuboctahedron also has tetrahedral symmetry with two colors of triangles.\nThe cuboctahedron exists in a sequence of symmetries of quasiregular polyhedra and tilings with vertex configurations (3.\"n\"), progressing from tilings of the sphere to the Euclidean plane and into the hyperbolic plane. With orbifold notation symmetry of *\"n\"32 all of these tilings are wythoff construction within a fundamental domain of symmetry, with generator points at the right angle corner of the domain.\n\nThis polyhedron is topologically related as a part of sequence of cantellated polyhedra with vertex figure (3.4.\"n\".4), and continues as tilings of the hyperbolic plane. These vertex-transitive figures have (*\"n\"32) reflectional symmetry.\n\nThe cuboctahedron can be decomposed into a regular octahedron and eight irregular but equal octahedra in the shape of the convex hull of a cube with two opposite vertices removed. This decomposition of the cuboctahedron corresponds with the cell-first parallel projection of the 24-cell into three dimensions. Under this projection, the cuboctahedron forms the projection envelope, which can be decomposed into six square faces, a regular octahedron, and eight irregular octahedra. These elements correspond with the images of six of the octahedral cells in the 24-cell, the nearest and farthest cells from the 4D viewpoint, and the remaining eight pairs of cells, respectively.\n\nIn the mathematical field of graph theory, a cuboctahedral graph is the graph of vertices and edges of the cuboctahedron, one of the Archimedean solids. It has 12 vertices and 24 edges, and is a quartic Archimedean graph.\n\n\n", "id": "6280", "title": "Cuboctahedron"}
{"url": "https://en.wikipedia.org/wiki?curid=6281", "text": "Canton\n\nCanton may refer to:\n\n\n\n\n\n\n\n\n\n\n\n", "id": "6281", "title": "Canton"}
{"url": "https://en.wikipedia.org/wiki?curid=6282", "text": "Class\n\nClass may refer to:\n\n\n\n\n\n\n\n\n", "id": "6282", "title": "Class"}
{"url": "https://en.wikipedia.org/wiki?curid=6283", "text": "Critical point\n\nCritical point may refer to:\n\n", "id": "6283", "title": "Critical point"}
{"url": "https://en.wikipedia.org/wiki?curid=6285", "text": "Cube\n\nIn geometry, a cube is a three-dimensional solid object bounded by six square faces, facets or sides, with three meeting at each vertex.\n\nThe cube is the only regular hexahedron and is one of the five Platonic solids. It has 6 faces, 12 edges, and 8 vertices.\n\nThe cube is also a square parallelepiped, an equilateral cuboid and a right rhombohedron. It is a regular square prism in three orientations, and a trigonal trapezohedron in four orientations.\n\nThe cube is dual to the octahedron. It has cubical or octahedral symmetry.\n\nThe \"cube\" has four special orthogonal projections, centered, on a vertex, edges, face and normal to its vertex figure. The first and third correspond to the A and B Coxeter planes.\nThe cube can also be represented as a spherical tiling, and projected onto the plane via a stereographic projection. This projection is conformal, preserving angles but not areas or lengths. Straight lines on the sphere are projected as circular arcs on the plane.\n\nFor a cube centered at the origin, with edges parallel to the axes and with an edge length of 2, the Cartesian coordinates of the vertices are\n\nwhile the interior consists of all points (\"x\", \"x\", \"x\") with −1 < \"x\" < 1.\n\nIn analytic geometry, a cube's surface with center (\"x\", \"y\", \"z\") and edge length of \"2a\" is the locus of all points (\"x\", \"y\", \"z\") such that\n\nFor a cube of edge length formula_2:\nAs the volume of a cube is the third power of its sides formula_3, third powers are called \"cubes\", by analogy with squares and second powers.\n\nA cube has the largest volume among cuboids (rectangular boxes) with a given surface area. Also, a cube has the largest volume among cuboids with the same total linear size (length+width+height).\n\nFor a cube whose circumscribing sphere has radius \"R\", and for a given point in its 3-dimensional space with distances \"d\" from the cube's eight vertices, we have:\n\nDoubling the cube, or the \"Delian problem\", was the problem posed by ancient Greek mathematicians of using only a compass and straightedge to start with the length of the edge of a given cube and to construct the length of the edge of a cube with twice the volume of the original cube. They were unable to solve this problem, and in 1837 Pierre Wantzel proved it to be impossible because the cube root of 2 is not a constructible number.\n\nThe cube has three uniform colorings, named by the colors of the square faces around each vertex: 111, 112, 123.\n\nThe cube has three classes of symmetry, which can be represented by vertex-transitive coloring the faces. The highest octahedral symmetry O has all the faces the same color. The dihedral symmetry D comes from the cube being a prism, with all four sides being the same color. The lowest symmetry D is also a prismatic symmetry, with sides alternating colors, so there are three colors, paired by opposite sides. Each symmetry form has a different Wythoff symbol.\nA cube has eleven nets (one shown above): that is, there are eleven ways to flatten a hollow cube by cutting seven edges. To color the cube so that no two adjacent faces have the same color, one would need at least three colors.\n\nThe cube is the cell of the only regular tiling of three-dimensional Euclidean space. It is also unique among the Platonic solids in having faces with an even number of sides and, consequently, it is the only member of that group that is a zonohedron (every face has point symmetry).\n\nThe cube can be cut into six identical square pyramids. If these square pyramids are then attached to the faces of a second cube, a rhombic dodecahedron is obtained (with pairs of coplanar triangles combined into rhombic faces).\n\nThe analogue of a cube in four-dimensional Euclidean space has a special name—a tesseract or hypercube. More properly, a hypercube (or \"n\"-dimensional cube or simply \"n\"-cube) is the analogue of the cube in \"n\"-dimensional Euclidean space and a tesseract is the order-4 hypercube. A hypercube is also called a \"measure polytope\".\n\nThere are analogues of the cube in lower dimensions too: a point in dimension 0, a segment in one dimension and a square in two dimensions.\n\nThe quotient of the cube by the antipodal map yields a projective polyhedron, the hemicube.\n\nIf the original cube has edge length 1, its dual polyhedron (an octahedron) has edge length formula_5.\n\nThe cube is a special case in various classes of general polyhedra:\nThe vertices of a cube can be grouped into two groups of four, each forming a regular tetrahedron; more generally this is referred to as a demicube. These two together form a regular compound, the stella octangula. The intersection of the two forms a regular octahedron. The symmetries of a regular tetrahedron correspond to those of a cube which map each tetrahedron to itself; the other symmetries of the cube map the two to each other.\n\nOne such regular tetrahedron has a volume of of that of the cube. The remaining space consists of four equal irregular tetrahedra with a volume of of that of the cube, each.\n\nThe rectified cube is the cuboctahedron. If smaller corners are cut off we get a polyhedron with six octagonal faces and eight triangular ones. In particular we can get regular octagons (truncated cube). The rhombicuboctahedron is obtained by cutting off both corners and edges to the correct amount.\n\nA cube can be inscribed in a dodecahedron so that each vertex of the cube is a vertex of the dodecahedron and each edge is a diagonal of one of the dodecahedron's faces; taking all such cubes gives rise to the regular compound of five cubes.\n\nIf two opposite corners of a cube are truncated at the depth of the three vertices directly connected to them, an irregular octahedron is obtained. Eight of these irregular octahedra can be attached to the triangular faces of a regular octahedron to obtain the cuboctahedron.\n\nThe cube is topologically related to a series of spherical polyhedra and tilings with order-3 vertex figures.\nThe cuboctahedron is one of a family of uniform polyhedra related to the cube and regular octahedron.\nThe cube is topologically related as a part of sequence of regular tilings, extending into the hyperbolic plane: {4,p}, p=3,4,5...\nWith dihedral symmetry, Dih, the cube is topologically related in a series of uniform polyhedra and tilings 4.2n.2n, extending into the hyperbolic plane:\nAll these figures have octahedral symmetry.\n\nThe cube is a part of a sequence of rhombic polyhedra and tilings with [\"n\",3] Coxeter group symmetry. The cube can be seen as a rhombic hexahedron where the rhombi are squares.\nThe cube is a square prism:\nAs a trigonal trapezohedron, the cube is related to the hexagonal dihedral symmetry family.\n\nIt is an element of 9 of 28 convex uniform honeycombs: \nIt is also an element of five four-dimensional uniform polychora: \n\nThe skeleton of the cube (the vertices and edges) form a graph, with 8 vertices, and 12 edges. It is a special case of the hypercube graph. It is one of 5 Platonic graphs, each a skeleton of its Platonic solid.\n\nAn extension is the three dimensional \"k\"-ary Hamming graph, which for \"k\" = 2 is the cube graph. Graphs of this sort occur in the theory of parallel processing in computers.\n\n\nMiscellaneous cubes\n\n\n", "id": "6285", "title": "Cube"}
{"url": "https://en.wikipedia.org/wiki?curid=6286", "text": "Commuter rail\n\nCommuter rail, also called suburban rail, is a passenger rail transport service that primarily operates between a city centre, and the middle to outer suburbs beyond 15 km (10 miles) and commuter towns or other locations that draw large numbers of commuters—people who travel on a daily basis. Trains operate following a schedule, at speeds varying from 50 to 200 km/h (30 to 125 mph). Distance charges or zone pricing may be used.\n\nNon-English names include \"Treno suburbano\" in Italian, \"Cercanías\" in Spanish, \"Rodalies\" in Catalan, \"Proastiakos\" in Greek, \"S-Bahn\" in German (although \"Regionalbahn\" or stopping services occasionally also operate as commuter trains), \"Train de banlieue\" in French, \"Příměstský vlak\" or \"Esko\" in Czech, \"Elektrichka\" in Russian, \"Pociąg podmiejski \" in Polish and \"Pendeltåg\" in Swedish. The development of commuter rail services has become popular today, with the increased public awareness of congestion, dependence on fossil fuels, and other environmental issues, as well as the rising costs of owning, operating and parking automobiles.\n\nMost commuter (or suburban) trains are built to main line rail standards, differing from light rail or rapid transit (metro rail) systems by:\n\nCompared to rapid transit (or metro rail), commuter/suburban rail has lower frequency, following a schedule rather than fixed intervals, and fewer stations spaced further apart. They primarily serve lower density suburban areas (non inner-city), and often share right-of-way with intercity or freight trains. Some services operate only during peak hours and others uses fewer departures during off peak hours and weekends. Average speeds are high, often 50 km/h (30 mph) or higher. These higher speeds better serve the longer distances involved. Some services include express services which skip some stations in order to run faster and separate longer distance riders from short-distance ones.\n\nThe general range of commuter trains' distance varies between 15 and 200 km (10 and 125 miles). Sometimes long distances can be explained by that the train runs between two or several cities (e.g. S-Bahn in the Ruhr area of Germany). Distances between stations may vary, but are usually much longer than those of urban rail systems. In city centers the train either has a terminal station or passes through the city centre with notably fewer station stops than those of urban rail systems. Toilets are often available on board trains and in stations.\n\nTheir ability to coexist with freight or intercity services in the same right-of-way can drastically reduce system construction costs. However, frequently they are built with dedicated tracks within that right-of-way to prevent delays, especially where service densities have converged in the inner parts of the network.\n\nMost such trains run on the local standard gauge track. Some light rail systems may run on a narrower gauge. Examples of narrow gauge systems are found in Japan, Indonesia, Switzerland, in the Brisbane (Queensland Rail's City network) and Perth (Transperth) systems in Australia, in some commuter rail systems in Sweden, and on the in Italy. Some countries, including Finland, India, Pakistan, Russia, Brazil and Sri Lanka, as well as San Francisco (BART) in the USA and Melbourne and Adelaide in Australia, use broad gauge track.\n\nMetro rail or rapid transit usually covers a smaller inner-urban area ranging outwards to between 12 km to 20 km (or 8 to 14 miles), has a higher train frequency and runs on separate tracks (underground or elevated), whereas commuter rail often shares tracks, technology and the legal framework within mainline railway systems.\n\nHowever, the classification as a metro or rapid rail can be difficult as both may typically cover a metropolitan area exclusively, run on separate tracks in the centre, and often feature purpose-built rolling stock. The fact that the terminology is not standardised across countries (even across English-speaking countries) further complicates matters. This distinction is most easily made when there are two (or more) systems such as New York's subway and the LIRR, Metro-North along with PATH, Paris' Métro and RER along with Transilien, London's tube lines of the Underground and the Overground, (future) Crossrail, Thameslink along with other commuter rail operators, Madrid's Metro and Cercanías, Barcelona's Metro and Rodalies, and Tokyo's subway and the JR lines along with various privately owned and operated commuter rail systems.\n\nIn Germany the S-Bahn is considered as a train category of its own, and exists in many of the large cities and in some other areas but do have differing service and technical standards from city to city. \nMost S-bahns typically behave like commuter rail with most trackage not separated from other trains, and long lines with trains running between cities and suburbs rather than within a city. The distances between stations however, are usually short. In larger systems there is usually a high frequency metro-like central corridor in the city center where all the lines converge into. Typical examples of large city S-Bahns include Munich and Frankfurt. S-Bahns do also exist in some mid-size cities like Rostock and Magdeburg but behave more like typical commuter rail with lower frequencies and very little exclusive trackage. In Berlin, the S-Bahn systems arguably fulfill all considerations of a true metro system (despite the existence of U-Bahns as well) – the trains run on tracks that are entirely separated from other trains, short distances between stations, high frequency and uses tunnels but do run a bit further out from the city centre, compared with U-Bahn. A similar network exists in Copenhagen called the S-tog. (where a metro system also exists). In Hamburg and Copenhagen, other, diesel driven trains, do continue where the S-Bahn ends (\"A-Bahn\" in Hamburg area, and \"L-tog\" in Copenhagen).\n\nRegional rail usually provides rail services between towns and cities, rather than purely linking major population hubs in the way inter-city rail does. Regional rail operates outside major cities. Unlike Inter-city, it stops at most or all stations between cities. It provides a service between smaller communities along the line, and also connections with long-distance services at interchange stations located at junctions or at larger towns along the line. Alternative names are \"local train\" or \"stopping train\". Examples include the former BR's Regional Railways, France's TER (\"Transport express régional\"), Germany's DB Regio and South Korea's Tonggeun services.\n\nRegional rail does not exist in this sense in the United States, so the term \"regional rail\" has become synonymous with commuter rail there, although the two are more clearly defined in Europe.\n\nIn some European countries the distinction between commuter trains and long-distance/intercity trains is very hard to make, because of the relatively short distances involved. For example, so-called \"intercity\" trains in Belgium and the Netherlands carry many commuters and their equipment, range and speeds are similar to those of commuter trains in some larger countries. In the United Kingdom there is no real division of organisation and brand name between commuter, regional and inter-city trains, making it hard to categorize train connections.\n\nRussian commuter trains, on the other hand, frequently cover areas larger than Belgium itself, although these are still short distances by Russian standards. They have a different ticketing system from long-distance trains, and in major cities they often operate from a separate section of the train station.\n\nThe easiest way to identify these \"inter-city\" services is that they tend to operate as express services - only linking the main stations in the cities they link, not stopping at any other stations. However, this term is used in Australia (Sydney for example) to describe the regional trains operating beyond the boundaries of the suburban services, even though some of these \"inter-city\" services stop all stations similar to German regional services. In this regard, the German service delineations and corresponding naming conventions are clearer and better used for academic purposes.\n\nSometimes high-speed rail can serve daily use of commuters. The Japanese Shinkansen high speed rail system is heavily used by commuters in the Greater Tokyo Area. They commute between 100 and 200 km by Shinkansen. To meet the demand of commuters, JR sells commuter discount passes and operates 16-car bilevel E4 Series Shinkansen trains at rush hour, providing a capacity of 1,600 seats. Several lines in China such as the Beijing–Tianjin Intercity Railway, and the Shanghai–Nanjing High-Speed Railway, serve a similar role with many more under construction or planned.\n\nThe high-speed services linking Zürich, Bern and Basel in Switzerland () have brought the Central Business Districts (CBDs) of these three cities within 1 hour of each other. This has resulted in unexpectedly high demand for new commuter trips between the three cities and a corresponding increase in suburban rail passengers accessing the high-speed services at the main city-centre stations (or Hauptbahnhof). The Regional-Express commuter service between Munich and Nuremberg in Germany go in () along a 300 km/h high-speed line.\n\nThe regional trains Stockholm–Uppsala, Stockholm–Västerås, Stockholm–Eskilstuna and Gothenburg–Trollhättan in Sweden reach and have many daily commuters.\n\nCommuter/suburban trains are usually optimized for maximum passenger volume, in most cases without sacrificing too much comfort and luggage space, though they seldom have all the amenities of long-distance trains. Cars may be single- or double-level, and aim to provide seating for all. Compared to intercity trains, they have less space, fewer amenities and limited baggage areas.\n\nCommuter rail trains are usually composed of multiple units, which are self-propelled, bidirectional, articulated passenger rail cars with driving motors on each (or every other) bogie. Depending on local circumstances and tradition they may be powered either by diesel engines located below the passenger compartment (diesel multiple units) or by electricity picked up from third rails or overhead lines (electric multiple units). Multiple units are almost invariably equipped with control cabs at both ends, which is why such units are so frequently used to provide commuter services, due to the associated short turn-around time.\n\nLocomotive hauled services are used in some countries or locations. This is often a case of asset sweating, by using a single large combined fleet for intercity and regional services. Loco hauled services are usually run in push-pull formation, that is, the train can run with the locomotive at the \"front\" or \"rear\" of the train (pushing or pulling). Trains are often equipped with a control cab at the other end of the train from the locomotive, allowing the train operator to operate the train from either end. The motive power for locomotive-hauled commuter trains may be either electric or Diesel-electric, although some countries, such as Germany and some of the former Soviet-bloc countries, also use diesel-hydraulic locomotives.\n\nIn the USA and some other countries, a three-and-two seat plan is used. However, few people sit in the middle seat on these trains because they feel crowded and uncomfortable. It is said one industrial designer for one of New York City's commuter railroads, Metro-North, told people: \"I designed the aisle seat with a half-back and no upholstery, so it will be very uncomfortable to sit there. They'll move in and take the center seat!\" (This seating design can also be found on older NJ Transit and Long Island Rail Road rolling stock.)\n\nIn Japan, longitudinal (sideways window-lining) seating is widely used in many commuter rail trains to increase capacity in rush hours. Carriages are usually not organized to increase seating capacity (although in some trains at least one carriage would feature more doors to facilitate easier boarding and alighting and bench seats so that they can be folded up during rush hour to provide more standing room) even in the case of commuting longer than 50 km and commuters in the Greater Tokyo Area have to stand in the train for more than an hour.\n\nCurrently there are not many examples of commuter rail in Africa. Metrorail operates in the major cities of South Africa, and there are some commuter rail services in Algeria, Kenya, Morocco, Alexandria, Egypt and Tunisia.\nIn Algeria, SNTF operates commuter-rail lines between the capital Algiers and its southern and eastern suburbs. They also serve to connect Algiers' main universities to each other. The Dar es Salaam commuter rail offers intracity services in Dar es Salaam, Tanzania.\n\nIn Japan, commuter rail systems have extensive network and frequent service, and are heavily used. In many cases, Japanese commuter rail is operationally more like a typical metro system (with very high operating frequencies, an emphasis on standing passengers, short station spacing) than it is like commuter rail in other countries. Japanese commuter rail also tends to be heavily interlined with subway lines, with commuter rail trains continuing into the subway network, and then out onto different commuter rail systems on the other side of the city. Many Japanese commuter systems operate several levels of express trains to reduce the travel time to distant locations, often using station bypass tracks instead of dedicated express tracks. It is notable that the larger Japanese commuter rail systems are owned and operated by for-profit private railway companies, without public subsidy.\n\nCommuter rail systems have been inaugurated in several cities in China such as Beijing, Shanghai, Zhengzhou, Wuhan, Changsha and the Pearl River Delta. With plans for large systems in northeastern Zhejiang, Jingjinji, and Yangtze River Delta areas. The level of service varies considerably from line to line ranging high to near high speeds. More developed and established lines such as the Guangshen Railway have more frequent metro like service. Hong Kong MTR's East Rail Line and West Rail Line were built to commuter rail standards but are operated as a metro system. \n\nIn Taiwan, Western Line in Taipei-Taoyuan Metropolitan Area, Taichung Metropolitan Area, Tainan-Kaohsiung Metropolitan Area as well as Neiwan-Liujia Line in Hsinchu Area is considered commuter rail.\n\nOther examples in Asia include Seoul Metropolitan Subway of which some lines are suburban lines operated by Korail in South Korea.\n\nIn Indonesia, the KA Commuter Jabodetabek is the largest commuter rail system in the country, serving Jakarta metropolitan area. It connects Jakarta city center with surrounding cities and sub-urbans in Banten and West Java provinces, including Depok, Bogor, Tangerang, Bekasi, Serpong and Maja. In July 2015, KA Commuter Jabodetabek served more than 850,000 passengers per day, which is almost triple of the 2011 figures, but still less than 3.5% of all Jabodetabek commutes.\n\nOther examples include KTM Komuter in Malaysia, and the Philippine National Railways orange line in Metro Manila, Philippines.\n\nIn India, commuter rail systems are present in major cities. Mumbai Suburban Railway, the oldest suburban rail system in Asia, carries more than 7.24 million commuters on a daily basis which constitutes more than half of the total daily passenger capacity of the Indian Railways itself. The Chennai Suburban Railway along with MRTS is another railway of comparison where more than 1 million people travel daily to different areas in Chennai. In Hyderabad, the MMTS mainly transports people from the city centre to HI-TEC city, the city's Information Technology hub. Other commuter railways in India include Kolkata Suburban Railway which is the biggest Suburban Railway network in India covering 348 stations, Delhi Suburban Railway, Pune Suburban Railway and Lucknow-Kanpur Suburban Railway.\n\nIn Iran, SYSTRA has done a \"Tehran long term urban rail study\". SYSTRA proposed 4 express lines which are similar to RER suburban lines in Paris.\nTehran Metro is going to construct express lines. For instance, the Rahyab Behineh, a consultant for Tehran Metro, is studying Tehran Express Line 2. Tehran Metro currently has a commuter line between Tehran and Karaj. Esfahan has two lines to its suburbs Baharestan and Fuladshahr under construction, and a third line to Shahinshahr is planned.\n\nMajor metropolitan areas in most European countries are usually served by extensive commuter/suburban rail systems. Well-known examples include Beovoz in Belgrade (Serbia), S-Bahn in Germany and German-speaking areas of Switzerland and Austria, Proastiakos in Greece, RER in France and Belgium, suburban lines in Milan (Italy), Cercanías in Spain, CP Urban Services in Portugal, Esko in Prague and Ostrava (Czech Republic), HÉV in Budapest (Hungary) and DART in Dublin (Ireland).\n\nIn Russia, Ukraine and some other countries of the former Soviet Union, electrical multiple unit passenger suburban trains called Elektrichka are widespread.\n\nIn \"Sweden\", electrified commuter rail systems known as \"Pendeltåg\" are present in the cities of Stockholm and Gothenburg. The Stockholm commuter rail system, which began in 1968, is similar to the S-Bahn train systems of Munich and Frankfurt such that it may share railway tracks with inter-city trains and freight trains, but for the most part run on its own dedicated tracks, and that it is mainly used to transport passengers from nearby towns and other suburban areas into the city centre, not for transportation inside the city centre. The Gothenburg commuter rail system, which began in 1960, is similar to the Stockholm system, but does fully share tracks with long-distance trains. Other train systems that are also considered as commuter rail but not counted as \"pendeltåg\" include Roslagsbanan and Saltsjöbanan in Stockholm, Östgötapendeln in Östergötland County, Upptåget in Uppsala County and Skåne Commuter Rail. Skåne Commuter Rail (\"Pågatågen\") in Skåne County acts also as a regional rail system, as it serves cities over 100 km (62 miles) and over one hour from the principal city of Malmö.\n\nIn \"Norway\", the Oslo commuter rail system is the largest, which mostly shares tracks with more long-distance trains, but also runs on some local railways without other traffic. Oslo has the largest commuter rail system in Scandinavia measured as line lengths or number of stations. But some lines have travel times (over an hour from Oslo) and frequencies (once per hour) which are more like regional trains. Also Bergen, Stavanger and Trondheim have commuter rail systems. These have only one or two lines each and they share tracks with other trains.\n\nIn \"Poland\", commuter rail systems exist in Tricity, Warsaw, Cracow and Katowice urban area. There is also a similar system planned in Wrocław.\n\nIn the United States, Canada, Costa Rica, El Salvador and Mexico regional passenger rail services are provided by governmental or quasi-governmental agencies, with a limited number of metropolitan areas served.\n\nExamples include an commuter system in the Buenos Aires metropolitan area, the long Supervia in Rio de Janeiro, and the Metrotrén in Santiago, Chile. Another example is Companhia Paulista de Trens Metropolitanos (CPTM) in Greater São Paulo, Brazil. CPTM has 93 stations with six lines, numbered starting on 7 (the lines 1 to 6 belong to the São Paulo Metro), with a total length of .\n\nThe five major cities in Australia have suburban railway systems in their metropolitan areas. These networks have frequent services, with frequencies varying from every 10 to every 30 minutes on most suburban lines, and up to 3–5 minutes in peak on bundled underground lines in the city centres of Sydney and Melbourne. The networks in each state developed from mainline railways and have never been completely operationally separate from long distance and freight traffic, unlike metro systems in some comparable countries, but nevertheless have cohesive identities and are the backbones of their respective cities' public transport system. The suburban networks are all completely electrified, apart from Adelaide's, which still operates diesel services on some of its lines.\n\nThe main operators of suburban rail in Australia are:\n\nNew Zealand, has two frequent suburban rail services comparable to Australia's, one using 25,000 V AC in Auckland and the other one using 1,500 V DC in Wellington (formerly operaterd by Tranz Metro).\n\n\n", "id": "6286", "title": "Commuter rail"}
{"url": "https://en.wikipedia.org/wiki?curid=6288", "text": "Cambridgeshire\n\nCambridgeshire ( or ; abbreviated Cambs.), is an East Anglian county in England, bordering Lincolnshire to the north, Norfolk to the north-east, Suffolk to the east, Essex and Hertfordshire to the south, and Bedfordshire and Northamptonshire to the west. The city of Cambridge is the county town. Modern Cambridgeshire was formed in 1974 as an amalgamation of the counties of Cambridgeshire and Isle of Ely and Huntingdon and Peterborough, which had been created in 1965 from the historic counties of Cambridgeshire, Huntingdonshire, the Isle of Ely and the Soke of Peterborough. It contains most of the region known as Silicon Fen.\n\nLocal government is divided between Cambridgeshire County Council and Peterborough City Council, which is a separate unitary authority. Under the county council, there are five district councils, Cambridge City Council, South Cambridgeshire District Council, East Cambridgeshire District Council, Huntingdonshire District Council and Fenland District Council.\n\nCambridgeshire is noted as the site of Flag Fen in Fengate, one of the earliest-known Neolithic permanent settlements in the United Kingdom, compared in importance to Balbridie in Aberdeen, Scotland. A great quantity of archaeological finds from the Stone Age, the Bronze Age and the Iron Age were made in East Cambridgeshire. Most items were found in Isleham.\n\nCambridgeshire was recorded in the Domesday Book as \"Grantbridgeshire\" (or rather \"Grentebrigescire\") (related to the river Granta).\n\nCovering a large part of East Anglia, Cambridgeshire today is the result of several local government unifications. In 1888 when county councils were introduced, separate councils were set up, following the traditional division of Cambridgeshire, for\nIn 1965, these two administrative counties were merged to form Cambridgeshire and the Isle of Ely.\nUnder the Local Government Act 1972 this merged with the county to the west, Huntingdon and Peterborough. (The latter had been organised in 1965 by the merger of Huntingdonshire with the Soke of Peterborough – previously a part of Northamptonshire which had its own county council). The resulting county was called simply Cambridgeshire.\n\nSince 1998, the City of Peterborough has been a separately administered area, as a unitary authority. It is associated with Cambridgeshire for ceremonial purposes such as Lieutenancy, and joint functions such as policing and the fire service.\n\nIn 2002, the conservation charity Plantlife unofficially designated Cambridgeshire's county flower as the Pasqueflower.\n\nThe Cambridgeshire Regiment (or Fen Tigers), the county-based army unit, fought in the Boer War of South Africa, the First World War and Second World War.\n\nDue to the county's flat terrain and proximity to the continent, during the Second World War the military built many airfields here for RAF Bomber Command, RAF Fighter Command, and the allied USAAF. In recognition of this collaboration, the Cambridge American Cemetery and Memorial is located in Madingley. It is the only WWII burial ground in England for American servicemen who died during that event.\n\nMost English counties have nicknames for their people, such as a \"Tyke\" from Yorkshire and a \"Yellowbelly\" from Lincolnshire. The traditional nicknames for people from Cambridgeshire are \"Cambridgeshire Camel\" or \"Cambridgeshire Crane\", referring to the wildfowl that were once abundant in the fens. The term \"Fenners\" was often applied to those who come from the flat country to the north of Cambridge. Since the late 20th century, this term is considered to be derogatory and has been discouraged in use.\n\nOriginal historical documents relating to Cambridgeshire are held by Cambridgeshire Archives and Local Studies.\n\nLarge areas of the county are extremely low-lying and Holme Fen is notable for being the UK's lowest physical point at 2.75 m (9 ft) below sea level. The highest point is in the village of Great Chishill at 146 m (480 ft) above sea level. Other prominent hills are Little Trees Hill and Wandlebury Hill in the Gog Magog Downs, Rivey Hill above Linton, Rowley's Hill and the Madingley Hills.\n\nCambridgeshire contains seven Parliamentary constituencies:\n\nThis is a chart of trend of regional gross value added of Cambridgeshire at current basic prices published (pp. 240–253) by \"Office for National Statistics\" with figures in millions of English Pounds Sterling.\nAWG plc is based in Huntingdon. The RAF has several stations in the Huntingdon and St Ives area. RAF Waterbeach, 6 miles north of Cambridge, is a former RAF airfield, now used as an army barracks. RAF Alconbury, 3 miles north of Huntingdon, is being reorganised after a period of obsolescence following the departure of the USAF, to be the focus of RAF/USAFE intelligence operations, with activities at Upwood and Molesworth being transferred there. Most of Cambridgeshire is agricultural. Close to Cambridge is the so-called Silicon Fen area of high-technology (electronics, computing and biotechnology) companies. ARM Limited is based in Cherry Hinton.\n\nCambridgeshire has a completely comprehensive education system with 12 independent schools and over 240 state schools, not including sixth form colleges.\n\nSome of the secondary schools act as Village Colleges, institutions unique to Cambridgeshire. For example, Bottisham Village College.\n\nCambridgeshire is home to a number of institutes of higher education:\n\n\nIn addition, Cambridge Regional College and Huntingdonshire Regional College both offer a limited range of higher education courses in conjunction with partner universities.\n\nThese are the settlements in Cambridgeshire with a town charter, city status or a population over 5,000; for a complete list of settlements see list of places in Cambridgeshire.\n\nSee the List of Cambridgeshire settlements by population page for more detail.\n\nThe town of Newmarket is surrounded on three sides by Cambridgeshire, being connected by a narrow strip of land to the rest of Suffolk.\n\nCambridgeshire has seen 32,869 dwellings created from 2002–2013 and there are a further 35,360 planned new dwellings between now and 2023.\n\nCambridgeshire has a maritime temperate climate which is broadly similar to the rest of the United Kingdom, though it is drier than the UK average due to its low altitude and easterly location, the prevailing southwesterly winds having already deposited moisture on higher ground further west. Average winter temperatures are cooler than the English average, due to Cambridgeshire's inland location and relative nearness to continental Europe, which results in the moderating maritime influence being less strong. Snowfall is slightly more common than in western areas, due to the relative winter coolness and easterly winds bringing occasional snow from the North Sea. In summer temperatures are average or slightly above, due to less cloud cover. It reaches on around 10 days each year, and is comparable to parts of Kent and East Anglia.\n\nVarious forms of football have been popular in Cambridgeshire since medieval times at least. In 1579 one match played at Chesterton between townspeople and Cambridge University students ended in a violent brawl that led the Vice-Chancellor to issue a decree forbidding them to play \"footeball” outside of college grounds. Despite this and other decrees, football continued to be popular. George Elwes Corrie, Master of Jesus College, observed in 1838, that while walking past a park named Parker's Piece he \"saw some forty Gownsmen playing at football. The novelty and liveliness of the scene were amusing!\" By 1839, Albert Pell was organising football matches at the university; because each town or school had different rules, students had to devise a compromise set of rules.\n\nAt Cambridge University in 1846, H. de Winton and J. C. Thring formed a pioneering football club. Only a few matches were played, but in 1848 interest in football increased and that year the Cambridge rules, the first attempt to codify a form of football were drawn up in Cambridge. The Cambridge rules are generally regarded as the main precursor of Association football.\n\nAs a result of its role in the formation of the first football rules, Parker's Piece remains hallowed turf for football fans and historians.\nAccording to folklore, there are 11 players on each team because, when the game was invented, there were 11 trees on either side of Parker's Piece. In commemoration of the creation of Football; a statue is to be raised in the middle of the park where the game was invented.\n\nCambridgeshire is also the birthplace of bandy, now an IOC accepted sport. According to documents from 1813, Bury Fen Bandy Club was undefeated for 100 years. A member of the club, Charles Goodman Tebbutt, wrote down the first official rules in 1882. Tebbutt was instrumental in spreading the sport to many countries. England Bandy Federation is based in Cambridgeshire.\n\nOn 6–7 June 2015, the inaugural Tour of Cambridgeshire cycle race took place on closed roads across the county. The event was an official UCI qualification event, and consisted of a Time Trial on the 6th, and a Gran Fondo event on the 7th. The Gran Fondo event was open to the public, and over 6000 riders took part in the race.\n\nCambridge is home to the Kettle's Yard gallery and the artist run Aid and Abet project Space. Nine miles west of Cambridge next to the village of Bourn is Wysing Arts Centre.\n\n\"See \n\n\n", "id": "6288", "title": "Cambridgeshire"}
{"url": "https://en.wikipedia.org/wiki?curid=6290", "text": "Christian Goldbach\n\nChristian Goldbach (March 18, 1690 – November 20, 1764) was a German mathematician who also studied law. He is remembered today for Goldbach's conjecture. \n\nBorn in the Duchy of Prussia's capital Königsberg, part of Brandenburg-Prussia, Goldbach was the son of a pastor. He studied at the Royal Albertus University.\nAfter finishing his studies he went on long educational voyages from 1710 to 1724 through Europe, visiting other German states, England, Holland, Italy, and France, meeting with many famous mathematicians, such as Gottfried Leibniz, Leonhard Euler, and Nicholas I Bernoulli. Back in Königsberg he got acquainted with Georg Bernhard Bilfinger and Jakob Hermann.\n\nHe went on to work at the newly opened St Petersburg Academy of Sciences in 1725, as a professor of mathematics and historian of the academy. In 1728, when Peter II became Tsar of Russia, Goldbach became his tutor. In 1742 he entered the Russian Ministry of Foreign Affairs.\n\nChristian Goldbach was multilingual – he wrote a diary which was written in German and Latin, his letters were written in German, Latin, French, and Italian and for official documents he used Russian, German and Latin.\n\nHe died on November 20, 1764 at age of 74, in Moscow.\n\nGoldbach is most noted for his correspondence with Leibniz, Euler, and Bernoulli, especially in his 1742 letter to Euler stating his Goldbach's conjecture. He also studied and proved some theorems on perfect powers, such as the Goldbach–Euler theorem, and made several notable contributions to analysis. He also proved a result concerning Fermat numbers that is called Goldbach's theorem.\n\n\n", "id": "6290", "title": "Christian Goldbach"}
{"url": "https://en.wikipedia.org/wiki?curid=6291", "text": "Roman censor\n\nThe censor was an officer in ancient Rome who was responsible for maintaining the census, supervising public morality, and overseeing certain aspects of the government's finances.\n\nThe censors' regulation of public morality is the origin of the modern meaning of the words \"censor\" and \"censorship\".\n\nThe \"census\" was first instituted by Servius Tullius, sixth king of Rome. After the abolition of the monarchy and the founding of the Republic, the consuls had responsibility for the census until 443 BC. In 442 BC, no consuls were elected, but tribunes with consular power were appointed instead; this was a move by the plebeians to try to attain higher magistracies: only patricians could be elected consuls, while some military tribunes were plebeians. To avoid the possibility of plebeians obtaining control of the census, the patricians removed the right to take the census from the consuls and tribunes, and appointed for this duty two magistrates, called \"censores\" (censors), elected exclusively from the patricians in Rome. \n\nIt would not be uncommon for the patrician consulars of the early republic to intersperse public office with agricultural labour. In Cicero’s words: \"in agris erant tum senatores, id est senes\": ‘In those days senators—that is, seniors—would live on their farms’. This practice was obsolete by the 2nd century.\n\nThe magistracy continued to be controlled by patricians until 351 BC, when Gaius Marcius Rutilus was appointed the first plebeian censor. Twelve years later, in 339 BC, one of the Publilian laws required that one censor had to be a plebeian. Despite this, no plebeian censor performed the solemn purification of the people (the \"\"lustrum\"\"; \"Livy\" Periochae 13) until 280 BC. In 131 BC, for the first time, both censors were plebeians.\n\nThe reason for having two censors was that the two consuls had previously taken the census together. If one of the censors died during his term of office, another was chosen to replace him, just as with consuls. This happened only once, in 393 BC. However, the Gauls captured Rome in that \"lustrum\" (five-year period), and the Romans thereafter regarded such replacement as \"an offense against religion\". From then on, if one of the censors died, his colleague resigned, and two new censors were chosen to replace them.\n\nThe censors were elected in the Centuriate Assembly, which met under the presidency of a consul. Barthold Niebuhr suggests that the censors were at first elected by the Curiate Assembly, and that the Assembly's selections were confirmed by the Centuriate, but William Smith believes that \"there is no authority for this supposition, and the truth of it depends entirely upon the correctness of <nowiki>[Niebuhr's]</nowiki> views respecting the election of the consuls\". Both censors had to be elected on the same day, and accordingly if the voting for the second was not finished in the same day, the election of the first was invalidated, and a new assembly had to be held.\n\nThe assembly for the election of the censors was held under different auspices from those at the election of the consuls and praetors, so the censors were not regarded as their colleagues, although they likewise possessed the \"maxima auspicia\". The assembly was held by the new consuls shortly after they began their term of office; and the censors, as soon as they were elected and the censorial power had been granted to them by a decree of the Centuriate Assembly (\"lex centuriata\"), were fully installed in their office.\n\nAs a general principle, the only ones eligible for the office of censor were those who had previously been consuls, but there were a few exceptions. At first, there was no law to prevent a person being censor twice, but the only person who was elected to the office twice was Gaius Marcius Rutilus in 265 BC. In that year, he originated a law stating that no one could be elected censor twice. In consequence of this, he received the cognomen of \"Censorinus\".\n\nThe censorship differed from all other Roman magistracies in the length of office. The censors were originally chosen for a whole \"lustrum\" (the period of five years), but as early as ten years after its institution (433 BC) their office was limited to eighteen months by a law of the dictator Mamercus Aemilius Mamercinus. The censors were also unique with respect to rank and dignity. They had no \"imperium\", and accordingly no lictors. Their rank was granted to them by the Centuriate Assembly, and not by the \"curiae\", and in that respect they were inferior in power to the consuls and praetors.\n\nNotwithstanding this, the censorship was regarded as the highest dignity in the state, with the exception of the dictatorship; it was a \"sacred magistracy\" (\"sanctus magistratus\"), to which the deepest reverence was due. The high rank and dignity which the censorship obtained was due to the various important duties gradually entrusted to it, and especially to its possessing the \"regimen morum\", or general control over the conduct and the morals of the citizens. In the exercise of this power, they were regulated solely by their own views of duty, and were not responsible to any other power in the state.\n\nThe censors possessed the official stool called a \"curule chair\" (\"sella curulis\"), but some doubt exists with respect to their official dress. A well-known passage of Polybius describes the use of the \"imagines\" at funerals; we may conclude that a consul or praetor wore the purple-bordered \"toga praetexta\", one who triumphed the embroidered \"toga picta\", and the censor a purple toga peculiar to him, but other writers speak of their official dress as being the same as that of the other higher magistrates. The funeral of a censor was always conducted with great pomp and splendour, and hence a \"censorial funeral\" (\"funus censorium\") was voted even to the emperors.\n\nThe censorship continued in existence for 421 years, from 443 BC to 22 BC, but during this period, many \"lustra\" passed by without any censor being chosen at all. According to one statement, the office was abolished by Lucius Cornelius Sulla. Although the authority on which this statement rests is not of much weight, the fact itself is probable, since there was no census during the two \"lustra\" which elapsed from Sulla's dictatorship to Gnaeus Pompeius Magnus (Pompey)'s first consulship (82–70 BC), and any strict \"imposition of morals\" would have been found inconvenient to the aristocracy that supported Sulla.\n\nIf the censorship had been done away with by Sulla, it was at any rate restored in the consulship of Pompey and Marcus Licinius Crassus. Its power was limited by one of the laws of the tribune Publius Clodius Pulcher (58 BC), which prescribed certain regular forms of proceeding before the censors in expelling a person from the Roman Senate, and required that the censors be in agreement to exact this punishment. This law, however, was repealed in the third consulship of Pompey in 52 BC, on the urging of his colleague Q. Caecilius Metellus Scipio, but the office of the censorship never recovered its former power and influence.\n\nDuring the civil wars which followed soon afterwards, no censors were elected; it was only after a long interval that they were again appointed, namely in 22 BC, when Augustus caused Lucius Munatius Plancus and Aemilius Lepidus Paullus to fill the office. This was the last time that such magistrates were appointed; the emperors in future discharged the duties of their office under the name of Praefectura Morum (\"prefect of the morals\").\n\nSome of the emperors sometimes took the name of censor when they held a census of the Roman people; this was the case with Claudius, who appointed the elder Vitellius as his colleague, and with Vespasian, who likewise had a colleague in his son Titus. Domitian assumed the title of \"perpetual censor\" (\"censor perpetuus\"), but this example was not imitated by succeeding emperors. In the reign of Decius, we find the elder Valerian nominated to the censorship, but Valerian was never actually elected censor.\n\nThe duties of the censors may be divided into three classes, all of which were closely connected with one another:\n\n\nThe original business of the censorship was at first of a much more limited kind, and was restricted almost entirely to taking the census, but the possession of this power gradually brought with it fresh power and new duties, as is shown below. A general view of these duties is briefly expressed in the following passage of Cicero: \"\"Censores populi aevitates, soboles, familias pecuniasque censento: urbis templa, vias, aquas, aerarium, vectigalia tuento: populique partes in tribus distribunto: exin pecunias, aevitates, ordines patiunto: equitum, peditumque prolem describunto: caelibes esse prohibento: mores populi regunto: probrum in senatu ne relinquunto.\"\" This can be translated as: \"The Censors are to determine the generations, origins, families, and properties of the people; they are to (watch over/protect) the city's temples, roads, waters, treasury, and taxes; they are to divide the people into three parts; next, they are to (allow/approve) the properties, generations, and ranks [of the people]; they are to describe the offspring of knights and footsoldiers; they are to forbid being unmarried; they are to guide the behavior of the people; they are not to overlook abuse in the Senate.\" \n\nThe Census, the first and principal duty of the censors, was always held in the Campus Martius, and from the year 435 BC onwards, in a special building called Villa Publica, which was erected for that purpose by the second pair of censors, Gaius Furius Pacilus Fusus and Marcus Geganius Macerinus.\n\nAn account of the formalities with which the census was opened is given in a fragment of the \"Tabulae Censoriae\", preserved by Varro. After the auspices had been taken, the citizens were summoned by a public crier to appear before the censors. Each tribe was called up separately, and the names in each tribe were probably taken according to the lists previously made out by the tribunes of the tribes. Every paterfamilias had to appear in person before the censors, who were seated in their curule chairs, and those names were taken first which were considered to be of good omen, such as Valerius, Salvius, Statorius, etc.\n\nThe census was conducted according to the judgment of the censor (\"ad arbitrium censoris\"), but the censors laid down certain rules, sometimes called \"leges censui censendo\", in which mention was made of the different kinds of property subject to the census, and in what way their value was to be estimated. According to these laws, each citizen had to give an account of himself, of his family, and of his property upon oath, \"declared from the heart\".\n\nFirst he had to give his full name (praenomen, nomen, and cognomen) and that of his father, or if he were a \"Libertus\" (\"freedman\") that of his patron, and he was likewise obliged to state his age. He was then asked, \"You, declaring from your heart, do you have a wife?\" and if married he had to give the name of his wife, and likewise the number, names, and ages of his children, if any. Single women and orphans were represented by their guardians; their names were entered in separate lists, and they were not included in the sum total of heads.\n\nAfter a citizen had stated his name, age, family, etc., he then had to give an account of all his property, so far as it was subject to the census. Only such things were liable to the census (\"censui censendo\") as were property according to the Quiritarian law. At first, each citizen appears to have merely given the value of his whole property in general without entering into details; but it soon became the practice to give a minute specification of each article, as well as the general value of the whole.\n\nLand formed the most important article of the census, but public land, the possession of which only belonged to a citizen, was excluded as not being Quiritarian property. If we may judge from the practice of the imperial period, it was the custom to give a most minute specification of all such land as a citizen held according to the Quiritarian law. He had to state the name and location of the land, and to specify what portion of it was arable, what meadow, what vineyard, and what olive-ground: and of the land thus described, he had to give his assessment of its value.\n\nSlaves and cattle formed the next most important item. The censors also possessed the right of calling for a return of such objects as had not usually been given in, such as clothing, jewels, and carriages. It has been doubted by some modern writers whether the censors possessed the power of setting a higher valuation on the property than the citizens themselves gave, but when we recollect the discretionary nature of the censors' powers, and the necessity almost that existed, in order to prevent fraud, that the right of making a surcharge should be vested in somebody's hands, we can hardly doubt that the censors had this power. It is moreover expressly stated that on one occasion they made an extravagant surcharge on articles of luxury; and even if they did not enter in their books the property of a person at a higher value than he returned it, they accomplished the same end by compelling him to pay a tax upon the property at a higher rate than others. The tax was usually one per thousand upon the property entered in the books of the censors, but on one occasion the censors compelled a person to pay eight per thousand as a punishment.\n\nA person who voluntarily absented himself from the census was considered \"incensus\" and subject to the severest punishment. Servius Tullius is said to have threatened such individuals with imprisonment and death, and in the Republican period he might be sold by the state as a slave In the later times of the republic, a person who was absent from the census might be represented by another, and be thus registered by the censors. Whether the soldiers who were absent on service had to appoint a representative is uncertain. In ancient times, the sudden outbreaks of war prevented the census from being taken, because a large number of the citizens would necessarily be absent. It is supposed from a passage in Livy that in later times the censors sent commissioners into the provinces with full powers to take the census of the Roman soldiers there, but this seems to have been a special case. It is, on the contrary, probable from the way in which Cicero pleads the absence of Archias from Rome with the army under Lucullus, as a sufficient reason for his not having been enrolled in the census, that service in the army was a valid excuse for absence.\n\nAfter the censors had received the names of all the citizens with the amount of their property, they then had to make out the lists of the tribes, and also of the classes and centuries; for by the legislation of Servius Tullius the position of each citizen in the state was determined by the amount of his property (Comitia Centuriata). These lists formed a most important part of the Tabulae Censoriae, under which name were included all the documents connected in any way with the discharge of the censors' duties. These lists, insofar as they were connected with the finances of the state, were deposited in the aerarium, which was the temple of Saturn; but the regular depositary for all the archives of the censors was in earlier times the Atrium Libertatis, near the Villa publica, and in later times the temple of the Nymphs.\n\nBesides the division of the citizens into tribes, centuries, and classes, the censors had also to make out the lists of the senators for the ensuing five years, or until new censors were appointed; striking out the names of such as they considered unworthy, and making additions to the body from those who were qualified. In the same manner they held a review of the Equestrians who received a horse from public funds (\"equites equo publico\"), and added and removed names as they judged proper. They also confirmed the princeps senatus, or appointed a new one. The princeps himself had to be a former censor.\n\nAfter the lists had been completed, the number of citizens was counted up, and the sum total announced. Accordingly, we find that in the account of a census, the number of citizens is likewise usually given. They are in such cases spoken of as \"capita\" (\"heads\"), sometimes with the addition of the word \"civium\" (\"of the citizens\"), and sometimes not. Hence, to be registered in the census was the same thing as \"having a head\" (\"caput habere\").\n\nA census was sometimes taken in the provinces, even under the republic. The Emperor sent into the provinces special officers called Censitores to take the census; but the duty was sometimes discharged by the Imperial legati. The Censitores were assisted by subordinate officers, called Censuales, who made out the lists, &c. In Rome, the census was still taken under the empire, but the old ceremonies connected with it were no longer performed, and the ceremony of the lustration was not performed after the time of Vespasian. The jurists Paulus and Ulpian each wrote works on the census in the imperial period; and several extracts from these works are given in a chapter in the \"Digest\" (50 15). \n\nThe word \"census\", besides the conventional meaning of \"valuation\" of a person's estate, has other meaning in Rome; it could refer to: \n\nKeeping the public morals (\"regimen morum\", or in the empire \"cura morum\" or \"praefectura morum\") was the second most important branch of the censors' duties, and the one which caused their office to be one of the most revered and the most dreaded in the Roman state; hence they were also known as \"Castigatores\" (\"chastisers\"). It naturally grew out of the right which they possessed of excluding persons from the lists of citizens; for, as has been well remarked, \"they would, in the first place, be the sole judges of many questions of fact, such as whether a citizen had the qualifications required by law or custom for the rank which he claimed, or whether he had ever incurred any judicial sentence, which rendered him infamous: but from thence the transition was easy, according to Roman notions, to the decisions of questions of right; such as whether a citizen was really worthy of retaining his rank, whether he had not committed some act as justly degrading as those which incurred the sentence of the law.\" \n\nIn this manner, the censors gradually assumed at least nominal complete superintendence over the whole public and private life of every citizen. They were constituted as the conservators of public morality; they were not simply to prevent crime or particular acts of immorality, but rather to maintain the traditional Roman character, ethics, and habits (\"mos majorum\")—\"regimen morum\" also encompassed this protection of traditional ways, which was called in the times of the empire \"cura\" (\"supervision\") or \"praefectura\" (\"command\"). The punishment inflicted by the censors in the exercise of this branch of their duties was called \"nota\" (\"mark, letter\") or \"notatio\", or \"animadversio censoria\" (\"censorial reproach\"). In inflicting it, they were guided only by their conscientious convictions of duty; they had to take an oath that they would act biased by neither partiality nor favour; and, in addition to this, they were bound in every case to state in their lists, opposite the name of the guilty citizen, the cause of the punishment inflicted on him, \"Subscriptio censoria\".\n\nThis part of the censors' office invested them with a peculiar kind of jurisdiction, which in many respects resembled the exercise of public opinion in modern times; for there are innumerable actions which, though acknowledged by every one to be prejudicial and immoral, still do not come within the reach of the positive laws of a country; as often said, \"immorality does not equal illegality\". Even in cases of real crimes, the positive laws frequently punish only the particular offence, while in public opinion the offender, even after he has undergone punishment, is still incapacitated for certain honours and distinctions which are granted only to persons of unblemished character.\n\nHence the Roman censors might brand a man with their \"censorial mark\" (\"nota censoria\") in case he had been convicted of a crime in an ordinary court of justice, and had already suffered punishment for it. The consequence of such a nota was only \"ignominia\" and not \"infamia\". \"Infamia\" and the censorial verdict was not a \"judicium\" or \"res judicata\", for its effects were not lasting, but might be removed by the following censors, or by a \"lex\" (roughly \"law\"). A censorial mark was moreover not valid unless both censors agreed. The \"ignominia\" was thus only a transitory reduction of status, which does not even appear to have deprived a magistrate of his office, and certainly did not disqualify persons labouring under it for obtaining a magistracy, for being appointed as \"judices\" by the praetor, or for serving in the Roman armies. Mamercus Aemilius Mamercinus was thus, notwithstanding the reproach of the censors (\"animadversio censoria\"), made dictator.\n\nA person might be branded with a censorial mark in a variety of cases, which it would be impossible to specify, as in a great many instances it depended upon the discretion of the censors and the view they took of a case; and sometimes even one set of censors would overlook an offence which was severely chastised by their successors. But the offences which are recorded to have been punished by the censors are of a threefold nature.\nA person who had been branded with a \"nota censoria\", might, if he considered himself wronged, endeavour to prove his innocence to the censors, and if he did not succeed, he might try to gain the protection of one of the censors, that he might intercede on his behalf.\n\nThe punishments inflicted by the censors generally differed according to the station which a man occupied, though sometimes a person of the highest rank might suffer all the punishments at once, by being degraded to the lowest class of citizens. But they are generally divided into four classes:\n\n\nIt was this authority of the Roman censors which eventually developed into the modern meaning of \"censor\" and \"censorship\"—i.e., officials who review published material and forbid the publication of material judged to be contrary to \"public morality\" as the term is interpreted in a given political and social environment.\n\nThe administration of the state's finances was another part of the censors' office. In the first place the \"tributum\", or property-tax, had to be paid by each citizen according to the amount of his property registered in the census, and, accordingly, the regulation of this tax naturally fell under the jurisdiction of the censors. They also had the superintendence of all the other revenues of the state, the \"vectigalia\", such as the tithes paid for the public lands, the salt works, the mines, the customs, etc.\n\nThe censors typically auctioned off to the highest bidder for the space of a \"lustrum\" the collection of the tithes and taxes (tax farming). This auctioning was called \"venditio\" or \"locatio\", and seems to have taken place in the month of March, in a public place in Rome The terms on which they were let, together with the rights and duties of the purchasers, were all specified in the \"leges censoriae\", which the censors published in every case before the bidding commenced. For further particulars see Publicani.\n\nThe censors also possessed the right, though probably not without the assent of the Senate, of imposing new \"vectigalia\", and even of selling the land belonging to the state. It would thus appear that it was the duty of the censors to bring forward a budget for a five-year period, and to take care that the income of the state was sufficient for its expenditure during that time. In part, their duties resembled those of a modern minister of finance. The censors, however, did not receive the revenues of the state. All the public money was paid into the \"aerarium\", which was entirely under the jurisdiction of the senate; and all disbursements were made by order of this body, which employed the quaestors as its officers.\n\nIn one important department the censors were entrusted with the expenditure of the public money, though the actual payments were no doubt made by the quaestors. The censors had the general superintendence of all the public buildings and works (\"opera publica\"), and to meet the expenses connected with this part of their duties, the senate voted them a certain sum of money or certain revenues, to which they were restricted, but which they might at the same time employ according to their discretion. They had to see that the temples and all other public buildings were in a good state of repair, that no public places were encroached upon by the occupation of private persons, and that the aqueduct, roads, drains, etc. were properly attended to.\n\nThe repairs of the public works and the keeping of them in proper condition were let out by the censors by public auction to the lowest bidder, just as the \"vectigalia\" were let out to the highest bidder. These expenses were called \"ultrotributa\", and hence we frequently find \"vectigalia\" and \"ultrotributa\" contrasted with one another. The persons who undertook the contract were called \"conductores\", \"mancipes\", \"redemptores\", \"susceptores\", etc.; and the duties they had to discharge were specified in the Leges Censoriae. The censors had also to superintend the expenses connected with the worship of the gods, even for instance the feeding of the sacred geese in the Capitol; these various tasks were also let out on contract. It was ordinary for censors to expend large amounts of money (“by far the largest and most extensive” of the state) in their public works.\n\nBesides keeping existing public buildings and facilities in a proper state of repair, the censors were also in charge of constructing new ones, either for ornament or utility, both in Rome and in other parts of Italy, such as temples, basilicae, theatres, porticoes, fora, walls of towns, aqueducts, harbours, bridges, cloacae, roads, etc. These works were either performed by them jointly, or they divided between them the money, which had been granted to them by the senate. They were let out to contractors, like the other works mentioned above, and when they were completed, the censors had to see that the work was performed in accordance with the contract: this was called \"opus probare\" or \"in acceptum referre\".\n\nThe aediles had likewise a superintendence over the public buildings, and it is not easy to define with accuracy the respective duties of the censors and aediles, but it may be remarked in general that the superintendence of the aediles had more of a police character, while that of the censors were more financial in subject matter.\n\nAfter the censors had performed their various duties and taken the five-yearly census, the \"lustrum\", a solemn purification of the people, followed. When the censors entered upon their office, they drew lots to see which of them should perform this purification; but both censors were of course obliged to be present at the ceremony.\n\nLong after the Roman census was no longer taken, the Latin word \"lustrum\" has survived, and been adopted in some modern languages, in the derived sense of a period of five years, i.e. half a decennium.\n\n\n", "id": "6291", "title": "Roman censor"}
{"url": "https://en.wikipedia.org/wiki?curid=6292", "text": "Convex set\n\nIn convex geometry, a convex set is a subset of an affine space that is closed under convex combinations. More specifically, in a Euclidean space, a convex region is a region where, for every pair of points within the region, every point on the straight line segment that joins the pair of points is also within the region. For example, a solid cube is a convex set, but anything that is hollow or has an indent, for example, a crescent shape, is not convex.\n\nThe boundary of a convex set is always a convex curve. The intersection of all convex sets containing a given subset of Euclidean space is called the convex hull of . It is the smallest convex set containing .\n\nA convex function is a real-valued function defined on an interval with the property that its epigraph (the set of points on or above the graph of the function) is a convex set. Convex minimization is a subfield of optimization that studies the problem of minimizing convex functions over convex sets. The branch of mathematics devoted to the study of properties of convex sets and convex functions is called convex analysis.\n\nThe notion of a convex set can be generalized as described below.\n\nLet be a vector space over the real numbers, or, more generally, some ordered field. This includes Euclidean spaces. A set in is said to be convex if, for all and in and all in the interval , the point also belongs to . In other words, every point on the line segment connecting and is in . This implies that a convex set in a real or complex topological vector space is path-connected, thus connected.\nFurthermore, is strictly convex if every point on the line segment connecting and other than the endpoints is inside the interior of .\n\nA set is called absolutely convex if it is convex and balanced.\n\nThe convex subsets of (the set of real numbers) are simply the intervals of . Some examples of convex subsets of the Euclidean plane are solid regular polygons, solid triangles, and intersections of solid triangles. Some examples of convex subsets of a Euclidean 3-dimensional space are the Archimedean solids and the Platonic solids. The Kepler-Poinsot polyhedra are examples of non-convex sets.\n\nA set that is not convex is called a \"non-convex set\". A polygon that is not a convex polygon is sometimes called a concave polygon, and some sources more generally use the term \"concave set\" to mean a non-convex set, but most authorities prohibit this usage.\n\nThe complement of a convex set, such as the epigraph of a concave function, is sometimes called a \"reverse convex set\", especially in the context of mathematical optimization.\n\nIf is a convex set in -dimensional space, then for any collection of , , -dimensional vectors in , and for any nonnegative numbers such that , then one has:\nA vector of this type is known as a convex combination of .\n\nThe collection of convex subsets of a vector space has the following properties:\n\nClosed convex sets are convex sets that contain all their limit points. They can be characterised as the intersections of \"closed half-spaces\" (sets of point in space that lie on and to one side of a hyperplane).\n\nFrom what has just been said, it is clear that such intersections are convex, and they will also be closed sets. To prove the converse, i.e., every convex set may be represented as such intersection, one needs the supporting hyperplane theorem in the form that for a given closed convex set and point outside it, there is a closed half-space that contains and not . The supporting hyperplane theorem is a special case of the Hahn–Banach theorem of functional analysis.\n\nLet C be a convex body in the plane. We can inscribe a rectangle r in C such that a homothetic copy R of r is circumscribed about C. The positive homothety ratio is at most 2 and:\n\nEvery subset of the vector space is contained within a smallest convex set (called the convex hull of ), namely the intersection of all convex sets containing . The convex-hull operator Conv() has the characteristic properties of a hull operator:\nThe convex-hull operation is needed for the set of convex sets to form a lattice, in which the \"\"join\"\" operation is the convex hull of the union of two convex sets\nThe intersection of any collection of convex sets is itself convex, so the convex subsets of a (real or complex) vector space form a complete lattice.\n\nIn a real vector-space, the \"Minkowski sum\" of two (non-empty) sets, and , is defined to be the set formed by the addition of vectors element-wise from the summand-sets\nMore generally, the \"Minkowski sum\" of a finite family of (non-empty) sets is the set formed by element-wise addition of vectors\n\nFor Minkowski addition, the \"zero set\"  containing only the zero vector  has special importance: For every non-empty subset S of a vector space\nin algebraic terminology, is the identity element of Minkowski addition (on the collection of non-empty sets).\n\nMinkowski addition behaves well with respect to the operation of taking convex hulls, as shown by the following proposition:\n\nLet be subsets of a real vector-space, the convex hull of their Minkowski sum is the Minkowski sum of their convex hulls\n\nThis result holds more generally for each finite collection of non-empty sets:\n\nIn mathematical terminology, the operations of Minkowski summation and of forming convex hulls are commuting operations.\n\nThe Minkowski sum of two compact convex sets is compact. The sum of a compact convex set and a closed convex set is closed.\n\nThe notion of convexity in the Euclidean space may be generalized by modifying the definition in some or other aspects. The common name \"generalized convexity\" is used, because the resulting objects retain certain properties of convex sets.\n\nLet be a set in a real or complex vector space. is star convex if there exists an in such that the line segment from to any point in is contained in . Hence a non-empty convex set is always star-convex but a star-convex set is not always convex.\n\nAn example of generalized convexity is orthogonal convexity.\n\nA set in the Euclidean space is called orthogonally convex or ortho-convex, if any segment parallel to any of the coordinate axes connecting two points of lies totally within . It is easy to prove that an intersection of any collection of orthoconvex sets is orthoconvex. Some other properties of convex sets are valid as well.\n\nThe definition of a convex set and a convex hull extends naturally to geometries which are not Euclidean by defining a geodesically convex set to be one that contains the geodesics joining any two points in the set.\n\nConvexity can be extended for a space endowed with the order topology, using the total order of the space.\n\nLet . The subspace is a convex set if for each pair of points in such that , the interval is contained in . That is, is convex if and only if for all in , implies .\n\nThe notion of convexity may be generalised to other objects, if certain properties of convexity are selected as axioms.\n\nGiven a set , a convexity over is a collection of subsets of satisfying the following axioms:\n\n\nThe elements of are called convex sets and the pair is called a convexity space. For the ordinary convexity, the first two axioms hold, and the third one is trivial.\n\nFor an alternative definition of abstract convexity, more suited to discrete geometry, see the \"convex geometries\" associated with antimatroids.\n\n", "id": "6292", "title": "Convex set"}
{"url": "https://en.wikipedia.org/wiki?curid=6293", "text": "Cairo\n\nCairo ( ; ', ') is the capital and largest city of Egypt. The city's metropolitan area is the largest in the Middle East and the Arab world, and 15th-largest in the world, and is associated with ancient Egypt, as the famous Giza pyramid complex and the ancient city of Memphis are located in its geographical area. Located near the Nile Delta, modern Cairo was founded in 969 CE by Jawhar of the Fatimid dynasty, but the land composing the present-day city was the site of ancient national capitals whose remnants remain visible in parts of Old Cairo. Cairo has long been a center of the region's political and cultural life, and is titled \"the city of a thousand minarets\" for its preponderance of Islamic architecture.\n\nCairo has the oldest and largest film and music industries in the Arab world, as well as the world's second-oldest institution of higher learning, Al-Azhar University. Many international media, businesses, and organizations have regional headquarters in the city; the Arab League has had its headquarters in Cairo for most of its existence.\n\nWith a population of 6.76 million spread over , Cairo is by far the largest city in Egypt. An additional 9.5 million inhabitants live in close proximity to the city. Cairo, like many other mega-cities, suffers from high levels of pollution and traffic. Cairo's metro, one of only two in Africa (the other is in Algiers, Algeria), ranks among the fifteen busiest in the world, with over 1 billion annual passenger rides. The economy of Cairo was ranked first in the Middle East in 2005, and 43rd globally on \"Foreign Policy\" 2010 Global Cities Index.\n\nEgyptians often refer to Cairo as ' (; ), the Egyptian Arabic name for Egypt itself, emphasizing the city's importance for the country. Its official name ' () means \"the Vanquisher\" or \"the Conqueror\", supposedly due to the fact that the planet Mars, al-Najm al-Qahir (, literally \"the Counquering Star\"), was rising at the time when the city was founded, possibly also in reference to the much awaited arrival of Caliph al-Mu'izz li Din Allah who reached Cairo in 973 from Mahdia, the old Fatimid capital. In Coptic the city is known as Kahire (), meaning \"Place of the Sun\", possibly referring to the ancient city of Heliopolis, the main seat of worship of the solar deity Ra—(or Re). The location of the ancient city is the suburb of Ain Shams (, literally \"Sun-Eye\" or \"Eye of the Sun\"). The ancient Egyptian name for the area is thought to be Khere-Ohe, \"The Place of Combat\", supposedly in reference to a mythical battle that took place between Seth and Horus. Sometimes the city is informally referred to as ' (; ).\n\nThe area around present-day Cairo, especially Memphis, had long been a focal point of Ancient Egypt due to its strategic location just upstream from the Nile Delta. However, the origins of the modern city are generally traced back to a series of settlements in the first millennium. Around the turn of the 4th century, as Memphis was continuing to decline in importance, the Romans established a fortress town along the east bank of the Nile. This fortress, known as Babylon, remained the nucleus of the Roman, and, later, the Byzantine, city and is the oldest structure in the city today. It is also situated at the nucleus of the Coptic Orthodox community, which separated from the Roman and Byzantine church in the late 4th century. Many of Cairo's oldest Coptic churches, including the Hanging Church, are located along the fortress walls in a section of the city known as Coptic Cairo.\n\nFollowing the Muslim conquest in 640 AD the conqueror Amr ibn As settled to the north of the Babylon in an area that became known as al-Fustat. Originally a tented camp (\"Fustat\" signifies \"City of Tents\") Fustat became a permanent settlement and the first capital of Islamic Egypt.\n\nIn 750, following the overthrow of the Ummayad caliphate by the Abbasids, the new rulers created their own settlement to the northeast of Fustat which became their capital. This was known as al-Askar (the city of sections, or cantonments) as it was laid out like a military camp.\n\nA rebellion in 869 by Ahmad ibn Tulun led to the abandonment of Al Askar and the building of another settlement, which became the seat of government. This was al-Qatta'i (\"the Quarters\"), to the north of Fustat and closer to the river. Al Qatta'i was centred around a palace and ceremonial mosque, now known as the Mosque of ibn Tulun.\n\nIn 905 the Abbasids re-asserted control of the country and their governor returned to Fustat, razing al Qattai to the ground.\n\nIn 969 the Fatimid conquest saw the founding of yet another settlement, further north again, called al Qahira (\"the Victorious\", or \"the Conqueror\"), the nascent city of Cairo. However Fustat remained the capital, until 1168, when the then vizier of al Qahira transferred his government there and had Fustat destroyed by fire.\n\nAs Qahira expanded these earlier settlements were encompassed, and have since become part of the city of Cairo as it expanded and spread; they are now collectively known as \"Old Cairo\".\n\nIn 968, the Fatimids were led by General Jawhar al-Siqilli with his Kutama army, to establish a new capital for the Fatimid dynasty. Egypt was conquered from their base in Ifriqiya and a new fortified city northeast of Fustat was established. It took four years for Jawhar to build the city, initially known as al-Manṣūriyyah, which was to serve as the new capital of the caliphate. During that time, Jawhar also commissioned the construction of the al-Azhar Mosque, which developed into the third-oldest university in the world. Cairo would eventually become a centre of learning, with the library of Cairo containing hundreds of thousands of books. When Caliph al-Mu'izz li Din Allah finally arrived from the old Fatimid capital of Mahdia in Tunisia in 973, he gave the city its present name, \"al-Qahira\" (\"The Victorious\").\n\nFor nearly 200 years after Cairo was established, the administrative centre of Egypt remained in Fustat. However, in 1168 the Fatimids under the leadership of Vizier Shawar set fire to Fustat to prevent Cairo's capture by the Crusaders. Egypt's capital was permanently moved to Cairo, which was eventually expanded to include the ruins of Fustat and the previous capitals of al-Askar and al-Qatta'i. While the Fustat fire successfully protected the city of Cairo, a continuing power struggle between Shawar, King Amalric I of Jerusalem, and the Zengid general Shirkuh led to the downfall of the Fatimid establishment.\n\nIn 1169 Saladin was appointed as the new vizier of Egypt by the Fatimids and two years later he seized power from the family of the last Fatimid caliph, al-'Āḍid. As the first Sultan of Egypt, Saladin established the Ayyubid dynasty, based in Cairo, and aligned Egypt with the Abbasids, who were based in Baghdad. During his reign, Saladin also constructed the Cairo Citadel, which served as the seat of the Egyptian government until the mid-19th century.\nIn 1250 slave soldiers, known as the Mamluks, seized control of Egypt and like many of their predecessors established Cairo as the capital of their new dynasty. Continuing a practice started by the Ayyubids, much of the land occupied by former Fatimid palaces was sold and replaced by newer buildings. Construction projects initiated by the Mamluks pushed the city outward while also bringing new infrastructure to the centre of the city. Meanwhile, Cairo flourished as a centre of Islamic scholarship and a crossroads on the spice trade route among the civilisations in Afro-Eurasia. By 1340, Cairo had a population of close to half a million, making it the largest city west of China.\n\nAlthough Cairo avoided Europe's stagnation during the Late Middle Ages, it could not escape the Black Death, which struck the city more than fifty times between 1348 and 1517. During its initial, and most deadly waves, approximately 200,000 people were killed by the plague, and, by the 15th century, Cairo's population had been reduced to between 150,000 and 300,000. The city's status was further diminished after Vasco da Gama discovered a sea route around the Cape of Good Hope between 1497 and 1499, thereby allowing spice traders to avoid Cairo.\nCairo's political influence diminished significantly after the Ottomans supplanted Mamluk power over Egypt in 1517. Ruling from Constantinople, Sultan Selim I relegated Egypt to a mere province, with Cairo as its capital. For this reason, the history of Cairo during Ottoman times is often described as inconsequential, especially in comparison to other time periods. However, during the 16th and 17th centuries, Cairo remained an important economic and cultural centre. Although no longer on the spice route, the city facilitated the transportation of Yemeni coffee and Indian textiles, primarily to Anatolia, North Africa, and the Balkans. Cairene merchants were instrumental in bringing goods to the barren Hejaz, especially during the annual hajj to Mecca. It was during this same period that al-Azhar University reached the predominance among Islamic schools that it continues to hold today; pilgrims on their way to hajj often attested to the superiority of the institution, which had become associated with Egypt's body of Islamic scholars. By the 16th century, Cairo also had high-rise apartment buildings where the two lower floors were for commercial and storage purposes and the multiple stories above them were rented out to tenants.\n\nUnder the Ottomans, Cairo expanded south and west from its nucleus around the Citadel. The city was the second-largest in the empire, behind only Constantinople, and, although migration was not the primary source of Cairo's growth, twenty percent of its population at the end of the 18th century consisted of religious minorities and foreigners from around the Mediterranean. Still, when Napoleon arrived in Cairo in 1798, the city's population was less than 300,000, forty percent lower than it was at the height of Mamluk—and Cairene—influence in the mid-14th century.\n\nThe French occupation was short-lived as British and Ottoman forces, including a sizeable Albanian contingent, recaptured the country in 1801. Cairo itself was besieged by a British and Ottoman force culminating with the French surrender on 22 June 1801. The British vacated Egypt two years later, leaving the Ottomans, the Albanians, and the long-weakened Mamluks jostling for control of the country. Continued civil war allowed an Albanian named Muhammad Ali Pasha to ascend to the role of commander and eventually, with the approval of the religious establishment, viceroy of Egypt in 1805.\n\nUntil his death in 1848, Muhammad Ali Pasha instituted a number of social and economic reforms that earned him the title of founder of modern Egypt. However, while Muhammad Ali initiated the construction of public buildings in the city, those reforms had minimal effect on Cairo's landscape. Bigger changes came to Cairo under Isma'il Pasha (r. 1863–1879), who continued the modernisation processes started by his grandfather. Drawing inspiration from Paris, Isma'il environs a city of maidans and wide avenues; due to financial constraints, only some of them, in the area now composing Downtown Cairo, came to fruition. Isma'il also sought to modernize the city, which was merging with neighboring settlements, by establishing a public works ministry, bringing gas and lighting to the city, and opening a theater and opera house.\n\nThe immense debt resulting from Isma'il's projects provided a pretext for increasing European control, which culminated with the British invasion in 1882. The city's economic centre quickly moved west toward the Nile, away from the historic Islamic Cairo section and toward the contemporary, European-style areas built by Isma'il. Europeans accounted for five percent of Cairo's population at the end of the 19th century, by which point they held most top governmental positions.\n\nThe British occupation was intended to be temporary, but it lasted well into the 20th century. Nationalists staged large-scale demonstrations in Cairo in 1919, five years after Egypt had been declared a British protectorate. Nevertheless, while this led to Egypt's independence in 1922, British troops remained in the country until 1956. During this time, urban Cairo, spurred by new bridges and transport links, continued to expand to include the upscale neighbourhoods of Garden City, Zamalek, and Heliopolis. Between 1882 and 1937, the population of Cairo more than tripled—from 347,000 to 1.3 million—and its area increased from .\n\nThe city was devastated during the 1952 riots known as the Cairo Fire or Black Saturday, which saw the destruction of nearly 700 shops, movie theatres, casinos and hotels in Downtown Cairo. The British departed Cairo following the Egyptian Revolution of 1952, but the city's rapid growth showed no signs of abating. Seeking to accommodate the increasing population, President Gamal Abdel Nasser redeveloped Midan Tahrir and the Nile Corniche, and improved the city's network of bridges and highways. Meanwhile, additional controls of the Nile fostered development within Gezira Island and along the city's waterfront. The metropolis began to encroach on the fertile Nile Delta, prompting the government to build desert satellite towns and devise incentives for city-dwellers to move to them.\n\nDespite these efforts, Cairo's population has doubled since the 1960s, reaching close to seven million (with an additional ten million in its urban area). Concurrently, Cairo has established itself as a political and economic hub for North Africa and the Arab world, with many multinational businesses and organisations, including the Arab League, operating out of the city.\n\nIn 1992, Cairo was hit by a damaging earthquake, that caused 545 deaths, 6,512 injuries and left 50,000 people homeless.\n\nCairo's Tahrir Square was the focal point of the 2011 Egyptian Revolution against former president Hosni Mubarak. Over 2 million protesters were at Cairo's Tahrir square. More than 50,000 protesters first occupied the square on 25 January, during which the area's wireless services were reported to be impaired. In the following days Tahrir Square continued to be the primary destination for protests in Cairo as it took place following a popular uprising that began on Tuesday, 25 January 2011 and is still continuing as of February 2012. The uprising was mainly a campaign of non-violent civil resistance, which featured a series of demonstrations, marches, acts of civil disobedience, and labour strikes. Millions of protesters from a variety of socio-economic and religious backgrounds demanded the overthrow of the regime of Egyptian President Hosni Mubarak. Despite being predominantly peaceful in nature, the revolution was not without violent clashes between security forces and protesters, with at least 846 people killed and 6,000 injured. The uprising took place in Cairo, Alexandria, and in other cities in Egypt, following the Tunisian revolution that resulted in the overthrow of the long-time Tunisian president Zine El Abidine Ben Ali. On 11 February, following weeks of determined popular protest and pressure, Hosni Mubarak resigned from office.\n\nUnder the rule of President el-Sisi, in March 2015 plans were announced for another yet-unnamed planned city to be built further east of the existing satellite city of New Cairo, intended to serve as the new capital of Egypt.\n\nCairo is located in northern Egypt, known as Lower Egypt, south of the Mediterranean Sea and west of the Gulf of Suez and Suez Canal. The city is along the Nile River, immediately south of the point where the river leaves its desert-bound valley and branches into the low-lying Nile Delta region. Although the Cairo metropolis extends away from the Nile in all directions, the city of Cairo resides only on the east bank of the river and two islands within it on a total area of .\n\nUntil the mid-19th century, when the river was tamed by dams, levees, and other controls, the Nile in the vicinity of Cairo was highly susceptible to changes in course and surface level. Over the years, the Nile gradually shifted westward, providing the site between the eastern edge of the river and the Mokattam highlands on which the city now stands. The land on which Cairo was established in 969 (present-day Islamic Cairo) was located underwater just over three hundred years earlier, when Fustat was first built.\n\nLow periods of the Nile during the 11th century continued to add to the landscape of Cairo; a new island, known as \"Geziret al-Fil\", first appeared in 1174, but eventually became connected to the mainland. Today, the site of \"Geziret al-Fil\" is occupied by the Shubra district. The low periods created another island at the turn of the 14th century that now composes Zamalek and Gezira. Land reclamation efforts by the Mamluks and Ottomans further contributed to expansion on the east bank of the river.\n\nBecause of the Nile's movement, the newer parts of the city—Garden City, Downtown Cairo, and Zamalek—are located closest to the riverbank. The areas, which are home to most of Cairo's embassies, are surrounded on the north, east, and south by the older parts of the city. Old Cairo, located south of the centre, holds the remnants of Fustat and the heart of Egypt's Coptic Christian community, Coptic Cairo. The Boulaq district, which lies in the northern part of the city, was born out of a major 16th-century port and is now a major industrial centre. The Citadel is located east of the city centre around Islamic Cairo, which dates back to the Fatimid era and the foundation of Cairo. While western Cairo is dominated by wide boulevards, open spaces, and modern architecture of European influence, the eastern half, having grown haphazardly over the centuries, is dominated by small lanes, crowded tenements, and Islamic architecture.\n\nNorthern and extreme eastern parts of Cairo, which include satellite towns, are among the most recent additions to the city, as they developed in the late-20th and early-21st centuries to accommodate the city's rapid growth. The western bank of the Nile is commonly included within the urban area of Cairo, but it composes the city of Giza and the Giza Governorate. Giza has also undergone significant expansion over recent years, and today the city, although still a suburb of Cairo, has a population of 2.7 million. The Cairo Governorate was just north of the Helwan Governorate from 2008 when some Cairo's southern districts, including Maadi and New Cairo, were split off and annexed into the new governorate, to 2011 when the Helwan Governorate was reincorporated into the Cairo Governorate.\nIn Cairo, and along the Nile River Valley, the climate is a hot desert climate (\"BWh\" according to the Köppen climate classification system), but often with high humidity as it is not very far from the Mediterranean Sea and the Nile Delta. Wind storms can be frequent, bringing Saharan dust into the city, sometimes from March to May (see Khamasin) and the air often becomes uncomfortably dry. High temperatures in winter range from , while night-time lows drop to below , often to . In summer, the highs rarely surpass , and lows drop to about . Rainfall is sparse and only happens in the colder months, but sudden showers do cause harsh flooding. Snowfall is extremely rare; a small amount of graupel, widely believed to be snow, fell on Cairo's easternmost suburbs on 13 December 2013, the first time Cairo's area received this kind of precipitation in many decades. Dewpoints in the hottest months range from in June to in August.\n\nThe Greater Cairo is the largest metropolitan area in Africa. It consists of Cairo Governorate, parts of Giza Governorate, and parts of Qalyubia Governorate.\n\n6th of October City, west of Cairo, and New Cairo, east of Cairo, are major urban developments which have been built to accommodate additional growth and development of the Cairo area. New development includes several high-end residential developments.\n\nIn March 2015, plans were announced for a yet-unnamed planned city to be built east of Cairo, in an undeveloped area of the Cairo Governorate, which would serve as the administrative and financial capital of Egypt.\n\nCairo, as well as neighbouring Giza, has been established as Egypt's main centre for medical treatment, and despite some exceptions, has the most advanced level of medical care in the country. Cairo's hospitals include the JCI-accredited As-Salaam International Hospital—Corniche El Nile, Maadi (Egypt's largest private hospital with 350 beds), Ain Shams University Hospital, Dar El Fouad Hospital, as well as Kasr El Aini Hospital.\n\nGreater Cairo has long been the hub of education and educational services for Egypt and the region.\nToday, Greater Cairo is the centre for many government offices governing the Egyptian educational system, has the largest number of educational schools, and higher learning institutes among other cities and governorates of Egypt.\n\nSome of the International Schools found in Cairo:\nUniversities in Greater Cairo:\n\nCairo has an extensive road network, rail system, subway system and maritime services. Road transport is facilitated by personal vehicles, taxi cabs, privately owned public buses and Cairo microbuses. Cairo, specifically Ramses Square, is the centre of almost the entire Egyptian transportation network.\n\nThe subway system, officially called \"Metro (مترو)\", is a fast and efficient way of getting around Cairo. Metro network covers Helwan and other suburbs. It can get very crowded during rush hour. Two train cars (the fourth and fifth ones) are reserved for women only, although women may ride in any car they want.\n\nTrams in Greater Cairo (Heliopolis and Nasr City) exists now, while Cairo trolleybus was closed.\n\nAn extensive road network connects Cairo with other Egyptian cities and villages. There is a new Ring Road that surrounds the outskirts of the city, with exits that reach outer Cairo districts. There are flyovers and bridges, such as the Sixth of October bridge that, when the traffic is not heavy, allow fast means of transportation from one side of the city to the other.\n\nCairo traffic is known to be overwhelming and overcrowded. Traffic moves at a relatively fluid pace. Drivers tend to be aggressive, but are more courteous at junctions, taking turns going, with police aiding in traffic control of some congested areas.\n\nOn 25 October 2009 a passenger train ran into another one near Giza, just outside Cairo. Local news agencies reported at least 25 people dead. A local resident, Samhi Saleh Abdel Al, told reporters that \"\"the first train stopped after hitting a cow and 10 minutes later the second train arrived at full speed.\"\" One of the two trains was travelling from Cairo to Assiut, while the other was said to have been en route to Fayoum from Giza. Around 55 people were injured.\n\nFootball is the most popular sport in Egypt, and Cairo has a number of sporting teams that compete in national and regional leagues. The best known teams are Al-Ahly, El Zamalek and Al-Ismaily. Al-Ahly and El Zamalek annual football tournament is perhaps the most watched sports event in Egypt as well as the African-Arab region. Both teams are known as the \"rivals\" of Egyptian football, and are the first and the second champions in Africa and the Arab world. They play their home games at Cairo International Stadium or Naser Stadium, which is Egypt's 2nd largest stadium, Cairo's largest one and one of the largest stadiums in the world.\n\nThe Cairo International Stadium was built in 1960 and its multi-purpose sports complex that houses the main football stadium, an indoor stadium, several satellite fields that held several regional, continental and global games, including the African Games, U17 Football World Championship and was one of the stadiums scheduled that hosted the 2006 Africa Cup of Nations which was played in January 2006. Egypt later won the competition and went on to win the next edition In Ghana (2008) making the Egyptian and Ghanaian national teams the only teams to win the African Nations Cup Back to back which resulted in Egypt winning the title for a record number of six times in the history of African Continental Competition. This was followed by a third consecutive win in Angola 2010, making Egypt the only country with a record 3-consecutive and 7-total Continental Football Competition winner. This achievement had also placed the Egyptian football team as the #9 best team in the world's FIFA rankings.\n\nCairo failed at the applicant stage when bidding for the 2008 Summer Olympic Games, which was hosted in Beijing, China. However, Cairo did host the 2007 Pan Arab Games.\n\nThere are several other sports teams in the city that participate in several sports including el Gezira Sporting Club, el Shams Club, el Seid Club, Heliopolis Club and several smaller clubs, but the biggest clubs in Egypt (not in area but in sports) are Al Ahly and Al Zamalek. They have the two biggest football teams in Egypt. There are new sports clubs in the area of New Cairo (one hour far from Cairo's down town), these are Al Zohour sporting club, Wadi Degla sporting club and Platinum Club.\n\nMost of the sports federations of the country are also located in the city suburbs, including the Egyptian Football Association. The headquarters of the Confederation of African Football (CAF) was previously located in Cairo, before relocating to its new headquarters in 6 October City, a small city away from Cairo's crowded districts.\n\nIn October 2008, the Egyptian Rugby Federation was officially formed and granted membership into the International Rugby Board.\n\nEgypt is internationally known for the excellence of its squash players who excel in both professional and junior divisions. Gizira Club in Zamalek is where former world #1 Amr Shabana and former world #1 Karim Darwish practice. The Heliopolis Club in Heliopolis is the home of current world #1 Ramy Ashour and his brother, world #24, Hisham Ashour. Other major squash-playing venues are The Shooting Club (Nadi el Seid) in Dokki, The Maadi Club in Maadi and Wadi Degla in Degla.\n\nPresident Mubarak inaugurated the new Cairo Opera House of the Egyptian National Cultural Centres on 10 October 1988, 17 years after the Royal Opera House had been destroyed by fire. The National Cultural Centre was built with the help of JICA, the Japan International Co-operation Agency and stands as a prominent feature for the Japanese-Egyptian co-operation and the friendship between these two nations.\n\nThe Khedivial Opera House or Royal Opera House was the original opera house in Cairo, Egypt. It was dedicated on 1 November 1869 and burned down on 28 October 1971. After the original opera house was destroyed, Cairo was without an opera house for nearly two decades until the opening of the new Cairo Opera House in 1988.\n\nEgypt's love of the arts in general can be traced back to the rich heritage bequeathed by the ancient Egyptians. In modern times, Egypt has enjoyed a strong cinematic tradition since the art of film making was first developed, early in the 20th century. A natural progression from the active theatre scene of the time, cinema rapidly evolved into a vast motion picture industry. This together with the much older music tradition, raised Egypt to become a center for motion picture production in the Middle East and the cultural capital of the Arab world.\n\nEgypt has also been a fount of Arabic literature, producing some of the 20th century's greatest Arab writers such as Taha Hussein and Tawfiq al-Hakim to Nobel Laureate, novelist Naguib Mahfouz. Each of them has written for the cinema.\n\nWith these credentials, it was clear that Cairo should aim to hold an international film festival. This dream came true on Monday 16 August 1976, when the first Cairo International Film Festival was launched by the Egyptian Association of Film Writers and Critics, headed by Kamal El-Mallakh. The Association ran the festival for seven years until 1983.\n\nThis achievement lead to the President of the Festival again contacting the FIAPF with the request that a competition should be included at the 1991 Festival. The request was granted.\n\nIn 1998, the Festival took place under the presidency of one of Egypt's leading actors, Hussein Fahmy, who was appointed by the Minister of Culture, Farouk Hosni, after the death of Saad El-Din Wahba.\n\nFour years later, the journalist and writer Cherif El-Shoubashy became president.\n\nFor 33 years The International Festival has awarded dozens of international superstars, including John Malkovich, Nicolas Cage, Morgan Freeman, Bud Spencer, Gina Lollobrigida, Ornella Muti, Sophia Loren, Claudia Cardinale, Victoria Abril, Elizabeth Taylor, Shashi Kapoor, Alain Delon, Goldie Hawn, Kurt Russell, Susan Sarandon, Greta Scacchi, Catherine Deneuve, Peter O'Toole, Charlize Theron, Julia Ormond, Mira Sorvino, Stuart Townsend, Alicia Silverstone, Priscilla Presley, Christopher Lee, Irene Papas, Marcello Mastroianni, Salma Hayek, Lucy Liu, Samuel L. Jackson, Tom Berenger and Omar Sharif, as well as directors like Robert Wise, Elia Kazan, Vanessa Redgrave, Oliver Stone, Roland Joffé, Carlos Saura, Ismail Merchant and Michelangelo Antonioni, in an annual celebration and examination of the state of cinema in the world today. The presidents of the Festival since it was founded in 1976 are Saad El-Din Wahba, Hussein Fahmy and Sherif El Shoubashy. This year the festival a milestone of 30 years in an annual celebration and examination of the state of cinema in the world today.\n\nThe Cairo Geniza is an accumulation of almost 200,000 Jewish manuscripts that were found in the genizah of the Ben Ezra synagogue (built 882) of Fustat, Egypt (now Old Cairo), the Basatin cemetery east of Old Cairo, and a number of old documents that were bought in Cairo in the later 19th century. These documents were written from about 870 to as late as 1880 AD and have now been archived in various American and European libraries. The Taylor-Schechter collection in the University of Cambridge runs to 140,000 manuscripts, a further 40,000 manuscripts are at the Jewish Theological Seminary of America.\n\nMost residents (89%) are Sunni Muslim, while the rest of the population is mostly Christian. Al-Azhar University, based in Cairo, is considered the leading authority of Sunni Islam worldwide. Most Christians are Coptic Orthodox. Until his death in March 2012, Pope Shenouda III of Alexandria was the leader of the Coptic Orthodox Church, followed by Pope Tawadros II who became Pope on November 18, 2012, whose residence is in Cairo. Cairo has several synagogues, but few Jews remain after Israel was established and the subsequent exodus, largely due to state sponsored discrimination. Tension between members of different religions has increased recently.\n\nCairo was ranked as the \"world's most 24-hour city\" in a 2011 study conducted by the social networking site Badoo, placing it well ahead of other famous big cities such as New York, London or Paris. The study's rankings were determined by measuring the amount of online activity at night versus during the day and by comparing peak-times for such activity in cities across the world. Cairo's highly nocturnal lifestyle is attributed not only to young people in nightclubs but also to the importance of cafés, which remain very active at night as social gathering places to smoke shisha, and even to the late-night public activeness of families with children.\n\nCairo is also one of few cities in the Muslim world to have several casinos.\n\nCairo accounts for 11% of Egypt's population and 22% of its economy (PPP). Cairo is also in every respect the centre of Egypt, as it has been almost since its founding in 969 AD. The majority of the nation's commerce is generated there, or passes through the city. The great majority of publishing houses and media outlets and nearly all film studios are there, as are half of the nation's hospital beds and universities. This has fueled rapid construction in the city—one building in five is less than 15 years old.\n\nThis astonishing growth until recently surged well ahead of city services. Homes, roads, electricity, telephone and sewer services were all suddenly in short supply. Analysts trying to grasp the magnitude of the change coined terms like \"hyper-urbanization\".\n\n\nTahrir Square was founded during the mid 19th century with the establishment of modern downtown Cairo. It was first named Ismailia Square, after the 19th-century ruler Khedive Ismail, who commissioned the new downtown district's 'Paris on the Nile' design. After the Egyptian Revolution of 1919 the square became widely known as Tahrir (Liberation) Square, though it was not officially renamed as such until after the 1952 Revolution which eliminated the monarchy. Several notable buildings surround the square including, the American University in Cairo's downtown campus, the Mogamma governmental administrative Building, the headquarters of the Arab League, the Nile Ritz Carlton Hotel, and the Egyptian Museum. Being at the heart of Cairo, the square witnessed several major protests over the years. However, the most notable event in the square was being the focal point of the 2011 Egyptian Revolution against former president Hosni Mubarak.\n\nThe Museum of Egyptian Antiquities, known commonly as the Egyptian Museum, is home to the most extensive collection of ancient Egyptian antiquities in the world. It has 136,000 items on display, with many more hundreds of thousands in its basement storerooms. Among its most famous collections on display are the finds from the Tomb of Tutankhamun.\n\nThe Cairo Tower is a free-standing tower with a revolving restaurant at the top. It provides a bird's eye view of Cairo to the restaurant patrons. It stands in the Zamalek district on Gezira Island in the Nile River, in the city centre. At , it is higher than the Great Pyramid of Giza, which stands some to the southwest.\n\nThis area of Cairo is so-named as it contains the remains of the ancient Roman fortress of Babylon and also overlaps the original site of Fustat, the first Arab settlement in Egypt (7th century AD) and the predecessor of later Cairo. The area is also known as Coptic Cairo as it holds a high concentration of old Christian churches including the Hanging Church, the Greek Orthodox Church of St. George, and other Christian or Coptic buildings, most of which are located over the site of the ancient Roman fortress. It is also the location of the Coptic Museum, which showcases the history of Coptic art from Greco-Roman to Islamic times, and of the Ben Ezra Synagogue, the oldest and best-known synagogue in Cairo, where the important collection of Geniza documents were discovered in the 19th century. To the north of this Coptic enclave is the Amr ibn al-'As Mosque, the first mosque in Egypt and the most important religious center of former Fustat, founded in 642 AD right after the Arab conquest but rebuilt many times since.\n\nCairo holds one of the greatest concentrations of historical monuments of Islamic architecture in the world. The areas around the old walled city and around the Citadel are characterized by hundreds of mosques, tombs, madrasas, mansions, caravanserais, and fortifications dating from the Islamic era and are often referred to as \"Islamic Cairo\", especially in English travel literature. It is also the location of several important religious shrines such as the al-Hussein Mosque (whose shrine is believed to hold the head of Husayn ibn Ali), the Mausoleum of Imam al-Shafi'i (founder of the Shafi'i madhhab, one of the primary schools of thought in Sunni Islamic jurisprudence), the Tomb of Sayyida Ruqayya, the Mosque of Sayyida Nafisa, and others.\n\nWhile the first mosque in Egypt was the Mosque of Amr ibn al-As in Fustat, the Mosque of Ibn Tulun is the oldest mosque to retain its original form and is a rare example of Abbasid architecture, from the classical period of Islamic civilization. It was built in 876–879 AD in a style inspired by the Abbasid capital of Samarra in Iraq. It is one of the largest mosques in Cairo and is often cited as one of the most beautiful. Another Abbasid construction, the Nilometer on Rhoda Island, is the oldest original structure in Cairo, built in 862 AD. It was designed to measure the level of the Nile, which was important for agricultural and administrative purposes.\n\nThe city named Cairo (Arabic: \"al-Qahira\") was founded to the northeast of Fustat in 959 AD by the victorious Fatimid army. The Fatimids built a separate palatial city which contained their palaces and institutions of government. It was enclosed by a circuit of walls, which were rebuilt in stone in the late 11th century AD by the vizir Badr al-Gamali, parts of which survive today at Bab Zuwayla in the south and Bab al-Futuh and Bab al-Nasr in the north.\n\nOne of the most important and lasting institutions founded in the Fatimid period was the Mosque of al-Azhar, founded in 970 AD, which competes with the Qarawiyyin in Fes for the title of oldest university in the world. Today, al-Azhar University is the foremost center of Islamic learning in the world and one of Egypt's largest universities with campuses across the country. The mosque itself retains significant Fatimid elements but has been added to and expanded in subsequent centuries, notably by the Mamluk sultans Qaitbay and al-Ghuri and by Abd al-Rahman Katkhuda in the 18th century.\n\nOther extant monuments from the Fatimid era include the large Mosque of al-Hakim, the al-Aqmar mosque, Juyushi Mosque, Lulua Mosque, and the Mosque of Salih Tala'i.\n\nThe most prominent architectural heritage of medieval Cairo, however, dates from the Mamluk period, from 1250 to 1517 AD. The Mamluk sultans and elites were eager patrons of religious and scholarly life, commonly building religious or funerary complexes whose functions could include a mosque, madrasa, khanqah (for Sufis), water distribution centers (sabils), and mausoleum for themselves and their families. \nAmong the best-known examples of Mamluk monuments in Cairo are the huge Mosque-Madrasa of Sultan Hasan, the Mosque of Amir al-Maridani, the Mosque of Sultan al-Mu'ayyad (whose twin minarets were built above the gate of Bab Zuwayla), the Sultan Al-Ghuri complex, the funerary complex of Sultan Qaytbay in the Northern Cemetery, and the trio of monuments in the Bayn al-Qasrayn area comprising the complex of Sultan al-Mansur Qalawun, the Madrasa of al-Nasir Muhammad, and the Madrasa of Sultan Barquq. It is said that a lot of the columns found in mosques were taken from the Coptic churches because of their beautiful artistic carvings and placed in mosques.\n\nThe Mamluks, and the later Ottomans, also built wikalas or caravanserais to house merchants and goods due to the important role of trade and commerce in Cairo's economy. The most famous example still intact today is the Wikala al-Ghuri, which nowadays also hosts regular performances by the Al-Tannoura Egyptian Heritage Dance Troupe. The famous Khan al-Khalili (see below) is a commercial hub which also integrated caravanserais (also known as khans).\n\nThe Citadel is a fortified enclosure begun by Salah al-Din in 1176 AD on an outcrop of the Muqattam Hills as part of a large defensive system to protect both Cairo to the north and Fustat to the southwest. It was the center of Egyptian government and residence of its rulers until 1874, when Khedive Isma'il moved to 'Abdin Palace. It is still occupied by the military today, but is now open as a tourist attraction comprising, notably, the National Military Museum, the 14th century Mosque of al-Nasir Muhammad, and the 19th century Mosque of Muhammad Ali which commands a dominant position on Cairo's skyline.\n\nKhan el-Khalili is an ancient bazaar, or marketplace adjacent to the Al-Hussein Mosque. It dates back to 1385, when Amir Jarkas el-Khalili built a large caravanserai, or khan. (A caravanserai is a hotel for traders, and usually the focal point for any surrounding area.) This original carvanserai building was demolished by Sultan al-Ghuri, who rebuilt it as a new commercial complex in the early 16th century, forming the basis for the network of souqs existing today. Many medieval elements remain today, including the ornate Mamluk-style gateways. Today, the Khan el-Khalili is a major tourist attraction and popular stop for tour groups.\n\nCairo is an expanding city, which has led to many environmental problems. The air pollution in Cairo is a matter of serious concern. Greater Cairo's volatile aromatic hydrocarbon levels are higher than many other similar cities. Air quality measurements in Cairo have also been recording dangerous levels of lead, carbon dioxide, sulphur dioxide, and suspended particulate matter concentrations due to decades of unregulated vehicle emissions, urban industrial operations, and chaff and trash burning. There are over 4,500,000 cars on the streets of Cairo, 60% of which are over 10 years old, and therefore lack modern emission cutting features like catalytic converters. Cairo has a very poor dispersion factor because of lack of rain and its layout of tall buildings and narrow streets, which create a bowl effect.\nIn recent years, a mysterious black cloud (as Egyptians refer to it) appeared over Cairo every autumn and causes serious respiratory diseases and eye irritations for the city's citizens. Tourists who are not familiar with such high levels of pollution must take extra care.\n\nCairo also has many unregistered lead and copper smelters which heavily pollute the city. The results of this has been a permanent haze over the city with particulate matter in the air reaching over three times normal levels. It is estimated that 10,000 to 25,000 people a year in Cairo die due to air pollution-related diseases. Lead has been shown to cause harm to the central nervous system and neurotoxicity particularly in children. In 1995, the first environmental acts were introduced and the situation has seen some improvement with 36 air monitoring stations and emissions tests on cars. Twenty thousand buses have also been commissioned to the city to improve congestion levels, which are very high.\n\nThe city also suffers from a high level of land pollution. Cairo produces 10,000 tons of waste material each day, 4,000 tons of which is not collected or managed. This once again is a huge health hazard and the Egyptian Government is looking for ways to combat this. The Cairo Cleaning and Beautification Agency was founded to collect and recycle the waste; however, they also work with the Zabbaleen (or Zabaleen), a community that has been collecting and recycling Cairo's waste since the turn of the 20th century and live in an area known locally as Manshiyat naser. Both are working together to pick up as much waste as possible within the city limits, though it remains a pressing problem.\n\nThe city also suffers from water pollution as the sewer system tends to fail and overflow. On occasion, sewage has escaped onto the streets to create a health hazard. This problem is hoped to be solved by a new sewer system funded by the European Union, which could cope with the demand of the city. The dangerously high levels of mercury in the city's water system has global health officials concerned over related health risks.\n\n\n\n\n", "id": "6293", "title": "Cairo"}
{"url": "https://en.wikipedia.org/wiki?curid=6295", "text": "Chaos theory\n\nChaos theory is a branch of mathematics focused on the behavior of dynamical systems that are highly sensitive to initial conditions. 'Chaos' is an interdisciplinary theory stating that within the apparent randomness of chaotic complex systems, there are underlying patterns, constant feedback loops, repetition, self-similarity, fractals, self-organization, and reliance on programming at the initial point known as \"sensitive dependence on initial conditions\". The butterfly effect describes how a small change in one state of a deterministic nonlinear system can result in large differences in a later state, e.g. a butterfly flapping its wings in Brazil can cause a tornado in Texas.\n\nSmall differences in initial conditions (such as those due to rounding errors in numerical computation) yield widely diverging outcomes for such dynamical systems — a response popularly referred to as the butterfly effect - rendering long-term prediction of their behavior impossible in general. This happens even though these systems are deterministic, meaning that their future behavior is fully determined by their initial conditions, with no random elements involved. In other words, the deterministic nature of these systems does not make them predictable. This behavior is known as deterministic chaos, or simply chaos. The theory was summarized by Edward Lorenz as:\n\nChaotic behavior exists in many natural systems, such as weather and climate. It also occurs spontaneously in some systems with artificial components, such as road traffic. This behavior can be studied through analysis of a chaotic mathematical model, or through analytical techniques such as recurrence plots and Poincaré maps. Chaos theory has applications in several disciplines, including meteorology, sociology, physics, environmental science, computer science, engineering, economics, biology, ecology, and philosophy.\nThe theory formed the basis for such fields of study as complex dynamical systems, edge of chaos theory, self-assembly process.\n\nChaos theory concerns deterministic systems whose behavior can in principle be predicted. Chaotic systems are predictable for a while and then 'appear' to become random. The amount of time that the behavior of a chaotic system can be effectively predicted depends on three things: How much uncertainty we tolerate in the forecast, how accurately we can measure its current state, and a time scale depending on the dynamics of the system, called the Lyapunov time. Some examples of Lyapunov times are: chaotic electrical circuits, about 1 millisecond; weather systems, a few days (unproven); the solar system, 50 million years. In chaotic systems, the uncertainty in a forecast increases exponentially with elapsed time. Hence, mathematically, doubling the forecast time more than squares the proportional uncertainty in the forecast. This means, in practice, a meaningful prediction cannot be made over an interval of more than two or three times the Lyapunov time. When meaningful predictions cannot be made, the system appears random.\n\nIn common usage, \"chaos\" means \"a state of disorder\". However, in chaos theory, the term is defined more precisely. Although no universally accepted mathematical definition of chaos exists, a commonly used definition originally formulated by Robert L. Devaney says that, to classify a dynamical system as chaotic, it must have these properties:\n\n\nIn some cases, the last two properties in the above have been shown to actually imply sensitivity to initial conditions. In these cases, while it is often the most practically significant property, \"sensitivity to initial conditions\" need not be stated in the definition.\n\nIf attention is restricted to intervals, the second property implies the other two. An alternative, and in general weaker, definition of chaos uses only the first two properties in the above list.\n\nSensitivity to initial conditions means that each point in a chaotic system is arbitrarily closely approximated by other points with significantly different future paths, or trajectories. Thus, an arbitrarily small change, or perturbation, of the current trajectory may lead to significantly different future behavior.\n\nSensitivity to initial conditions is popularly known as the \"butterfly effect\", so-called because of the title of a paper given by Edward Lorenz in 1972 to the American Association for the Advancement of Science in Washington, D.C., entitled \"Predictability: Does the Flap of a Butterfly's Wings in Brazil set off a Tornado in Texas?\". The flapping wing represents a small change in the initial condition of the system, which causes a chain of events leading to large-scale phenomena. Had the butterfly not flapped its wings, the trajectory of the system might have been vastly different.\n\nA consequence of sensitivity to initial conditions is that if we start with only a finite amount of information about the system (as is usually the case in practice), then beyond a certain time the system is no longer predictable. This is most familiar in the case of weather, which is generally predictable only about a week ahead. Of course, this does not mean that we cannot say anything about events far in the future; some restrictions on the system are present. With weather, we know that the temperature will never naturally reach 100 °C or fall to -130 °C on earth, but we can't say exactly what day will have the hottest temperature of the year.\n\nIn more mathematical terms, the Lyapunov exponent measures the sensitivity to initial conditions. Given two starting trajectories in the phase space that are infinitesimally close, with initial separation formula_1, the two trajectories end up diverging at a rate given by\n\nwhere t is the time and λ is the Lyapunov exponent. The rate of separation depends on the orientation of the initial separation vector, so a whole spectrum of Lyapunov exponents exist. The number of Lyapunov exponents is equal to the number of dimensions of the phase space, though it is common to just refer to the largest one. For example, the maximal Lyapunov exponent (MLE) is most often used because it determines the overall predictability of the system. A positive MLE is usually taken as an indication that the system is chaotic.\n\nAlso, other properties relate to sensitivity of initial conditions, such as measure-theoretical mixing (as discussed in ergodic theory) and properties of a K-system.\n\nTopological mixing (or topological transitivity) means that the system evolves over time so that any given region or open set of its phase space eventually overlaps with any other given region. This mathematical concept of \"mixing\" corresponds to the standard intuition, and the mixing of colored dyes or fluids is an example of a chaotic system.\n\nTopological mixing is often omitted from popular accounts of chaos, which equate chaos with only sensitivity to initial conditions. However, sensitive dependence on initial conditions alone does not give chaos. For example, consider the simple dynamical system produced by repeatedly doubling an initial value. This system has sensitive dependence on initial conditions everywhere, since any pair of nearby points eventually becomes widely separated. However, this example has no topological mixing, and therefore has no chaos. Indeed, it has extremely simple behavior: all points except 0 tend to positive or negative infinity.\n\nFor a chaotic system to have dense periodic orbits means that every point in the space is approached arbitrarily closely by periodic orbits. The one-dimensional logistic map defined by \"x\" → 4 \"x\" (1 – \"x\") is one of the simplest systems with density of periodic orbits. For example, formula_3 → formula_4 → formula_3 (or approximately 0.3454915 → 0.9045085 → 0.3454915) is an (unstable) orbit of period 2, and similar orbits exist for periods 4, 8, 16, etc. (indeed, for all the periods specified by Sharkovskii's theorem).\n\nSharkovskii's theorem is the basis of the Li and Yorke (1975) proof that any one-dimensional system that exhibits a regular cycle of period three will also display regular cycles of every other length, as well as completely chaotic orbits.\n\nSome dynamical systems, like the one-dimensional logistic map defined by \"x\" → 4 \"x\" (1 – \"x\"), are chaotic everywhere, but in many cases chaotic behavior is found only in a subset of phase space. The cases of most interest arise when the chaotic behavior takes place on an attractor, since then a large set of initial conditions leads to orbits that converge to this chaotic region.\n\nAn easy way to visualize a chaotic attractor is to start with a point in the basin of attraction of the attractor, and then simply plot its subsequent orbit. Because of the topological transitivity condition, this is likely to produce a picture of the entire final attractor, and indeed both orbits shown in the figure on the right give a picture of the general shape of the Lorenz attractor. This attractor results from a simple three-dimensional model of the Lorenz weather system. The Lorenz attractor is perhaps one of the best-known chaotic system diagrams, probably because it was not only one of the first, but it is also one of the most complex and as such gives rise to a very interesting pattern, that with a little imagination, looks like the wings of a butterfly.\n\nUnlike fixed-point attractors and limit cycles, the attractors that arise from chaotic systems, known as strange attractors, have great detail and complexity. Strange attractors occur in both continuous dynamical systems (such as the Lorenz system) and in some discrete systems (such as the Hénon map). Other discrete dynamical systems have a repelling structure called a Julia set, which forms at the boundary between basins of attraction of fixed points. Julia sets can be thought of as strange repellers. Both strange attractors and Julia sets typically have a fractal structure, and the fractal dimension can be calculated for them.\n\nDiscrete chaotic systems, such as the logistic map, can exhibit strange attractors whatever their dimensionality. In contrast, for continuous dynamical systems, the Poincaré–Bendixson theorem shows that a strange attractor can only arise in three or more dimensions. Finite-dimensional linear systems are never chaotic; for a dynamical system to display chaotic behavior, it must be either nonlinear or infinite-dimensional.\n\nThe Poincaré–Bendixson theorem states that a two-dimensional differential equation has very regular behavior. The Lorenz attractor discussed above is generated by a system of three differential equations such as:\nwhere formula_7, formula_8, and formula_9 make up the system state, formula_10 is time, and formula_11, formula_12, formula_13 are the system parameters. Five of the terms on the right hand side are linear, while two are quadratic; a total of seven terms. Another well-known chaotic attractor is generated by the Rössler equations, which have only one nonlinear term out of seven. Sprott found a three-dimensional system with just five terms, that had only one nonlinear term, which exhibits chaos for certain parameter values. Zhang and Heidel showed that, at least for dissipative and conservative quadratic systems, three-dimensional quadratic systems with only three or four terms on the right-hand side cannot exhibit chaotic behavior. The reason is, simply put, that solutions to such systems are asymptotic to a two-dimensional surface and therefore solutions are well behaved.\n\nWhile the Poincaré–Bendixson theorem shows that a continuous dynamical system on the Euclidean plane cannot be chaotic, two-dimensional continuous systems with non-Euclidean geometry can exhibit chaotic behavior. Perhaps surprisingly, chaos may occur also in linear systems, provided they are infinite dimensional. A theory of linear chaos is being developed in a branch of mathematical analysis known as functional analysis.\n\nIn physics, jerk is the third derivative of position, with respect to time. As such, differential equations of the form\nare sometimes called \"Jerk equations\". It has been shown, that a jerk equation, which is equivalent to a system of three first order, ordinary, non-linear differential equations is in a certain sense the minimal setting for solutions showing chaotic behaviour. This motivates mathematical interest in jerk systems. Systems involving a fourth or higher derivative are called accordingly hyperjerk systems.\n\nA jerk system's behavior is described by a jerk equation, and for certain jerk equations, simple electronic circuits can model solutions. These circuits are known as jerk circuits.\n\nOne of the most interesting properties of jerk circuits is the possibility of chaotic behavior. In fact, certain well-known chaotic systems, such as the Lorenz attractor and the Rössler map, are conventionally described as a system of three first-order differential equations that can combine into a single (although rather complicated) jerk equation. Nonlinear jerk systems are in a sense minimally complex systems to show chaotic behaviour, there is no chaotic system involving only two first-order, ordinary differential equations (the system resulting in an equation of second order only).\n\nAn example of a jerk equation with nonlinearity in the magnitude of formula_7 is:\n\nHere, \"A\" is an adjustable parameter. This equation has a chaotic solution for \"A\"=3/5 and can be implemented with the following jerk circuit; the required nonlinearity is brought about by the two diodes:\n\nIn the above circuit, all resistors are of equal value, except formula_17, and all capacitors are of equal size. The dominant frequency is formula_18. The output of op amp 0 will correspond to the x variable, the output of 1 corresponds to the first derivative of x and the output of 2 corresponds to the second derivative.\n\nUnder the right conditions, chaos spontaneously evolves into a lockstep pattern. In the Kuramoto model, four conditions suffice to produce synchronization in a chaotic system.\nExamples include the coupled oscillation of Christiaan Huygens' pendulums, fireflies, neurons, the London Millennium Bridge resonance, and large arrays of Josephson junctions.\n\nAn early proponent of chaos theory was Henri Poincaré. In the 1880s, while studying the three-body problem, he found that there can be orbits that are nonperiodic, and yet not forever increasing nor approaching a fixed point. In 1898 Jacques Hadamard published an influential study of the chaotic motion of a free particle gliding frictionlessly on a surface of constant negative curvature, called \"Hadamard's billiards\". Hadamard was able to show that all trajectories are unstable, in that all particle trajectories diverge exponentially from one another, with a positive Lyapunov exponent.\n\nChaos theory got its start in the field of ergodic theory. Later studies, also on the topic of nonlinear differential equations, were carried out by George David Birkhoff, Andrey Nikolaevich Kolmogorov, Mary Lucy Cartwright and John Edensor Littlewood, and Stephen Smale. Except for Smale, these studies were all directly inspired by physics: the three-body problem in the case of Birkhoff, turbulence and astronomical problems in the case of Kolmogorov, and radio engineering in the case of Cartwright and Littlewood. Although chaotic planetary motion had not been observed, experimentalists had encountered turbulence in fluid motion and nonperiodic oscillation in radio circuits without the benefit of a theory to explain what they were seeing.\n\nDespite initial insights in the first half of the twentieth century, chaos theory became formalized as such only after mid-century, when it first became evident to some scientists that linear theory, the prevailing system theory at that time, simply could not explain the observed behavior of certain experiments like that of the logistic map. What had been attributed to measure imprecision and simple \"noise\" was considered by chaos theorists as a full component of the studied systems.\n\nThe main catalyst for the development of chaos theory was the electronic computer. Much of the mathematics of chaos theory involves the repeated iteration of simple mathematical formulas, which would be impractical to do by hand. Electronic computers made these repeated calculations practical, while figures and images made it possible to visualize these systems. As a graduate student in Chihiro Hayashi's laboratory at Kyoto University, Yoshisuke Ueda was experimenting with analog computers and noticed, on November 27, 1961, what he called \"randomly transitional phenomena\". Yet his advisor did not agree with his conclusions at the time, and did not allow him to report his findings until 1970.\n\nEdward Lorenz was an early pioneer of the theory. His interest in chaos came about accidentally through his work on weather prediction in 1961. Lorenz was using a simple digital computer, a Royal McBee LGP-30, to run his weather simulation. He wanted to see a sequence of data again, and to save time he started the simulation in the middle of its course. He did this by entering a printout of the data that corresponded to conditions in the middle of the original simulation. To his surprise, the weather the machine began to predict was completely different from the previous calculation. Lorenz tracked this down to the computer printout. The computer worked with 6-digit precision, but the printout rounded variables off to a 3-digit number, so a value like 0.506127 printed as 0.506. This difference is tiny, and the consensus at the time would have been that it should have no practical effect. However, Lorenz discovered that small changes in initial conditions produced large changes in long-term outcome. Lorenz's discovery, which gave its name to Lorenz attractors, showed that even detailed atmospheric modelling cannot, in general, make precise long-term weather predictions.\n\nIn 1963, Benoit Mandelbrot found recurring patterns at every scale in data on cotton prices. Beforehand he had studied information theory and concluded noise was patterned like a Cantor set: on any scale the proportion of noise-containing periods to error-free periods was a constant – thus errors were inevitable and must be planned for by incorporating redundancy. Mandelbrot described both the \"Noah effect\" (in which sudden discontinuous changes can occur) and the \"Joseph effect\" (in which persistence of a value can occur for a while, yet suddenly change afterwards). This challenged the idea that changes in price were normally distributed. In 1967, he published \"How long is the coast of Britain? Statistical self-similarity and fractional dimension\", showing that a coastline's length varies with the scale of the measuring instrument, resembles itself at all scales, and is infinite in length for an infinitesimally small measuring device. Arguing that a ball of twine appears as a point when viewed from far away (0-dimensional), a ball when viewed from fairly near (3-dimensional), or a curved strand (1-dimensional), he argued that the dimensions of an object are relative to the observer and may be fractional. An object whose irregularity is constant over different scales (\"self-similarity\") is a fractal (examples include the Menger sponge, the Sierpiński gasket, and the Koch curve or \"snowflake\", which is infinitely long yet encloses a finite space and has a fractal dimension of circa 1.2619). In 1982 Mandelbrot published \"The Fractal Geometry of Nature\", which became a classic of chaos theory. Biological systems such as the branching of the circulatory and bronchial systems proved to fit a fractal model.\n\nIn December 1977, the New York Academy of Sciences organized the first symposium on Chaos, attended by David Ruelle, Robert May, James A. Yorke (coiner of the term \"chaos\" as used in mathematics), Robert Shaw, and the meteorologist Edward Lorenz. The following year, independently Pierre Coullet and Charles Tresser with the article \"Iterations d'endomorphismes et groupe de renormalisation\" and Mitchell Feigenbaum with the article \"Quantitative Universality for a Class of Nonlinear Transformations\" described logistic maps. They notably discovered the universality in chaos, permitting the application of chaos theory to many different phenomena.\n\nIn 1979, Albert J. Libchaber, during a symposium organized in Aspen by Pierre Hohenberg, presented his experimental observation of the bifurcation cascade that leads to chaos and turbulence in Rayleigh–Bénard convection systems. He was awarded the Wolf Prize in Physics in 1986 along with Mitchell J. Feigenbaum for their inspiring achievements.\n\nIn 1986, the New York Academy of Sciences co-organized with the National Institute of Mental Health and the Office of Naval Research the first important conference on chaos in biology and medicine. There, Bernardo Huberman presented a mathematical model of the eye tracking disorder among schizophrenics. This led to a renewal of physiology in the 1980s through the application of chaos theory, for example, in the study of pathological cardiac cycles.\n\nIn 1987, Per Bak, Chao Tang and Kurt Wiesenfeld published a paper in \"Physical Review Letters\" describing for the first time self-organized criticality (SOC), considered one of the mechanisms by which complexity arises in nature.\n\nAlongside largely lab-based approaches such as the Bak–Tang–Wiesenfeld sandpile, many other investigations have focused on large-scale natural or social systems that are known (or suspected) to display scale-invariant behavior. Although these approaches were not always welcomed (at least initially) by specialists in the subjects examined, SOC has nevertheless become established as a strong candidate for explaining a number of natural phenomena, including earthquakes, (which, long before SOC was discovered, were known as a source of scale-invariant behavior such as the Gutenberg–Richter law describing the statistical distribution of earthquake sizes, and the Omori law describing the frequency of aftershocks), solar flares, fluctuations in economic systems such as financial markets (references to SOC are common in econophysics), landscape formation, forest fires, landslides, epidemics, and biological evolution (where SOC has been invoked, for example, as the dynamical mechanism behind the theory of \"punctuated equilibria\" put forward by Niles Eldredge and Stephen Jay Gould). Given the implications of a scale-free distribution of event sizes, some researchers have suggested that another phenomenon that should be considered an example of SOC is the occurrence of wars. These investigations of SOC have included both attempts at modelling (either developing new models or adapting existing ones to the specifics of a given natural system), and extensive data analysis to determine the existence and/or characteristics of natural scaling laws.\n\nIn the same year, James Gleick published \"\", which became a best-seller and introduced the general principles of chaos theory as well as its history to the broad public, though his history under-emphasized important Soviet contributions. Initially the domain of a few, isolated individuals, chaos theory progressively emerged as a transdisciplinary and institutional discipline, mainly under the name of nonlinear systems analysis. Alluding to Thomas Kuhn's concept of a paradigm shift exposed in \"The Structure of Scientific Revolutions\" (1962), many \"chaologists\" (as some described themselves) claimed that this new theory was an example of such a shift, a thesis upheld by Gleick.\n\nThe availability of cheaper, more powerful computers broadens the applicability of chaos theory. Currently, chaos theory remains an active area of research, involving many different disciplines (mathematics, topology, physics, social systems, population modeling, biology, meteorology, astrophysics, information theory, computational neuroscience, etc.).\n\nChaos theory was born from observing weather patterns, but it has become applicable to a variety of other situations. Some areas benefiting from chaos theory today are geology, mathematics, microbiology, biology, computer science, economics, engineering, finance, algorithmic trading, meteorology, philosophy, physics, politics, population dynamics, psychology, and robotics. A few categories are listed below with examples, but this is by no means a comprehensive list as new applications are appearing.\n\nChaos theory is not new to computer science and has been used for many years in cryptography. One type of encryption, secret key or symmetric key, relies on diffusion and confusion, which is modeled well by chaos theory. Another type of computing, DNA computing, when paired with chaos theory, offers a more efficient way to encrypt images and other information. Robotics is another area that has recently benefited from chaos theory. Instead of robots acting in a trial-and-error type of refinement to interact with their environment, chaos theory has been used to build a predictive model.\nChaotic dynamics have been exhibited by passive walking biped robots.\n\nFor over a hundred years, biologists have been keeping track of populations of different species with population models. Most models are continuous, but recently scientists have been able to implement chaotic models in certain populations. For example, a study on models of Canadian lynx showed there was chaotic behavior in the population growth. Chaos can also be found in ecological systems, such as hydrology. While a chaotic model for hydrology has its shortcomings, there is still much to learn from looking at the data through the lens of chaos theory. Another biological application is found in cardiotocography. Fetal surveillance is a delicate balance of obtaining accurate information while being as noninvasive as possible. Better models of warning signs of fetal hypoxia can be obtained through chaotic modeling.\n\nIn chemistry, predicting gas solubility is essential to manufacturing polymers, but models using particle swarm optimization (PSO) tend to converge to the wrong points. An improved version of PSO has been created by introducing chaos, which keeps the simulations from getting stuck. In celestial mechanics, especially when observing asteroids, applying chaos theory leads to better predictions about when these objects will approach Earth and other planets. Four of the five moons of Pluto rotate chaotically. In quantum physics and electrical engineering, the study of large arrays of Josephson junctions benefitted greatly from chaos theory. Closer to home, coal mines have always been dangerous places where frequent natural gas leaks cause many deaths. Until recently, there was no reliable way to predict when they would occur. But these gas leaks have chaotic tendencies that, when properly modeled, can be predicted fairly accurately.\n\nChaos theory can be applied outside of the natural sciences. By adapting a model of career counseling to include a chaotic interpretation of the relationship between employees and the job market, better suggestions can be made to people struggling with career decisions. Modern organizations are increasingly seen as open complex adaptive systems with fundamental natural nonlinear structures, subject to internal and external forces that may contribute chaos. The chaos metaphor—used in verbal theories—grounded on mathematical models and psychological aspects of human behavior\nprovides helpful insights to describing the complexity of small work groups, that go beyond the metaphor itself.\n\nIt is possible that economic models can also be improved through an application of chaos theory, but predicting the health of an economic system and what factors influence it most is an extremely complex task. Economic and financial systems are fundamentally different from those in the classical natural sciences since the former are inherently stochastic in nature, as they result from the interactions of people, and thus pure deterministic models are unlikely to provide accurate representations of the data. The empirical literature that tests for chaos in economics and finance presents very mixed results, in part due to confusion between specific tests for chaos and more general tests for non-linear relationships.\n\nTraffic forecasting also benefits from applications of chaos theory. Better predictions of when traffic will occur lets measures be taken to disperse it before it would have occurred. Combining chaos theory principles with a few other methods has led to a more accurate short-term prediction model (see the plot of the BML traffic model at right).\n\nChaos theory can be applied in psychology. For example, in modeling group behavior in which heterogeneous members may behave as if sharing to different degrees what in Wilfred Bion's theory is a basic assumption, the group dynamics is the result of the individual dynamics of the members: each individual reproduces the group dynamics in a different scale, and the chaotic behavior of the group is reflected in each member.\n\n\n\n\n\n\n\n\n\n", "id": "6295", "title": "Chaos theory"}
{"url": "https://en.wikipedia.org/wiki?curid=6298", "text": "Cupola\n\nIn architecture, a cupola is a small, most often dome-like, structure on top of a building. Often used to provide a lookout or to admit light and air, it usually crowns a larger roof or dome.\n\nThe word derives, via Italian, from the lower Latin \"cupula\" (classical Latin \"cupella\" from the Greek κύπελλον \"kupellon\") \"small cup\" (Latin \"cupa\") indicating a vault resembling an upside down cup.\nThe cupola is a development during the Renaissance of the oculus, an ancient device found in Roman architecture, but being weatherproof was superior for the wetter climates of northern Europe. The chhatri, seen in Indian architecture, fits the definition of a cupola when it is used atop a larger structure.\n\nCupolas often appear as small buildings in their own right. They often serve as a belfry, belvedere, or roof lantern above a main roof. In other cases they may crown a spire, tower, or turret.\n\nThe square, dome-like segment of a North American railroad train caboose that contains the second-level or \"angel\" seats is also called a cupola.\n\nSome armored fighting vehicles have cupolas, called commander's cupola, which is a raised dome or cylinder with armored glass to provide 360-degree vision around the vehicle.\n\n", "id": "6298", "title": "Cupola"}
{"url": "https://en.wikipedia.org/wiki?curid=6299", "text": "Chupacabra\n\nThe chupacabra or chupacabras (, literally \"goat-sucker\"; from \"\"chupar\"\", \"to suck\", and \"\"cabra\"\", \"goat\") is a legendary creature in the folklore of parts of the Americas, with its first purported sightings reported in Puerto Rico. The name comes from the animal's reported habit of attacking and drinking the blood of livestock, especially goats.\n\nPhysical descriptions of the creature vary. It is purportedly a heavy creature, the size of a small bear, with a row of spines reaching from the neck to the base of the tail.\n\nEyewitness sightings have been claimed as early as 1995 in Puerto Rico, and have since been reported as far north as Maine, and as far south as Chile, and even being spotted outside the Americas in countries like Russia and the Philippines, but many of the reports have been disregarded as uncorroborated or lacking evidence. Sightings in northern Mexico and the southern United States have been verified as canids afflicted by mange. According to biologists and wildlife management officials, the chupacabra is an urban legend.\n\n\"Chupacabras\" can be literally translated as \"goat-sucker\", from \"chupar\" (\"to suck\") and \"cabra\" (\"goat\"). It is known as both \"chupacabras\" and \"chupacabra\" throughout the Americas, with the former being the original word, and the latter a regularization of it. The name in Spanish can be preceded by a singular masculine article (\"el chupacabras\"), or the plural masculine article (\"los chupacabras\").\n\nThe first reported attacks occurred in March 1995 in Puerto Rico. In this attack, eight sheep were discovered dead, each with three puncture wounds in the chest area and completely drained of blood. A few months later, in August, an eyewitness, Madelyne Tolentino, reported seeing the creature in the Puerto Rican town of Canóvanas, when as many as 150 farm animals and pets were reportedly killed. In 1975, similar killings in the small town of Moca were attributed to \"El Vampiro de Moca\" (The Vampire of Moca). Initially, it was suspected that the killings were committed by a Satanic cult; later more killings were reported around the island, and many farms reported loss of animal life. Each of the animals was reported to have had its body bled dry through a series of small circular incisions.\n\nPuerto Rican comedian and entrepreneur Silverio Pérez is credited with coining the term \"chupacabras\" soon after the first incidents were reported in the press. Shortly after the first reported incidents in Puerto Rico, other animal deaths were reported in other countries, such as the Dominican Republic, Argentina, Bolivia, Chile, Colombia, Honduras, El Salvador, Nicaragua, Panama, Peru, Brazil, United States, and Mexico.\n\nA five-year investigation by Benjamin Radford, documented in his 2011 book \"Tracking the Chupacabra\", concluded that the description given by the original eyewitness in Puerto Rico, Madelyne Tolentino, was based on the creature Sil in the science-fiction horror film \"Species\". The alien creature Sil is nearly identical to Tolentino’s chupacabra eyewitness account and she had seen the movie before her report: \"It was a creature that looked like the chupacabra, with spines on its back and all... The resemblance to the chupacabra was really impressive,\" Tolentino reported. Radford revealed that Tolentino \"believed that the creatures and events she saw in \"Species\" were happening in reality in Puerto Rico at the time,\" and therefore concludes that \"the most important chupacabra description cannot be trusted.\" This, Radford believes, seriously undermines the credibility of the chupacabra as a real animal.\n\nIn addition, the reports of blood-sucking by the chupacabra were never confirmed by a necropsy, the only way to conclude that the animal was drained of blood. An analysis by a veterinarian of 300 reported victims of the chupacabra found that they had not been bled dry.\n\nRadford divided the chupacabra reports into two categories:\n\nIn late October 2010, University of Michigan biologist Barry O'Connor concluded that all the chupacabra reports in the United States were simply coyotes infected with the parasite \"Sarcoptes scabiei\", whose symptoms would explain most of the features of the chupacabra: they would be left with little fur, thickened skin, and rank odour. O'Connor theorized that the attacks on goats occurred \"because these animals are greatly weakened, they're going to have a hard time hunting. So they may be forced into attacking livestock because it's easier than running down a rabbit or a deer.\" \n\nAlthough several witnesses came to the conclusion that the attacks could not be the work of dogs or coyotes because they had not eaten the victim, this conclusion is incorrect. Both dogs and coyotes can kill and not consume the prey, either because they are inexperienced, or due to injury or difficulty in killing the prey. The prey can survive the attack and die afterwards from internal bleeding or circulatory shock. The presence of two holes in the neck, corresponding with the canine teeth, are to be expected since this is the only way that most land carnivores have to catch their prey.\n\nThere are reports of stray Mexican Hairless Dogs being mistaken for chupacabras.\n\nDuring the first year, more than 200 reports were made in Puerto Rico.\n\nIn July 2004, a rancher near San Antonio, Texas, killed a hairless dog-like creature which was attacking his livestock. This animal, initially given the name the Elmendorf Beast, was later determined by DNA assay conducted at the University of California, Davis to be a coyote with demodectic or sarcoptic mange. In October 2004, two more carcasses were found in the same area. Biologists in Texas examined samples from the two carcasses and determined they were also coyotes suffering from very severe cases of mange. In Coleman, Texas, a farmer named Reggie Lagow caught an animal in a trap he set up after the deaths of a number of his chickens and turkeys. The animal was described as resembling a mix of hairless dog, rat, and kangaroo. Lagow provided the animal to Texas Parks and Wildlife officials for identification, but Lagow reported in a September 17, 2006, phone interview with John Adolfi, founder of the Lost World Museum, that the \"critter was caught on a Tuesday and thrown out in Thursday's trash.\"\n\nIn April 2006, \"MosNews\" reported that the chupacabra was spotted in Russia for the first time. Reports from Central Russia beginning in March 2005 tell of a beast that kills animals and sucks out their blood. 32 turkeys were killed and drained overnight. Reports later came from neighboring villages when 30 sheep were killed and their blood was drained. Finally, eyewitnesses were able to describe the chupacabra. In May 2006, experts were determined to track the animal down. According to Russian paranormal researcher Vadim Chernobrov, the territory allegedly frequented by chupacabras lies in the Kharkiv region of Ukraine and neighboring regions of Russia, but also in parts of Belarus and Poland. Recently the reports appeared of chupacabra-like attacks in the Moscow region of Russia with dozens of birds and animals found bloodless, with strange incisions. At least twice the mysterious kangaroo-like creature (\"with a crocodile head\") attacked humans, causing no serious damage, though. According to Chernobrov, the two extraordinary things about the chupacabras' ways are that the thing leaves a 'vanishing' line of footprints, looking as if it takes off as a bird, and also it tends occasionally to assort its victim's bodies 'aesthetically', often by colour and size, or build pyramids with killed bodies.\n\nIn mid-August 2006, Michelle O'Donnell of Turner, Maine, described an \"evil looking\" rodent-like animal with fangs that had been found dead alongside a road. The animal was apparently struck by a car, and was unidentifiable. Photographs were taken and witness reports seem to be in relative agreement that the creature was canine in appearance, but in widely published photos seemed unlike any dog or wolf in the area. Photos from other angles seem to show a chow or akita mixed-breed dog. It was reported that \"the carcass was picked clean by vultures before experts could examine it\". For years, residents of Maine have reported a mysterious creature and a string of dog maulings.\n\nIn May 2007, a series of reports on national Colombia news reported more than 300 dead sheep in the region of Boyaca, and the capture of a possible specimen to be analyzed by zoologists at the National University of Colombia.\nIn August 2007, Phylis Canion found three animals in Cuero, Texas. She and her neighbors reported to have discovered three strange animal carcasses outside Canion's property. She took photographs of the carcasses and preserved the head of one in her freezer before turning it over for DNA analysis. Canion reported that nearly 30 chickens on her farm had been exsanguinated over a period of years, a factor which led her to connect the carcasses with the chupacabra legend. State Mammologist John Young estimated that the animal in Canion's pictures was a gray fox suffering from an extreme case of mange. In November 2007, biology researchers at Texas State University–San Marcos determined from DNA samples that the suspicious animal was a coyote. The coyote, however, had grayish-blue, mostly hairless skin and large fanged teeth, attributes which caused it to appear different from a normal coyote. Additional skin samples were taken to attempt to determine the cause of the hair loss.\n\nOn January 11, 2008, a sighting was reported at the province of Capiz in the Philippines. Some of the residents from the barangay believed that it was the chupacabra that killed eight chickens. The owner of the chickens saw a dog-like animal attacking his chickens.\n\nOn August 8, 2008, a DeWitt County deputy, Brandon Riedel, filmed an unidentifiable animal along back roads near Cuero, Texas, on his dashboard camera. The animal was about the size of a coyote but was hairless with a long snout, short front legs and long back legs. However, Reiter's boss, Sheriff Jode Zavesky, believes it may be the same species of coyote identified by Texas State University–San Marcos researchers in November 2007. The video footage was shown on an April 2011 episode of the Syfy television series \"\" where an investigative team tried to recreate the dashboard video footage using a miniature horse and a Mexican Hairless Dog (both of which were bred locally). Neither test animal matched the creature in the video. The team had also tested a DNA sample taken from an alleged carcass of one of the creatures found by a local rancher and later identified as being a hybrid wolf/coyote.\n\nIn September 2009, CNN aired a report showing closeup video footage of an unidentified dead animal. The same CNN report stated that locals have begun speculating the possibility that this might be a chupacabra. A Blanco, Texas, taxidermist reported that he received the body from a former student whose cousin had discovered the animal in his barn, where it had succumbed to poison left out for rodents. The taxidermist expressed his belief that this is a genetically mutated coyote.\n\nOn September 18, 2009, taxidermist Jerry Ayer sold the Blanco Texas Chupacabra to the Lost World Museum. The museum, as reported in the Syracuse Post Standard on September 26, 2009, is placing the creature on display as it works with an unnamed university to have the remains tested.\n\nIn July 2010, there were reports of chupacabras being shot dead by animal control officers in Hood County, Texas. A second creature was also reportedly spotted and killed several miles away. However, an officer of Hood County animal control said Texas A&M University scientists conducted tests and identified the corpse as a \"coyote-dog hybrid\" with signs of mange and internal parasites. The second reported chupacabra, shot July 9 about 8 miles south of Cresson, was eaten by vultures before it could be taken for testing.\n\nOn December 18, 2010, in Nelson County, Kentucky, Mark Cothren shot and killed an animal that he could not recognize and feared. Many pictures of the Chupacabra were taken and the story was well documented by various news organizations. Cothren described the creature as having large ears, whiskers, a long tail, and about the size of a house cat. Cothren says he spoke with the Kentucky Department of Fish and Wildlife Resources and handed over the preserved animal for further analysis.\n\nOn July 4, 2011, Jack (Jeff) Crabtree, of Lake Jackson, Texas, reported seeing a chupacabra in his back yard. At first, Crabtree stood firm on his original theory of the chupacabra, but after the local newspaper and several other media reporters wrote his story on July 11, he quickly backed down, agreeing with wildlife experts that it was most likely a coyote with mange. \"It was a spoof or a practical joke,\" Crabtree said. \"...I really didn't believe it.\" His story appeared on CNN, as well as MSNBC. On July 15, 2011, local authorities caught what Crabtree saw. Experts confirmed that the animal was definitely a coyote with mange.\n\nOn September 17, 2013, the Fox 2 News affiliate in Saint Louis, Missouri, posted on its website a report of two sightings. In the first, a woman spotted a \"small grey dog-like animal\" near the front gate of the Old Lake Hill Speedway in Saint Louis. A week previously, a hunter claimed to have killed a chupacabra while \"coon hunting\". The Mississippi Department of Wildlife said that it was a dog with mange.\n\nIn October 2013, WOWT News in Omaha reported that two Nebraska Department of Roads employees claimed to have spotted a chupacabra just outside Blair, Nebraska. The individuals took photos of the animal that they described as a “four-legged Dracula and a scrawny, scraggly thing.” The animal had no hair and looked skinny and weak. Later, the Director of Animal Health at the Henry Doorly Zoo in Omaha, Nebraska, identified the animal as a coyote.\n\nA Texan couple who reside on a ranch in Victoria County, Texas informed the media that they had shot and killed a chupacabra on their property during the evening of February 23, 2014. A wildlife biologist with the Texas Parks and Wildlife organization also spoke with the media and stated: \"I've seen squirrels, raccoons and coyotes in this area with the same features. They're [chupacabra] a mythical creature that most people see, but what it really is sarcoptic mange which is caused by a mite that bites the animal and it can be on any mammal - dogs, cats, coyotes foxes, and humans can get another version of it as well.\"\n\nOn April 3, 2014, a Texan couple claimed to have captured a chupacabra in Ratcliff, Texas on March 29, 2014 Livescience's Benjamin Radford suggested the animal is a raccoon suffering from sarcoptic mange.\n\nThe most common description of the chupacabra is that of a reptile-like creature, said to have leathery or scaly greenish-gray skin and sharp spines or quills running down its back. It is said to be approximately 3 to 4 feet (1 to 1.2 m) high, and stands and hops in a fashion similar to that of a kangaroo.\n\nAnother common description of the chupacabra is of a strange breed of wild dog. This form is mostly hairless and has a pronounced spinal ridge, unusually pronounced eye sockets, fangs, and claws. Unlike conventional predators, the chupacabra is said to drain all of the animal's blood (and sometimes organs) usually through three holes in the shape of an upside-down triangle or through one or two holes.\n\nA popular legend in New Orleans concerns a popular lovers' lane called Grunch Road, which was said to be inhabited by \"grunches\", creatures similar in appearance to the \"Chupacabra\".\n\nThe Peuchen of Chile also share similarities in their supposed habits, but instead of being dog-like they are described as winged snakes. This legend may have originated from the vampire bat, an animal endemic to the region.\n\nIn the Philippines, another legendary creature called the Sigbin shares many of the same descriptions as the \"Chupacabra\". The recent discovery of the cat-fox in Southeast Asia suggests that it could also have been simply sightings of this once unknown animal.\n\nThe popularity of the chupacabra has resulted in its being featured in many types of media.\n\n", "id": "6299", "title": "Chupacabra"}
{"url": "https://en.wikipedia.org/wiki?curid=6309", "text": "Cayuga Lake\n\nCayuga Lake ( or )  is the longest of central New York's glacial Finger Lakes, and is the second largest in surface area (marginally smaller than Seneca Lake) and second largest in volume. It is just under long. Its average width is 1.7 miles (2.7 km), and it is at its widest point near Aurora. It is approximately at its deepest point.\n\nThe city of Ithaca, site of Ithaca College and Cornell University, is located at the southern end of Cayuga Lake.\n\nVillages and settlements along the east shore of Cayuga Lake include Myers, King Ferry, Aurora, Levanna, Union Springs, and Cayuga. Settlements along the west shore of the lake include Sheldrake, Poplar Beach, and Canoga.\n\nThe lake has one small island near Union Springs, Frontenac Island. It is one of only two islands in the Finger Lakes, the other being Squaw Island in Canandaigua Lake.\n\nCayuga Lake is located at ; above sea level. Its depth, steep east and west sides with shallow north and south ends is typical of the Finger Lakes, as they were carved by glaciers during the last ice age.\n\nThe water level is regulated by the Mud Lock at the north end of the lake. It is connected to Lake Ontario by the Erie Canal and Seneca Lake by the Seneca River. The lake is drawn down as winter approaches, to minimize ice damage and to maximize its capacity to store heavy spring runoff.\n\nThe north end is dominated by shallow mudflats. An important stopover for migratory birds, the mudflats and marsh are the location of the Montezuma National Wildlife Refuge. The southern end is also shallow and often freezes during the winter.\n\nThe fish population is managed and substantial sport fishing is practiced, with anglers targeting smelt, lake trout and smallmouth bass.\n\nCayuga Lake is very popular among recreational boaters. The Allan H. Treman State Marine Park, a large state marina and boat launch, is located at the southern end of the lake in Ithaca. There are two yacht clubs on the western shore: Ithaca Yacht Club a few miles north of Ithaca, and Red Jacket Yacht Club just south of Canoga. There are several other marinas and boat launches scattered along the lake shore.\n\nCayuga Lake is the source of drinking water for several communities, including Lansing near the southern end of the lake along the east side, which draws water through the Bolton Point Municipal Water system. There are also several lake source cooling systems that are in operation on the lake, whereby cooler water is pumped from the depths of the lake, warmed, and circulated in a closed system back to the surface. One of these systems, which is operated by Cornell University and began operation in 2000, was controversial during the planning and building states for potential negative environmental impact. All the environmental impact reports and scientific studies have shown that the Cornell lake source cooling system has not yet had and will not likely have any measurably significant environmental impact. Furthermore, Cornell's system pumps significantly less warm water back into the lake than others further north which have been operating for decades, including the coal-fired power plant on the eastern shore.\nThe AES Cayuga electrical generating station operates in the Town of Lansing, on the east shore of Cayuga Lake. This coal-fired plant uses Cayuga Lake as a cooling source. In the late 1960s, citizens successfully opposed the construction of an 830-MW nuclear power plant on the shore of Cayuga Lake.\n\nRod Serling named his production company Cayuga Productions during the years of his TV series, \"The Twilight Zone\". Serling and his family had a summer home at Cayuga Lake.\n\nThe lake is the subject of local folklore. Cornell's alma mater makes reference to its position \"Far Above Cayuga's Waters\", while that of Ithaca College references \"Cayuga's shore\".\n\nA tradition at Wells College in Aurora holds that if the lake completely freezes over, classes are canceled (though for only one day). According to Wells College records, this most recently happened in 1979 and 2015. However, other sources suggest that the only time the entire lake froze over solid end to end in the 20th century was in 1912.\n\nCayuga Lake, like nearby Seneca Lake, is also the site of a phenomenon known as the Guns of the Seneca, mysterious cannon-like booms heard in the surrounding area. Many of these booms may be attributable to bird-scarers, automated cannon-like devices used by farmers to scare birds away from the many vineyards, orchards and crops. There is however no proof of this.\n\nCayuga Lake is included in the American Viticultural Area with which it shares its name. Established in 1988, the AVA now boasts over a dozen wineries, four distilleries, a cidery, and a meadery.\n\n\n", "id": "6309", "title": "Cayuga Lake"}
{"url": "https://en.wikipedia.org/wiki?curid=6310", "text": "Columbia University\n\nColumbia University (Columbia; officially Columbia University in the City of New York) is a private Ivy League research university in Upper Manhattan, New York City. It was established in 1754 as King's College by royal charter of George II of Great Britain. Columbia is the oldest college in the state of New York and the fifth chartered institution of higher learning in the country, making it one of nine colonial colleges founded before the Declaration of Independence. After the American Revolutionary War, King's College briefly became a state entity, and was renamed Columbia College in 1784. A 1787 charter placed the institution under a private board of trustees before it was renamed Columbia University in 1896 when the campus was moved from Madison Avenue to its current location in Morningside Heights occupying of land. Columbia is one of the fourteen founding members of the Association of American Universities and was the first school in the United States to grant the M.D. degree.\n\nThe university is organized into twenty schools, including Columbia College, the School of Engineering and Applied Science, and the School of General Studies, as well as Columbia Law School, Columbia College of Physicians and Surgeons, Teachers College, and Columbia Business School. The university also has global research outposts in Amman, Beijing, Istanbul, Paris, Mumbai, Rio de Janeiro, Santiago, Asunción and Nairobi. It has affiliations with several other institutions nearby, including Barnard College, and Union Theological Seminary, with joint undergraduate programs available through the Jewish Theological Seminary of America, University College London, Sciences Po, City University of Hong Kong, and the Juilliard School.\n\nThe university has graduated many notable alumni. Alumni and affliates include 5 Founding Fathers of the United States - amongst these an author of the Declaration of Independence and an author of the United States Constitution; 10 Justices of the United States Supreme Court; 20 living billionaires; 123 Pulitzer Prize winners; 39 Academy Award winners; 3 United States Presidents; 29 heads of state; 99 Nobel laureates; 77 National Medal of Science winners; 23 National Humanities Medal recipients. Columbia is second only to Harvard University in the number of Nobel Prize-winning affiliates, with over 100 recipients of the award as of 2017.Columbia administers annually the Pulitzer Prize.\n\nDiscussions regarding the founding of a college in the Province of New York began as early as 1704, at which time Colonel Lewis Morris wrote to the Society for the Propagation of the Gospel in Foreign Parts, the missionary arm of the Church of England, persuading the society that New York City was an ideal community in which to establish a college; however, not until the founding of Princeton University across the Hudson River in New Jersey did the City of New York seriously consider founding a college. In 1746 an act was passed by the general assembly of New York to raise funds for the foundation of a new college. In 1751, the assembly appointed a commission of ten New York residents, seven of whom were members of the Church of England, to direct the funds accrued by the state lottery towards the foundation of a college.\n\nClasses were initially held in July 1754 and were presided over by the college's first president, Dr. Samuel Johnson. Dr. Johnson was the only instructor of the college's first class, which consisted of a mere eight students. Instruction was held in a new schoolhouse adjoining Trinity Church, located on what is now lower Broadway in Manhattan. The college was officially founded on October 31, 1754, as King's College by royal charter of King George II, making it the oldest institution of higher learning in the state of New York and the fifth oldest in the United States.\n\nIn 1763, Dr. Johnson was succeeded in the presidency by Myles Cooper, a graduate of The Queen's College, Oxford, and an ardent Tory. In the charged political climate of the American Revolution, his chief opponent in discussions at the college was an undergraduate of the class of 1777, Alexander Hamilton. The American Revolutionary War broke out in 1776, and was catastrophic for the operation of King's College, which suspended instruction for eight years beginning in 1776 with the arrival of the Continental Army. The suspension continued through the military occupation of New York City by British troops until their departure in 1783. The college's library was looted and its sole building requisitioned for use as a military hospital first by American and then British forces. Loyalists were forced to abandon their King's College in New York, which was seized by the rebels and renamed Columbia College. The Loyalists, led by Bishop Charles Inglis fled to Windsor, Nova Scotia, where they founded King's Collegiate School.\n\nAfter the Revolution, the college turned to the State of New York in order to restore its vitality, promising to make whatever changes to the school's charter the state might demand. The Legislature agreed to assist the college, and on May 1, 1784, it passed \"an Act for granting certain privileges to the College heretofore called King's College.\" The Act created a Board of Regents to oversee the resuscitation of King's College, and, in an effort to demonstrate its support for the new Republic, the Legislature stipulated that \"the College within the City of New York heretofore called King's College be forever hereafter called and known by the name of Columbia College,\" a reference to Columbia, an alternative name for America. The Regents finally became aware of the college's defective constitution in February 1787 and appointed a revision committee, which was headed by John Jay and Alexander Hamilton. In April of that same year, a new charter was adopted for the college, still in use today, granting power to a private board of 24 Trustees.\n\nOn May 21, 1787, William Samuel Johnson, the son of Dr. Samuel Johnson, was unanimously elected President of Columbia College. Prior to serving at the university, Johnson had participated in the First Continental Congress and been chosen as a delegate to the Constitutional Convention. For a period in the 1790s, with New York City as the federal and state capital and the country under successive Federalist governments, a revived Columbia thrived under the auspices of Federalists such as Hamilton and Jay. Both President George Washington and Vice President John Adams attended the college's commencement on May 6, 1789, as a tribute of honor to the many alumni of the school who had been involved in the American Revolution.\n\nIn November 1813, the College agreed to incorporate its medical school with The College of Physicians and Surgeons, a new school created by the Regents of New York, forming Columbia University College of Physicians and Surgeons. The college's enrollment, structure, and academics stagnated for the majority of the 19th century, with many of the college presidents doing little to change the way that the college functioned. In 1857, the college moved from the King's College campus at Park Place to a primarily Gothic Revival campus on 49th Street and Madison Avenue, where it remained for the next forty years. During the last half of the 19th century, under the leadership of President F.A.P. Barnard, the institution rapidly assumed the shape of a modern university. By this time, the college's investments in New York real estate became a primary source of steady income for the school, mainly owing to the city's expanding population. University president Seth Low moved the campus from 49th Street to its present location, a more spacious campus in the developing neighborhood of Morningside Heights. Under the leadership of Low's successor, Nicholas Murray Butler, who served for over four decades, Columbia rapidly became the nation's major institution for research, setting the \"multiversity\" model that later universities would adopt. Prior to becoming the president of Columbia University, Butler founded Teachers College, as a school to prepare home economists and manual art teachers for the children of the poor, with philanthropist Grace Hoadley Dodge. Teachers College came under the aegis of Columbia University in 1893 and became the University's Graduate School of Education.\n\nResearch into the atom by faculty members John R. Dunning, I. I. Rabi, Enrico Fermi and Polykarp Kusch placed Columbia's Physics Department in the international spotlight in the 1940s after the first nuclear pile was built to start what became the Manhattan Project. In 1928, Seth Low Junior College was established by Columbia University in order to mitigate the number of Jewish applicants to Columbia College. The college was closed in 1938 due to the adverse effects of the Great Depression and its students were subsequently absorbed into University Extension. In 1947, the program was reorganized as an undergraduate college and designated the School of General Studies in response to the return of GIs after World War II. In 1995, the School of General Studies was again reorganized as a full-fledged liberal arts college for non-traditional students (those who have had an academic break of one year or more, or are pursuing dual-degrees) and was fully integrated into Columbia's traditional undergraduate curriculum. Within the same year, the Division of Special Programs—later the School of Continuing Education, and now the School of Professional Studies—was established to reprise the former role of University Extension. While the School of Professional Studies only offered non-degree programs for lifelong learners and high school students in its earliest stages, it now offers degree programs in a diverse range of professional and inter-disciplinary fields.\n\nIn the aftermath of World War II, the discipline of international relations became a major scholarly focus of the University, and in response, the School of International and Public Affairs was founded in 1946, drawing upon the resources of the faculties of political science, economics, and history.\n\nDuring the 1960s Columbia experienced large-scale student activism, which reached a climax in the spring of 1968 when hundreds of students occupied buildings on campus. The incident forced the resignation of Columbia's President, Grayson Kirk and the establishment of the University Senate.\n\nThough several schools within the university had admitted women for years, Columbia College first admitted women in the fall of 1983, after a decade of failed negotiations with Barnard College, the all-female institution affiliated with the university, to merge the two schools. Barnard College still remains affiliated with Columbia, and all Barnard graduates are issued diplomas authorized by both Columbia University and Barnard College.\n\nDuring the late 20th century, the University underwent significant academic, structural, and administrative changes as it developed into a major research university. For much of the 19th century, the University consisted of decentralized and separate faculties specializing in Political Science, Philosophy, and Pure Science. In 1979, these faculties were merged into the Graduate School of Arts and Sciences. In the 1970s, Teachers College's departments ran joint Ph.D programs with the University including psychology, history, and anthropology and all Teachers College diplomas were conferred by Columbia University. Teachers College was soon established as the University's Faculty of Education and Department of Education. In 1991, the faculties of Columbia College, the School of General Studies, the Graduate School of Arts and Sciences, the School of the Arts, and the School of Professional Studies were merged into the Faculty of Arts and Sciences, leading to the academic integration and centralized governance of these schools. In 2010, the School of International and Public Affairs, which was previously a part of the Faculty of Arts and Sciences, became an independent faculty.\n\nAlong with NYU and the Catholic Church, Columbia University is one of the top 3 largest landowners in New York City.\n\nThe majority of Columbia's graduate and undergraduate studies are conducted in Morningside Heights on Seth Low's late-19th century vision of a university campus where all disciplines could be taught at one location. The campus was designed along Beaux-Arts principles by architects McKim, Mead, and White. Columbia's main campus occupies more than six city blocks, or , in Morningside Heights, New York City, a neighborhood that contains a number of academic institutions. The university owns over 7,800 apartments in Morningside Heights, housing faculty, graduate students, and staff. Almost two dozen undergraduate dormitories (purpose-built or converted) are located on campus or in Morningside Heights. Columbia University has an extensive underground tunnel system more than a century old, with the oldest portions predating the present campus. Some of these remain accessible to the public, while others have been cordoned off.\n\nThe Nicholas Murray Butler Library, commonly known simply as Butler Library, is the largest single library in the Columbia University Library System, and is one of the largest buildings on the campus. Proposed as \"South Hall\" by the university's former President Nicholas Murray Butler as expansion plans for Low Memorial Library stalled, the new library was funded by Edward Harkness, benefactor of Yale's residential college system, and designed by his favorite architect, James Gamble Rogers. It was completed in 1934 and renamed for Butler in 1946. The library design is neo-classical in style. Its facade features an arcade of columns in the Ionic order above which are inscribed the names of great writers, philosophers, and thinkers, most of whom are read by students engaged in the Core Curriculum of Columbia College. As of 2012, Columbia's library system includes over 11.9  million volumes, making it the eighth largest library system and fifth largest collegiate library system in the United States. It has also been ranked among the United States' most beautiful libraries.\n\nSeveral buildings on the Morningside Heights campus are listed on the National Register of Historic Places. Low Memorial Library, a National Historic Landmark and the centerpiece of the campus, is listed for its architectural significance. Philosophy Hall is listed as the site of the invention of FM radio. Also listed is Pupin Hall, another National Historic Landmark, which houses the physics and astronomy departments. Here the first experiments on the fission of uranium were conducted by Enrico Fermi. The uranium atom was split there ten days after the world's first atom-splitting in Copenhagen, Denmark.\n\nA statue by sculptor Daniel Chester French called \"Alma Mater\" is centered on the front steps of Low Memorial Library. McKim, Mead & White invited French to build the sculpture in order to harmonize with the larger composition of the court and library in the center of the campus. Draped in an academic gown, the female figure of Alma Mater wears a crown of laurels and sits on a throne. The scroll-like arms of the throne end in lamps, representing sapientia and doctrina. A book signifying knowledge, balances on her lap, and an owl, the attribute of wisdom, is hidden in the folds of her gown. Her right hand holds a scepter composed of four sprays of wheat, terminating with a crown of King's College which refers to Columbia's origin as a Royalist institution in 1754. A local actress named Mary Lawton was said to have posed for parts of the sculpture. The statue was dedicated on September 23, 1903, as a gift of Mr. & Mrs. Robert Goelet, and was originally covered in golden leaf. During the Columbia University protests of 1968 a bomb damaged the sculpture, but it has since been repaired. The small hidden owl on the sculpture is also the subject of many Columbia legends, the main legend being that the first student in the freshmen class to find the hidden owl on the statue will be valedictorian, and that any subsequent Columbia male who finds it will marry a Barnard student, given that Barnard is a women's college.\n\n\"The Steps\", alternatively known as \"Low Steps\" or the \"Urban Beach\", are a popular meeting area for Columbia students. The term refers to the long series of granite steps leading from the lower part of campus (South Field) to its upper terrace. With a design inspired by the City Beautiful movement, the steps of Low Library provides Columbia University and Barnard College students, faculty, and staff with a comfortable outdoor platform and space for informal gatherings, events, and ceremonies. McKim's classical facade epitomizes late 19th century new-classical designs, with its columns and portico marking the entrance to an important structure. On warm days when the weather is favorable, the Low Steps often become a popular gathering place for students to sunbathe, eat lunch, or play frisbee.\n\nIn April 2007, the university purchased more than two-thirds of a site for a new campus in Manhattanville, an industrial neighborhood to the north of the Morningside Heights campus. Stretching from 125th Street to 133rd Street, the new campus will house buildings for Columbia's Business School, School of International and Public Affairs, and the Jerome L. Greene Center for Mind, Brain, and Behavior, where research will occur on neurodegenerative diseases such as Parkinson's and Alzheimer's. The $7 billion expansion plan includes demolishing all buildings, except three that are historically significant, eliminating the existing light industry and storage warehouses, and relocating tenants in 132 apartments. Replacing these buildings will be of space for the university. Community activist groups in West Harlem fought the expansion for reasons ranging from property protection and fair exchange for land, to residents' rights. Subsequent public hearings drew neighborhood opposition. Most recently, as of December 2008, the State of New York's Empire State Development Corporation approved use of eminent domain, which, through declaration of Manhattanville's \"blighted\" status, gives governmental bodies the right to appropriate private property for public use. On May 20, 2009, the New York State Public Authorities Control Board approved the Manhanttanville expansion plan and the first buildings are under construction.\n\nNew York-Presbyterian Hospital is affiliated with the medical schools of both Columbia University and Cornell University. According to \"U.S. News & World Report\"'s \"America's Best Hospitals 2009\", it is ranked sixth overall and third among university hospitals. Columbia's medical school has a strategic partnership with New York State Psychiatric Institute, and is affiliated with 19 other hospitals in the U.S. and four hospitals overseas. Health-related schools are located at the Columbia University Medical Center, a campus located in the neighborhood of Washington Heights, fifty blocks uptown. Other teaching hospitals affiliated with Columbia through the New York-Presbyterian network include the Payne Whitney Clinic in Manhattan, and the Payne Whitney Westchester, a psychiatric institute located in White Plains, New York. On the northern tip of Manhattan island (in the neighborhood of Inwood), Columbia owns Baker Field, which includes the Lawrence A. Wien Stadium as well as facilities for field sports, outdoor track, and tennis. There is a third campus on the west bank of the Hudson River, the Lamont-Doherty Earth Observatory and Earth Institute in Palisades, New York. A fourth is the Nevis Laboratories in Irvington, New York for the study of particle and motion physics. A satellite site in Paris, France holds classes at Reid Hall.\n\nIn 2006, the university established the Office of Environmental Stewardship to initiate, coordinate and implement programs to reduce the university's environmental footprint. The U.S. Green Building Council selected the university's Manhattanville plan for the Leadership in Energy and Environmental Design (LEED) Neighborhood Design pilot program. The plan commits to incorporating smart growth, new urbanism and \"green\" building design principles. Columbia is one of the 2030 Challenge Partners, a group of nine universities in the city of New York that have pledged to reduce their greenhouse emissions by 30% within the next ten years. Columbia University adopts LEED standards for all new construction and major renovations. The University requires a minimum of Silver, but through its design and review process seeks to achieve higher levels. This is especially challenging for lab and research buildings with their intensive energy use; however, the university also uses lab design guidelines that seek to maximize energy efficiency while protecting the safety of researchers.\n\nEvery Thursday and Sunday of the month, Columbia hosts a greenmarket where local farmers can sell their produce to residents of the city. In addition, from April to November Hodgson's farm, a local New York gardening center, joins the market bringing a large selection of plants and blooming flowers. The market is one of the many operated at different points throughout the city by the non-profit group GrowNYC. Dining services at Columbia spends 36 percent of its food budget on local products, in addition to serving sustainably harvested seafood and fair trade coffee on campus. Columbia has been rated \"B+\" by the 2011 College Sustainability Report Card for its environmental and sustainability initiatives.\n\nColumbia University received 36,292 applications for its undergraduate class of 2020 (entering 2016). In early decision, 620 out of 3,520 applicants were admitted, for an acceptance rate of 17.61%. In regular decision, 1,573 out of 32,772 applicants were admitted, for an acceptance rate of 4.79%. In total, 2,193 out of 36,292 applicants were admitted for an overall acceptance rate of 6.04%, making Columbia the third most selective college in the United States by admission rate behind Stanford and Harvard. The undergraduate yield rate for the class of 2019 was 63.2%. According to the 2012 college selectivity ranking by U.S. News & World Report, which factors admission and yield rates among other criteria, Columbia was tied with Yale, Caltech and MIT as the most selective colleges in the country. Columbia is a racially diverse school, with approximately 52% of all students identifying themselves as persons of color. Additionally, 50% of all undergraduates received grants from Columbia. The average grant size awarded to these students is $46,516. In 2015-2016, annual undergraduate tuition at Columbia was $50,526 with a total cost of attendance of $65,860 (including room and board).\n\nOn April 11, 2007, Columbia University announced a $400m to $600m donation from media billionaire alumnus John Kluge to be used exclusively for undergraduate financial aid. The donation is among the largest single gifts to higher education. Its exact value will depend on the eventual value of Kluge's estate at the time of his death; however, the generous donation has helped change financial aid policy at Columbia. Annual gifts, fund-raising, and an increase in spending from the university's endowment have allowed Columbia to extend generous financial aid packages to qualifying students. As of 2008, undergraduates from families with incomes as high as $60,000 a year will have the projected cost of attending the university, including room, board, and academic fees, fully paid for by the university. That same year, the university ended loans for incoming and current students who were on financial aid, replacing loans that were traditionally part of aid packages with grants from the university. However, this does not apply to international students, transfer students, visiting students, or students in the School of General Studies. In the fall of 2010, admission to Columbia's undergraduate colleges Columbia College and the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering) began accepting the Common Application. The policy change made Columbia one of the last major academic institutions and the last Ivy League university to switch to the Common Application.\n\nScholarships are also given to undergraduate students by the admissions committee. Designations include John W. Kluge Scholars, John Jay Scholars, C. Prescott Davis Scholars, Global Scholars, Egleston Scholars, and Science Research Fellows. Named scholars are selected by the admission committee from first-year applicants. According to Columbia, the first four designated scholars \"distinguish themselves for their remarkable academic and personal achievements, dynamism, intellectual curiosity, the originality and independence of their thinking, and the diversity that stems from their different cultures and their varied educational experiences.\"\n\nColumbia University is an independent, privately supported, nonsectarian institution of higher education. Its official corporate name is \"The Trustees of Columbia University in the City of New York.\" The university's first Charter was granted in 1754 by King George II; however, its modern Charter was first enacted in 1787 and last amended in 1810 by the New York State Legislature. The university is governed by 24 Trustees, customarily including the President, who serves ex officio. The Trustees themselves are responsible for choosing their successors. Six of the 24 are nominated from a pool of candidates recommended by the Columbia Alumni Association. Another six are nominated by the Board in consultation with the Executive Committee of the University Senate. The remaining 12, including the President, are nominated by the Trustees themselves through their internal processes. The term of office for Trustees is six years. Generally, they serve for no more than two consecutive terms. The Trustees appoint the President and other senior administrative officers of the university, and review and confirm faculty appointments as required. They determine the university's financial and investment policies, authorize the budget, supervise the endowment, direct the management of the university's real estate and other assets, and otherwise oversee the administration and management of the university.\n\nThe University Senate was established by the Trustees after a university-wide referendum in 1969. It succeeded to the powers of the University Council, which was created in 1890 as a body of faculty, deans, and other administrators to regulate inter-Faculty affairs and consider issues of university-wide concern. The University Senate is a unicameral body consisting of 107 members drawn from all constituencies of the university. These include the president of the university, the Provost, the Deans of Columbia College and the Graduate School of Arts and Sciences, all who serve ex officio, and five additional representatives, appointed by the President, from the university's administration. The President serves as the Senate's presiding officer. The Senate is charged with reviewing the educational policies, physical development, budget, and external relations of the university. It oversees the welfare and academic freedom of the faculty and the welfare of students.\n\nThe President of Columbia University, who is selected by the Trustees in consultation with the Executive Committee of the University Senate and who serves at the Trustees' pleasure, is the chief executive officer of the university. Assisting the President in administering the University are the Provost, the Senior Executive Vice President, the Executive Vice President for Health and Biomedical Sciences, several other vice presidents, the General Counsel, the Secretary of the University, and the deans of the Faculties, all of whom are appointed by the Trustees on the nomination of the President and serve at their pleasure. Lee C. Bollinger became the 19th President of Columbia University on June 1, 2002. A prominent advocate of affirmative action, he played a leading role in the twin Supreme Court cases—Grutter v Bollinger and Gratz v Bollinger—that upheld and clarified the importance of diversity as a compelling justification for affirmative action in higher education. A leading First Amendment scholar, he is widely published on freedom of speech and press, and serves on the faculty of Columbia Law School.\n\nColumbia has three official undergraduate colleges: Columbia College (CC), the liberal arts college offering the Bachelor of Arts degree, the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering) is the engineering and applied science school offering the Bachelor of Science degree, and The School of General Studies (GS), the liberal arts college offering the Bachelor of Arts degree to non-traditional students undertaking full- or part-time study.\n\nThe university is affiliated with Teachers College, Barnard College, and Union Theological Seminary, all located nearby in Morningside Heights. Of these, Barnard College and Teachers College are integrated as Faculties of the university. Furthermore, Teachers College is incorporated as an academic department of Columbia University, serving as the University's Graduate School of Education and Department of Education. Joint undergraduate programs are available through the Jewish Theological Seminary of America as well as through the Juilliard School.\n\nColumbia was the first North American site where the uranium atom was split. The College of Physicians and Surgeons played a central role in developing the modern understanding of neuroscience with the publication of \"Principles of Neural Science\", described by historian of science Katja Huenther as the \"neuroscience 'bible'\". The book was written by a team of Columbia researchers that included Nobel Prize winner Eric Kandel, James H. Schwartz, and Thomas Jessell. Columbia was the birthplace of FM radio and the laser. The MPEG-2 algorithm of transmitting high quality audio and video over limited bandwidth was developed by Dimitris Anastassiou, a Columbia professor of electrical engineering. Biologist Martin Chalfie was the first to introduce the use of Green Fluorescent Protein (GFP) in labeling cells in intact organisms. Other inventions and products related to Columbia include Sequential Lateral Solidification (SLS) technology for making LCDs, System Management Arts (SMARTS), Session Initiation Protocol (SIP) (which is used for audio, video, chat, instant messaging and whiteboarding), pharmacopeia, Macromodel (software for computational chemistry), a new and better recipe for glass concrete, Blue LEDs, and Beamprop (used in photonics).\nColumbia scientists have been credited with about 175 new inventions in the health sciences each year. More than 30 pharmaceutical products based on discoveries and inventions made at Columbia are on the market today. These include Remicade (for arthritis), Reopro (for blood clot complications), Xalatan (for glaucoma), Benefix, Latanoprost (a glaucoma treatment), shoulder prosthesis, homocysteine (testing for cardiovascular disease), and Zolinza (for cancer therapy). Columbia Technology Ventures (formerly Science and Technology Ventures), , manages some 600 patents and more than 250 active license agreements. Patent-related deals earned Columbia more than $230 million in the 2006 fiscal year, according to the university, more than any university in the world.\n\nColumbia University was ranked 3rd among U.S. national universities for 2016 by Wall Street Journal/Times Higher Education and first among Ivy League universities was ranked 4th overall among U.S. national universities for 2016 by \"U.S. News & World Report\". Individual colleges and schools were also nationally ranked by \"U.S. News & World Report\" for its 2016 edition. The Columbia Law School was ranked tied for 4th, the Mailman School of Public Health 5th, the School of Social Work 5th, the Teachers College (Columbia Graduate School of Education) 7th, the Columbia Business School 8th, the College of Physicians and Surgeons tied for 8th for research (and tied for 52nd for primary care), the Graduate School of Arts 10th, the School of Nursing tied for 11th, and the Fu Foundation School of Engineering and Applied Science (graduate) was ranked 14th.\n\nIn 2016, Columbia was ranked 9th in the world by \"Academic Ranking of World Universities\", 20th in the world by \"QS World University Rankings\", and 16th globally by \"Times Higher Education World University Rankings\".\n\nRankings by other organizations include the Graduate School of Architecture, Planning and Preservation #2, and its Graduate School of Journalism #1.\n\nBetween 1996 and 2008, 18 Columbia affiliates have won Nobel Prizes, of whom nine are faculty members while one is an adjunct senior research scientist (Daniel Tsui) and the other a Global Fellow (Kofi Annan). Columbia faculty awarded the Nobel Prize include Richard Axel, Martin Chalfie, Eric Kandel, Tsung-Dao Lee, Robert Mundell, Orhan Pamuk, Edmund S. Phelps, Joseph Stiglitz, and Horst L. Stormer. Other awards and honors won by faculty include 30 MacArthur Foundation Award winners, 4 National Medal of Science recipients, 43 National Academy of Sciences Award winners, 20 National Academy of Engineering Award winners, 38 Institute of Medicine of the National Academies Award recipients and 143 American Academy of Arts and Sciences Award winners.\n\nIn 2015, Columbia University was ranked the first in the state by average professor salaries. In 2011, the ranked Columbia 3rd best university for forming CEOs in the US and 12th worldwide.\n\nIn fall 2014, Columbia University's student population was 29,870 (8,559 students in undergraduate programs and 21,311 in postgraduate programs), with 39% of the student population identifying themselves as a minority and 28% born outside of the United States. Twenty-six percent of students at Columbia have family incomes below $60,000, making it one of the most socioeconomically diverse top-tier colleges. Sixteen percent of students at Columbia receive Federal Pell Grants, which mostly go to students whose family incomes are below $40,000. Fifteen percent of students are the first member of their family to attend a four-year college.\n\nOn-campus housing is guaranteed for all four years as an undergraduate. Columbia College and the Fu Foundation School of Engineering and Applied Science (also known as SEAS or Columbia Engineering) share housing in the on-campus residence halls. First-year students usually live in one of the large residence halls situated around South Lawn: Hartley Hall, Wallach Hall (originally Livingston Hall), John Jay Hall, Furnald Hall or Carman Hall. Upperclassmen participate in a room selection process, wherein students can pick to live in a mix of either corridor- or apartment-style housing with their friends. The Columbia University School of General Studies and graduate schools have their own apartment-style housing in the surrounding neighborhood.\n\nColumbia University is home to many fraternities, sororities, and co-educational Greek organizations. Approximately 10–15% of undergraduate students are associated with Greek life. There has been a Greek presence on campus since the establishment in 1836 of the Delta Chapter of Alpha Delta Phi. The InterGreek Council is the self-governing student organization that provides guidelines and support to its member organizations within each of the three councils at Columbia, the Interfraternity Council, Panhellenic Council, and Multicultural Greek Council. The three council presidents bring their affiliated chapters together once a month to meet as one Greek community. The InterGreek Council meetings provide opportunity for member organizations to learn from each other, work together and advocate for community needs.\n\nColumbia University is home to a rich diversity of undergraduate, graduate, and professional publications. The \"Columbia Daily Spectator\" is the nation's second-oldest student newspaper; and \"The Blue and White\", a monthly literary magazine established in 1890, has recently begun to delve into campus life and local politics in print and on its daily blog, dubbed the \"Bwog\". \"The Morningside Post\" is a student-run multimedia news publication. Its content: student-written investigative news, international affairs analysis, opinion, and satire.\n\nPolitical publications include \"The Current\", a journal of politics, culture and Jewish Affairs; the \"Columbia Political Review\", the multi-partisan political magazine of the Columbia Political Union; and \"AdHoc\", which denotes itself as the \"progressive\" campus magazine and deals largely with local political issues and arts events.\n\nArts and literary publications include \"The Columbia Review\", the nation's oldest college literary magazine; \"Columbia\", a nationally regarded literary journal; the \"Columbia Journal of Literary Criticism\"; and \"The Mobius Strip\", an online arts and literary magazine. \"Inside New York\" is an annual guidebook to New York City, written, edited, and published by Columbia undergraduates. Through a distribution agreement with Columbia University Press, the book is sold at major retailers and independent bookstores.\n\nColumbia is home to numerous undergraduate academic publications. The \"Journal of Politics & Society\", is a journal of undergraduate research in the social sciences, published and distributed nationally by the Helvidius Group; \"Publius\" is an undergraduate journal of politics established in 2008 and published biannually; the \"Columbia East Asia Review\" allows undergraduates throughout the world to publish original work on China, Japan, Korea, Tibet, and Vietnam and is supported by the Weatherhead East Asian Institute; and \"The Birch\", is an undergraduate journal of Eastern European and Eurasian culture that is the first national student-run journal of its kind; the \"Columbia Political Review\", the undergraduate magazine on politics operated by the Columbia Political Union; the \"Columbia Economics Review\", the undergraduate economic journal on research and policy supported by the Columbia Economics Department; and the \"Columbia Science Review\" is a science magazine that prints general interest articles, faculty profiles, and student research papers.\n\n\"The Fed\" a triweekly satire and investigative newspaper, and the \"Jester of Columbia\", the newly (and frequently) revived campus humor magazine both inject humor into local life. Other publications include \"The Columbian\", the undergraduate colleges' annually published yearbook the \"Gadfly\", a biannual journal of popular philosophy produced by undergraduates; and \"Rhapsody in Blue\", an undergraduate urban studies magazine. Professional journals published by academic departments at Columbia University include \"Current Musicology\" and \"The Journal of Philosophy\". During the spring semester, graduate students in the Journalism School publish \"The Bronx Beat\", a bi-weekly newspaper covering the South Bronx. Teachers College publishes the \"Teachers College Record\", a journal of research, analysis, and commentary in the field of education, published continuously since 1900.\n\nFounded in 1961 under the auspices of Columbia University's Graduate School of Journalism, the \"Columbia Journalism Review\" (CJR) examines day-to-day press performance as well as the forces that affect that performance. The magazine is published six times a year, and offers a reporting, analysis, criticism, and commentary. CJR.org, its web site, delivers real-time criticism and reporting, giving CJR a presence in the ongoing conversation about the media.\n\nColumbia is home to two pioneers in undergraduate campus radio broadcasting, WKCR-FM and CTV. WKCR, the student run radio station that broadcasts to the Tri-State area, claims to be the oldest FM radio station in the world, owing to the university's affiliation with Major Edwin Armstrong. The station went operational on July 18, 1939, from a 400-foot antenna tower in Alpine, New Jersey, broadcasting the very first FM transmission in the world. Initially, WKCR wasn't a radio station, but an organization concerned with the technology of radio communications. As membership grew, however, the nascent club turned its efforts to broadcasting. Armstrong helped the students in their early efforts, donating a microphone and turntables when they designed their first makeshift studio in a dorm room. The station has its studios on the second floor of Alfred Lerner Hall on the Morningside campus with its main transmitter tower at 4 Times Square in Midtown Manhattan. Columbia Television (CTV) is the nation's second oldest Student television station and home of CTV News, a weekly live news program produced by undergraduate students.\n\nThe Philolexian Society is a literary and debating club founded in 1802, making it the oldest student group at Columbia, as well as the third oldest collegiate literary society in the country. The society annually administers the Joyce Kilmer Bad Poetry Contest. The Columbia Parliamentary Debate Team competes in tournaments around the country as part of the American Parliamentary Debate Association, and hosts both high school and college tournaments on Columbia's campus, as well as public debates on issues affecting the university.\n\nThe Columbia International Relations Council and Association (CIRCA), oversees Columbia's Model United Nations activities. CIRCA hosts college and high school Model UN conferences, hosts speakers influential in international politics to speak on campus, trains students from underprivileged schools in New York in Model UN and oversees a competitive team, which travels to colleges around the country and to an international conference every year. The competitive team consistently wins best and outstanding delegation awards and is considered one of the top teams in the country.\n\nThe Columbia University Organization of Rising Entrepreneurs (CORE) was founded in 1999. The student-run group aims to foster entrepreneurship on campus. Each year CORE hosts dozens of events, including talks, #StartupColumbia, a conference and venture competition for $250,000, and Ignite@CU, a weekend for undergrads interested in design, engineering, and entrepreneurship. Notable speakers include Peter Thiel, Jack Dorsey, Alexis Ohanian, Drew Houston, and Mark Cuban. By 2006, CORE had awarded graduate and undergraduate students over $100,000 in seed capital.\n\nCampusNetwork, an on-campus social networking site called Campus Network that preceded Facebook, was created and popularized by Columbia engineering student Adam Goldberg in 2003. Mark Zuckerberg later asked Goldberg to join him in Palo Alto to work on Facebook, but Goldberg declined the offer. The Fu Foundation School of Engineering and Applied Science offers a minor in Technical Entrepreneurship through its Center for Technology, Innovation, and Community Engagement. SEAS' entrepreneurship activities focus on community building initiatives in New York and worldwide, made possible through partners such as Microsoft Corporation.\n\nColumbia is a top supplier of young engineering entrepreneurs for New York City. Over the past 20 years, graduates of Columbia established over 100 technology companies. Mayor Bloomberg has provided over $6.7 million towards entrepreneurial programs that partner with Columbia and other universities in New York. Professor Chris Wiggins of the Fu Foundation School of Engineering and Applied Science is working in conjunction with Professors Evan Korth of New York University and Hilary Mason, chief scientist at bit.ly to facilitate the growth of student tech-startups in an effort to transform a traditionally financially centered New York City into the next Silicon Valley. Their website, hackny.org, is a gathering ground of ideas and discussions for New York's young entrepreneurial community, the Silicon Alley.\n\nOn June 14, 2010, Mayor Michael R. Bloomberg launched the NYC Media Lab to promote innovations in New York's media industry. Situated in the Polytechnic Institute of New York University, the lab is a consortium of Columbia University, New York University, and New York City Economic Development Corporation acting to connect companies with universities in new technology research. The Lab is modeled after similar ones at MIT and Stanford. A $250,000 grant from the New York City Economic Development Corporation was used to establish the NYC Media Lab. Each year, the lab will host a range of roundtable discussions between the private sector and academic institutions. It will support research projects on topics of content format, next-generation search technologies, computer animation for film and gaming, emerging marketing techniques, and new devices development. The lab will also create a media research and development database. Columbia University will coordinate the long-term direction of the media lab as well as the involvement of its faculty and those of other universities.\n\nA member institution of the National Collegiate Athletic Association (NCAA) in Division I FCS, Columbia fields varsity teams in 29 sports and is a member of the Ivy League. The football Lions play home games at the 17,000-seat Robert K. Kraft Field at Lawrence A. Wien Stadium. One hundred blocks north of the main campus at Morningside Heights, the Baker Athletics Complex also includes facilities for baseball, softball, soccer, lacrosse, field hockey, tennis, track and rowing, as well as the new Campbell Sports Center opened in January 2013. The basketball, fencing, swimming & diving, volleyball and wrestling programs are based at the Dodge Physical Fitness Center on the main campus.\n\nColumbia University athletics has a long history, with many accomplishments in athletic fields. In 1870, Columbia played against Rutgers University in the second football game in the history of the sport. Eight years later, Columbia crew won the famed Henley Royal Regatta in the first-ever defeat for an English crew rowing in English waters. In 1900, Olympian and Columbia College student Maxie Long set the first official world record in the 400 meters with a time of 47.8 seconds. In 1983, Columbia men's soccer went 18-0 and was ranked first in the nation, but lost to Indiana 1-0 in double overtime in the NCAA championship game; nevertheless, the team went further toward the NCAA title than any Ivy League soccer team in history. The football program unfortunately is best known for its record of futility set during the 1980s: between 1983 and 1988, the team lost 44 games in a row, which is still the record for the NCAA Football Championship Subdivision. The streak was broken on October 8, 1988, with a 16-13 victory over archrival Princeton University. That was the Lions' first victory at Wien Stadium, which had been opened during the losing streak and was already four years old. A new tradition has developed with the Liberty Cup. The Liberty Cup is awarded annually to the winner of the football game between Fordham and Columbia Universities, two of the only three NCAA Division I football teams in New York City. The tradition began in 2002, a year after the Fordham-Columbia game was postponed due to the September 11 attacks.\n\nFormer students include Baseball Hall of Famers Lou Gehrig and Eddie Collins, football Hall of Famer Sid Luckman, Marcellus Wiley, and world champion women's weightlifter Karyn Marshall. On May 17, 1939, fledgling NBC broadcast a doubleheader between the Columbia Lions and the Princeton Tigers at Columbia's Baker Field, making it the first televised regular athletic event in history.\n\nEstablished in 2003 by university president Lee C. Bollinger, the World Leaders Forum at Columbia University provides the opportunity for undergraduate and graduate students alike to listen to world leaders in government, religion, industry, finance, and academia. The World Leaders Forum is a year-around event series that strives to provide a platform for uninhibited speech among nations and cultures, while educating students about problems and progress around the globe.\n\nAll Columbia undergraduates and graduates as well as students of Barnard College and other Columbia affiliated schools can register to participate in the World Leaders Forum using their student IDs. Even for individuals who do not have the privilege to attend the event live, they can watch the forum via online videos on Columbia University's website.\n\nPast forum speakers include former President of the United States Bill Clinton, the Prime Minister of India Atal Bihari Vajpayee, Former President of Ghana John Agyekum Kufuor, President of Afghanistan Hamid Karzai, Prime Minister of Russia Vladimir Putin, President of the Republic of Mozambique Joaquim Alberto Chissano, President of the Republic of Bolivia Carlos Diego Mesa Gisbert, President of the Republic of Romania Ion Iliescu, President of the Republic of Latvia Vaira Vīķe-Freiberga, the first female President of Finland Tarja Halonen, President Yudhoyono of Indonesia, President Pervez Musharraf of the Islamic Republic of Pakistan, Iraq President Jalal Talabani, the 14th Dalai Lama, President of the Islamic Republic of Iran Mahmoud Ahmadinejad, financier George Soros, Mayor of New York City Michael R. Bloomberg, President Václav Klaus of the Czech Republic, President Cristina Fernández de Kirchner of Argentina, former Secretary-General of the United Nations Kofi Annan, and Al Gore.\n\nThe Columbia University Orchestra was founded by composer Edward MacDowell in 1896, and is the oldest continually operating university orchestra in the United States. Undergraduate student composers at Columbia may choose to become involved with Columbia New Music, which sponsors concerts of music written by undergraduate students from all of Columbia's schools.\n\nThere are a number of performing arts groups at Columbia dedicated to producing student theater, including the Columbia Players, King's Crown Shakespeare Troupe (KCST), Columbia Musical Theater Society (CMTS), NOMADS (New and Original Material Authored and Directed by Students), LateNite Theatre, Columbia University Performing Arts League (CUPAL), Black Theatre Ensemble (BTE), sketch comedy group Chowdah, and improvisational troupes Alfred and Fruit Paunch. The Columbia University Marching Band tells jokes during the campus tradition of Orgo Night.\nThe Columbia Queer Alliance is the central Columbia student organization that represents the bisexual, lesbian, gay, transgender, and questioning student population. It is the oldest gay student organization in the world, founded as the Student Homophile League in 1967 by students including lifelong activist Stephen Donaldson. Columbia University campus military groups include the U.S. Military Veterans of Columbia University and Advocates for Columbia ROTC. In the 2005–06 academic year, the Columbia Military Society, Columbia's student group for ROTC cadets and Marine officer candidates, was renamed the Hamilton Society for \"students who aspire to serve their nation through the military in the tradition of Alexander Hamilton\".\n\nThe university also houses an independent nonprofit organization, Community Impact, which strives to serve disadvantaged people in the Harlem, Washington Heights, and Morningside Heights communities. From its earliest inception as a single service initiative formed in 1981 by Columbia University undergraduates, Community Impact has grown into Columbia University's largest student service organization. CI provides food, clothing, shelter, education, job training, and companionship for residents in its surrounding communities. CI consists of a dedicated corps of about 950 Columbia University student volunteers participating in 25 community service programs, which serve more than 8,000 people each year.\n\nStudents initiated a major demonstration in 1968 over two main issues. The first was Columbia's proposed gymnasium in neighboring Morningside Park; this was seen by the protesters to be an act of aggression aimed at the black residents of neighboring Harlem. A second issue was the Columbia administration's failure to resign its institutional membership in the Pentagon's weapons research think-tank, the Institute for Defense Analyses (IDA). Students barricaded themselves inside Low Library, Hamilton Hall, and several other university buildings during the protests, and New York City police were called onto the campus to arrest or forcibly remove the students.\n\nThe protests achieved two of their stated goals. Columbia disaffiliated from the IDA and scrapped the plans for the controversial gym, building a subterranean physical fitness center under the north end of campus instead. A popular myth states that the gym's plans were eventually used by Princeton University for the expansion of its athletic facilities, but as Jadwin Gymnasium was already 50% complete by 1966 (when the Columbia gym was announced) this was clearly not correct. At least 30 Columbia students were suspended by the administration as a result of the protests. Many of the Class of '68 walked out of their graduation and held a countercommencement on Low Plaza with a picnic following at Morningside Park, the place where the protests began. The protests hurt Columbia financially as many potential students chose to attend other universities and some alumni refused to donate money to the school. Allan Bloom, a professor of philosophy at the University of Chicago,\nbelieved that the protest efforts at Columbia were responsible for pushing higher education further toward the liberal left. As a result of the protests, Bloom stated, \"American universities were no longer places of intellectual and academic debate, but rather places of 'political correctness' and liberalism.\" \n\nFurther student protests, including hunger strike and more barricades of Hamilton Hall and the Business School during the late 1970s and early 1980s, were aimed at convincing the university trustees to divest all of the university's investments in companies that were seen as active or tacit supporters of the apartheid regime in South Africa. A notable upsurge in the protests occurred in 1978, when following a celebration of the tenth anniversary of the student uprising in 1968, students marched and rallied in protest of university investments in South Africa. The Committee Against Investment in South Africa (CAISA) and numerous student groups including the Socialist Action Committee, the Black Student Organization and the Gay Students group joined together and succeeded in pressing for the first partial divestment of a U.S. university.\n\nThe initial (and partial) Columbia divestment,\nfocused largely on bonds and financial institutions directly involved with the South African regime. It followed a year-long campaign first initiated by students who had worked together to block the appointment of former United States Secretary of State Henry Kissinger to an endowed chair at the university in 1977.\n\nBroadly backed by student groups and many faculty members the Committee Against Investment in South Africa held teach-ins and demonstrations through the year focused on the trustees ties to the corporations doing business with South Africa. Trustee meetings were picketed and interrupted by demonstrations culminating in May 1978 in the takeover of the Graduate School of Business.\n\nThe School of International and Public Affairs extends invitations to heads of state and heads of government who come to New York City for the opening of the fall session of the United Nations General Assembly. In 2007, Iranian President Mahmoud Ahmadinejad was one of those invited to speak on campus. Ahmadinejad accepted his invitation and spoke on September 24, 2007, as part of Columbia University's World Leaders Forum. The invitation proved to be highly controversial. Hundreds of demonstrators swarmed the campus on September 24 and the speech itself was televised worldwide. University President Lee C. Bollinger tried to allay the controversy by letting Ahmadenijad speak, but with a negative introduction (given personally by Bollinger). This did not mollify those who were displeased with the fact that the Iranian leader had been invited onto the campus. Columbia students, though, turned out en masse to listen to the speech on the South Lawn. An estimated 2,500 undergraduates and graduates came out for the historic occasion.\n\nDuring his speech, Ahmadinejad criticized Israel's policies towards the Palestinians; called for research on the historical accuracy of the Holocaust; raised questions as to who initiated the 9/11 attacks; defended Iran's nuclear power program, criticizing the UN's policy of sanctions on his country; and attacked U.S. foreign policy in the Middle East. In response to a question about Iran's treatment of women and homosexuals, he asserted that women are respected in Iran and that \"In Iran, we don't have homosexuals like in your country... In Iran, we do not have this phenomenon. I don't know who told you this.\" The latter statement drew laughter from the audience. The Manhattan District Attorney's Office accused Columbia of accepting grant money from the Alavi Foundation to support faculty \"sympathetic\" to Iran's Islamic republic.\n\nBeginning in 1969, during the Vietnam War, the university did not allow the U.S. military to have Reserve Officers' Training Corps (ROTC) programs on campus, though Columbia students could participate in ROTC programs at other local colleges and universities. At a forum at the university during the 2008 presidential election campaign, both John McCain and Barack Obama said that the university should consider reinstating ROTC on campus. After the debate, the President of the University, Lee C. Bollinger, stated that he did not favor reinstating Columbia's ROTC program, because of the military's anti-gay policies. In November 2008, Columbia's undergraduate student body held a referendum on the question of whether or not to invite ROTC back to campus, and the students who voted were almost evenly divided on the issue. ROTC lost the vote (which would not have been binding on the administration, and did not include graduate students, faculty, or alumni) by a fraction of a percentage point.\n\nIn April 2010 during Admiral Mike Mullen's address at Columbia, President Lee C. Bollinger stated that the ROTC would be readmitted to campus if the admiral's plans for revoking the don't ask, don't tell policy were successful. In February 2011 during one of three town-hall meetings on the ROTC ban, former Army staff sergeant Anthony Maschek, a Purple Heart recipient for injuries sustained during his service in Iraq, was booed and hissed at by some students during his speech promoting the idea of allowing the ROTC on campus. In April 2011 the Columbia University Senate voted to welcome the ROTC program back on campus. Secretary of the Navy Ray Mabus and Columbia University President Lee C. Bollinger signed an agreement to reinstate Naval Reserve Officers Training Corps (NROTC) program at Columbia for the first time in more than 40 years on May 26, 2011. The agreement was signed at a ceremony on board the USS Iwo Jima, docked in New York for the Navy's annual Fleet Week.\n\nOn the day before the Organic Chemistry exam—which is often on the first day of finals—at precisely the stroke of midnight, the Columbia University Marching Band occupies Butler Library to distract diligent students from studying. After a forty-five minutes or so of jokes and music, the procession then moves out to the lawn in front of Hartley, Wallach and John Jay residence halls to entertain the residents there. The band then plays at other locations around Morningside Heights, including the residential quadrangle of Barnard College, where students of the all-women's school, in mock-consternation, rain trash – including notes and course packets – and water balloons upon them from their dormitories above. The band tends to close their Orgo Night performances before Furnald Hall, known among students as the more studious and reportedly \"anti-social\" residence hall, where the underclassmen in the band serenade the graduating seniors with an entertaining, though vulgar, mock-hymn to Columbia, composed of quips that poke fun at the stereotypes about the Columbia student body.\n\nIn December 2016, University administrators banned the Marching Band from performing its Orgo Night show in its traditional Butler Library location, setting off a storm of protests and accusations that University President Lee C. Bollinger was censoring the Band's speech. Concerned alumni initiated an organized campaign to restore the Orgo Night show by publishing a series of pamphlets addressing the issues.\n\nThe campus Tree-Lighting Ceremony was inaugurated in 1998. It celebrates the illumination of the medium-sized trees lining College Walk in front of Kent and Hamilton Halls on the east end and Dodge and Journalism Halls on the west, just before finals week in early December. The lights remain on until February 28. Students meet at the sun-dial for free hot chocolate, performances by \"a cappella\" groups, and speeches by the university president and a guest.\n\nImmediately following the College Walk festivities is one of Columbia's older holiday traditions, the lighting of the Yule Log. The Christmas ceremony dates to a period prior to the American Revolutionary War, but lapsed before being revived by University President Nicholas Murray Butler in the early 20th century. A troop of students dressed as Continental Army soldiers carry the eponymous log from the sun-dial to the lounge of John Jay Hall, where it is lit amid the singing of seasonal carols. The Christmas ceremony is accompanied by a reading of \"A Visit From St. Nicholas\" by Clement Clarke Moore and \"Yes, Virginia, There is a Santa Claus\" by Francis Pharcellus Church.\n\nThe Varsity Show is an annual musical written by and for students and was established in 1894, making it one of Columbia's oldest traditions. Past writers and directors have included Columbians Richard Rodgers and Oscar Hammerstein, Lorenz Hart, I.A.L. Diamond, and Herman Wouk. The show has one of the largest operating budgets of all university events.\n\nAs of 2011, Columbia alumni included three United States Presidents, 26 foreign Heads of State, ten Justices of the Supreme Court of the United States (including three Chief Justices) and 39 Nobel winners. As of 2011, alumni also have received more than 35 National Book Awards and 123 Pulitzer Prizes. Today, two United States Senators and 16 Chief Executives of Fortune 500 companies hold Columbia degrees, as do three of the 25 richest Americans and 20 living billionaires. Five Founding Fathers including a member of the Committee of Five are alumni of Columbia University, then named \"King's College\".\n\nFormer U.S. Presidents Theodore Roosevelt and Franklin Delano Roosevelt attended the law school. Other more recent political figures educated at Columbia include former U.S President Barack Obama, Associate Justice of the U.S. Supreme Court Ruth Bader Ginsburg, former U.S. Secretary of State Madeleine Albright, former chairman of the U.S. Federal Reserve Bank Alan Greenspan, U.S. Attorney General Eric Holder, and U.S. Solicitor General Donald Verrilli Jr. Dwight D. Eisenhower served as the thirteenth president of Columbia University from 1948 to 1953. The university has also educated 26 foreign heads of state, including President of Georgia Mikheil Saakashvili, President of East Timor Jose Ramos Horta, President of Estonia Toomas Hendrik Ilves and other historical figures such as Wellington Koo, Radovan Karadžić, Gaston Eyskens, and T. V. Soong. The author of India's constitution and Dalit leader Dr. B. R. Ambedkar was also an alumnus of Columbia.\n\nAlumni of Columbia have occupied top positions in Wall Street and the rest of the business world. Notable members of the Astor family attended Columbia, while some recent business graduates include investor Warren Buffett, former CEO of PBS and NBC Larry Grossman, and chairman of Wal-Mart S. Robson Walton. CEO's of top Fortune 500 companies include James P. Gorman of Morgan Stanley, Robert J. Stevens of Lockheed Martin, Philippe Dauman of Viacom, Ursula Burns of Xerox, and Vikram Pandit of Citigroup. Notable labor organizer and women's educator Louise Leonard McLaren received her degree of Master of Arts from Columbia.\n\nIn science and technology, Columbia alumni include: founder of IBM Herman Hollerith; inventor of FM radio Edwin Armstrong; Francis Mechner; integral in development of the nuclear submarine Hyman Rickover; founder of Google China Kai-Fu Lee; scientists Stephen Jay Gould, Robert Millikan, Helium–neon laser inventor Ali Javan and Mihajlo Pupin; chief-engineer of the New York City Subway, William Barclay Parsons; philosophers Irwin Edman and Robert Nozick; economist Milton Friedman; and psychologist Harriet Babcock.\n\nMany Columbia alumni have gone on to renowned careers in the arts, such as the composers Richard Rodgers, Oscar Hammerstein II, Lorenz Hart, and Art Garfunkel. Four United States Poet Laureates received their degrees from Columbia. Columbia alumni have made an indelible mark in the field of American poetry and literature, with such people as Jack Kerouac and Allen Ginsberg, pioneers of the Beat Generation, and Langston Hughes, a seminal figure in the Harlem Renaissance, all having attended the university. Other notable writers who attended Columbia include authors Isaac Asimov, J.D. Salinger, Upton Sinclair, Danielle Valore Evans, and Hunter S. Thompson.\n\nUniversity alumni have also been very prominent in the film industry, with 28 alumni and former students winning a combined 39 Academy Awards (as of 2011), second in the world only to New York University (NYU). Some notable Columbia alumni that have gone on to work in film include directors Sidney Lumet (\"12 Angry Men\") and Kathryn Bigelow (\"The Hurt Locker\"), screenwriters Howard Koch (\"Casablanca\") and Joseph L. Mankiewicz (\"All About Eve\"), and actors James Cagney and Ed Harris.\n\n\n", "id": "6310", "title": "Columbia University"}
{"url": "https://en.wikipedia.org/wiki?curid=6312", "text": "Cell wall\n\nA cell wall is a structural layer surrounding some types of cells, situated outside the cell membrane. It can be tough, flexible, and sometimes rigid. It provides the cell with both structural support and protection, and also acts as a filtering mechanism. Cell walls are present in most prokaryotes (except mycoplasma bacteria), in algae, plants and fungi but rarely in other eukaryotes including animals. A major function is to act as pressure vessels, preventing over-expansion of the cell when water enters.\n\nThe composition of cell walls varies between species and may depend on cell type and developmental stage. The primary cell wall of land plants is composed of the polysaccharides cellulose, hemicellulose and pectin. Often, other polymers such as lignin, suberin or cutin are anchored to or embedded in plant cell walls. Algae possess walls made of glycoproteins and polysaccharides such as carrageenan and agar that are absent from land plants. In bacteria, the cell wall is composed of peptidoglycan. The cell walls of archaea have various compositions, and may be formed of glycoprotein S-layers, pseudopeptidoglycan, or polysaccharides. Fungi possess cell walls made of the glucosamine polymer chitin. Unusually, diatoms have a cell wall composed of biogenic silica.\n\nA plant cell wall was first observed and named (simply as a \"wall\") by Robert Hooke in 1665. However, \"the dead excrusion product of the living protoplast\" was forgotten, for almost three centuries, being the subject of scientific interest mainly as a resource for industrial processing or in relation to animal or human health.\n\nIn 1804, Karl Rudolphi and J.H.F. Link proved that cells had independent cell walls. Before, it had been thought that cells shared walls and that fluid passed between them this way.\n\nThe mode of formation of the cell wall was controversial in the 19th century. Hugo von Mohl (1853, 1858) advocated the idea that the cell wall grows by apposition. Carl Nägeli (1858, 1862, 1863) believed that the growth of the wall in thickness and in area was due to a process termed intussusception. Each theory was improved in the following decades: the apposition (or lamination) theory by Eduard Strasburger (1882, 1889), and the intussusception theory by Julius Wiesner (1886).\n\nIn 1930, Ernst Münch coined the term \"apoplast\" in order to separate the \"living\" symplast from the \"dead\" plant region, the latter of which included the cell wall.\n\nBy the 1980s, some authors suggested replacing the term \"cell wall\", particularly as it was used for plants, with the more precise term \"extracellular matrix\", as used for animal cells, but others preferred the older term.\n\nCell walls serve similar purposes in those organisms that possess them. They may give cells rigidity and strength, offering protection against mechanical stress. In multicellular organisms, they permit the organism to build and hold a definite shape (morphogenesis). Cell walls also limit the entry of large molecules that may be toxic to the cell. They further permit the creation of stable osmotic environments by preventing osmotic lysis and helping to retain water. Their composition, properties, and form may change during the cell cycle and depend on growth conditions.\n\nIn most cells, the cell wall is flexible, meaning that it will bend rather than holding a fixed shape, but has considerable tensile strength. The apparent rigidity of primary plant tissues is enabled by cell walls, but is not due to the walls' stiffness. Hydraulic turgor pressure creates this rigidity, along with the wall structure. The flexibility of the cell walls is seen when plants wilt, so that the stems and leaves begin to droop, or in seaweeds that bend in water currents. As John Howland explains:\nThe apparent rigidity of the cell wall thus results from inflation of the cell contained within. This inflation is a result of the passive uptake of water.\n\nIn plants, a secondary cell wall is a thicker additional layer of cellulose which increases wall rigidity. Additional layers may be formed by lignin in xylem cell walls, or suberin in cork cell walls. These compounds are rigid and waterproof, making the secondary wall stiff. Both wood and bark cells of trees have secondary walls. Other parts of plants such as the leaf stalk may acquire similar reinforcement to resist the strain of physical forces.\n\nThe primary cell wall of most plant cells is freely permeable to small molecules including small proteins, with size exclusion estimated to be 30-60 kDa. The pH is an important factor governing the transport of molecules through cell walls.\n\nCell walls evolved independently in many groups, even in the photosynthetic eukaryotes. In these lineages, the cell wall is closely related to the evolution of multicellularity, terrestrialization and vascularization.\n\nThe walls of plant cells must have sufficient tensile strength to withstand internal osmotic pressures of several times atmospheric pressure that result from the difference in solute concentration between the cell interior and external solutions. Plant cell walls vary from 0.1 to several µm in thickness.\n\nUp to three strata or layers may be found in plant cell walls:\n\n\nIn the primary (growing) plant cell wall, the major carbohydrates are cellulose, hemicellulose and pectin. The cellulose microfibrils are linked via hemicellulosic tethers to form the cellulose-hemicellulose network, which is embedded in the pectin matrix. The most common hemicellulose in the primary cell wall is xyloglucan. In grass cell walls, xyloglucan and pectin are reduced in abundance and partially replaced by glucuronarabinoxylan, another type of hemicellulose. Primary cell walls characteristically extend (grow) by a mechanism called acid growth, which involves turgor-driven movement of the strong cellulose microfibrils within the weaker hemicellulose/pectin matrix, catalyzed by expansin proteins. The outer part of the primary cell wall of the plant epidermis is usually impregnated with cutin and wax, forming a permeability barrier known as the plant cuticle.\n\nSecondary cell walls contain a wide range of additional compounds that modify their mechanical properties and permeability. The major polymers that make up wood (largely secondary cell walls) include:\n\nAdditionally, structural proteins (1-5%) are found in most plant cell walls; they are classified as hydroxyproline-rich glycoproteins (HRGP), arabinogalactan proteins (AGP), glycine-rich proteins (GRPs), and proline-rich proteins (PRPs). Each class of glycoprotein is defined by a characteristic, highly repetitive protein sequence. Most are glycosylated, contain hydroxyproline (Hyp) and become cross-linked in the cell wall. These proteins are often concentrated in specialized cells and in cell corners. Cell walls of the epidermis may contain cutin. The Casparian strip in the endodermis roots and cork cells of plant bark contain suberin. Both cutin and suberin are polyesters that function as permeability barriers to the movement of water. The relative composition of carbohydrates, secondary compounds and proteins varies between plants and between the cell type and age. Plant cells walls also contain numerous enzymes, such as hydrolases, esterases, peroxidases, and transglycosylases, that cut, trim and cross-link wall polymers.\n\nSecondary walls - especially in grasses - may also contain microscopic silica crystals, which may strengthen the wall and protect it from herbivores.\n\nCell walls in some plant tissues also function as storage deposits for carbohydrates that can be broken down and resorbed to supply the metabolic and growth needs of the plant. For example, endosperm cell walls in the seeds of cereal grasses, nasturtium\nand other species, are rich in glucans and other polysaccharides that are readily digested by enzymes during seed germination to form simple sugars that nourish the growing embryo.\n\nThe middle lamella is laid down first, formed from the cell plate during cytokinesis, and the primary cell wall is then deposited inside the middle lamella. The actual structure of the cell wall is not clearly defined and several models exist - the covalently linked cross model, the tether model, the diffuse layer model and the stratified layer model. However, the primary cell wall, can be defined as composed of cellulose microfibrils aligned at all angles. Cellulose microfibrils are produced at the plasma membrane by the cellulose synthase complex, which is proposed to be made of a hexameric rosette that contains three cellulose synthase catalytic subunits for each of the six units. Microfibrils are held together by hydrogen bonds to provide a high tensile strength. The cells are held together and share the gelatinous membrane called the \"middle lamella\", which contains magnesium and calcium pectates (salts of pectic acid). Cells interact though plasmodesmata, which are inter-connecting channels of cytoplasm that connect to the protoplasts of adjacent cells across the cell wall.\n\nIn some plants and cell types, after a maximum size or point in development has been reached, a \"secondary wall\" is constructed between the plasma membrane and primary wall. Unlike the primary wall, the cellulose microfibrils are aligned parallel in layers, the orientation changing slightly with each additional layer so that the structure becomes helicoidal. Cells with secondary cell walls can be rigid, as in the gritty sclereid cells in pear and quince fruit. Cell to cell communication is possible through pits in the secondary cell wall that allow plasmodesmata to connect cells through the secondary cell walls.\n\nThere are several groups of organisms that have been called \"fungi\". Some of these groups (Oomycete and Myxogastria) have been transferred out of the Kingdom Fungi, in part because of fundamental biochemical differences in the composition of the cell wall. Most true fungi have a cell wall consisting largely of chitin and other polysaccharides. True fungi do not have cellulose in their cell walls.\n\nIn fungi, the cell wall is the outer-most layer, external to the plasma membrane. The fungal cell wall is a matrix of three main components:\n\nLike plants, algae have cell walls. Algal cell walls contain either polysaccharides (such as cellulose (a glucan)) or a variety of glycoproteins (Volvocales) or both. The inclusion of additional polysaccharides in algal cells walls is used as a feature for algal taxonomy.\n\n\nOther compounds that may accumulate in algal cell walls include sporopollenin and calcium ions.\n\nThe group of algae known as the diatoms synthesize their cell walls (also known as frustules or valves) from silicic acid (specifically orthosilicic acid, HSiO). The acid is polymerised intra-cellularly, then the wall is extruded to protect the cell. Significantly, relative to the organic cell walls produced by other groups, silica frustules require less energy to synthesize (approximately 8%), potentially a major saving on the overall cell energy budget and possibly an explanation for higher growth rates in diatoms.\n\nIn brown algae, phlorotannins may be a constituent of the cell walls.\n\nThe group Oomycetes, also known as water molds, are saprotrophic plant pathogens like fungi. Until recently they were widely believed to be fungi, but structural and molecular evidence has led to their reclassification as heterokonts, related to autotrophic brown algae and diatoms. Unlike fungi, oomycetes typically possess cell walls of cellulose and glucans rather than chitin, although some genera (such as \"Achlya\" and \"Saprolegnia\") do have chitin in their walls. The fraction of cellulose in the walls is no more than 4 to 20%, far less than the fraction of glucans. Oomycete cell walls also contain the amino acid hydroxyproline, which is not found in fungal cell walls.\n\nThe dictyostelids are another group formerly classified among the fungi. They are slime molds that feed as unicellular amoebae, but aggregate into a reproductive stalk and sporangium under certain conditions. Cells of the reproductive stalk, as well as the spores formed at the apex, possess a cellulose wall. The spore wall has been shown to possess three layers, the middle of which is composed primarily of cellulose, and the innermost is sensitive to cellulase and pronase.\n\nAround the outside of the cell membrane is the bacterial cell wall. Bacterial cell walls are made of peptidoglycan (also called murein), which is made from polysaccharide chains cross-linked by unusual peptides containing D-amino acids. Bacterial cell walls are different from the cell walls of plants and fungi which are made of cellulose and chitin, respectively. The cell wall of bacteria is also distinct from that of Archaea, which do not contain peptidoglycan. The cell wall is essential to the survival of many bacteria, although L-form bacteria can be produced in the laboratory that lack a cell wall. The antibiotic penicillin is able to kill bacteria by preventing the cross-linking of peptidoglycan and this causes the cell wall to weaken and lyse. The lysozyme enzyme can also damage bacterial cell walls.\n\nThere are broadly speaking two different types of cell wall in bacteria, called Gram-positive and Gram-negative. The names originate from the reaction of cells to the Gram stain, a test long-employed for the classification of bacterial species.\n\nGram-positive bacteria possess a thick cell wall containing many layers of peptidoglycan and teichoic acids. In contrast, Gram-negative bacteria have a relatively thin cell wall consisting of a few layers of peptidoglycan surrounded by a second lipid membrane containing lipopolysaccharides and lipoproteins. Most bacteria have the Gram-negative cell wall and only the Firmicutes and Actinobacteria (previously known as the low G+C and high G+C Gram-positive bacteria, respectively) have the alternative Gram-positive arrangement. These differences in structure can produce differences in antibiotic susceptibility, for instance vancomycin can kill only Gram-positive bacteria and is ineffective against Gram-negative pathogens, such as \"Haemophilus influenzae\" or \"Pseudomonas aeruginosa\".\n\nAlthough not truly unique, the cell walls of Archaea are unusual. Whereas peptidoglycan is a standard component of all bacterial cell walls, all archaeal cell walls lack peptidoglycan, with the exception of one group of methanogens. In that group, the peptidoglycan is a modified form very different from the kind found in bacteria. There are four types of cell wall currently known among the Archaea.\n\nOne type of archaeal cell wall is that composed of pseudopeptidoglycan (also called pseudomurein). This type of wall is found in some methanogens, such as \"Methanobacterium\" and \"Methanothermus\". While the overall structure of archaeal \"pseudo\"peptidoglycan superficially resembles that of bacterial peptidoglycan, there are a number of significant chemical differences. Like the peptidoglycan found in bacterial cell walls, pseudopeptidoglycan consists of polymer chains of glycan cross-linked by short peptide connections. However, unlike peptidoglycan, the sugar N-acetylmuramic acid is replaced by N-acetyltalosaminuronic acid, and the two sugars are bonded with a \"β\",1-3 glycosidic linkage instead of \"β\",1-4. Additionally, the cross-linking peptides are L-amino acids rather than D-amino acids as they are in bacteria.\n\nA second type of archaeal cell wall is found in \"Methanosarcina\" and \"Halococcus\". This type of cell wall is composed entirely of a thick layer of polysaccharides, which may be sulfated in the case of \"Halococcus\". Structure in this type of wall is complex and not fully investigated.\n\nA third type of wall among the Archaea consists of glycoprotein, and occurs in the hyperthermophiles, \"Halobacterium\", and some methanogens. In \"Halobacterium\", the proteins in the wall have a high content of acidic amino acids, giving the wall an overall negative charge. The result is an unstable structure that is stabilized by the presence of large quantities of positive sodium ions that neutralize the charge. Consequently, \"Halobacterium\" thrives only under conditions with high salinity.\n\nIn other Archaea, such as \"Methanomicrobium\" and \"Desulfurococcus\", the wall may be composed only of surface-layer proteins, known as an \"S-layer\". S-layers are common in bacteria, where they serve as either the sole cell-wall component or an outer layer in conjunction with polysaccharides. Most Archaea are Gram-negative, though at least one Gram-positive member is known.\n\nMany protists and bacteria produce other cell surface structures apart from cell walls, external (extracellular matrix) or internal. Many algae have a sheath or envelope of mucilage outside the cell made of exopolysaccharides. Diatoms build a frustule from silica extracted from the surrounding water; radiolarians, foraminiferans, testate amoebae and silicoflagellates also produce a skeleton from minerals, called test in some groups. Many green algae, such as \"Halimeda\" and the Dasycladales, and some red algae, the Corallinales, encase their cells in a secreted skeleton of calcium carbonate. In each case, the wall is rigid and essentially inorganic. It is the non-living component of cell. Some golden algae, ciliates and choanoflagellates produces a shell-like protective outer covering called lorica. Some dinoflagellates have a theca of cellulose plates, and coccolithophorids have coccoliths.\n\nAn extracellular matrix is also present in metazoans. Its composition varies between cells, but collagens are the most abundant protein in the ECM.\n\n\n", "id": "6312", "title": "Cell wall"}
{"url": "https://en.wikipedia.org/wiki?curid=6313", "text": "Classical element\n\nClassical elements typically refer to the concepts in Ancient Greece, of earth, water, air, fire, and aether, which were proposed to explain the nature and complexity of all matter in terms of simpler substances. Ancient cultures in Egypt, Babylonia, Japan, Tibet, and India had similar lists, sometimes referring in local languages to \"air\" as \"wind\" and the fifth element as \"void\". The Chinese Wu Xing system lists Wood (木 \"mù\"), Fire (火 \"huǒ\"), Earth (土 \"tǔ\"), Metal (金 \"jīn\"), and Water (水 \"shuǐ\"), though these are described more as energies or transitions than as types of material.\n\nThese different cultures and even individual philosophers had widely varying explanations concerning their attributes and how they related to observable phenomena as well as cosmology. Sometimes these theories overlapped with mythology and were personified in deities. Some of these interpretations included atomism (the idea of very small, indivisible portions of matter) but other interpretations considered the elements to be divisible into infinitely small pieces without changing their nature.\n\nWhile the classification of the material world by the ancient Indians and Greeks into Air, Earth, Fire and Water was more philosophical, during the Islamic Golden Age medieval middle eastern scientists used practical, experimental observation to classify materials. In Europe, the Ancient Greek system of Aristotle evolved slightly into the medieval system, which for the first time in Europe became subject to experimental verification in the 1600s, during the Scientific Revolution.\n\nCenturies of empirical investigation have proven that all the ancient systems were incorrect explanations of the physical world. It is now known that atomic theory is a correct explanation, and that atoms can be classified into more than a hundred chemical elements such as oxygen, iron, and mercury. These elements form chemical compounds and mixtures, and under different temperatures and pressures, these substances can adopt different states of matter. The most commonly observed states of solid, liquid, gas, and plasma share many attributes with the classical elements of earth, water, air, and fire, respectively, but it is now known that these states are due to similar behavior of different types of atoms at similar energy levels, and not due to containing a certain type of atom or a certain type of infinitely divisible substance or energy.\n\nIn classical thought, the four elements earth, water, air, and fire as proposed by Empedocles frequently occur; Aristotle added a fifth element, aether; it has been called akasha in India and quintessence in Europe.\n\nThe concept of the five elements formed a basis of analysis in both Hinduism and Buddhism. In Hinduism, particularly in an esoteric context, the four states-of-matter describe matter, and a fifth element describes that which was beyond the material world. Similar lists existed in ancient China and Japan. In Buddhism the four great elements, to which two others are sometimes added, are not viewed as substances, but as categories of sensory experience.\n\nA Greek text called the \"Kore Kosmou\" (\"Virgin of the World\") ascribed to Hermes Trismegistus (associated with the Egyptian god Thoth), names the four elements fire, water, air, and earth. As described in this book:\n\nAnd Isis answer made: Of living things, my son, some are made friends with \"fire\", and some with \"water\", some with \"air\", and some with \"earth\", and some with two or three of these, and some with all. And, on the contrary, again some are made enemies of fire, and some of water, some of earth, and some of air, and some of two of them, and some of three, and some of all. For instance, son, the locust and all flies flee fire; the eagle and the hawk and all high-flying birds flee water; fish, air and earth; the snake avoids the open air. Whereas snakes and all creeping things love earth; all swimming things love water; winged things, air, of which they are the citizens; while those that fly still higher love the fire and have the habitat near it. Not that some of the animals as well do not love fire; for instance salamanders, for they even have their homes in it. It is because one or another of the elements doth form their bodies' outer envelope. Each soul, accordingly, while it is in its body is weighted and constricted by these four.\n\nAccording to Galen, these elements were used by Hippocrates in describing the human body with an association with the four humours: yellow bile (fire), black bile (earth), blood (air), and phlegm (water). Medical care was flexible and primarily about helping the patient stay in or return to his/her own personal natural balanced state.\n\nIn Babylonian mythology, the cosmogony called \"Enûma Eliš\", a text written between the 18th and 16th centuries BC, involves four gods that we might see as personified cosmic elements: sea, earth, sky, wind. In other Babylonian texts these phenomena are considered independent of their association with deities, though they are not treated as the component elements of the universe, as later in Empedocles.\n\nThe system of five elements are found in Vedas, especially Ayurveda, the \"pancha mahabhuta\", or \"five great elements\", of Hinduism are \"bhūmi\" (earth), \"ap\" or \"jala\" (water), \"tejas\" or \"agni\" (fire), \"marut\", \"vayu\" or \"pavan\" (air or wind) and \"vyom\" or \"shunya\" (space or zero) or \"akash\" (aether or void). They further suggest that all of creation, including the human body, is made up of these five essential elements and that upon death, the human body dissolves into these five elements of nature, thereby balancing the cycle of nature.\n\nThe five elements are associated with the five senses, and act as the gross medium for the experience of sensations. The basest element, earth, created using all the other elements, can be perceived by all five senses – (i) hearing, (ii) touch, (iii) sight, (iv) taste, and (v) smell. The next higher element, water, has no odor but can be heard, felt, seen and tasted. Next comes fire, which can be heard, felt and seen. Air can be heard and felt. \"Akasha\" (aether) is beyond the senses of smell, taste, sight, and touch; it being accessible to the sense of hearing alone.\n\nIn the Pali literature, the \"mahabhuta\" (\"great elements\") or \"catudhatu\" (\"four elements\") are earth, water, fire and air. In early Buddhism, the four elements are a basis for understanding suffering and for liberating oneself from suffering. The earliest Buddhist texts explain that the four primary material elements are the sensory qualities solidity, fluidity, temperature, and mobility; their characterization as earth, water, fire, and air, respectively, is declared an abstraction – instead of concentrating on the fact of material existence, one observes how a physical thing is sensed, felt, perceived.\n\nThe Buddha's teaching regarding the four elements is to be understood as the base of all observation of real sensations rather than as a philosophy. The four properties are cohesion (water), solidity or inertia (earth), expansion or vibration (air) and heat or energy content (fire). He promulgated a categorization of mind and matter as composed of eight types of \"kalapas\" of which the four elements are primary and a secondary group of four are color, smell, taste, and nutriment which are derivative from the four primaries.\n\nThanissaro Bhikkhu (1997) renders an extract of Shakyamuni Buddha's from Pali into English thus:\nTibetan Buddhist medical literature speaks of the Panch Mahābhūta (five elements).\n\nThe Chinese had a somewhat different series of elements, namely Fire, Earth, Metal (literally gold), Water and Wood, which were understood as different types of energy in a state of constant interaction and flux with one another, rather than the Western notion of different kinds of material.\n\nAlthough it is usually translated as \"element\", the Chinese word \"xing\" literally means something like \"changing states of being\", \"permutations\" or \"metamorphoses of being\". In fact Sinologists cannot agree on any single translation. The Chinese elements were seen as ever changing and movingone translation of \"wu xing\" is simply \"the five changes\".\n\nThe Wu Xing are chiefly an ancient mnemonic device for systems with five stages; hence the preferred translation of \"movements\", \"phases\" or \"steps\" over \"elements.\"\n\nIn the bagua, metal is associated with the divination figure 兌 \"Duì\" (☱, the lake or marsh: 澤/泽 \"zé\") and with 乾 \"Qián\" (☰, the sky or heavens: 天 \"tiān\"). Wood is associated with 巽 \"Xùn\" (☴, the wind: 風/风 \"fēng\") and with 震 \"Zhèn\" (☳, the arousing/thunder: 雷 \"léi\"). In view of the durability of meteoric iron, metal came to be associated with the aether, which is sometimes conflated with Stoic pneuma, as both terms originally referred to air (the former being higher, brighter, more fiery or celestial and the latter being merely warmer, and thus vital or biogenetic). In Taoism, \"qi\" functions similarly to pneuma in a prime matter (a basic principle of energetic transformation) that accounts for both biological and inanimate phenomena.\n\nIn Chinese philosophy the universe consists of heaven and earth. The five major planets are associated with and even named after the elements: Jupiter 木星 is Wood (木), Mars 火星 is Fire (火), Saturn 土星 is Earth (土), Venus 金星 is Metal (金), and Mercury 水星 is Water (水). Also, the Moon represents Yin (陰), and the Sun 太陽 represents Yang (陽). Yin, Yang, and the five elements are associated with themes in the I Ching, the oldest of Chinese classical texts which describes an ancient system of cosmology and philosophy. The five elements also play an important part in Chinese astrology and the Chinese form of geomancy known as Feng shui.\n\nThe doctrine of five phases describes two cycles of balance, a generating or creation (生, shēng) cycle and an overcoming or destruction (克/剋, kè) cycle of interactions between the phases.\n\n\"Generating\"\n\n\"Overcoming\"\n\nThere are also two cycles of imbalance, an overacting cycle (cheng) and an insulting cycle (wu).\n\nThe ancient Greek belief in five basic elements, these being earth (γῆ \"ge\"), water (ὕδωρ \"hudor\"), air (ἀήρ \"aer\"), fire (πῦρ \"pur\") and aether (αἰθήρ \"aither\"), dates from pre-Socratic times and persisted throughout the Middle Ages and into the Renaissance, deeply influencing European thought and culture. These five elements are sometimes associated with the five platonic solids.\n\nSicilian philosopher Empedocles (ca. 450 BC) proved (at least to his satisfaction) that air was a separate substance by observing that a bucket inverted in water did not become filled with water, a pocket of air remaining trapped inside. Prior to Empedocles, Greek philosophers had debated which substance was the primordial element from which everything else was made; Heraclitus championed fire, Thales supported water, and Anaximenes plumped for air. Anaximander argued that the primordial substance was not any of the known substances, but could be transformed into them, and they into each other. Empedocles was the first to propose four elements, fire, earth, air, and water. He called them the four \"roots\" (ῥιζὤματα, rhizōmata).\n\nPlato seems to have been the first to use the term \"element (στοιχεῖον, \"stoicheion\")\" in reference to air, fire, earth, and water. The ancient Greek word for element, \"stoicheion\" (from \"stoicheo\", \"to line up\") meant \"smallest division (of a sun-dial), a syllable\", as the composing unit of an alphabet it could denote a letter and the smallest unit from which a word is formed. A similar alphabetic metaphor may be the origin of the equivalent Latin word \"elementum\" (from which the English word comes), possibly based on the names of the letters 'l', 'm', and 'n', though the validity of this idea is debated.\n\nIn his \"On Generation and Corruption\", Aristotle related each of the four elements to two of the four sensible qualities:\n\nA classic diagram has one square inscribed in the other, with the corners of one being the classical elements, and the corners of the other being the properties. The opposite corner is the opposite of these properties, \"hot – cold\" and \"dry – wet\".\n\nAristotle added a fifth element, aether, as the quintessence, reasoning that whereas fire, earth, air, and water were earthly and corruptible, since no changes had been perceived in the heavenly regions, the stars cannot be made out of any of the four elements but must be made of a different, unchangeable, heavenly substance.\n\nThe Neoplatonic philosopher, Proclus, rejected Aristotle's theory relating the elements to the sensible qualities hot, cold, wet, and dry. He maintained that each of the elements has three properties. Fire is sharp, subtle, and mobile while its opposite, earth, is blunt, dense, and immobile; they are joined by the intermediate elements, air and water, in the following fashion:\n\nIn Bön or ancient Tibetan philosophy, the five elemental processes of earth, water, fire, air and space are the essential materials of all existent phenomena or aggregates. The elemental processes form the basis of the calendar, astrology, medicine, psychology and are the foundation of the spiritual traditions of shamanism, tantra and Dzogchen.\n\nTenzin Wangyal Rinpoche states that\nThe names of the elements are analogous to categorised experiential sensations of the natural world. The names are symbolic and key to their inherent qualities and/or modes of action by analogy. In Bön the elemental processes are fundamental metaphors for working with external, internal and secret energetic forces. All five elemental processes in their essential purity are inherent in the mindstream and link the trikaya and are aspects of primordial energy. As Herbert V. Günther states:\nIn the above block quote the trikaya is encoded as: dharmakaya \"god\"; sambhogakaya \"temple\" and nirmanakaya \"house\".\n\nThe elemental system used in Medieval alchemy was developed primarily by the Persian alchemist Jābir ibn Hayyān (Geber). His system consisted of the four classical elements of air, earth, fire, and water, in addition to two philosophical elements: sulphur, characterizing the principle of combustibility, \"the stone which burns\"; and mercury, characterizing the principle of metallic properties. They were seen by early alchemists as idealized expressions of irreducibile components of the universe and are of larger consideration within philosophical alchemy.\n\nThe three metallic principles—sulphur to flammability or combustion, mercury to volatility and stability, and salt to solidity—became the \"tria prima\" of the Swiss alchemist Paracelsus. He reasoned that Aristotle’s four element theory appeared in bodies as three principles. Paracelsus saw these principles as fundamental and justified them by recourse to the description of how wood burns in fire. Mercury included the cohesive principle, so that when it left in smoke the wood fell apart. Smoke described the volatility (the mercurial principle), the heat-giving flames described flammability (sulphur), and the remnant ash described solidity (salt).\n\nThe Islamic philosophers al-Kindi, Avicenna and Fakhr al-Din al-Razi connected the four elements with the four natures heat and cold (the active force), and dryness and moisture (the recipients).\n\nJapanese traditions use a set of elements called the (\"godai\", literally \"five great\"). These five are earth, water, fire, wind/air, and void. These came from Indian Vastu shastra philosophy and Buddhist beliefs; in addition, the classical Chinese elements (, \"wu xing\") are also prominent in Japanese culture, especially to the influential Neo-Confucianists during the medieval Edo period.\n\n\nWestern astrology uses the four classical elements in connection with astrological charts and horoscopes. The twelve signs of the zodiac are divided into the four elements: Fire signs are Aries, Leo and Sagittarius, Earth signs are Taurus, Virgo and Capricorn, Air signs are Gemini, Libra and Aquarius, and Water signs are Cancer, Scorpio, and Pisces.\n\nThe Aristotelian tradition and medieval Alchemy eventually gave rise to modern scientific theories and new taxonomies. By the time of Antoine Lavoisier, for example, a list of elements would no longer refer to classical elements. Some modern scientists see a parallel between the classical elements and the four states of matter: solid, liquid, gas and weakly ionized plasma.\n\nModern science recognizes classes of elementary particles which have no substructure (or rather, particles that are not made of other particles) and composite particles having substructure (particles made of other particles).\n\n\n\n", "id": "6313", "title": "Classical element"}
{"url": "https://en.wikipedia.org/wiki?curid=6314", "text": "Fire (classical element)\n\nFire has been an important part of all cultures and religions from pre-history to modern day and was vital to the development of civilization. It has been regarded in many different contexts throughout history, but especially as a metaphysical constant of the world.\n\nFire is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with the qualities of energy, assertiveness, and passion. In one Greek myth, Prometheus stole \"fire\" from the gods to protect the otherwise helpless humans, but was punished for this charity.\n\nFire was one of many \"archai\" proposed by the Pre-socratics, most of whom sought to reduce the cosmos, or its creation, to a single substance. Heraclitus considered \"fire\" to be the most fundamental of all elements. He believed fire gave rise to the other three elements: \"All things are an interchange for fire, and fire for all things, just like goods for gold and gold for goods.\" He had a reputation for obscure philosophical principles and for speaking in riddles. He described how fire gave rise to the other elements as the: \"upward-downward path\", (), a \"hidden harmony\"  or series of transformations he called the \"turnings of fire\", (), first into \"sea\", and half that \"sea\" into \"earth\", and half that \"earth\" into rarefied \"air\". This is a concept that anticipates both the four classical elements of Empedocles and Aristotle's transmutation of the four elements into one another.\nThis world, which is the same for all, no one of gods or men has made. But it always was and will be: an ever-living fire, with measures of it kindling, and measures going out. \nHeraclitus regarded the soul as being a mixture of fire and water, with fire being the more noble part and water the ignoble aspect. He believed the goal of the soul is to be rid of water and become pure fire: the dry soul is the best and it is worldly pleasures that make the soul \"moist\". He was known as the \"weeping philosopher\" and died of hydropsy, a swelling due to abnormal accumulation of fluid beneath the skin.\n\nHowever, Empedocles of Acragas , is best known for having selected all elements as his \"archai\" and by the time of Plato , the four Empedoclian elements were well established. In the \"Timaeus\", Plato's major cosmological dialogue, the Platonic solid he associated with fire was the tetrahedron which is formed from four triangles and contains the least volume with the greatest surface area. This also makes fire the element with the smallest number of sides, and Plato regarded it as appropriate for the heat of fire, which he felt is sharp and stabbing, (like one of the points of a tetrahedron).\n\nPlato’s student Aristotle did not maintain his former teacher's geometric view of the elements, but rather preferred a somewhat more naturalistic explanation for the elements based on their traditional qualities. Fire the hot and dry element, like the other elements, was an abstract principle and not identical with the normal solids, liquids and combustion phenomena we experience:\n\nAccording to Aristotle, the four elements rise or fall toward their natural place in concentric layers surrounding the center of the earth and form the terrestrial or sublunary spheres.\n\nIn ancient Greek medicine, each of the four humours became associated with an element. Yellow bile was the humor identified with fire, since both were hot and dry. Other things associated with fire and yellow bile in ancient and medieval medicine included the season of summer, since it increased the qualities of heat and aridity; the choleric temperament (of a person dominated by the yellow bile humour); the masculine; and the eastern point of the compass.\n\nIn alchemy the chemical element of sulfur was often associated with fire and its alchemical symbol and its symbol was an upward-pointing triangle. In alchemic tradition, metals are incubated by fire in the womb of the Earth and alchemists only accelerate their development.\n\nAgni is a Hindu and Vedic deity. The word \"agni\" is Sanskrit for fire (noun), cognate with Latin \"ignis\" (the root of English \"ignite\"), Russian \"огонь\" (fire), pronounced \"agon\". Agni has three forms: fire, lightning and the sun.\n\nAgni is one of the most important of the Vedic gods. He is the god of fire and the acceptor of sacrifices. The sacrifices made to Agni go to the deities because Agni is a messenger from and to the other gods. He is ever-young, because the fire is re-lit every day, yet he is also immortal. In Indian tradition Fire is also linked to Surya or the Sun and Mangala or Mars, and with the south-east direction.\n\nPeople born under the astrological signs of Aries, Leo and Sagittarius are thought to have dominant fire personalities. Fire personalities are believed to have good leading qualities and also tend to be enthusiastic, extroverted, rebellious, passionate, brave and valiant.\n\nFire and the other Greek classical elements were incorporated into the Golden Dawn system. Philosophus (4=7) is the elemental grade attributed to fire; this grade is also attributed to the Qabalistic Sephirah Netzach and the planet Venus. The elemental weapon of fire is the Wand. Each of the elements has several associated spiritual beings. The archangel of fire is Michael, the angel is Aral, the ruler is Seraph, the king is Djin, and the fire elementals (following Paracelsus) are called salamanders. Fire is considered to be active; it is represented by the symbol for Leo and it is referred to the lower right point of the pentacle in the Supreme Invoking Ritual of the Pentacle. Many of these associations have since spread throughout the occult community.\n\nFire in Tarot symbolizes conversion or passion. Many references to fire in tarot are related to the usage of fire in the practice of alchemy, in which the application of fire is a prime method of conversion, and everything that touches fire is changed, often beyond recognition. The symbol of fire was a cue pointing towards transformation, the chemical variant being the symbol delta, which is also the classical symbol for fire. Conversion symbolized can be good, for example, refining raw crudities to gold, as seen in The Devil. Conversion can also be bad, as in The Tower, symbolizing a downfall due to anger. Fire is associated with the suit of rods/wands, and as such, represents passion from inspiration. As an element, fire has mixed symbolism because it represents energy, which can be helpful when controlled, but volatile if left unchecked.\n\nFire is one of the five elements that appear in most Wiccan traditions influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn.\n\nThe element of fire shows up in mythological stories all across the world, often in stories related to the sun.\n\nIn East Asia fire is represented by the Vermilion Bird, known as 朱雀 (\"Zhū Què\") in Chinese, \"Suzaku\" in Japanese and Ju-jak (주작, Hanja:朱雀) in Korean. \"Fire\" is represented in the Aztec religion by a flint; to the Native Americans, a mouse; to the Hindu and Islamic faiths, a lightning bolt; to the Scythians, an axe, to the Greeks, an apple-bough; and in Christian iconography, lions and ravens.\n\nIn freemasonry, fire is present, for example, during the ceremony of winter solstice, a symbol also of renaissance and energy. Freemasonry takes the ancient symbolic meaning of fire and recognizes its double nature: creation, light, on the one hand, and destruction and purification, on the other.\n\n\n\n", "id": "6314", "title": "Fire (classical element)"}
{"url": "https://en.wikipedia.org/wiki?curid=6315", "text": "Air (classical element)\n\nAir (also sometimes called Wind) is often seen as a universal power or pure substance. Its fundamental importance to life can be seen in words such as \"aspire\", \"inspire\", \"perspire\" and \"spirit\", all derived from the Latin \"spirare\".\n\nAir is one of the four classical elements in ancient Greek philosophy and science. According to Plato, it is associated with the octahedron; air is considered to be both hot and wet. The ancient Greeks used two words for air: \"aer\" meant the dim lower atmosphere, and \"aether\" meant the bright upper atmosphere above the clouds. Plato, for instance writes that \"So it is with air: there is the brightest variety which we call \"aether\", the muddiest which we call mist and darkness, and other kinds for which we have no name...\" Among the early Greek Pre-Socratic philosophers, Anaximenes (mid-6th century BCE) named air as the \"arche\". A similar belief was attributed by some ancient sources to Diogenes Apolloniates (late 5th century BCE), who also linked air with intelligence and soul (\"psyche\"), but other sources claim that his \"arche\" was a substance between air and fire. Aristophanes parodied such teachings in his play \"The Clouds\" by putting a prayer to air in the mouth of Socrates.\n\nAir was one of many \"archai\" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495-c. 435 BCE) selected four \"archai\" for his four roots: Air, fire, water, and earth. Ancient and modern opinions differ as to whether he identified air by the divine name Hera, Aidoneus or even Zeus. Empedocles’ roots became the four classical elements of Greek philosophy. Plato (427–347 BCE) took over the four elements of Empedocles. In the \"Timaeus\", his major cosmological dialogue, the Platonic solid associated with air is the octahedron which is formed from eight equilateral triangles. This places air between fire and water which Plato regarded as appropriate because it is intermediate in its mobility, sharpness, and ability to penetrate. He also said of air that its minuscule components are so smooth that one can barely feel them.\n\nPlato's student Aristotle (384–322 BCE) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the universe to form the sublunary sphere. According to Aristotle, air is both hot and wet and occupies a place between fire and water among the elemental spheres. Aristotle definitively separated air from aether. For him, aether was an unchanging, almost divine substance that was found only in the heavens, where it formed celestial spheres.\n\nIn ancient Greek medicine, each of the four humours became associated with an element. Blood was the humor identified with air, since both were hot and wet. Other things associated with air and blood in ancient and medieval medicine included the season of spring, since it increased the qualities of heat and moisture; the sanguine temperament (of a person dominated by the blood humour); hermaphrodite (combining the masculine quality of heat with the feminine quality of moisture); and the northern point of the compass.\nThe alchemical symbol for air is an upward-pointing triangle, bisected by a horizontal line.\n\nIn Hinduism, Vayu (Sanskrit वायु ), \"also known as\" Vāta वात, Pavana पवन (meaning the Purifier), or Prāna, is a primary deity, who is the father of Bhima and the spiritual father of Lord Hanuman. As the words for air (Vāyu) or wind (Pavana) it is one of the \"Panchamahābhuta\" the \"five great elements\" in Hinduism. The Sanskrit word 'Vāta' literally means \"blown\", 'Vāyu' \"blower\", and 'Prāna' \"breathing\" (viz. the breath of life, cf. the *an- in 'animate').\n\nAir is not one of the traditional five Chinese classical elements. Nevertheless, the ancient Chinese concept of \"Qi\" or \"chi\" is believed to be close to that of air. Qi (; spelled \"qì\" in Pinyin romanization and \"ch'i4\" in Wade-Giles) or ki (in Japanese romanization), is a fundamental concept of traditional Chinese culture. Qi is believed to be part of every living thing that exists, as a kind of \"life force\" or \"spiritual energy\". It is frequently translated as \"energy flow\", or literally as \"air\" or \"breath\". (For example, \"tiānqì\", literally \"sky breath\", is the ordinary Chinese word for \"weather\"). In Mandarin Chinese it is pronounced something like \"chee\" in English, but the tongue position is different. (See .) The concept of qi is often reified, however no scientific evidence supports its existence.\n\nThe element air also appears as a concept in the Buddhist philosophy which has an ancient history in China.\n\nSome Western modern occultists equate the Chinese classical element of metal with \"air\", others with wood due to the elemental association of wind and wood in the bagua.\n\nPeople born under the astrological signs of Gemini, Libra and Aquarius are thought to have dominant air personalities. Air personalities tend to be kind, intellectual, communicative and social; however, they can also be selfish, superficial, vicious and insensitive to other people's emotions.\n\nThe Hermetic Order of the Golden Dawn, founded in 1888, incorporates air and the other Greek classical elements into its teachings. The elemental weapon of air is the dagger which must be painted yellow with magical names and sigils written upon it in violet. Each of the elements has several associated spiritual beings. The archangel of air is Raphael, the angel is Chassan, the ruler is Aral, the king is Paralda, and the air elementals (following Paracelsus) are called sylphs. Air is considerable and it is referred to the upper left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\n\nIn the Golden Dawn and many other magical systems, each element is associated with one of the cardinal points and is placed under the care of guardian Watchtowers. The Watchtowers derive from the Enochian system of magic founded by Dee. In the Golden Dawn, they are represented by the Enochian elemental tablets. Air is associated with the east, which is guarded by the First Watchtower.\n\nAir is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism.\n\nEnlil was the god of air in ancient Sumer. Shu was the ancient Egyptian deity of air and the husband of Tefnut, goddess of moisture. He became an emblem of strength by virtue of his role in separating Nut from Geb. Shu played a primary role in the Coffin Texts, which were spells intended to help the deceased reach the realm of the afterlife safely. On the way to the sky, the spirit had to travel through the air as one spell indicates: \"I have gone up in Shu, I have climbed on the sunbeams.\"\n\n\n\n", "id": "6315", "title": "Air (classical element)"}
{"url": "https://en.wikipedia.org/wiki?curid=6316", "text": "Water (classical element)\n\nWater is one of the elements in ancient Greek philosophy, in the Asian Indian system \"Panchamahabhuta\", and in the Chinese cosmological and physiological system \"Wu Xing\". In contemporary esoteric traditions, it is commonly associated with the qualities of emotion and intuition.\n\nWater was one of many \"archai\" proposed by the Pre-socratics, most of whom tried to reduce all things to a single substance. However, Empedocles of Acragas (c. 495 – c. 435 BC) selected four archai for his four roots: air, fire, water and earth. Empedocles roots became the four classical elements of Greek philosophy. Plato (427–347 BC) took over the four elements of Empedocles. In the Timaeus, his major cosmological dialogue, the Platonic solid associated with water is the icosahedron which is formed from twenty equilateral triangles. This makes water the element with the greatest number of sides, which Plato regarded as appropriate because water flows out of one's hand when picked up, as if it is made of tiny little balls.\n\nPlato’s student Aristotle (384–322 BC) developed a different explanation for the elements based on pairs of qualities. The four elements were arranged concentrically around the center of the Universe to form the sublunary sphere. According to Aristotle, water is both cold and wet and occupies a place between air and earth among the elemental spheres.\n\nIn ancient Greek medicine, each of the four humours became associated with an element. Phlegm was the humor identified with water, since both were cold and wet. Other things associated with water and phlegm in ancient and medieval medicine included the season of Winter, since it increased the qualities of cold and moisture; the phlegmatic temperament, the feminine, the brain and the western point of the compass.\n\nIn alchemy, the chemical element of mercury was often associated with water and its alchemical symbol was a downward-pointing triangle.\n\nAp (') is the Vedic Sanskrit term for water, in Classical Sanskrit occurring only in the plural is not an element.v, ' (sometimes re-analysed as a thematic singular, '), whence Hindi '. The term is from PIE \"hap\" water.\n\nIn Hindu philosophy, the term refers to \nwater as an element, one of the \"Panchamahabhuta,\" or \"five great elements\". In Hinduism, it is also the name of the deva, a personification of water, (one of the Vasus in most later Puranic lists). The element water is also associated with Chandra or the moon and Shukra, who represent feelings, intuition and imagination.\n\nPeople born under the astrological signs of Cancer, Scorpio and Pisces are thought to have dominant water personalities. Water personalities tend to be emotional, deep, nurturing, sympathetic, empathetic, imaginative and intuitive.\n\nWater and the other Greek classical elements were incorporated into the Golden Dawn system. The elemental weapon of water is the cup. Each of the elements has several associated spiritual beings. The archangel of water is Gabriel, the angel is Taliahad, the ruler is Tharsis, the king is Nichsa and the water elementals are called Ondines. It is referred to the upper right point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\n\nWater is one of the five elements that appear in most Wiccan traditions. Wicca in particular was influenced by the Golden Dawn system of magic and Aleister Crowley's mysticism, which was in turn inspired by the Golden Dawn.\n\n\n", "id": "6316", "title": "Water (classical element)"}
{"url": "https://en.wikipedia.org/wiki?curid=6317", "text": "Earth (classical element)\n\nEarth is one of the classical elements, in some systems numbering four along with air, fire, and water.\n\nEarth is one of the four classical elements in ancient Greek philosophy and science. It was commonly associated with qualities of heaviness, matter and the terrestrial world. Due to the hero cults, and chthonic underworld deities, the element of \"earth\" is also associated with the sensual aspects of both life and death in later occultism.\n\nEmpedocles of Acragas proposed four \"archai\" by which to understand the cosmos: \"fire\",\" air\", \"water\", and \"earth\". Plato believed the elements were geometric forms (the platonic solids) and he assigned the cube to the element of \"earth\" in his dialogue \"Timaeus\". Aristotle, (384–322 BCE), believed \"earth\" was the heaviest element, and his theory of \"natural place\" suggested that any \"earth–laden\" substances, would fall quickly, straight down, toward the center of the \"cosmos\".\n\nIn Classical Greek and Roman myth, various goddesses represented the Earth, seasons, crops and fertility, including Demeter and Persephone; Ceres; the Horae (goddesses of the seasons), and Proserpina; and Hades (Pluto) who ruled the souls of dead in the Underworld.\n\nIn ancient Greek medicine, each of the four humours became associated with an element. Black bile was the humor identified with earth, since both were cold and dry. Other things associated with earth and black bile in ancient and medieval medicine included the season of fall, since it increased the qualities of cold and aridity; the melancholic temperament (of a person dominated by the black bile humour); the feminine; and the southern point of the compass.\n\nIn alchemy, earth was believed to be primarily dry, and secondarily cold, (as per Aristotle). Beyond those classical attributes, the chemical substance salt, was associated with earth and its alchemical symbol was a downward-pointing triangle, bisected by a horizontal line.\n\nPrithvi (Sanskrit: ', also ') is the Hindu \"earth\" and mother goddess. According to one such tradition, she is the personification of the Earth itself; according to another, its actual mother, being \"Prithvi Tattwa\", the essence of the element earth.\n\nAs \"Prithvi Mata\", or \"Mother Earth\", she contrasts with \"Dyaus Pita\", \"father sky\". In the Rigveda, \"earth\" and sky are frequently addressed as a duality, often indicated by the idea of two complementary \"half-shells.\" In addition, the element Earth is associated with Budha or Mercury who represents communication, business, mathematics and other practical matters.\n\nPeople born under the astrological signs of Taurus, Virgo and Capricorn are thought to have dominant earth personalities. Earth personalities are characterized in this belief system as calm, practical, hard-working, brave, smart, wise, stable and patient; however, they can also be stubborn, possessive, nearsighted and harsh.\n\nEarth and the other Greek classical elements were incorporated into the Golden Dawn system. Zelator is the elemental grade attributed to earth; this grade is also attributed to the Qabbalistic sphere Malkuth. The elemental weapon of earth is the Pentacle. Each of the elements has several associated spiritual beings. The archangel of earth is Uriel, the angel is Phorlakh, the ruler is Kerub, the king is Ghob, and the earth elementals (following Paracelsus) are called gnomes. Earth is considered to be passive; it is represented by the symbol for Taurus, and it is referred to the lower left point of the pentagram in the Supreme Invoking Ritual of the Pentagram. Many of these associations have since spread throughout the occult community.\n\nIt is sometimes represented by its Tattva or by a downward pointing triangle with a horizontal line through it.\n\nEarth is one of the five elements that appear in most Wiccan and Pagan traditions. Wicca in particular was influenced by the Golden Dawn system of magic, and Aleister Crowley's mysticism which was in turn inspired by the Golden Dawn.\n\nIn East Asia, metal is sometimes seen as the equivalent of \"earth\" and is represented by the White Tiger (Chinese constellation), known as 白虎 (\"Bái Hǔ\") in Chinese, \"Byakko\" in Japanese, \"Bạch Hổ\" in Vietnamese and \"Baekho\" (백호, Hanja:白虎) in Korean. \"Earth\" is represented in the Aztec religion by a house; to the Hindus, a lotus; to the Scythians, a plough; to the Greeks, a wheel; and in Christian iconography; bulls and birds.\n\n\n", "id": "6317", "title": "Earth (classical element)"}
{"url": "https://en.wikipedia.org/wiki?curid=6319", "text": "Blue Jam\n\nBlue Jam was an ambient radio comedy programme created and directed by Chris Morris. It aired on BBC Radio 1 in the early hours of the morning from 1997 to 1999.\n\nThe programme gained cult status due to its unique mix of surreal monologue, music, synthesised voices, heavily edited broadcasts and recurring sketches. It featured vocal performances of Kevin Eldon, Julia Davis, Mark Heap, David Cann and Amelia Bullmore, with Morris himself delivering disturbing monologues, one of which was revamped and made into the BAFTA-winning short film \"My Wrongs #8245–8249 & 117\". Writers who contributed to the programme included Graham Linehan, Arthur Mathews, Peter Baynham, David Quantick, Jane Bussmann, Robert Katz and the cast.\n\nThe programme was adapted into the TV series \"Jam\", which aired in 2000. All episodes of \"Blue Jam\" are currently available for streaming and download on the Internet Archive.\n\nOn his inspiration for making the show, Morris commented: \"It was so singular, and it came from a mood, quite a desolate mood. I had this misty, autumnal, boggy mood anyway, so I just went with that\".\n\nEach episode opened (and closed) with a short spoken introduction (delivered by Morris) describing, in surreal, broken language, various bizarre feelings and situations (for example: \"when you sick so sad you cry, and in crying cry a whole leopard from your eye\"), set to ambient music interspersed with short clips of other songs and sounds. The introduction would always end with \"welcome in Blue Jam\", inviting the listener, who is presumably experiencing such feelings, to get lost in the program. (This format was replicated in the television adaptation \"Jam\", often reusing opening monologues from series 3 of the radio series.)\n\n\nMorris included a series of 'radio stings', bizarre sequences of sounds and prose as a parody of modern DJs' own soundbites and self-advertising pieces. Each one revolves around a contemporary DJ, such as Chris Moyles, Jo Whiley and Mark Goodier, typically involving each DJ dying in a graphic way or going mad in some form – for example, Chris Moyles covering himself in jam and hanging himself from the top of a building.\n\nThree series were produced, with a total of eighteen episodes. All episodes were originally broadcast weekly on BBC Radio 1. Series 1 was broadcast from 14 November to 19 December 1997; series 2 was broadcast from 27 March to 1 May 1998; and series 3 broadcast from 21 January to 25 February 1999.\n\n\nThe first five episodes of series 1 of \"Blue Jam\" were repeated by BBC Radio 4 Extra in February and March 2014, and series 2 was rebroadcast in December.\n\n\"Blue Jam\" features songs, generally of a downtempo nature, interspersed between (and sometimes during) sketches. Artists featured includes Massive Attack, Air, Morcheeba, The Chemical Brothers, Björk, Aphex Twin, Everything But the Girl and Dimitri from Paris, as well as various non-electronic artists including Sly and the Family Stone, Serge Gainsbourg, The Cardigans and Eels.\n\n\"Blue Jam\" was favourably reviewed on several occasions by \"The Guardian\" and also received a positive review by \"The Independent\".\n\nDigital Spy wrote in 2014: \"It's a heady cocktail that provokes an odd, unsettling reaction in the listener, yet \"Blue Jam\" is still thumpingly and frequently laugh-out-loud hilarious.\" \"Hot Press\" called it \"as odd as comedy gets\".\n\nA CD of a number of \"Blue Jam\" sketches was released on 23 October 2000 by record label Warp. Although the CD claims to have 22 tracks, the last one, \"www.bishopslips.com\", is a reference to the \"Bishopslips\" sketch. Most of the sketches on the CD were remade for \"Jam\".\n\n\n\n\"Blue Jam\" was later made for television and broadcast on Channel 4 as \"Jam\". It utilised unusual editing techniques to achieve an unnerving ambience in keeping with the radio show. Many of the sketches were lifted from the radio version, even to the extent of simply setting images to the radio soundtrack. A subsequent \"re-mixed\" airing, called \"Jaaaaam\" was even more extreme in its use of post-production gadgetry, often heavily distorting the footage.\n\n\"Blue Jam\" shares parallels with early editions of a US public radio show \"Work in Progress\" from the mid-1980s, that Joe Frank did on the NPR affiliate station, KCRW, in Santa Monica, California.\n\n", "id": "6319", "title": "Blue Jam"}
{"url": "https://en.wikipedia.org/wiki?curid=6321", "text": "Channel 4\n\nChannel 4 is a British public-service television broadcaster that began transmission on 2 November 1982. Although largely commercially self-funded, it is ultimately publicly owned; originally a subsidiary of the Independent Broadcasting Authority (IBA), the station is now owned and operated by Channel Four Television Corporation, a public corporation of the Department for Culture, Media & Sport, which was established in 1990 and came into operation in 1993. With the conversion of the Wenvoe transmitter group in Wales to digital on 31 March 2010, Channel 4 became a UK-wide TV channel for the first time.\n\nThe channel was established to provide a fourth television service to the United Kingdom in addition to the licence-funded BBC's two services, BBC One and BBC Two and the single commercial broadcasting network, ITV.\n\nBefore Channel 4 and S4C, Britain had three terrestrial television services: BBC1, BBC2, and ITV. The Broadcasting Act 1980 began the process of adding a fourth, and Channel 4, along with its Welsh counterpart, was formally created by an Act of Parliament in 1982. After some months of test broadcasts, it began scheduled transmissions on 2 November 1982.\n\nThe notion of a second commercial broadcaster in the United Kingdom had been around since the inception of ITV in 1954 and its subsequent launch in 1955; the idea of an \"ITV2\" was long expected and pushed for. Indeed, television sets sold throughout the 1970s and early 1980s had a spare channel called \"ITV/IBA 2\". Throughout ITV's history and until Channel 4 finally became a reality, a perennial dialogue existed between the GPO, the government, the ITV companies and other interested parties, concerning the form such an expansion of commercial broadcasting would take. It was most likely politics which had the biggest impact in leading to a delay of almost three decades before the second commercial channel became a reality. With what can crudely be summed up as a clash of ideologies between an expansion of ITV's commercial ethos and a public service approach more akin to the BBC, it was ultimately something of a compromise that eventually led to the formation of Channel 4 as launched in 1982.\n\nOne clear benefit of the \"late arrival\" of the channel was that its frequency allocations at each transmitter had already been arranged in the early 1960s, when the launch of an ITV2 was highly anticipated. This led to very good coverage across most of the country and few problems of interference with other UK-based transmissions; a stark contrast to the problems associated with Channel 5's launch fourteen and a half years later.\n\nAt the time the fourth service was being considered, a movement in Wales lobbied for the creation of dedicated service that would air Welsh-language programmes, then only catered for at 'off peak' times on BBC Wales and HTV. The campaign was taken so seriously by Gwynfor Evans, former president of Plaid Cymru, that he threatened the government with a hunger strike were it not to honour the plans.\n\nThe result was that Channel 4 as seen by the rest of the United Kingdom would be replaced in Wales by \"Sianel Pedwar Cymru (S4C)\" (\"Channel Four Wales\"). Operated by a specially created authority, S4C would air programmes in Welsh made by HTV, the BBC, or independent companies. Initially limited frequency space meant that Channel 4 could not be broadcast alongside S4C, though some Channel 4 programmes would be aired at less popular times on the Welsh variant, a practice that carried on up until the closure of S4C's analogue transmissions in 2010 when S4C became a fully Welsh channel.\n\nSince then, carriage on digital cable, satellite and digital terrestrial has introduced Channel 4 to Welsh homes where it is now universally available.\n\nThe first voice heard on Channel 4's opening day of Tuesday 2 November 1982 was that of continuity announcer Paul Coia who said:\n\nFollowing the announcement, the channel headed into a montage of clips from its programmes set to the station's signature tune, \"Fourscore\", written by Lord David Dundas, which would form the basis of the station's jingles for its first decade. The first programme to air on the channel was the teatime game show \"Countdown\", at 16:45 produced by Yorkshire Television. The first person to be seen on Channel 4 was Richard Whiteley with Ted Moult being the second. The first woman on the channel, contrary to popular belief, was not Carol Vorderman and was a lexicographer only ever identified as Mary. Whiteley opened the show with the words:\n\nOn its first day, Channel 4 also broadcast controversial soap opera \"Brookside\", which ran until 2003.\n\nOn its launch, Channel 4 committed itself to providing an alternative to the existing channels, an agenda in part set out by its remit which required the provision of programming to minority groups.\n\nIn step with its remit, the channel became well received both by minority groups and the arts and cultural worlds during this period, especially under founding chief executive Jeremy Isaacs, where the channel gained a reputation for programmes on the contemporary arts. Channel 4 co-commissioned Robert Ashley's ground-breaking television opera \"Perfect Lives\", which it premiered over several episodes in 1984. The channel often did not receive mass audiences for much of this period, however, as might be expected for a station focusing on minority interest. Channel 4 for many years had a poorer quality signal compared to other channels.\n\nChannel 4 also began the funding of independent films, such as the Merchant-Ivory docudrama \"The Courtesans of Bombay\", during this time.\n\nIn 1992, Channel 4 also faced its first libel case by Jani Allan, a South African journalist, who objected to her representation in the documentary \"The Leader, His Driver and the Driver's Wife\".\n\nAfter control of the station passed from the Channel Four Television Company to the Channel Four Television Corporation in 1993, a shift in broadcasting style took place. Instead of aiming for the fringes of society, it began to focus on the edges of the mainstream, and the centre of the mass market itself. It began to show many US programmes in peak viewing time, far more than it had previously done. It gave such shows as \"Friends\" and \"ER\" their UK premières.\n\nIn the early 2000s, Channel 4 began broadcasting reality formats such as \"Big Brother\" and obtained the rights to broadcast mass appeal sporting events like cricket and horse racing. This new direction increased ratings and revenues.\n\nIn addition, the corporation launched a number of new television channels through its new 4Ventures offshoot, including Film4, At the Races, E4 and More4.\n\nPartially in reaction to its new 'populist' direction, the Communications Act 2003 directed the channel to demonstrate innovation, experimentation and creativity, appeal to the tastes and interests of a culturally diverse society and to include programmes of an educational nature which exhibit a distinctive character.\n\nOn 31 December 2004, Channel 4 launched a new look and new idents in which the logo is disguised as different objects and the 4 can be seen in an angle.\n\nUnder the leadership of Freeview founder Andy Duncan, 2005 saw a change of direction for Channel 4's digital channels. Channel 4 made E4 free-to-air on digital terrestrial television, and launched a new free-to-air digital channel called More4. By October, Channel 4 had joined the Freeview consortium. By July 2006, Film4 had also become a 'free to air' and restarted broadcasting on digital terrestrial.\n\nVenturing into radio broadcasting, 2005 saw Channel 4 purchase 51 per cent of shares in the now defunct Oneword radio station with UBC Media holding on to the remaining shares. New programmes such as the weekly, half-hour \"The Morning Report\" news programme were among some of the new content Channel 4 provided for the station, with the name 4Radio being used. As of early 2009, however, Channel 4's future involvement in radio remained uncertain.\n\nOn 2 November 2007, the station celebrated its twenty-fifth birthday. It showed the first episode of \"Countdown\", an anniversary \"Countdown\" special, as well as a special edition of \"The Big Fat Quiz\" and using the original multicoloured 1982–1996 blocks logo on presentation and idents using the Fourscore jingle throughout the day.\n\nIn November 2009, Channel 4 launched a week of 3D television, broadcasting selected programmes each night using stereoscopic ColorCode 3D technology. The accompanying 3D glasses were distributed through Sainsbury's supermarkets.\n\nOn 29 September 2015, Channel 4 revamped its presentation for a fifth time; the new branding downplays the \"4\" logo from most on-air usage, and instead utilises various variations of the shapes which comprise the logo. The full logo is still occasionally used, but primarily for print advertising. Four new idents, filmed by Jonathan Glazer, are used to introduce programmes and feature various elements of the blocks within them. A fifth ident, in which hundreds of the blocks form what appears to be a clock face, is used to introduce the Channel 4 News.\n\nChannel 4 has raised concerns over how it might finance its public service obligations after digital switch-over. However, some certainty lies in the announcement in April 2006 that Channel 4's digital switch-over costs would be paid for by licence fee revenues.\n\nOn 28 March 2007, Channel 4 announced plans to launch a music channel \"4Music\" as a joint venture with British media company EMAP which would include carriage on the Freeview platform. On 15 August 2008, 4Music was launched across the UK. Recently, Channel 4 have announced interest in launching a high-definition version of Film4 on Freeview, to coincide with the launch of Channel 4 HD, however the fourth HD slot was given to Channel 5 instead. Channel 4 has since acquired a 50% stake in EMAP's TV business for a reported £28 million.\n\nChannel 4 was considered for privatisation by the governments of Margaret Thatcher, John Major and Tony Blair. As of 2016 the future of the channel is again being looked into by the government, with analysts suggesting several options for the channel's future.\n\nChannel 4 was established with, and continues to hold, a remit of public service obligations which it must fulfil. The remit changes periodically, as dictated by various broadcasting and communications acts, and is regulated by the various authorities Channel 4 has been answerable to; originally the IBA, then the ITC and now Ofcom.\n\nThe preamble of the remit as per the Communications Act 2003 states that:\n\"The public service remit for Channel 4 is the provision of a broad range of high quality and diverse programming which, in particular:\nThe remit also involves an obligation to provide programming for schools, and a substantial amount of programming produced outside of Greater London.\n\nChannel 4 was carried from its beginning on analogue terrestrial, which was practically the only means of television broadcast in the United Kingdom at the time. It continued to be broadcast through these means until the changeover to digital terrestrial television in the United Kingdom was complete. Since 1998, it has been universally available on digital terrestrial, and the Sky platform (initially encrypted, though encryption was dropped on 14 April 2008 and is now free of charge and available on the Freesat platform) as well as having been available from various times in various areas, on analogue and digital cable networks.\n\nDue to its special status as a public service broadcaster with a specific remit, it is afforded free carriage on the terrestrial platforms, in contrast with other broadcasters such as ITV.\n\nChannel 4 is also available outside the United Kingdom where it is widely available in Ireland, Switzerland and Belgium. Here viewers receive the channel either on basic cable subscription services or premium services.\n\nChannel 4 Ulster has been available in large parts of Ireland, especially border counties which have been able to receive terrestrial transmissions from Northern Ireland. Channel 4 Ulster has been carried on Irish cable networks since the station went on the air in 1982. \nS4C has been available as a terrestrial transmission from Wales in southern counties such as Cork, Waterford, Wexford and Wicklow.\n\nFrom 4 December 2006 Channel 4 was officially available to Sky viewers in Ireland; some programmes, mainly imports, are not aired on this channel variant, due to Channel 4 not owning the relevant broadcast rights within the country.\n\nChannel 4 allowed Internet users in the United Kingdom to watch Channel 4 live on the Internet. However some programmes (mostly international imports) were not shown and this service no longer exists. Channel 4 is also provided by Virgin Mobile's DAB mobile TV service which has the same restrictions as the Internet live stream had. Channel 4 is also carried by the Internet TV service TVCatchup and was previously carried by Zattoo until the operator removed the channel from its platform.\n\nChannel 4 also makes some of its programming available \"on demand\" via cable and the Internet through All 4.\n\nDuring the station's formative years, funding came from the ITV companies in return for their right to sell advertisements in their region on the fourth channel.\n\nNowadays it pays for itself in much the same way as most privately run commercial stations, i.e. through the sale of on-air advertising, programme sponsorship, and the sale of any programme content and merchandising rights it owns, such as overseas sales and video sales. For example, as of 2012 its total revenues were £925 million with 91% derived from sale of advertising. It also has the ability to subsidise the main network through any profits made on the corporation's other endeavours, which have in the past included subscription fees from stations such as E4 and Film4 (now no longer subscription services) and its 'video-on-demand' sales. In practice, however, these other activities are loss-making, and are subsidised by the main network. According to Channel 4's last published accounts, for 2005, the extent of this cross-subsidy was some £30 million.\n\nThe change in funding came about under the Broadcasting Act 1990 when the new corporation was afforded the ability to fund itself. Originally this arrangement left a 'safety net' guaranteed minimum income should the revenue fall too low, funded by large insurance payments made to the ITV companies. Such a subsidy was never required, however, and these premiums were phased out by the government in 1998. After the link with ITV was cut, the cross-promotion which had existed between ITV and Channel 4 also ended.\n\nIn 2007 due to severe funding difficulties, the channel sought government help and was granted a payment of £14 million over a six-year period. The money would have come from the television licence fee and would have been the first time that money from the licence fee had been given to any broadcaster other than the BBC. The plan was scrapped by The Secretary of State for Culture, Media and Sport, Andy Burnham, ahead of \"broader decisions about the future framework of public service broadcasting\".\nThe broadcasting regulator Ofcom released their review in January 2009 in which they suggested that Channel 4 would preferably be funded by \"partnerships, joint ventures or mergers\".\n\nChannel 4 is a \"publisher-broadcaster\", meaning that it commissions or \"buys\" all of its programming from companies independent of itself, and was the first broadcaster in the United Kingdom to do so on any significant scale; such commissioning is a stipulation which is included in its licence to broadcast. This had the consequence of starting an industry of production companies that did not have to rely on owning an ITV licence to see their programmes air, though since Channel 4, external commissioning has become regular practise on the numerous stations that have launched since, as well as on the BBC and in ITV (where a quota of 25% minimum of total output has been imposed since the 1990 Broadcasting Act came into force). Although it was the first British broadcaster to commission all of its programmes from third parties, Channel 4 was the last terrestrial broadcaster to outsource its transmission and playout operations (to Red Bee Media), after 25 years in-house.\n\nThe requirement to obtain all content externally is stipulated in its licence. Additionally, Channel 4 also began a trend of owning the copyright and distribution rights of the programmes it aired, in a manner that is similar to the major Hollywood studios' ownership of television programmes that they did not directly produce. Thus, although Channel 4 does not produce programmes, many are seen as belonging to it.\n\nIt was established with a specific intention of providing programming to groups of minority interests, not catered for by its competitors, which at the time were only the BBC and ITV.\n\nChannel 4 also pioneered the concept of \"stranded programming\", where seasons of programmes following a common theme would be aired and promoted together. Some would be very specific, and run for a fixed period of time; the \"4 Mation\" season, for example, showed innovative animation. Other, less specific strands, were (and still are) run regularly, such as \"T4\", a strand of programming aimed at teenagers, on weekend mornings (and weekdays during school/college holidays); \"Friday Night Comedy\", a slot where the channel would pioneer its style of comedy commissions, \"4Music\" (now a separate channel) and \"4Later\", an eclectic collection of offbeat programmes transmitted to a cult audience in the early hours of the morning.\n\nIn its earlier years, \"Red Triangle\" was the name given to the airing of certain risqué art-house films due to the use of a red triangle DOG in the upper right of the screen, dubbed as being pornographic by many of Channel 4's critics, while general broadcasting of films on the station for many years came under the banner of \"Film on Four\" prior to the launch of the \"FilmFour\" brand and station in the late 1990s.\n\nThe following is a list of the ten most watched shows on Channel 4 since launch, based on Live +7 data supplied by BARB, and archival data published by Channel 4.\nDuring the station's early days, the screenings of innovative short one-off comedy films produced by a rotating line-up of alternative comedians went under the title of \"The Comic Strip Presents\". \"The Tube\" and \"Friday Night Live\" also launched the careers of a number of comedians and writers. Channel 4 broadcast a number of popular American imports including \"Roseanne\", \"Friends\", \"Sex and the City\", \"South Park\" and \"Will & Grace\". Other significant US acquisitions include \"The Simpsons\", for which the station was reported to have paid £700,000 per episode for the terrestrial television rights.\n\nIn April 2010, Channel 4 became the first UK broadcaster to adapt the American comedy institution of roasting to British television, with \"A Comedy Roast\".\n\nIn 2010, Channel 4 organised \"Channel 4's Comedy Gala\", a comedy benefit show in aid of Great Ormond Street Children's Hospital. With over 25 comedians appearing, it billed it as \"the biggest live stand up show in United Kingdom history\". Filmed live on 30 March in front of 14,000 at The O2 Arena in London, it was broadcast on 5 April. This has continued to 2016.\n\nChannel 4 has a strong reputation for history programmes and real-life documentaries. It has also courted controversy, for example by broadcasting live the first public autopsy in the UK for 170 years, carried out by Gunther von Hagens in 2002, or the 2003 one-off stunt \"Derren Brown Plays Russian Roulette Live\".\n\nIts critically acclaimed news service, \"Channel 4 News\", is supplied by ITN whilst its long-standing investigative documentary series, \"Dispatches\", attracts perennial media attention.\n\nFourDocs is an online documentary site provided by Channel 4. It allows viewers to upload their own documentaries to the site for others to view. It focuses on documentaries of between 3 and 5 minutes. The website also includes an archive of classic documentaries, interviews with documentary filmmakers and short educational guides to documentary-making. It won a Peabody Award in 2006. The site also includes a strand for documentaries of under 59 seconds, called 'Microdocs'.\n\nChannel 4 is obliged to carry schools programming as part of its remit and licence.\n\nSince 1957 ITV had produced schools programming, which became an obligation. In 1987, five years after the station was launched, the IBA afforded ITV free carriage of these programmes during Channel 4's then-unused weekday morning hours. This arrangement allowed the ITV companies to fulfil their obligation to provide schools programming, whilst allowing ITV itself to broadcast regular programmes complete with advertisements. During the times in which schools programmes were aired Central Television provided most of the continuity with play-out originating from Birmingham.\n\nAfter the restructuring of the station in 1993, ITV's obligations to provide such programming on Channel 4's airtime passed to Channel 4 itself, and the new service became Channel 4 Schools, with the new corporation administering the service and commissioning its programmes, some still from ITV, others from independent producers.\n\nIn March 2008, the 4Leaning interactive new media commission slabovia.tv was launched. The Slabplayer online media player showing TV shows for teenagers was launched on 26 May 2008.\n\nSee also: Channel 4 Learning site.\n\nThe schools programming has always had elements different to its normal presentational package. In 1993, the Channel 4 Schools idents featured famous people in one category, with light shining on them in front of an industrial looking setting supplemented by instrumental calming music. This changed in 1996 with the circles look to numerous children touching the screen, forming circles of information then picked up by other children. The last child would produce the channel 4 logo in the form of three vertical circles, with another in the middle and to the left containing the Channel 4 logo.\n\nA present feature of presentation was a countdown sequence featuring, in 1993 a slide with the programme name, and afterwards an extended sequence matching the channel branding. In 1996, this was an extended ident with timer in top left corner, and in 1999 following the adoption of the squares look, featured a square with timer slowly make its way across the right of the screen with people learning and having fun while doing so passing across the screen. It finished with the Channel 4 logo box on the right of the screen and the name 'Channel 4 Schools' being shown. This was adapted in 2000 when the services name was changed to '4Learning'. In 2001, this was altered to various scenes from classrooms around the world and different parts of school life. The countdown now flips over from the top, right, bottom and left with each second, and ends with four coloured squares, three of which are aligned vertically to the left of the Channel 4 logo, with is contained inside the fourth box. The tag 'Learning' is located directly beneath the logo. The final countdown sequence lasted between 2004 and 2005 and featured a background video of current controversial issues, overlaid with upcoming programming information. the video features people in the style of graffiti enacting the overuse of CCTV cameras, fox hunting, computer viruses and pirate videos, relationships, pollution of the seas and violent lifestyles. Following 2005, no branded section has been used for Schools programmes.\n\nNumerous genres of film-making – such as comedy, drama, documentary, adventure/action, romance and horror/thriller – are represented in the channel's schedule. From the launch of Channel 4 until 1998, film presentations on C4 would often be broadcast under the \"Film on Four\" banner.\n\nSince 1 November 1998, Channel 4 has had a digital subsidiary channel dedicated to the screening of films. This channel launched as a paid subscription channel under the name \"FilmFour\", and was relaunched in July 2006 as a free-to-air channel under the current name of \"Film4\". The Film4 channel carries a wide range of film productions, including acquired and Film4-produced projects. Channel 4's general entertainment channels E4 and More4 also screen feature films at certain points in the schedule as part of their content mix.\n\nA season of television programmes about masturbation, called \"Wank Week\", was to be broadcast in the United Kingdom by Channel 4 in March 2007. The first show was about a Masturbate-a-thon, a public mass masturbation event, organised to raise money for the sexual health charity Marie Stopes International. Another film would have focused on compulsive male masturbators and a third was to feature the sex educator Dr Betty Dodson.\n\nThe series came under public attack from senior television figures, and was pulled amid claims of declining editorial standards and controversy over the channel's public service broadcasting credentials. However, the films it was meant to showcase may yet be broadcast by the channel at a later date.\n\nOn 8 March 2007 Channel 4 screened the highly controversial documentary \"The Great Global Warming Swindle\". The programme states that global warming is \"a lie\" and \"the biggest scam of modern times\". The programme's accuracy has been disputed on multiple points and several commentators have criticised it for being one-sided, noting that the mainstream position on global warming is supported by the scientific academies of the major industrialised nations\nThere were 246 complaints to Ofcom as of 25 April 2007, including the complaints that the programme falsified data. The programme has been criticised by scientists and scientific organisations and various scientists which participated in the documentary claimed their views had been distorted.\n\n\"Against Nature\": An earlier controversial Channel 4 programme made by Martin Durkin which was also critical of the environmental movement and was charged by the Independent Television Commission of the UK for misrepresenting and distorting the views of interviewees by selective editing.\n\n\"The Greenhouse Conspiracy\": An earlier Channel 4 documentary broadcast on 12 August 1990, as part of the \"Equinox\" series, in which similar claims were made. Three of the people interviewed (Lindzen, Michaels and Spencer) were also interviewed in \"The Great Global Warming Swindle\".\n\nIn the Christmas address of 2008, a Channel 4 tradition since 1993, Iranian President Mahmoud Ahmadinejad made a thinly veiled attack on the United States by claiming that Christ would have been against \"bullying, ill-tempered and expansionist powers\".\n\nA spokeswoman for the FCO said: “President Ahmadinejad has, during his time in office, made a series of appalling anti-Semitic statements. The British media are rightly free to make their own editorial choices, but this invitation will cause offence and bemusement not just at home but among friendly countries abroad.”\n\nOn 15 August 2013, Channel 4 aired a 45-minute documentary on One Direction and their fans dubbed as \"Directioners\". Following the airing, fans from all over the world, went on social media in rage against the documentary arguing that this was not them.\n\n4Talent is an editorial branch of Channel 4's commissioning wing, which co-ordinates Channel 4's various talent development schemes for film, television, radio, new media and other platforms and provides a showcasing platform for new talent.\n\nThere are bases in London, Birmingham, Glasgow and Belfast, serving editorial hubs known respectively as 4Talent National, 4Talent Central England, 4Talent Scotland and 4Talent Northern Ireland. These four sites include features, profiles and interviews in text, audio and video formats, divided into five zones: TV, Film, Radio, New Media and Extras, which covers other arts such as theatre, music and design. 4Talent also collates networking, showcasing and professional development opportunities, and runs workshops, masterclasses, seminars and showcasing events across the UK.\n\n4Talent has an active presence on social networking site Facebook.\n\nSee also 4Talent.\n\n\"4Talent magazine\" is the creative industries magazine from 4Talent, which launched in 2005 (originally titled TEN4 magazine) under the editorship of Dan Jones. \"4Talent Magazine\" is currently edited by Nick Carson. Other staff include deputy editor Catherine Bray and production editor Helen Byrne. The magazine covers rising and established figures of interest in the creative industries, a remit including film, radio, TV, comedy, music, new media and design.\n\nSubjects are usually UK-based, with contributing editors based in Northern Ireland, Scotland, London and Birmingham, but the publication has been known to source international content from Australia, America, continental Europe and the Middle East. The magazine is frequently organised around a theme for the issue, for instance giving half of November 2007's pages over to profiling winners of the annual 4Talent Awards.\n\nAn unusual feature of the magazine's credits is the equal prominence given to the names of writers, photographers, designers and illustrators, contradicting standard industry practice of more prominent writer bylines. It is also recognisable for its 'wraparound' covers, which use the front and back as a continuous canvas – often produced by guest artists.\n\nAlthough \"4Talent Magazine\" is technically a newsstand title, a significant proportion of its readers are subscribers. It started life as a quarterly 100-page title, but has since doubled in size and is now published bi-annually.\n\nChannel 4 has, since its inception, broadcast identical programmes and continuity throughout the United Kingdom (excluding Wales where it did not operate on analogue transmitters). At launch this made it unique, as both the BBC and ITV had long established traditions of providing regional variations in their programming in different areas of the country. Since the launch of subsequent British television channels, Channel 4 has become typical in its lack of regional programming variations.\n\nA few exceptions exist to this rule for programming and continuity:\n\nSome of Channel 4's schools' programming (1980s/early '90s) were regionalised due to differences in curricula between different regions.\n\nPart of Channel 4's remit covers the commissioning of programmes from outside London. Channel 4 has a dedicated director of nations and regions, Stuart Cosgrove, who is based in a regional office in Glasgow. As his job title suggests, it is his responsibility to foster relations with independent producers based in areas of the United Kingdom (including Wales) outside London.\n\nAdvertising on Channel 4 does contain regular variation: prior to 1993, when ITV was responsible for selling Channel 4's advertising, each regional ITV company would provide the content of advertising breaks, covering the same transmitter area as themselves, and these breaks were often unique to that area. After Channel 4 became responsible for its own advertising, it continued to offer advertisers the ability to target particular audiences and divided its coverage area into six regions: London, South, Midlands, North, Northern Ireland and Scotland.\n\nAt present, Wales does not have its own advertising region, instead its viewers receive the southern region on digital platforms intentionally broadcast to the area, or the neighbouring region where terrestrial transmissions spill over into Wales. The Republic of Ireland shares its advertising region with Northern Ireland (referred to by Channel 4 as the 'Ulster Macro') with many advertisers selling products for Ireland here. E4 has an advertising variant for Ireland, although Northern Ireland receives the UK version of E4. The six regions are also carried on satellite, cable and Digital Terrestrial.\n\nChannel 5 and ITV Breakfast use a similar model to Channel 4 for providing their own advertising regions, despite also having a single national output of programming.\n\nDespite the Republic of Ireland not being in the UK, Channel 4 has a dedicated variant broadcast on Sky Ireland which omits programmes for which broadcast rights are not held in Ireland. For example, the series \"Glee\" is not available on Channel 4 on Sky in Ireland. In recent years a Republic of Ireland advertising opt-out has been added to this version.\n\nWith ITV plc pushing for much looser requirements on the amount of regional news and other programming it is obliged to broadcast in its ITV regions, the idea of Channel 4 taking on a regional news commitment has been considered, with the corporation in talks with Ofcom and ITV over the matter. Channel 4 believe that a scaling-back of such operations on ITV's part would be detrimental to Channel 4's national news operation, which shares much of its resources with ITV through their shared news contractor ITN. At the same time, Channel 4 also believe that such an additional public service commitment would bode well in on-going negotiations with Ofcom in securing additional funding for its other public service commitments.\n\nIn mid-2006 Channel 4 ran a six-month closed trial of HDTV, as part of the wider Freeview HD experiment via the Crystal Palace transmitter to London and parts of the home counties, including the use of \"Lost\" and \"Desperate Housewives\" as part of the experiment, as US broadcasters such as ABC already have an HDTV back catalogue.\n\nOn 10 December 2007, Channel 4 launched a high definition television simulcast of Channel 4 on Sky's digital satellite platform, after Sky agreed to contribute toward the channel's satellite distribution costs. It was the first full-time high definition channel from a terrestrial UK broadcaster.\n\nOn 31 July 2009, Virgin Media added Channel 4 HD on channel 146 (later on channel 142, now on channel 141) as a part of the M pack. On 25 March 2010 Channel 4 HD appeared on Freeview channel 52 with a placeholding caption, ahead of a commercial launch on 30 March 2010, coinciding with the commercial launch of Freeview HD. On 19 April 2011, Channel 4 HD was added to Freesat on channel 126. As a consequence, the channel moved from being free-to-view to free-to-air on satellite during March 2011. With the closure of S4C Clirlun in Wales on 1 December 2012, on Freeview, Channel 4 HD launched in Wales on 2 December 2012.\n\nThe channel carries the same schedule as Channel 4, broadcasting programmes in HD when available, acting as a simulcast. Therefore, SD programming is broadcast upscaled to HD. The first true HD programme to be shown was the 1996 Adam Sandler film Happy Gilmore. From launch until 2016 the presence of the 4HD logo on screen denoted true HD content.\n\nOn 1 July 2014, Channel 4 +1 HD, a timeshift of Channel 4 HD, launched on Freeview channel 110.\n\nAll 4 is a video on demand service from Channel 4, launched in November 2006 as 4oD. The service offers a variety of programmes recently shown on Channel 4, E4, More4 or from their archives, though some programmes and movies are not available due to rights issues.\n\nChannel 4 originally licensed an ancillary teletext service to provide schedules, programme information and features. The original service was called 4-Tel, and was produced by Intelfax, a company set up especially for the purpose. It was carried in the 400s on Oracle. In 1993, with Oracle losing its franchise to Teletext Ltd, 4-Tel found a new home in the 300s, and had its name shown in the header row. Intelfax continued to produce the service and in 2002 it was renamed FourText.\n\nIn 2003, Channel 4 awarded Teletext Ltd a ten-year contract to run the channel's ancillary teletext service, named Teletext on 4. This has now ceased and Teletext is no longer available on Channel 4, ITV and Channel 5.\n\n", "id": "6321", "title": "Channel 4"}
{"url": "https://en.wikipedia.org/wiki?curid=6322", "text": "Carolina parakeet\n\nThe Carolina parakeet (\"Conuropsis carolinensis\") or Carolina conure was a small green neotropical parrot with a bright yellow head, reddish orange face and pale beak native to the eastern, midwest and plains states of the United States and was the only indigenous parrot within its range. It was found from southern New York and Wisconsin to Kentucky, Tennessee and the Gulf of Mexico, from the Atlantic seaboard to as far west as eastern Colorado. It lived in old-growth forests along rivers and in swamps. It was called \"puzzi la née\" (\"head of yellow\") or \"pot pot chee\" by the Seminole and \"kelinky\" in Chickasaw. Though formerly prevalent within its range, the bird had become rare by the middle of the 19th century. The last confirmed sighting in the wild was of the \"ludovicianus\" subspecies in 1910. The last known specimen perished in captivity at the Cincinnati Zoo in 1918 and the species was declared extinct in 1939.\n\nThe earliest reference to these parrots was in 1583 in Florida reported by Sir George Peckham in \"A True Report of the Late Discoveries of the Newfound Lands\" of expeditions conducted by English explorer Sir Humphrey Gilbert who notes that explorers in North America \"doe testifie that they have found in those countryes; ... parrots.\" They were first scientifically described in English naturalist Mark Catesby's two volume \"Natural History of Carolina, Florida and the Bahama Islands\" published in London in 1731 and 1743.\n\nCarolina parakeets were probably poisonous—American naturalist and painter John J. Audubon noted that cats apparently died from eating them, and they are known to have eaten the toxic seeds of cockleburs.\n\n\"Carolinensis\" is a species of the genus \"Conuropsis\", one of numerous genera of New World long-tailed parrots in tribe Arini, which also includes the Central and South American macaws. Tribe Arini together with the Amazonian parrots and a few miscellaneous genera make up subfamily Arinae of Neotropical parrots in family Psittacidae of true parrots.\n\nThe specific name \"Psittacus carolinensis\" was assigned by Swedish zoologist Carl Linnaeus in the 10th edition of Systema Naturae published in 1758. The species was given its own genus \"Conuropsis\" by Italian zoologist and ornithologist Tommaso Salvadori in 1891 in his \"Catalogue of the Birds in the British Museum\", volume 20. The name is derived from the Greek-ified \"conure\" (\"parrot of the genus \"Conurus\"\" an obsolete name of genus \"Aratinga\") + \"-opsis\" (\"likeness of\") and Latinized \"Carolina\" (from Carolana, an English colonial province) + \"-ensis\" (of or \"from a place\"), therefore a bird \"like a conure from Carolina\".\n\nThere are two recognized subspecies. The Louisiana subspecies of the Carolina parakeet, \"C. c. ludovicianus\", was slightly different in color than the nominate subspecies, being more bluish-green and generally of a somewhat subdued coloration, and became extinct in much the same way, but at a somewhat earlier date (early 1910s). The Appalachian Mountains separated these birds from the eastern \"C. c. carolinensis\".\n\nAccording to a study of mitochondrial DNA recovered from museum specimens, their closest living relatives include some of the South American \"Aratinga\" parakeets: the Nanday parakeet, the sun parakeet, and the golden-capped parakeet. The authors note the bright yellow and orange plumage and blue wing feathers found in \"Conuropsis carolinensis\" are traits shared by another species, the jandaya parakeet (\"A. jandaya\"), that was not sampled in the study but is generally thought to be closely related. Carolinensis is in a sister clade to that of Spix's macaw. The Carolina parakeet colonized North America about 5.5 million years ago. This was well before North America and South America were joined together by the formation of the Panama land bridge about 3.5 mya. Since the Carolina parakeets' more distant relations are geographically closer to its own historic range whilst its closest relatives are more geographically distant to it, these data are consistent with the generally accepted hypothesis that Central and North America were colonized at different times by distinct lineages of parrots – parrots that originally invaded South America from Antarctica some time after the breakup of Gondwana, where Neotropical parrots originated approximately 50 mya.\n\nThe following cladogram shows the placement of the Carolina parakeet among its closest relatives, after a DNA study by Kirchman et al., 2012:\nA fossil parrot, designated \"Conuropsis fratercula\", was described based on a single humerus from the Miocene Sheep Creek Formation (possibly late Hemingfordian, c. 16 mya, possibly later) of Snake River, Nebraska. This was a smaller bird, three-quarters the size of the Carolina parakeet. \"The present \"species\" is of peculiar interest as it represents the first known parrotlike bird to be described as a fossil from North America.\" (Wetmore 1926; italics added) However, it is not altogether certain that this species is correctly assigned to \"Conuropsis\", but some authors consider it a paleosubspecies of the Carolina parakeet.\n\nThe Carolina parakeet was a small green parrot very similar in size and coloration to the extant jenday and sun conures. The majority of the plumage was green with lighter green underparts, a bright yellow head and orange forehead and face extending to behind the eyes and upper cheeks (lores). The shoulders were yellow, continuing down the outer edge of the wings. The primary feathers were mostly green, but with yellow edges on the outer primaries. Thighs were green towards the top and yellow towards the feet. Male and female adults were identical in plumage, however males were slightly larger than females (sexually dimorphic). The legs and feet were light brown. They share the zygodactyl feet of the parrot family. The skin around the eyes was white and the beak was pale flesh colored. These birds weigh about 3.5 oz., are 13 in. long, and have wingspans of 2123 in.\n\nYoung Carolina parakeets differed slightly in coloration from adults. The face and entire body was green, with paler underparts. They lacked yellow or orange plumage on the face, wings, and thighs. Hatchlings were covered in mouse-gray down, until about 39–40 days when green wings and tails appear. Fledglings had full adult plumage at around 1 year of age. (\"Nature Serve, Conuropsis carolinensis\", 2005; Fuller, 2001; Mauler, 2001; Rising, 2004; Snyder and Russell, 2002)\n\nThese birds were fairly long lived, at least in captivity - a pair was kept at the Cincinnati Zoo for over 35 years.\n\nThe Carolina parakeet had the northern-most range of any known parrot. It was found from southern New England and New York and Wisconsin to Kentucky, Tennessee and the Gulf of Mexico. It has also had a wide distribution west of the Mississippi River, as far west as eastern Colorado. Its range was described by early explorers thus: the 43rd parallel as the northern limit, the 26th as the most southern, the 73rd and 106th meridians as the eastern and western boundaries respectively, the range included all or portions of at least 28 states. Its habitats were old-growth wetland forests along rivers and in swamps especially in the Mississippi-Missouri drainage basin with large hollow trees including cypress and sycamore to use as roosting and nesting sites.\n\nOnly very rough estimates of the birds' former prevalence can be made: with an estimated range of 20,000 to 2.5 million km, and population density of 0.5 to 2.0 parrots per km, population estimates range from tens of thousands to a few million birds (though the densest populations occurred in Florida covering 170,000 km, so there may have been hundreds of thousands of the birds in that state alone).\n\nThe species may have appeared as a very rare vagrant in places as far north as Southern Ontario. A few bones, including a pygostyle found at the Calvert Site in Southern Ontario, came from the Carolina parakeet. The possibility remains open that this specimen was taken to Southern Ontario for ceremonial purposes.\n\nThe bird lived in huge, noisy flocks of as many as 200–300 birds. It built its nest in a hollow tree, laying two to five (most accounts say two) round white eggs.\n\nIt mostly ate the seeds of forest trees and shrubs including those of cypress, hackberry, beech, sycamore, elm, pine, maple, oak, and other plants such as thistles and sandspurs (\"Cenchrus\" species). It also ate fruits, including apples, grapes and figs (often from orchards by the time of its decline). It was especially noted for its predilection for cockleburs (\"Xanthium strumarium\"), a plant which contains a toxic glucoside, and it was considered to be an agricultural pest of grain crops.\n\nThere are no scientific studies or surveys of this bird by American naturalists; most information about it is from anecdotal accounts and museum specimens. Therefore, details of its prevalence and decline are unverified or speculative.\n\nThere are extensive accounts of the pre-colonial and early colonial prevalence of this bird. The existence of flocks of gregarious, very colorful and raucous parrots could hardly have gone unnoted by European explorers, as parrots were virtually unknown in seafaring European nations in the 16th and 17th centuries. Later accounts in the latter half of the 19th century onward noted the birds' sparseness and absence.\n\nThe birds' range collapsed from east to west with settlement and clearing of the eastern and southern deciduous forests. John J. Audubon commented as early as 1832 on the decline of the birds. The bird was rarely reported outside Florida after 1860. The last reported sighting east of the Mississippi River (except Florida) was in 1878 in Kentucky. By the turn of the century it was restricted to the swamps of central Florida. The last known wild specimen was killed in Okeechobee County, Florida, in 1904, and the last captive bird died at the Cincinnati Zoo on February 21, 1918. This was the male specimen, called \"Incas\", who died within a year of his mate, \"Lady Jane\". Additional reports of the bird were made in Okeechobee County, Florida, until the late 1920s, but these are not supported by specimens. It was not until 1939, however, that the American Ornithologists' Union declared that the Carolina parakeet had become extinct. The IUCN has listed the species as extinct since 1920.\nIn 1937, three parakeets resembling this species were sighted and filmed in the Okefenokee Swamp of Georgia. However, the American Ornithologists' Union analyzed the film and concluded that they had probably filmed feral parakeets.\n\nAbout 720 skins and 16 skeletons are housed in museums around the world and analyzable DNA has been extracted from them.\n\nThe evidence is rather conclusive that extinction of the Carolina parakeet was by anthropogenic activity, through a variety of means. Chief among them is deforestation in the 18th and 19th centuries. Hunting played a significant role, both for their colorful feathers used to adorn women's hats and to reduce predation on southern crops. This was partially offset by recognition of their value in controlling invasive cockleburs. Minor roles were played by capture for the pet trade and, it was hypothesized, by the introduction for crop pollination of European honeybees that competed for nest sites.\n\nA factor that exacerbated their decline to extinction was the flocking behavior that led them to return to the vicinity of dead and dying birds (e.g., birds downed by hunting), enabling wholesale slaughter.\n\nThe final extinction of the species in the early years of the 20th century is somewhat of a mystery, as it happened so rapidly. Vigorous flocks with many juveniles and reproducing pairs were noted as late as 1896, and the birds were long-lived in captivity, but they had virtually disappeared by 1904. Sufficient nest sites remained intact, so deforestation was not the final cause. American ornithologist Noel F. Snyder speculates that the most likely cause seems to be that the birds succumbed to poultry disease, although no recent or historical records exist of New World parrot populations being afflicted by domestic poultry diseases. The modern poultry scourge Newcastle disease was not detected until 1926 in Indonesia, and only a subacute form of it was reported in the United States in 1938.\n\n\n\n", "id": "6322", "title": "Carolina parakeet"}
{"url": "https://en.wikipedia.org/wiki?curid=6324", "text": "Collective trauma\n\nA collective trauma is a traumatic psychological effect shared by a group of people of any size, up to and including an entire society. Traumatic events witnessed by an entire society can stir up collective sentiment, often resulting in a shift in that society's culture and mass actions.\n\nWell known collective traumas include: The Holocaust, the Armenian Genocide, Slavery in the United States, the Atomic bombings of Hiroshima and Nagasaki, the Trail of Tears, the Assassination of John F. Kennedy in the United States, the MS Estonia in Sweden, the September 11, 2001 attacks in the United States, and various others.\n\nCollective traumas have been shown to play a key role in group identity formation (see: Law of Common Fate). During World War II, a US submarine, the USS Puffer (SS-268), came under several hours of depth charge attack by a Japanese surface vessel until the ship became convinced the submarine had somehow escaped. Psychological studies later showed that crewmen transferred to the submarine after the event were never accepted as part of the team. Later, US naval policy was changed so that after events of such psychological trauma, the crew would be dispersed to new assignments.\n\nRehabilitation of survivors becomes extremely difficult when entire nation has experienced such severe traumas as war, genocide, torture, massacre, etc. Treatment is hardly effective when everybody is traumatized. Trauma remains chronic and would reproduce itself as long as social causes are not addressed and perpetrators continue to enjoy impunity. The whole society may suffer from an everlasting culture of pain. (1)\n\nDuring liberation war in Algeria, the Algerian Psychiatrist Frantz Omar Fanon found his practice of treatment of native Algerians ineffective due to the continuation of the horror of a colonial war. He emphasized about the social origin of traumas, joined the liberation movement and urged oppressed people to purge themselves of their degrading traumas through their collective liberation struggle. He made the following remarks in his letter of resignation, as the Head of the Psychiatry Department at the Blida-Joinville Hospital in Algeria:\"If psychiatry is the medical technique that aims to enable man no longer to be a stranger to his environment, I owe it to myself to affirm that the Arab, permanently an alien in his own country, lives in a state of absolute depersonalization.\" (2) Inculcation of horror and anxiety, through widespread torture, massacre, genocide and similar coercive measures has happened frequently in human history. There are plenty of examples in our modern history. Tyrants have always used their technique of “psychological artillery\" in an attempt to cause havoc and confusion in the minds of people and hypnotize them with intimidation and cynicism. The result is a collective trauma that will pass through generations. There is no magic formula of rehabilitation. Collective trauma can be alleviated through cohesive and collective efforts such as recognition, remembrance, solidarity, communal therapy and massive cooperation.\n\n\n1. Mossallanejad, E. (2005). Torture in the Age of Fear. Hamilton, Canada: Seraphim Editions\n2. Frantz Fanon, Toward the African Revolution, New York, 1967. Reprint of Pour la revolution africaine. Paris, 1964, p. 53.\n", "id": "6324", "title": "Collective trauma"}
{"url": "https://en.wikipedia.org/wiki?curid=6325", "text": "Church (building)\n\nA church building, often simply called a church, is a building used for Christian religious activities, particularly worship services. The term in its architectural sense is most often used by Christians to refer to their religious buildings, but it is sometimes used (by analogy) for buildings of other religions. In traditional Christian architecture, the church is often arranged in the shape of a Christian cross. When viewed from plan view the longest part of a cross is represented by the aisle and the junction of the cross is located at the altar area.\n\nTowers or domes are often added with the intention of directing the eye of the viewer towards the heavens and inspiring church visitors. Modern church buildings have a variety of architectural styles and layouts; many buildings that were designed for other purposes have now been converted for church use; and, similarly, many original church buildings have been put to other uses.\n\nThe earliest identified Christian church was a house church founded between 233 and 256. During the 11th through 14th centuries, a wave of building of cathedrals and smaller parish churches occurred across Western Europe. A cathedral is a church, usually Roman Catholic, Anglican, Oriental Orthodox or Eastern Orthodox, housing the seat of a bishop.\n\nIn Greek, the adjective \"kyriak-ós/-ē/-ón\" means \"belonging, or pertaining, to a \"Kyrios\"\" (\"Lord\"), and the usage was adopted by early Christians of the Eastern Mediterranean with regard to anything pertaining to the Lord Jesus Christ: hence \"\"Kyriakós oíkos\"\" (\"house of the Lord\", church), \"\"Kyriakē\"\" (\"[the day] of the Lord\", i.e. Sunday), or \"\"Kyriakē proseukhē\"\" (the \"Lord's Prayer\").\n\nIn standard Greek usage, the older word \"ecclesia\" (ἐκκλησία, \"ekklesía\", literally \"assembly\", \"congregation\", or the place where such a gathering occurs) was retained to signify both a specific edifice of Christian worship (a \"church\"), and the overall community of the faithful (the \"Church\"). This usage was also retained in Latin and the languages derived from Latin (e.g. French \"église\", Italian \"chiesa\", Spanish \"iglesia\", Portuguese \"igreja\", etc.), as well as in the Celtic languages (Welsh \"eglwys\", Irish \"eaglais\", Breton \"iliz\", etc.) and in Turkish (\"kilise\").\n\nIn the Germanic and some Slavic languages, the word \"kyriak-ós/-ē/-ón\" was adopted instead and derivatives formed thereof. In Old English the sequence of derivation started as \"cirice\" (Ki-ri-keh), then \"churche\" (kerke), and eventually \"church\" in its current pronunciation. German \"Kirche\", Scottish \"kirk\", Russian церковь (\"tserkov\"), etc., are all similarly derived.\n\nAccording to the New Testament, the earliest Christians did not build church buildings. Instead, they gathered in homes (Acts 17:5, 20:20, 1 Cor 16:19) or in Jewish worship places like the Second Temple or synagogues (Acts 2:46, 19:8). The earliest archeologically identified Christian church is a house church, the Dura-Europos church, founded between 233 and 256.\n\nDuring the 11th through 14th centuries, a wave of building of cathedrals and smaller parish churches occurred across Western Europe. In addition to being a place of worship, the cathedral or parish church was used by the community in other ways. It could serve as a meeting place for guilds or a hall for banquets. Mystery plays were sometimes performed in cathedrals, and cathedrals might also be used for fairs. The church could be used as a place to thresh and store grain.\n\nA common architecture for churches is the shape of a cross (a long central rectangle, with side rectangles, and a rectangle in front for the altar space or sanctuary). These churches also often have a dome or other large vaulted space in the interior to represent or draw attention to the heavens. Other common shapes for churches include a circle, to represent eternity, or an octagon or similar star shape, to represent the church's bringing light to the world. Another common feature is the spire, a tall tower on the \"west\" end of the church or over the crossing.\n\nThe Latin word basilica (derived from Greek, \"Basiliké Stoà\", Royal \"Stoa\") was originally used to describe a Roman public building (as in Greece, mainly a tribunal), usually located in the forum of a Roman town.\n\nAfter the Roman Empire became officially Christian, the term came by extension to refer to a large and important church that has been given special ceremonial rights by the Pope. Thus the word retains two senses today, one architectural and the other ecclesiastical.\n\nA cathedral is a church, usually Roman Catholic, Anglican, Oriental Orthodox or Eastern Orthodox, housing the seat of a bishop. The word cathedral takes its name from \"cathedra\", or Bishop's Throne (In ). The term is sometimes (improperly) used to refer to any church of great size.\n\nA church that has the function of cathedral is not necessarily a large building. It might be as small as Christ Church Cathedral in Oxford, England, Sacred Heart Cathedral in Raleigh, United States, or Chur Cathedral in Switzerland. However, frequently, the cathedral along with some of the abbey churches, was the largest building in any region.\n\nOld and disused church buildings can be seen as an interesting proposition for developers as the architecture and location often provide for attractive homes or city centre entertainment venues On the other hand, many newer churches have decided to host meetings in public buildings such as schools, universities, cinemas or theatres.\n\nThere is another trend to convert old buildings for worship rather than face the construction costs and planning difficulties of a new build. Unusual venues in the UK include an old Tram power station, a former bus garage, an old cinema and bingo hall, a former Territorial Army Drill Hall, and a former synagogue. A windmill has also been converted into a church at Reigate Heath.\nThere has been an increase in partnerships between church management and private real estate companies to redevelop church properties into mixed uses. While it has garnered criticism from some, the partnership offers congregations the opportunity to increase revenue while preserving the property.\n\n\n\n", "id": "6325", "title": "Church (building)"}
{"url": "https://en.wikipedia.org/wiki?curid=6326", "text": "Childe's Tomb\n\nChilde's Tomb is a granite cross on Dartmoor, Devon, England. Although not in its original form, it is more elaborate than most of the crosses on Dartmoor, being raised upon a constructed base, and it is known that a kistvaen is underneath.\n\nA well-known legend attached to the site, first recorded in 1630 by Tristram Risdon, concerns a wealthy hunter, Childe, who became lost in a snow storm and supposedly died there despite disembowelling his horse and climbing into its body for protection. The legend relates that Childe left a note of some sort saying that whoever found and buried his body would inherit his lands at Plymstock. After a race between the monks of Tavistock Abbey and the men of Plymstock, the Abbey won.\n\nThe tomb was virtually destroyed in 1812 by a man who stole most of the stones to build a house nearby, but it was partly reconstructed in 1890.\n\nChilde's Tomb is a reconstructed granite cross on the south-east edge of Foxtor Mires, about 500 metres north of Fox Tor on Dartmoor, Devon, England at . According to William Burt, in his notes to \"Dartmoor, a Descriptive Poem\" by N. T. Carrington (1826), the original tomb consisted of a pedestal of three steps, the lowest of which was built of four stones each six feet long and twelve inches square. The two upper steps were made of eight shorter but similarly shaped stones, and on top was an octagonal block about three feet high with a cross fixed upon it.\n\nThe tomb lies on the line of several cairns that marked the east-west route of the ancient Monks' Path between Buckfast Abbey and Tavistock Abbey and it was no doubt erected here as part of that route: it would have been particularly useful in this part of the moor with few landmarks where a traveller straying from the path could easily end up in Foxtor Mires. Tristram Risdon, writing in about 1630, said that Childe's Tomb was one of three remarkable things in the Forest of Dartmoor (the others being Crockern Tor and Wistman's Wood). Risdon also stated that the original tomb bore an inscription: \"They fyrste that fyndes and bringes mee to my grave, The priorie of Plimstoke they shall have\", but no sign of this has ever been found.\n\nToday the cross, which is a replacement, is about tall and across at the crosspiece, and it has its base in a socket stone which rests on a pedestal of granite blocks that raises the total height of the cross to . The original, now broken, socket stone for the cross lies nearby. The whole is surrounded by a circle of granite stones set on their edge which once surrounded the cairn—the rocks of which are now scattered around—that was originally built over a large kistvaen that still exists beneath the pedestal.\n\nIn the early 19th century there was much interest in enclosing and \"improving\" the open moorland on Dartmoor, encouraged by Sir Thomas Tyrwhitt's early successes at Tor Royal near Princetown. Enclosure was aided by the greatly enhanced access provided by the construction of the first turnpike roads over the moor: the road between Ashburton and Two Bridges opened in around 1800, for instance. In February 1809 one Thomas Windeatt, from Bridgetown, Totnes, took over the lease of a plot of land (a \"newtake\") of about 582 acres in the valley of the River Swincombe. In 1812 Windeatt started to build a farmhouse, Fox Tor Farm, on his land and his workmen robbed the nearby Childe's Tomb of most of its stones for the building and its doorsteps.\n\nIn 1902 William Crossing wrote that he had been told by an old moorman that some of the granite blocks from the tomb's pedestal had also been used to make a clapper bridge across a stream flowing into the River Swincombe near the farm. The moorman also said that they had lettering on their undersides. This encouraged Crossing to arrange to lift the clapper bridge, but no inscription was found. However, he did locate nine out of the twelve stones that had made up the pedestal, as well as the broken socket stone for the cross.\n\nCrossing rediscovered the original site of the tomb in 1882 and said that all that remained was a small mound and some half buried stones. He cleared out the kistvaen, reporting that it was long by wide and that unlike most kistvaens found on the moor, the stones lining it had apparently been shaped by man, which led him to suggest that it was less old than most. Having located most of the stones of the original tomb, Crossing thought that it could be rebuilt in its original form with little effort, but it was not to be.\n\nJ. Brooking Rowe, writing in 1895, states that the tomb was re-erected in 1890 under the direction of Mr. E. Fearnley Tanner, who said that he was dissatisfied with the result because several stones were missing and it was difficult to recreate the original character of the monument. Tanner was the honourable secretary of the Dartmoor Preservation Association, and this reconstruction was one of the first acts of that organisation. The replacement base and cross were made in Holne in 1885.\n\nAccording to legend, the cross was erected over the kistvaen (burial chamber) of Childe the Hunter, who was Ordulf, son of Ordgar, an Anglo-Saxon Earl of Devon in the 11th century. The name \"Childe\" is probably derived from the Old English word \"cild\" which was used as a title of honour.\n\nLegend has it that Childe was in a party hunting on the moor when they were caught in some changeable weather. Childe became separated from the main party and was lost. In order to save himself from dying of exposure, he killed his horse, disembowelled it and crept inside the warm carcass for shelter. He nevertheless froze to death, but before he died, he wrote a note to the effect that whoever should find him and bury him in their church should inherit his Plymstock estate.\n\nHis body was found by the monks of Tavistock Abbey, who started to carry it back. However, they heard of a plot to ambush them by the people of Plymstock, at a bridge over the River Tavy. They took a detour and built a new bridge over the river, just outside Tavistock. They were successful in burying the body in the grounds of the Abbey and inherited the Plymstock estate.\n\nThe first account of this story is to be found in Risdon's \"Survey of Devon\" which was completed in around 1632:\n\nFinberg pointed out, however, that a document of 1651 refers to Tavistock's guildhall as \"Guilehall\", so \"Guilebridge\" is more likely to be \"guild bridge\", probably because it was built or maintained by one of the town guilds.\n\nDevon folk singer Seth Lakeman sang about Childe the Hunter on his 2006 album \"Freedom Fields\".\n\n", "id": "6326", "title": "Childe's Tomb"}
{"url": "https://en.wikipedia.org/wiki?curid=6328", "text": "Cognate\n\nIn linguistics, cognates are words that have a common etymological origin. In etymology, the \"cognate\" category excludes doublets and loanwords. The word \"cognate\" derives from the Latin noun \"cognatus\", which means \"blood relative\".\n\nCognates do not need to have the same meaning, which may have changed as the languages developed separately. For example, consider English \"starve\" and Dutch \"sterven\" or German \"sterben\" (\"to die\"); these three words all derive from the same Proto-Germanic root, \"*sterbaną\" (\"die\"). English \"dish\" and German \"Tisch\" (\"table\"), with their flat surfaces, both come from Latin \"discus\", but it would be a mistake to identify their later meanings as the same. \"Discus\" is from Greek \"δίσκος\" (from the verb \"δικεῖν\" \"to throw\"). A later and \"separate\" English reflex of \"discus\", probably through medieval Latin \"desca\", is \"desk\" (see OED s.v. \"desk\").\n\nCognates also do not need to have obviously similar forms, e.g. English \"father\", French \"père\", and Armenian հայր (\"hayr\") all descend directly from Proto-Indo-European (PIE) \"*ph₂tḗr\".\n\nExamples of cognates in Indo-European languages are the words \"night\" (English), \"nuit\" (French), \"noche\" (Spanish), \"Nacht\" (German), \"nacht\" (Dutch), \"nag\" (Afrikaans), \"nicht\" (Scots), \"natt\" (Swedish, Norwegian), \"nat\" (Danish), \"nátt\" (Faroese), \"nótt\" (Icelandic), \"noc\" (Czech, Slovak, Polish), ночь, \"noch\" (Russian), ноќ, \"noć\" (Macedonian), нощ, \"nosht\" (Bulgarian), \"ніч\", \"nich\" (Ukrainian), \"ноч\", \"noch\"/\"noč\" (Belarusian), \"noč\" (Slovene), \"noć\" (Bosnian, Serbian, Croatian), νύξ, \"nyx\" (Ancient Greek, \"νύχτα\"/\"nychta\" in Modern Greek), \"nox/nocte\" (Latin), \"nakt-\" (Sanskrit), \"natë\" (Albanian), \"nos\" (Welsh), \"nueche\" (Asturian), \"noite\" (Portuguese and Galician), \"notte\" (Italian), \"nit\" (Catalan), \"nuèch/nuèit\" (Occitan), \"noapte\" (Romanian), \"nakts\" (Latvian), \"naktis\" (Lithuanian) and \"Naach\" (Colognian), all meaning \"night\" and derived from the PIE , \"night\".\n\nAnother Indo-European example is \"star\" (English), \"str-\" (Sanskrit), \"tara\" (Hindustani and Bengali), \"tora\" (Assamese), \"astre\"/\"étoile\" (French), \"ἀστήρ (astēr)\" (Greek or \"ἀστέρι\"/\"ἄστρο\", \"asteri\"/\"astro\" in Modern Greek), \"astro/stella\" (Italian), \"aster\" (Latin) \"stea\" (Romanian and Venetian), \"stairno\" (Gothic), \"astl\" (Armenian), \"Stern\" (German), \"ster\" (Dutch and Afrikaans), \"Schtähn\" (Colognian), \"starn\" (Scots), \"stjerne\" (Norwegian and Danish), \"stjarna\" (Icelandic), \"stjärna\" (Swedish), \"stjørna\" (Faroese), \"setāre\" (Persian), \"stoorei\" (Pashto), \"seren\" (Welsh), \"steren\" (Cornish), \"estel\" (Catalan), \"estela\" (Occitan) \"estrella\" and \"astro\" Spanish, \"estrella\" Asturian and Leonese, \"estrela\" and \"astro\" (Portuguese and Galician) and \"estêre\" or \"stêrk\" (Kurdish), from the PIE , \"star\".\n\nThe Hebrew \"shalom\", the Arabic \"salām\", the Assyrian Neo-Aramaic \"shlama\" and the Amharic \"selam\" (\"peace\") are also cognates, derived from Proto-Semitic *šalām-.\n\nCognates may often be less easily recognised than the above examples, and authorities sometimes differ in their interpretations of the evidence. The English word \"milk\" is clearly a cognate of German \"Milch\", Dutch \"melk\", Russian \"молоко (moloko)\" and (Bosnian, Serbian, Croatian) \"mlijeko\". On the other hand, French \"lait\", Catalan \"llet\", Italian \"latte\", Romanian \"lapte\", Spanish \"leche\" and \"leite\" (Portuguese and Galician) (all meaning \"milk\") are less obviously cognates of Ancient Greek \"\" \"gálaktos\" (genitive singular of \"gála\", \"milk\"), a relationship more evidently seen through the intermediate Latin \"lac\" \"milk\", as well as the English word \"lactic\" and other terms borrowed from Latin.\n\nAt times, cognates may be semantic opposites. For instance, while the Hebrew word \"chutzpah\" means \"impudence,\" its Classical Arabic cognate \"ḥaṣāfah\" means \"sound judgment.\" English \"black\" and Polish \"biały\", meaning white, are cognates with opposite meanings, both deriving from the PIE , meaning, \"to burn or shine.\"\n\nCognate doublets can exist within the same language, with meanings that are slightly to totally different. For example, English \"ward\" and \"guard\" (<PIE \"*wer-\", \"to perceive, watch out for\") are cognates, as are \"shirt\" (garment on top) and \"skirt\" (garment on bottom) (<PIE \"*sker-\", \"to cut\"). In some cases, such as \"shirt\" and \"skirt\", one of the cognate pairs has an ultimate source in another language related to English, while the other one is native, as happened with many loanwords from Old Norse borrowed during the period of the Danelaw. Sometimes, both cognates come from other languages, often the same one but at different times. For example, the word \"chief\" (meaning the leader of any group) comes from the Middle French \"chef\" (\"head\"), and its modern pronunciation preserves the Middle French consonant sound; the word \"chef\" (the leader of the cooks) was borrowed from the same source centuries later, by which time the consonant had changed to a \"sh\"-sound in French. Such word sets can also be called etymological twins, and of course they may come in groups of higher numbers, as with, for example, the words \"wain\" (native), \"waggon/wagon\" (Dutch) and \"vehicle\" (Latin) in English.\n\nA word may also enter another language, develop a new form or meaning there, and be re-borrowed into the original language; this is called reborrowing. For example, the Greek word \"κίνημα\" (\"kinēma\", \"movement\") became French \"cinéma\" (cf. American English \"movie\") and then later returned to Greece as \"σινεμά\" (\"sinema\", \"the art of film\", \"movie theater\"). Now in Greece \"κίνημα\" (\"kinēma\", \"movement\") and \"σινεμά\" (\"sinema\", \"filmmaking, cinema\") exist together as a doublet.\n\nAn example of very different and non-obvious English-language doublets is \"grammar\" and \"glamour\".\n\nFalse cognates are words that people commonly believe are related (have a common origin), but that linguistic examination reveals are unrelated. For example, on the basis of superficial similarities, the Latin verb \"habēre\" and German \"haben\", both meaning 'to have', appear to be cognates. However, because of the way words in the two languages evolved from Proto-Indo-European (PIE) roots, they cannot be cognate (see for example Grimm's law). German \"haben\", like English \"have\", comes from PIE \"*kh₂pyé-\" 'to grasp', and its real cognate in Latin is \"capere\", 'to seize, grasp, capture'. Latin \"habēre\", on the other hand, is from PIE \"*gʰabʰ\", 'to give, to receive', and hence cognate with English \"give\" and German \"geben\".\n\nLikewise, English \"much\" and Spanish \"mucho\" look similar and have a similar meaning but are not cognates, as they evolved from different roots: \"much\" from Proto-Germanic \"*mikilaz\" < PIE \"*meǵ-\" and \"mucho\" from Latin \"multum\" < PIE \"*mel-\".\n\n\n\n", "id": "6328", "title": "Cognate"}
{"url": "https://en.wikipedia.org/wiki?curid=6329", "text": "Chromatography\n\nChromatography (; from Greek χρῶμα \"chroma\" which means \"color\" and γράφειν \"graphein\" \"to write\") is a laboratory technique for the separation of a mixture.\nThe mixture is dissolved in a fluid called the \"mobile phase,\" which carries it through a structure holding another material called the \"stationary phase.\" The various constituents of the mixture travel at different speeds, causing them to separate. The separation is based on differential partitioning between the mobile and stationary phases. Subtle differences in a compound's partition coefficient result in differential retention on the stationary phase and thus changing the separation.\n\nChromatography may be preparative or analytical. The purpose of preparative chromatography is to separate the components of a mixture for later use, and is thus a form of purification. Analytical chromatography is done normally with smaller amounts of material and is for establishing the presence or measuring the relative proportions of analytes in a mixture. The two are not mutually exclusive.\n\nChromatography was first employed in Russia by the Italian-born scientist Mikhail Tsvet in 1900. He continued to work with chromatography in the first decade of the 20th century, primarily for the separation of plant pigments such as chlorophyll, carotenes, and xanthophylls. Since these components have different colors (green, orange, and yellow, respectively) they gave the technique its name. New types of chromatography developed during the 1930s and 1940s made the technique useful for many separation processes.\n\nChromatography technique developed substantially as a result of the work of Archer John Porter Martin and Richard Laurence Millington Synge during the 1940s and 1950s, for which they won a Nobel prize. They established the principles and basic techniques of partition chromatography, and their work encouraged the rapid development of several chromatographic methods: paper chromatography, gas chromatography, and what would become known as high performance liquid chromatography. Since then, the technology has advanced rapidly. Researchers found that the main principles of Tsvet's chromatography could be applied in many different ways, resulting in the different varieties of chromatography described below. Advances are continually improving the technical performance of chromatography, allowing the separation of increasingly similar molecules.\n\nChromatography is based on the concept of partition coefficient. Any solute partitions between two immiscible solvents. When we make one solvent immobile (by adsorption on a solid support matrix) and another mobile it results in most common applications of chromatography. If the matrix support, or stationary phase, is polar (e.g. paper, silica etc.) it is forward phase chromatography, and if it is non-polar (C-18) it is reverse phase.\n\nColumn chromatography is a separation technique in which the stationary bed is within a tube. The particles of the solid stationary phase or the support coated with a liquid stationary phase may fill the whole inside volume of the tube (packed column) or be concentrated on or along the inside tube wall leaving an open, unrestricted path for the mobile phase in the middle part of the tube (open tubular column). Differences in rates of movement through the medium are calculated to different retention times of the sample.\n\nIn 1978, W. Clark Still introduced a modified version of column chromatography called flash column chromatography (flash). The technique is very similar to the traditional column chromatography, except for that the solvent is driven through the column by applying positive pressure. This allowed most separations to be performed in less than 20 minutes, with improved separations compared to the old method. Modern flash chromatography systems are sold as pre-packed plastic cartridges, and the solvent is pumped through the cartridge. Systems may also be linked with detectors and fraction collectors providing automation. The introduction of gradient pumps resulted in quicker separations and less solvent usage.\n\nIn expanded bed adsorption, a fluidized bed is used, rather than a solid phase made by a packed bed. This allows omission of initial clearing steps such as centrifugation and filtration, for culture broths or slurries of broken cells.\n\nPhosphocellulose chromatography utilizes the binding affinity of many DNA-binding proteins for phosphocellulose. The stronger a protein's interaction with DNA, the higher the salt concentration needed to elute that protein.\n\nPlanar chromatography is a separation technique in which the stationary phase is present as or on a plane. The plane can be a paper, serving as such or impregnated by a substance as the stationary bed (paper chromatography) or a layer of solid particles spread on a support such as a glass plate (thin layer chromatography). Different compounds in the sample mixture travel different distances according to how strongly they interact with the stationary phase as compared to the mobile phase. The specific Retention factor (R) of each chemical can be used to aid in the identification of an unknown substance.\n\nPaper chromatography is a technique that involves placing a small dot or line of sample solution onto a strip of \"chromatography paper\". The paper is placed in a container with a shallow layer of solvent and sealed. As the solvent rises through the paper, it meets the sample mixture, which starts to travel up the paper with the solvent. This paper is made of cellulose, a polar substance, and the compounds within the mixture travel farther if they are non-polar. More polar substances bond with the cellulose paper more quickly, and therefore do not travel as far.\n\nThin layer chromatography (TLC) is a widely employed laboratory technique use to separate different biochemicals on the basis of their size and is similar to paper chromatography. However, instead of using a stationary phase of paper, it involves a stationary phase of a thin layer of adsorbent like silica gel, alumina, or cellulose on a flat, inert substrate. Compared to paper, it has the advantage of faster runs, better separations, and the choice between different adsorbents. For even better resolution and to allow for quantification, high-performance TLC can be used. An older popular use had been to differentiate chromosomes by observing distance in gel (separation of was a separate step).\n\nThe basic principle of displacement chromatography is:\nA molecule with a high affinity for the chromatography matrix (the displacer) competes effectively for binding sites, and thus displace all molecules with lesser affinities.\nThere are distinct differences between displacement and elution chromatography. In elution mode, substances typically emerge from a column in narrow, Gaussian peaks. Wide separation of peaks, preferably to baseline, is desired for maximum purification. The speed at which any component of a mixture travels down the column in elution mode depends on many factors. But for two substances to travel at different speeds, and thereby be resolved, there must be substantial differences in some interaction between the biomolecules and the chromatography matrix. Operating parameters are adjusted to maximize the effect of this difference. In many cases, baseline separation of the peaks can be achieved only with gradient elution and low column loadings. Thus, two drawbacks to elution mode chromatography, especially at the preparative scale, are operational complexity, due to gradient solvent pumping, and low throughput, due to low column loadings. Displacement chromatography has advantages over elution chromatography in that components are resolved into consecutive zones of pure substances rather than “peaks”. Because the process takes advantage of the nonlinearity of the isotherms, a larger column feed can be separated on a given column with the purified components recovered at significantly higher concentrations.\n\nGas chromatography (GC), also sometimes known as gas-liquid chromatography, (GLC), is a separation technique in which the mobile phase is a gas. Gas chromatographic separation is always carried out in a column, which is typically \"packed\" or \"capillary\". Packed columns are the routine work horses of gas chromatography, being cheaper and easier to use and often giving adequate performance. Capillary columns generally give far superior resolution and although more expensive are becoming widely used, especially for complex mixtures. Both types of column are made from non-adsorbent and chemically inert materials. Stainless steel and glass are the usual materials for packed columns and quartz or fused silica for capillary columns.\n\nGas chromatography is based on a partition equilibrium of analyte between a solid or viscous liquid stationary phase (often a liquid silicone-based material) and a mobile gas (most often helium). The stationary phase is adhered to the inside of a small-diameter (commonly 0.53 – 0.18mm inside diameter) glass or fused-silica tube (a capillary column) or a solid matrix inside a larger metal tube (a packed column). It is widely used in analytical chemistry; though the high temperatures used in GC make it unsuitable for high molecular weight biopolymers or proteins (heat denatures them), frequently encountered in biochemistry, it is well suited for use in the petrochemical, environmental monitoring and remediation, and industrial chemical fields. It is also used extensively in chemistry research.\n\nLiquid chromatography (LC) is a separation technique in which the mobile phase is a liquid. It can be carried out either in a column or a plane. Present day liquid chromatography that generally utilizes very small packing particles and a relatively high pressure is referred to as high performance liquid chromatography (HPLC).\n\nIn HPLC the sample is forced by a liquid at high pressure (the mobile phase) through a column that is packed with a stationary phase composed of irregularly or spherically shaped particles, a porous monolithic layer, or a porous membrane. HPLC is historically divided into two different sub-classes based on the polarity of the mobile and stationary phases. Methods in which the stationary phase is more polar than the mobile phase (e.g., toluene as the mobile phase, silica as the stationary phase) are termed normal phase liquid chromatography (NPLC) and the opposite (e.g., water-methanol mixture as the mobile phase and C18 (octadecylsilyl) as the stationary phase) is termed reversed phase liquid chromatography (RPLC).\n\nSpecific techniques under this broad heading are listed below.\n\nAffinity chromatography is based on selective non-covalent interaction between an analyte and specific molecules. It is very specific, but not very robust. It is often used in biochemistry in the purification of proteins bound to tags. These fusion proteins are labeled with compounds such as His-tags, biotin or antigens, which bind to the stationary phase specifically. After purification, some of these tags are usually removed and the pure protein is obtained.\n\nAffinity chromatography often utilizes a biomolecule's affinity for a metal (Zn, Cu, Fe, etc.). Columns are often manually prepared. Traditional affinity columns are used as a preparative step to flush out unwanted biomolecules.\n\nHowever, HPLC techniques exist that do utilize affinity chromatography properties. Immobilized Metal Affinity Chromatography (IMAC) is useful to separate aforementioned molecules based on the relative affinity for the metal (I.e. Dionex IMAC). Often these columns can be loaded with different metals to create a column with a targeted affinity.\n\nSupercritical fluid chromatography is a separation technique in which the mobile phase is a fluid above and relatively close to its critical temperature and pressure.\n\nIon exchange chromatography (usually referred to as ion chromatography) uses an ion exchange mechanism to separate analytes based on their respective charges. It is usually performed in columns but can also be useful in planar mode. Ion exchange chromatography uses a charged stationary phase to separate charged compounds including anions, cations, amino acids, peptides, and proteins. In conventional methods the stationary phase is an ion exchange resin that carries charged functional groups that interact with oppositely charged groups of the compound to retain. Ion exchange chromatography is commonly used to purify proteins using FPLC.\n\nSize-exclusion chromatography (SEC) is also known as gel permeation chromatography (GPC) or gel filtration chromatography and separates molecules according to their size (or more accurately according to their hydrodynamic diameter or hydrodynamic volume).\nSmaller molecules are able to enter the pores of the media and, therefore, molecules are trapped and removed from the flow of the mobile phase. The average residence time in the pores depends upon the effective size of the analyte molecules. However, molecules that are larger than the average pore size of the packing are excluded and thus suffer essentially no retention; such species are the first to be eluted. It is generally a low-resolution chromatography technique and thus it is often reserved for the final, \"polishing\" step of a purification. It is also useful for determining the tertiary structure and quaternary structure of purified proteins, especially since it can be carried out under native solution conditions.\n\nAn expanded bed chromatographic adsorption (EBA) column for a biochemical separation process comprises a pressure equalization liquid distributor having a self-cleaning function below a porous blocking sieve plate at the bottom of the expanded bed, an upper part nozzle assembly having a backflush cleaning function at the top of the expanded bed, a better distribution of the feedstock liquor added into the expanded bed ensuring that the fluid passed through the expanded bed layer displays a state of piston flow. The expanded bed layer displays a state of piston flow. The expanded bed chromatographic separation column has advantages of increasing the separation efficiency of the expanded bed.\n\nExpanded-bed adsorption (EBA) chromatography is a convenient and effective technique for the capture of proteins directly from unclarified crude sample. In EBA chromatography, the settled bed is first expanded by upward flow of equilibration buffer. The crude feed, a mixture of soluble proteins, contaminants, cells, and cell debris, is then passed upward through the expanded bed. Target proteins are captured on the adsorbent, while particulates and contaminants pass through. A change to elution buffer while maintaining upward flow results in desorption of the target protein in expanded-bed mode. Alternatively, if the flow is reversed, the adsorbed particles will quickly settle and the proteins can be desorbed by an elution buffer. The mode used for elution (expanded-bed versus settled-bed) depends on the characteristics of the feed. After elution, the adsorbent is cleaned with a predefined cleaning-in-place (CIP) solution, with cleaning followed by either column regeneration (for further use) or storage.\n\nReversed-phase chromatography (RPC) is any liquid chromatography procedure in which the mobile phase is significantly more polar than the stationary phase. It is so named because in normal-phase liquid chromatography, the mobile phase is significantly less polar than the stationary phase. Hydrophobic molecules in the mobile phase tend to adsorb to the relatively hydrophobic stationary phase. Hydrophilic molecules in the mobile phase will tend to elute first. Separating columns typically comprise a C8 or C18 carbon-chain bonded to a silica particle substrate.\n\nHydrophobic interactions between proteins and the chromatographic matrix can be exploited to purify proteins. In hydrophobic interaction chromatography the matrix material is lightly substituted with hydrophobic groups. These groups can range from methyl, ethyl, propyl, octyl, or phenyl groups.[] At high salt concentrations, non-polar sidechains on the surface on proteins \"interact\" with the hydrophobic groups; that is, both types of groups are excluded by the polar solvent (hydrophobic effects are augmented by increased ionic strength). Thus, the sample is applied to the column in a buffer which is highly polar. The eluant is typically an aqueous buffer with decreasing salt concentrations, increasing concentrations of detergent (which disrupts hydrophobic interactions), or changes in pH.\n\nIn general, Hydrophobic Interaction Chromatography (HIC) is advantageous if the sample is sensitive to pH change or harsh solvents typically used in other types of chromatography but not high salt concentrations. Commonly, it is the amount of salt in the buffer which is varied. In 2012, Müller and Franzreb described the effects of temperature on HIC using Bovine Serum Albumin (BSA) with four different types of hydrophobic resin. The study altered temperature as to effect the binding affinity of BSA onto the matrix. It was concluded that cycling temperature from 50 degrees to 10 degrees would not be adequate to effectively wash all BSA from the matrix but could be very effective if the column would only be used a few times. Using temperature to effect change allows labs to cut costs on buying salt and saves money.\n\nIf high salt concentrations along with temperature fluctuations want to be avoided you can use a more hydrophobic to compete with your sample to elute it. [source] This so-called salt independent method of HIC showed a direct isolation of Human Immunoglobulin G (IgG) from serum with satisfactory yield and used Beta-cyclodextrin as a competitor to displace IgG from the matrix. This largely opens up the possibility of using HIC with samples which are salt sensitive as we know high salt concentrations precipitate proteins.\n\nIn some cases, the chemistry within a given column can be insufficient to separate some analytes. It is possible to direct a series of unresolved peaks onto a second column with different physico-chemical (Chemical classification) properties. Since the mechanism of retention on this new solid support is different from the first dimensional separation, it can be possible to separate compounds that are indistinguishable by one-dimensional chromatography.\nThe sample is spotted at one corner of a square plate,developed, air-dried, then rotated by 90° and usually redeveloped in a second solvent system.\n\nThe simulated moving bed (SMB) technique is a variant of high performance liquid chromatography; it is used to separate particles and/or chemical compounds that would be difficult or impossible to resolve otherwise. This increased separation is brought about by a valve-and-column arrangement that is used to lengthen the stationary phase indefinitely.\nIn the moving bed technique of preparative chromatography the feed entry and the analyte recovery are simultaneous and continuous, but because of practical difficulties with a continuously moving bed, simulated moving bed technique was proposed. In the simulated moving bed technique instead of moving the bed, the sample inlet and the analyte exit positions are moved continuously, giving the impression of a moving bed.\nTrue moving bed chromatography (TMBC) is only a theoretical concept. Its simulation, SMBC is achieved by the use of a multiplicity of columns in series and a complex valve arrangement, which provides for sample and solvent feed, and also analyte and waste takeoff at appropriate locations of any column, whereby it allows switching at regular intervals the sample entry in one direction, the solvent entry in the opposite direction, whilst changing the analyte and waste takeoff positions appropriately as well.\n\nPyrolysis gas chromatography mass spectrometry is a method of chemical analysis in which the sample is heated to decomposition to produce smaller molecules that are separated by gas chromatography and detected using mass spectrometry.\n\nPyrolysis is the thermal decomposition of materials in an inert atmosphere or a vacuum. The sample is put into direct contact with a platinum wire, or placed in a quartz sample tube, and rapidly heated to 600–1000 °C. Depending on the application even higher temperatures are used. Three different heating techniques are used in actual pyrolyzers: Isothermal furnace, inductive heating (Curie Point filament), and resistive heating using platinum filaments. Large molecules cleave at their weakest points and produce smaller, more volatile fragments. These fragments can be separated by gas chromatography. Pyrolysis GC chromatograms are typically complex because a wide range of different decomposition products is formed. The data can either be used as fingerprint to prove material identity or the GC/MS data is used to identify individual fragments to obtain structural information. To increase the volatility of polar fragments, various methylating reagents can be added to a sample before pyrolysis.\n\nBesides the usage of dedicated pyrolyzers, pyrolysis GC of solid and liquid samples can be performed directly inside Programmable Temperature Vaporizer (PTV) injectors that provide quick heating (up to 30 °C/s) and high maximum temperatures of 600–650 °C. This is sufficient for some pyrolysis applications. The main advantage is that no dedicated instrument has to be purchased and pyrolysis can be performed as part of routine GC analysis. In this case quartz GC inlet liners have to be used. Quantitative data can be acquired, and good results of derivatization inside the PTV injector are published as well.\n\nFast protein liquid chromatography (FPLC), is a form of liquid chromatography that is often used to analyze or purify mixtures of proteins. As in other forms of chromatography, separation is possible because the different components of a mixture have different affinities for two materials, a moving fluid (the \"mobile phase\") and a porous solid (the stationary phase). In FPLC the mobile phase is an aqueous solution, or \"buffer\". The buffer flow rate is controlled by a positive-displacement pump and is normally kept constant, while the composition of the buffer can be varied by drawing fluids in different proportions from two or more external reservoirs. The stationary phase is a resin composed of beads, usually of cross-linked agarose, packed into a cylindrical glass or plastic column. FPLC resins are available in a wide range of bead sizes and surface ligands depending on the application.\n\nCountercurrent chromatography (CCC) is a type of liquid-liquid chromatography, where both the stationary and mobile phases are liquids. \nThe operating principle of CCC equipment requires a column consisting of an open tube coiled around a bobbin. The bobbin is rotated in a double-axis gyratory motion (a cardioid), which causes a variable gravity (G) field to act on the column during each rotation. This motion causes the column to see one partitioning step per revolution and components of the sample separate in the column due to their partitioning coefficient between the two immiscible liquid phases used. There are many types of CCC available today. These include HSCCC (High Speed CCC) and HPCCC (High Performance CCC). HPCCC is the latest and best performing version of the instrumentation available currently.\n\nChiral chromatography involves the separation of stereoisomers. In the case of enantiomers, these have no chemical or physical differences apart from being three-dimensional mirror images. Conventional chromatography or other separation processes are incapable of separating them. To enable chiral separations to take place, either the mobile phase or the stationary phase must themselves be made chiral, giving differing affinities between the analytes. Chiral chromatography HPLC columns (with a chiral stationary phase) in both normal and reversed phase are commercially available.\n\n", "id": "6329", "title": "Chromatography"}
{"url": "https://en.wikipedia.org/wiki?curid=6330", "text": "Clement Martyn Doke\n\nClement Martyn Doke (16 May 1893 in Bristol, United Kingdom – 24 February 1980 in East London, South Africa) was a South African linguist working mainly on African languages. Realizing that the grammatical structures of Bantu languages are quite different from those of European languages, he was one of the first African linguists of his time to abandon the Euro-centric approach to language description for a more locally grounded one. A most prolific writer, he published a string of grammars, several dictionaries, comparative work, and a history of Bantu linguistics.\n\nThe Doke family had been engaged in missionary activity for the Baptist Church for some generations. His father Reverend Joseph J. Doke left England and travelled to South Africa in 1882, where he met and married Agnes Biggs. They returned to England, where Clement was born as the third of four children. The family moved to New Zealand and eventually returned to South Africa in 1903, where they later on settled in Johannesburg.\n\nAt the age of 18, Clement received a bachelor's degree from Transvaal University College in Pretoria (now the University of Pretoria). He decided to devote his life to missionary activity. In 1913, he accompanied his father on a tour of north-western Rhodesia, to an area called Lambaland, now known as Ilamba. It is situated at the watershed of the Congo and Zambesi rivers, part of the district lay in Northern Rhodesia and part in the Belgian Congo State. The Cape-Cairo Railway threaded through its eastern portion; otherwise, travelling mostly had to be done on foot.\n\nThe Reverend William Arthur Phillips of the Nyasa Industrial Mission in Blantyre had established a Baptist mission there in 1905, serving an area of and 50,000 souls. The Dokes were supposed to investigate, whether the mission in Lambaland could be taken over by the Baptist Union of South Africa. It was on this trip that Doke's father contracted enteric fever and died soon afterwards (Gandhi attended the memorial service and addressed the congregation). Clement assumed his father's role.\n\nThe South African Baptists decided to take over Kafulafuta Mission, while its founder Reverend Phillips remained as superintendent. Clement Doke returned to Kafulafuta as missionary in 1914, followed by his sister Olive two years later.\n\nAt first, Clement Doke was frustrated by his inability to communicate with the Lamba. The only written material available at the time was a translation of Jonah and a collection of 47 hymns. Soon he mastered the language and published his first book \"Ifintu Fyakwe Lesa\" (The Things of God, a Primer of Scripture Knowledge) in 1917. He enrolled in Johannesburg as the extension of Transvaal University College for an MA degree. His thesis was published as \"The Grammar of the Lamba language\". The book is couched in traditional grammatical terms as Doke had not yet established his innovative method of analysis and description for the Bantu languages. His later \"Textbook of Lamba Grammar\" is far superior in this respect. \n\nClement Doke was also interested in ethnology. In 1931 he compiled \"The Lambas of Northern Rhodesia\", which remains one of the outstanding ethnographic descriptions of the peoples of Central Africa. For Doke, literacy was part of the evangelisation since people had to be able to read to appreciate the message of the Bible, but it was only after his retirement that he completed the translation of the Bible into Lamba. It was published under the title of \"Amasiwi AwaLesa\" (The Words of God) in 1959.\n\nIn 1919 Doke married Hilda Lehmann, who accompanied him back to Lambaland. They both contracted malaria during their work and she was forbidden to return to Lambaland. Clement Doke also realised that his field work couldn't continue much longer and left in 1921. He was recruited by the newly founded University of the Witwatersrand. In order to secure a qualification as a lecturer, the family moved to England, where he registered at the School of Oriental and African Studies. His major languages were Lamba and Luba, but as no suitable examiner was available, he eventually had to change his language to Zulu.\n\nDoke took up his appointment in the new Department of Bantu Studies at the University of Witwatersrand in 1923. In 1925 he received his D. Litt. for his doctoral thesis \"The Phonetics of the Zulu Language\" and was promoted to Senior Lecturer. In 1931 he was appointed to the Chair of Bantu Studies and thus headed the Department of Bantu Studies. The Department acted as a catalyst for the admission of Africans to the University: as early as 1925 a limited number were admitted to the vacation course in African Studies. Doke supported the appointment of Benedict Wallet Vilakazi as member of the staff, as he believed a native speaker was essential for acquiring a language. This provoked a storm of criticism and controversy from the public. They both collaborated on the \"Zulu-English Dictionary\", first published in 1948. It is still one of the best examples of lexicography for any of the Bantu languages. \n\nAt the request of the government of Southern Rhodesia, Doke investigated the range of dialect diversity among the languages of the country and made recommendations for \"Unified Shona\". This formed the basis for Standard Shona. He devised a unified orthography based on the Zezuru, Karanga and Manyika dialects. However, Doke's orthography was never fully accepted and the South African government introduced an alternative, leaving Shona with two competing orthographies between 1935 and 1955.\n\nDuring his tenure Doke developed and promoted a method of linguistic analysis and description of the Bantu languages that was based upon the structure of these languages. The \"Dokean model\" continues to be one of the dominant models of linguistic description in Southern and Central Africa. His classification of the Bantu languages was for many years the dominant view of the interrelations among the African languages. He was also an early describer of Khoisan and Bantu click consonants, devising phonetic symbols for a number of them. \n\nDoke served the University of the Witwatersrand until his retirement in 1953. He was awarded the honorary degree of Doctor of letters by Rhodes University and the honorary degree of Doctor of Laws by the University of the Witwatersrand in 1972.\n\nThe former missionary always remained devoted to the Baptist Church. He was elected President of the South African Baptist Union in 1949 and spent a year visiting churches and mission stations. He used his presidential address in condemning the recently established apartheid policy: \"I solemnly warn the Government that the spirit behind their apartheid legislation, and the way in which they are introducing discriminatory measures of all types today, will bring disaster upon this fair land of ours.\"\n\n", "id": "6330", "title": "Clement Martyn Doke"}
{"url": "https://en.wikipedia.org/wiki?curid=6331", "text": "Carl Meinhof\n\nCarl Friedrich Michael Meinhof (July 23, 1857 – February 11, 1944) was a German linguist and one of the first linguists to study African languages.\n\nMeinhof was born in Barzwitz near Rügenwalde in the Province of Pomerania. He studied at the University of Tübingen and at the University of Greifswald. In 1905 he became professor at the School of Oriental Studies in Berlin. On 5 May 1933 he became a member of the Nazi Party.\n\nHis most notable work was developing comparative grammar studies of the Bantu languages, building on the pioneering work of Wilhelm Bleek. In his work, Meinhof looked at the common Bantu languages such as Swahili and Zulu to determine similarities and differences.\n\nIn his work, Meinhof looked at noun classes with all Bantu languages having at least 10 classes and with 22 classes of nouns existing throughout the Bantu languages, though his definition of noun class differs slightly from the accepted one, considering the plural form of a word as belonging to a different class from the singular form (thus leading, for example, to consider a language like French as having four classes instead of two). While no language has all 22 (later: 23) classes active, Venda has 20, Lozi has 18, and Ganda has 16 or 17 (depending on whether the locative class 23 \"e-\" is included). All Bantu languages have a noun class specifically for humans (sometimes including other animate beings).\n\nMeinhof also examined other African languages, including groups classified at the time as Kordofanian, Bushman, Khoikhoi, and Hamitic.\n\nMeinhof developed a comprehensive classification scheme for African languages. His classification was the standard one for many years (Greenberg 1955:3). It was replaced by those of Joseph Greenberg in 1955 and in 1963.\n\nIn 1902, Meinhof made recordings of East African music. These are among the first recordings made of traditional African music.\n\nIn 1912, Carl Meinhof published \"Die Sprachen Der Hamiten\" (The Languages of the Hamites). He used the term Hamitic. Meinhof's system of classification of the Hamitic languages was based on a belief that \"speakers of Hamitic became largely coterminous with cattle herding peoples with essentially Caucasian origins, intrinsically different from and superior to the 'Negroes of Africa'.\" However, in the case of the so-called Nilo-Hamitic languages (a concept he introduced), it was based on the typological feature of gender and a \"fallacious theory of language mixture.\" Meinhof did this in spite of earlier work by scholars such as Lepsius and Johnston demonstrating that the languages which he would later dub \"Nilo-Hamitic\" were in fact Nilotic languages with numerous similarities in vocabulary with other Nilotic languages.\n\nCarl Meinhof was the great-uncle (the brother of the grandfather) of Ulrike Meinhof, a founding member of the German Red Army Faction (RAF), a left-wing militant group, which operated in West Germany in the 1970s and 1980s.\n\n", "id": "6331", "title": "Carl Meinhof"}
{"url": "https://en.wikipedia.org/wiki?curid=6335", "text": "Cucurbitaceae\n\nThe Cucurbitaceae, also called cucurbits and the gourd family, are a plant family consisting of about 965 species in around 95 genera, the most important of which are:\n\nThe plants in this family are grown around the tropics and in temperate areas, where those with edible fruits were among the earliest cultivated plants both in the Old and New Worlds. The Cucurbitaceae family ranks among the highest of plant families for number and percentage of species used as human food.\n\nThe Cucurbitaceae consist of 98 proposed genera with 975 species, mainly in regions tropical and subtropical. All species are sensitive to frost. Most of the plants in this family are annual vines, but some are woody lianas, thorny shrubs, or trees (\"Dendrosicyos\"). Many species have large, yellow or white flowers. The stems are hairy and pentangular. Tendrils are present at 90° to the leaf petioles at nodes. Leaves are exstipulate alternate simple palmately lobed or palmately compound. The flowers are unisexual, with male and female flowers on different plants (dioecious) or on the same plant (monoecious). The female flowers have inferior ovaries. The fruit is often a kind of modified berry called a pepo.\n\nOne of the oldest fossil records so far is \"Cucurbitaciphyllum lobatum\" from the Paleocene epoch, found at Shirley Canal, Montana. It was described for the first time in 1924 by Knowlton. The fossil leaf is palmate, trilobed with rounded lobal sinuses and an entire or serrate margin. It has a leaf pattern similar to the members of the genera \"Kedrostis\", \"Melothria\" and \"Zehneria\".\n\nThe most recent classification of Cucurbitaceae delineates 15 tribes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"Abobra, Acanthosicyos, Actinostemma, Alsomitra, Ampelosicyos, Anisosperma, Apodanthera, Austrobryonia, Baijiania, Bambekea, Bayabusua, Benincasa, Borneosicyos, Bryonia, Calycophysum, Cayaponia, Cephalopentandra, Ceratosanthes, Cionosicys, Citrullus, Coccinia, Cogniauxia, Corallocarpus, Ctenolepis, Cucumis, Cucurbita, Cucurbitella, Cyclanthera, Cyclantheropsis, Dactyliandra, Dendrosicyos, Diplocyclos, Doyerea, Ecballium, Echinocystis, Echinopepon, Eureiandra, Fevillea, Frantzia, Gerrardanthus, Gomphogyne, Gurania, Gynostemma, Halosicyos, Hanburia, Helmontia, Hemsleya, Herpetospermum, Hodgsonia, Ibervillea, Indofevillea, Indomelothria, Kedrostis, Khmeriosicyos, Lagenaria, Lemurosicyos, Linnaeosicyos, Luffa, Marah, Melothria, Melotrianthus, Momordica, Muellerargia, Neoalsomitra, Nothoalsomitra, Papuasicyos, Penelopeia, Peponium, Peponopsis, Polyclathra, Psiguria, Pteropepon, Raphidiocystis, Ruthalicia, Schizocarpum, Schizopepon, Scopellaria, Seyrigia, Sicana, Sicydium, Sicyos, Siolmatra, Siraitia, Solena, Tecunumania, Telfairia, Thladiantha, Trichosanthes, Trochomeria, Trochomeriopsis, Tumamoca, Wilbrandia, Xerosicyos, Zanonia, Zehneria.\"\nModern molecular phylogenetics suggest the following relationships:\n\nSix cucurbit crops are represented in 23 Byzantine-era mosaics from Israel, these being round melons (\"Cucumis melo\"), watermelons (\"Citrullus lanatus\"), sponge gourds (\"Luffa aegyptiaca\"), snake melons (\"faqqous\", \"Cucumis melo\" flexuosus group), \"adzhur\" melons (\"C. melo\" adzhur group), and bottle gourds (\"Lagenaria siceraria\"). Cucurbits are represented in 23 of the 134 mosaics containing images of crop plants, a surprisingly high frequency of 17%. Several of the cucurbit images have not been found elsewhere, suggesting a diverse and highly developed local horticulture of cucurbits in Israel during the Byzantine era. Representations of mature sponge gourds are found in widespread localities, suggestive of the high value accorded to cleanliness and hygiene.\n\nThe name \"Cucurbitaceae\" () comes to international scientific vocabulary from New Latin, from \"Cucurbita\", the type genus, + \"-aceae\", a standardized suffix for plant family names in modern taxonomy. The genus name comes from the Classical Latin word \"cucurbita\", \"gourd\".\n\n\n", "id": "6335", "title": "Cucurbitaceae"}
