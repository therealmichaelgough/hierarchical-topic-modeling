{"url": "https://en.wikipedia.org/wiki?curid=2703", "text": "Aberration of light\n\nThe aberration of light (also referred to as astronomical aberration, stellar aberration, or velocity aberration) is an astronomical phenomenon which produces an apparent motion of celestial objects about their true positions, dependent on the velocity of the observer. Aberration causes objects to appear to be angled or tilted towards the direction of motion of the observer compared to when the observer is stationary. The change in angle is typically very small — of the order of \"v/c\" where \"c\" is the speed of light and \"v\" the velocity of the observer. In the case of \"stellar\" or \"annual\" aberration, the apparent position of a star to an observer on Earth varies periodically over the course of a year as the Earth's velocity changes as it revolves around the Sun, by a maximum angle of approximately 20 arcseconds in right ascension or declination.\n\nThe term \"aberration\" has historically been used to refer to a number of related phenomena concerning the propagation of light in moving bodies. \nAberration should not be confused with \"parallax\". The latter is a change in the apparent position of a relatively nearby object, as measured by a moving observer, relative to more distant objects that define a reference frame. The amount of parallax depends on the \"distance\" of the object from the observer, whereas aberration does not. Aberration is also related to light-time correction and relativistic beaming, although it is often considered separately from these effects.\n\nAberration is historically significant because of its role in the development of the theories of light, electromagnetism and, ultimately, the theory of special relativity. It was first observed in the late 1600s by astronomers searching for stellar parallax in order to confirm the heliocentric model of the Solar System. However, it was not understood at the time to be a different phenomenon.\nIn 1727, James Bradley provided a classical explanation for it in terms of the finite speed of light relative to the motion of the Earth in its orbit around the Sun, \nwhich he used to make one of the earliest measurements of the speed of light. However, Bradley's theory was incompatible with 19th century theories of light, and aberration became a major motivation for the aether drag theories of Augustin Fresnel (in 1818) and G. G. Stokes (in 1845), and for Hendrick Lorentz's aether theory of electromagnetism in 1892. The aberration of light, together with Lorentz's elaboration of Maxwell's electrodynamics, the moving magnet and conductor problem, the negative aether drift experiments, as well as the Fizeau experiment, led Albert Einstein to develop the theory of special relativity in 1905, which provided a conclusive explanation for the phenomenon.\n\nAberration may be explained as the difference in angle of a beam of light in different inertial frames of reference. A common analogy is to consider the apparent direction of falling rain. If rain is falling vertically in the frame of reference of a person standing still, then to a person moving forwards the rain will appear to arrive at an angle, requiring the moving observer to tilt their umbrella forwards. The faster the observer moves, the more tilt is needed.\n\nThe net effect is that light rays striking the moving observer from the sides in a stationary frame will come angled from ahead in the moving observer's frame. This effect is sometimes called the \"searchlight\" or \"headlight\" effect.\n\nIn the case of annual aberration of starlight, the direction of incoming starlight as seen in the Earth's moving frame is tilted relative to the angle observed in the Sun's frame. Since the direction of motion of the Earth changes during its orbit, the direction of this tilting changes during the course of the year, and causes the apparent position of the star to differ from its true position as measured in the inertial frame of the Sun.\n\nWhile classical reasoning gives intuition for aberration, it leads to a number of physical paradoxes observable even at the classical level (see history). The theory of special relativity is required to correctly account for aberration. The relativistic explanation is very similar to the classical one however, and in both theories aberration may be understood as a case of addition of velocities.\n\nIn the Sun's frame, consider a beam of light with velocity equal to the speed of light c, with x and y velocity components formula_1 and formula_2, at an angle formula_3. If the Earth is moving at velocity formula_4 in the x direction relative to the Sun, then by velocity addition the x component of the beam's velocity in the Earth's frame of reference is formula_5, and the y velocity is unchanged, formula_6. (Note that you need the velocity of the Sun with respect to the Earth which is the negative of the velocity of the Earth with respect to the Sun. Also note that we are only using vectors here without indication of direction.) Thus the angle of the light in the Earth's frame in terms of the angle in the Sun's frame is\n\nIn the case of formula_8, this result reduces to formula_9.\n\nThe reasoning in the relativistic case is the same except that the relativistic velocity addition formulae must be used, which can be derived from Lorentz transformations between different frames of reference. These formulae are\n\nwhere formula_12, giving the components of the light beam in the Earth's frame in terms of the components in the Sun's frame. The angle of the beam in the Earth's frame is thus \n\nIn the case of formula_8, this result reduces to formula_15, and in the limit formula_16 this may be approximated by formula_17. This relativistic derivation keeps the speed of light formula_18 constant in all frames of reference, unlike the classical derivation above.\n\nAberration is related to two other phenomena, light-time correction, which is due to the motion of an observed object during the time taken by its light to reach an observer, and relativistic beaming, which is an angling of the light emitted by a moving light source. It can be considered equivalent to them but in a different inertial frame of reference. In aberration, the observer is considered to be moving relative to a (for the sake of simplicity) stationary light source, while in light-time correction and relativistic beaming the light source is considered to be moving relative to a stationary observer.\n\nConsider the case of an observer and a light source moving relative to each other at constant velocity, with a light beam moving from the source to the observer. At the moment of emission, the beam in the observer's rest frame is tilted compared to the one in the source's rest frame, as understood through relativistic beaming. During the time it takes the light beam to reach the observer the light source moves in the observer's frame, and the 'true position' of the light source is displaced relative to the apparent position the observer sees, as explained by light-time correction. Finally, the beam in the observer's frame at the moment of observation is tilted compared to the beam in source's frame, which can be understood as an aberrational effect. Thus, a person in the light source's frame would describe the apparent tilting of the beam in terms of aberration, while a person in the observer's frame would describe it as a light-time effect.\n\nThe relationship between these phenomena is only valid if the observer and source's frames are inertial frames. In practice, because the Earth is not an inertial rest frame but experiences centripetal acceleration towards the Sun, many aberrational effects such as annual aberration on Earth cannot be considered light-time corrections. However, if the time between emission and detection of the light is short compared to the orbital period of the Earth, the Earth may be approximated as an inertial frame and aberrational effects are equivalent to light-time corrections.\n\nThere are a number of types of aberration, caused by the differing components of the Earth's and observed object's motion:\n\n\nAnnual aberration is caused by the motion of an observer on the Earth revolving around the Sun. The velocity formula_4 of the Earth (in the Sun's rest frame) varies periodically over the course of a year as the Earth traverses its orbit and consequently the aberration also varies periodically, typically causing stars to appear to move in small ellipses.\n\nApproximating the Earth's orbit as circular, the maximum displacement of a star due to annual aberration is known as the \"constant of aberration\", conventionally represented by formula_20. It may be calculated using the relation formula_21 substituting the Earth's average speed in the Sun's frame for formula_4 and the speed of light formula_23. Its accepted value is 20″.49552  arcseconds (at J2000).\n\nAssuming a circular orbit, annual aberration causes stars exactly on the ecliptic (the plane of the Earth's orbit) to appear to move back and forth along a straight line, varying by formula_20 on either side of their position in the Sun's frame. A star that is precisely at one of the ecliptic poles (at 90 degrees from the ecliptic plane) will appear to move in a circle of radius formula_20 about its true position, and stars at intermediate ecliptic latitudes will appear to move along a small ellipse.\n\nFor illustration, consider a star at the northern ecliptic pole viewed by an observer at a point on the Arctic Circle. Such an observer will see the star transit at the zenith, once every day (strictly speaking sidereal day). At the time of the March equinox, the Earth's orbit carries the observer in a southwards direction, and the star's apparent declination is therefore displaced to the south by an angle of formula_20. At the September equinox, the star's position is displaced to the north by an equal and opposite amount. At the June and December solstices, the displacement in declination is zero. Conversely, the amount of displacement in right ascension is zero at either equinox and maximum at the solstices.\nIn practice the Earth's orbit is slightly elliptic rather than circular and its speed changes somewhat over the course of its orbit, which means the description above is only approximate. Aberration is more accurately calculated using the Earth's instantaneous velocity relative to the center of mass of the Solar System.\n\nNote that the displacement due to aberration is orthogonal to any displacement due to parallax. If parallax were detectable, the maximum displacement to the south would occur in December, and the maximum displacement to the north in June. It is this apparently anomalous motion that so mystified early astronomers.\n\nA special case of annual aberration is the nearly constant deflection of the Sun from its position in the Sun's rest frame by formula_20 towards the \"west\" (as viewed from Earth), opposite to the apparent motion of the Sun along the ecliptic (which is from west to east, as seen from Earth). The deflection thus makes the Sun appear to be behind (or retarded) from its rest-frame position on the ecliptic by a position or angle formula_20.\n\nThis deflection may equivalently be described as a light-time effect due to motion of the Earth during the 8.3 minutes that it takes light to travel from the Sun to Earth. This is possible since the transit time of sunlight is short relative to the orbital period of the Earth, so the Earth's frame may be approximated as inertial. In the Earth's frame, the Sun moves by a distance formula_29 in the time it takes light to reach Earth, formula_30 for the orbit of radius formula_31. This gives an angular correction formula_32 which can be solved to give formula_33, the same as the aberrational correction.\n\nPlanetary aberration is the combination of the aberration of light (due to Earth's velocity) and light-time correction (due to the object's motion and distance), as calculated in the rest frame of the Solar System. Both are determined at the instant when the moving object's light reaches the moving observer on Earth. It is so called because it is usually applied to planets and other objects in the Solar System whose motion and distance are accurately known.\n\nDiurnal aberration is caused by the velocity of the observer on the surface of the rotating Earth. It is therefore dependent not only on the time of the observation, but also the latitude and longitude of the observer. Its effect is much smaller than that of annual aberration, and is only 0′′.32 in the case of an observer at the equator, where the rotational velocity is greatest.\n\nThe Sun and Solar System are revolving around the center of the Galaxy. Aberration due to this motion is known as secular aberration and affects the apparent positions of distant stars and extragalactic objects. However, since the galactic year is about 230 million years, the aberration varies very slowly and this change is extremely difficult to observe. Therefore, secular aberration is usually ignored when considering the positions of stars. In other words, star maps show the observed apparent positions of the stars, not their calculated true positions after accounting for secular aberration.\n\nFor stars significantly less than 230 million light years away, the Solar System may be approximated as an inertial frame and so the effect of secular aberration is equivalent to a light-time correction. This includes stars in the Milky Way, since the Milky Way is about 100,000 light years in diameter. For these stars the true position of the star is then easily computed from its proper motion and its distance.\n\nSecular aberration is typically a small number of arcminutes, for example the stationary star Groombridge 1830 is displaced by approximately 3 arcminutes, due to secular aberration. This is roughly 8 times the effect of annual aberration, as one would expect since the velocity of the Solar System relative to the center of the Galaxy is about 8 times the velocity of the Earth relative to the Sun.\n\nThe discovery of the aberration of light was totally unexpected, and it was only by considerable perseverance and perspicacity that Bradley was able to explain it in 1727. It originated from attempts to discover whether stars possessed appreciable parallaxes.\n\nThe Copernican heliocentric theory of the Solar System had received confirmation by the observations of Galileo and Tycho Brahe and the mathematical investigations of Kepler and Newton. As early as 1573, Thomas Digges had suggested that parallactic shifting of the stars should occur according to the heliocentric model, and consequently if stellar parallax could be observed it would help confirm this theory. Many observers claimed to have determined such parallaxes, but Tycho Brahe and Giovanni Battista Riccioli concluded that they existed only in the minds of the observers, and were due to instrumental and personal errors. However, in 1680 Jean Picard, in his \"Voyage d’Uranibourg,\" stated, as a result of ten years' observations, that Polaris, the Pole Star, exhibited variations in its position amounting to 40″ annually. Some astronomers endeavoured to explain this by parallax, but these attempts failed because the motion differed from that which parallax would produce. John Flamsteed, from measurements made in 1689 and succeeding years with his mural quadrant, similarly concluded that the declination of Polaris was 40″ less in July than in September. Robert Hooke, in 1674, published his observations of γ Draconis, a star of magnitude 2 which passes practically overhead at the latitude of London (hence its observations are largely free from the complex corrections due to atmospheric refraction), and concluded that this star was 23″ more northerly in July than in October.\n\nConsequently, when Bradley and Samuel Molyneux entered this sphere of research in 1725, there was still considerable uncertainty as to whether stellar parallaxes had been observed or not, and it was with the intention of definitely answering this question that they erected a large telescope at Molyneux's house at Kew. They decided to reinvestigate the motion of γ Draconis with a telescope constructed by George Graham (1675–1751), a celebrated instrument-maker. This was fixed to a vertical chimney stack in such manner as to permit a small oscillation of the eyepiece, the amount of which (i.e. the deviation from the vertical) was regulated and measured by the introduction of a screw and a plumb line.\n\nThe instrument was set up in November 1725, and observations on γ Draconis were made starting in December. The star was observed to move 40″ southwards between September and March, and then reversed its course from March to September. At the same time, 35 Camelopardalis, a star with a right ascension nearly exactly opposite to that of γ Draconis, was 19\" more northerly at the beginning of March than in September. These results were completely unexpected and inexplicable by existing theories.\n\nBradley and Molyneux discussed several hypotheses in the hope of finding the solution. Since the apparent motion was evidently caused neither by parallax nor observational errors, Bradley first hypothesized that it could be due to oscillations in the orientation of the Earth's axis relative to the celestial sphere – a phenomenon known as nutation. 35 Camelopardalis was seen to possess an apparent motion which could be consistent with nutation, but since its declination varied only one half as much as that of γ Draconis, it was obvious that nutation did not supply the answer (however, Bradley later went on to discover that the Earth does indeed nutate). He also investigated the possibility that the motion was due to an irregular distribution of the Earth's atmosphere, thus involving abnormal variations in the refractive index, but again obtained negative results.\n\nOn August 19, 1727, Bradley embarked upon a further series of observations using a telescope of his own erected at the Rectory, Wanstead. This instrument had the advantage of a larger field of view and he was able to obtain precise positions of a large number of stars over the course of about twenty years. During his first two years at Wanstead, he established the existence of the phenomenon of aberration beyond all doubt, and this also enabled him to formulate a set of rules that would allow the calculation of the effect on any given star at a specified date.\n\nBradley eventually developed his explanation of aberration in about September 1728 and this theory was presented to the Royal Society in mid January the following year. One well-known story was that he saw the change of direction of a wind vane on a boat on the Thames, caused not by an alteration of the wind itself, but by a change of course of the boat relative to the wind direction.\nHowever, there is no record of this incident in Bradley's own account of the discovery, and it may therefore be apocryphal.\n\nBased on his early calculations, Bradley was able to estimate the constant of aberration at 20\", and with this was able to estimate the speed of light at per second.\n\nThe discovery and elucidation of aberration is now regarded as a classic case of the application of scientific method, in which observations are made to test a theory, but unexpected results are sometimes obtained that in turn lead to new discoveries. It is also worth noting that part of the original motivation of the search for stellar parallax was to test the Copernican theory that the Earth revolves around the Sun, but of course the existence of aberration also establishes the truth of that theory.\n\nThe phenomenon of aberration became a driving force for many physical theories during the 200 years between its observation and the conclusive explanation by Albert Einstein.\n\nThe first classical explanation was provided in 1729, by James Bradley as described above, who attributed it to the finite speed of light and the motion of Earth in its orbit around the Sun. However, this explanation proved inaccurate once the wave nature of light was better understood, and correcting it became a major goal of the 19th century theories of luminiferous aether. Augustin-Jean Fresnel proposed a correction due to the motion of a medium (the aether) through which light propagated, known as \"partial aether drag\". He proposed that objects partially drag the aether along with them as they move, and this became the accepted explanation for aberration for some time. George Stokes proposed a similar theory, explaining that aberration occurs due to the flow of aether induced by the motion of the Earth. Accumulated evidence against these explanations, combined with new understanding of the electromagnetic nature of light, led Hendrik Lorentz to develop an electron theory which featured an immobile aether, and he explained that objects contract in length as they move through the aether. Motivated by these previous theories, Albert Einstein then developed the theory of special relativity in 1905, which provides the modern account of aberration.\n\nBradley conceived of an explanation in terms of a corpuscular theory of light in which light is made of particles unaffected by gravity. His classical explanation appeals to the motion of the earth relative to a beam of light-particles moving at a finite velocity, and is developed in the Sun's frame of reference, unlike the classical derivation given above.\n\nConsider the case where a distant star is motionless relative to the Sun, and the star is extremely far away, so that parallax may be ignored. In the rest frame of the Sun, this means light from the star travels in parallel paths to the Earth observer, and arrives at the same angle regardless of where the Earth is in its orbit. Suppose the star is observed on Earth with a telescope, idealized as a narrow tube. The light enters the tube from the star at angle formula_34 and travels at speed formula_23 taking a time formula_36 to reach the bottom of the tube, where it is detected. Suppose observations are made from Earth, which is moving with a speed formula_4. During the transit of the light, the tube moves a distance formula_38. Consequently, for the particles of light to reach the bottom of the tube, the tube must be inclined at an angle formula_39 different from formula_34, resulting in an \"apparent\" position of the star at angle formula_39. As the Earth proceeds in its orbit it changes direction, so formula_39 changes with the time of year the observation is made. The apparent angle and true angle are related using trigonometry as:\n\nIn the case of formula_8, this gives formula_45. While this is different from the more accurate relativistic result described above, in the limit of small angle and low velocity they are approximately the same, within the error of the measurements of Bradley's day. These results allowed Bradley to make one of the earliest measurements of the speed of light.\n\nIn the early nineteenth century the wave theory of light was being rediscovered, and in 1804 Thomas Young adapted Bradley's explanation for corpuscular light to wavelike light traveling through a medium known as the luminiferous aether. His reasoning was the same as Bradley's, but it required that this medium be immobile in the Sun's reference frame and must pass through the earth unaffected, otherwise the medium (and therefore the light) would move along with the earth and no aberration would be observed. \nHowever, it soon became clear Young's theory could not account for aberration when materials with a non-vacuum index of refraction were present. An important example is of a telescope filled with water. The velocity of the light in such a telescope will be slower than in vacuum, and is given by formula_46 rather than formula_23 where formula_48 is the index of refraction of the water. Thus, by Bradley and Young's reasoning the aberration angle is given by\n\nwhich predicts a medium-dependent angle of aberration. When refraction at the telescope's objective is taken into account this result deviates even more from the vacuum result. In 1810 François Arago performed a similar experiment and found that the aberration was unaffected by the medium in the telescope, providing solid evidence against Young's theory. This experiment was subsequently verified by many others in the following decades, most accurately by Airy in 1871, with the same result.\n\nIn 1818, Augustin Fresnel developed a modified explanation to account for the water telescope and for other aberration phenomena. He explained that the aether is generally at rest in the Sun's frame of reference, but objects partially drag the aether along with them as they move. That is, the aether in an object of index of refraction formula_48 moving at velocity formula_4 is partially dragged with a velocity formula_52 bringing the light along with it. This factor is known as \"Fresnel's dragging coefficient\". This dragging effect, along with refraction at the telescope's objective, compensates for the slower speed of light in the water telescope in Bradley's explanation. With this modification Fresnel obtained Bradley's vacuum result even for non-vacuum telescopes, and was also able to predict many other phenomena related to the propagation of light in moving bodies. Fresnel's dragging coefficient became the dominant explanation of aberration for the next decades.\n\nHowever, the fact that light is polarized (discovered by Fresnel himself) led scientists such as Cauchy and Green to believe that the aether was a totally immobile elastic solid as opposed to Fresnel's fluid aether. There was thus renewed need for an explanation of aberration consistent both with Fresnel's predictions (and Arago's observations) as well as polarization.\n\nIn 1845, Stokes proposed a 'putty-like' aether which acts as a liquid on large scales but as a solid on small scales, thus supporting both the transverse vibrations required for polarized light and the aether flow required to explain aberration. Making only the assumptions that the fluid is irrotational and that the boundary conditions of the flow are such that the aether has zero velocity far from the Earth, but moves at the Earth's velocity at its surface and within it, he was able to completely account for aberration.\nThe velocity of the aether outside of the Earth would decrease as a function of distance from the Earth so light rays from stars would be progressively dragged as they approached the surface of the Earth. The Earth's motion would be unaffected by the aether due to D'Alembert's paradox.\n\nBoth Fresnel and Stokes' theories were popular. However, the question of aberration was put aside during much of the second half of the 19th century as focus of inquiry turned to the electromagnetic properties of aether.\n\nIn the 1880s once electromagnetism was better understood, interest turned again to the problem of aberration. By this time flaws were known to both Fresnel's and Stokes' theories. Fresnel's theory required that the relative velocity of aether and matter to be different for light of different colors, and it was shown that the boundary conditions Stokes had assumed in his theory were inconsistent with his assumption of irrotational flow. At the same time, the modern theories of electromagnetic aether could not account for aberration at all. Many scientists such as Maxwell, Heaviside and Hertz unsuccessfully attempted to solve these problems by incorporating either Fresnel or Stokes' theories into Maxwell's new electromagnetic laws.\n\nHendrik Lorentz spent considerable effort along these lines. After working on this problem for a decade, the issues with Stokes' theory caused him to abandon it and to follow Fresnel's suggestion of a (mostly) stationary aether (1892, 1895). However, in Lorentz's model the aether was \"completely\" immobile, like the electromagnetic aethers of Cauchy, Green and Maxwell and unlike Fresnel's aether. He obtained Fresnel's dragging coefficient from modifications of Maxwell's electromagnetic theory, including a modification of the time coordinates in moving frames (\"local time\"). In order to explain the Michelson–Morley experiment (1887), which apparently contradicted both Fresnel's and Lorentz's immobile aether theories, and apparently confirmed Stokes' complete aether drag, Lorentz theorized (1892) that objects undergo \"length contraction\" by a factor of formula_53 in the direction of their motion through the aether. In this way, aberration (and all related optical phenomena) can be accounted for in the context of an immobile aether. Lorentz' theory became the basis for much research in the next decade, and beyond. Its predictions for aberration are identical to those of the relativistic theory.\n\nLorentz' theory matched experiment well, but it was complicated and made many unsubstantiated physical assumptions about the microscopic nature of electromagnetic media. In his 1905 theory of special relativity, Albert Einstein reinterpreted the results of Lorentz' theory in a much simpler and more natural conceptual framework which disposed of the idea of an aether. His derivation is given above, and is now the accepted explanation. Robert S. Shankland reported some conversations with Einstein, in which Einstein emphasized the importance of aberration:\n\nOther important motivations for Einstein's development of relativity were the moving magnet and conductor problem and (indirectly) the negative aether drift experiments, already mentioned by him in the introduction of his first relativity paper. Einstein wrote in a note in 1952:\n\nWhile Einstein's result is the same as Bradley's original equation except for an extra factor of formula_54, it should be emphasized that Bradley's result does not merely give the classical limit of the relativistic case, in the sense that it gives incorrect predictions even at low relative velocities. Bradley's explanation cannot account for situations such as the water telescope, nor for many other optical effects (such as interference) that might occur within the telescope. This is because in the Earth's frame it predicts that the direction of propagation of the light beam in the telescope is not normal to the wavefronts of the beam, in contradiction with Maxwell's theory of electromagnetism. It also does not preserve the speed of light c between frames. However, Bradley did correctly infer that the effect was due to relative velocities.\n\n\n\n", "id": "2703", "title": "Aberration of light"}
{"url": "https://en.wikipedia.org/wiki?curid=2704", "text": "Optical aberration\n\nAn optical aberration is a departure of the performance of an optical system from the predictions of paraxial optics. In an imaging system, it occurs when light from one point of an object does not converge into (or does not diverge from) a single point after transmission through the system. Aberrations occur because the simple paraxial theory is not a completely accurate model of the effect of an optical system on light (due to the wave nature of light), rather than due to flaws in the optical elements.\n\nAberration leads to blurring of the image produced by an image-forming optical system. Makers of optical instruments need to correct optical systems to compensate for aberration.\n\nThe articles on reflection, refraction and caustics discuss the general features of reflected and refracted rays.\n\nAberrations fall into two classes: \"monochromatic\" and \"chromatic\". Monochromatic aberrations are caused by the geometry of the lens or mirror and occur both when light is reflected and when it is refracted. They appear even when using monochromatic light, hence the name.\n\nChromatic aberrations are caused by dispersion, the variation of a lens's refractive index with wavelength. They do not appear when monochromatic light is used.\n\n\nPiston and tilt are not actually true optical aberrations, as they do not represent or model curvature in the wavefront. If an otherwise perfect wavefront is \"aberrated\" by piston and tilt, it will still form a perfect, aberration-free image, only shifted to a different position. Defocus is the lowest-order true optical aberration.\n\n\nThe elementary theory of optical systems leads to the theorem: Rays of light proceeding from any \"object point\" unite in an \"image point\"; and therefore an \"object space\" is reproduced in an \"image space.\" The introduction of simple auxiliary terms, due to C. F. Gauss (\"Dioptrische Untersuchungen\", Göttingen, 1841), named the focal lengths and focal planes, permits the determination of the image of any object for any system (see lens). The Gaussian theory, however, is only true so long as the angles made by all rays with the optical axis (the symmetrical axis of the system) are infinitely small, i.e. with infinitesimal objects, images and lenses; in practice these conditions may not be realized, and the images projected by uncorrected systems are, in general, ill-defined and often completely blurred, if the aperture or field of view exceeds certain limits.\n\nThe investigations of James Clerk Maxwell (\"Phil.Mag.,\" 1856; \"Quart. Journ. Math.,\" 1858) and Ernst Abbe showed that the properties of these reproductions, i.e. the relative position and magnitude of the images, are not special properties of optical systems, but necessary consequences of the supposition (in Abbe) of the reproduction of all points of a space in image points (Maxwell assumes a less general hypothesis), and are independent of the manner in which the reproduction is effected. These authors proved, however, that no optical system can justify these suppositions, since they are contradictory to the fundamental laws of reflection and refraction. Consequently, the Gaussian theory only supplies a convenient method of approximating to reality; and no constructor would attempt to realize this unattainable ideal. At present, all that can be attempted is to reproduce a single plane in another plane; but even this has not been altogether satisfactorily accomplished: aberrations always occur, and it is improbable that these will ever be entirely corrected.\n\nThis, and related general questions, have been treated — besides the above-mentioned authors — by M. Thiesen (\"Berlin. Akad. Sitzber.,\" 1890, xxxv. 799; \"Berlin. Phys. Ges. Verh.,\" 1892) and H. Bruns (\"Leipzig. Math. Phys. Ber.,\" 1895, xxi. 325) by means of Sir W. R. Hamilton's \"characteristic function\" (Irish Acad. Trans., \"Theory of Systems of Rays\", 1828, et seq.). Reference may also be made to the treatise of Czapski-Eppenstein, pp. 155–161.\n\nA review of the simplest cases of aberration will now be given.\n\nLet S (fig. 1) be any optical system, rays proceeding from an axis point O under an angle u1 will unite in the axis point O'1; and those under an angle u2 in the axis point O'2. If there is refraction at a collective spherical surface, or through a thin positive lens, O'2 will lie in front of O'1 so long as the angle u2 is greater than u1 (\"under correction\"); and conversely with a dispersive surface or lenses (\"over correction\"). The caustic, in the first case, resembles the sign > (greater than); in the second < (less than). If the angle u1 is very small, O'1 is the Gaussian image; and O'1 O'2 is termed the \"longitudinal aberration,\" and O'1R the \"lateral aberration\" of the pencils with aperture u2. If the pencil with the angle u2 is that of the maximum aberration of all the pencils transmitted, then in a plane perpendicular to the axis at O'1 there is a circular \"disk of confusion\" of radius O'1R, and in a parallel plane at O'2 another one of radius O'2R2; between these two is situated the \"disk of least confusion.\"\n\nThe largest opening of the pencils, which take part in the reproduction of O, i.e. the angle u, is generally determined by the margin of one of the lenses or by a hole in a thin plate placed between, before, or behind the lenses of the system. This hole is termed the \"stop\" or \"diaphragm\"; Abbe used the term \"aperture stop\" for both the hole and the limiting margin of the lens. The component S1 of the system, situated between the aperture stop and the object O, projects an image of the diaphragm, termed by Abbe the \"entrance pupil\"; the \"exit pupil\" is the image formed by the component S2, which is placed behind the aperture stop. All rays which issue from O and pass through the aperture stop also pass through the entrance and exit pupils, since these are images of the aperture stop. Since the maximum aperture of the pencils issuing from O is the angle u subtended by the entrance pupil at this point, the magnitude of the aberration will be determined by the position and diameter of the entrance pupil. If the system be entirely behind the aperture stop, then this is itself the entrance pupil (\"front stop\"); if entirely in front, it is the exit pupil (\"back stop\").\n\nIf the object point be infinitely distant, all rays received by the first member of the system are parallel, and their intersections, after traversing the system, vary according to their \"perpendicular height of incidence,\" i.e. their distance from the axis. This distance replaces the angle u in the preceding considerations; and the aperture, i.e. the radius of the entrance pupil, is its maximum value.\n\nIf rays issuing from O (fig. 1) be concurrent, it does not follow that points in a portion of a plane perpendicular at O to the axis will be also concurrent, even if the part of the plane be very small. With a considerable aperture, the neighboring point N will be reproduced, but attended by aberrations comparable in magnitude to ON. These aberrations are avoided if, according to Abbe, the \"sine condition,\" sin u'1/sin u1=sin u'2/sin u2, holds for all rays reproducing the point O. If the object point O is infinitely distant, u1 and u2 are to be replaced by h1 and h2, the perpendicular heights of incidence; the \"sine condition\" then becomes sin u'1/h1=sin u'2/h2. A system fulfilling this condition and free from spherical aberration is called \"aplanatic\" (Greek a-, privative, plann, a wandering). This word was first used by Robert Blair (d. 1828), professor of practical astronomy at Edinburgh University, to characterize a superior achromatism, and, subsequently, by many writers to denote freedom from spherical aberration. Both the aberration of axis points, and the deviation from the sine condition, rapidly increase in most (uncorrected) systems with the aperture.\n\nA point O (fig. 2) at a finite distance from the axis (or with an infinitely distant object, a point which subtends a finite angle at the system) is, in general, even then not sharply reproduced if the pencil of rays issuing from it and traversing the system is made infinitely narrow by reducing the aperture stop; such a pencil consists of the rays which can pass from the object point through the now infinitely small entrance pupil. It is seen (ignoring exceptional cases) that the pencil does not meet the refracting or reflecting surface at right angles; therefore it is astigmatic (Gr. a-, privative, stigmia, a point). Naming the central ray passing through the entrance pupil the \"axis of the pencil\" or \"principal ray,\" it can be said: the rays of the pencil intersect, not in one point, but in two focal lines, which can be assumed to be at right angles to the principal ray; of these, one lies in the plane containing the principal ray and the axis of the system, i.e. in the \"first principal section\" or \"meridional section\", and the other at right angles to it, i.e. in the second principal section or sagittal section. We receive, therefore, in no single intercepting plane behind the system, as, for example, a focusing screen, an image of the object point; on the other hand, in each of two planes lines O' and O\" are separately formed (in neighboring planes ellipses are formed), and in a plane between O' and O\" a circle of least confusion. The interval O'O\", termed the astigmatic difference, increases, in general, with the angle W made by the principal ray OP with the axis of the system, i.e. with the field of view. Two \"astigmatic image surfaces\" correspond to one object plane; and these are in contact at the axis point; on the one lie the focal lines of the first kind, on the other those of the second. Systems in which the two astigmatic surfaces coincide are termed anastigmatic or stigmatic.\n\nSir Isaac Newton was probably the discoverer of astigmation; the position of the astigmatic image lines was determined by Thomas Young (\"A Course of Lectures on Natural Philosophy,\" 1807); and the theory was developed by Allvar Gullstrand. A bibliography by P. Culmann is given in Moritz von Rohr's \"Die Bilderzeugung in optischen Instrumenten\".\n\nBy opening the stop wider, similar deviations arise for lateral points as have been already discussed for axial points; but in this case they are much more complicated. The course of the rays in the meridional section is no longer symmetrical to the principal ray of the pencil; and on an intercepting plane there appears, instead of a luminous point, a patch of light, not symmetrical about a point, and often exhibiting a resemblance to a comet having its tail directed towards or away from the axis. From this appearance it takes its name. The unsymmetrical form of the meridional pencil—formerly the only one considered—is coma in the narrower sense only; other errors of coma have been treated by Arthur König and Moritz von Rohr, and later by Allvar Gullstrand.\n\nIf the above errors be eliminated, the two astigmatic surfaces united, and a sharp image obtained with a wide aperture—there remains the necessity to correct the curvature of the image surface, especially when the image is to be received upon a plane surface, e.g. in photography. In most cases the surface is concave towards the system.\n\nEven if the image is sharp, it may be distorted compared to ideal pinhole projection. In pinhole projection, the magnification of an object is inversely proportional to its distance to the camera along the optical axis so that a camera pointing directly at a flat surface reproduces that flat surface. Distortion can be thought of as stretching the image non-uniformly, or, equivalently, as a variation in magnification across the field. While \"distortion\" can include arbitrary deformation of an image, the most pronounced modes of distortion produced by conventional imaging optics is \"barrel distortion\", in which the center of the image is magnified more than the perimeter (figure 3a). The reverse, in which the perimeter is magnified more than the center, is known as \"pincushion distortion\" (figure 3b). This effect is called lens distortion or image distortion, and there are algorithms to correct it.\n\nSystems free of distortion are called \"orthoscopic\" (orthos, right, skopein to look) or \"rectilinear\" (straight lines).\nThis aberration is quite distinct from that of the sharpness of reproduction; in unsharp, reproduction, the question of distortion arises if only parts of the object can be recognized in the figure. If, in an unsharp image, a patch of light corresponds to an object point, the \"center of gravity\" of the patch may be regarded as the image point, this being the point where the plane receiving the image, e.g., a focusing screen, intersects the ray passing through the middle of the stop. This assumption is justified if a poor image on the focusing screen remains stationary when the aperture is diminished; in practice, this generally occurs. This ray, named by Abbe a \"principal ray\" (not to be confused with the \"principal rays\" of the Gaussian theory), passes through the center of the entrance pupil before the first refraction, and the center of the exit pupil after the last refraction. From this it follows that correctness of drawing depends solely upon the principal rays; and is independent of the sharpness or curvature of the image field. Referring to fig. 4, we have O'Q'/OQ = a' tan w'/a tan w = 1/N, where N is the \"scale\" or magnification of the image. For N to be constant for all values of w, a' tan w'/a tan w must also be constant. If the ratio a'/a be sufficiently constant, as is often the case, the above relation reduces to the \"condition of Airy,\" i.e. tan w'/ tan w= a constant. This simple relation (see Camb. Phil. Trans., 1830, 3, p. 1) is fulfilled in all systems which are symmetrical with respect to their diaphragm (briefly named \"symmetrical or holosymmetrical objectives\"), or which consist of two like, but different-sized, components, placed from the diaphragm in the ratio of their size, and presenting the same curvature to it (hemisymmetrical objectives); in these systems tan w' / tan w = 1.\n\nThe constancy of a'/a necessary for this relation to hold was pointed out by R. H. Bow (Brit. Journ. Photog., 1861), and Thomas Sutton (Photographic Notes, 1862); it has been treated by O. Lummer and by M. von Rohr (Zeit. f. Instrumentenk., 1897, 17, and 1898, 18, p. 4). It requires the middle of the aperture stop to be reproduced in the centers of the entrance and exit pupils without spherical aberration. M. von Rohr showed that for systems fulfilling neither the Airy nor the Bow-Sutton condition, the ratio a' cos w'/a tan w will be constant for one distance of the object. This combined condition is exactly fulfilled by holosymmetrical objectives reproducing with the scale 1, and by hemisymmetrical, if the scale of reproduction be equal to the ratio of the sizes of the two components.\n\nCircular wavefront profiles associated with aberrations may be mathematically modeled using Zernike polynomials. Developed by Frits Zernike in the 1930s, Zernike's polynomials are orthogonal over a circle of unit radius. A complex, aberrated wavefront profile may be curve-fitted with Zernike polynomials to yield a set of fitting coefficients that individually represent different types of aberrations. These Zernike coefficients are linearly independent, thus individual aberration contributions to an overall wavefront may be isolated and quantified separately.\n\nThere are even and odd Zernike polynomials. The even Zernike polynomials are defined as\n\nand the odd Zernike polynomials as\n\nwhere \"m\" and \"n\" are nonnegative integers with formula_3, Φ is the azimuthal angle in radians, and ρ is the normalized radial distance. The radial polynomials formula_4 have no azimuthal dependence, and are defined as\n\nand formula_6 if formula_7 is odd.\n\nThe first few Zernike polynomials are:\nwhere formula_8 is the normalized pupil radius with formula_9, formula_10 is the azimuthal angle around the pupil with formula_11, and the fitting coefficients formula_12 are the wavefront errors in wavelengths.\n\nAs in Fourier synthesis using sines and cosines, a wavefront may be perfectly represented by a sufficiently large number of higher-order Zernike polynomials. However, wavefronts with very steep gradients or very high spatial frequency structure, such as produced by propagation through atmospheric turbulence or aerodynamic flowfields, are not well modeled by Zernike polynomials, which tend to low-pass filter fine spatial definition in the wavefront. In this case, other fitting methods such as fractals or singular value decomposition may yield improved fitting results.\n\nThe circle polynomials were introduced by Frits Zernike to evaluate the point image of an aberrated optical system taking into account the effects of diffraction. The perfect point image in the presence of diffraction had already been described by Airy, as early as 1835. It took almost hundred years to arrive at a comprehensive theory and modeling of the point image of aberrated systems (Zernike and Nijboer). The analysis by Nijboer and Zernike describes the intensity distribution close to the optimum focal plane. An extended theory that allows the calculation of the point image amplitude and intensity over a much larger volume in the focal region was recently developed (Extended Nijboer-Zernike theory). This Extended Nijboer-Zernike theory of point image or ‘point-spread function’ formation has found applications in general research on image formation, especially for systems with a high numerical aperture, and in characterizing optical systems with respect to their aberrations.\n\nThe preceding review of the several errors of reproduction belongs to the \"Abbe theory of aberrations,\" in which definite aberrations are discussed separately; it is well suited to practical needs, for in the construction of an optical instrument certain errors are sought to be eliminated, the selection of which is justified by experience. In the mathematical sense, however, this selection is arbitrary; the reproduction of a finite object with a finite aperture entails, in all probability, an infinite number of aberrations. This number is only finite if the object and aperture are assumed to be \"infinitely small of a certain order\"; and with each order of infinite smallness, i.e. with each degree of approximation to reality (to finite objects and apertures), a certain number of aberrations is associated. This connection is only supplied by theories which treat aberrations generally and analytically by means of indefinite series.\n\nA ray proceeding from an object point O (fig. 5) can be defined by the coordinates (ξ, η). Of this point O in an object plane I, at right angles to the axis, and two other coordinates (x, y), the point in which the ray intersects the entrance pupil, i.e. the plane II. Similarly the corresponding image ray may be defined by the points (ξ', η'), and (x', y'), in the planes I' and II'. The origins of these four plane coordinate systems may be collinear with the axis of the optical system; and the corresponding axes may be parallel. Each of the four coordinates ξ', η', x', y' are functions of ξ, η, x, y; and if it be assumed that the field of view and the aperture be infinitely small, then ξ, η, x, y are of the same order of infinitesimals; consequently by expanding ξ', η', x', y' in ascending powers of ξ, η, x, y, series are obtained in which it is only necessary to consider the lowest powers. It is readily seen that if the optical system be symmetrical, the origins of the coordinate systems collinear with the optical axis and the corresponding axes parallel, then by changing the signs of ξ, η, x, y, the values ξ', η', x', y' must likewise change their sign, but retain their arithmetical values; this means that the series are restricted to odd powers of the unmarked variables.\n\nThe nature of the reproduction consists in the rays proceeding from a point O being united in another point O'; in general, this will not be the case, for ξ', η' vary if ξ, η be constant, but x, y variable. It may be assumed that the planes I' and II' are drawn where the images of the planes I and II are formed by rays near the axis by the ordinary Gaussian rules; and by an extension of these rules, not, however, corresponding to reality, the Gauss image point O', with coordinates ξ', η', of the point O at some distance from the axis could be constructed. Writing Dξ'=ξ'-ξ' and Dη'=η'-η', then Dξ' and Dη' are the aberrations belonging to ξ, η and x, y, and are functions of these magnitudes which, when expanded in series, contain only odd powers, for the same reasons as given above. On account of the aberrations of all rays which pass through O, a patch of light, depending in size on the lowest powers of ξ, η, x, y which the aberrations contain, will be formed in the plane I'. These degrees, named by J. Petzval (\"Bericht uber die Ergebnisse einiger dioptrischer Untersuchungen\", Buda Pesth, 1843; \"Akad. Sitzber., Wien,\" 1857, vols. xxiv. xxvi.) \"the numerical orders of the image,\" are consequently only odd powers; the condition for the formation of an image of the mth order is that in the series for Dξ' and Dη' the coefficients of the powers of the 3rd, 5th…(m-2)th degrees must vanish. The images of the Gauss theory being of the third order, the next problem is to obtain an image of 5th order, or to make the coefficients of the powers of 3rd degree zero. This necessitates the satisfying of five equations; in other words, there are five alterations of the 3rd order, the vanishing of which produces an image of the 5th order.\n\nThe expression for these coefficients in terms of the constants of the optical system, i.e. the radii, thicknesses, refractive indices and distances between the lenses, was solved by L. Seidel (Astr. Nach., 1856, p. 289); in 1840, J. Petzval constructed his portrait objective, from similar calculations which have never been published (see M. von Rohr, \"Theorie und Geschichte des photographischen Objectivs\", Berlin, 1899, p. 248). The theory was elaborated by S. Finterswalder (Munchen. Acad. Abhandl., 1891, 17, p. 519), who also published a posthumous paper of Seidel containing a short view of his work (\"München. Akad. Sitzber.,\" 1898, 28, p. 395); a simpler form was given by A. Kerber (\"Beiträge zur Dioptrik\", Leipzig, 1895-6-7-8-9). A. Konig and M. von Rohr (see M. von Rohr, \"Die Bilderzeugung in optischen Instrumenten\", pp. 317–323) have represented Kerber's method, and have deduced the Seidel formulae from geometrical considerations based on the Abbe method, and have interpreted the analytical results geometrically (pp. 212–316).\n\nThe aberrations can also be expressed by means of the \"characteristic function\" of the system and its differential coefficients, instead of by the radii, &c., of the lenses; these formulae are not immediately applicable, but give, however, the relation between the number of aberrations and the order. Sir William Rowan Hamilton (British Assoc. Report, 1833, p. 360) thus derived the aberrations of the third order; and in later times the method was pursued by Clerk Maxwell (\"Proc. London Math. Soc.,\" 1874–1875; (see also the treatises of R. S. Heath and L. A. Herman), M. Thiesen (\"Berlin. Akad. Sitzber.,\" 1890, 35, p. 804), H. Bruns (\"Leipzig. Math. Phys. Ber.,\" 1895, 21, p. 410), and particularly successfully by K. Schwarzschild (\"Göttingen. Akad. Abhandl.,\" 1905, 4, No. 1), who thus discovered the aberrations of the 5th order (of which there are nine), and possibly the shortest proof of the practical (Seidel) formulae. A. Gullstrand (vide supra, and \"Ann. d. Phys.,\" 1905, 18, p. 941) founded his theory of aberrations on the differential geometry of surfaces.\n\nThe aberrations of the third order are: (1) aberration of the axis point; (2) aberration of points whose distance from the axis is very small, less than of the third order — the deviation from the sine condition and coma here fall together in one class; (3) astigmatism; (4) curvature of the field; (5) distortion.\n\nThe classical imaging problem is to reproduce perfectly a finite plane (the object) onto another plane (the image) through a finite aperture. It is impossible to do so perfectly for \"more than one\" such pair of planes (this was proven with increasing generality by Maxwell in 1858, by Bruns in 1895, and by Carathéodory in 1926, see summary in Walther, A., J. Opt. Soc. Am. A 6, 415–422 (1989)). For a single pair of planes (e.g. for a single focus setting of an objective), however, the problem can in principle be solved perfectly. Examples of such a theoretically perfect system include the Luneburg lens and the Maxwell fish-eye.\n\nPractical methods solve this problem with an accuracy which mostly suffices for the special purpose of each species of instrument. The problem of finding a system which reproduces a given object upon a given plane with given magnification (insofar as aberrations must be taken into account) could be dealt with by means of the approximation theory; in most cases, however, the analytical difficulties were too great for older calculation methods but may be ameliorated by application of modern computer systems. Solutions, however, have been obtained in special cases (see A. Konig in M. von Rohr's \"Die Bilderzeugung\", p. 373; K. Schwarzschild, Göttingen. Akad. Abhandl., 1905, 4, Nos. 2 and 3). At the present time constructors almost always employ the inverse method: they compose a system from certain, often quite personal experiences, and test, by the trigonometrical calculation of the paths of several rays, whether the system gives the desired reproduction (examples are given in A. Gleichen, \"Lehrbuch der geometrischen Optik\", Leipzig and Berlin, 1902). The radii, thicknesses and distances are continually altered until the errors of the image become sufficiently small. By this method only certain errors of reproduction are investigated, especially individual members, or all, of those named above. The analytical approximation theory is often employed provisionally, since its accuracy does not generally suffice.\n\nIn order to render spherical aberration and the deviation from the sine condition small throughout the whole aperture, there is given to a ray with a finite angle of aperture u* (width infinitely distant objects: with a finite height of incidence h*) the same distance of intersection, and the same sine ratio as to one neighboring the axis (u* or h* may not be much smaller than the largest aperture U or H to be used in the system). The rays with an angle of aperture smaller than u* would not have the same distance of intersection and the same sine ratio; these deviations are called \"zones,\" and the constructor endeavors to reduce these to a minimum. The same holds for the errors depending upon the angle of the field of view, w: astigmatism, curvature of field and distortion are eliminated for a definite value, w*, \"zones of astigmatism, curvature of field and distortion,\" attend smaller values of w. The practical optician names such systems: \"corrected for the angle of aperture u* (the height of incidence h*) or the angle of field of view w*.\" Spherical aberration and changes of the sine ratios are often represented graphically as functions of the aperture, in the same way as the deviations of two astigmatic image surfaces of the image plane of the axis point are represented as functions of the angles of the field of view.\n\nThe final form of a practical system consequently rests on compromise; enlargement of the aperture results in a diminution of the available field of view, and vice versa. But the larger aperture will give the larger resolution. The following may be regarded as typical:\n\nIn optical systems composed of lenses, the position, magnitude and errors of the image depend upon the refractive indices of the glass employed (see Lens (optics) and Monochromatic aberration, above). Since the index of refraction varies with the color or wavelength of the light (see dispersion), it follows that a system of lenses (uncorrected) projects images of different colors in somewhat different places and sizes and with different aberrations; i.e. there are \"chromatic differences\" of the distances of intersection, of magnifications, and of monochromatic aberrations. If mixed light be employed (e.g. white light) all these images are formed and they cause a confusion, named chromatic aberration; for instance, instead of a white margin on a dark background, there is perceived a colored margin, or narrow spectrum. The absence of this error is termed achromatism, and an optical system so corrected is termed achromatic. A system is said to be \"chromatically under-corrected\" when it shows the same kind of chromatic error as a thin positive lens, otherwise it is said to be \"overcorrected.\"\n\nIf, in the first place, monochromatic aberrations be neglected — in other words, the Gaussian theory be accepted — then every reproduction is determined by the positions of the focal planes, and the magnitude of the focal lengths, or if the focal lengths, as ordinarily happens, be equal, by three constants of reproduction. These constants are determined by the data of the system (radii, thicknesses, distances, indices, etc., of the lenses); therefore their dependence on the refractive index, and consequently on the color, are calculable. The refractive indices for different wavelengths must be known for each kind of glass made use of. In this manner the conditions are maintained that any one constant of reproduction is equal for two different colors, i.e. this constant is achromatized. For example, it is possible, with one thick lens in air, to achromatize the position of a focal plane of the magnitude of the focal length. If all three constants of reproduction be achromatized, then the Gaussian image for all distances of objects is the same for the two colors, and the system is said to be in \"stable achromatism.\"\n\nIn practice it is more advantageous (after Abbe) to determine the chromatic aberration (for instance, that of the distance of intersection) for a fixed position of the object, and express it by a sum in which each component conlins the amount due to each refracting surface. In a plane containing the image point of one color, another colour produces a disk of confusion; this is similar to the confusion caused by two \"zones\" in spherical aberration. For infinitely distant objects the radius Of the chromatic disk of confusion is proportional to the linear aperture, and independent of the focal length (\"vide supra\", \"Monochromatic Aberration of the Axis Point\"); and since this disk becomes the less harmful with an increasing image of a given object, or with increasing focal length, it follows that the deterioration of the image is proportional to the ratio of the aperture to the focal length, i.e. the \"relative aperture.\" (This explains the gigantic focal lengths in vogue before the discovery of achromatism.)\n\nExamples:\n\nNewton failed to perceive the existence of media of different dispersive powers required by achromatism; consequently he constructed large reflectors instead of refractors. James Gregory and Leonhard Euler arrived at the correct view from a false conception of the achromatism of the eye; this was determined by Chester More Hall in 1728, Klingenstierna in 1754 and by Dollond in 1757, who constructed the celebrated achromatic telescopes. (See telescope.)\n\nGlass with weaker dispersive power (greater formula_43) is named \"crown glass\"; that with greater dispersive power, \"flint glass\". For the construction of an achromatic collective lens (formula_15 positive) it follows, by means of equation (4), that a collective lens I. of crown glass and a dispersive lens II. of flint glass must be chosen; the latter, although the weaker, corrects the other chromatically by its greater dispersive power. For an achromatic dispersive lens the converse must be adopted. This is, at the present day, the ordinary type, e.g., of telescope objective; the values of the four radii must satisfy the equations (2) and (4). Two other conditions may also be postulated: one is always the elimination of the aberration on the axis; the second either the \"Herschel\" or \"Fraunhofer Condition,\" the latter being the best vide supra, \"Monochromatic Aberration\"). In practice, however, it is often more useful to avoid the second condition by making the lenses have contact, i.e. equal radii. According to P. Rudolph (Eder's Jahrb. f. Photog., 1891, 5, p. 225; 1893, 7, p. 221), cemented objectives of thin lenses permit the elimination of spherical aberration on the axis, if, as above, the collective lens has a smaller refractive index; on the other hand, they permit the elimination of astigmatism and curvature of the field, if the collective lens has a greater refractive index (this follows from the Petzval equation; see L. Seidel, Astr. Nachr., 1856, p. 289). Should the cemented system be positive, then the more powerful lens must be positive; and, according to (4), to the greater power belongs the weaker dispersive power (greater formula_43), that is to say, crown glass; consequently the crown glass must have the greater refractive index for astigmatic and plane images. In all earlier kinds of glass, however, the dispersive power increased with the refractive index; that is, formula_43 decreased as formula_13 increased; but some of the Jena glasses by E. Abbe and O. Schott were crown glasses of high refractive index, and achromatic systems from such crown glasses, with flint glasses of lower refractive index, are called the \"new achromats,\" and were employed by P. Rudolph in the first \"anastigmats\" (photographic objectives).\n\nInstead of making formula_29 vanish, a certain value can be assigned to it which will produce, by the addition of the two lenses, any desired chromatic deviation, e.g. sufficient to eliminate one present in other parts of the system. If the lenses I. and II. be cemented and have the same refractive index for one color, then its effect for that one color is that of a lens of one piece; by such decomposition of a lens it can be made chromatic or achromatic at will, without altering its spherical effect. If its chromatic effect (formula_49) be greater than that of the same lens, this being made of the more dispersive of the two glasses employed, it is termed \"hyper-chromatic.\"\n\nFor two thin lenses separated by a distance formula_50 the condition for achromatism is formula_51; if formula_52 (e.g. if the lenses be made of the same glass), this reduces to formula_53, known as the \"condition for oculars.\"\n\nIf a constant of reproduction, for instance the focal length, be made equal for two colors, then it is not the same for other colors, if two different glasses are employed. For example, the condition for achromatism (4) for two thin lenses in contact is fulfilled in only one part of the spectrum, since formula_54 varies within the spectrum. This fact was first ascertained by J. Fraunhofer, who defined the colors by means of the dark lines in the solar spectrum; and showed that the ratio of the dispersion of two glasses varied about 20% from the red to the violet (the variation for glass and water is about 50%). If, therefore, for two colors, a and b, formula_55, then for a third color, c, the focal length is different; that is, if c lies between a and b, then formula_56, and vice versa; these algebraic results follow from the fact that towards the red the dispersion of the positive crown glass preponderates, towards the violet that of the negative flint. These chromatic errors of systems, which are achromatic for two colors, are called the \"secondary spectrum,\" and depend upon the aperture and focal length in the same manner as the primary chromatic errors do.\n\nIn fig. 6, taken from M. von Rohr's \"Theorie und Geschichte des photographischen Objectivs\", the abscissae are focal lengths, and the ordinates wavelengths. The Fraunhofer lines used are shown in adjacent table.\n\nThe focal lengths are made equal for the lines C and F. In the neighborhood of 550 nm the tangent to the curve is parallel to the axis of wavelengths; and the focal length varies least over a fairly large range of color, therefore in this neighborhood the color union is at its best. Moreover, this region of the spectrum is that which appears brightest to the human eye, and consequently this curve of the secondary on spectrum, obtained by making formula_57, is, according to the experiments of Sir G. G. Stokes (Proc. Roy. Soc., 1878), the most suitable for visual instruments (\"optical achromatism,\"). In a similar manner, for systems used in photography, the vertex of the color curve must be placed in the position of the maximum sensibility of the plates; this is generally supposed to be at G'; and to accomplish this the F and violet mercury lines are united. This artifice is specially adopted in objectives for astronomical photography (\"pure actinic achromatism\"). For ordinary photography, however, there is this disadvantage: the image on the focusing-screen and the correct adjustment of the photographic sensitive plate are not in register; in astronomical photography this difference is constant, but in other kinds it depends on the distance of the objects. On this account the lines D and G' are united for ordinary photographic objectives; the optical as well as the actinic image is chromatically inferior, but both lie in the same place; and consequently the best correction lies in F (this is known as the \"actinic correction\" or \"freedom from chemical focus\").\n\nShould there be in two lenses in contact the same focal lengths for three colours a, b, and c, i.e. formula_58, then the relative partial dispersion formula_59 must be equal for the two kinds of glass employed. This follows by considering equation (4) for the two pairs of colors ac and bc. Until recently no glasses were known with a proportional degree of absorption; but R. Blair (Trans. Edin. Soc., 1791, 3, p. 3), P. Barlow, and F. S. Archer overcame the difficulty by constructing fluid lenses between glass walls. Fraunhofer prepared glasses which reduced the secondary spectrum; but permanent success was only assured on the introduction of the Jena glasses by E. Abbe and O. Schott. In using glasses not having proportional dispersion, the deviation of a third colour can be eliminated by two lenses, if an interval be allowed between them; or by three lenses in contact, which may not all consist of the old glasses. In uniting three colors an \"achromatism of a higher order\" is derived; there is yet a residual \"tertiary spectrum,\" but it can always be neglected.\n\nThe Gaussian theory is only an approximation; monochromatic or spherical aberrations still occur, which will be different for different colors; and should they be compensated for one color, the image of another color would prove disturbing. The most important is the chromatic difference of aberration of the axis point, which is still present to disturb the image, after par-axial rays of different colors are united by an appropriate combination of glasses. If a collective system be corrected for the axis point for a definite wavelength, then, on account of the greater dispersion in the negative components — the flint glasses, — overcorrection will arise for the shorter wavelengths (this being the error of the negative components), and under-correction for the longer wavelengths (the error of crown glass lenses preponderating in the red). This error was treated by Jean le Rond d'Alembert, and, in special detail, by C. F. Gauss. It increases rapidly with the aperture, and is more important with medium apertures than the secondary spectrum of par-axial rays; consequently, spherical aberration must be eliminated for two colors, and if this be impossible, then it must be eliminated for those particular wavelengths which are most effectual for the instrument in question (a graphical representation of this error is given in M. von Rohr, \"Theorie und Geschichte des photographischen Objectivs\").\n\nThe condition for the reproduction of a surface element in the place of a sharply reproduced point — the constant of the sine relationship must also be fulfilled with large apertures for several colors. E. Abbe succeeded in computing microscope objectives free from error of the axis point and satisfying the sine condition for several colors, which therefore, according to his definition, were \"aplanatic for several colors\"; such systems he termed \"apochromatic\". While, however, the magnification of the individual zones is the same, it is not the same for red as for blue; and there is a chromatic difference of magnification. This is produced in the same amount, but in the opposite sense, by the oculars, which Abbe used with these objectives (\"compensating oculars\"), so that it is eliminated in the image of the whole microscope. The best telescope objectives, and photographic objectives intended for three-color work, are also apochromatic, even if they do not possess quite the same quality of correction as microscope objectives do. The chromatic differences of other errors of reproduction have seldom practical importances.\n\n\n\n", "id": "2704", "title": "Optical aberration"}
{"url": "https://en.wikipedia.org/wiki?curid=2705", "text": "Amy Grant\n\nAmy Lee Grant (born November 25, 1960) is an American singer, songwriter, musician, author, media personality and actress. She is known for performing contemporary Christian music (CCM) and for a successful crossover to pop music in the 1980s and 1990s. She has been referred to as \"The Queen of Christian Pop\". , she had sold more than 30 million albums worldwide, won six Grammy Awards and 22 Gospel Music Association Dove Awards, and had the first Christian album ever to go Platinum. She was honored with a star on Hollywood Walk of Fame in 2006 for her contributions to the entertainment industry. She made her debut as a teenager, and gained fame in Christian music during the 1980s with such hits as \"Father's Eyes\", \"El Shaddai\", and \"Angels\". In the mid-1980s, she began broadening her audience and soon became one of the first CCM artists to cross over into mainstream pop on the heels of her successful albums \"Unguarded\" and \"Lead Me On\". In 1986, she scored her first \"Billboard\" Hot 100 No. 1 song in a duet with Peter Cetera, \"The Next Time I Fall\". In 1991, she released the blockbuster album \"Heart in Motion\" which became her best-selling album to date, topping the \"Billboard\" Christian album chart for 32 weeks, selling five million copies in the U.S., and producing her second No. 1 pop single \"Baby Baby\". She is the author of several books, including a memoir, \"\", and a book based on the popular Christmas song \"Breath of Heaven (Mary's Song)\" which she co-wrote.\n\nBorn in Augusta, Georgia, Grant is the youngest of four sisters. Her family settled in Nashville, Tennessee, in 1967. She is a great-granddaughter of Nashville philanthropist A. M. Burton (founder of Life and Casualty Insurance Company, eponym of Nashville's Life & Casualty Tower, WLAC Radio, and WLAC-TV) and Lillie Burton. She has acknowledged the influence of the Burtons on her development as a musician, starting with their common membership in Nashville's Ashwood Church of Christ.\n\nIn 1976, Grant wrote her first song (\"Mountain Man\"), performed in public for the first time at Harpeth Hall School, the all-girls school she attended in Nashville. She recorded a demo tape for her parents with church youth-leader Brown Bannister. When Bannister was dubbing a copy of the tape, Chris Christian, the owner of the recording studio, heard the demo and called Word Records. He played it over the phone, and she was offered a recording contract, five weeks before her 16th birthday. In 1977, she recorded her first album titled \"Amy Grant\", produced by Brown Bannister, who would also produce her next 11 albums. It was released in early 1978, one month before her high-school graduation. Toward the end of 1978 she performed her first ticketed concert after beginning her first year at Furman University. In May 1979, while at the album-release party for her second album, \"My Father's Eyes\", Grant met Gary Chapman, who had written the title track and would become her first husband. Grant and Chapman toured together in mid-1979. In late 1980, she transferred to Vanderbilt University, where she was a member of the sorority Kappa Alpha Theta. Grant then made a few more albums before dropping out of college to pursue a career in music—\"Never Alone\", followed by a pair of live albums in 1981 (\"In Concert\" and \"In Concert Volume Two\"), both backed by an augmented edition of the DeGarmo & Key band. It was during these early shows that Grant also established one of her concert trademarks: performing barefoot. To date, Grant continues to take off her shoes midway through performances, as she has said \"it is just more comfortable.\"\n\n1982 saw the release of her breakthrough album \"Age to Age\". The album contains the signature track, \"El Shaddai\" (written by Michael Card) and the Grant-Chapman penned song, \"In a Little While\". \"El Shaddai\" was later awarded one of the \"Songs of the Century\" by the RIAA in 2001. Grant received her first Grammy Award for Best Contemporary Gospel Performance, as well as two GMA Dove Awards for Gospel Artist of the Year and Pop/Contemporary Album of the Year. \"Age to Age\" became the first Christian album by a solo artist to be certified gold (1983) and the first Christian album to be certified platinum (1985).\n\nIn the mid-1980s, Grant began touring and recording with young up-and-coming songwriter Michael W. Smith. Grant and Smith continue to have a strong friendship and creative relationship, often writing songs for or contributing vocals to each other's albums. During the 1980s, Grant was also a backup singer for Bill Gaither.\n\nGrant followed this album with the first of her Christmas albums, which would later be the basis for her holiday shows. In 1984, she released another pop-oriented Christian hit, \"Straight Ahead\", earning Grant her first appearance at the Grammy Awards show in 1985. The head of NBC took notice of Grant's performance and called her manager to book her for her own Christmas special.\n\nHardly had Grant established herself as the \"Queen of Christian Pop\" when she changed directions to widen her fan base (and hence her musical message). Her goal was to become the first Christian singer-songwriter who was also successful as a contemporary pop singer. \"Unguarded\" (1985) surprised some fans for its very mainstream sound (and Grant's leopard-print jacket, in four poses for four different covers). \"Find a Way\", from \"Unguarded\", became the first non-Christmas Christian song to hit \"Billboard\" Top 40 list, also reaching No. 7 on the Adult Contemporary chart. She also scored No. 18 on \"Billboard\" AC in 1986 with \"Stay for Awhile\". Grant scored her first \"Billboard\" No. 1 song in 1986 with \"The Next Time I Fall\", a duet with former Chicago singer/bassist Peter Cetera. That year, she also recorded a duet with singer Randy Stonehill for his \"Love Beyond Reason\" album, titled \"I Could Never Say Goodbye\", and recorded \"The Animals' Christmas\" with Art Garfunkel.\n\n\"Lead Me On\" (1988) contained many songs that were about Christianity and love relationships, but some interpreted it as not being an obviously \"Christian\" record. Years later, \"Lead Me On\" would be chosen as the greatest Contemporary Christian album of all time by \"CCM Magazine\". The mainstream song \"Saved by Love\" was a minor hit, receiving airplay on radio stations featuring the newly emerging Adult Contemporary format. The album's title song received some pop radio airplay and crossed over to No. 96 on the \"Billboard\" Hot 100, and \"1974 (We Were Young)\" and \"Saved By Love\" also charted as Adult Contemporary songs. In 1989, she appeared in a Target ad campaign, performing songs off the album.\n\nWhen \"Heart in Motion\" was released in 1991, many fans were surprised that the album was so clearly one of contemporary pop music. Grant's desire to widen her audience was frowned upon by the confines of the popular definitions of ministry at the time. The track \"Baby Baby\" (written for Grant's newborn daughter Millie, whose \"six-week-old face was my inspiration,\") became a pop hit (hitting No. 1 on the \"Billboard\" Hot 100), and Grant was established as a name in the mainstream music world. \"Baby Baby\" received Grammy nominations for Best Female Pop Vocal Performance, and Record and Song of the Year (although it failed to win in any of those categories). Four other hits from the album made the Pop top 20: \"Every Heartbeat\" (No. 2), \"That's What Love Is For\" (No. 7), \"Good for Me\" (No. 8), and \"I Will Remember You\" (No. 20). On the Adult Contemporary chart, all five songs were top 10 hits, with two of the five (\"Baby Baby\" and \"That's What Love Is For\") reaching No. 1. Many Christian fans remained loyal, putting the album atop \"Billboard\" Contemporary Christian Chart for 32 weeks. \"Heart in Motion\" is Grant's best-selling album, having sold over five million copies according to the RIAA. Grant followed the album with her second Christmas album, \"Home For Christmas\" in 1992, which included the song \"Breath of Heaven (Mary's Song)\", written by Chris Eaton and Grant, and would later be covered by many artists, including Donna Summer, Jessica Simpson (who acknowledged Grant as one of her favorite artists), Vince Gill, Sara Groves, Point of Grace, Gladys Knight, and Broadway star Barbara Cook.\n\n\"House of Love\" in 1994 continued in the same vein, boasting catchy pop songs mingled with spiritual lyrics. The album was a multi-platinum success and produced the pop hit \"Lucky One\" (No. 18 pop and No. 2 AC; No. 1 on Radio & Records) as well as the title track (a duet with country music star and future husband Vince Gill) (No. 37 pop) and a cover of Joni Mitchell's frequently covered \"Big Yellow Taxi\" (No. 67 pop) (in which she changed the line \"And they charged the people \"a dollar and a half\" just to see'em\" to \"And then they charged the people \"25 bucks\" just to see'em\").\n\nAfter she covered the 10cc song \"The Things We Do for Love\" for the \"Mr. Wrong\" soundtrack, \"Behind the Eyes\" was released in September 1997. The album struck a much darker note, leaning more towards downtempo, acoustic soft-rock songs, with more mature (yet still optimistic) lyrics. She called it her \"razor blades and Prozac\" album. Although \"Takes a Little Time\" was a moderate hit single, the album failed to sell like the previous two albums, which had both gone multi-platinum. \"Behind The Eyes\" was eventually certified Gold by the RIAA. The video for \"Takes a Little Time\" was a new direction for Grant; with a blue light filter, acoustic guitar, the streets and characters of New York City, and a plot, Grant was re-cast as an adult light rocker. She followed up \"Behind The Eyes\" with \"A Christmas To Remember\", her third Christmas album, in 1999. The album was certified Gold in 2000.\n\nIn 2001, Grant sang \"God Bless America\" in front of a sellout crowd at the Owen County Fair Grounds in Spencer, Indiana. She dedicated her performance to the victims of 9/11, and officially started the Demolition Derby. Following the 9/11 attacks, Grant's \"I Will Remember You\" saw a resurgence in popularity as many radio DJs mixed a special tribute version of the song. That same year, Grant won $125,000 for charity on the \"Rock Star Edition\" of \"Who Wants to Be a Millionaire?\"\n\nGrant returned to her roots with the 2002 release of an album of hymns titled \"Legacy... Hymns and Faith\". The album featured a Vince Gill-influenced mix of bluegrass and pop and marked Grant's 25th anniversary in the music industry. Grant followed this up with \"Simple Things\" in 2003. The album did not have the success of her previous pop or gospel efforts. Soon after \"Simple Things\", Grant and Interscope/A&M parted ways. The same year, Grant was inducted into the Gospel Music Hall of Fame by the Gospel Music Association, an industry trade organization of which she is a longstanding member, in her first year of eligibility. Grant released a sequel in 2005 titled \"Rock of Ages...Hymns and Faith\".\n\nGrant joined the reality television phenomenon by hosting \"Three Wishes\", a show in which she and a team of helpers make wishes come true for small-town residents. The show debuted on NBC in the fall of 2005 but was canceled at the end of its first season because of high production costs. After \"Three Wishes\" was canceled, Grant won her 6th Grammy Award for \"Rock of Ages... Hymns & Faith\". In a February 2006 webchat, Grant stated she believes her \"best music is still ahead\".\n\nIn April 2006, a live CD/DVD titled \"Time Again...Amy Grant Live\" was recorded in Fort Worth, Texas, at Bass Performance Hall. (Grant's first paid public performance was at the Will Rogers Auditorium in Fort Worth.) The concert was released on September 26, 2006. In addition to receiving a star on the Hollywood Walk of Fame, media appearances included write-ups in \"CCM Magazine\", and a performance on \"The View\".\n\nIn a February 2007 web chat on her web site, Grant discussed a book she was working on titled \"\", saying, \"It's not an autobiography, but more a collection of memories, song lyrics, poetry and a few pictures.\" The book was released on October 16, 2007. In November, it debuted at No. 35 on the New York Times Best Seller list. In the same web chat, Grant noted that she is \"anxious to get back in the studio after the book is finished, and reinvent myself as an almost-50 performing woman\".\n\n2007 was Grant's 30th year in music. She left Word/Warner, and contracted with EMI CMG who re-released her regular studio albums as remastered versions on August 14, 2007. Marking the start of Grant's new contract is a career-spanning greatest hits album, with all the songs digitally remastered. The album was released as both a single-disc CD edition, and a two-disc CD/DVD Special Edition, the DVD featuring music videos and interviews.\n\nGrant appeared with Gill on \"The Oprah Winfrey Show\" for a holiday special in December 2007. Grant has plans to appear on CMT, a Food Network special, the Gospel Music Channel, and The Hour of Power.\n\nIn February 2008, Grant joined the writing team from Compassionart as a guest vocalist at the Abbey Road studios, London, to record a song called \"Highly Favoured\", which was included on the album \"CompassionArt\".\n\nOn June 24, 2008, Grant re-released her 1988 album, \"Lead Me On\", in honor of its 20th anniversary. The two-disc release includes the original album and a second disc with new acoustic recordings, live performances from 1989, and interviews with Amy. Grant recreated the \"Lead Me On\" tour in the fall of 2008.\n\nOn June 27, 2008, Grant surprised everyone at the Creation Festival Northeast by being the special guest. She performed \"Lead Me On\" and a few other songs backed with the Hawk Nelson band. At the end of the concert, Grant returned to the stage and sang \"Thy Word\". She appeared on the 2008 album \"\" singing \"Could I Have This Dance\".\n\nOn May 5, 2009, Grant released an EP containing two new songs, \"She Colors My Day\", and \"Unafraid\", as well as the previously released songs \"Baby Baby\" and \"Oh How the Years Go By\". The EP, exclusively through iTunes, benefited the Entertainment Industry Foundation's (EIF) Women's Cancer Research Fund.\n\nIn 2010, Grant released \"Somewhere Down the Road\", featuring the hit single \"Better Than a Hallelujah\", which peaked at No. 8 on \"Billboard\" Top Christian Songs chart. When asked about the new album during an interview with CBN.com, Grant says, \"... my hope is just for those songs to provide companionship, remind myself and whoever else is listening what's important. I feel like songs have the ability to connect us to ourselves and to each other, and to our faith, to the love of Jesus, in a way that conversation doesn't do. Songs kind of slip in and move you before you realize it.\"\n\nIn September 2012, Grant took part in a campaign called \"30 Songs / 30 Days\" to support \"\", a multi-platform media project inspired by Nicholas Kristof and Sheryl WuDunn's book.\n\nGrant's next album, titled \"How Mercy Looks from Here\", was released on May 14, 2013. The album was produced by Marshall Altman. The album reached No. 12 on the \"Billboard\" 200 chart, making it her highest charting album since 1997's \"Behind the Eyes\". Two singles were released from the album: \"Don't Try So Hard\" and \"If I Could See\", both of which charted on the US \"Billboard\" Hot Christian Songs chart.\n\nOn August 19, 2014, she released an album of hits remixed by well known engineers and DJs. The album was titled \"In Motion: The Remixes\". It charted at 110 on the US \"Billboard\" 200 chart and at number 5 on the US Dance chart. To promote the album, several new remix EPs were released on iTunes the following month including \"Find a Way, \"Stay for Awhile\", \"Baby Baby, \"Every Heartbeat\" and \"That's What Love Is For\". Due to club play of the remix of \"Every Heartbeat\", it charted at number 13 on the US Dance Chart. This marked her first appearance on that chart in 23 years. On September 30, 2014, Grant released a new single titled \"Welcome Yourself\". In honor of Breast Cancer Awareness Month, proceeds of the single go to breast cancer research.\n\nOn February 12, 2015, she announced a new compilation album titled \"Be Still and Know... Hymns & Faith\", to be released. The album was released on April 14, 2015 and charted at No. 7 in the U.S. on the \"Billboard\" Christian Albums chart. .\n\nOn June 19, 1982, Grant married fellow Christian musician Gary Chapman. Their marriage produced three children. In March 1999, she filed for divorce from Chapman, citing \"irreconcilable differences,\" and the divorce was finalized three months later.\nOn March 10, 2000, Grant married country singer-songwriter Vince Gill, who had been previously married to country singer Janis Oliver of Sweethearts of the Rodeo. Grant and Gill have one daughter together, Corrina Grant Gill, born March 12, 2001.\n\nIn the November 1999 \"CCM Magazine\", Grant explained why she left Chapman and married Gill:\n\n\"I didn't get a divorce because 'I had a great marriage and then along came Vince Gill'. Gary and I had a rocky road from day one. I think what was so hard—and this is (what) one of our counselors said—sometimes an innocent party can come into a situation, and they're like a big spotlight. What they do is reveal, by comparison, the painful dynamics that are already in existence.\"\n\nAmong praise for her contributions to the Contemporary Christian genre, Grant has also generated controversy within the Christian community, from \"complaints that she was too worldly and too sexy\" to a \"barrage of condemnation\" following her divorce and remarriage.\n\nIn an interview early in her career, Grant stated, \"I have a healthy sense of right and wrong, but sometimes, for example, using foul, exclamation-point words among friends can be good for a laugh.\" The article which was based on that interview was constructed in such a manner so as to make it appear as though Grant condoned premarital sex. Later Grant reflected on how the article misrepresented her views, stating: \"We probably talked for two hours about sexual purity, but when the interview finally came out he worded it in such a way that it sounded like I condoned premarital sex. So I picked up that article and thought, 'You've made me say something I've never said, and you've totally disregarded two hours of Bible put in one flippant comment that I made about a moan.'\"\n\n\n\n\n", "id": "2705", "title": "Amy Grant"}
{"url": "https://en.wikipedia.org/wiki?curid=2707", "text": "Arthur William à Beckett\n\nArthur William à Beckett (25 October 1844 – 14 January 1909) was an English journalist and intellectual.\n\nHe was a younger son of Gilbert Abbott à Beckett and Mary Anne à Beckett, brother of Gilbert Arthur à Beckett and educated at Felsted School. Besides fulfilling other journalistic engagements, Beckett was on the staff of \"Punch\" from 1874 to 1902, edited the \"Sunday Times\" 1891-1895, and the \"Naval and Military Magazine\" in 1896.\n\nHe gave an account of his father and his own reminiscences in \"The à Becketts of Punch\" (1903). A childhood friend (and distant relative) of W. S. Gilbert, Beckett briefly feuded with Gilbert in 1869, but the two patched up the friendship, and Gilbert even later collaborated on projects with Beckett's brother.\n\nHe was married to Suzanne Frances Winslow, daughter of the noted psychiatrist Forbes Benignus Winslow.\n\nHe published:\n\nHe wrote for the theatre two three-act comedies:\nand\n\n\n\n \n", "id": "2707", "title": "Arthur William à Beckett"}
{"url": "https://en.wikipedia.org/wiki?curid=2709", "text": "Aberdeen, South Dakota\n\nAberdeen (Lakota: \"Ablíla\") is a city in and the county seat of Brown County, South Dakota, United States, about northeast of Pierre. The city population was 26,091 at the 2010 census, making it the third largest city in the state. Aberdeen is the principal city of the Aberdeen Micropolitan Statistical Area, which includes all of Brown and Edmunds counties and has a population of 40,602 in 2010. Aberdeen is considered a college town, being the home of both Northern State University and Presentation College.\n\nBefore Aberdeen or Brown County was inhabited by European settlers, it was inhabited by the Sioux Indians from approximately 1700 to 1879. Europeans entered the region for business, founding fur trading posts during the 1820s; these trading posts operated until the mid-1830s. The first \"settlers\" of this region were the Arikara Indians, but they would later be joined by others.\n\nThe first group of Euro-American settlers to reach the area that is now Brown County was a party of four people, three horses, two mules, fifteen cattle, and two wagons. This group of settlers was later joined by another group the following spring, and, eventually, more settlers migrated toward this general area, currently known as Columbia, South Dakota. This town was established on June 15, 1879. The town was settled in 1880, and incorporated in 1882.\n\nAberdeen, like many towns of the Midwest, was built around the newly developing railroad systems. Aberdeen was first officially plotted as a town site on January 3, 1881, by Charles Prior, the superintendent of the Minneapolis office of the Chicago, Milwaukee, and St. Paul Railroad, or the Milwaukee Road for short, which was presided over by Alexander Mitchell. Mitchell, Charles Prior's boss, was responsible for the choice of town names, was born in Aberdeen, Scotland, after which the town of Aberdeen, South Dakota, was named. Aberdeen was officially founded on July 6, 1881, the date of the first arrival of a Milwaukee Railroad train. Aberdeen then operated under a city charter granted by the Territorial Legislature in March 1883.\n\nAs Aberdeen grew, many businesses and buildings were constructed along Aberdeen's Main Street. However, this soon became a problem due to Aberdeen's periodic flooding, which led to it being referred to as \"The Town in the Frog Pond\". At first, this unique condition presented no problem to the newly constructed buildings because it had not rained very much but, when heavy rains fell, the Pond reappeared and flooded the basements of every building on Main Street, causing many business owners and home owners much turmoil. When this flooding happened, the city had one steam-powered pump that had to be used to dry out the entire area that had been flooded, which would take days, if not weeks – and more often than not, it would have rained again in this time period and caused even more flooding, even in the basements that had already been emptied of the water. When the water was gone from the basements, the city still had to deal with the mud that also resulted from the heavy rains.\n\nThe city decided in 1882 to build an artesian ditch to control the \"Frog Pond\" effects; the plan was later upgraded and developed into an artesian well in 1884 to combat the heavy rains and keep the basements from flooding. The artesian well was designed by the city engineers to prevent flooding and develop a water system. However, during the digging of the well, the water stream that was found underground was too powerful to be contained. The water came blasting out with violent force and had the entire Main Street submerged in up to four feet of water. The engineers realized the previous flaws of the artesian well plan and soon added a gate valve to the well to control the flow of water, giving Aberdeen its first working water supply.\n\nAberdeen had four different railroad companies with depots built in the newly developing town. With these four railroads intersecting here, Aberdeen soon became known as the \"Hub City of the Dakotas\". When looking down on Aberdeen from above, the railroad tracks converging in Aberdeen resembled the spokes of a wheel converging at a hub, hence the name \"Hub City of the Dakotas\". These four railroad companies are the reason why Aberdeen was able to grow and flourish as it did. The only railroad still running through Aberdeen is the Burlington Northern Santa Fe.\n\nOn October 25, 1999, a Learjet 35 carrying golfing star Payne Stewart crashed in a field near Aberdeen. All on board died.\n\nAberdeen is located in northeastern South Dakota, in the James River valley, approximately west of the river. The James River enters northeastern South Dakota in Brown County, where it is dammed to form two reservoirs northeast of Aberdeen. The city is bisected by \"Moccasin Creek\", a slow-moving waterway which flows south and then northeast to the James River.\n\nAccording to the United States Census Bureau, the city has a total area of , of which is land and is water.\n\nAberdeen has been assigned the ZIP code range 57401−57402.\n\nAberdeen experiences a humid continental climate (Köppen \"Dfb/Dfa\") influenced by its position far from moderating bodies of water. This brings four distinct seasons, a phenomenon that is characterized by hot, relatively humid summers and cold, dry winters, and it lies in USDA Hardiness Zone 4. The monthly daily average temperature ranges from in January to in July, while there are 13 days of + highs and 37 days with sub- lows annually. Snowfall occurs mostly in light to moderate amounts during the winter, totaling . Precipitation, at annually, is concentrated in the warmer months. Extreme temperatures have ranged from on January 12, 1912 and February 8, 1895 to on July 6 and 15, 1936, although a reading occurred as recently as January 15, 2009.\n\nThe National Oceanographic and Atmospheric Administration maintains a National Weather Service office in Aberdeen. Their area of responsibility includes northern and eastern South Dakota and two counties in west-central Minnesota.\n\nAberdeen is the county seat of Brown County. The original county seat was, however, Columbia. During the days of the railroad construction, plans were laid to bring the railroad through Columbia, then the county seat. When word of this spread, land in and around Columbia soared in price due to speculation. When the time came for the railroads to purchase land, the increase in land prices led them to change their decision and instead to route the rail lines through Aberdeen. However, once Aberdeen became a town in 1881, there was a long-running controversy concerning which town would be the county seat, which continued until 1890, when it was declared by the newly formed South Dakota state constitution in 1889 that a majority vote could move the county seat if the county seat in question had originally been established by less than a majority vote. The result of the vote declared that Aberdeen would be the county seat once and for all, so all of the records were once again transferred to Aberdeen's courthouse; during the battle for county seat, the records had been moved from Columbia's courthouse to Aberdeen's courthouse (which was built from 1886 to 1887), and back again to Columbia's in what seemed to be a never-ending cycle of the transferring of records. This was typically done in the form of nighttime raids from the two towns.\n\nAs of the census of 2010, there were 26,091 people, 11,418 households, and 6,354 families residing in the city. The population density was . There were 12,158 housing units at an average density of . The racial makeup of the city was 91.8% White, 0.7% African American, 3.6% Native American, 1.3% Asian, 0.2% Pacific Islander, 0.5% from other races, and 2.0% from two or more races. Hispanic or Latino of any race were 1.6% of the population.\n\nThere were 11,418 households of which 27.1% had children under the age of 18 living with them, 42.1% were married couples living together, 9.5% had a female householder with no husband present, 4.0% had a male householder with no wife present, and 44.4% were non-families. 36.9% of all households were made up of individuals and 13.1% had someone living alone who was 65 years of age or older. The average household size was 2.18 and the average family size was 2.86.\n\nThe median age in the city was 36.4 years. 22.2% of residents were under the age of 18; 12.8% were between the ages of 18 and 24; 24.1% were from 25 to 44; 24.4% were from 45 to 64; 16.4% were 65 years of age or older. The gender makeup of the city was 47.6% male and 52.4% female.\n\nAs of the census of 2000, there were 24,658 people, 10,553 households and 6,184 families residing in the city. The population density was 1,902.1 per square mile (734.4/km²). There were 11,259 housing units at an average density of 868.5 per square mile (335.3/km²). The racial makeup of the city was 94.61% White, 0.37% Black or African American, 3.17% Native American, 0.54% Asian, 0.13% Pacific Islander, 0.19% from other races, and 0.99% from two or more races. 0.79% of the population were Hispanic or Latino of any race. 53.7% were of German, 15% Norwegian and 8.5% Irish ancestry.\n\nThere were 10,553 households out of which 27.3% had children under the age of 18 living with them, 47.0% were married couples living together, 8.9% had a female householder with no husband present, and 41.4% were non-families. 34.9% of all households were made up of individuals and 13.6% had someone living alone who was 65 years of age or older. The average household size was 2.21 and the average family size was 2.86.\n\nAge spread: 21.8% under the age of 18, 14.1% from 18 to 24, 26.4% from 25 to 44, 20.4% from 45 to 64, and 17.2% who were 65 years of age or older. The median age was 36 years. For every 100 females, there were 89.2 males. For every 100 females age 18 and over, there were 85.3 males.\n\nAs of 2000, the median income for a household in the city was $33,276, and the median income for a family was $43,882. Males had a median income of $30,355 versus $20,092 for females. The per capita income for the city was $17,923. About 7.6% of families and 10.5% of the population were below the poverty line, including 10.6% of those under age 18 and 10.1% of those age 65 or over.\n\nThere are several Roman Catholic, Baptist, Lutheran, Methodist, and the Church of Jesus Christ of Latter-day Saints churches in the area, as well as one synagogue.\n\nSuper 8 Motels was founded in 1972 by Dennis Brown and Ron Rivett as a motel referral system, which was replaced with a franchise operation in 1973. The first Super 8, with 60 rooms, was opened in 1974 in Aberdeen and still operates today as the Super 8 Aberdeen East.\n\nThe Aberdeen area has several cultural organizations.\n\nThe Aberdeen Area Arts Council publishes a small monthly newspaper, \"ARTiFACTS\", with information on area events.\n\nThe Aberdeen Community Theatre was created in 1979 and performs at the Capitol Theatre in downtown Aberdeen. The Capitol Theatre opened in 1927 and donated to the Aberdeen Community Theatre in 1991; since then more than $963,000 has been spent on renovating and preserving the historical aspect of the Capitol Theatre. Today, the Aberdeen Community Theatre performs five mainstage productions and three youth productions per year.\n\nThe South Dakota Film Festival established in 2007 is held annually in the fall. The festival has been host to Kevin Costner, Graham Greene, Adam Greenberg, CSA and many more stars of film and television. The festival's first feature film screened was Into The Wild, shot partially in SD. The festival is held at the historic Capitol Theatre.\n\nThe Northern State University Theater Department puts on plays during the school year.\n\nThe ArtWorks Cooperative is a partnership of artists who work to market their artwork in a gallery setting. The ArtWorks Cooperative sells artists' work and provides an environment that will benefit the artist in terms of artist-to-artist communication, and public interest.\n\nThere are four galleries in Aberdeen: Presentation College's Wein Gallery, Northern State University's Lincoln Gallery, the Aberdeen Recreation & Cultural Center (ARCC) Gallery and the ArtWorks Cooperative Gallery located in The Aberdeen Mall.\n\nThe Village Bowl in Aberdeen is a modern bowling center with multiple lanes. Located at 1314 8th Ave. NW.\n\nAberdeen has been home to three minor league baseball teams since 1920. The Aberdeen Boosters, a class D league team, played in 1920, the Aberdeen Grays, also a class D team, played from 1921 to 1923. The class C Aberdeen Pheasants from 1946 to 1971, and 1995 to 1997. The Pheasants were the affiliate of the former St. Louis Browns (current Baltimore Orioles). Aberdeen was a stop to the majors for such notable players as Don Larsen (perfect game in the World Series), Lou Piniella (AL rookie of the year with Kansas City Royals in 1969), and Jim Palmer, Baseball Hall of Fame pitcher for the Baltimore Orioles.\n\nAberdeen is presently home to 24 public tennis courts throughout the city – Melgaard Park (4), Northern State University (12), and Holgate Middle School (8).\n\nAberdeen has three golf courses. These are Lee Park Municipal Golf Course, Moccasin Creek Country Club and Rolling Hills Country Club. Lee Park and Moccasin Creek are both 18-hole courses. Rolling Hills is a combined nine-hole course and housing development which opened in 2005.\n\nAberdeen has multiple outdoor skating rinks and hockey rinks open to the public during winter months.\nAberdeen is also home to the NAHL team, Aberdeen Wings.\n\nAberdeen has a skate park located between East Melgaard Road and 17th Ave SE at Melgaard Park. The equipment installed includes a quarter pipe, penalty box with half pyramid, bank ramp, spine, kinked rail and a ground rail.\n\nAberdeen has two disc golf courses, Melgaard Park, and the Richmond Lake Disc Golf Course.\n\nAberdeen has an All-women's Roller Derby league \"A-Town Roller Girlz\" established 2011, also bringing Junior Roller Derby to the area. Men's league to follow in the midst of interest in the dynamic of the sport.\n\nCompleted in the summer of 2007, this complex includes a zero entry pool, competition lap pool, lazy river, numerous water slides, play sand area, and a concession area.\n\nWylie Park Recreation Area features go-kart racing, sand volleyball courts, access to Wylie Lake, camping area, picnic areas, and is connected to Storybook Land. Wylie Lake is a small man-made lake, open in the summer months for swimming, lying on the beach, and paddle boating. \n\nStorybook Land is a park with attractions from several different children's storybooks. The park contains a castle, as well as a train that takes visitors through the park. There are two barns which contain petting zoos. Humpty Dumpty's Great Fall Roller Coaster was added to the park, summer 2015. Newly added is the Land of Oz, that features characters and attractions from L. Frank Baum's \"The Wonderful Wizard of Oz\". Baum was a resident of Aberdeen in the 1880s, but left after the failure of the newspaper \"The Aberdeen Saturday Pioneer\", where he wrote a column, \"Our Landlady\".\n\nThe Richmond Lake Recreation Area is used by all types of outdoors enthusiasts. Three separate areas in this park cater to the needs of campers, swimmers, naturalists, boaters and anglers. Campers stay in the South Unit, while the Forest Drive Unit is a great place for wildlife viewing. The Boat Ramp Unit provides access to the more than lake.\n\nRichmond Lake Recreation Area's small campground offers a quiet camping experience. The park also features a wheelchair accessible camping cabin.\n\nThe park's extensive trail system features over of trails, including both accessible and interpretive trails. Hikers, bikers, and horseback riders can observe the abundance of prairie plants and wildlife of the area up-close.\n\nThe park has multiple private and public boat ramps as well as an accessible fishing dock. Richmond Lake has a population of walleye, northern pike, bass, perch, crappie, bluegill, catfish, and bullheads within its waters. An entrance fee is required to gain access to the water and park itself.\n\nAberdeen is the center of government for Brown County. City government is overseen by a mayor/city manager and eight council members. The city council is composed of Mayor Mike Levson, City Manager Lynn Lander, and council members Todd Campbell, Jennifer Slaight-Hansen, Mark Remily, Rob Ronayne, Alan Johnson, David Bunsness, Clint Rux and Dennis 'Mike' Olson. Each council member serves a five-year term.\n\nCounty government is overseen by five commissioners. Each county commissioner serves a five-year term. The county commissioners include Duane Sutton, Tom Fischbach, Nancy Hansen, Rachel Kippley, and Doug Fjeldheim. Aberdeen is home to Brown County offices including clerk-magistrate, county auditor, landfill office, register of deeds, county treasurer, coroner, emergency management, highway superintendent, public welfare, state's attorney, and a few others.\n\nThe state senators from Brown County include Brock Greenfield and Al Novstrup, and the state representatives included Lana Greefield, Burt Tulson, Dan Kaiser and Drew Dennert. They are all in office until December 2018\n\nIn 2008, Gov Mike Rounds named Aberdeen as the South Dakota Community of the Year.\n\nAberdeen Public Schools are part of the Aberdeen School District. The school district has five elementary schools, two middle schools, and one high school.\n\nThe elementary schools are C.C. Lee Elementary School, Lincoln Elementary School, May Overby Elementary School, O.M. Tiffany Elementary School and Simmons Elementary School. The two middle schools are Holgate Middle School, which serves the north side of Aberdeen, and Simmons Middle School, which serves the south side of the city. Students in the district attend Central High School. The Hub Area Technical School is located in the district. Aberdeen also has an alternative middle and high school.\n\nThe Aberdeen School District's enrollment for the year 2011–2012 was approximately 3,945 students, and the average class size was in the low to mid-twenties. Due to a projected increase in enrollment and the modernization of facilities, Simmons Middle School was completely remodeled with the demolition of the original 1929 building and the addition of a new classroom and cafeteria building which was completed in August 2008. The public school in Aberdeen is AA under the SDHSAA.\n\nAberdeen has several parochial schools, including the Catholic-affiliated Roncalli High School, the nondenominational Aberdeen Christian School and the Trinity Lutheran School (WELS).\n\nThe South Dakota School for the Blind and Visually Impaired is a state special school under the direction of the South Dakota Board of Regents.\n\nNorthern State University (NSU) is a public university that was founded in 1901 and today occupies a campus. 2,528 students, ranging from first-year to graduate students, attended NSU for the 2006–2007 school year. The student to teacher ratio is 19:1.\n\nNSU was originally called the Institute of South Dakota before changing its name to Northern Normal and Industrial School in 1901. It changed its name again in 1939 when it became the Northern State Teachers College, and again in 1964, becoming Northern State College before finalizing at Northern State University in 1989.\n\nNSU offers thirty-eight majors and forty-two minors as well as other degrees, and also has nine graduate degree areas for students wishing to further their education after achieving their first degree.\n\nThe mascot of NSU is the wolf named Thunder.\n\nPresentation College is a Catholic college on a campus, and was founded in 1951. Enrollment in fall 2014 was reported to be 735. PC offers 26 programs between the main Aberdeen campus and the other campuses located throughout the state. Most of the degrees offered are in the health-care field. The student to teacher ratio is 12:1. Presentation's mascot is the Saint, giving it the nickname the Presentation College Saints.\n\n\"The American News\" was founded as a weekly newspaper in 1885, by C.W. Starling and Paul Ware. It is now a daily newspaper.\n\nThe Aberdeen Regional Airport is currently served by Delta Connection. It offers flights to Minneapolis-St. Paul International Airport using the Bombardier CRJ200 aircraft.\n\nThere are two major US highways that serve Aberdeen. One is US Highway 281 that runs north-south from the North Dakota border to the border with Nebraska. The second highway is US Highway 12 that runs east-west across northern South Dakota from the Minnesota border before curving northwest into the southwestern corner of North Dakota. US Highway 12 is the major thoroughfare in Aberdeen. US Highway 12 is signed in the city of Aberdeen as 6th Avenue South. US Highway 281 was recently realigned onto a new bypass that was constructed around the western area of the city.\n\nAberdeen Taxi service provides general taxi service in Aberdeen. Aberdeen Shuttle provides shuttle service to and from the airport along with general taxi services.\n\nJefferson Lines is a bus service from Aberdeen that connects to Sioux Falls, South Dakota, Fargo, North Dakota, and Minneapolis, Minnesota.\n\nThere are five car rental services in Aberdeen: Hertz, Avis, Dollar-Thrifty, Toyota Rent-a-Car and Nissan Rental Car. Hertz and Avis Car rental are located in the airport terminal. Dollar-Thrifty is located in Aberdeen Flying Service. Toyota Rent-a-Car and Nissan Rental Car are located at Harr Motors across from the airport.\n\nThe BNSF Railway conveys freight and grain through Aberdeen.\n\nAberdeen is currently home to two hospitals, Avera St. Luke's Hospital, and Sanford Aberdeen Medical Center.\n\nThere are several nursing homes in the area, including Avera Mother Joseph Manor, Manor Care, Bethesda Home of Aberdeen, Aberdeen Health and Rehab, Angelhaus and Gellhaus Carehaus.\n\n\n\n", "id": "2709", "title": "Aberdeen, South Dakota"}
{"url": "https://en.wikipedia.org/wiki?curid=2710", "text": "Au\n\nAu, AU or au may refer to:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "2710", "title": "Au"}
{"url": "https://en.wikipedia.org/wiki?curid=2712", "text": "Aberdour\n\nAberdour (; , ) is a scenic and historic village on the south coast of Fife, Scotland. It is on the north shore of the Firth of Forth, looking south to the island of Inchcolm and its Abbey, and to Leith and Edinburgh beyond. According to the 2011 census, the village has a population of 1,633.\n\nThe village's winding High Street lies a little inland from the coast. Narrow lanes run off it, providing access to the more hidden parts of the village and the shoreline itself. The village nestles between the bigger coastal towns of Burntisland to the east and Dalgety Bay to the west.\n\nThe origins of the village lie with its harbour, where the Dour Burn enters the River Forth. The place-name itself is Pictish, implying an origin in the Dark Ages: \"aber\" 'confluence'. The -dour element, referring to the Burn, means simply 'water' (archaic \"dobur\"), and is unconnected to the Scots/English 'dour'. For much of its history Aberdour was two villages, Wester Aberdour and Easter Aberdour, on either side of the Dour Burn. Although this distinction was blurred by the 19th century arrival of the railway.\n\nIn the 18th century Aberdour's harbour was improved by the addition of a stone pier to help handle the coal traffic from nearby collieries. However, in the 1850s the traffic changed dramatically, and Aberdour Harbour became a popular destination for pleasure steamers from Leith. This in turn led to the building of a deeper water pier a little around the bay at Hawkcraig, and to the development of hotels and many of the other services still on view today in the village.\n\nThe railway came to Aberdour in 1890, with the building of the line east from the newly opened Forth Bridge. The station has won many \"best kept station\" awards. The half an hour journey to the centre of Edinburgh helped build on the existing popularity of the village, though it put the steamers out of business. The main result was a growth in the building of large and attractive houses, especially down the hill from Wester Aberdour to the West Sands. Ticket inspectors on the train line through Aberdour were known for their sing song refrain: \"\"Half an hour, Half an hour, Half an hour to Aberdour - tickets please.\"\"\n\nVirtually between the two former settlements, though actually part of Easter Aberdour, lies Aberdour Castle. This started life as a modest hall house on a site overlooking the Dour Burn in the 13th century. The oldest part of the present semi-ruin constitutes one of the earliest surviving stone castles in mainland Scotland. Over the next four hundred years the Castle was successively developed according to contemporary architectural ideas. Notable are the parts, still largely roofed, built by the Earls of Morton, with refined Renaissance detail, in the second half of the 16th century. A fire in the late 17th century was followed by some repairs, but in 1725 the family purchased 17th century Aberdour House, on the west side of the burn and in Wester Aberdour, and the medieval Castle was allowed to fall into relative decay. Aberdour Castle is now in the care of Historic Scotland and open to the public (entrance charge). After a period of dereliction Aberdour House was developed for residential use in the early 1990s.\n\nNeighbouring St Fillan's Church is one of the best-preserved medieval parish churches in Scotland, dating largely to the 12th century. A south arcade was added to the nave in the early 16th century (open in summer). The A921, the main road along the south coast of Fife, leads down the High Street of Wester Aberdour, before kinking sharply left to cross the railway line, then right again to progress through Easter Aberdour's Main Street.\n\nWester Aberdour has the more 'olde worlde' feel of the two, with the narrower through road more closely hemmed in by shops and hotels. A number of vernacular buildings of the 17th-early 19th centuries add to the historic scene. Close to the railway bridge, three lanes continue eastwards, presumably once the route of the original High Street before the arrival of the railway. One now leads to Aberdour railway station, a beautifully kept and cared for example of a traditional station, in keeping with its role of transporting at least a quarter of the village's working population to their work each day.\n\nA second lane leads alongside the railway line to Aberdour Castle, while a third leads to the restored Aberdour House. A little further west, a narrow road closely lined with high walls, Shore Road, leads down to the West Sands and the Harbour. For many this area is the highlight of any visit to Aberdour; parking at the foot of Shore Road is usually at a premium.\n\nAnother road leads coastwards from Easter Aberdour. Hawkcraig Road leads past St Fillan's Church and through Silversand Park, home to Aberdour Shinty Club, en route to the much better parking area on Hawkcraig. This was formerly a sandstone quarry and then used as the council refuse tip before becoming a carpark, part of the overgrown and rocky bluff separating Aberdour's two bays. From here is it a short walk to the Silver Sands, Aberdour's busiest and most popular beach. On the west side of Hawkcraig Point there is a short concrete jetty that was used as part of the development of radio controlled torpedoes during World War One. The foundations of the Radio Hut can still be seen in the lea of the hill.\n\nThe Aberdour obelisk was built by Lord Morton on his departure from the village to relocate to a large home in Edinburgh, it was built so he could see his former hometown from his new house when he looked through binoculars - it stands in a cowfield between the castle and the beach.\n\nThe yearly festival runs from the last week in July for a week, running into early August. It is now in its 32nd year and is most notable for its marquee on the silver sands playing fields. The festival hosts a number of children's, cultural and local events. Acts that have performed at Aberdour festival have been Yard Of Ale, Percy & The Peanuts, Swings & Roundabouts, Capercaillie, Boys of the Lough, Eddi Reader and The Fence Collective's Three Craws\n\nThe Donkey brae run is held on the first Sunday of the festival and is popular nationwide, with a 7-mile race, 2-mile run and a 1-mile run for children.\n\nAberdour has a very popular yearly festival, which runs from late July to early August and features musical events, shows, sporting events and children's events.\n\nAberdour was a 2005 finalist in the prestigious \"Beautiful Scotland in Bloom\" awards. It was nominated for \"\"Best Coastal Resort\"\" in Scotland along with St Andrews in Fife, North Berwick in East Lothian, and Rothesay in Argyll and Bute.\nIn 2014 Aberdour was voted Best Coastal Village in Fife and Best Small Coastal Village in Scotland. It also received a Gold Award in Beautiful Fife and Beautiful Scotland.\n\nAberdour is home to Fife's only senior shinty club. Aberdour Shinty Club field teams in both the men's and women's senior national leagues.\n\nAberdour has two beaches - the Silver Sands, and the Black Sands.\n\nThe Silver Sands are located on the East side of the village, and has previously held a \"Blue flag\" beach award, which denotes an exemplary standard of cleanliness, facilities, safety, environmental education and management. New facilities are currently under construction by Fife Council, which will much improve the beach throughout the year.\n\nThe Black Sands (also known as the West Beach), as the contrasting name would suggest, have a rockier and darker sand, and are also popular with visitors exploring the rock caves and fascinating sea life. During the summer months (April–September), dogs are banned from the Silver Sands but they are allowed all year round at the West Beach. The two beaches are linked by part of the Fife Coastal Path which also takes you past the harbour and the Hawkcraig - a popular rock climbing location.\n\nSilver Sands is becoming more popular with open water swimmers, who swim daily in the sea, both as a leisure pursuit, and as training for open water competition. The bay provides safety from the currents, although only the adventurous swim round to the harbour.\n\nSeveral scenes of Richard Jobson's 2003 movie \"16 Years of Alcohol\" were filmed at the Black Sands in Aberdour.\n\nThe island of Inchcolm, or Island (Gaelic \"innis\") of Columba, a quarter of a mile from the shore, forms part of the parish of Aberdour. Its name implies associations dating back to the time of Columba and, although undocumented before the 12th century, it may have served the monks of the Columban family as an 'Iona of the east' from early times.\n\nDuring the First and Second World Wars, Inchcolm was occupied by the army as part of the defences of the Firth of Forth. There are extensive remains of gun emplacements, barracks, etc. from these periods.\n\nThe island is notable for its wildlife, especially seabirds and seals. These draw many visitors in summer, along with the remains of the historic Abbey, and is a popular setting for weddings.\n\nNotable past and present residents of the town include:\n\n\n\n", "id": "2712", "title": "Aberdour"}
{"url": "https://en.wikipedia.org/wiki?curid=2714", "text": "Aberfoyle, Stirling\n\nAberfoyle () is a village in the historic county and registration county of Perthshire and the council area of Stirling, Scotland. The settlement lies northwest of Glasgow.\n\nThe town is situated on the River Forth at the foot of Craigmore (420 metres high). Since 1885, when the Duke of Montrose constructed a road over the eastern shoulder of Craigmore to join the older road at the entrance of the Trossachs pass, Aberfoyle has become the alternative route to the Trossachs and Loch Katrine; this road, known as the Duke's Road or Duke's Pass, was opened to the public in 1931 when the Forestry Commission acquired the land.\n\nLoch Ard, about two miles (3 km) west of Aberfoyle, lies 40 metres above the sea. It is three miles (5 km) long (including the narrows at the east end) and one mile (1½ km) broad. Towards the west end is Eilean Gorm (\"the green isle\"), and near the north-western shore are the falls of Ledard. Two miles northwest is Loch Chon, at 90m above the sea, long, and about half a mile broad. It drains by the Avon Dhu to Loch Ard, which is drained in turn by the Forth.\n\nIn the past Aberfoyle was spelt alternatively as \"Aberfoil\". \nThe slate quarries on Craigmore which operated from the 1820s to the 1950s are now defunct; at its peak this was a major industry. Other industries included an ironworks, established in the 1720s, as well as wool spinning and a lint mill.\n\nFrom 1882 the village was served by Aberfoyle railway station, the terminus of the Strathendrick and Aberfoyle Railway which connected to Glasgow via Dumbarton or Kirkintilloch The station closed to passenger traffic in 1951, and the remaining freight services ceased in 1959.\n\nThe above industries have since died out, and Aberfoyle is supported mainly by the forestry, industry and tourism.\n\nVisitors were first attracted to Aberfoyle and the surrounding area after the publication of \"The Lady of the Lake\" by Sir Walter Scott in 1810. The poem described the beauty of Loch Katrine. Aberfoyle describes itself as \"The Gateway to the Trossachs\", and is well situated for visitors to access attractions such as Loch Lomond and Inchmahome Priory at the Lake of Menteith. A tourist information office run by VisitScotland sits in the centre of town, offering free information, selling souvenirs and acting as a booking office for many of the local B&B's and hotels. Aberfoyle Golf Club was built in 1860 and is located just south of town near the Rob Roy restaurant. Aberfoyle is also part of the Loch Lomond and The Trossachs National Park.\n\nAberfoyle is also home to the largest Go Ape adventure course in the UK, featuring the longest death slide, or 'zip-line', in the UK.\n\nAberfoyle has connections to many historical figures such as Rob Roy and Mary, Queen of Scots. Robert Roy MacGregor was born at the head of nearby Loch Katrine, and his well-known cattle stealing exploits took him all around the area surrounding Aberfoyle. It is recorded, for example, that in 1691, the MacGregors raided every barn in the village of Kippen and stole all the villagers' livestock! There currently stands a tree in the village that MacGregor was reputed to have climbed and hid in to escape the clutches of the law. Also, Mary, Queen of Scots, visited nearby Inchmahome Priory often as a child, and during her short reign. She also used the priory during her short reign, particularly in 1547, where she felt safe from the English Army.\n\nHowever, the most local historical figure is the Reverend Robert Kirk, born in 1644. It was the Rev. Kirk who provided the first translation into Gaidhlig of the Book of Psalms, however, he is better remembered for the publication of his book \"\"The Secret Commonwealth of Elves, Fauns, and Fairies\"\" in 1691. Kirk had long been researching fairies, and the book collected several personal accounts and stories of folk who claimed to have encountered them. It was after this, while Kirk was minister of Aberfoyle parish, that he died in unusual circumstances.\n\nKirk had long believed that the local Doon Hill was the gateway to the \"Secret Commonwealth\", or the land of the Fairies. It was a place that Kirk visited often, taking daily walks there from his manse. The story goes that the Fairies of Doon Hill were angry with the Rev. Kirk for going into the domain of the Unseelie court, where he had been warned not to go, and decided to imprison him in Doon Hill — for one night in May 1692, the Rev. Kirk went out for a walk to the hill, in his nightshirt. Some accounts claim that he simply vanished, however he suddenly collapsed. He was found and brought home, but died soon afterwards. He was buried in his own kirkyard, although local legends claim that the fairies took his body away, and the coffin contains only stones. The huge pine tree that still stands at the top of Doon Hill is said to contain Kirk's imprisoned spirit.\n\nKirk's cousin, Graham of Duchray, was then to claim that the spectre of Kirk had visited him in the night, and told him that he had been carried off by the Fairies. Having left his widow expecting a child, the spectre of Kirk told Graham that he would appear at the baptism, whereupon Graham was to throw an iron knife at the apparition, thus freeing Kirk from the Fairies' clutches. However, when Kirk's spectre appeared, Graham was apparently too shocked by the vision to throw the knife, and Kirk's ghost faded away forever.\n\nToday, visitors to Doon Hill write their wishes on pieces of white silk, or other white cloth, and tie them to the branches of the trees for the Fairies to grant. Unfortunately some people tie plastic confectionery wrappers instead, which slightly spoils the magic of the location and may harm the ecology of the forest. It is also said that if one runs around the great 'Minister's Pine' tree at the summit seven times, then the Fairies will appear. Some people have tried this and afterwards claim to have seen apparitions. Others merely get a bit dizzy and fall over.\n\n", "id": "2714", "title": "Aberfoyle, Stirling"}
{"url": "https://en.wikipedia.org/wiki?curid=2715", "text": "Abergavenny\n\nAbergavenny (; , archaically \"Abergafenni\" meaning \"Mouth of the River Gavenny\") is a market town in Monmouthshire, Wales. It is located west of Monmouth on the A40 and A465 roads, from the English border. Originally the site of a Roman fort, Gobannium, it became a medieval walled town within the Welsh marches. The town contains the remains of a medieval stone castle built soon after the Norman conquest of Wales. The town hosted the 2016 National Eisteddfod of Wales.\n\nAbergavenny is promoted as a \"Gateway to Wales\". Situated at the confluence of a tributary stream, the Gavenny, and the River Usk, it is almost surrounded by two mountains – the Blorenge () and the Sugar Loaf () – and five hills: Ysgyryd Fawr (The Skirrid), Ysgyryd Fach (Skirrid Fach), Deri, Rholben and Mynydd Llanwenarth, known locally as \"Llanwenarth Breast\". It provides access to the nearby Black Mountains and the Brecon Beacons National Park. The Offa's Dyke Path is close by and the Marches Way, the Beacons Way and Usk Valley Walk all pass through the town.\n\nThe name derives from a Brythonic word \"Gobannia\" meaning \"river of the blacksmiths\", and relates to the town's pre-Roman importance in iron smelting. The name is related to the modern Welsh word \"gof\" (blacksmith), and so is also associated with the Welsh smith Gofannon from folklore. The river later became, in Welsh, \"Gafenni\", and the town's name became Abergavenny, meaning \"mouth of (Welsh: \"Aber\") the Gavenny (\"Gafenni\")\". In Welsh, the shortened form \"Y Fenni\" may have come into use for a very short period after about the 15th century, although pronounced similarly in English or Welsh the English spelling Abergavenny is in general use.\n\nGobannium was a Roman fort guarding the road along the valley of the River Usk, which linked the legionary fortress of Burrium (Usk) and later Isca Augusta or Isca Silurum (Caerleon) in the south with Y Gaer, Brecon and Mid Wales. It was also built to keep the peace among the local British Iron Age tribe, the Silures.\n\nRemains of the walls of this fort were discovered west of the castle when excavating the foundations for a new post office and telephone exchange building in the late 1960s.\n\nAbergavenny grew as a town in early Norman times under the protection of the Lords of Abergavenny. The first Baron was Hamelin de Balun, from Ballon, a small town and castle in Maine-Anjou called \"Gateway to Maine\", near Le Mans, today in the Sarthe département of France. He founded the Benedictine priory, now the Priory Church of St Mary, in the late 11th century. The Priory belonged originally to the Benedictine foundation of St. Vincent Abbaye at Le Mans. It was subsequently endowed by William de Braose, with a tithe of the profits of the castle and town. The church contains some unique alabaster effigies, church monuments and unique medieval wood carving, such as the Tree of Jesse.\n\nOwing to its geographical location, the town was frequently embroiled in the border warfare and power play of the 12th and 13th centuries in the Welsh Marches. In 1175, Abergavenny Castle was the site of the Massacre. Reference to a market at Abergavenny is found in a charter granted to the Prior by William de Braose.\n\nOwain Glyndŵr attacked Abergavenny in 1404. According to popular legend, his raiders gained access to the walled town with the aid of a local woman who sympathised with the rebellion, letting a small party in via the Market Street gate at midnight. They were able to open the gate and allow a much larger party who set fire to the town and plundered its churches and homes leaving Abergavenny Castle intact. Market Street has been referred to as \"Traitors' Lane\" thereafter. In 1404 Abergavenny was declared its own nation by Ieuan ab Owain Glyndŵr, illegitimate son of Owain Glyndŵr. The arrangement lasted approximately two weeks.\n\nAt the Dissolution of the Monasteries in 1541, the priory's endowment went towards the foundation of a free grammar school, King Henry VIII Grammar School, the site itself passing to the Gunter family.\n\nDuring the Civil War, prior to the siege of Raglan Castle in 1645, King Charles I visited Abergavenny and presided in person over the trial of Sir Trefor Williams, 1st Baronet of Llangibby, a Royalist who changed sides, and other Parliamentarians.\n\nIn 1639, Abergavenny received a charter of incorporation under the title of bailiff and burgesses. A charter with extended privileges was drafted in 1657, but appears never to have been enrolled or to have come into effect. Owing to the refusal of the chief officers of the corporation to take the oath of allegiance to William III in 1688, the charter was annulled, and the town subsequently declined in prosperity. Chapter 28 of the 1535 Act of Henry VIII, which provided that Monmouth, as county town, should return one burgess to Parliament, further stated that other ancient Monmouthshire boroughs were to contribute towards the payment of the member. In consequence of this clause Abergavenny on various occasions shared in the election, the last instance being in 1685.\n\nThe right to hold two weekly markets and three yearly fairs, beginning in the 13th century, was held ever since as confirmed in 1657. Abergavenny was celebrated for the production of Welsh flannel, and also for the manufacture, whilst the fashion prevailed, of goats' hair periwigs.\n\nAbergavenny railway station opened 2 January 1854 by the Newport, Abergavenny and Hereford Railway. The London North Western Railway sponsored the construction of the railway linking Newport station to Hereford station. The line was taken over by the West Midland Railway in 1860 before becoming part of the Great Western Railway in 1863. The station is on the Welsh Marches Line and is mostly served by Arriva Trains Wales services. Adolf Hitler's deputy Rudolf Hess was kept under escort at Maindiff Court Military Hospital during the Second World War, after his flight to Britain.\n\nThe title of Baron Abergavenny, in the Nevill family, dates from the 15th century with Edward Nevill, 3rd Baron Bergavenny, who was the youngest son of Ralph de Neville, 1st Earl of Westmorland by his second wife Joan Beaufort, daughter of John of Gaunt, first Duke of Lancaster. He married the heiress of Richard de Beauchamp, 1st Earl of Worcester, whose father had inherited the castle and estate of Abergavenny, and was summoned in 1392 to parliament as Lord Bergavenny. Edward Nevill was summoned to parliament with this title in 1450. His direct male descendants ended in 1587 in Henry Nevill, 6th Baron Bergavenny, but a cousin, Edward Nevill, 8th Baron Bergavenny, was confirmed in the barony in 1604. From him it has descended continuously, through fifteen individuals, the title being increased to an earldom in 1784; and in 1876 William Nevill 5th Earl, an indefatigable and powerful supporter of the Tory Party, was created 1st Marquess of Abergavenny.\n\nColdbrook Park was a country house in an estate some southeast of the town. The house was originally built in the 14th century and belonged to the Herbert family for many generations until purchased by John Hanbury for his son, the diplomat Sir Charles Hanbury Williams. Sir Charles reconstructed the house in 1746 with the addition of a nine-bay two-storey Georgian façade with a Doric portico. It subsequently passed down in the Hanbury Williams family until it was demolished in 1954.\n\nHeld during the first week of August every year, the National Eisteddfod is a celebration of the culture and language in Wales. The festival travels from place to place, alternating between north and south Wales, attracting around 150,000 visitors and over 250 tradestands and stalls. The Chair and Crown for 2016 were presented to the festival's Executive Committee, at a special ceremony in Monmouth held on 14 June 2016.\n\nThe Abergavenny Food Festival, is held in the second week of September each year. The Steam, Veteran and Vintage Rally takes place in May every year. The event expands year on year with the 2016 rally including a rock choir, shire horses, motorcycling stunts, vintage cars and steam engines. The Country and Western Music Festival is attended by enthusiasts of country music. It marked its third year in 2016 and was attended by acts including Ben Thompson, LA Country and many more. The Abergavenny Writing Festival began in April 2016 and is a celebration of writing and the written word.\n\nIn recent decades the number of Welsh speakers in the town has increased dramatically. The 2001 census recorded 10% of the local population spoke the language, a five fold increase over ten years from the figure of 2% recorded in 1991.\n\nThe town has one of the two Welsh-medium primary schools in Monmouthshire, Ysgol Gymraeg y Fenni, which was founded in the early 1990s. It is also home to the Abergavenny Welsh society, Cymreigyddion y Fenni, and the local Abergavenny Eisteddfod.\n\nAbergavenny was the home of Abergavenny Thursdays F.C., which was formed in 1927, but wound up in 2013. However, football is now represented in the town by the new Abergavenny Town team which was formerly called Govilon FC. Town play at the Penypound Stadium and are members of the Welsh League Division 2 for season 2016-17.\n\nAbergavenny Cricket Club play at Pen-y-Pound, Avenue Road, and Glamorgan CCC also play some of their games here. Abergavenny Cricket Club is one of the oldest in the country and celebrated the 175th anniversary of its foundation in 2009. Abergavenny Tennis Club also play at Pen-y-Pound and plays in the South Wales Doubles League and Aegon Team Tennis. The club engages the services of a head tennis professional to run a coaching programme for the town and was crowned Tennis Wales' Club of the Year in 2010.\n\nAbergavenny is also the home of Abergavenny RFC, a rugby union club founded in 1875 who play at Bailey Park. They play in the Welsh Rugby Union Division Two East league. Abergavenny Hockey Club, formed in 1897, currently compete in the Davis Woods hockey league and play at the Old Hereford Road ground. Abergavenny hosted the British National Cycling Championships in 2007, 2009 and 2014, as part of the town's Festival of Cycling.\n\nA cattle market has been held in Abergavenny on its current site since 1863. During the period 1825–1863 a sheep market was held at a site in Castle Street, to stop the sale of sheep on the streets of the town. Today the market is leased and operated by Abergavenny Market Auctioneers Ltd, who hold regular livestock auctions on the site. Market days are: Tuesday – auction sale of finished sheep, cull ewe/store and fodder (hay and straw). Some Fridays – auction sale of cattle. A few other sales are held at the market on other days throughout the year. Following the closure of Newport's cattle market for redevelopment, Newport’s sales are held at Abergavenny every Wednesday.\n\nIn 2011, doubts about the future of Abergavenny Cattle Market were raised following the granting of planning permission by Monmouthshire County Council for its demolition and replacement with a supermarket, car park, and library.\n\nIn January 2012, the Welsh Government announced the repeal the Abergavenny Improvement Acts of 1854 to 1871 which obliged the holding of a livestock market within the boundaries of Abergavenny town; that repeal being effective from 26 March 2012.\n\nMonmouthshire County Council, which requested that the Abergavenny Improvement Acts be repealed, is supporting plans for a new cattle market to be established about from Abergavenny in countryside at Bryngwyn, some from Raglan. There has been extensive local opposition to this site, which is situated on a notoriously dangerous B road.\n\nVarious markets are held in the Market Hall, for example: Tuesdays, Fridays and Saturdays – retail market; Wednesdays – flea market; fourth Thursday of each month – farmers' market; third Sunday of each month – antique fair; second Saturday of each month – craft fair.\n\n\nAbergavenny Castle is located strategically just south of the town centre overlooking the River Usk. It was built in about 1067 by the Norman baron Hamelin de Ballon to guard against incursions by the Welsh from the hills to the north and west. All that remains is defensive ditches and the ruins of the stone keep, towers, and part of the curtain wall. It is a Grade I listed building.\nOther listed buildings in the town include the parish Church of St Mary, a medieval and Victorian building that was originally the church of the Benedictine priory founded in Abergavenny before 1100; the sixteenth century tithe barn near St Mary's; the Victorian Church of the Holy Trinity; the Grade II* listed St John's Masonic Lodge; the Museum; the Public Library; the Town Hall; and the remains of the town walls behind Neville Street.\nThe Church in Wales church of the Holy Trinity is in the Diocese of Monmouth. Holy Trinity Church was consecrated by the Bishop of Llandaff on November 6, 1840. It was originally built as a chapel to serve the adjacent almshouses and the nearby school. It has been Grade II listed since January 1974.\n\nFrom 1851, the Monmouthshire Lunatic Asylum, later Pen-y-Fal Hospital, a psychiatric hospital, stood on the outskirts of Abergavenny. Between 1851 and 1950, over 3,000 patients died at the hospital. A memorial plaque for the deceased has now been placed at the site. After closure in the 1990s, its buildings and grounds were redeveloped as a luxury housing development comprising houses as well as apartments. Some psychiatric services are now administered from Maindiff Court Hospital on the outskirts of the town, close to the foot of the Skirrid mountain. The hospital is housed in historic buildings, and is known for Rudolf Hess who was incarcerated here during WW2.\n\n\n\n\n\n", "id": "2715", "title": "Abergavenny"}
{"url": "https://en.wikipedia.org/wiki?curid=2716", "text": "Abersychan\n\nAbersychan is a settlement and community north of Pontypool in Torfaen, Wales, and lies within the boundaries of the historic county of Monmouthshire and the preserved county of Gwent.\n\nAbersychan lies in the narrow northern section of the Afon Lwyd valley.\n\nThe town includes two schools; Abersychan Comprehensive School and Victoria Primary School; together with various shops and other amenities including Abersychan Rugby Club.\n\nAbersychan was the birthplace of the politicians Roy Jenkins, Don Touhig and Paul Murphy (MP for Torfaen); and of the rugby footballers Wilfred Hodder, Candy Evans and Bryn Meredith.\n\nLike many of the 17th century isolated agricultural hamlets in the forested South Wales Valleys, Abersychan became a thriving industrial centre in the 19th and early 20th centuries, particularly for iron production.\n\nAfter the discovery of iron stone locally, the principal ironworks were built by the British Iron Company in 1825, served mainly by the LNWR's Brynmawr and Blaenavon Railway. The ironwork's main office building and quadrangle were designed by architect Decimus Burton, best known for his design of London Zoo. The works passed to the New British Iron Company in 1843 and to the Ebbw Vale Company in 1852, before closing in 1889. On 6 February 1890, an underground explosion at Llanerch Colliery killed 176.\n\nThe site of the former ironworks today is a core site of , and a total land area of , includes a number of listed buildings:\n\nVarious proposals have been made over the years to redevelop the site, currently under the ownership of HSBC, but none have so far passed the requirements of Torfaen county council.\n\nAbersychan constitutes a community and electoral ward of the county borough of Torfaen. The area was part of the ancient parish of Trevethin, in Monmouthshire. On 3 June 1864 Abersychan was constituted a local government district, governed by a local board. In 1894 Abersychan became an urban district and civil parish. The urban district was abolished in 1935, with most of its area passing to Pontypool urban district, and a small area going to Abercarn UD.\n\nIn 1974 the area became part of the borough of Torfaen, in the new local government county of Gwent. The community of Abersychan was formed in 1985, but no community council has yet been formed. Abersychan and Cwmavon is now a ward for the Pontypool Community Council. In 1996 Torfaen became a unitary authority.\n\nThe Abersychan community includes Abersychan, Cwmavon, Garndiffaith, Pentwyn, Talywain, Varteg, and Victoria Village.\n\nThe nearest railway stations to Abersychan are Pontypool & New Inn (3 miles), Llanhilleth (3.5 miles) and Abergavenny (7 miles). Abersychan was served by the following (disused) stations:\n\n\"Pentwyn\", Torfaen is a small village located in the district of Abersychan. It contains a post office, a chapel, several houses and a small play park. The village has a cricket team (Pentwyn CC) and is located right next to the old railway line. The cricket club celebrated its 100-year anniversary in 2006 with a successful tour to Cork, Ireland. The village has superb views over the River Severn and Newport to the south.\n\n\"Victoria Village\" is a small hamlet located in the district of Abersychan. It comprises a small village school and a number of houses. A small group of houses on Incline Road mark the beginning of the village and the village boundary is near Cwmavon. Victoria Primary School is also in this area, housed in large grounds. Many homes are built around the school's boundaries.\n", "id": "2716", "title": "Abersychan"}
{"url": "https://en.wikipedia.org/wiki?curid=2717", "text": "Abertillery\n\nAbertillery (; , meaning mouth of the River Tyleri is the largest town of the Ebbw Fach valley in what was the historic county of Monmouthshire, Wales. Following local government reorganisation it became part of the Blaenau Gwent County Borough administrative area.\n\nThe surrounding landscape borders the Brecon Beacons National Park and the Blaenavon World heritage Site. Formerly a major coal mining centre the Abertillery area has been transformed in recent decades. The local landscape has long been known for its varied natural beauty.\n\nSituated on the A467 the town is north of the M4 and south of the A465 \"Heads of the Valleys\" trunk road. It is about by road from Cardiff and from Bristol.\n\nAccording to the 2001 Census and information gathered by The Welsh Language Board (), 1,146 (9.9%) of Abertillery speaks Welsh. In the 2011 Census, this figure dropped to 7.2%, a 2.7 percentage point drop.\n\nAbertillery's traditional-style town centre mainly developed in the late 19th century and as such has some interesting Victorian architecture. Spread over 4 main streets the town in its heyday had two department stores and a covered Victorian arcade linking two of the main shopping areas. These were all included in a Blaenau Gwent Borough Council remodelling and modernisation project using European Union funding in a £13 million programme spread over a 5-year period ending in 2015.\n\nThe project included a new multi-storey car park, a revamp of public areas and the town's Metropole Theatre. This RICS award-winning building provides state of the art production, exhibition, conference and meeting facilities as well as housing Abertillery museum. In March 2014 Prince Edward, the Earl of Wessex, officiated at the launch of Jubilee Square, a public facility in the town centre next to St Michael's Church.\n\nMajor industry came to the area in 1843 when the locality's first deep coal mine was sunk at Tir Nicholas Farm, Cwmtillery. The town developed rapidly thereafter and played a major part in the South Wales coalfield. Its population rose steeply, being 10,846 in the 1891 census and 21,945 ten years later. The population peaked just short of 40,000 around the beginning of the 1930s. Eventually there were six deep coal mines, numerous small coal levels, a tin works, brick works, iron foundry and light engineering businesses in the area. Just one of the coal mines, Cwmtillery, produced over 32 million tons of coal in its lifetime and at its height employed 2760 men and boys.\n\nIn 1960 an underground explosion at Six Bells Colliery resulted in the loss of life of 45 local miners. Fifty years later the archbishop of Canterbury Rowan Williams officiated at the launch of the \"Guardian\" mining memorial. This artistically acclaimed monument standing at 20m tall overlooks Parc Arael Griffin, the now reclaimed and landscaped former colliery site. The adjoining Ty Ebbw Fach visitor centre provides conference facilities, a restaurant and a \"mining valley\" experience room. Not long after the disaster the renowned artist L. S. Lowry visited the area and recorded the scene. The resultant landscape painting now hangs in the Museum of Wales in Cardiff.\n\nThe coal mines remained the predominant economic emphasis until the general run down of the industry in the 1980s.\n\nAway from the town centre, the often steep sided nature of the landscape, imposes its own demands on development. Whilst this sounds limiting it has helped provide the almost amphitheatre nature of Abertillery Park, often described as one of the most attractive rugby grounds in world rugby.\n\nThe street plan and housing stock flow uninterrupted from Cwmtillery in the north to Six Bells in the south, forming the town that is Abertillery. Prior to 1974 local government was provided by Abertillery Urban District Council (AUDC). Its area included the small neighbouring villages of Aberbeeg, Llanhilleth and Brynithel. Historical data relating to Abertillery occasionally refers to this AUDC area meaning that it can be difficult to compare like with like. For example, the 2014 population for the wider conurbation area is around 20,000 rather than the 11,000 often quoted for Abertillery itself.\n\nWhilst in the main the area has an older housing stock there are several developments of modern, often large homes, generally found on the outskirts of the town with views out over the surrounding area. These apart, terraced council tax band A and B properties predominate, meaning that average house prices are among the most affordable in the UK.\n\nThere are very few written historical records relating to the area possibly because today's town developed as late as the middle of the 19th century. Nevertheless, there are facts that you can use to outline important events.\n\n\nBefore the coming of major industry, Abertillery was little more than an area of scattered farms in the ancient parish of Aberystruth. In 1779 the parish minister Edmund Jones described the area thus: \"The valley of Tyleri ... is the most delightful. The trees ... especially the beech trees, abounding about rivers great and small, the hedges and lanes make these places exceeding pleasant and the passing by them delightful and affecting ... in these warm valleys, with the prospect of the grand high mountains about them would make very delightful habitations.\" In 1799 historian Arch Deacon Coxe toured the area and in writing a diary of his travels described it as \"... richly wooded, and highly cultivated...we looked down with delight upon numerous valleys ... with romantic scenery\". The entire population of Aberystruth parish at the turn of the 19th century was just a little over 800. It is not known what the population of Abertillery was at the time but it was probably in the very low hundreds, all of whom would have spoken Welsh only.\n\nThe area's first deep coal mine was sunk in 1843.\n\nFormed in 1877, Abertillery Urban District Council incorporated the adjoining smaller communities of Six Bells, Cwmtillery, Brynithel, Aberbeeg and Llanhilleth. The population of this conurbation climbed to almost 40,000 in 1931 making it the second largest town in Monmouthshire. The council was abolished in 1974 as part of major UK wide local government reorganisation.\n\nThe reopening of Abertillery railway station has been identified as a future development of the Ebbw Valley Railway. Regular bus services in the area link with Llanhilleth railway station, away.\n\nThe modern local comprehensive provides secondary education for the town and neighbouring areas. It is fed by several small schools, the most recent of which was opened in 2000. Until the 1970s the town had its own local authority run Grammar school providing education up to the age of eighteen. Tertiary education is now provided by Coleg Gwent at Ebbw Vale – opened in 2013.\n\nThere are several small and medium-sized business parks in the area offering a range of business premises. In 2014 the largest employer was Tyleri Valley Foods. Many local people commute outside the area to work.\n\nAbertillery Town cricket club and Abertillery Blaenau Gwent RFC formed in the 1880s. Both have their playing headquarters at \"the Park\" one of the most picturesque sporting complexes in the UK.\nThe town supports two local Saturday football teams: Abertillery Bluebirds and Abertillery Excelsiors. There are numerous other sports activities running on an organized basis such as bowls, badminton, squash etc.\n\nThe surrounding landscape provides ideal hill walking opportunities and walker led groups are thriving in the area. The Borough Council provides details of local walks.\n\nThe local museum has displays showing what life was like in the area in its heyday. It even has its own \"valleys\" Italian café complete with original furnishings.\n\nThe very modern and well equipped Metropole theatre holds regular musical and drama events – from Blues to amateur dramatics and dance.\n\nThe critically acclaimed \"Guardian\" memorial is a favourite destination for visitors to South Wales and amateur photographers in particular. The visitor centre Tŷ Ebbw Fach stands nearby and provides cafe and visitor \"mining valley\" experience facilities.\n\nAbertillery is twinned with:\n\n\n", "id": "2717", "title": "Abertillery"}
{"url": "https://en.wikipedia.org/wiki?curid=2719", "text": "Abettor\n\nAbettor (from \"to abet,\" Old French \"abeter\", \"à\" and \"beter\", to bait, urge dogs upon any one; this word is probably of Scandinavian origin, meaning to cause to bite), is a legal term implying one who instigates, encourages or assists another to commit an offence.\n\nAn abettor differs from an accessory in that he must be present at the commission of the crime; in addition they are equally guilty as they knowingly and voluntarily assist in the commission of that crime. All abettors (with certain exceptions) are principals, and, in the absence of specific statutory provision to the contrary, are punishable to the same extent as the actual perpetrator of the offence. A person may in certain cases be convicted as an abettor in the commission of an offence in which he or she could not be a principal, e.g. a woman or boy under fourteen years of age in aiding rape, or a solvent person in aiding and abetting a bankrupt to commit offences against the bankruptcy laws.\n\nMore recently, an abettor is generally known as an accomplice.\n", "id": "2719", "title": "Abettor"}
{"url": "https://en.wikipedia.org/wiki?curid=2720", "text": "Abeyance\n\nAbeyance (from the Old French \"abeance\" meaning \"gaping\") is a state of expectancy in respect of property, titles or office, when the right to them is not vested in any one person, but awaits the appearance or determination of the true owner. In law, the term abeyance can only be applied to such future estates as have not yet vested or possibly may not vest. For example, an estate is granted to A for life, with remainder to the heir of B. During B's lifetime, the remainder is in abeyance, for until the death of B it is uncertain who is B's heir. Similarly the freehold of a benefice, on the death of the incumbent, is said to be in abeyance until the next incumbent takes possession.\n\nThe term hold in abeyance is used in lawsuits and court cases when a case is temporarily put on hold.\n\nThe most common use of the term is in the case of English peerage dignities. Most such peerages pass to heirs-male, but the ancient baronies created by writ, as well as some very old earldoms, pass instead to heirs-general (by cognatic primogeniture). In this system, sons are preferred from eldest to youngest, the heirs of a son over the next son, and any son over daughters, but there is no preference among daughters: they or their heirs inherit equally.\n\nIf the daughter is an only child or her sisters are deceased and have no living issue, she (or her heir) is vested with the title; otherwise, since a peerage cannot be shared nor divided, the dignity goes into abeyance between the sisters or their heirs, and is held by no one. If through lack of issue, marriage, or both, eventually only one person represents the claims of all the sisters, he or she can claim the dignity as a matter of right, and the abeyance is said to be terminated. On the other hand, the number of prospective heirs can grow quite large, since each share potentially can be divided between daughters, where the owner of a share dies without leaving a son.\n\nA co-heir may petition the Crown for a termination of the abeyance. The Crown may choose to grant the petition, but if there is any doubt whatsoever as to the pedigree of the petitioner, the claim is normally referred to the Committee for Privileges. If the claim is unopposed, the Committee will generally award the claim, unless there is evidence of collusion, the peerage has been in abeyance for more than a century, or the petitioner holds less than one-third of the claim.\n\nThis doctrine is a 17th-century innovation, although it is now applied retrospectively for centuries. It cannot be applied perfectly; for example, the eighth Baron De La Warr had three surviving sons; the first died without children, the second left two daughters, and the third left a son. In modern law, the title would have fallen into abeyance between the two daughters of the second son, and nobody else would have been able to claim it even if the abeyance were settled; however, in 1597, the grandson of the third son (whose father had been re-created Baron De La Warr in 1570) claimed the title and its precedence.\n\nIn 1604, the Baron le Despencer case was the first peerage abeyance ever settled; the second was at the Restoration in 1660. Most subsequent abeyances (only a few dozen cases) were settled after a few years, in favour of the holder of the family properties; there were two periods in which long-abeyant peerages (in some cases peerages of doubtful reality) were brought back: between 1838 and 1841 and between 1909 and 1921. \"The Complete Peerage\" reports that only baronies have been called out of abeyance, although the Earldom of Cromartie was called out of a two-year abeyance in 1895.\n\nIt is entirely possible for a peerage to remain in abeyance for centuries. For example, the Barony of Grey of Codnor was in abeyance for over 490 years between 1496 and 1989, and the Barony of Hastings was similarly in abeyance for over 299 years from 1542 to 1841. Some other baronies became abeyant in the 13th century, and the abeyance has yet to be terminated. The only titles other than a barony that have yet gone into abeyance are the earldom of Arlington and the viscountcy of Thetford, which are united, and (as noted above) the earldom of Cromartie.\n\nIt is no longer straightforward to claim English peerages after long abeyances. In 1927 a parliamentary Select Committee on Peerages in Abeyance recommended that no claim should be considered where the abeyance has lasted more than 100 years, nor where the claimant lays claim to less than one third of the dignity. The Barony of Grey of Codnor was treated as an exception to this principle, as a claim to it had been submitted prior to these recommendations being made to the Sovereign.\n\nTitles in the Peerage of Scotland cannot go into abeyance, because in Scottish law the eldest sister is preferred over younger sisters; sisters are not considered equal co-heirs.\n\nIt is common, but incorrect, to speak of peerage dignities which are dormant (i.e. unclaimed) as being in abeyance.\n\n\nAbeyance can be used in cases where parties are interested in temporarily settling litigation while still holding the right to seek relief later if necessary. This may be considered a desirable outcome in cases where the party to the lawsuit is an organization with a transient membership and political perspective. The use of abeyance in such instances can allow such an organization to 'settle' with the party without officially binding its actions in the future, should a new group of decision makers within the organization choose to pursue taking the dispute to court.\n\nFor example, abeyance was used as a settlement method in a Canadian lawsuit involving the University of Victoria Students' Society (UVSS), the BCCLA, and a campus pro-life club to whom the UVSS denied funding. The parties agreed to settle the lawsuit by holding the case in abeyance in return for the UVSS temporarily giving resources back to the club. With this arrangement, the pro-life club held on to its right to immediately reopen the case again should the UVSS deny resources to the club in the future, and the UVSS was able to avoid an expensive legal battle it did not have the will to pursue at the time. Thus the use of abeyance provided the security of a settlement for the pro-life campus club, while preserving the student society's voting membership's ability to take the matter back to court should they choose in the future to deny resources to the club.\n\nOther court cases may be held in abeyance when the issue may be resolved by another court or another event. This saves time and effort trying to resolve a dispute that may be made moot by the other events. During lawsuits related to the Patient Protection and Affordable Care Act (ACA, Obamacare) after the Supreme Court of the United States granted certiorari in \"King v. Burwell\" attorneys in \"Halbig v. Burwell\" requested abeyance of that case as the matter would be resolved in \"King\" and it would be a waste of time and effort to try and resolve it in the \"Halbig\" case.\n\n", "id": "2720", "title": "Abeyance"}
{"url": "https://en.wikipedia.org/wiki?curid=2722", "text": "Anders Celsius\n\nAnders Celsius (27 November 1701 – 25 April 1744) was a Swedish astronomer, physicist and mathematician. He was professor of astronomy at Uppsala University from 1730 to 1744, but traveled from 1732 to 1735 visiting notable observatories in Germany, Italy and France. He founded the Uppsala Astronomical Observatory in 1741, and in 1742 proposed the Celsius temperature scale which bears his name.\n\nAnders Celsius was born in Uppsala, Sweden on 27 November 1701. His family originated from Ovanåker in the province of Hälsingland. Their family estate was at \"Doma\", also known as \"Höjen\" or \"Högen\" (locally as \"Högen 2\"). The name \"Celsius\" is a latinization of the estate's name (Latin \"celsus\" \"mound\").\n\nAs the son of an astronomy professor, Nils Celsius, and the grandson of the mathematician Magnus Celsius and the astronomer Anders Spole, Celsius chose a career in science. He was a talented mathematician from an early age. Anders Celsius studied at Uppsala University, where his father was a teacher, and in 1730 he too, became a professor of astronomy there.\n\nIn 1730, Celsius published the (\"New Method for Determining the Distance from the Earth to the Sun\"). His research also involved the study of auroral phenomena, which he conducted with his assistant Olof Hiorter, and he was the first to suggest a connection between the aurora borealis and changes in the magnetic field of the Earth. He observed the variations of a compass needle and found that larger deflections correlated with stronger auroral activity. At Nuremberg in 1733, he published a collection of 316 observations of the aurora borealis made by himself and others over the period 1716–1732.\n\nCelsius traveled frequently in the early 1730s, including to Germany, Italy and France, when he visited most of the major European observatories. In Paris he advocated the measurement of an arc of the meridian in Lapland. In 1736, he participated in the expedition organized for that purpose by the French Academy of Sciences, led by the French mathematician Pierre Louis Maupertuis (1698–1759) to measure a degree of latitude. The aim of the expedition was to measure the length of a degree along a meridian, close to the pole, and compare the result with a similar expedition to Peru, today in Ecuador, near the equator. The expeditions confirmed Isaac Newton's belief that the shape of the earth is an ellipsoid flattened at the poles. \n\nIn 1738, he published the (\"Observations on Determining the Shape of the Earth\"). Celsius' participation in the Lapland expedition won him much respect in Sweden with the government and his peers, and played a key role in generating interest from the Swedish authorities in donating the resources required to construct a new modern observatory in Uppsala. He was successful in the request, and Celsius founded the Uppsala Astronomical Observatory in 1741. The observatory was equipped with instruments purchased during his long voyage abroad, comprising the most modern instrumental technology of the period.\n\nIn astronomy, Celsius began a series of observations using colored glass plates to record the magnitude (a measure of brightness) of certain stars. This was the first attempt to measure the intensity of starlight with a tool other than the human eye. He made observations of eclipses and various astronomical objects and published catalogues of carefully determined magnitudes for some 300 stars using his own photometric system (mean error=0.4 mag).\n\nCelsius was the first to perform and publish careful experiments aiming at the definition of an international temperature scale on scientific grounds. In his Swedish paper \"Observations of two persistent degrees on a thermometer\" he reports on experiments to check that the freezing point is independent of latitude (and of atmospheric pressure). He determined the dependence of the boiling of water with atmospheric pressure which was accurate even by modern-day standards. He further gave a rule for the determination of the boiling point if the barometric pressure deviates from a certain standard pressure. He proposed the Celsius temperature scale in a paper to the Royal Society of Sciences in Uppsala, the oldest Swedish scientific society, founded in 1710. His thermometer was calibrated with a value of 100° for the freezing point of water and 0° for the boiling point. In 1745, a year after Celsius' death, the scale was reversed by Carl Linnaeus to facilitate more practical measurement. Celsius originally called his scale centigrade derived from the Latin for \"hundred steps\". For years it was simply referred to as the Swedish thermometer.\n\nCelsius conducted many geographical measurements for the Swedish General map, and was one of earliest to note that much of Scandinavia is slowly rising above sea level, a continuous process which has been occurring since the melting of the ice from the latest ice age. However, he wrongly posed the notion that the water was evaporating.\n\nIn 1725 he became secretary of the Royal Society of Sciences in Uppsala, and served at this post until his death from tuberculosis in 1744. He supported the formation of the Royal Swedish Academy of Sciences in Stockholm in 1739 by Linnaeus and five others, and was elected a member at the first meeting of this academy. It was in fact Celsius who proposed the new academy's name.\n\n\n", "id": "2722", "title": "Anders Celsius"}
{"url": "https://en.wikipedia.org/wiki?curid=2723", "text": "Adam Carolla\n\nAdam Carolla (born May 27, 1964) is an American comedian, radio personality, television host, actor, podcaster, author and director. He hosts \"The Adam Carolla Show\", a talk show distributed as a podcast which set the record as the \"most downloaded podcast\" as judged by Guinness World Records in 2011.\n\nCarolla co-hosted the syndicated radio call-in program \"Loveline\" from 1995 to 2005 as well as the show's television incarnation on MTV from 1996 to 2000. He was the co-host and co-creator of the television program \"The Man Show\" (1999–2004), and the co-creator and a regular performer on the television show \"Crank Yankers\" (2002–2007). He hosted \"The Adam Carolla Project\", a home improvement television program which aired on TLC in 2005 and \"The Car Show\" on Speed TV in 2011.\n\nCarolla has also appeared on the network reality television programs \"Dancing with the Stars\" and \"The Celebrity Apprentice\". His book \"In Fifty Years We'll All Be Chicks\" debuted on \"The New York Times\" Best Seller list in 2010, and his second book, \"Not Taco Bell Material\", also reached \"New York Times\" bestseller status.\n\nAn outspoken commentator on various social, political, and religious issues, Carolla has made numerous guest appearances on political talk shows, ranging from Bill Maher's \"Real Time with Bill Maher\" to Bill O'Reilly's \"The O'Reilly Factor\", on which he headlines the weekly segment \"Rollin' with Carolla\".\n\nAdam Carolla was born in North Hollywood, Los Angeles, California. His father, Jim Carolla, was a psychologist of Italian heritage, and his mother, Kris (born McCall), was of Irish heritage. The two separated when Adam was young. Carolla was not given a middle name by his parents; on his driver's license application he listed his middle name as \"Lakers\" as a joke. The application was processed without notice, and the name still appears as Adam Lakers Carolla to this day. His maternal step-grandfather was screenwriter László Görög, who wrote \"The Mole People\".\n\nAdam was raised in the North Hollywood neighborhood of Los Angeles. He attended Colfax Elementary School, Walter Reed Junior High, and North Hollywood High School. Carolla did not receive his high school diploma until years later as it was held by the school until a library fine was paid. Carolla can be seen paying off the book and receiving his diploma in an episode of his 2005 television show, \"The Adam Carolla Project\".\n\nDuring his earlier years, Carolla played Pop Warner football for seven years; he later suggested that being involved in sports saved him from a chaotic home life. During his senior year at North Hollywood High School, Carolla distinguished himself in football. In December 1981, he was named to the First Team Offensive Line, Central Valley League, one of 8 leagues at the time in the LA City Section of the California Interscholastic Federation.\n\nHe began living on his own at the age of 18. He briefly attended Los Angeles Valley College, a community college, where he was placed on academic probation before dropping out to work in a series of jobs, including carpet cleaner, carpenter, boxing instructor, and traffic school instructor. Although broke, Carolla, his friends, and roommates owned a 1963 Cadillac limousine.\n\nIn the early 1990s, Carolla studied improvisational comedy with The Groundlings and was a member of the ACME Comedy Theatre troupe.\n\nIn 1994, Carolla volunteered his services as a boxing trainer to prepare Jimmy Kimmel for a bout being staged by KROQ-FM's morning radio program \"Kevin and Bean\". Kimmel was a regular on the show as \"Jimmy the Sports Guy\" and he was set to fight another KROQ personality in a boxing exhibition which was being billed as the \"Bleeda in Reseda.\" Carolla parlayed this opportunity into a long-running friendship and business partnership with Kimmel as well as a recurring role on \"Kevin and Bean\" as cranky woodshop teacher, Mr. Birchum.\n\nIn October 1995, after being signed to the William Morris Agency by Mark Itkin, Carolla was offered the job of co-hosting the radio call-in show \"Loveline.\" His co-hosts were the physician Drew Pinsky (\"Dr. Drew\") and Riki Rachtman. Carolla received the offer after Pinsky heard him on \"Kevin and Bean\" (Rachtman left the show the following year.) \"Loveline\" is broadcast on KROQ-FM in Los Angeles and is syndicated nationwide on the Westwood One radio network.\n\nWhile the format of the program was primarily a call-in show where listeners would ask questions about sex and relationships, Carolla would often spend much of the show ranting about various topics, from fart jokes to extended parodies of radio morning shows, including mocking the format's penchant for useless and repetitive weather and traffic reports. In contrast to the reserved, thoughtful Pinsky, Carolla served as the loud, funny side of the show. Carolla's character was described by one reviewer as \"a toned-down version of Howard Stern minus the huge ego\". On September 25, 2001 Carolla and Jimmy Kimmel both had filled in for Howard Stern's head writer Jackie Martling after Martling's departure from the show in March 2001. Carolla had mentioned in various interviews and on his podcast that he was offered the job to replace Jackie Martling, but turned it down primarily due to Stern's show being located in New York as well as his commitment to \"Loveline\".\n\nIn October 2005, Carolla was announced as the host of a new morning radio show on the Infinity Broadcasting network. His new show would replace the popular syndicated Howard Stern Show (which was moving to satellite radio) in twelve of the 27 markets in which Stern had been broadcast including Los Angeles, Las Vegas, San Francisco, San Diego, Phoenix and Portland, Oregon. \"The Adam Carolla Show\" debuted in January 2006.\n\nIn early 2009, actor Gerard Butler sat in and observed Adam Carolla on \"The Adam Carolla Show\" in order to prepare for his role in The Ugly Truth as the cynical and crass talk-radio host Mike Chadway allegedly based on Adam Carolla.\n\nOn February 18, 2009, The Adam Carolla Show was canceled as part of a format switch at KLSX to AMP FM, a new top 40 station. The final show was Friday, February 20, 2009.\n\nCarolla started a daily podcast on February 23, 2009, at his personal website, which would evolve into the ACE Broadcasting Network. The first Adam Carolla podcast was downloaded more than 250,000 times in the initial 24 hours, and by the third podcast, it was the number one podcast on iTunes in both the U.S. and Canada. During the debut week, the Adam Carolla podcast recorded 1.6 million downloads. In the second week it recorded 2.4 million downloads. By the fourth episode of the second week, featuring former Adam Carolla Show sidekick Dave Dameshek, the show was downloaded more than 500,000 times. Adam stated that bandwidth cost more than $9,000 a month as of May 2009.\n\nAt the end of 2009, The Adam Carolla Podcast was selected by iTunes for its end-of-the-year awards as the Best Audio Podcast of 2009. On May 18, 2011, Carolla made the claim on Jimmy Kimmel Live! that The Adam Carolla Show had taken the Guinness World Record for the most downloaded podcast ever from Ricky Gervais after he claims it received 59,574,843 unique downloads from March 2009 to March 16, 2011.\n\nIn a case that has been referred to as patent trolling, patent holding company Personal Audio sued, among others, Adam Carolla, claiming a patent on \"an audio program and message distribution system in which a host system organizes and transmits program segments to client subscriber locations\".\n\nAfter co-hosting (with Dr. Drew) a television version of Loveline on MTV during the late 90s, Carolla began his first original television series with \"The Man Show\", along with partner and close friend Jimmy Kimmel, on Comedy Central from 1999 to 2003. He left \"The Man Show\" at the same time as Kimmel, after having been reportedly offered $50,000 per episode to stay on. Carolla has continued his work with Kimmel as a writer and guest on \"Jimmy Kimmel Live!\". He also appeared on an episode of \"Space Ghost Coast to Coast\" around this time.\n\nCarolla and partner Daniel Kellison are the heads of Jackhole Productions. The two created the television show \"Crank Yankers\" for Comedy Central, which revived the Mr. Birchum character. (The show premiered in 2002 on Comedy Central and returned to MTV2 on February 9, 2007, running again until March 30, 2007. The show screened in Australia on SBS Television and The Comedy Channel between 2003 and 2008.)\n\nFrom August 2005 to November 2005, Carolla hosted the talk show \"Too Late with Adam Carolla\" on Comedy Central.\n\nAlso in 2005, Carolla was featured in a home remodeling program called \"The Adam Carolla Project\" wherein he and a crew of old friends renovated his childhood home. The 13 episodes aired on the cable channel TLC (The Learning Channel) from October through December 2005. The house was then sold for 1.2 million dollars.\n\nIn 2006, Carolla appeared on the special summer series \"Gameshow Marathon\" as a celebrity panelist on the Match Game episode.\n\nOn the February 18, 2008 broadcast of his radio show, Carolla announced that he would be one of the contestants on the next season of \"Dancing with the Stars\". Later in the broadcast, it was revealed to Adam that his partner would be Julianne Hough. He was voted off on the April 8, 2008 episode after his performance of the Paso Doble, after incorporating a demonstration of unicycle riding in his dance routine.\n\nOn June 16, 2008 Carolla was selected to host a pilot of an American version of the popular BBC show \"Top Gear\" for NBC. In December 2008, NBC decided not to pick up the show.\n\nOn February 21, 2009, a day after his Los Angeles-based morning radio show was canceled — as part of a format change at KLSX-FM — CBS ordered a comedy pilot starring the actor/comedian. \"Ace in the Hole\" was to star Carolla as a husband and father who works as a driving instructor. Carolla created and wrote the pilot with Kevin Hench (\"Jimmy Kimmel Live!\"). Carolla stated that Pamela Adlon was to play his wife and Windell Middlebrooks of the Miller High Life commercial fame will play his best friend. During his March 30, 2009, podcast, Carolla briefly described the show as being \"\"All in the Family\", essentially\", with Carolla playing a similar role to that of Archie Bunker. On the July 23, 2009, episode of the Adam Carolla Podcast, Carolla announced that CBS was not picking up the pilot for the 2009 season, \"in any way, shape or form.\"\n\nOn October 22, 2009, it was reported in \"Variety\" that Carolla had struck a deal with NBC to produce a half-hour pilot for a sitcom. The report was later confirmed on January 4, 2010, and was the first comedy pilot ordered by NBC for the season. The untitled project, written by Carolla and Kevin Hench, was a single-camera endeavor that starred Carolla as a contractor and father who attempts to rebuild his life after his wife leaves him. Carolla was set to executive produce the NBC project along with frequent collaborators Kimmel and Hench, as well as his agent James \"Babydoll\" Dixon, Jon Pollack from \"30 Rock\", Gail Berman, Daniel Kellison, and Lloyd Braun. Universal Media Studios, BermanBraun, and Carolla and Jimmy Kimmel's own Jackhole Industries.\n\nOn the February 13, 2010 episode of Carolla's CarCast podcast, he broke the news that The History Channel had picked up \"Top Gear US\", which NBC had decided against in 2008. On the March 26, 2010, episode of CarCast, Carolla said that he would not be co-hosting \"Top Gear US\" because of scheduling conflicts with his NBC sitcom project. In June 2010, Carolla said that his NBC pilot had not been picked up and was now \"dead.\"\n\nPremiering on February 19, 2012, Carolla was also one of the contestants in the 12th season of NBC's \"The Celebrity Apprentice\". He was fired in Week 4, because Mr. Trump perceived that Carolla did not utilize Andretti's car background during a Buick presentation, even though it was clear that Andretti did not like public speaking.\n\nCarolla's \"The Car Show\" debuted on Speed TV July 13, 2011. Appearing Wednesdays at 10 pm Eastern, it featured Carolla as the host, along with Dan Neil, John Salley, and Matt Farah. It had a format similar to Top Gear, mixing car reviews, tests and humor. The show was initially met with largely positive reviews from car enthusiasts and comedy fans. Talk show host and comedian Jay Leno called The Car Show, \"...a lot of fun.\"\nThe Car Show was cancelled after one season, after undergoing format changes due to low ratings, as Carolla mentioned on his podcast January 13, 2012.\n\n\"Catch a Contractor\" is a non-scripted, original series on Spike, hosted by Adam Carolla along with \"no-nonsense contractor\" Skip Bedell and his wife, investigator Alison Bedell. Together they expose crooked contractors and seek retribution for wronged homeowners.\n\nThe show premiered on March 9, 2014, to 1.2 million viewers, the largest audience for a series debut on Spike since \"Coal\" in March 2011. The show was cancelled in 2015. \n\nPremiering on Spike TV on March 14th, 2017, Adam Carolla and Friends Build Stuff Live features Adam building projects live and in studio with some of his Hollywood friends, and tackling viewers' home improvement projects via social media.\n\nCarolla has also done voice acting on cartoons, including Commander Nebula on the Disney animated series \"Buzz Lightyear of Star Command\", Death on \"Family Guy\" (replacing Norm Macdonald) and Spanky Ham on \"Drawn Together\". He was also the voice of a police officer, Wynchell, who was also an éclair, in the Disney film \"Wreck-It Ralph\". In 2008 and 2009, he was the spokesperson for T.G.I. Friday's.\n\nIn 2003, he appeared in \"Windy City Heat\" as himself. In 2006, Carolla finished work on \"The Hammer\", a semi-autobiographical independent film he co-wrote and co-produced, in which he stars opposite Heather Juergensen. The film is based loosely on his own life and is filmed at a gym he helped build with his co-star, Ozzie, played by Oswaldo Castillo, his friend in real life whom he met while building the gym when they both worked in construction. The film made its world premiere at the 2007 Tribeca Film Festival in New York City and shortly thereafter received a positive review in Variety. The film was released on March 21, 2008. The film is rated 80% on Rotten Tomatoes.\n\nAdam made a short appearance in Jeff Balis' \"Still Waiting...\" (a sequel to \"Waiting...\") playing a pick-up artist guru.\n\nAdam helped write an unproduced screenplay for a movie entitled \"Deaf Frat Guy: Showdown at Havasu\".\n\nHe is the voice of Virgil in the independent short film \"Save Virgil\".\n\nIn July 2013, Carolla used crowdfunding for \"Road Hard\"; a film he directed and starred in, about the lives of aging road comics. Adam confirmed through a press conference that the film will co-star David Alan Grier, Illeana Douglas, Diane Farr, and Larry Miller. It had limited theatrical release in the United States. It is interesting to note that several minutes of the credits are devoted to listing the names of those who helped crowdfund the movie.\n\nCarolla also directed the documentary \"\" on the 35 year car racing career of Paul Newman. The documentary showcases Newman's racing life as both a prolific driver and owner.\n\nCarolla and Drew Pinsky co-wrote (with Marshall Fine) the self-help book \"The Dr. Drew and Adam Book: A Survival Guide to Life and Love,\" published in 1998. The book is a compilation of some of the advice the pair compiled while producing Loveline.\n\nIn November 2010, Carolla's \"In Fifty Years We'll All Be Chicks... And Other Complaints from an Angry Middle-Aged White Guy\" was published by Crown Archetype and debuted at number eight on the \"New York Times\" Best Seller list for hardcover non-fiction on November 21, 2010. The book was compiled from rants Carolla had delivered on his radio show and podcast along with some new material and was dictated to and ghost-written by Mike Lynch.\n\nCarolla published a short, illustrated e-book entitled \"Rich Man, Poor Man\" in January 2012. The book details some similarities in the experiences of the very rich and the very poor which are not shared by the middle class. The book was illustrated by Michael Narren.\n\nCarolla's book \"Not Taco Bell Material\" was published by Crown Archetype on June 12, 2012. It climbed the New York Times bestseller list and received widespread praise for its satirical humor and honest, self-deprecating style.\n\nIn \"President Me: The America That's in My Head,\" Carolla presents the comedian's fantasy of the United States with him at the helm. When asked in separate interviews, both before and after the book's release, about whether the \"if-I-were-king\" critique of America was a serious piece, he said it's both: \"Well, there's a lot of jokes in it, but you know, it's like... Well, if you have a fat friend you may make a lot of fat jokes about your fat friend, but he's still fat\".\n\nCarolla's latest book is \"Daddy, Stop Talking!: And Other Things My Kids Want but won't be Getting,\" in which he uses the meme of modern parenting as a general theme for his humorous insights into modern life. Carolla spells out what adults must do if they don’t want to have to support their kids forever. Using his own childhood as a cautionary tale, and touting the pitfalls of the kind of helicopter parenting so pervasive today.\n\nCarolla has occasionally made generalizations about various groups, leading to criticism. For example, in a late-2003 \"Loveline\" episode, Carolla said that Hawaiians are \"dumb,\" \"in-bred,\" \"retarded, \" people who are among the \"dumbest people we have.\" The comments were met with anger in Hawaii and resulted in \"Loveline\"'s cancellation on Hawaiian affiliate KPOI.\n\nOn the April 4, 2010, episode of \"The Adam Carolla Show\", Carolla referred to Filipino boxer Manny Pacquiao as a \"fucking idiot\" and said of the Philippines: \"They got this and sex tours, that's all they have over there. Get your shit together, Philippines.\" A spokesman for President Gloria Macapagal-Arroyo called Carolla an \"ignorant fool.\" Carolla subsequently apologized via Twitter.\n\nIn 2010, Carolla posed for the NOH8 campaign. In August 2011, Carolla released a podcast where he mocked a petition to the producers of \"Sesame Street\" that demanded Bert and Ernie get married on air. He said on air that gay activists should \"[j]ust get married, and please shut up\" and that \"Y.U.C.K.\" would be more memorable acronym than LGBT, and referring to transgender people he asked: \"When did we start giving a shit about these people?\"\n\nThe Gay & Lesbian Alliance Against Defamation characterized the previous remarks by Carolla as offensive, including an assertion that \"all things being equal,\" heterosexual parents make better parents than homosexual parents. Carolla responded: \"I'm sorry my comments were hurtful. I'm a comedian, not a politician.\" GLAAD called the apology \"empty.\"\n\nIn June 2012, Carolla became the target of charges of sexism due to his remarks during an interview published in the \"New York Post\":\n\nDespite his clarifications, Carolla's comments were reported as \"Women Aren't Funny\", resulting in viral criticism from a variety of individuals concerning the perceived innate sexism underlying these statements. Carolla himself criticized the viral reports as overly simplistic and misleading.\n\nOn September 28, 2002, Carolla married Lynette Paradise. Lynette gave birth to their first children, twins Natalia and Santino \"Sonny\" Richard Carolla on June 7, 2006.\nOn \"The Adam Carolla Show\", Adam repeatedly mentioned the birth was originally scheduled for June 6, but that he and Lynette decided to push it back one day as to avoid the symbolic 666 (06–06–06).\n\nCarolla is a part owner of Amalfi, an Italian restaurant in Los Angeles.\n\nCarolla won the 2013 Pro/Celebrity Race as a professional and the 2012 Pro/Celebrity Race at the Toyota Grand Prix of Long Beach as an amateur. The race was run on April 14, 2012 and was broadcast on Speed TV. In 2013, Carolla again competed in the Toyota Grand Prix race, this time he raced as a pro-driver. Carolla finished first in the Pro category in the 2013 race Carolla has previously participated in the race in 2010 and 2003. He finished ninth among 19 racers (fifth among the ten celebrities) in 2010 despite being regarded as a pre-race favorite. He is also a serious automobile collector with over 20 cars. His collection includes several Lamborghinis from the 1960s and early 1970s, including two Miuras (of 764 examples ever produced), one of which he has loaned to the Petersen Automotive Museum in Los Angeles, two 400GT 2+2s (of 247 units produced) and a 1965 350GT (one of 135 built). At least one Ferrari and Aston Martin and several vintage race cars round out the collection.\n\nCarolla conceived the fortified wine cocktail 'Mangria' (a pun on sangria), which later became commercialized with the Napa Valley-based \"Patio Wine Company\" as a partner.\n\nRegarding his religious beliefs, Carolla has stated, \"I am not agnostic. I am atheist. I don't think there is no God; I know there's no God. I know there's no God the same way I know many other laws in our universe. I know there's no God and I know most of the world knows that as well. They just won't admit it because there's another thing they know: they know they're going to die, and it freaks them out. So most people don't have the courage to admit there's no God and they know it. They feel it. They try to suppress it. And if you bring it up they get angry because it freaks them out.\"\n\nRegarding his political views, Carolla has stated, \"I guess I would be Republican, in the sense that I want a secure border, I'm not into the welfare state, I'm not into all those freebie lunch programs. It just kind of demeans people.\" He goes on to state, however, that he is also in favor of typically liberal causes such as the legalization of marijuana and support for as well some progressive causes such as \"...  [being] against semi-automatic and automatic weapons. I'm not an NRA guy by any stretch of the imagination. I'd like alternative energy to be explored and electric cars to be used, but I want them to be powered by nuclear power plants.\" (He is a member of the advisory board of the Marijuana Policy Project.) Elsewhere, he has stated, \"My feeling is this whole country is founded on the principle of 'If you are not hurting anyone, and you're not fucking with someone else's shit, and you are paying your taxes, you should be able to just do what you want to do.' It's the freedom and the independence.\" In an interview with \"Reason TV\", Carolla described his views as libertarian.\n\nCarolla and Pinsky received a Sexual Health In Entertainment (SHINE) Award from The Media Project in 2000 for \"incorporating accurate and honest portrayals of sexuality\" in the talk show category for Loveline.\n\nAsteroid 4535 Adamcarolla is named in his honor.\n\n \n", "id": "2723", "title": "Adam Carolla"}
{"url": "https://en.wikipedia.org/wiki?curid=2724", "text": "Autocorrelation\n\nAutocorrelation, also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations as a function of the time lag between them. The analysis of autocorrelation is a mathematical tool for finding repeating patterns, such as the presence of a periodic signal obscured by noise, or identifying the missing fundamental frequency in a signal implied by its harmonic frequencies. It is often used in signal processing for analyzing functions or series of values, such as time domain signals.\n\nUnit root processes, trend stationary processes, autoregressive processes, and moving average processes are specific forms of processes with autocorrelation.\n\nDifferent fields of study define autocorrelation differently, and not all of these definitions are equivalent. In some fields, the term is used interchangeably with autocovariance.\n\nIn statistics, the autocorrelation of a random process is the correlation between values of the process at different times, as a function of the two times or of the time lag. Let \"X\" be a stochastic process, and \"t\" be any point in time. (\"t\" may be an integer for a discrete-time process or a real number for a continuous-time process.) Then \"X\" is the value (or realization) produced by a given run of the process at time \"t\". Suppose that the process has mean \"μ\" and variance \"σ\" at time \"t\", for each \"t\". Then the definition of the autocorrelation between times \"s\" and \"t\" is\n\nwhere \"E\" is the expected value operator. Note that this expression is not well-defined for all-time series or processes, because the mean may not exist, or the variance may be zero (for a constant process) or infinite (for processes with distribution lacking well-behaved moments, such as certain types of power law). If the function \"R\" is well-defined, its value must lie in the range [−1, 1], with 1 indicating perfect correlation and −1 indicating perfect anti-correlation. \n\nIf \"X\" is a wide-sense stationary process then the mean \"μ\" and the variance \"σ\" are time-independent, and further the autocorrelation depends only on the lag between \"t\" and \"s\": the correlation depends only on the time-distance between the pair of values but not on their position in time. This further implies that the autocorrelation can be expressed as a function of the time-lag, and that this would be an even function of the lag \"τ\" = \"s\" − \"t\". This gives the more familiar form\n\nand the fact that this is an even function can be stated as\n\nIt is common practice in some disciplines, other than statistics and time series analysis, to drop the normalization by \"σ\" and use the term \"autocorrelation\" interchangeably with \"autocovariance\". However, the normalization is important both because the interpretation of the autocorrelation as a correlation provides a scale-free measure of the strength of statistical dependence, and because the normalization has an effect on the statistical properties of the estimated autocorrelations.\n\nIn signal processing, the above definition is often used without the normalization, that is, without subtracting the mean and dividing by the variance. When the autocorrelation function is normalized by mean and variance, it is sometimes referred to as the autocorrelation coefficient or autocovariance function.\n\nGiven a signal formula_4, the continuous autocorrelation formula_5 is most often defined as the continuous cross-correlation integral of formula_4 with itself, at lag formula_7.\n\nwhere formula_9 represents the complex conjugate, formula_10 is a function which manipulates the function formula_11 and is defined as formula_12 and formula_13 represents convolution.\n\nFor a real function, formula_14.\n\nNote that the parameter formula_15 in the integral is a dummy variable and is only necessary to calculate the integral. It has no specific meaning.\n\nThe discrete autocorrelation formula_16 at lag formula_17 for a discrete signal formula_18 is\n\nThe above definitions work for signals that are square integrable, or square summable, that is, of finite energy. Signals that \"last forever\" are treated instead as random processes, in which case different definitions are needed, based on expected values. For wide-sense-stationary random processes, the autocorrelations are defined as\n\nFor processes that are not stationary, these will also be functions of formula_22, or formula_23.\n\nFor processes that are also ergodic, the expectation can be replaced by the limit of a time average. The autocorrelation of an ergodic process is sometimes defined as or equated to\n\nThese definitions have the advantage that they give sensible well-defined single-parameter results for periodic functions, even when those functions are not the output of stationary ergodic processes.\n\nAlternatively, signals that \"last forever\" can be treated by a short-time autocorrelation function analysis, using finite time integrals. (See short-time Fourier transform for a related process.)\n\nMulti-dimensional autocorrelation is defined similarly. For example, in three dimensions the autocorrelation of a square-summable discrete signal would be\n\nWhen mean values are subtracted from signals before computing an autocorrelation function, the resulting function is usually called an auto-covariance function.\n\nIn the following, we will describe properties of one-dimensional autocorrelations only, since most properties are easily transferred from the one-dimensional case to the multi-dimensional cases.\n\n\n\n\nFor data expressed as a discrete sequence, it is frequently necessary to compute the autocorrelation with high computational efficiency. A brute force method based on the signal processing definition formula_41 can be used when the signal size is small. For example, to calculate the autocorrelation of the real signal sequence formula_42 (i.e. formula_43, and formula_44 for all other values of ) by hand, we first recognize that the definition just given is same as the \"usual\" multiplication, but with right shifts, where each vertical addition gives the autocorrelation for particular lag values:\n\nThus the required autocorrelation sequence is formula_46, where formula_47 formula_48 and formula_49 the autocorrelation for other lag values being zero. In this calculation we do not perform the carry-over operation during addition as is usual in normal multiplication. Note that we can halve the number of operations required by exploiting the inherent symmetry of the autocorrelation. If the signal happens to be periodic, i.e. formula_50 then we get a circular autocorrelation (similar to circular convolution) where the left and right tails of the previous autocorrelation sequence will overlap and give formula_51 which has the same period as the signal sequence formula_52 The procedure can be regarded as an application of the convolution property of z-transform of a discrete signal.\n\nWhile the brute force algorithm is order , several efficient algorithms exist which can compute the autocorrelation in order . For example, the Wiener–Khinchin theorem allows computing the autocorrelation from the raw data with two Fast Fourier transforms (FFT):\n\nwhere IFFT denotes the inverse Fast Fourier transform. The asterisk denotes complex conjugate.\n\nAlternatively, a multiple correlation can be performed by using brute force calculation for low values, and then progressively binning the data with a logarithmic density to compute higher values, resulting in the same efficiency, but with lower memory requirements.\n\nFor a discrete process with known mean and variance for which we observe formula_23 observations formula_55, an estimate of the autocorrelation may be obtained as\n\nfor any positive integer formula_57. When the true mean formula_58 and variance formula_59 are known, this estimate is unbiased. If the true mean and variance of the process are not known there are a several possibilities:\nThe advantage of estimates of the last type is that the set of estimated autocorrelations, as a function of formula_66, then form a function which is a valid autocorrelation in the sense that it is possible to define a theoretical process having exactly that autocorrelation. Other estimates can suffer from the problem that, if they are used to calculate the variance of a linear combination of the formula_67's, the variance calculated may turn out to be negative. \n\nIn regression analysis using time series data, autocorrelation in a variable of interest is typically modeled either with an autoregressive model (AR), a moving average model (MA), their combination as an autoregressive moving average model (ARMA), or an extension of the latter called an autoregressive integrated moving average model (ARIMA). With multiple interrelated data series, vector autoregression (VAR) or its extensions are used.\n\nIn ordinary least squares (OLS), the adequacy of a model specification can be checked in part by establishing whether there is autocorrelation of the regression residuals. \nProblematic autocorrelation of the errors, which themselves are unobserved, can generally be detected because it produces autocorrelation in the observable residuals. (Errors are also known as \"error terms\" in econometrics.) Autocorrelation of the errors violates the ordinary least squares assumption that the error terms are uncorrelated, meaning that the Gauss Markov theorem does not apply, and that OLS estimators are no longer the Best Linear Unbiased Estimators (BLUE). While it does not bias the OLS coefficient estimates, the standard errors tend to be underestimated (and the t-scores overestimated) when the autocorrelations of the errors at low lags are positive.\n\nThe traditional test for the presence of first-order autocorrelation is the Durbin–Watson statistic or, if the explanatory variables include a lagged dependent variable, Durbin's h statistic. The Durbin-Watson can be linearly mapped however to the Pearson correlation between values and their lags. A more flexible test, covering autocorrelation of higher orders and applicable whether or not the regressors include lags of the dependent variable, is the Breusch–Godfrey test. This involves an auxiliary regression, wherein the residuals obtained from estimating the model of interest are regressed on (a) the original regressors and (b) \"k\" lags of the residuals, where \"k\" is the order of the test. The simplest version of the test statistic from this\nauxiliary regression is \"TR\", where \"T\" is the sample size and \"R\" is the coefficient of determination. Under the null hypothesis of no autocorrelation, this statistic is\nasymptotically distributed as formula_68 with \"k\" degrees of freedom.\n\nResponses to nonzero autocorrelation include generalized least squares and the Newey–West HAC estimator (Heteroskedasticity and Autocorrelation Consistent).\n\nIn the estimation of a moving average model (MA), the autocorrelation function is used to determine the appropriate number of lagged error terms to be included. This is based on the fact that for an MA process of order \"q\", we have formula_69, for formula_70, and formula_71, for formula_72.\n\n\n\nSerial dependence is closely linked to the notion of autocorrelation, but represents a distinct concept (see Correlation and dependence). In particular, it is possible to have serial dependence but no (linear) correlation. In some fields however, the two terms are used as synonyms.\n\nA time series of a random variable has serial dependence if the value at some time \"t\" in the series is statistically dependent on the value at another time \"s\". A series is serially independent if there is no dependence between any pair.\n\nIf a time series {\"X\"} is stationary, then statistical dependence between the pair (\"X , X\") would imply that there is statistical dependence between all pairs of values at the same lag \"s\"−\"t\".\n\n\n\n", "id": "2724", "title": "Autocorrelation"}
{"url": "https://en.wikipedia.org/wiki?curid=2726", "text": "Atlas Autocode\n\nAtlas Autocode (AA) was a programming language developed around 1965 at Manchester University. A variant of the ALGOL programming language, it was developed by Tony Brooker and Derrick Morris for the Atlas Computer. \n\n(\"Autocode\" was basically an early term for \"programming language\"; different autocodes could be totally different).\n\nIt removed some Algol features such as \"passing parameters by name\" (which in Algol 60 means passing the address of a short subroutine to recalculate the parameter each time it was mentioned). \n\nIt featured explicitly typed variables, subroutines, and functions. \n\nThe AA compiler generated range-checking for array accesses, and allowed an array to have dimensions that were determined at run-time (i.e. you could declare an array as codice_1, where codice_2 and codice_3 were calculated values).\n\nMachine code could be included within the high-level AA routines either to make an inner loop more efficient or to effect some operation which could not easily be done otherwise.\n\nAtlas Autocode included a codice_4 data type to represent complex numbers, partly because of pressure from the electrical engineering department, as complex numbers are used to represent the behavior of alternating current. The square root of -1 was represented by codice_2, which was treated as a fixed complex constant = \"i\".\n\nThe codice_4 data type was dropped when Atlas Autocode later evolved into the Edinburgh IMP programming language. (Imp was an extension of AA and was used to write the EMAS operating system.)\n\nAtlas Autocode's second-greatest claim to fame (after being the progenitor of Imp and EMAS) was that it had many of the features of the original \"Compiler Compiler\". A variant of the AA compiler included run-time support for a top-down recursive descent parser. The style of parser used in the Compiler Compiler was in use continuously at Edinburgh from the 60's until almost the turn of the millennium.\n\nOther Autocodes were developed for the Titan computer, a prototype Atlas 2 at Cambridge, and the Ferranti Mercury.\n\nAtlas Autocode's syntax was largely similar to Algol, though it was influenced by the output device which the author had available, a Friden Flexowriter. Consequently, it allowed symbols like \"½\" for \".5\" and the superscript for \"to the power of 2\". The Flexowriter supported overstriking and therefore AA did as well — up to three characters could be overstruck as a single symbol. For example, the character set had no \"↑\" symbol, so exponentiation was an overstrike of \"|\" and \"*\". The aforementioned underlining of keywords could also be done using overstriking. The language is described in detail in the Atlas Autocode Reference Manual.\n\nOther Flexowriter characters that were found a use in Atlas Autocode were: codice_7 in floating-point numbers, \"e.g.\", codice_8 for modern codice_9 ; codice_10 to mean \"the second half of a 48-bit Atlas memory word\"; codice_11 for the mathematical constant pi.\n\nWhen AA was ported to the English Electric KDF9 computer, the character set was changed to ISO and that compiler has been recovered from an old paper tape by the Edinburgh Computer History Project and is available online, as is a high-quality scan of the original Edinburgh version of the Atlas Autocode manual.\n\nKeywords in AA were distinguishable from other text by being underlined, which was implemented via overstrike in the Flexowriter (compare to bold in Algol). There were also two stropping regimes. First, there was an \"uppercasedelimiters\" mode where all uppercase letters (outside strings) were treated as underlined lowercase. Second, in some versions (but not in the original Atlas version), it was possible to strop keywords by placing a \"codice_12\" sign in front of them, for example the keyword codice_13 could be typed as codice_14 or codice_15. This significantly reduced typing, due to only needing one character, rather than overstriking the whole keyword. As in Algol, there were no reserved words in the language as keywords were identified by underlining (or stropping), not by recognising reserved character sequences. In the statement codice_16, there is both a keyword codice_17 and a variable named codice_17.\n\nAs in Algol, AA allowed spaces in variable names, such as codice_19. Spaces were not significant and were removed prior to parsing in a trivial pre-lexing stage called \"line reconstruction\". What the compiler would see in the above example would be \"codice_20\". Spaces were possible due partly to keywords being distinguished in other ways, and partly because the source was processed by a scannerless parser, without a separate lexing phase, which allowed the lexical syntax to be context-sensitive.\n\nThe syntax for expressions let the multiplication operator be omitted, e.g. codice_21 was treated as codice_22, and codice_23 was treated as codice_24 if codice_25 was not an array. In ambiguous usages, the longest possible name was taken (maximal munch), for example codice_26 was not treated as codice_27, whether or not codice_25 and codice_29 had been declared.\n\nIn the original Atlas Autocode for the Atlas computer, Atlas machine code instructions could be interpolated between the Atlas Autocode statements.\n\n", "id": "2726", "title": "Atlas Autocode"}
{"url": "https://en.wikipedia.org/wiki?curid=2729", "text": "Arthur J. Stone\n\nArthur J. Stone (1847–1938), a leading American silversmith, was born, trained and worked in Sheffield, England, and Edinburgh, Scotland, before travelling to the United States in 1884. He was one of the last silversmiths in America to train apprentices to carry out designs in hand-wrought silver. In 1901, Stone set up a workshop in Gardner, Massachusetts which operated under his name until its sale in 1937 to Henry Heywood. Heywood was a Gardner businessman, who renamed it The Stone Silver Shop, and later, Stone Associates. Heywood died in 1945. His sons Henry, Jr. and Jerome ran Stone Associates until 1957.\n\nOne of the silversmiths in Arthur Stone's shop was George Porter Blanchard, father of silversmith Porter Blanchard.\n\n\n", "id": "2729", "title": "Arthur J. Stone"}
{"url": "https://en.wikipedia.org/wiki?curid=2732", "text": "Au file format\n\nThe Au file format is a simple audio file format introduced by Sun Microsystems. The format was common on NeXT systems and on early Web pages. Originally it was headerless, being simply 8-bit µ-law-encoded data at an 8000 Hz sample rate. Hardware from other vendors often used sample rates as high as 8192 Hz, often integer factors of video clock signals. Newer files have a header that consists of six unsigned 32-bit words, an optional information chunk and then the data (in big endian format).\n\nAlthough the format now supports many audio encoding formats, it remains associated with the µ-law logarithmic encoding. This encoding was native to the SPARCstation 1 hardware, where SunOS exposed the encoding to application programs through the /dev/audio interface. This encoding and interface became a de facto standard for Unix sound.\n\nAll fields are stored in big-endian format, including the sample data.\n\nThe type of encoding depends on the value of the \"encoding\" field (word 3 of the header). Formats 2 through 7 are uncompressed linear PCM, therefore technically lossless (although not necessarily free of quantisation error, especially in 8-bit form). Formats 1 and 27 are μ-law and A-law, respectively, both companding logarithmic representations of PCM, and arguably lossy as they pack what would otherwise be almost 16 bits of dynamic range into 8 bits of encoded data, even though this is achieved by an altered dynamic response and no data is actually \"thrown away\". Formats 23 through 26 are ADPCM, which is an early form of lossy compression, usually but not always with 4 bits of encoded data per audio sample (for 4:1 efficiency with 16-bit input, or 2:1 with 8-bit; equivalent to e.g. encoding CD quality MP3 at a 352kbit rate using a low quality encoder). Several of the others are DSP commands or data, designed to be processed by the NeXT Music Kit software.\n\nNote: PCM formats are encoded as signed data (as opposed to unsigned).\n\nFollowing the header structure is a variable-length annotation field. The contents of this field are currently undefined, except that its length must be a multiple of eight bytes and it must be terminated with at least one null (zero) byte. The audio data segment begins on an eight-byte boundary immediately following the annotation field. Audio data is encoded in the format identified by the file header. The current implementation supports only a single audio data segment per file. The variable-length annotation field is currently ignored by most audio applications.\n\n", "id": "2732", "title": "Au file format"}
{"url": "https://en.wikipedia.org/wiki?curid=2733", "text": "April 25\n\n\n\n", "id": "2733", "title": "April 25"}
{"url": "https://en.wikipedia.org/wiki?curid=2734", "text": "April 24\n\n\n\n", "id": "2734", "title": "April 24"}
{"url": "https://en.wikipedia.org/wiki?curid=2735", "text": "April 7\n\n\n\n\n\n", "id": "2735", "title": "April 7"}
{"url": "https://en.wikipedia.org/wiki?curid=2736", "text": "Andalusia\n\nAndalusia (Andalucia) (; ) is an autonomous community in southern Spain. It is the most populated and the second largest in area of the autonomous communities in the country. The Andalusian autonomous community is officially recognised as \"historical nationality\". The territory is divided into eight provinces: Almería, Cádiz, Córdoba, Granada, Huelva, Jaén, Málaga and Seville. Its capital is the city of Seville (Spanish: \"Sevilla\").\n\nAndalusia is in the south of the Iberian peninsula, in south-western Europe, immediately south of the autonomous communities of Extremadura and Castilla-La Mancha; west of the autonomous community of Murcia and the Mediterranean Sea; east of Portugal and the Atlantic Ocean; and north of the Mediterranean Sea and the Strait of Gibraltar. Andalusia is the only European region with both Mediterranean and Atlantic coastlines. The small British overseas territory of Gibraltar shares a three-quarter-mile land border with the Andalusian province of Cádiz at the eastern end of the Strait of Gibraltar.\n\nThe main mountain ranges of Andalusia are the Sierra Morena and the Baetic System, consisting of the Subbaetic and Penibaetic Mountains, separated by the Intrabaetic Basin. In the north, the Sierra Morena separates Andalusia from the plains of Extremadura and Castile–La Mancha on Spain's Meseta Central. To the south the geographic subregion of Upper Andalusia lies mostly within the Baetic System, while Lower Andalusia is in the Baetic Depression of the valley of the Guadalquivir.\n\nThe name \"Andalusia\" is derived from the Arabic word \"Al-Andalus\" (الأندلس). As well as Romani influences, the region's history and culture have been influenced by the earlier Iberians, Phoenicians, Carthaginians, Greeks, Romans, Vandals, Visigoths, Byzantines, Muslim Moors and as well as the later Castilian and other Christian North Iberian nationalities who conquered and settled the area in the latter phases of the \"Reconquista\". Including an intense relationship with Naples, Italy.\n\nAndalusia has been a traditionally agricultural region, compared to the rest of Spain and the rest of Europe. However, the growth of the community especially in the sectors of industry and services was above average in Spain and higher than many communities in the Eurozone. The region has, however, a rich culture and a strong cultural identity. Many cultural phenomena that are seen internationally as distinctively Spanish are largely or entirely Andalusian in origin. These include flamenco and, to a lesser extent, bullfighting and Hispano-Moorish architectural styles.\n\nAndalusia's hinterland is the hottest area of Europe, with cities like Córdoba and Seville averaging above 36 °C (97 °F) in summer high temperatures. Late evening temperatures can sometimes stay around 35 °C (95 °F) until close to midnight, with daytime highs of over 40 °C (104 °F) common. Seville also has the highest average annual temperature in mainland Spain and mainland Europe (19.2 °C), closely followed by Almería (19.1 °C).\n\nIts present form is certainly derived from the Arabic name for Muslim Iberia, \"Al-Andalus\". However, the etymology of the name \"Al-Andalus\" is disputed, and the extent of Iberian territory encompassed by the name has changed over the centuries.\n\nThe Spanish place name \"Andalucía\" (immediate source of the English \"Andalusia\") was introduced into the Spanish languages in the 13th century under the form \"el Andalucía\". The name was adopted to refer to those territories still under Moorish rule, and generally south of Castilla Nueva and Valencia, and corresponding with the former Roman province hitherto called Baetica in Latin sources. This was a Castilianization of \"Al-Andalusiya\", the adjectival form of the Arabic language \"al-Andalus\", the name given by the Arabs to all of the Iberian territories under Muslim rule from 711 to 1492. The etymology of \"al-Andalus\" is itself somewhat debated (see al-Andalus), but in fact it entered the Arabic language before this area came under Muslim rule.\n\nLike the Arabic term \"al-Andalus\", in historical contexts the Spanish term \"Andalucía\" or the English term \"Andalusia\" do not necessarily refer to the exact territory designated by these terms today. Initially, the term referred exclusively to territories under Muslim control; later, it was applied to some of the last Iberian territories to be regained from the Muslims, though not always to exactly the same ones. In the \"Estoria de España\" (also known as the \"Primera Crónica General\") of Alfonso X of Castile, written in the second half of the 13th century, the term \"Andalucía\" is used with three different meanings:\n\n\nFrom an administrative point of view, Granada remained separate for many years even after the completion of the \"Reconquista\" due, above all, to its emblematic character as the last territory regained, and as the seat of the important Real Chancillería de Granada, a court of last resort. Still, the reconquest and repopulation of Granada was accomplished largely by people from the three preexisting Christian kingdoms of Andalusia, and Granada came to be considered a fourth kingdom of Andalusia. The often-used expression \"Four Kingdoms of Andalusia\" dates back in Spanish at least to the mid-18th century.\n\nThe Andalusian coat of arms shows the figure of Hercules and two lions between the two pillars of Hercules that tradition situates on either side of the Strait of Gibraltar. An inscription below, superimposed on an image of the flag of Andalusia reads \"Andalucía por sí, para España y la Humanidad\" (\"Andalusia by herself, for Spain and Humanity\"). Over the two columns is a semicircular arch in the colors of the flag of Andalusia, with the Latin words \"Dominator Hercules Fundator\" superimposed.\n\nThe official flag of Andalusia consists of three equal horizontal stripes, colored green, white, and green respectively; the Andalusian coat of arms is superimposed on the central stripe. Its design was overseen by Blas Infante and approved in the Assembly of Ronda (a 1918 gathering of Andalusian nationalists at Ronda). The green symbolizes hope and union, and the white symbolizes peace and dialogue. Blas Infante considered these to have been the colors most used in regional symbols throughout the region's history. According to him, the green came in particular from the standard of the Umayyad Caliphate and represented the call for a gathering of the populace. The white symbolized pardon in the Almohad dynasty, interpreted in European heraldry as parliament or peace. Other writers have justified the colors differently, with some Andalusian nationalists referring to them as the \"Arbonaida\", meaning white-and-green in Mozarabic, a Romance language that was spoken in the region in Muslim times.\nThe anthem of Andalusia was composed by José del Castillo Díaz (director of the Municipal Band of Seville, commonly known as Maestro Castillo) with lyrics by Blas Infante. The music was inspired by \"Santo Dios\", a popular religious song sung at harvest time by peasants and day laborers in the provinces of Málaga, Seville, and Huelva. Blas Infante brought the song to Maestro Castillo's attention; Maestro Castillo adapted and harmonized the traditional melody. The lyrics appeal to the Andalusians to mobilize and demand \"tierra y libertad\" (\"land and liberty\") by way of agrarian reform and a statute of autonomy within Spain.\n\nThe Parliament of Andalusia voted unanimously in 1983 that the preamble to the Statute of Autonomy recognize Blas Infante as the Father of the Andalusian Nation (\"Padre de la Patria Andaluza\"), which was reaffirmed in the reformed Statute of Autonomy submitted to popular referendum 18 February 2007. The preamble of the present 2007 Statute of Autonomy says that Article 2 of the present Spanish Constitution of 1978 recognizes Andalusia as a nationality. Later, in its articulation, it speaks of Andalusia as a \"historic nationality\" (Spanish: \"nacionalidad histórica\"). It also cites the 1919 Andalusianist Manifesto of Córdoba describing Andalusia as a \"national reality\" (\"realidad nacional\"), but does not endorse that formulation. Article 1 of the earlier 1981 Statute of Autonomy defined it simply as a \"nationality\" (\"nacionalidad\").\n\nThe national holiday, the Día de Andalucía, is celebrated on 28 February, commemorating the 1980 autonomy referendum. In spite of this, nationalist groups celebrate the holiday on 4 December, commemorating the 1977 demonstrations to demand autonomy.\n\nThe honorific title of \"Hijo Predilecto de Andalucía\" (\"Favorite Son of Andalucia\") is granted by the Regional Government of Andalusia to those whose exceptional merits benefited Andalusia, for work or achievements in natural, social, or political science. It is the highest distinction given by the Autonomous Community of Andalusia.\n\nThe Sevillian historian Antonio Domínguez Ortiz wrote that:\n\nAndalusia has a surface area of , 17.3 percent of the territory of Spain. Andalusia alone is comparable in extent and in the variety of its terrain to any of several of the smaller European countries. To the east is the Mediterranean Sea; to the west the Atlantic Ocean; to the north the Sierra Morena constitutes the border with the Meseta Central; to the south, the self-governing British overseas territory of Gibraltar and the Strait of Gibraltar separate it from Morocco.\n\nAndalusia is home to the hottest and driest summers in Spain, but in the west, weather systems sweeping in from the Atlantic ensure that it is relatively wet in the winter, with some areas receiving copious amounts. Contrary to what many people think, as a whole, the region enjoys above average yearly rainfall in the context of Spain.\n\nAndalusia sits at a latitude between 36° and 38° 44' N, in the warm-temperate region. In general, it experiences a hot-summer Mediterranean climate, with dry summers influenced by the Azores High, but subject to occasional torrential rains and extremely hot temperatures. In the winter, the tropical anticyclones move south, allowing cold polar fronts to penetrate the region. Still, within Andalusia there is considerable climatic variety. From the extensive coastal plains one may pass to the valley of the Guadalquivir, barely above sea level, then to the highest altitudes in the Iberian peninsula in the peaks of the Sierra Nevada. In a mere one can pass from the subtropical coast of the province of Granada to the snowy peaks of Mulhacén. Andalusia also includes both the dry Tabernas Desert in the province of Almería and the Sierra de Grazalema Natural Park in the province of Cádiz, which experiences Spain's greatest rainfall.\n\nAnnual rainfall in the Sierra de Grazalema has been measured as high as in 1963, the highest ever recorded for any location in Iberia. Andalusia is also home to the driest place in continental Europe, the Cabo de Gata, with only of rain per year.\n\nIn general, as one goes from west to east, away from the Atlantic, there is less precipitation. \"Wet Andalusia\" includes most of the highest points in the region, above all the Sierra de Grazalema but also the Serranía de Ronda in western Málaga. The valley of the Guadalquivir has moderate rainfall. The Tabernas Desert in Almería, Europe's only true desert, has less than 75 days with any measurable precipitation, and some particular places in the desert have as few as 50 such days. Much of \"dry Andalusia\" has more than 300 \"sunny\" days a year.\n\nThe average temperature in Andalusia throughout the year is over . Averages in the cities range from in Baeza to in Almería. Much of the Guadalquivir valley and the Mediterranean coast has an average of about . The coldest month is January when Granada at the foot of the Sierra Nevada experiences an average temperature of . The hottest are July and August, with an average temperature of for Andalusia as a whole. Córdoba is the hottest provincial capital, followed by Seville.\n\nThe Guadalquivir valley has experienced the highest temperatures recorded in Europe, with a maximum of recorded at Córdoba and Seville. The mountains of Granada and Jaén have the coldest temperatures in southern Iberia, but do not reach continental extremes (and, indeed are surpassed by some mountains in northern Spain). In the cold snap of January 2005, Santiago de la Espada (Jaén) experienced a temperature of and the ski resort at Sierra Nevada National Park—the southernmost ski resort in Europe—dropped to . Sierra Nevada Natural Park has Iberia's lowest average annual temperature, ( at Pradollano) and its peaks remain snowy practically year-round.\n\nMountain ranges affect climate, the network of rivers, soils and their erosion, bioregions, and even human economies insofar as they rely on natural resources. The Andalusian terrain offers a range of altitudes and slopes. Andalusia has the Iberian peninsula's highest mountains and nearly 15 percent of its terrain over . The picture is similar for areas under (with the Baetic Depression), and for the variety of slopes.\n\nThe Atlantic coast is overwhelmingly beach and gradually sloping coasts; the Mediterranean coast has many cliffs, above all in the Malagan Axarquía and in Granada and Almería. This asymmetry divides the region naturally into Upper Andalusia (two mountainous areas) and Lower Andalusia (the broad basin of the Guadalquivir).\n\nThe Sierra Morena separates Andalusia from the plains of Extremadura and Castile–La Mancha on Spain's Meseta Central. Although sparsely populated, this is not a particularly high range, and its highest point, the peak of La Bañuela in the Sierra Madrona, lies outside of Andalusia. Within the Sierra Morena, the gorge of Despeñaperros forms a natural frontier between Castile and Andalusia.\n\nThe Baetic Cordillera consists of the parallel mountain ranges of the Cordillera Penibética near the Mediterranean coast and the Cordillera Subbética inland, separated by the Surco Intrabético. The Cordillera Subbética is quite discontinuous, offering many passes that facilitate transportation, but the Penibético forms a strong barrier between the Mediterranean coast and the interior. The Sierra Nevada, part of the Cordillera Penibética in the Province of Granada, has the highest peaks in Iberia: El Mulhacén at and El Veleta at .\n\nLower Andalusia, the Baetic Depression, the basin of the Guadalquivir, lies between these two mountainous areas. It is a nearly flat territory, open to the Gulf of Cádiz in the southeast. Throughout history, this has been the most populous part of Andalusia.\n\nAndalusia has rivers that flow into both the Atlantic and the Mediterranean. Flowing to the Atlantic are the Guadiana, Odiel-Tinto, Guadalquivir, Guadalete, and Barbate. Flowing to the Mediterranean are the Guadiaro, Guadalhorce, Guadalmedina, Guadalfeo, Andarax (also known as the Almería) and Almanzora. Of these, the Guadalquivir is the longest in Andalusia and fifth longest on the Iberian peninsula, at .\nThe rivers of the Atlantic basin are characteristically long, run through mostly flat terrain, and have broad river valleys. As a result, at their mouths are estuaries and wetlands, such as the marshes of Doñana in the delta of the Guadalquivir, and wetlands of the Odiel. In contrast, the rivers of the Mediterranean Basin are shorter, more seasonal, and make a precipitous descent from the mountains of the Baetic Cordillera. Their estuaries are small, and their valleys are less suitable for agriculture. Also, being in the rain shadow of the Baetic Cordillera means that they receive a lesser volume of water.\n\nThe following hydrographic basins can be distinguished in Andalusia. On the Atlantic side are the Guadalquivir basin; the Andalusian Atlantic Basin with the sub-basins Guadalete-Barbate and Tinto-Odiel; and the Guadiana basin. On the Mediterranean side is the Andalusian Mediterranean Basin and the very upper portion of the basin of the Segura.\n\nThe soils of Andalusia can be divided into three large areas: the Sierra Morena, Cordillera Subbética, and the Baetic Depression and the Surco Intrabético.\n\nThe Sierra Morena, due to its morphology and the acidic content of its rocks, developed principally relatively poor, shallow soils, suitable only for forests. In the valleys and in some areas where limestone is present, deeper soils allowed farming of cereals suitable for livestock. The more complicated morphology of the Baetic Cordillera makes it more heterogeneous, with the most heterogeneous soils in Andalusia. Very roughly, in contrast to the Sierra Morena, a predominance of basic (alkaline) materials in the Cordillera Subbética, combined with a hilly landscape, generates deeper soils with greater agricultural capacity, suitable to the cultivation of olives.\n\nFinally, the Baetic Depression and the Surco Intrabético have deep, rich soils, with great agricultural capacity. In particular, the alluvial soils of the Guadalquivir valley and plain of Granada have a loamy texture and are particularly suitable for intensive irrigated crops. In the hilly areas of the countryside, there is a double dynamic: the depressions have filled with older lime-rich material, developing the deep, rich, dark clay soils the Spanish call \"bujeo\", or \"tierras negras andaluzas\", excellent for dryland farming. In other zones, the whiter \"albariza\" provides an excellent soil for vineyards.\n\nDespite their marginal quality, the poorly consolidated soils of the sandy coastline of Huelva and Almería\nhave been successfully used in recent decades for hothouse cultivation under clear plastic of strawberries, raspberries, blueberries, and other fruits.\n\nBiogeographically, Andalusia forms part of the Western Mediterranean subregion of the Mediterranean Basin, which falls within the Boreal Kingdom. Five floristic provinces lie, in whole or in part, within Andalusia: along much of the Atlantic coast, the Lusitanian-Andalusian littoral or Andalusian Atlantic littoral; in the north, the southern portion of the Luso-Extremaduran floristic province; covering roughly half of the region, the Baetic floristic province; and in the extreme east, the Almerian portion of the Almerian-Murcian floristic province and (coinciding roughly with the upper Segura basin) a small portion of the Castilian-Maestrazgan-Manchegan floristic province. These names derive primarily from past or present political geography: \"Luso\" and \"Lusitanian\" from Lusitania, one of three Roman provinces in Iberia, most of the others from present-day Spanish provinces, and Maestrazgo being a historical region of northern Valencia.\nIn broad terms, the typical vegetation of Andalusia is Mediterranean woodland, characterized by leafy xerophilic perennials, adapted to the long, dry summers. The dominant species of the climax community is the holly oak (\"Quercus ilex\"). Also abundant are cork oak (\"Quercus suber\"), various pines, and Spanish fir (\"Abies pinsapo\"). Due to cultivation, olive (\"Olea europaea\") and almond (\"Prunus dulcis\") trees also abound. The dominant understory is composed of thorny and aromatic woody species, such as rosemary (\"Rosmarinus officinalis\"), thyme (\"Thymus\"), and \"Cistus\". In the wettest areas with acidic soils, the most abundant species are the oak and cork oak, and the cultivated \"Eucalyptus\". In the woodlands, leafy hardwoods of genus \"Populus\" (poplars, aspens, cottonwoods) and \"Ulmus\" (elms) are also abundant; poplars are cultivated in the plains of Granada.\n\nThe Andalusian woodlands have been much altered by human settlement, the use of nearly all of the best land for farming, and frequent wildfires. The degraded forests become shrubby and combustible garrigue. Extensive areas have been planted with non-climax trees such as pines. There is now a clear conservation policy for the remaining forests, which survive almost exclusively in the mountains.\n\nThe biodiversity of Andalusia extends to its fauna as well. More than 400 of the 630 vertebrate species extant in Spain can be found in Andalusia. Spanning the Mediterranean and Atlantic basins, and adjacent to the Strait of Gibraltar, Andalusia is on the migratory route of many of the numerous flocks of birds that travel annually from Europe to Africa and back.\n\nThe Andalusian wetlands host a rich variety of birds. Some are of African origin, such as the red-knobbed coot (\"Fulica cristata\"), the purple swamphen (\"Porphyrio porphyrio\"), and the greater flamingo (\"Phoenicopterus roseus\"). Others originate in Northern Europe, such as the greylag goose (\"Anser anser\"). Birds of prey (raptors) include the Spanish imperial eagle (\"Aquila adalberti\"), the griffon vulture (\"Gyps fulvus\"), and both the black and red kite (\"Milvus migrans\" and \"Milvus milvus\").\nAmong the herbivores, are several deer (Cervidae) species, notably the fallow deer (\"Dama dama\") and roe deer (\"Capreolus capreolus\"); the European mouflon (\"Ovis orientalis musimon\"), a type of sheep; and the Spanish ibex (\"Capra pyrenaica\", which despite its scientific name is no longer found in the Pyrenees). The Spanish ibex has recently been losing ground to the Barbary sheep (\"Ammotragus lervia\"), an invasive species from Africa, introduced for hunting in the 1970s. Among the small herbivores are rabbits—especially the European rabbit (\"Oryctolagus cuniculus\")—which form the most important part of the diet of the carnivorous species of the Mediterranean woodlands.\n\nThe large carnivores such as the Iberian wolf (\"Canis lupus signatus\") and the Iberian lynx (\"Lynx pardinus\") are quite threatened, and are limited to the Sierra de Andújar, inside of Sierra Morena, Doñana and Despeñaperros. Stocks of the wild boar (\"Sus scrofa\"), on the other hand, have been well preserved because they are popular with hunters. More abundant and in varied situations of conservation are such smaller carnivores as otters, dogs, foxes, the European badger (\"Meles meles\"), the European polecat (\"Mustela putorius\"), the least weasel (\"Mustela nivalis\"), the wildcat (\"Felis silvestris\"), the common genet (\"Genetta genetta\"), and the Egyptian mongoose (\"Herpestes ichneumon)\".\n\nOther notable species are \"Acherontia atropos\" (a variety of death's-head hawkmoth), \"Vipera latasti\" (a venomous snake), and the endemic (and endangered) fish \"Aphanius baeticus\".\n\nAndalusia has many unique ecosystems. In order to preserve these areas in a manner compatible with both conservation and economic exploitation, many of the most representative ecosystems have been given protected status.\n\nThe various levels of protection are encompassed within the Network of Protected Natural Spaces of Andalusia (Red de Espacios Naturales Protegidos de Andalucía, RENPA) which integrates all protected natural spaces located in Andalusia, whether they are protected at the level of the local community, the autonomous community of Andalusia, the Spanish state, or by international conventions. RENPA consists of 150 protected spaces, consisting of two national parks, 24 natural parks, 21 periurban parks (on the fringes of cities or towns), 32 natural sites, two protected countrysides, 37 natural monuments, 28 nature reserves, and four concerted nature reserves (in which a government agency coordinates with the owner of the property for its management), all part of the European Union's Natura 2000 network. Under the international ambit are the nine Biosphere Reserves, 20 Ramsar wetland sites, four Specially Protected Areas of Mediterranean Importance and two UNESCO Geoparks.\n\nIn total, nearly 20 percent of the territory of Andalusia lies in one of these protected areas, which constitute roughly 30 percent of the protected territory of Spain. Among these many spaces, some of the most notable are the Sierras de Cazorla, Segura y Las Villas Natural Park, Spain's largest natural park and the second largest in Europe, the Sierra Nevada National Park, Doñana National Park and Natural Park, the Tabernas Desert, and the Cabo de Gata-Níjar Natural Park, the largest terrestrial-maritime reserve in the European Western Mediterranean Sea.\n\nThe geostrategic position of Andalusia in the extreme south of Europe, providing (along with Morocco) a gateway between Europe and Africa, added to its position between the Atlantic Ocean and the Mediterranean Sea, as well as its rich deposits of minerals and its agricultural wealth, have made Andalusia a tempting prize for civilizations since prehistoric times. Add to this its area of (larger than many European countries), and it can be no surprise that Andalusia has figured prominently in the history of Europe and the Mediterranean.\n\nSeveral theories postulate that the first hominids in Europe were in Andalusia, having passed across the Strait of Gibraltar; the earliest known paintings of humanity have been found in the Caves of Nerja, Málaga. The first settlers, based on artifacts from the archaeological sites at Los Millares, El Argar, and Tartessos, were clearly influenced by cultures of the Eastern Mediterranean who arrived on the Andalusian coast. Andalusia then went through a period of protohistory, when the region did not have a written language of its own, but its existence was known to and documented by literate cultures, principally the Phoenicians (Gadir, Malaka) and Ancient Greeks. During the second millennium BCE, the kingdom of Tartessos developed in Andalusia.\n\nWith the fall of the Phoenician cities, Carthage became the dominant sea power of the western Mediterranean and the most important trading partner for the Phoenician towns along the Andalusian coast. Between the First and Second Punic Wars, Carthage extended its control beyond Andalucia to include all of Iberia except the Basque Country. Andalusia was the major staging ground for the war with Rome led by the Hannibal Barca. The Romans defeated the Carthaginians and conquered Andalusia, the region being renamed Baetica. It was fully incorporated into the Roman Empire, and from this region came many Roman magistrates and senators, as well as the emperors Trajan and (most likely) Hadrian.\n\nThe Vandals moved briefly through the region during the 5th century AD before settling in North Africa, after which the region fell into the hands of the Visigothic Kingdom. The Visigoths in this region were practically independent of the Visigothic Catholic Kingdom of Toledo. This is the era of Saints Isidore of Seville and Hermenegild. During this period, around 555 AD, the Eastern Roman Empire conquered Andalusia under Justinian I, the Eastern Roman Emperor. They established Spania, a province of the Byzantine Empire from 552 until 624. Though their holdings were quickly reduced, they continued to have interests in the region until it was lost altogether in 624.\n\nThe Visigothic era came to an abrupt end in 711 with the Umayyad conquest of Hispania by the Umayyad general Tariq ibn Ziyad, an Islamic Berber. Tariq is known in Spanish history and legend as a formidable conqueror who dared and bore the nerve to burn his fleet of ships, when he landed with his troops on the coast of Gibraltar - an acronym of \"Jabel alTariq\" meaning \"the mountain of Tariq\". The —by the Umayyad Caliphate—of the Iberian Peninsula in 711–718 marked the collapse of Visigothic rule. When the Muslim invaders seized control and consolidated their domain of the region, they remained tolerant of the Christian religion, but they also needed a place of cult for their own faith. In the 750s, they forcibly rented half of Cordoba's Christian Cathedral of San Vicente (Visigothic) to use as a mosque. \n\nIn this period, the name \"Al-Andalus\" was applied to a much larger area than the present Andalusia, and in some periods it referred to nearly the entire Iberian peninsula. Islamic rulers of Hispania were economic invaders and interested in collecting taxes, they were not social invaders. Changes were mainly confined to geographical, political and legal conveniences. Al-Andalus remained quite connected to its sister Christian states under Islamic rule, As such trade routes between it and Constantinople and Alexandria remained fluent. Roman/Byzantine ideas and customs flowed on between post Byzantine regions. This Bizantine/Roman architecture is such an example. Now referred to as Moorish, commissioned in the Moorish era.\n\nNevertheless, the Guadalquivir River valley in present-day Andalusia became the hub of Muslim power in the peninsula, with the Caliphate of Córdoba making Córdoba its capital. The Umayyad Caliphate produced such leaders as Caliph Abd-ar-Rahman III (ruled 912–961) and his son, Caliph Al-Hakam II (ruled 961–976); and built the magnificent Great Mosque of Córdoba. Under these rulers, Moorish Islam in Spain reached its zenith, and Córdoba was a center of global economic and cultural significance.\n\nBy the 10th century, the Christians of northern Spain had begun what would eventually become the Reconquista: the reconquest of Spain for Christendom. Caliph Abd-ar-Rahman suffered some minor military defeats, but often managed to manipulate the Christian kingdoms to act against each other's interests. Al-Hakam achieved military successes, but at the expense of uniting the Christian kings of the north against him.\nAfter the conquest of Toledo in 1086 by Alfonso VI, Christian rule dominated the peninsula. The main \"Taifas\" therefore had to resort to assistance from various Muslim powers across the Mediterranean. A number of different Muslim dynasties of North African origin—notably Almoravid dynasty and Almohad dynasty—dominated a slowly diminishing Al-Andalus over the next several centuries.\n\nAfter the Muslim victory at the Battle of Sagrajas (1086) put a temporary stop to Christian expansion, the Almoravid dynasty constructed a unified Al-Andalus with its capital in Granada, ruling until the mid-12th century. The various \"Taifa\" kingdoms were assimilated. the Almohad dynasty expansion in North Africa weakened Al-Andalus, and in 1170 the Almohads transferred their capital from Marrakesh to Seville. The Christian victory at the Battle of Las Navas de Tolosa (1212) marked the beginning of the end of the Almohad dynasty.\n\nThe weakness caused by the collapse of Almohad power and the subsequent creation of new \"Taifas\", each with its own ruler, led to the rapid Christian reconquest of the valley of the Guadalquivir. Córdoba was regained in 1236 and Seville in 1248. The fall of Granada in 1492 put an end to Muslim rule in the Iberian peninsula.\nOn 3 August 1492 Christopher Columbus left the town of Palos de la Frontera, with the first expedition that resulted in the Europeans learning of the existence of America. Many Andalusians participated in the expedition that would end the Middle Ages and signal the beginning of modernity. Contacts between Spain and the Americas, including royal administration and the shipping trade of Spanish colonies for over three hundred years, came almost exclusively through Andalusia. As a result, it became the wealthiest, most influential region in Spain and amongst the most influential in Europe. However, Habsburg ambitions elsewhere in Europe diverted much of the colonial wealth to war. Discontent with this situation culminated in 1641, when the Andalusian nobility staged an unsuccessful conspiracy to gain independence in 1641 from the provincial government of the Gaspar de Guzmán, Count-Duke of Olivares.\n\nIn the first half of the 16th century plague was still prevalent in Spain. According to George C. Kohn, \"One of the worst epidemics of the century, whose miseries were accompanied by severe drought and food shortage, started in 1505; by 1507, about 100,000 people had died in Andalusia alone... Andalusia was struck once again in 1646. For three years, plague haunted the entire region, causing perhaps as many as 200,000 deaths, especially in Málaga and Seville.\"\n\nFollowing the Second Rebellion of the Alpujarras in 1568-1571, the Moorish population—that is, unconverted Moriscos—were expelled from Kingdom of Castile (and Aragon). However, by order of the Spanish crown, two Moorish families were required to remain in each village in order to demonstrate to the new inhabitants, introduced from northern Spain, the workings of the terracing and irrigation systems on which the district's agriculture depends.\n\nIn 1810-12 the people strongly resisted the French occupation during the Peninsular War (part of the Napoleonic Wars).\n\nAndalusia profited from the Spanish overseas empire, although much trade and finance eventually came to be controlled by other parts of Europe to where it was ultimately destined. In the 18th century, commerce from other parts of Spain began to displace Andalusian commerce when the Spanish government ended Andalusia's trading monopoly with the American colonies. The loss of the empire in the 1820s hurt the economy of the region, particularly the cities that had benefited from the trade and ship building. The construction of railways in the latter part of the 19th century enabled Andalusia to better develop its agricultural potential and it became an exporter of food. While industrialisation was taking off in the northern Spanish regions of Catalonia and the Basque country, Andalusia remained traditional and displayed a deep social division between a small class of wealthy landowners and a population made up largely of poor agricultural labourers and tradesmen.\n\nAndalusia is one of the 17 autonomous communities of Spain. The Regional Government of Andalusia (Spanish: \"Junta de Andalucía\") includes the Parliament of Andalusia, its chosen president, a Consultative Council, and other bodies.\n\nThe Autonomous Community of Andalusia was formed in accord with a referendum of 28 February 1980 and became an autonomous community under the 1981 Statute of Autonomy known as the \"Estatuto de Carmona\". The process followed the Spanish Constitution of 1978, still current as of 2009, which recognizes and guarantees the right of autonomy for the various regions and nationalities of Spain. The process to establish Andalusia as an autonomous region followed Article 151 of the Constitution, making Andalusia the only autonomous community to take that particular course. That article was set out for regions like Andalusia that had been prevented by the outbreak of the Spanish Civil War from adopting a statute of autonomy during the period of the Second Spanish Republic.\n\nArticle 1 of the 1981 Statute of Autonomy justifies autonomy based on the region's \"historical identity, on the self-government that the Constitution permits every nationality, on outright equality to the rest of the nationalities and regions that compose Spain, and with a power that emanates from the Andalusian Constitution and people, reflected in its Statute of Autonomy\".\n\nIn October 2006 the constitutional commission of the Cortes Generales (the national legislature of Spain), with favorable votes from the left-of-center Spanish Socialist Workers' Party (PSOE), the leftist United Left (IU) and the right-of-center People`s Party (PP), approved a new Statute of Autonomy for Andalusia, whose preamble refers to the community as a \"national reality\" (\"realidad nacional\"):\n\nOn 2 November 2006 the Spanish Chamber Deputies ratified the text of the Constitutional Commission with 306 votes in favor, none opposed, and 2 abstentions. This was the first time a Spanish Organic Law adopting a Statute of Autonomy was approved with no opposing votes. The Senate, in a plenary session of 20 December 2006, ratified the referendum to be voted upon by the Andalusian public 18 February 2007.\n\nThe Statute of Autonomy spells out Andalusia's distinct institutions of government and administration. Chief among these is the Andalusian Autonomous Government (\"Junta de Andalucía\"). Other institutions specified in the Statute are the Defensor del Pueblo Andaluz (literally \"Defender of the Andalusian People\", basically an ombudsperson), the Consultative Council, the Chamber of Accounts, the Audiovisual Council of Andalusia, and the Economic and Social Council.\n\nThe Andalusian Statute of Autonomy recognizes Seville as the region's capital. The Andalusian Autonomous Government is located there. However, the region's highest court, the High Court of Andalusia (\"Tribunal Superior de Justicia de Andalucía\") is not part of the Autonomous Government, and has its seat in Granada.\n\nThe Andalusian Autonomous Government (\"Junta de Andalucía\") is the institution of self-government of the Autonomous Community of Andalusia. Within the government, the President of the Regional Government of Andalusia is the supreme representative of the autonomous community, and the ordinary representative of the Spanish state in the autonomous community. The president is formally named to the position by the Monarch of Spain and then confirmed by a majority vote of the Parliament of Andalusia. In practice, the monarch always names a person acceptable to the ruling party or coalition of parties in the autonomous region. In theory, were the candidate to fail to gain the needed majority, the monarch could propose a succession of candidates. After two months, if no proposed candidate could gain the parliament's approval, the parliament would automatically be dissolved and the acting president would call new elections. On September 5, 2013 Susana Díaz was elected president.\n\nThe Council of Government, the highest political and administrative organ of the Community, exercises regulatory and executive power. The President presides over the council, which also includes the heads of various departments (\"Consejerías\"). In the current legislature (2008–2012), there are 15 of these departments. In order of precedence, they are Presidency, Governance, Economy and Treasury, Education, Justice and Public Administration, Innovation, Science and Business, Public Works and Transportation, Employment, Health, Agriculture and Fishing, Housing and Territorial Planning, Tourism, Commerce and Sports, Equality and Social Welfare, Culture, and Environment.\n\nThe Parliament of Andalusia, its Autonomic Legislative Assembly, develops and approves laws and elects and removes the President. Elections to the Andalusian Parliament follow a democratic formula through which the citizens elect 109 representatives. After the approval of the Statute of Autonomy through Organic Law 6/1981 on 20 December 1981, the first elections to the autonomic parliament took place 23 May 1982. Further elections have occurred in 1986, 1990, 1994, 1996, 2000, 2004, and 2008.\n\nThe current (2008–2012) legislature includes representatives of the PSOE-A (Andalusian branch of the left-of-center PSOE), PP-A (Andalusian branch of the right-of-center PP) and IULV-CA (Andalusian branch of the leftist IU).\n\nThe High Court of Andalusia (\"Tribunal Superior de Justicia de Andalucía\") in Granada is subject only to the higher jurisdiction of Supreme Court of Spain. The High Court is not an organ of the Autonomous Community, but rather of the Judiciary of Spain, which is unitary throughout the kingdom and whose powers are not transferred to the autonomous communities. The Andalusian territory is divided into 88 legal/judicial districts (\"partidos judiciales\").\n\nAndalusia consists of eight provinces. The latter were established by Javier de Burgos in the 1833 territorial division of Spain. Each of the Andalusian provinces bears the same name as its capital:\n\nAndalusia is traditionally divided into two historical subregions: Upper Andalusia\" or \"Eastern Andalusia (\"Andalucía Oriental\"), consisting of the provinces of Almería, Granada, Jaén, and Málaga, and Lower Andalusia\" or \"Western Andalusia (\"Andalucía Occidental\"), consisting of the provinces of Cádiz, Córdoba, Huelva and Seville.\n\nBeyond the level of provinces, Andalusia is further divided into 774 municipalities (\"municipios\"). The municipalities of Andalusia are regulated by Title III of the Statute of Autonomy, Articles 91–95, which establishes the municipality as the basic territorial entity of Andalusia, each of which has legal personhood and autonomy in many aspects of its internal affairs. At the municipal level, representation, government and administration is performed by the \"ayuntamiento\" (municipal government), which has competency for urban planning, community social services, supply and treatment of water, collection and treatment of waste, and promotion of tourism, culture, and sports, among other matters established by law.\n\nAmong the more important Andalusian cities besides the provincial capitals are:\n\nIn conformity with the intent to devolve control as locally as possible, in many cases, separate nuclei of population within municipal borders each administer their own interests. These are variously known as \"pedanías\" (\"hamlets\"), \"villas\" (\"villages\"), \"aldeas\" (also usually rendered as \"villages\"), or other similar names.\n\nWithin the various autonomous communities of Spain, \"comarcas\" are comparable to shires (or, in some countries, counties) in the English-speaking world. Unlike in some of Spain's other autonomous communities, under the original 1981 Statute of Autonomy, the \"comarcas\" of Andalusia had no formal recognition, but, in practice, they still had informal recognition as geographic, cultural, historical, or in some cases administrative entities. The 2007 Statute of Autonomy echoes this practice, and mentions \"comarcas\" in Article 97 of Title III, which defines the significance of \"comarcas\" and establishes a basis for formal recognition in future legislation.\n\nThe current statutory entity that most closely resembles a \"comarca\" is the \"mancomunidad\", a freely chosen, bottom-up association of municipalities intended as an instrument of socioeconomic development and coordination between municipal governments in specific areas.\n\nAndalusia ranks first by population among the 17 autonomous communities of Spain. The estimated population at the beginning of 2009 was 8,285,692. The population is concentrated, above all, in the provincial capitals and along the coasts, so that the level of urbanization is quite high; half the population is concentrated in the 28 cities of more than 50,000 inhabitants. The population is aging, although the process of immigration is countering the inversion of the population pyramid.\n\nAt the end of the 20th century, Andalusia was in the last phase of demographic transition. The death rate stagnated at around 8–9 per thousand, and the population came to be influenced mainly by birth and migration.\nIn 1950, Andalusia had 20.04 percent of the national population of Spain. By 1981, this had declined to 17.09 percent. Although the Andalusian population was not declining in absolute terms, these relative losses were due to emigration great enough to nearly counterbalance having the highest birth rate in Spain. Since the 1980s, this process has reversed on all counts, and as of 2009, Andalusia has 17.82 percent of the Spanish population.\nThe birth rate is sharply down, as is typical in developed economies, although it has lagged behind much of the rest of the world in this respect. Furthermore, prior emigrants have been returning to Andalusia. Beginning in the 1990s, others have been immigrating in large numbers as well, as Spain has become a country of net immigration.\n\nAt the beginning of the 21st century, statistics show a slight increase in the birth rate, due in large part to the higher birth rate among immigrants. The result is that as of 2009, the trend toward rejuvenation of the population is among the strongest of any autonomous community of Spain, or of any comparable region in Europe.\n\nAt the beginning of the 21st century, the population structure of Andalusia shows a clear inversion of the population pyramid, with the largest cohorts falling between ages 25 and 50. Comparison of the population pyramid in 2008 to that in 1986 shows:\n\nAs far as composition by sex, two aspects stand out: the higher percentage of women in the elderly population, owing to women's longer life expectancy, and, on the other hand, the higher percentage of men of working age, due in large part to a predominantly male immigrant population.\n\nIn 2005, 5.35 percent of the population of Andalusia were born outside of Spain. This is a relatively low number for a Spanish region, the national average being three percentage points higher. The immigrants are not evenly distributed among the Andalusian provinces: Almería, with a 15.20 percent immigrant population, is third among all provinces in Spain, while at the other extreme Jaén is only 2.07 percent immigrants and Córdoba 1.77 percent. The predominant nationalities among the immigrant populations are Moroccan (92,500, constituting 17.79 percent of the foreigners living in Andalusia) and British (15.25 percent across the region). When comparing regions rather than individual countries, the single largest immigrant block is from Latin America, outnumbering either North Africans or non-Spanish Western Europeans. Demographically, this group has provided an important addition to the Andalusian labor force.\n\nAndalusia is traditionally an agricultural area, but the service sector (particularly tourism, retail sales, and transportation) now predominates. The once booming construction sector, hit hard by the 2009 recession, was also important to the region's economy. The industrial sector is less developed than most other regions in Spain.\n\nBetween 2000–2006 economic growth per annum was 3.72%, one of the highest in the country. Still, according to the Spanish Instituto Nacional de Estadística (INE), the GDP per capita of Andalusia (€17,401; 2006) remains the second lowest in Spain, with only Extremadura lagging behind.\n\nThe primary sector, despite adding the least of the three sectors to the regional GDP remains important, especially when compared to typical developed economies. The primary sector produces 8.26 percent of regional GDP and employs 8.19 percent of the workforce. In monetary terms it could be considered a rather uncompetitive sector, given its level of productivity compared to other Spanish regions. In addition to its numeric importance relative to other regions, agriculture and other primary sector activities have strong roots in local culture and identity.\n\nThe primary sector is divided into a number of subsectors: agriculture, commercial fishing, animal husbandry, hunting, forestry, mining, and energy.\n\nFor many centuries, Andalusian society was mainly agricultural. Even today, 45.74 percent of the Andalusian territory is cultivated. The primary cultivation is dryland farming of cereals and sunflowers without artificial irrigation, especially in the vast countryside of the Guadalquivir valley and the high plains of Granada and Almería-with a considerably lesser and more geographically focused cultivation of barley and oats. Using irrigation, maize, cotton and rice are also grown on the banks of the Guadalquivir and Genil.\n\nThe most important tree crops are olives, especially in the Subbetic regions of the provinces of Córdoba and Jáen, where irrigated olive orchards constitute a large component of agricultural output. There are extensive vineyards in various zones such as Jerez de la Frontera (sherry), Condado de Huelva, Montilla-Moriles and Málaga. Fruits—mainly citrus fruits—are grown near the banks of the Guadalquivir; almonds, which require far less water, are grown on the high plains of Granada and Almería.\n\nIn monetary terms, by far the most productive and competitive agriculture in Andalusia is the intensive forced cultivation of strawberries, raspberries, blueberries, and other fruits grown under hothouse conditions under clear plastic, often in sandy zones, on the coasts, in Almería and Huelva.\n\nOrganic farming has recently undergone rapid expansion in Andalusia, mainly for export to European markets but with increasing demand developing in Spain.\n\nAndalusia has a long tradition of animal husbandry and livestock farming, but it is now restricted mainly to mountain meadows, where there is less pressure from other potential uses. Andalusians have a long and colourful history of dog breeding that can be observed throughout the region today. The raising of livestock now plays a semi-marginal role in the Andalusian economy, constituting only 15 percent of the primary sector, half the number for Spain taken as a whole.\n\n\"Extensive\" raising of livestock grazes the animals on natural or cultivated pastures, whereas \"intensive\" raising of livestock is based in fodder rather than pasture. Although the productivity is higher than with extensive techniques, the economics are quite different. While intensive techniques now dominate in Europe and even in other regions of Spain, most of Andalusia's cattle, virtually all of its sheep and goats, and a good portion of its pigs are raised by extensive farming in mountain pastures. This includes the Black Iberian pigs that are the source of \"Jamón ibérico\". Andalusia's native sheep and goats present a great economic opportunity in a Europe where animal products are generally in strong supply, but the sheep and goat meat, milk, and leather (and the products derived from these) are relatively scarce. Dogs are bred not just as companion animals, but also as herding animals used by goat and sheep herders.\n\nHunting remains relatively important in Andalusia, but has largely lost its character as a means of obtaining food.\nIt is now more of a leisure activity linked to the mountain areas and complementary to forestry and the raising of livestock. Dogs are frequently used as hunting companions to retrieve killed game.\n\nThe Andalusian forests are important for their extent—50 percent of the territory of Andalusia—and for other less quantifiable environmental reasons, such as their value in preventing erosion, regulating the flow of water necessary for other flora and fauna. For these reasons, there is legislation in place to protect the Andalusian forests. The value of forest products as such constitutes only 2 percent of agricultural production. This comes mostly from cultivated species—eucalyptus in Huelva and poplar in Granada—as well as naturally occurring cork oak in the Sierra Morena.\n\nFishing is a longstanding tradition on the Andalusian coasts. Fish and other seafood have long figured prominently in the local diet and in the local gastronomic culture: fried fish (\"pescaito frito\" in local dialect), white prawns, \"almadraba\" tuna, among others. The Andalusian fishing fleet is Spain's second largest, after Galicia, and Andalusia's 38 fishing ports are the most of any Spanish autonomous community. Commercial fishing produces only 0.5 percent of the product of the regional primary sector by value, but there are areas where it has far greater importance. In the province of Huelva it constitutes 20 percent of the primary sector, and locally in Punta Umbría 70 percent of the work force is involved in commercial fishing.\n\nFailure to comply with fisheries laws regarding the use of trawling, urban pollution of the seacoast, destruction of habitats by coastal construction (for example, alteration of the mouths of rivers, construction of ports), and diminution of fisheries by overexploitation\nhave created a permanent crisis in the Andalusian fisheries, justifying attempts to convert the fishing fleet. The decrease in fish stocks has led to the rise of aquaculture, including fish farming both on the coasts and in the interior.\n\nDespite the general poor returns in recent years, mining retains a certain importance in Andalusia. Andalusia produces half of Spain's mining product by value. Of Andalusia's production, roughly half comes from the province of Huelva. Mining for precious metals at Minas de Riotinto in Huelva (\"see Rio Tinto Group\") dates back to pre-Roman times; the mines were abandoned in the Middle Ages and rediscovered in 1556. Other mining activity is coal mining in the Guadiato valley in the province of Córdoba; various metals at Aznalcóllar in the province of Seville, and iron at Alquife in the province of Granada. In addition, limestone, clay, and other materials used in construction are well distributed throughout Andalusia.\n\nThe Andalusian industrial sector has always been relatively small. Nevertheless, in 2007, Andalusian industry earned 11.979 million euros and employed more than 290,000 workers. This represented 9.15 percent of regional GDP, far below the 15.08 the secondary sector represents in the economy of Spain as a whole. By analyzing the different subsectors of the food industry Andalusian industry accounts for more than 16% of total production. In a comparison with the Spanish economy, this subsector is virtually the only food that has some weight in the national economy with 16.16%. Lies far behind the manufacturing sector of shipping materials just over 10% of the Spanish economy. Companies like Cruzcampo (Heineken Group), Puleva, Domecq, Santana Motors or Renault-Andalusia, are exponents of these two subsectors. Of note is the Andalusian aeronautical sector, which is second nationally only behind Madrid and represents approximately 21% of total turnover in terms of employment, highlighting companies like Airbus, Airbus Military, or the newly formed Aerospace Alestis. On the contrary it is symptomatic of how little weight the regional economy in such important sectors such as textiles or electronics at the national level.\n\nAndalusian industry is also characterized by a specialization in industrial activities of transforming raw agricultural and mineral materials. This is largely done by small enterprises without the public or foreign investment more typical of a high level of industrialization.\n\nIn recent decades the Andalusian tertiary (service) sector has grown greatly, and has come to constitute the majority of the regional economy, as is typical of contemporary economies in developed nations. In 1975 the service sector produced 51.1 percent of local GDP and employed 40.8 percent of the work force. In 2007, this had risen to 67.9 percent of GDP and 66.42 percent of jobs. This process of \"tertiarization\" of the economy has followed a somewhat unusual course in Andalusia. This growth occurred somewhat earlier than in most developed economies and occurred independently of the local industrial sector. There were two principal reasons that \"tertiarization\" followed a different course in Andalusia than elsewhere:\n\n1. Andalusian capital found it impossible to compete in the industrial sector against more developed regions, and was obligated to invest in sectors that were easier to enter.\n\n2. The absence of an industrial sector that could absorb displaced agricultural workers and artisans led to the proliferation of services with rather low productivity. This unequal development compared to other regions led to a hypertrophied and unproductive service sector, which has tended to reinforce underdevelopment, because it has not led to large accumulations of capital.\n\nDue in part to the relatively mild winter and spring climate, the south of Spain is attractive to overseas visitors–especially tourists from Northern Europe. While inland areas such as Jaén, Córdoba and the hill villages and towns remain relatively untouched by tourism, the coastal areas of Andalusia have heavy visitor traffic for much of the year.\n\nAmong the autonomous communities, Andalusia is second only to Catalonia in tourism, with nearly 30 million visitors every year. The principal tourist destinations in Andalusia are the Costa del Sol and (secondarily) the Sierra Nevada. As discussed above, Andalusia is one of the sunniest and warmest places in Europe, making it a center of \"sun and sand\" tourism. 70 percent of the lodging capacity and 75 percent of the nights booked in Andalusian hotels are in coastal municipalities. The largest number of tourists come in August—13.26 percent of the nights booked throughout the year—and the smallest number in December—5.36 percent.\n\nOn the west (Atlantic) coast are the Costa de la Luz (provinces of Huelva and Cádiz), and on the east (Mediterranean) coast, the Costa del Sol (provinces of Cádiz y Málaga), Costa Tropical (Granada and part of Almería) and the Costa de Almería. In 2004, the Blue Flag beach program of the non-profit Foundation for Environmental Education recognized 66 Andalusian beaches and 18 pleasure craft ports as being in a good state of conservation in terms of sustainability, accessibility, and quality. Nonetheless, the level of tourism on the Andalusian coasts has been high enough to have a significant environmental impact, and other organizations—such as the Spanish Ecologists in Action (\"Ecologistas en Acción\") with their description of \"Black Flag beaches\" or Greenpeace—have expressed the opposite sentiment. However, Hotel chains such as Fuerte Hotels have ensured that sustainability within the tourism industry is one of their highest priorities.\n\nTogether with \"sand and sun\" tourism, there has also been a strong increase in nature tourism in the interior, as well as cultural tourism, sport tourism, and conventions. One example of sport and nature tourism is the ski resort at Sierra Nevada National Park.\n\nAs for cultural tourism, Andalusia has some notable monuments dating back to the Muslim era: the Great Mosque of Córdoba, the Alhambra in Granada, the Giralda and Alcazar in Seville, and the Alcazaba in Málaga. There are hundreds of cultural tourist destinations: cathedrals, castles, forts, monasteries, and historic city centers; the city centers of Úbeda and Baeza in the province of Jaén are UNESCO World Heritage Sites.\n\nEach of the provinces shows a great variety of architectural styles: Islamic architecture, Renaissance architecture, Baroque architecture and more modern styles. Further, there are the \"Lugares colombinos\", significant places in the life of Christopher Columbus: Palos de la Frontera, La Rábida Monastery, and Moguer) in the province of Huelva. There are also archeological sites of great interest: the Roman city of Italica, birthplace of Emperor Trajan and (most likely) Hadrian; Baelo Claudia near the Straits of Gibraltar; Medina Azahara, the city-palace of the Cordoban caliph Abd-ar-Rahman III, where major excavations still continue.\n\nAndalusia was the birthplace of such great painters as Velázquez and Murillo (Seville) and, more recently, Picasso (Málaga); Picasso is memorialized by his native city at the Museo Picasso Málaga and Natal House Foundation; the Casa de Murillo was a house museum 1982–1998, but is now mostly offices for the Andalusian Council of Culture. The CAC Málaga (Museum of Modern Art) is the most visited museum of Andalusia and has offered exhibitions of artists such as Louise Bourgeois, Jake and Dinos Chapman, Gerhard Richter, Anish Kapoor, Ron Mueck or Rodney Graham. Malaga is also located part of the private Carmen Thyssen-Bornemisza Collection at Carmen Thyssen Museum.\n\nThere are numerous other significant museums around the region, both of paintings and of archeological artifacts such as gold jewelry, pottery and other ceramics, and other works that demonstrate the region's artisanal traditions.\n\nThe Council of Government has designated the following \"Municipios Turísticos\": in Almería, Roquetas de Mar; in Cádiz, Chiclana de la Frontera, Chipiona, Conil de la Frontera, Grazalema, Rota, and Tarifa; in Granada, Almuñécar; in Huelva, Aracena; in Jaén, Cazorla; in Málaga, Benalmádena, Fuengirola, Nerja, Rincón de la Victoria, Ronda, and Torremolinos; in Seville, Santiponce.\n\nAs in any modern society, transport systems are an essential structural element of the functioning of Andalusia. The transportation network facilitates territorial coordination, economic development and distribution, and intercity transportation.\n\nIn urban transport, underdeveloped public transport systems put pedestrian traffic and other non-motorized traffic are at a disadvantage compared to the use of private vehicles. Several Andalusian capitals—Córdoba, Granada and Seville—have recently been trying to remedy this by strengthening their public transport systems and providing a better infrastructure for the use of bicycles.\n\nFor over a century, the conventional rail network has been centralized on the regional capital, Seville, and the national capital, Madrid; in general, there are no direct connections between provincial capitals. High-speed AVE trains run from Madrid via Córdoba to Seville and Málaga. Further AVE routes are under construction. The Madrid-Córdoba-Seville route was the first high-velocity route in Spain (operating since 1992). Other principal routes are the one from Algeciras to Seville and from Almería via Granada to Madrid.\n\nMost of the principal roads have been converted into limited access highways known as \"autovías\". The Autovía del Este (Autovía A-4) runs from Madrid through the Despeñaperros Natural Park, then via Bailén, Córdoba, and Seville to Cádiz, and is part of European route E05 in the International E-road network. The other main road in the region is the portion of European route E15, which runs as the Autovia del Mediterráneo along the Spanish Mediterranean coast. Parts of this constitute the superhighway Autopista AP-7, while in other areas it is Autovía A-7. Both of these roads run generally east-west, although the Autovía A-4 turns to the south in western Andalusia.\n\nOther first-order roads include the Autovía A-48 roughly along the Atlantic coast from Cádiz to Algeciras, continuing European route E05 to meet up with European route E15; the Autovía del Quinto Centenario (Autovía A-49), which continues west from Seville (where the Autovía A-4 turns toward the south) and goes on to Huelva and into Portugal as European route E01; the Autovía Ruta de la Plata (Autovía A-66), European route E803, which roughly corresponds to the ancient Roman 'Silver Route' from the mines of northern Spain, and runs north from Seville; the Autovía de Málaga (Autovía A-45), which runs south from Córdoba to Málaga; and the Autovía de Sierra Nevada (Autovía A-44), part of European route E902, which runs south from Jaén to the Mediterranean coast at Motril.\n\nAs of 2008 Andalusia has six public airports, all of which can legally handle international flights; however the Málaga Airport is dominant, handling 60.67 percent of passengers and 85 percent of its international traffic. The Seville Airport handles another 20.12 percent of traffic, and the Jerez Airport 7.17 percent, so that these three airports account for 87.96 percent of traffic.\n\nMálaga Airport is the international airport that offers a wide variety of international destinations. It has a daily link with twenty cities in Spain and over a hundred cities in Europe (mainly in Great Britain, Central Europe and the Nordic countries but also the main cities of Eastern Europe: Moscow, Saint Petersburg, Sofia, Riga or Bucharest), North Africa, Middle East (Riyadh, Jeddah and Kuwait) and North America (New York, Toronto and Montreal).\n\nThe main ports are Algeciras (for freight and container traffic) and Málaga for cruise ships. Algeciras is Spain's leading commercial port, with of cargo in 2004. Seville has Spain's only commercial river port. Other significant commercial ports in Andalusia are the ports of the Bay of Cádiz, Almería and Huelva.\n\nThe Council of Government has approved a Plan of Infrastructures for the Sustainability of Transport in Andalusia (PISTA) 2007–2013, which plans an investment of 30 billion euros during that period.\n\nThe lack of high-quality fossil fuels in Andalusia has led to a strong dependency on petroleum imports. Still, Andalusia has a strong potential for the development of renewable energy, above all wind energy. The Andalusian Energy Agency established in 2005 by the autonomous government, is a new governmental organ charged with the development of energy policy and provision of a sufficient supply of energy for the community.\n\nThe infrastructure for production of electricity consists of eight large thermal power stations, more than 70 hydroelectric power plants, two wind farms, and 14 major cogeneration facilities. Historically, the largest Andalusian business in this sector was the Compañía Sevillana de Electricidad, founded in 1894, absorbed into Endesa in 1996.\n\nThe Solar power tower PS10 was built by the Andalusian firm Abengoa in Sanlúcar la Mayor in the province of Seville, and began operating in March 2007. It is the largest existing solar power facility in Europe. Smaller solar power stations, also recent, exist at Cúllar and Galera, Granada, inaugurated by Geosol and Caja Granada. Two more large thermosolar facilities, Andasol I y II, planned at Hoya de Guadix in the province of Granada are expected to supply electricity to half a million households. The Plataforma Solar de Almería (PSA) in the Tabernas Desert is an important center for the exploration of the solar energy.\n\nThe largest wind power firm in the region is the Sociedad Eólica de Andalucía, formed by the merger of Planta Eólica del Sur S.A. and Energía Eólica del Estrecho S.A.\n\nAs throughout Spain, basic education in Andalusia is free and compulsory. Students are required to complete ten years of schooling, and may not leave school before the age of 16, after which students may continue on to a baccalaureate, to intermediate vocational education, to intermediate-level schooling in arts and design, to intermediate sports studies, or to the working world.\n\nAndalusia has a tradition of higher education dating back to the Middle Ages and the Madrasah of Granada, University of Baeza, and University of Osuna.\n\nAs of 2009, there are ten private or public universities in Andalucia. University studies are structured in cycles, awarding degrees based on ECTS credits in accord with the Bologna process, which the Andalusian universities are adopting in accord with the other universities of the European Higher Education Area.\n\nResponsibility for healthcare jurisdictions devolved from the Spanish government to Andalusia with the enactment of the Statute of Autonomy. Thus, the Andalusian Health Service (\"Servicio Andaluz de Salud\") currently manages almost all public health resources of the Community, with such exceptions as health resources for prisoners and members of the military, which remain under central administration.\n\nAccording to the Outreach Program for Science in Andalusia, Andalusia contributes 14 percent of Spain's scientific production behind only Madrid and Catalonia among the autonomous communities, even though regional investment in research and development (R&D) as a proportion of GDP is below the national average. The lack of research capacity in business and the low participation of the private sector in research has resulted in R&D taking place largely in the public sector.\n\nThe Council of Innovation, Science and Business is the organ of the autonomous government responsible for universities, research, technological development, industry, and energy. The council coordinates and initiates scientific and technical innovation through specialized centers an initiatives such as the Andalusian Center for Marine Science and Technology (\"Centro Andaluz de Ciencia y Tecnología Marina\") and Technological Corporation of Andalusia (\"Corporación Tecnológica de Andalucía\").\n\nWithin the private sphere, although also promoted by public administration, technology parks have been established throughout the Community, such as the Technological Park of Andalucia (\"Parque Tecnológico de Andalucía\") in Campanillas on the outskirts of Málaga, and Cartuja 93 in Seville. Some of these parks specialize in specific sector, such as Aerópolis in aerospace or Geolit in food technology. The Andalusian government deployed 600,000 Ubuntu desktop computers in their schools.\n\nAndalusia has international, national, regional, and local media organizations, which are active gathering and disseminating information (as well as creating and disseminating entertainment).\n\nThe most notable is the public Radio y Televisión de Andalucía (RTVA), broadcasting on two regional television channels, Canal Sur and Canal Sur 2, four regional radio stations, Canal Sur Radio, Canal Fiesta Radio, Radio Andalucía Información and Canal Flamenco Radio, as well as various digital signals, most notably Canal Sur Andalucía available on cable TV throughout Spain.\n\nDifferent newspapers are published for each Andalusian provincial capital, comarca, or important city. Often, the same newspaper organization publishes different local editions with much shared content, with different mastheads and different local coverage. There are also popular papers distributed without charge, again typically with local editions that share much of their content.\n\nNo single Andalusian newspaper is distributed throughout the region, not even with local editions. In eastern Andalusia the \"Diario Ideal\" has editions tailored for the provinces if Almería, Granada, and Jaén. Grupo Joly is based in Andalucia, backed by Andalusian capital, and publishes eight daily newspapers there. Efforts to create a newspaper for the entire autonomous region have not succeeded (the most recent as of 2009 was the \"Diario de Andalucía\"). The national press (\"El País\", \"El Mundo\", \"ABC\", etc.) include sections or editions specific to Andalusia.\n\nAndalusia has two public television stations, both operated by Radio y Televisión de Andalucía (RTVA):\n\nIn addition, RTVA also operates the national and international cable channel Canal Sur Andalucía, which first broadcast in 1996 as Andalucía Televisión.\n\nThere are four public radio stations in the region, all operated by RTVA:\n\nThe culture of Andalusia has been shaped by its particular history and geography, as well as its complex flows of population. Andalusia has been home to a succession of peoples and civilizations, many very different from one another, each impacting the settled inhabitants. The ancient Iberians were followed by Celts, Phoenicians and other Eastern Mediterranean traders, Romans, migrating Germanic tribes, North African Muslims, and the Castilians and other Spanish of the \"Reconquista\". All have affected Andalusian identity and culture, which was already delineated in the 19th century and diffused widely in the literary and pictorial genre of the \"costumbrismo andaluz\".\nIn the 19th century, Andalusian culture came to be widely viewed as the Spanish culture \"par excellence\", in part thanks to the perceptions of romantic travellers. In the words of Ortega y Gasset:\n\nAndalusia has been the birthplace of many great artists: the classic painters Velázquez, Murillo, and Juan de Valdés Leal; the sculptors Juan Martínez Montañés, Alonso Cano and Pedro de Mena; and such modern painters as Daniel Vázquez Díaz and Pablo Picasso.\n\nThe composer Manuel de Falla was from Cádiz and incorporated typical Andalusian melodies in his works, as did Joaquín Turina, from Seville. The great singer Camarón de la Isla was born in San Fernando, Cádiz, and Andrés Segovia who helped shape the romantic-modernist approach to classical guitar, was born in Linares, Jaén.\n\nSince the Neolithic era, Andalusia has preserved important megaliths, such as the dolmens at the Cueva de Menga and the Dolmen de Viera, both at Antequera. Archeologists have found Bronze Age cities at Los Millares and El Argar. Archeological digs at Doña Blanca in El Puerto de Santa María have revealed the oldest Phoenicians city in the Iberian peninsula; major ruins have also been revealed at Roman Italica near Seville.\n\nSome of the greatest architecture in Andalusia dates from the Muslim era: the Alhambra and the Great Mosque of Córdoba.\n\nThe traditional architecture of Andalusia retains its Roman and Arab roots, with a marked Mediterranean character strongly conditioned by the climate. Traditional urban houses are constructed with shared walls to minimize exposure to high exterior temperatures. Solid exterior walls are painted with lime to minimize the heating effects of the sun. In accord with the climate and tradition of each area, the roofs may be terraces or tiled in the Roman imbrex and tegula style. One of the most characteristic elements (and one of the most obviously influenced by Roman and North African architecture) is the interior patio or courtyard; the patios of Córdoba are particularly famous. Other characteristic elements are decorative (and functional) wrought iron gratings, and the tiles known as \"azulejos\". Landscaping—both for common private homes and homes on a more lavish scale—also carries on older traditions, with plants, flowers, and fountains, pools, and streams of water. Beyond these general elements, there are also specific local architectural styles, such as the flat roofs, roofed chimneys, and radically extended balconies of the Alpujarra, the cave dwellings of Guadix and of Granada's Sacromonte, or the traditional architecture of the Marquisate of Zenete.\n\nThe monumental architecture of the centuries immediately after the Reconquista often displayed an assertion of Christian hegemony through architecture that referenced non-Arab influences. Some of the greatest Renaissance buildings in Andalusia are from the then-kingdom of Jaén: the Jaén Cathedral, designed in part by Andrés de Vandelvira, served as a model for the Cathedral of Malaga and Guadix; the centers of Úbeda and Baeza, dating largely from this era, are UNESCO World Heritage Sites. Seville and its kingdom also figured prominently in this era, as is shown by the Casa consistorial de Sevilla, the Hospital de las Cinco Llagas or the Charterhouse of Jerez de la Frontera. The Palace of Charles V in Granada is uniquely important for its Italianate purism. Andalusia also has such Baroque-era buildings as the Palace of San Telmo in Seville (seat of the current autonomic presidency), the Church of Our Lady of Reposo in Campillos, and the Granada Charterhouse. Academicism gave the region the Royal Tobacco Factory in Seville and Neoclassicism the nucleus of Cádiz, such as its city hall, Royal Prison and the Oratorio de la Santa Cueva.\n\nRevivalist architecture in the 19th and 20th centuries contributed the buildings of the Ibero-American Exposition of 1929 in Seville, including the Neo-Mudéjar Plaza de España. Andalusia also preserves an important industrial patrimony related to various economic activities.\n\nBesides the architecture of the cities, there is also much outstanding rural architecture: houses, as well as ranch and farm buildings and dog houses.\n\nThe Iberian reliefs of Osuna, Lady of Baza, and León de Bujalance, the Phoenician sarcophagi of Cádiz, and the Roman sculptures of the Baetic cities such as Italica give evidence of traditions of sculpture in Andalusia dating back to antiquity. There are few significant surviving sculptures from the time of al-Andalus; two notable exceptions are the lions of the Alhambra and of the Maristán of Granada (the Muslim-era hospital in the Albaicín).\n\nThe Sevillian school of sculpture dating from the 13th century onward and the Granadan school beginning toward the end of the 16th century both focused primarily on Christian religious subject matter, including many wooden altarpieces. Notable sculptors in these traditions include Lorenzo Mercadante de Bretaña, Pedro Millán, Juan Martínez Montañés, Pedro Roldán, José de Arce, Jerónimo Balbás, Alonso Cano, and Pedro de Mena.\n\nNon-religious sculpture has also existed in Andalusia since antiquity. A fine example from the Renaissance era is the decoration of the Casa de Pilatos in Seville. Nonetheless, non-religious sculpture played a relatively minor role until such 19th-century sculptors as Antonio Susillo.\n\nAs in sculpture, there were Sevillian and the Granadan schools of painting. The latter has figured prominently in the history of Spanish art since the 15th century and includes such important artists as Zurbarán, Velázquez and Murillo, as well as theoreticians of art such as Francisco Pacheco. The Museum of Fine Arts of Seville and the The Prado contain numerous representative works of the Sevillian school of painting.\n\nA specific romantic genre known as \"costumbrismo andaluz\" depicts traditional and folkloric Andalusian subjects, such as bullfighting scenes, dogs, and scenes from Andalusia's history. Important artists in this genre include Manuel Barrón, José García Ramos, Gonzalo Bilbao and Julio Romero de Torres. The genre is well represented in the private Carmen Thyssen-Bornemisza Collection, part of which is on display at Madrid's Thyssen-Bornemisza Museum and Carmen Thyssen Museum in Málaga.\n\nMálaga also has been and is an important artistic center. Its most illustrious representative was Pablo Picasso, one of the most influential artists of the 20th century. The city has a Museum and Natal House Foundation, dedicated to the painter.\n\nAndalusia plays a significant role in the history of Spanish language literature, however not all of the important literature associated with Andalusia was written in Spanish. Before 1492, there was the literature written in Andalusian Arabic. Hispano-Arabic authors native to the region include\nIbn Hazm, Ibn Zaydun, Ibn Tufail, Al-Mu'tamid, Ibn al-Khatib, Ibn al-Yayyab, and Ibn Zamrak or Andalusian Hebrew poets as Solomon Ibn Gabirol. Ibn Quzman, of the 12th century, crafted poems in the colloquial Andalusian language.\n\nIn 1492 Antonio de Nebrija published his celebrated \"Gramática de la lengua castellana\" (\"Grammar of the Castilian language\"), the first such work for a modern European language. In 1528 Francisco Delicado wrote \"\", a novel in the orbit of \"La Celestina\", and in 1599 the Sevillian Mateo Alemán wrote the first part of \"Guzmán de Alfarache\", the first picaresque novel with a known author.\n\nThe prominent humanist literary school of Seville included such writers as Juan de Mal Lara, Fernando de Herrera, Gutierre de Cetina, Luis Barahona de Soto, Juan de la Cueva, Gonzalo Argote de Molina, and Rodrigo Caro. The Cordoban Luis de Góngora was the greatest exponent of the \"culteranismo\" of Baroque poetry in the Siglo de Oro; indeed, the style is often referred to as \"Góngorismo\".\n\nLiterary Romanticism in Spain had one of its great centers in Andalusia, with such authors as Ángel de Saavedra, Duke of Rivas, José Cadalso and Gustavo Adolfo Bécquer. \"Costumbrismo andaluz\" existed in literature as much as in visual art, with notable examples being the \"Escenas andaluzas\" of Serafín Estébanez Calderón and the works of Pedro Antonio de Alarcón.\n\nAndalusian authors Ángel Ganivet, Manuel Gómez-Moreno, Manuel and Antonio Machado, and Francisco Villaespesa are all generally counted in the Generation of '98. Also of this generation were the Hermanos Álvarez Quintero, dramatists who faithfully captured Andalusian dialects and idiosyncrasies. Also of note, 1956 Nobel Prize-winning poet Juan Ramón Jiménez was a native of Moguer, near Huelva.\n\nA large portion of the \"avant garde\" Generation of '27 who gathered at the Ateneo de Sevilla on the 300th anniversary of Góngora's death were Andalusians: Federico García Lorca, Luis Cernuda, Rafael Alberti, Manuel Altolaguirre, Emilio Prados, and 1977 Nobel laureate Vicente Aleixandre.\n\nCertain Andalusian fictional characters have become universal archetypes: Prosper Merimée's gypsy \"Carmen\", P. D. Eastman's \"Perro\", Pierre Beaumarchais's \"Fígaro\", and Tirso de Molina's \"Don Juan\".\n\nAs in most regions of Spain, the principal form of popular verse is the romance, although there are also strophes specific to Andalusia, such as the \"soleá\" or the \"soleariya\". Ballads, lullabies, street vendor's cries, nursery rhymes, and work songs are plentiful.\n\nAmong the philosophers native to the region can be counted Seneca, Avicebron, Maimonides, Averroes, Fernán Pérez de Oliva, Sebastián Fox Morcillo, Ángel Ganivet, Francisco Giner de los Ríos and María Zambrano.\n\nThe music of Andalusia includes traditional and contemporary music, folk and composed music, and ranges from flamenco to rock. Conversely, certain metric, melodic and harmonic characteristics are considered Andalusian even when written or performed by musicians from elsewhere.\n\nFlamenco, perhaps the most characteristically Andalusian genre of music and dance, originated in the 18th century, but is based in earlier forms from the region. The influence of the traditional music and dance of the Romani people or Gypsies is particularly clear. The genre embraces distinct vocal (\"cante flamenco\"), guitar (\"toque flamenco\"), and dance (\"baile flamenco\") styles.\n\nThe Andalusian Statute of Autonomy reflects the cultural importance of flamenco in its Articles 37.1.18 and 68:\n\nFundamental in the history of Andalusian music are the composers Cristóbal de Morales, Francisco Guerrero, Francisco Correa de Arauxo, Manuel García, Manuel de Falla, Joaquín Turina, and Manuel Castillo, as well as the father of modern classical guitar, the guitarist Andrés Segovia. Mention should also be made of the great folk artists of the \"copla (music)\" and the \"cante hondo\", such as Rocío Jurado, Lola Flores (\"La Faraona\", \"the pharaoh\"), Juanito Valderrama and the revolutionary Camarón de la Isla.\n\nProminent Andalusian rock groups include Triana and Medina Azahara. The duo Los del Río from Dos Hermanas had international success with their \"Macarena\", including playing at a Super Bowl half-time show in the United States, where their song has also been used as campaign music by the Democratic Party. Other notables include the singer, songwriter, and poet Joaquín Sabina, Isabel Pantoja, Rosa López, who represented Spain at Eurovision in 2002, and David Bisbal.\n\nThe portrayal of Andalusia in film is often reduced to archetypes: flamenco, bullfighting, Catholic pageantry, brigands, the property-rich and cash-poor \"señorito andaluz\" and emigrants. These images particularly predominated from the 1920s through the 1960s, and helped to consolidate a cliched image of the region. In a very different vein, the province of Almería was the filming location for many Westerns, especially (but by no means exclusively) the Italian-directed Spaghetti Westerns. During the dictatorship of Francisco Franco, this was the extent of the film industry in Andalusia.\n\nNonetheless, Andalusian film has roots as far back as José Val del Omar in the pre-Franco years, and since the Spanish transition to democracy has brought forth numerous nationally and internationally respected directors: Antonio Cuadri (\"Heart of the Earth\"), Chus Gutiérrez (\"Poniente\"), Chiqui Carabante (\"Carlos Against the World\"), Alberto Rodríguez (\"7 Virgins\"), Benito Zambrano (\"Solas\"), and Antonio Banderas (\"Summer Rain\").\n\nCounting together feature films, documentaries, television programs, music videos etc., Andalusia has boomed from 37 projects shooting in 1999 to 1,054 in 2007, with the figure for 2007 including 19 feature films. Although feature films are the most prestigious, commercials and television are currently more economically important to the region.\n\nThe Filmoteca de Andalucía, headquartered in Córdoba, is a government-run entity in charge of the investigation, collection and diffusion of Andalusian cinematic heritage. Other important contributors to this last activity are such annual film festivals as the (\"Festival de Málaga Cine Español (FMCE)\"), the most important festival dedicated exclusively to cinema made in Spain, the Seville Festival of European Film (SFCE), the International Festival of Short Films - Almería in Short, the Huelva Festival of Latin American Film, the Atlantic Film Show in Cádiz, the Islantilla Festival of Film and Television and the African Film Festival of Tarifa.\n\nAndalusia has a wide array of social customs, many of which have their roots in the Islamic traditions integrated into the culture of the area under Muslim rule. Each sub-region in Andalusia has its own unique customs that represent a fusion of Catholicism and local folklore. Traditional dress in all areas of Andalusia tends to be colorful and involve various head coverings reminiscent of a Muslim past. Cities like Almería have been influenced historically by both Granada and Murcia in the use of traditional head coverings. The \"sombrero de Labrador\", a worker's hat made of black velvet, is a signature style of the region.\n\nIn Cádiz, traditional costumes with rural origins are worn at bullfights and at parties on the large estates. The \"tablao flamenco\" dance and the accompanying \"cante jondo\" vocal style originated in Granada. They are believed to have their roots in oriental, Gregorian, Moorish, and Jewish music. This music is most often performed by the gypsy Romani, who are more numerous in Granada than anywhere else in Spain. One of the most distinctive cultural events in Andalusia is the Romeria de El Rocio in May. It consists of a pilgrimage to the Hermitage of El Rocío in the countryside near Almonte, in honor of the Virgin of El Rocío, an image of the Virgin and Child, which was supposedly hidden from the Muslims during Moorish rule. In recent times the \"Romería\" has attracted roughly a million pilgrims each year.\n\nIn Jaén, the saeta is a revered form of Spanish religious song, whose form and style has evolved over many centuries. Saetas evoke strong emotion and are sung most often during public processions. \"Verdiales\", based upon the fandango, are a flamenco music style and song form originating in Almogia, near Málaga. For this reason, the Verdiales are sometimes known as \"Fandangos de Málaga.\" The region also has a rich musical tradition of flamenco songs, or palos called cartageneras. Seville celebrates \"Semana Santa\", one of the better known religious events within Spain. During the festival, religious fraternities dress as penitents and carry large floats of lifelike wooden sculptures representing scenes of the Passion, and images of the Virgin Mary. Sevillanas, a type of old folk music sung and written in Seville and still very popular, are performed in fairs and festivals, along with an associated dance for the music, the \"Baile por sevillanas\". All the different regions of Andalusia have developed their own distinctive customs, but all share a connectedness to Catholicism and the region's Muslim cultural past.\n\nAndalusian Spanish is one of the most widely spoken forms of Spanish in Spain, and because of emigration patterns was very influential on American Spanish. Rather than a single dialect, it is really a range of dialects sharing some common features; among these is the retention of more Arabic words than elsewhere in Spain, as well as some phonological differences compared with Standard Spanish. The isoglosses that mark the borders of Andalusian Spanish overlap to form a network of divergent boundaries, so there is no clear border for the linguistic region.\n\nThe territory now known as Andalusia fell within the sphere of influence of ancient Mediterranean mythological beliefs. Phoenician colonization brought the cults of Baal and Melqart; the latter lasted into Roman times as Hercules, mythical founder of both Cádiz and Seville. The Islote de Sancti Petri held the supposed tomb of Hercules, with representations of his Twelve labors; the region was the traditional site of the tenth labor, obtaining the cattle of the monster Geryon. Traditionally, the Pillars of Hercules flank the Strait of Gibraltar. Clearly, the European pillar is the Rock of Gibraltar; the African pillar was presumably either Monte Hacho in Ceuta or Jebel Musa in Morocco. The Roman road that led from Cádiz to Rome was known by several names, one of them being \"Via Herculea\", Hercules route returning from his tenth labor. The present coat of arms of Andalusia shows Hercules between two lions, with two pillars behind these figures.\n\nRoman Catholicism is, by far, the largest religion in Andalusia. In 2012, the proportion of Andalusians that identify themselves as Roman Catholic was 78.8%. The principal characteristic of the local popular form of Catholicism is devotion to the Virgin Mary; Andalusia is sometimes known as \"la tierra de María Santísima\" (\"the land of Most Holy Mary\"). Also characteristic are the processions during Holy Week, in which thousands of penitents (known as \"nazarenos\") sing saetas. Andalusia is the site of such pilgrim destinations as the Santuario de Nuestra Señora de la Cabeza in Andújar and the Hermitage of El Rocío in Almonte.\n\nWhile some trace the lineage of the Spanish Fighting Bull back to Roman times, today's fighting bulls in the Iberian peninsula and in the former Spanish Empire trace back to Andalusia in the 15th and 16th centuries. Andalusia remains a center of bull-rearing and bullfighting: its 227 \"fincas de ganado\" where fighting bulls are raised cover . In the year 2000, Andalusia's roughly 100 bullrings hosted 1,139 \"corridas\".\n\nThe oldest bullring still in use in Spain is the neoclassical \"Plaza de toros\" in Ronda, built in 1784. The Andalusian Autonomous Government sponsors the \"Rutas de Andalucía taurina\", a touristic route through the region centered on bullfighting.\n\nThe Andalusian festivals provide a showcase for popular arts and traditional costume. Among the most famous of these are the Seville Fair or \"Feria de Abril\" in Seville, now echoed by smaller fairs in Madrid and Barcelona, both of which have many Andalusian immigrants; the \"Feria de Agosto\" in Málaga; the Feria de Jerez or \"Feria del Caballo\" in Jerez; the Festival of Corpus Christi in Granada; the Feria de Nuestra Señora de la Salud in Córdoba; the Columbian Festivals (\"Fiestas Colombinas\") in Huelva; the Feria de la Virgen del Mar in Almería; and the Feria de San Lucas in Jaén, among many others.\n\nFestivals of a religious nature are a deep Andalusian tradition and are met with great popular fervor. There are numerous major festivals during Holy Week. An annual pilgrimage brings a million visitors to the Hermitage of El Rocío in Almonte (population 16,914 in 2008); similarly large crowds visit the Santuario de Nuestra Señora de la Cabeza in Andújar every April.\n\nOther important festivals are the Carnival of Cádiz and the Fiesta de las Cruces or Cruz de mayo in Granada and Córdoba; in Córdoba this is combined with a competition for among the \"patios\" (courtyards) of the city.\n\nAndalusia hosts an annual festival for the dance of flamenco in the summer-time.\n\nThe Andalusian diet varies, especially between the coast and the interior, but in general is a Mediterranean diet based on olive oil, cereals, legumes, vegetables, fish, dried fruits and nuts, and meat; there is also a great tradition of drinking wine.\n\nFried fish—\"pescaíto frito\"—and seafood are common on the coast and also eaten well into the interior under coastal influence. Atlantic bluefin tuna (\"Thunnus thynnus\") from the Almadraba areas of the Gulf of Cádiz, prawns from Sanlúcar de Barrameda (known as \"langostino de Sanlúcar\"), and deepwater rose shrimp (\"\") from Huelva are all highly prized. Fishing for the transparent goby or \"chanquete\" (\"Aphia minuta\"), a once-popular small fish from Málaga, is now banned because the techniques used to catch them trap too many immature fish of other species.\nThe mountainous regions of the Sierra Morena and Sierra Nevada produce cured hams, notably including \"jamón serrano\" and \"jamón ibérico\". These come from two different types of pig, (\"jamón serrano\" from white pigs, the more expensive \"jamón ibérico\" from the Black Iberian pig). There are several Denominaciones de Origen, each with its own specifications including in just which microclimate region ham of a particular denomination must be cured. \"Plato alpujarreño\" is another mountain specialty, a dish combining ham, sausage, sometimes other pork, egg, potatoes, and olive oil.\n\nConfectionery is popular in Andalusia. Almonds and honey are common ingredients. Many enclosed convents of nuns make and sell pastries, especially Christmas pastries: \"mantecados\", \"polvorones\", \"pestiños\", \"alfajores\", \"yemas de San Leandro\", as well as \"churros\" or \"tejeringos\", meringue cookies (\"merengadas\"), and \"amarguillos\".\n\nCereal-based dishes include \"migas de harina\" in eastern Andalusia (a similar dish to couscous rather than the fried breadcrumb based \"migas\" elsewhere in Spain) and a sweeter, more aromatic porridge called \"poleá\" in western Andalusia.\nVegetables form the basis of such dishes as \"alboronía\" (similar to \"ratatouille\") and the chopped salad known as \"pipirrana\" or \"piriñaca\". Hot and cold soups based in olive oil, garlic, bread, tomato and peppers include \"gazpacho\", \"salmorejo\", \"porra antequerana\", \"ajo caliente\", \"sopa campera\", or—using almonds instead of tomato—\"ajoblanco\".\n\nWine has a privileged place at the Andalusian table. Andalusian wines are known worldwide, especially fortified wines such as sherry (\"jerez\"), aged in soleras. These are enormously varied; for example, dry sherry may be the very distinct \"fino\", \"manzanilla\", \"amontillado\", \"oloroso\", or \"Palo Cortado\" and each of these varieties can each be sweetened with Pedro Ximénez or Moscatel to produce a different variety of sweet sherry. Besides sherry, Andalucía has five other Denominaciones de Origen for wine: D.O. Condado de Huelva, D.O. Manzanilla-Sanlúcar de Barrameda, D.O. Málaga, D.O. Montilla-Moriles, and D.O. Sierras de Málaga. Most Andalusian wine comes from one of these regions, but there are other historic wines without a Protected Geographical Status, for example Tintilla de Rota, Pajarete, Moscatel de Chipiona and Mosto de Umbrete.\n\nAndalusia also produces D.O. vinegar and brandy: D.O. Vinagre de Jerez and D.O. Brandy de Jerez.\n\nThe traditional dress of 18th-century Andalusia was strongly influenced by \"majismo\" within the context of \"casticismo\" (purism, traditionalism, authenticity). The archetype of the \"majo\" and \"maja\" was that of a bold, pure Spaniard from a lower-class background, somewhat flamboyant in his or her style of dress. This emulation of lower-class dress also extended to imitating the clothes of brigands and Romani (\"Gypsy\") women.\nThe Museum of Arts and Traditions of Sevilla has collected representative samples of a great deal of the history of Andalusian dress, including examples of such notable types of hat as the \"sombrero cordobés, \"sombrero calañés, \"sombrero de catite\" and the \"pavero\", as well as the \"traje corto\" and \"traje de flamenca\".\n\nAndalusia has a great artisan tradition in tile, leather (\"see Shell cordovan\"), weaving (especially of the heavy \"jarapa\" cloth), marquetry, and ceramics (especially in Jaén, Granada, and Almería), lace (especially Granada and Huelva), embroidery (in Andévalo), ironwork, woodworking, and basketry in wicker, many of these traditions a heritage of the long period of Muslim rule.\n\nAndalusia is also known for its dogs, particularly the Andalusian Hound, which was originally bred in the region. Dogs, not just andalusian hounds, are very popular in the region.\n\nAndalusian equestrianism, institutionalized in the Royal Andalusian School of Equestrian Art is known well beyond the borders of Spain. The Andalusian horse is strongly built, compact yet elegant, distinguished in the area of dressage and show jumping, and is also an excellent horse for driving. They are known for their elegant \"dancing\" gait.\n\nIn Andalusia, as throughout Spain, football is the predominant sport. Introduced to Spain by British men who worked in mining for Rio Tinto in the province of Huelva, the sport soon became popular with the local population. As Spain's oldest existing football club, Recreativo de Huelva, founded 1889, is known as \"El Decano\" (\"the Dean\").\n\nFor the 2015/16 season, four Andalusian clubs will compete in Spain's First Division \"La Liga\": Granada CF, Málaga CF, Real Betis and Sevilla FC. Betis won La Liga in 1934–35 and Sevilla in the 1945–46 season. The four other Andalusian teams, Córdoba CF and UD Almería, play in the Segunda División, whilst Recreativo de Huelva, Spain's oldest club, and Real Jaén participate in the Segunda División B.\n\nThe Andalusia autonomous football team is not in any league, and plays only friendly matches. In recent years, they have played mostly during the Christmas break of the football leagues. They play mostly against national teams from other countries, but would not be eligible for international league play, where Spain is represented by a single national team.\n\nIn recent decades, basketball has become increasingly popular, with CB Málaga, also known as Unicaja Málaga who have won the Liga ACB in 2007 and the Korać Cup in 2001 and usually play the Euroleague, CB Sevilla (Banca Cívica) and CB Granada competing at the top level in the Liga ACB.\n\nUnlike basketball, handball has never really taken off in Andalusia. There is one Andalusian team in the Liga Asobal, Spain's premier handball league: BM Puente Genil, playing in the provincia of Córdoba.\n\nAndalusia's strongest showing in sports has been in table tennis. There are two professional teams: Cajasur Priego TM and Caja Granada TM, the latter being Spain's leading table tennis team, with more than 20 league championships in nearly consecutive years and 14 consecutive Copas del Rey, dominating the Liga ENEBÉ. Cajasur is also one of the league's leading teams. \n\n220 Andalusian athletes have competed in a total of 16 summer or winter Olympic Games. The first was Leopoldo Sáinz de la Maza, part of the silver-medal-winning polo team at the 1920 Summer Olympics in Antwerp, Belgium.\n\nIn all, Andalusians have won 6 gold medals, 11 silver, and 2 bronze. Winners of multiple medals include the Cordoban boxer Rafael Lozano (bronze in the 1996 Summer Olympics at Atlanta, Georgia, US, and silver in the 2000 Summer Olympics in Sydney, Australia); sailor Theresa Zabell, Malagueña by adoption (gold medals at Barcelona in 1992 and Atlanta in 1996). Other notable winners have been Granadan tennis player Manuel Orantes (silver in the men's singles of the demonstration tournament in Mexico City in 1968), Jerezano riders Ignacio Rambla and Rafael Soto (silver in dressage in Athens in 2004) and the racewalker Paquillo Fernández from Guadix (silver in Athens in 2004).\n\nThe largest number of Olympic appearances were by the Malagueña swimmer María Peláez (five appearances), the Granadan skier María José Rienda (four), the Sevillian rider Luis Astolfi (four), and the Sevillian rower Fernando Climent Huerta (four, including a silver at Los Angeles, California, US, in 1984.\n\nSeville has been a pre-candidate to host the Summer Olympics in two occasions, 2004 and 2008, and Granada has been a pre-candidate to host the winter Olympics; neither has ever succeeded in its candidature. The ski resort of Sierra Nevada, near Granada, has however hosted the 1996 Alpine World Ski Championships, and Granada hosted the 2015 Winter Universiade.\n\nOther sporting events in Andalusia include surfing, kitesurfing and windsurfing competitions at Tarifa, various golf tournaments at courses along the coast, and horse racing and polo at several locations in the interior. Andalusia hosted the 1999 World Championships in Athletics (Seville), the 2005 Mediterranean Games (Almería) and the FIS Alpine World Ski Championships 1996 (Granada), among other major events. There is also the annual Vuelta a Andalucía bicycle road race and the Linares chess tournament.\n\nAndalusia has had a sister region relationship with Buenos Aires, Argentina, since 2001.\n\n\n", "id": "2736", "title": "Andalusia"}
{"url": "https://en.wikipedia.org/wiki?curid=2739", "text": "Abhorrers\n\nAbhorrers, the name given in 1679 to the persons who expressed their abhorrence at the action of those who had signed petitions urging King Charles II of England to assemble Parliament.\n\nFeeling against Catholics, and especially against James, Duke of York, was running strongly; the Exclusion Bill had been passed by the House of Commons, and the popularity of James Scott, 1st Duke of Monmouth, was very great.\n\nTo prevent this bill from passing into law, Charles had dissolved parliament in July 1679, and in the following October had prorogued its successor, which became known as the Exclusion Bill Parliament, without allowing it to meet. He was then deluged with petitions urging him to call it together, and this agitation was opposed by Sir George Jeffreys and Francis Wythens, who presented addresses expressing \"abhorrence\" of the \"Petitioners,\" and thus initiated the movement of the abhorrers, who supported the action of the king. \"The frolic went all over England,\" says Roger North; and the addresses of the Abhorrers which reached the king from all parts of the country formed a counterblast to those of the Petitioners. It is said that the terms Whig and Tory were first applied to English political parties in consequence of this dispute.\n", "id": "2739", "title": "Abhorrers"}
{"url": "https://en.wikipedia.org/wiki?curid=2740", "text": "Abiathar\n\nAbiathar (אביתר, \"Ebyathar\", \"Evyatar\", \"the [divine] father is pre-eminent\" or \"father of plenty\"), in the Hebrew Bible, son of Ahimelech or Ahijah, High Priest at Nob, the fourth in descent from Eli (1 Sam. 23:6) and the last of Eli's House. The only one of the priests to escape from Saul's massacre, he fled to David at Keilah, taking with him the ephod and other priestly regalia (1 Sam. 22:20 f., 23:6, 9). He was of great service to David, especially at the time of the rebellion of Absalom (2 Sam. 15:24, 29, 35, 20:25). In 1 Kings 4:4 Zadok and Abiathar are found acting together as priests under Solomon. In 1 Kings 1:7, 19, 25, however, Abiathar appears as a supporter of Adonijah, and in 2:22 and 26 it is said that he was deposed by Solomon and banished to Anathoth. In 2 Sam. 8:17 \"Abiathar, the son of Achimelech\" should be read, with the Syriac, for \"Achimelech, the son of Abiathar.\"\n\nA similar confusion occurs in Gospel of Mark 2:26: in reporting Jesus' words, the evangelist used the name Abiathar when we might expect to see Jesus mention his father Ahimelech. Suggestions made to resolve the difficulty — e.g. that father and son each bore the same double name, or that Abiathar officiated during his father's lifetime and in his father's stead—have been supported by great names, but have not been fully accepted.\n\nWhen his father and the priests of Nob were slain on the command of Saul, Abiathar escaped, bearing with him the ephod. Rabbinical literature that linked the later extermination of the male descendants of David with the priests of Nob, also link the survival of David's descendant Joash with that of Abiathar. (Sanh. 95b)\n\nAbiathar joined David, who was then in the cave of Adullam (1 Sam. 22:20-23; 23:6). He remained with David, and became priest of the party of which he was the leader (1 Sam. 30:7). When David ascended the throne of Judah, Abiathar was appointed High Priest (1 Chr. 15:11; 1 Kings 2:26) and the \"king's counselor\" (1 Chr. 27:33-34). Meanwhile, Zadok, of the house of Eleazar, had been made High Priest. According to the Jewish Encyclopedia Abiathar was deposed from office when he was deserted by the Holy Spirit without which the Urim and Thummin could not be consulted. Another version says he was Co-Pontiff with Zadok during King David. He supported Prince Adonijah over Prince Solomon, and was deposed by him and exiled in Anathoth.\n\nThese appointments continued in force till the end of David's reign (1 Kings 4:4). Abiathar was deposed (the sole historical instance of the deposition of a high priest) and banished to his home at Anathoth by Solomon, because he took part in the attempt to raise Adonijah to the throne. The priesthood thus passed from the house of Ithamar (1 Sam. 2:30-36; 1 Kings 1:19; 2:26, 27). Zadok now became sole high priest. Abiathar's removal from the Priesthood fulfilled that other part of the curse on the House of Eli—that the Priesthood would pass out of the House of Eli.\n\nIn Georgian traditions, Abiathar and Sidonia were a legendary Jewish priest of Mtskheta and his daughter. Abiathar is said to have been the first person Saint Nino converted to Christianity.\n\n\"Abiathar\" (pronounced \"Abiathar\" (A·bi′a·thar) in Modern Hebrew) is sometimes used a male given name in contemporary Israel (see Eviatar Banai, Eviatar Zerubavel, Eviatar Manor).\n", "id": "2740", "title": "Abiathar"}
{"url": "https://en.wikipedia.org/wiki?curid=2741", "text": "Abigail\n\nAbigail (, spelled \"Abigal\" in in the American Standard Version but not in the King James Version) was the wife of Nabal; she became a wife of David after Nabal's death (1 Samuel ). Abigail is David's third wife, after Saul's daughter, Michal, whom Saul later married to Palti, son of Laish when David went into hiding, and Ahinoam.\n\nShe became the mother of one of David's sons, who is listed in the Book of Chronicles under the name \"Daniel\", in the Masoretic Text of the Books of Samuel as \"Chileab,\" and in the Septuagint text of 2 Samuel 3:3 as Δαλουια, \"Dalouia\".\n\nIn 1 Samuel 25, Nabal demonstrates ingratitude towards David, and Abigail attempts to placate David in order to stop the future King from taking revenge. She gives him food, and speaks to him, urging him not to \"have on his conscience the staggering burden of needless bloodshed\" (verse 31, NIV) and reminding him that God will make him a \"lasting dynasty\" (verse 28). Jon Levenson calls this an \"undeniable adumbration\" of Nathan's prophecy in 2 Samuel 7. Alice Bach notes that Abigail pronounces a \"crucial prophecy,\" and the Talmud regards her as one of the Tanakh's seven female prophets. Levenson, however, suggests that she \"senses the drift of history\" from intelligence rather than from special revelation.\n\nAfter Abigail reveals to Nabal what she has done, \"Yahweh struck Nabal and he died,\" (v.38), after which David married her. Abigail is described as intelligent and beautiful. The Talmud amplifies this idea, mentioning her as being one of the \"four women of surpassing beauty in the world,\" (the other three being Rahab, Sarah, and Esther). As the wife of the wealthy Nabal, she is also a woman of high socioeconomic status. Whether David married her because he was attracted to her, or as an astute political move, or both is unclear.\n\nAbigail and David's third wife, Ahinoam the Jezreelite, accompany David and his war band when they seek refuge in Philistine territory. While David and his men were encamped near Jezreel, and when they are captured by Amalekites raided the town of Ziglak and carried off the women and children. David led the pursuit and they were subsequently rescued. Both wives then settle with David in Hebron, where Abigail gives birth to David’s second son, Chileab (also called Daniel).\n\nAbigail is also listed as one of the seven Jewish women prophets, the other six being Miriam, Deborah, Hannah, Sarah, Huldah,and Esther. In terms of her moral character, Abraham Kuyper argues that Abigail's conduct indicates \"a most appealing character and unwavering faith,\" but Alice Bach regards her as subversive.\n\nAdele Berlin contrasts the story of Abigail with that of Bathsheba. In one, the wife prevents David from murdering her foolish and greedy husband. In the second, David orders the murder of a good man because he desires his wife. \"In the Abigail story, David, the potential king, is seen as increasingly strong and virtuous, whereas in the Bathsheba story, the reigning monarch shows his flaws ever more overtly and begins to lose control of his family.\"\n\nLevenson and Halpern suggest that Abigail may, in fact, also be the same person as Abigail, mother of Amasa. Richard M. Davidson, however, points out that \"on the basis of the final form of Old Testament canon, references to Abigail in the biblical accounts indicate two different individuals.\"\n\nAbigail's self-styling as a \"handmaid\" led to \"Abigail\" being the traditional term for a waiting-woman, for example as the \"waiting gentlewoman\" in Beaumont and Fletcher's \"The Scornful Lady\", published in 1616. Jonathan Swift and Henry Fielding use \"Abigail\" in this generic sense, as does Charlotte Brontë. Anthony Trollope makes two references to \"the abigail\" (all lower case) in \"The Eustace Diamonds\", at the beginning of Chapter 42, whilst Thomas Mann makes the same reference at the start of the second chapter of Part 2 in Buddenbrooks (published in 1901). William Rose Benet notes the notoriety of Abigail Hill, better known as \"Mrs Masham\", a lady-in-waiting to Queen Anne. George MacDonald Fraser makes mention of \"an \"abigail\" fussing about the room\" in his novel \"Flashman\" from \"The Flashman Papers\" series.\n\nAbigail is a featured figure on Judy Chicago's installation piece \"The Dinner Party\", being represented in one of the 999 tiles of the \"Heritage Floor.\"\n\n", "id": "2741", "title": "Abigail"}
{"url": "https://en.wikipedia.org/wiki?curid=2742", "text": "Abila\n\nAbila is the name of several places:\n\n\n", "id": "2742", "title": "Abila"}
{"url": "https://en.wikipedia.org/wiki?curid=2745", "text": "Azad Kashmir\n\nAzad Jammu and Kashmir ( \"Āzād Jammū̃ o Kaśmīr\"), abbreviated as AJK and commonly known as Azad Kashmir, is a self-governing administrative division of Pakistan. The territory lies west of the Indian-administered state of Jammu and Kashmir, and was previously part of the former princely state of Jammu and Kashmir, which ceased to exist as a result of the first Kashmir war fought between India and Pakistan in 1947.\n\nAzad Kashmir is part of the greater Kashmir region, which is the subject of a long-running conflict between India and Pakistan. The territory shares a border with Gilgit–Baltistan, together with which it is referred to by the United Nations and other international organisations as \"Pakistan-administered Kashmir\".\nThe territory also borders Pakistan's Punjab province to the south and Khyber Pakhtunkhwa province to the west. To the east, Azad Kashmir is separated from the Indian-administered state of Jammu and Kashmir by the Line of Control, the \"de facto\" border between India and Pakistan. Azad Kashmir has a total area of , with an estimated population of around 4.6 million people.\n\nThe territory has a parliamentary form of government modeled after the Westminster system, with its capital located at Muzaffarabad. The President of Azad Kashmir is the constitutional head of the state, while the prime minister, supported by a Council of Ministers, is the chief executive. The unicameral Azad Jammu & Kashmir Legislative Assembly elects both the prime minister and president. The state has its own Supreme Court and a High Court, while the Government of Pakistan's Ministry of Kashmir Affairs serves as a link between it and Azad Kashmir's government. Neither Azad Kashmir nor Gilgit-Baltistan elect members to Pakistan's National Assembly.\n\nThe 2005 earthquake killed 100,000 people and left another three million people displaced, with widespread devastation. Since then, with help from the Government of Pakistan and foreign donors, reconstruction of infrastructure is underway. Azad Kashmir's economy largely depends on agriculture, services, tourism, and remittances sent by members of the British Mirpuri community. Nearly 87% of the households own farms in Azad Kashmir, while the region has a literacy rate of approximately 72% and has the highest school enrollment in Pakistan.\n\nAt the time of the Partition of India in 1947, the British abandoned their suzerainty over the princely states, which were left with the options of joining India or Pakistan or remaining independent. Hari Singh, the maharaja of Jammu and Kashmir, wanted his state to remain independent. Muslims in Western Jammu province (current day Azad Kashmir) and the Frontier Districts Province (current day Gilgit-Baltistan) had wanted to join Pakistan.\n\nIn Spring 1947, an uprising against the Maharaja broke out in Poonch, an area bordering the Rawalpindi division of West Punjab. Maharaja's administration is said to have started levying punitive taxes on the peasantry which provoked a local revolt and the administration resorted to brutal suppression. The area's population, swelled by recently demobilised soldiers following World War II, rebelled against the Maharaja's forces and gained control of almost the entire district. Following this victory, the pro-Pakistan chieftains of the western districts of Muzaffarabad, Poonch and Mirpur proclaimed a provisional Azad Jammu and Kashmir government in Rawalpindi on October 3, 1947. Khwaja Ghulam Nabi Gilkar, under the assumed name \"Mr. Anwar,\" issued a proclamation in the name of the provisional government in Muzaffarabad. However, this government quickly fizzled out with the arrest of Anwar in Srinagar. On October 24, a second provisional government of Azad Kashmir was established at Palandri under the leadership of Sardar Ibrahim.\n\nOn October 21, several thousand Pashtun tribesmen from North-West Frontier Province poured into Jammu and Kashmir to liberate it from the Maharaja's rule. They were led by experienced military leaders and were equipped with modern arms. The Maharaja's crumbling forces were unable to withstand the onslaught. The raiders captured the towns of Muzaffarabad and Baramulla, the latter northwest of the state capital Srinagar. On October 24, the Maharaja requested military assistance from India, which responded that it was unable to help him unless he acceded to India. Accordingly, on October 26, 1947, Maharaja Hari Singh signed an Instrument of Accession, handing over control of defence, external affairs and communications to the Government of India in return for military aid. Indian troops were immediately airlifted into Srinagar. Pakistan intervened subsequently. Fighting ensued between the Indian and Pakistani armies, with the two areas of control more or less stabilised around what is now known as the \"Line of Control\".\n\nIndia later approached the United Nations, asking it to resolve the dispute, and resolutions were passed in favour of the holding of a plebiscite with regard to Kashmir's future. However, no such plebiscite has ever been held on either side, since there was a precondition which required the withdrawal of the Pakistani Army along with the non-state elements and the subsequent partial withdrawal of the Indian Army. from the parts of Kashmir under their respective control – a withdrawal that never took place. In 1949, a formal cease-fire line separating the Indian- and Pakistani-controlled parts of Kashmir came into effect.\n\nFollowing the 1949 cease-fire agreement with India, the government of Pakistan divided the northern and western parts of Kashmir that it occupied at the time of cease-fire into the following two separately-controlled political entities:\n\nAt one time under Pakistani control, Kashmir's Shaksgam tract, a small region along the northeastern border of Gilgit–Baltistan, was provisionally ceded by Pakistan to the People's Republic of China in 1963 and now forms part of China's Xinjiang Uygur Autonomous Region.\n\nIn 1972, the then current border between the Indian and Pakistani controlled parts of Kashmir was designated as the \"Line of Control\". This line has remained unchanged since the 1972 Simla Agreement, which bound the two countries \"to settle their differences by peaceful means through bilateral negotiations\". Some political experts claim that, in view of that pact, the only solution to the issue is mutual negotiation between the two countries without involving a third party such as the United Nations. The 1974 Interim Constitution Act was passed by the 48-member Azad Jammu and Kashmir unicameral assembly.\n\nAzad Jammu and Kashmir (AJK) is a self-governing state under Pakistani control, but under Pakistan's constitution the state is informally part of the country. Pakistan is administering the region as a self-governing territory rather than incorporating it in the federation since the UN-mandated ceasefire. Azad Kashmir has its own elected President, Prime Minister, Legislative Assembly, High Court, with Azam Khan as its present chief justice, and official flag.\n\nAzad Kashmir's financial matters, i.e., budget and tax affairs, are dealt with by the Azad Jammu and Kashmir Council rather than by Pakistan's Central Board of Revenue. The Azad Jammu and Kashmir Council is a supreme body consisting of 14 members, 8 from the government of Azad Jammu and Kashmir and 6 from the government of Pakistan. Its chairman/chief executive is the prime minister of Pakistan. Other members of the council are the president and the prime minister of Azad Kashmir(or and individual nominated by her/him) and 6 members of the AJK Legislative Assembly. Azad Kashmir Day is celebrated in Azad Jammu and Kashmir on October 24, which is the day that the Azad Jammu and Kashmir government was created in 1947. Pakistan has celebrated Kashmir Solidarity Day on February 5 of each year since 1990 as a day of protest against India's \"de facto\" sovereignty over its State of Jammu and Kashmir. That day is a national holiday in Pakistan. Kashmiris in Azad Kashmir observe the Kashmir Black Day on October 27 of each year since 1947 as day of protest against military occupation in Indian controlled Jammu and Kashmir.\n\nBrad Adams the Asia director at the U.S. based NGO Human Rights Watch has said in 2006; \"Although 'azad' means 'free,' the residents of Azad Kashmir are anything but, the Pakistani authorities govern Azad Kashmir government with tight controls on basic freedoms.\" Scholar Christopher Snedden has observed that despite tight controls the people of Azad Kashmir have generally accepted whatever Pakistan has done to them, which in any case has varied little from how most Pakistanis have been treated (by Pakistan). According to Christopher Snedden one of the reasons for this was that the people of Azad Kashmir had always wanted to be a part of Pakistan.\n\nConsequently, having little to fear from a pro-Pakistan population devoid of options, Pakistan imposed its will through the Federal Ministry of Kashmir Affairs and failed to empower the people of Azad Kashmir, allowing genuine self-government for only a short period in the 1970s. The Interim Constitution of the 1970s only allows the political parties that pay allegiance to Pakistan: \"No person or political party in Azad Jammu and Kashmir shall be permitted... activities prejudicial or detrimental to the State's accession to Pakistan.\" The pro-independence Jammu and Kashmir Liberation Front has never been allowed to contest elections in Azad Kashmir. While the Interim Constitution does not give them a choice, the people of Azad Kashmir have not considered any option other than joining Pakistan. Except in the legal sense, Azad Kashmir has been fully integrated into Pakistan.\n\nAccording to the project report by the Asian Development Bank; The Asian Development Bank has set out development goals for Azad Kashmir in the areas of Health, Education, Nutrition and Social development. The whole project is estimated to cost $76 million Dollars. Germany between 2006 and 2014 has also donated $38,180,000 towards the AJK Health Infrastructure Programme.\n\nThe state is administratively divided into three divisions which, in turn, are divided into ten districts.\n\nThe northern part of Azad Jammu and Kashmir encompasses the lower part of the Himalayas, including Jamgarh Peak (15,531 feet [4,734 meters]). However, Sarwali peak in the Neelum Valley is the highest peak in the state. Fertile, green, mountainous valleys are characteristic of Azad Kashmir's geography, making it one of the most beautiful regions on the subcontinent.\n\nThe southern parts of Azad Kashmir including Bhimber, Mirpur and Kotli districts has extremely hot weather in summers and moderate cold weather in winters. It receives rains mostly in monsoon weather.\n\nIn the central and northern parts of state weather remains moderate hot in summers and very cold and chilly in winter. Snow fall also occurs there in December and January.\n\nThis region receives rainfall in both winters and summers. Muzaffarabad and Pattan are among the wettest areas of the state. Throughout most of the region, the average rainfall exceeds 1400 mm, with the highest average rainfall occurring near Muzaffarabad (around 1800 mm). During summer, monsoon floods of the Jhelum and Leepa rivers are common, due to high rainfall and melting snow.\n\nAzad Jammu and Kashmir has an almost entirely Muslim population. Most residents of the region are not ethnic Kashmiris. The majority of people in Azad Kashmir are ethnically Punjabi. While Urdu is the official language of the region, other languages commonly spoken are Pahari, Gojri and Potohari. The main communities living in this region are as follows:\n\nThe culture of Azad Kashmir has many similarities to that of northern Punjabi (Potohar) culture in Punjab province. The natives of Azad Kashmir speak Urdu, Potwari, and the Pahari languages. The Kashmiri language is spoken by hardly 5% of Azad Kashmir's population according to Kashmiri journalist Shujaat Bukhari. Professor Khawaja Abdul Rehman states that the Kashmiri language is on the verge of dying out in the Neelam Valley.\n\nThe traditional dress of the women is the shalwar kameez in Pahari style. The shalwar kameez is commonly worn by both men and women. Women use shawl to cover their head and upper body.\n\nHistorically the economy of these areas now called ‘Azad’ Kashmir has been agricultural which meant that land was the main source or mean of production. This means that all food for immediate and long term consumption was produced from land. The produce included various crops, fruits, vegetables etc. Land was also the source of other livelihood necessities such as wood, fuel, grazing for animals which then turned into dairy products. Because of this land was also the main source of revenue for the governments whose primary purpose for centuries was to accumulate revenue.\n\nAgriculture is a major part of Azad Kashmir's economy. Low-lying areas that have high populations grow crops like barley, mangoes, millet, corn (maize), and wheat, and also raise cattle. In the elevated areas that are less populated and more spread-out, forestry, corn, and livestock are the main sources of income. There are mineral and marble resources in Azad Kashmir close to Mirpur and Muzaffarabad. There are also graphite deposits at Mohriwali. There are also reservoirs of low-grade coal, chalk, bauxite, and zircon. Local household industries produce carved wooden objects, textiles, and dhurrie carpets. There is also an arts and crafts industry that produces such cultural goods as namdas, shawls, pashmina, pherans, Papier-mâché, basketry copper, rugs, wood carving, silk and woolen clothing, patto, carpets, namda gubba, and silverware. Agricultural goods produced in the region include mushrooms, honey, walnuts, apples, cherries, medicinal herbs and plants, resin, deodar, kail, chir, fir, maple, and ash timber.\n\nThe migration to UK was accelerated and by the completion of Mangla Dam in 1967 the process of ‘chain migration’ became in full flow. Today, remittances from British Mirpuri community make a critical role in AJK's economy. In the mid-1950s various economic and social development processes were launched in Azad Kashmir. In the 1960s, with the construction of the Mangla Dam in Mirpur District, the Azad Jammu and Kashmir Government began to receive royalties from the Pakistani government for the electricity that the dam provided to Pakistan. During the mid-2000s, a multibillion-dollar reconstruction began in the aftermath of the 2005 Kashmir earthquake.\n\nIn addition to agriculture, textiles, and arts and crafts, remittances have played a major role in the economy of Azad Kashmir. One analyst estimated that the figure for Azad Kashmir was 25.1% in 2001. With regard to annual household income, people living in the higher areas are more dependent on remittances than are those living in the lower areas. In the latter part of 2006, billions of dollars for development were mooted by international aid agencies for the reconstruction and rehabilitation of earthquake-hit zones in Azad Kashmir, though much of that amount was subsequently lost in bureaucratic channels, leading to considerable delays in help getting to the most needy. Hundreds of people continued to live in tents long after the earthquake. A land-use plan for the city of Muzaffarabad was prepared by the Japan International Cooperation Agency.\n\nKashmir as a whole is the one of the most beautiful regions in the world. Some well-known and popular tourist destinations are the following:\n\n\nThe literacy rate in Azad Kashmir was 62% in 2004, higher than in any region in Pakistan. However, only 2.2% were graduates, compared to the average of 2.9% for Pakistan.\n\nThe following is a list of universities recognised by Higher Education Commission of Pakistan (HEC):\n\nThe following is a list of undergraduate medical institutions recognised by Pakistan Medical and Dental Council (PMDC) as of 2013.\n\nIn terms of sports, football, cricket and volleyball are very popular in Azad Kashmir. Many tournaments are also held throughout the year and in the holy month of Ramazan night time floodlit tournaments are also organised.\n\n\nMirpur has a cricket stadium (Quaid-e-Azam Stadium) which has been taken over by the Pakistan Cricket Board for renovation to bring it up to International standards. There is also a cricket stadium in Muzaffarabad with the capacity of 8,000 people. This stadium has hosted 8 matches of Inter-District Under 19 Tournament 2013.\n\nThere are also registered football clubs namely, Pilot Football Club, Youth Football Club, Kashmir National FC and Azad Super FC.\n\n\n\n\n", "id": "2745", "title": "Azad Kashmir"}
{"url": "https://en.wikipedia.org/wiki?curid=2747", "text": "Arabian Sea\n\nThe Arabian Sea is a region of the northern Indian Ocean bounded on the north by Pakistan and Iran, on the west by northeastern Somalia and the Arabian Peninsula, and on the east by India. Historically the sea has been known by other names including the Erythraean Sea and the Persian Sea. Its total area is and its maximum depth is . The Gulf of Aden is in the southwest, connecting the Arabian Sea to the Red Sea through the strait of Bab-el-Mandeb, and the Gulf of Oman is in the northwest, connecting it to the Persian Gulf.\n\nThe Arabian Sea has been crossed by important marine trade routes since the third or second millennium BCE. Major seaports include Jawaharlal Nehru Port in Mumbai, the Port of Karachi and the Gwadar Port in Pakistan and the Port of Salalah in Oman. Other important ports include in India, Kandla Port, and Mormugao in Goa. The largest islands in the Arabian Sea include Socotra (Yemen), Masirah Island (Oman), Astola Island (Pakistan) and Andrott (India).\n\nThe Arabian Sea's surface area is about . The maximum width of the Sea is approximately , and its maximum depth is . The biggest river flowing into the Sea is the Indus River.\n\nThe Arabian Sea has two important branches — the Gulf of Aden in the southwest, connecting with the Red Sea through the strait of Bab-el-Mandeb; and the Gulf of Oman to the northwest, connecting with the Persian Gulf. There are also the gulfs of Khambhat and Kutch on the Indian coast.\nThe countries with coastlines on the Arabian Sea are Somalia, Djibouti, Yemen, Oman, United Arab Emirates, Iran, Pakistan, India and the Maldives. There are several large cities on the sea's coast including Mumbai, Surat, Karachi, Gwadar, Pasni, Ormara, Aden, Muscat, Keti Bandar, Salalah, Duqm and Trivandrum.\n\nInternational Hydrographic Organization defines the limits of the Arabian Sea as follows:\n\"On the West.\" The Eastern limit of the Gulf of Aden [The meridian of Cape Guardafui (Ras Asir, 51°16'E)].\n\n\"On the North.\" A line joining Ràs al Hadd, East point of Arabia (22°32'N) and Ràs Jiyùni (61°43'E) on the coast of Pakistan.\n\n\"On the South.\" A line running from the South extremity of Addu Atoll (Maldives), to the Eastern extreme of Ràs Hafun (Africa, 10°26'N).\n\n\"On the East.\" The Western limit of the Laccadive Sea [A line running from Sadashivgad Lt. on West Coast of India () to Corah Divh () and thence down the West side of the Laccadive and Maldive Archipelagos to the most Southerly point of Addu Atoll in the Maldives].\nThe Arabian Sea historically and geographically has been referred to by many different names by Arab travellers and European geographers, that include Indian Sea, Persian Sea, Sindhu Sagar, Erythraean Sea, Sindh Sea, and Akhzar Sea.\n\nThe Arabian Sea has been an important marine trade route since the era of the \"coastal sailing vessels\" from possibly as early as the 3rd millennium BCE, certainly the late 2nd millennium BCE through the later days known as the Age of Sail. By the time of Julius Caesar, several well-established combined land-sea trade routes depended upon water transport through the Sea around the rough inland terrain features to its north.\n\nThese routes usually began in the Far East or down river from Madhya Pradesh with transshipment via historic Bharuch (Bharakuccha), traversed past the inhospitable coast of today's Iran then split around Hadhramaut into two streams north into the Gulf of Aden and thence into the Levant, or south into Alexandria via Red Sea ports such as Axum. Each major route involved transhipping to pack animal caravan, travel through desert country and risk of bandits and extortionate tolls by local potentiates.\n\nThis southern coastal route past the rough country in the southern Arabian peninsula (Yemen and Oman today) was significant, and the Egyptian Pharaohs built several shallow canals to service the trade, one more or less along the route of today's Suez canal, and another from the Red Sea to the Nile River, both shallow works that were swallowed up by huge sand storms in antiquity. Later the kingdom of Axum arose in Ethiopia to rule a mercantile empire rooted in the trade with Europe via Alexandria.\n\nJawaharlal Nehru Port in Mumbai is the largest port in the Arabian Sea, and the largest container port in India.\n\nThe Port of Karachi (Urdu: بندر گاہ كراچى, \"\") is Pakistan's largest and busiest seaport, handling about 60% of the nation's cargo (25 million tons per annum). It is located between the Karachi towns of Kiamari and Saddar, close to the main business district and several industrial areas. The geographic position of the port places it in close proximity to major shipping routes such as the Strait of Hormuz. The history of the port is intertwined with that of the city of Karachi. Several ancient ports have been attributed in the area including \"Krokola\", \"Morontobara\" (Woman's Harbour) (mentioned by Nearchus), Barbarikon (the Periplus of the Erythraean Sea, and Debal (a city invaded and captured by the Muslim general Muhammad bin Qasim in 712 AD). There is a reference to the early existence of the port of Karachi in the \"Umdah\", by the Arab navigator Sulaiman al Mahri (AD 1511), who mentions \"Ras al Karazi\" and \"Ras Karashi\" while describing a route along the coast from Pasni to Ras Karashi.\n\nKarachi is also mentioned in the sixteenth century Turkish treatise Mirat ul Memalik (Mirror of Countries, 1557) by the Ottoman captain Seydi Ali Reis, which is a compilation of sailing directions from the Portuguese island of Diu to Hormuz in the Persian Gulf. It warns sailors about whirlpools and advises them to seek safety in \"Kaurashi\" harbour if they found themselves drifting dangerously.\n\nThe gate facing the sea was called \"Kharadar\" (salt gate), and the gate facing the Lyari River was called \"Mithadar\" (sweet gate). The modern neighbourhoods around the location of the gates are called Mithadar and Kharadar. Surrounded by mangrove swamps to the east, the sea to the southwest, and the Lyari River to the north, the town was well defended and engaged in a profitable trade with Muscat and Bahrain.\n\nThe Gwadar Port is a warm-water, deep-sea port situated at Gwadar in Balochistan, Pakistan at the apex of the Arabian Sea and at the entrance of the Persian Gulf, about 460 km west of Karachi and approximately 75 km (47 mi) east of Pakistan's border with Iran. The port is located on the eastern bay of a natural hammerhead-shaped peninsula jutting out into the Arabian Sea from the coastline.\n\nPort of Salalah in Salalah, Oman is also a major port in the area. From a modest start in 1997, the Omani container transhipment port has achieved consistent growth. It is a key container transhipment hub on the Arabian Sea and is often used as the first port of call for vessels whose crew have just been released from the clutches of Somali pirates following ransom payments for withheld vessels and crew.\nThe port also plays host as a supply base for the visiting warships that provide protective escorts for merchant shipping in the sea lanes.\nFrom that dual role has emerged another, one as an intelligence network — both military and civilian — to exchange information on possible pirate sightings and near misses. Also, the International Task Force often uses the port as a base. There is a significant number of warships of all nations coming in and out of the port, which makes it a very safe bubble. The port handled just under 3.5m teu in 2009\n\nMajor Indian ports in the Arabian Sea are Mundra Port, Kandla Port, Nava Sheva, Kochi Port, Mumbai Port, and Mormugão.\n\nThere are several islands in the Arabian Sea, with the largest being Socotra (Yemen), Masirah (Oman), Astola Island (Pakistan) and Andrott (India).\nAstola Island, also known as \"Jezira Haft Talar\" () or 'Island of the Seven Hills', is a small, uninhabited island in the northern tip of the Arabian Sea in Pakistan's territorial waters. It is a popular eco-tourism destination in the region. Overnight tourists camp on the island and bring their own provisions. Camping, fishing and scuba-diving expeditions are popular. It is also a site for observing turtle breeding. Endangered animals such as the green turtle (\"Chelonia mydas\") and the Hawksbill turtle (\"Eretmochelys imbracata\") nest on the beach at the foot of the cliffs. The island is also a very important area for endemic reptiles such as the Astola Viper (\"Echis carinatus astolae\").\nSocotra ( '), also spelled Soqotra, is the largest island, being part of a small archipelago of four islands. It lies some east of the Horn of Africa and south of the Arabian Peninsula. The island is very isolated and through the process of speciation, a third of its plant life is found nowhere else on the planet. It has been described as the most alien-looking place on Earth.\n\nMasirah () is an island off the East coast of Oman. The main industries here are fishing and traditional textile manufacturing. Formerly, traditional ship building was important. The rugged terrain of the island and surrounding rough coastline has led to the appearance of many wrecked dhows on the beaches of the island, most of them well preserved by the salt water and intense heat. The ocean bottom environment surrounding Masirah is hostile as the majority of the area is covered in either sand or hard rock. Despite the poor quality ocean bottom, the area is very productive with marine fisheries, and any hard objects (barrels, engines) are immediately colonized by local fauna.\n\n\n", "id": "2747", "title": "Arabian Sea"}
{"url": "https://en.wikipedia.org/wiki?curid=2752", "text": "Aspartame\n\nAspartame (APM; or ) is an artificial, non-saccharide sweetener used as a sugar substitute in some foods and beverages. In the European Union, it is codified as E951. Aspartame is a methyl ester of the aspartic acid/phenylalanine dipeptide. It was first sold under the brand name NutraSweet. It was first synthesized in 1965, and the patent expired in 1992.\n\nThe safety of aspartame has been the subject of several political and medical controversies, United States congressional hearings and Internet hoaxes since its initial approval for use in food products by the U.S. Food and Drug Administration (FDA) in 1981. The European Food Safety Authority concluded in its 2013 re-evaluation that aspartame and its breakdown products are safe for human consumption at current levels of exposure, corroborating other medical reviews. However, because its breakdown products include phenylalanine, aspartame must be avoided by people with the genetic condition phenylketonuria (PKU).\n\nAspartame is a methyl ester of the dipeptide of the natural amino acids -aspartic acid and -phenylalanine. Under strongly acidic or alkaline conditions, aspartame may generate methanol by hydrolysis. Under more severe conditions, the peptide bonds are also hydrolyzed, resulting in free amino acids.\n\nWhile known aspects of synthesis are covered by patents, many details are proprietary. Two approaches to synthesis are used commercially. In the chemical synthesis, the two carboxyl groups of aspartic acid are joined into an anhydride, and the amino group is protected by converting it to a functional group that will not interfere in the next reaction. Phenylalanine is converted to its methyl ester and combined with the \"N\"-protected aspartic anhydride; then the protecting group is removed from aspartic nitrogen by acid hydrolysis. The drawback of this technique is that a byproduct, the bitter-tasting β-form, is produced when the wrong carboxyl group from aspartic acid links to phenylalanine. A process using an enzyme from \"Bacillus thermoproteolyticus\" to catalyze the condensation of the chemically altered amino acids will produce high yields without the β-form byproduct. A variant of this method, which has not been used commercially, uses unmodified aspartic acid, but produces low yields. Methods for directly producing aspartyl-phenylalanine by enzymatic means, followed by chemical methylation, have also been tried, but not scaled for industrial production.\n\nThe perceived sweetness of aspartame (and other sweet substances like acesulfame K) in humans is due to its binding of the heterodimer G-protein coupled receptor formed by the proteins TAS1R2 and TAS1R3.\n\nAspartame is approximately 200 times sweeter than sucrose (table sugar). Due to this property, even though aspartame produces four kilocalories of energy per gram (/g) when metabolized, the quantity of aspartame needed to produce a sweet taste is so small that its caloric contribution is negligible. The taste of aspartame and other artificial sweeteners differs from that of table sugar in the times of onset and how long the sweetness lasts, though aspartame comes closest to sugar's taste profile among approved artificial sweeteners. The sweetness of aspartame lasts longer than that of sucrose, so it is often blended with other artificial sweeteners such as acesulfame potassium to produce an overall taste more like that of sugar.\n\nLike many other peptides, aspartame may hydrolyze (break down) into its constituent amino acids under conditions of elevated temperature or high pH. This makes aspartame undesirable as a baking sweetener, and prone to degradation in products hosting a high pH, as required for a long shelf life. The stability of aspartame under heating can be improved to some extent by encasing it in fats or in maltodextrin. The stability when dissolved in water depends markedly on pH. At room temperature, it is most stable at pH 4.3, where its half-life is nearly 300 days. At pH 7, however, its half-life is only a few days. Most soft-drinks have a pH between 3 and 5, where aspartame is reasonably stable. In products that may require a longer shelf life, such as syrups for fountain beverages, aspartame is sometimes blended with a more stable sweetener, such as saccharin.\n\nAspartame's major decomposition products are its cyclic dipeptide (in a 2,5-diketopiperazine, or DKP, form), the de-esterified dipeptide (aspartyl-phenylalanine), and its constituent components, phenylalanine, aspartic acid, and methanol. At 180 °C, aspartame undergoes decomposition to form a diketopiperazine derivative.\n\nIn products such as powdered beverages, the amine in aspartame can undergo a Maillard reaction with the aldehyde groups present in certain aroma compounds. The ensuing loss of both flavor and sweetness can be prevented by protecting the aldehyde as an acetal.\n\nDescriptive analyses of solutions containing aspartame report a sweet aftertaste as well as bitter and off-flavor aftertastes.\n\nAspartame was discovered in 1965 by James M. Schlatter, a chemist working for G.D. Searle & Company. Schlatter had synthesized aspartame as an intermediate step in generating a tetrapeptide of the hormone gastrin, for use in assessing an anti-ulcer drug candidate. He discovered its sweet taste when he licked his finger, which had become contaminated with aspartame, to lift up a piece of paper. Torunn Atteraas Garin participated in the development of aspartame as an artificial sweetener.\n\nIn 1975, prompted by issues regarding Flagyl and Aldactone, a U.S. FDA task force team reviewed 25 studies submitted by the manufacturer, including 11 on aspartame. The team reported \"serious deficiencies in Searle's operations and practices\". The FDA sought to authenticate 15 of the submitted studies against the supporting data. In 1979, the Center for Food Safety and Applied Nutrition (CFSAN) concluded, since many problems with the aspartame studies were minor and did not affect the conclusions, the studies could be used to assess aspartame's safety.\n\nIn 1980, the FDA convened a Public Board of Inquiry (PBOI) consisting of independent advisors charged with examining the purported relationship between aspartame and brain cancer. The PBOI concluded aspartame does not cause brain damage, but it recommended against approving aspartame at that time, citing unanswered questions about cancer in laboratory rats.\n\nCiting data from a Japanese study that had not been available to the members of the PBOI, and after seeking advice from an expert panel that found fault with statistical analyses underlying the PBOI's hesitation, yet argued against approval, FDA commissioner Hayes approved aspartame for use in dry goods. In 1983, the FDA further approved aspartame for use in carbonated beverages, and for use in other beverages, baked goods, and confections in 1993. In 1996, the FDA removed all restrictions from aspartame, allowing it to be used in all foods. \n\nSeveral European Union countries approved aspartame in the 1980s, with EU-wide approval in 1994. The European Commission Scientific Committee on Food reviewed subsequent safety studies and reaffirmed the approval in 2002. The European Food Safety Authority reported in 2006 that the previously established Acceptable daily intake was appropriate, after reviewing yet another set of studies.\n\n\nAspartame has been found to be safe for human consumption by more than ninety countries worldwide, with FDA officials describing aspartame as \"one of the most thoroughly tested and studied food additives the agency has ever approved\" and its safety as \"clear cut\", but has been the subject of several controversies, hoaxes and health scares.\n\nInitially aspartame was approved by the U.S. Food and Drug Administration (FDA) in 1974; however, problems with Searle's safety testing program, including testing of aspartame, were discovered subsequently. The approval was rescinded the following year, but after outside reviews of the problematic tests and additional testing, final approval was granted in 1981. Because allegations of conflicts of interest marred the FDA's approval of aspartame, the U.S. Government Accountability Office reviewed the actions of involved officials in 1986 and the approval process in 1987; neither the allegations of conflict of interest nor problems in the final approval process were substantiated.\n\nIn addition, the Centers for Disease Control investigated in 1984 and was unable to find any significant epidemiological associations to serious risk or harm.\n\nSince December 1998, a widely circulated email hoax has cited aspartame as the cause of numerous diseases.\n\nThe weight of existing scientific evidence indicates that aspartame is safe at current levels of consumption as a non-nutritive sweetener. Reviews conducted by regulatory agencies decades after aspartame was first approved have supported its continued availability.\n\nThe safety of aspartame has been studied extensively since its discovery with research that includes animal studies, clinical and epidemiological research, and postmarketing surveillance. Aspartame is one of the most rigorously tested food ingredients. Peer-reviewed comprehensive review articles and independent reviews by governmental regulatory bodies have analyzed the published research on the safety of aspartame and have found aspartame is safe for consumption at current levels. Aspartame has been deemed safe for human consumption by over 100 regulatory agencies in their respective countries, including the UK Food Standards Agency, the European Food Safety Authority (EFSA) and Health Canada.\n\nThe acceptable daily intake (ADI) value for aspartame, as well as other food additives studied, is defined as the \"amount of a food additive, expressed on a body weight basis, that can be ingested daily over a lifetime without appreciable health risk.\" The Joint FAO/WHO Expert Committee on Food Additives (JECFA) and the European Commission's Scientific Committee on Food has determined this value is 40 mg/kg of body weight for aspartame, while FDA has set its ADI for aspartame at 50 mg/kg.\n\nThe primary source for exposure to aspartame in the United States is diet soft drinks, though it can be consumed in other products, such as pharmaceutical preparations, fruit drinks, and chewing gum among others in smaller quantities. A 12 US fluid ounce (355 ml) can of diet soda contains of aspartame, and for a adult, it takes approximately 21 cans of diet soda daily to consume the of aspartame that would surpass the FDA's 50 milligrams per kilogram of body weight ADI of aspartame from diet soda alone.\n\nReviews have analyzed studies which have looked at the consumption of aspartame in countries worldwide, including the United States, countries in Europe, and Australia, among others. These reviews have found that even the high levels of intake of aspartame, studied across multiple countries and different methods of measuring aspartame consumption, are well below the ADI for safe consumption of aspartame. Reviews have also found that populations that are believed to be especially high consumers of aspartame such as children and diabetics are below the ADI for safe consumption, even considering extreme worst-case scenario calculations of consumption.\n\nIn a report released on 10 December 2013, the EFSA said that, after an extensive examination of evidence, it ruled out the \"potential risk of aspartame causing damage to genes and inducing cancer,\" and deemed the amount found in diet sodas an amount safe to consume.\n\nAspartame is rapidly hydrolyzed in the small intestines. Even with ingestion of very high doses of aspartame (over 200 mg/kg), no aspartame is found in the blood due to the rapid breakdown. These metabolites have been studied in a wide range of populations including infants, children, adolescents, and healthy adults. In healthy adults and children, even enormous doses of aspartame do not lead to plasma levels of metabolites that are a concern for safety.\n\nUpon ingestion, aspartame breaks down into residual components, including aspartic acid, phenylalanine, methanol, in ratio of 4:5:1 by mass and further breakdown products including formaldehyde and formic acid. Human studies show that formic acid is excreted faster than it is formed after ingestion of aspartame. In some fruit juices, \"higher\" concentrations of methanol can be found than the amount produced from aspartame in beverages.\n\nAspartic acid (aspartate) is one of the most common amino acids in the typical diet. As with methanol and phenylalanine, intake of aspartic acid from aspartame is less than would be expected from other dietary sources. At the 90th percentile of intake, aspartame provides only between 1% and 2% of the daily intake of aspartic acid. There has been some speculation that aspartame, in conjunction with other amino acids like glutamate, may lead to excitotoxicity, inflicting damage on brain and nerve cells. However, clinical studies have shown no signs of neurotoxic effects, and studies of metabolism suggest it is not possible to ingest enough aspartic acid and glutamate through food and drink to levels that would be expected to be toxic.\n\nThe methanol produced by the metabolism of aspartame is absorbed and quickly converted into formaldehyde and then completely oxidized to formic acid. The methanol from aspartame is unlikely to be a safety concern for several reasons. The amount of methanol in aspartame is less than that found in fruit juices and citrus fruits, and there are other dietary sources for methanol such as fermented beverages. Therefore, the amount of methanol produced from aspartame is likely to be less than that from natural sources. With regard to formaldehyde, it is rapidly converted in the body, and the amounts of formaldehyde from the metabolism of aspartame are trivial when compared to the amounts produced routinely by the human body and from other foods and drugs. At the highest expected human doses of consumption of aspartame, there are no increased blood levels of methanol or formic acid, and ingesting aspartame at the 90th percentile of intake would produce 25 times less methanol than what would be considered toxic.\n\nHigh levels of the naturally occurring essential amino acid phenylalanine are a health hazard to those born with phenylketonuria (PKU), a rare inherited disease that prevents phenylalanine from being properly metabolized. Since individuals with PKU must consider aspartame as an additional source of phenylalanine, foods containing aspartame sold in the United States must state \"Phenylketonurics: Contains Phenylalanine\" on their product labels.\n\nIn the UK, foods that contain aspartame are legally required by the country's Food Standards Agency to list the substance among the product's ingredients and carry the warning \"Contains a source of phenylalanine\" – this is usually at the foot of the list of ingredients. Manufacturers are also required to print '\"with sweetener(s)\" on the label close to the main product name on foods that contain \"sweeteners such as aspartame\" or \"with sugar and sweetener(s)\" on \"foods that contain both sugar and sweetener\".\n\nIn Canada, foods that contain aspartame are legally required by the country to list the substance among the product's ingredients and include a measure of the amount of aspartame per serving. As well, labels must state that the product contains phenylalanine – this is usually in the order of ingredients, contained in brackets.\n\nPhenylalanine is one of the essential amino acids and is required for normal growth and maintenance of life. Concerns about the safety of phenylalanine from aspartame center largely on hypothetical changes in neurotransmitter levels as well as ratios of neurotransmitters to each other in the blood and brain that could lead to neurological symptoms. Reviews of the literature have found no consistent findings to support such concerns, and while high doses of aspartame consumption may have some biochemical effects, these effects are not seen in toxicity studies to suggest aspartame can adversely affect neuronal function. Like methanol, the typical diet will lead to ingestion of significantly higher amounts of phenylalanine than would be expected from aspartame consumption.\nPeople with the genetic disorder phenylketonuria are advised to avoid aspartame as they have a decreased ability to metabolize phenylalanine. Common foods such as milk, meat, and fruits provide far greater amounts of these metabolites in a diet than does aspartame.\n\nIn a study done in 1979, the effect of aspartame ingestion on blood and milk amino acid levels in lactating women was tested. In this study, six women from the ages of 20 to 29 with established lactation were studied after oral administration of aspartame or lactose (50 mg/kg body weight) in a random order, with the intent to study the differences in breast milk between the two. The study resulted with the conclusion that aspartame administration at 50 mg/kg body weight has a small effect upon the milk aspartate levels and although a small increase in aspartate time-effect scores was noted over the four-hour postabsorptive period, no significant difference was noted over the entire 24-hour watching period.\n\nReviews have found no association between aspartame and cancer. These reviews have looked at numerous carcinogenicity studies in animals, epidemiologic studies in humans, as well as \"in vitro\" genotoxicity studies. These studies have found no significant evidence that aspartame causes cancer in animals, damages the genome, or causes cancer in humans at doses currently used. This position is supported by multiple regulatory agencies like the FDA and EFSA as well as scientific bodies such as the National Cancer Institute. Aspartame did not show any DNA-damaging properties either.\n\nConcern about possible carcinogenic properties of aspartame was originally raised and popularized in the mainstream media by John Olney in the 1970s and again in 1996 by suggesting that aspartame may be related to brain tumors. Reviews have found that these concerns were flawed, due to reliance on the ecological fallacy and the purported mechanism of causing tumors being unlikely to actually cause cancer. Independent agencies such as the FDA and National Cancer Institute have reanalyzed multiple studies based on these worries and found no association between aspartame and brain cancer.\n\nAs discussed in the article on controversies around aspartame, the Cesare Maltoni Cancer Research Center of the European Ramazzini Foundation of Oncology and Environmental Sciences released several studies which claimed that aspartame can increase several malignancies in rodents, concluding that aspartame is a potential carcinogen at normal dietary doses. The EFSA and the FDA discounted the study results due to lack of transparency and numerous flaws in the study, finding no reason to revise their previously established acceptable daily intake levels for aspartame.\n\nNumerous allegations have been made via the Internet and in consumer magazines purporting neurotoxic effects of aspartame leading to neurological or psychiatric symptoms such as seizures, headaches, and mood changes. Review of the biochemistry of aspartame has found no evidence that the doses consumed would plausibly lead to neurotoxic effects.\nComprehensive reviews have not found any evidence for aspartame as a cause for these symptoms.\nOne review did provide a theoretical biochemical background of neurotoxicity and suggested further testing.\nHowever, a panel of EFSA experts noted that this review's conclusions were partially based on Internet sources and therefore were not scientifically robust. These experts also concurred with a critique that significant scientific errors were made in the critical review that led to unsubstantiated and misleading interpretations. A review of the pediatric literature did not show any significant findings for safety concerns with regard to neuropsychiatric conditions such as panic attacks, mood changes, hallucinations or with ADHD or seizures.\n\nHeadaches are the most common symptom reported by consumers. While one small review noted aspartame is likely one of many dietary triggers of migraines, in a list that includes \"cheese, chocolate, citrus fruits, hot dogs, monosodium glutamate, aspartame, fatty foods, ice cream, caffeine withdrawal, and alcoholic drinks, especially red wine and beer,\"\nother reviews have noted conflicting studies about headaches\nand still more reviews lack any evidence and references to support this claim.\n\nSince the caloric contribution of aspartame is negligible, it has been used as a means for weight loss through its role as a sugar substitute, with reviews finding that aspartame may aid in weight loss as part of a multidisciplinary weight loss program. On its own, aspartame is not known by medical literature to cause weight gain or weight loss. Although some researchers have stated that aspartame contributes to weight gain, hunger and increase in appetite, broad reviews and regulators conclude that aspartame has no appreciable effect on appetite.\n\nUnder the trade names Equal, NutraSweet, and Canderel, aspartame is an ingredient in approximately 6,000 consumer foods and beverages sold worldwide, including (but not limited to) diet sodas and other soft drinks, instant breakfasts, breath mints, cereals, sugar-free chewing gum, cocoa mixes, frozen desserts, gelatin desserts, juices, laxatives, chewable vitamin supplements, milk drinks, pharmaceutical drugs and supplements, shake mixes, tabletop sweeteners, teas, instant coffees, topping mixes, wine coolers and yogurt. It is provided as a table condiment in some countries. Aspartame is less suitable for baking than other sweeteners, because it breaks down when heated and loses much of its sweetness.\n\nIn 1985, Monsanto Company bought G.D.Searle, and the aspartame business became a separate Monsanto subsidiary, the NutraSweet Company. In March 2000, Monsanto sold it to J.W. Childs Equity Partners II L.P.<ref name=\"http://www.findarticles.com/p/articles/mi_m0EUY/is_22_6/ai_62920821\">J.W. Childs Equity Partners II, L.P , \"Food & Drink Weekly\", 5 June 2000</ref> European use patents on aspartame expired starting in 1987, and the U.S. patent expired in 1992. Since then, the company has competed for market share with other manufacturers, including Ajinomoto, Merisant and the Holland Sweetener Company.\n\nMany aspects of industrial synthesis of aspartame were established by Ajinomoto. In 2004, the market for aspartame, in which Ajinomoto, the world's largest aspartame manufacturer, had a 40 percent share, was 14,000 metric tons a year, and consumption of the product was rising by 2 percent a year. Ajinomoto acquired its aspartame business in 2000 from Monsanto for $67M.\n\nIn 2008, Ajinomoto sued British supermarket chain Asda, part of Wal-Mart, for a malicious falsehood action concerning its aspartame product when the substance was listed as excluded from the chain's product line, along with other \"nasties\". In July 2009, a British court found in favour of Asda. In June 2010, an appeals court reversed the decision, allowing Ajinomoto to pursue a case against Asda to protect aspartame's reputation. Asda said that it would continue to use the term \"no nasties\" on its own-label products, but the suit was settled in 2011 with Asda choosing to remove references to aspartame from its packaging.\n\nIn November 2009, Ajinomoto announced a new brand name for its aspartame sweetener – AminoSweet.\n\nA joint venture of DSM and Tosoh, the Holland Sweetener Company manufactured aspartame using the enzymatic process developed by Toyo Soda (Tosoh) and sold as the brand Sanecta. Additionally, they developed a combination aspartame-acesulfame salt under the brand name Twinsweet. They left the sweetener industry in late 2006, because \"global aspartame markets are facing structural oversupply, which has caused worldwide strong price erosion over the last five years\", making the business \"persistently unprofitable\".\n\nBecause sucralose, unlike aspartame, retains its sweetness after being heated, and has at least twice the shelf life of aspartame, it has become more popular as an ingredient. This, along with differences in marketing and changing consumer preferences, caused aspartame to lose market share to sucralose. In 2004, aspartame traded at about $30/kg and sucralose, which is roughly three times sweeter by weight, at around $300/kg.\n\nAspartame has been falsely claimed to have been originally developed as ant poison. The source for this was a satirical article posted on \"thespoof\" website. Further claims that the substance actually is poisonous to ants were inferred from that online article being quoted as fact by various anti-aspartame websites, and videos of numerous trials of this rumor have been shown on YouTube, or posted on social networks, some even claiming success in eradicating ants with Aspartame or with other sweeteners.\n\n", "id": "2752", "title": "Aspartame"}
{"url": "https://en.wikipedia.org/wiki?curid=2753", "text": "AutoCAD\n\nAutoCAD is a commercial computer-aided design (CAD) and drafting software application. Developed and marketed by Autodesk, AutoCAD was first released in December 1982 as a desktop app running on microcomputers with internal graphics controllers. Prior to the introduction of AutoCAD, most commercial CAD programs ran on mainframe computers or minicomputers, with each CAD operator (user) working at a separate graphics terminal. Since 2010, AutoCAD was released as a mobile- and web app as well, marketed as AutoCAD 360.\n\nAutoCAD is used across a wide range of industries, by architects, project managers, engineers, graphic designers, and many other professionals. It was supported by 750 training centers worldwide in 1994.\n\nAutoCAD was derived from a program begun in 1977 and released in 1979 called Interact CAD, also referred to in early Autodesk documents as MicroCAD, which was written prior to Autodesk's (then Marinchip Software Partners) formation by Autodesk cofounder Mike Riddle.\n\nThe first version by Autodesk was demonstrated at the 1982 Comdex and released that December. As Autodesk's flagship product, by March 1986 AutoCAD had become the most ubiquitous CAD program worldwide. The 2018 release marked the 32th major release of AutoCAD for Windows. The 2014 release marked the fourth consecutive year of AutoCAD for Mac.\n\nThe native file format of AutoCAD is \".dwg\". This and, to a lesser extent, its interchange file format \"DXF\", have become de facto, if proprietary, standards for CAD data interoperability, particularly for 2D drawing exchange. AutoCAD has included support for .dwf, a format developed and promoted by Autodesk, for publishing CAD data.\n\nAutodesk's logo and, respectively, AutoCAD icons have changed for several versions through the years.\n\nESRI ArcMap 10 permits export as AutoCAD drawing files. Civil 3D permits export as AutoCAD objects and as LandXML. Third-party file converters exist for specific formats such as Bentley MX GENIO Extension, PISTE Extension (France), \nISYBAU (Germany), OKSTRA and Microdrainage (UK);\nalso, conversion of .pdf files is feasible, however, the accuracy of the results may be unpredictable or distorted. For example, jagged edges may appear. Several vendors provide on-line conversions for free such as Cometdocs.\n\nAutoCAD and AutoCAD LT are available for English, German, French, Italian, Spanish, Korean, Chinese Simplified, Chinese Traditional, Brazilian Portuguese, Russian, Czech, Polish and Hungarian, Albanian (also through additional Language Packs). The extent of localization varies from full translation of the product to documentation only. The AutoCAD command set is localized as a part of the software localization.\n\nAutoCAD supports a number of APIs for customization and automation. These include AutoLISP, Visual LISP, VBA, .NET and ObjectARX. ObjectARX is a C++ class library, which was also the base for:\nThere are a large number of AutoCAD plugins (add-on applications) available on the application store Autodesk Exchange Apps\nAutoCAD's DXF, drawing exchange format, allows importing and exporting drawing information.\n\nAutodesk has also developed a few vertical programs:\n\n\nfor discipline-specific enhancements.\n\nFor example, AutoCAD Architecture (formerly Architectural Desktop) permits architectural designers to draw 3D objects, such as walls, doors and windows, with more intelligent data associated with them rather than simple objects, such as lines and circles. The data can be programmed to represent specific architectural products sold in the construction industry, or extracted into a data file for pricing, materials estimation, and other values related to the objects represented.\n\nAdditional tools generate standard 2D drawings, such as elevations and sections, from a 3D architectural model. Similarly, Civil Design, Civil Design 3D, and Civil Design Professional support data-specific objects, facilitating easy standard civil engineering calculations and representations.\n\nCivil 3D was originally developed as an AutoCAD add-on by a company in New Hampshire called Softdesk (originally DCA). Softdesk was acquired by Autodesk, and Civil 3D was further evolved.\n\nAutoCAD Architecture (abbreviated as ACA) is a version of AutoCAD with tools and functions specially suited to architectural work.\n\nAutoCAD LT is the lower cost version of AutoCAD, with reduced capabilities, first released in November 1993. Autodesk developed AutoCAD LT to have an entry-level CAD package to compete in the lower price level. AutoCAD LT, priced at $495, became the first AutoCAD product priced below $1000. It is sold directly by Autodesk and can also be purchased at computer stores (unlike the full version of AutoCAD, which must be purchased from official Autodesk dealers).\n\nAs of the 2011 release the AutoCAD LT MSRP has risen to $1200. While there are hundreds of small differences between the full AutoCAD package and AutoCAD LT, there are a few recognized major differences in the software's features:\n\n\nAutoCAD LT 2015 introduced Desktop Subscription (rental) from $360 per year\n\nFormerly marketed as AutoCAD WS, AutoCAD 360 is an account-based mobile and web application enabling registered users to view, edit, and share AutoCAD files via mobile device and web using a limited AutoCAD feature set — and using cloud-stored drawing files. The program, which is an evolution and combination of previous products, uses a freemium business model with a free plan and two paid levels — marketed as Pro ($4.99 monthly or $49.99 yearly) and Pro Plus ($99.99 yearly) — including various amounts of storage, tools, and online access to drawings. 360 includes new features such as a \"Smart Pen\" mode and linking to third-party cloud-based storage such as Dropbox. Having evolved from Flash-based software, AutoCAD 360 uses HTML5 browser technology available in newer browsers including Firefox and Google Chrome.\n\nAutoCAD WS began with a version for the iPhone and subsequently expanded to include versions for the iPod Touch, iPad, Android phones, and Android tablets. Autodesk released the iOS version in September 2010, following with the Android version on April 20, 2011. The program is available via download at no cost from the App Store (iOS), Google Play (Android) and Amazon Appstore (Android).\n\nIn its initial iOS version, AutoCAD WS supported drawing of lines, circles, and other shapes; creation of text and comment boxes; and management of color, layer, and measurements — in both landscape and portrait modes. Version 1.3, released August 17, 2011, added support of unit typing, layer visibility, area measurement and file management. The Android variant includes the iOS feature set along with such unique features as the ability to insert text or captions by voice command as well as manually. Both Android and iOS versions allow the user to save files on-line — or off-line in the absence of an Internet connection.\n\nIn 2011, Autodesk announced plans to migrate the majority of its software to \"the cloud\", starting with the AutoCAD WS mobile application.\n\nAccording to a 2013 interview with Ilai Rotbaein, an AutoCAD WS Product Manager for Autodesk, the name AutoCAD WS had no definitive meaning, and was interpreted variously as \"Autodesk Web Service\", \"White Sheet\" or \"Work Space.\"\n\nAutoCAD is licensed, for free, to students, educators, and educational institutions, with an 36-month renewable license available. The student version of AutoCAD is functionally identical to the full commercial version, with one exception: DWG files created or edited by a student version have an internal bit-flag set (the \"educational flag\"). When such a DWG file is printed by any version of AutoCAD (commercial or student) older than AutoCAD 2014 SP1, the output includes a plot stamp / banner on all four sides. Objects created in the Student Version cannot be used for commercial use. Student Version objects \"infect\" a commercial version DWG file if it is imported in older versions than AutoCAD 2015.\n\nAutoCAD is a software package created for Windows and usually any new AutoCAD version supports the current Windows version and some older ones. AutoCAD 2016 and 2017 supports Windows 7 up to Windows 10.\n\nAutodesk stopped supporting Apple's Macintosh computers in 1994. Over the next several years, no compatible versions for the Mac were released. In 2010 Autodesk announced that it would once again support Apple's Mac OS X software in the future. Most of the features found in the 2012 Windows version can be found in the 2012 Mac version. The main difference is the user interface and layout of the program. The interface is designed so that users who are already familiar with Apple's macOS software will find it similar to other Mac applications. Autodesk has also built in various features in order to take full advantage of Apple's Trackpad capabilities as well as the full-screen mode in Apple's OS X Lion. AutoCAD 2012 for Mac supports both the editing and saving of files in DWG formatting that will allow the file to be compatible with other platforms besides the OS X. AutoCAD 2014 for Mac supports Apple OS X v10.9.0 or later (Mavericks), OS X v10.8.0 or later (Mountain Lion) with 64-bit Intel processor.\n\nAutoCAD LT 2013 is now available through the Mac App Store for $899.99. The full featured version of AutoCAD 2013 for Mac, however, is not available through the Mac App Store due to the price limit of $999 set by Apple. AutoCAD 2014 for Mac is available for purchase from Autodesk's Web site for $4,195 and AutoCAD LT 2014 for Mac for $1,200, or from an Autodesk Authorized Reseller. The latest version available for Mac is AutoCAD 2016 as of October 2016.\n\nAutodesk AutoCAD 360 is the official AutoCAD mobile app for Android and iOS and Windows tablets (UWP). It can view, markup, measure and edit (2D only editing) any DWG file from a mobile phone or tablet. The actual file editing operations are performed in the cloud, in genuine DWG file format.\n\n\n\n\n", "id": "2753", "title": "AutoCAD"}
{"url": "https://en.wikipedia.org/wiki?curid=2754", "text": "AutoCAD DXF\n\nAutoCAD DXF (Drawing Interchange Format, or Drawing Exchange Format) is a CAD data file format developed by Autodesk for enabling data interoperability between AutoCAD and other programs.\n\nDXF was originally introduced in December 1982 as part of AutoCAD 1.0, and was intended to provide an exact representation of the data in the AutoCAD native file format, DWG (Drawing), for which Autodesk for many years did not publish specifications. Because of this, correct imports of DXF files have been difficult. Autodesk now publishes the DXF specifications as a PDF on its website.\n\nVersions of AutoCAD from Release 10 (October 1988) and up support both ASCII and binary forms of DXF. Earlier versions support only ASCII.\n\nAs AutoCAD has become more powerful, supporting more complex object types, DXF has become less useful. Certain object types, including ACIS solids and regions, are not documented. Other object types, including AutoCAD 2006's dynamic blocks, and all of the objects specific to the vertical market versions of AutoCAD, are partially documented, but not well enough to allow other developers to support them. For these reasons many CAD applications use the DWG format which can be licensed from Autodesk or non-natively from the Open Design Alliance.\n\nDXF coordinates are always without dimensions so that the reader or user needs to know the drawing unit or has to extract it from the textual comments in the sheets.\n\nASCII versions of DXF can be read with any text editor. The basic organization of a DXF file is as follows:\n\n\nThe data format of a DXF is called a \"tagged data\" format which \"means that each data element in the file is preceded by an integer number that is called a group code. A group code's value indicates what type of data element follows. This value also indicates the meaning of a data element for a given object (or record) type. Virtually all user-specified information in a drawing file can be represented in DXF format.\"\n\n\n", "id": "2754", "title": "AutoCAD DXF"}
{"url": "https://en.wikipedia.org/wiki?curid=2756", "text": "Asexual reproduction\n\nAsexual reproduction is a type of reproduction by which offspring arise from a single organism, and inherit the genes of that parent only; it does not involve the fusion of gametes, and almost never changes the number of chromosomes. Asexual reproduction is the primary form of reproduction for single-celled organisms such as the Archaea and bacteria. Many plants and fungi reproduce asexually as well.\n\nWhile all prokaryotes reproduce asexually (without the formation and fusion of gametes), mechanisms for lateral gene transfer such as conjugation, transformation and transduction are sometimes likened to sexual reproduction or at least with sex, in the sense of genetic recombination in meiosis. A complete lack of sexual reproduction is relatively rare among multicellular organisms, particularly animals. It is not entirely understood why the ability to reproduce sexually is so common among them. Current hypotheses suggest that asexual reproduction may have short term benefits when rapid population growth is important or in stable environments, while sexual reproduction offers a net advantage by allowing more rapid generation of genetic diversity, allowing adaptation to changing environments. Developmental constraints may underlie why few animals have relinquished sexual reproduction completely in their life-cycles. Another constraint on switching from sexual to asexual reproduction would be the concomitant loss of meiosis and the protective recombinational repair of DNA damage afforded as one function of meiosis.\n\nAn important form of fission is \"binary fission\".\nIn binary fission, the parent organism is replaced by two daughter organisms, because it literally divides in two. Only prokaryotes (the archaea and the bacteria) reproduce asexually through binary fission. Eukaryotes (such as protists and unicellular fungi) may reproduce in a functionally similar manner by mitosis; most of these are also capable of sexual reproduction.\n\nAnother type of fission is \"multiple fission\". Multiple fission at the cellular level occurs in many protists, e.g. sporozoans and algae. The nucleus of the parent cell divides several times by mitosis, producing several nuclei. The cytoplasm then separates, creating multiple daughter cells.\n\nIn apicomplexans, multiple fission, or schizogony, is manifested either as merogony, sporogony or gametogony. Merogony results in merozoites, which are multiple daughter cells, that originate within the same cell membrane, sporogony results in sporozoites, and gametogony results in microgametes.\n\nSome cells split via budding (for example baker's yeast), resulting in a \"mother\" and \"daughter\" cell. The offspring organism is smaller than the parent. Budding is also known on a multicellular level; an animal example is the hydra, which reproduces by budding. The buds grow into fully matured individuals which eventually break away from the parent organism.\n\nInternal budding is a process of asexual reproduction, favoured by parasites such as \"Toxoplasma gondii\". It involves an unusual process in which two (\"endodyogeny\") or more (\"endopolygeny\") daughter cells are produced inside a mother cell, which is then consumed by the offspring prior to their separation.\n\nAlso, budding (external or internal) is present in some worm like Taenia or Echinococci; these worm produce cyst and then produce (invaginated or evaginated) protoscolex with budding.\n\nVegetative propagation is a type of asexual reproduction found in plants where new individuals are formed without the production of seeds or spores by meiosis or syngamy. Examples of vegetative reproduction include the formation of miniaturized plants called plantlets on specialized leaves (for example in kalanchoe) and some produce new plants out of rhizomes or stolon (for example in strawberry). Other plants reproduce by forming bulbs or tubers (for example tulip bulbs and dahlia tubers). Some plants produce adventitious shoots and may form a clonal colony, where all the individuals are clones, and the clones may cover a large area.\n\nMany multicellular organisms form spores during their biological life cycle in a process called sporogenesis. Exceptions are animals and some protists, who undergo \"meiosis\" immediately followed by fertilization. Plants and many algae on the other hand undergo \"sporic meiosis\" where meiosis leads to the formation of haploid spores rather than gametes. These spores grow into multicellular individuals (called gametophytes in the case of plants) without a fertilization event. These haploid individuals give rise to gametes through mitosis. Meiosis and gamete formation therefore occur in separate generations or \"phases\" of the life cycle, referred to as alternation of generations. Since sexual reproduction is often more narrowly defined as the fusion of gametes (fertilization), spore formation in plant sporophytes and algae might be considered a form of asexual reproduction (agamogenesis) despite being the result of meiosis and undergoing a reduction in ploidy. However, both events (spore formation and fertilization) are necessary to complete sexual reproduction in the plant life cycle.\n\nFungi and some algae can also utilize true asexual spore formation, which involves mitosis giving rise to reproductive cells called mitospores that develop into a new organism after dispersal. This method of reproduction is found for example in conidial fungi and the red algae \"Polysiphonia\", and involves sporogenesis without meiosis. Thus the chromosome number of the spore cell is the same as that of the parent producing the spores. However, mitotic sporogenesis is an exception and most spores, such as those of plants, most Basidiomycota, and many algae, are produced by meiosis.\n\nFragmentation is a form of asexual reproduction where a new organism grows from a fragment of the parent. Each fragment develops into a mature, fully grown individual. Fragmentation is seen in many organisms. Animals that reproduce asexually include planarians, many annelid worms including polychaetes and some oligochaetes, turbellarians and sea stars. Many fungi and plants reproduce asexually. Some plants have specialized structures for reproduction via fragmentation, such as \"gemma\" in liverworts. Most lichens, which are a symbiotic union of a fungus and photosynthetic algae or bacteria, reproduce through fragmentation to ensure that new individuals contain both symbiont. These fragments can take the form of \"soredia\", dust-like particles consisting of fungal hyphen wrapped around photobiont cells.\n\nClonal Fragmentation in multicellular or colonial organisms is a form of asexual reproduction or cloning where an organism is split into fragments. Each of these fragments develop into mature, fully grown individuals that are clones of the original organism. In echinoderms, this method of reproduction is usually known as fissiparity. Researchers claim today that due to many environmental and epigenetic differences, that clones originated in the same ancestor might actually be genetically and epigenetically different.\n\nAgamogenesis is any form of reproduction that does not involve a male gamete. Examples are parthenogenesis and apomixis.\n\nParthenogenesis is a form of agamogenesis in which an unfertilized egg develops into a new individual. Parthenogenesis occurs naturally in many plants, invertebrates (e.g. water fleas, rotifers, aphids, stick insects, some ants, bees and parasitic wasps), and vertebrates (e.g. some reptiles, amphibians, rarely birds). In plants, apomixis may or may not involve parthenogenesis.\n\nApomixis in plants is the formation of a new sporophyte without fertilization. It is important in ferns and in flowering plants, but is very rare in other seed plants. In flowering plants, the term \"apomixis\" is now most often used for agamospermy, the formation of seeds without fertilization, but was once used to include vegetative reproduction. An example of an apomictic plant would be the triploid European dandelion. Apomixis mainly occurs in two forms: In gametophytic apomixis, the embryo arises from an unfertilized egg within a diploid embryo sac that was formed without completing meiosis. In nucellar embryony, the embryo is formed from the diploid nucellus tissue surrounding the embryo sac. Nucellar embryony occurs in some citrus seeds. Male apomixis can occur in rare cases, such as the Saharan Cypress \"Cupressus dupreziana\", where the genetic material of the embryo are derived entirely from pollen.\nThe term \"apomixis\" is also used for asexual reproduction in some animals, notably water-fleas, \"Daphnia\".\n\nSome species alternate between the sexual and asexual strategies, an ability known as heterogamy, depending on conditions. Alternation is observed in several rotifer species (cyclical parthenogenesis e.g. in Brachionus species) and a few types of insects, such as aphids which will, under certain conditions, produce eggs that have not gone through meiosis, thus cloning themselves. The cape bee \"Apis mellifera\" subsp. \"capensis\" can reproduce asexually through a process called thelytoky. A few species of amphibians, reptiles, and birds have a similar ability (see parthenogenesis for examples).\nFor example, the freshwater crustacean \"Daphnia\" reproduces by parthenogenesis in the spring to rapidly populate ponds, then switches to sexual reproduction as the intensity of competition and predation increases. Another example are monogonont rotifers of the genus \"Brachionus\", which reproduce via cyclical parthenogenesis: at low population densities females produce asexually and at higher densities a chemical cue accumulates and induces the transition to sexual reproduction. Many protists and fungi alternate between sexual and asexual reproduction.\n\nFor example, the slime mold \"Dictyostelium\" undergoes binary fission (mitosis) as single-celled amoebae under favorable conditions. However, when conditions turn unfavorable, the cells aggregate and follow one of two different developmental pathways, depending on conditions. In the social pathway, they form a multicellular slug which then forms a fruiting body with asexually generated spores. In the sexual pathway, two cells fuse to form a giant cell that develops into a large cyst. When this macrocyst germinates, it releases hundreds of amoebic cells that are the product of meiotic recombination between the original two cells.\n\nThe hyphae of the common mold (\"Rhizopus\") are capable of producing both mitotic as well as meiotic spores. Many algae similarly switch between sexual and asexual reproduction. A number of plants use both sexual and asexual means to produce new plants, some species alter their primary modes of reproduction from sexual to asexual under varying environmental conditions.\n\nFor example, in the rotifer \"Brachionus calyciflorus\" asexual reproduction (obligate parthenogenesis) can be inherited by a recessive allele, which leads to loss of sexual reproduction in homozygous offspring.\nInheritance of asexual reproduction by a single recessive locus has also been found in the parasitoid wasp \"Lysiphlebus fabarum\".\n\nParthenogenesis occurs in the hammerhead shark and the blacktip shark. In both cases, the sharks had reached sexual maturity in captivity in the absence of males, and in both cases the offspring were shown to be genetically identical to the mothers. The New Mexico whiptail is another example.\n\nReptiles use the ZW sex-determination system, which produces either males (with ZZ sex chromosomes) or females (with ZW or WW sex chromosomes). Until 2010, it was thought that the ZW chromosome system used by reptiles was incapable of producing viable WW offspring, but a (ZW) female boa constrictor was discovered to have produced viable female offspring with WW chromosomes. The female boa could have chosen any number of male partners (and had successfully in the past) but on these occasions she reproduced asexually, creating 22 female babies with WW sex-chromosomes.\n\nPolyembryony is a widespread form of asexual reproduction in animals, whereby the fertilized egg or a later stage of embryonic development splits to form genetically identical clones. Within animals, this phenomenon has been best studied in the parasitic Hymenoptera. In the 9-banded armadillos, this process is obligatory and usually gives rise to genetically identical quadruplets. In other mammals, monozygotic twinning has no apparent genetic basis, though its occurrence is common. There are at least 10 million identical human twins and triplets in the world today.\n\nBdelloid rotifers reproduce exclusively asexually, and all individuals in the class Bdelloidea are females. Asexuality evolved in these animals millions of years ago and has persisted since. There is evidence to suggest that asexual reproduction has allowed the animals to evolve new proteins through the Meselson effect that have allowed them to survive better in periods of dehydration.\n\nMolecular evidence strongly suggest that several species of the stick insect genus \"Timema\" have used only asexual (parthenogenetic) reproduction for millions of years, the longest period known for any insect.\n\nIn the grass thrips genus \"Aptinothrips\" there have been several transitions to asexuality, likely due to different causes.\n\n\n", "id": "2756", "title": "Asexual reproduction"}
{"url": "https://en.wikipedia.org/wiki?curid=2758", "text": "Aelbert Cuyp\n\nAelbert Jacobsz Cuyp (October 20, 1620 – November 15, 1691) was one of the leading Dutch landscape painters of the Dutch Golden Age in the 17th century. The most famous of a family of painters, the pupil of his father Jacob Gerritsz Cuyp (1594–1651/52), he is especially known for his large views of the Dutch countryside in early morning or late afternoon light.\n\nAelbert Cuyp was born in Dordrecht on October 20, 1620, and also died there on November 15, 1691. Known as the Dutch equivalent of Claude Lorrain, this landscape artist went on to inherit a considerable fortune. His family were all artists, with his uncle Benjamin and grandfather Gerrit being stained glass cartoon designers. Jacob Gerritsz Cuyp, his father, was a portraitist.\n\nThe amount of biographical information regarding Aelbert Cuyp is tremendously limited. Even Arnold Houbraken, a noted historian of Dutch Golden Age paintings and the sole authority on Cuyp for the hundred years following his death, paints a very thin biographical picture. His period of activity as a painter is traditionally limited to the two decades between 1639 and 1660, fitting directly within the generally accepted limits of the Dutch Golden Age's most significant period, 1640-1665. He is known to have been married to Cornelia Bosman in 1658, a date coinciding so directly with the end of his productivity as a painter that it has been accepted that his marriage played some sort of role in the end of his artistic career. The year after his marriage Cuyp became the deacon of the reformed church. Even Houbraken recalled that Cuyp was a devout Calvinist and the fact that when he died, there were no paintings of other artists found in his home.\n\nThe development of Aelbert Cuyp, who was trained as a landscape painter, may be roughly sketched in three phases based on the painters who most influenced him during that time and the subsequent artistic characteristics that are apparent in his paintings. Generally, Cuyp learned tone from the exceptionally prolific Jan van Goyen, light from Jan Both and form from his father, Jacob Gerritsz Cuyp.\n\nCuyp's \"van Goyen phase\" can be placed approximately in the early 1640s.\nCuyp probably first encountered a painting by van Goyen in 1640 when van Goyen was, as Stephen Reiss points out \"at the height of [his] powers.\" This is noticeable in the comparison between two of Cuyp's landscape paintings inscribed 1639 where no properly formed style is apparent and the landscape backgrounds he painted two years later for two of his father's group portraits that are distinctly van Goyenesque. \nCuyp took from van Goyen the straw yellow and light brown tones that are so apparent in his Dunes (1629) and the broken brush technique also very noticeable in that same work. \nThis technique, a precursor to impressionism, is noted for the short brush strokes where the colors are not necessarily blended smoothly. In Cuyp's River Scene, Two Men Conversing (1641) both of these van Goyen-influenced stylistic elements are noticeable\n\nThe next phase in the development of Cuyp's increasingly amalgamated style is due to the influence of Jan Both. In the mid-1640s Both, a native and resident of Utrecht, had just returned to his hometown from a trip to Rome. It is around this same time that Cuyp's style changed fundamentally. In Rome, Both had developed a new style of composition due, at least in part, to his interaction with Claude Lorrain. This new style was focused on changing the direction of light in the painting. Instead of the light being placed at right angles in relation to the line of vision, Both started moving it to a diagonal position from the back of the picture. In this new form of lighting, the artist (and viewer of the painting) faced the sun more or less contre-jour. Both, and subsequently Cuyp, used the advantages of this new lighting style to alter the sense of depth and luminosity possible in a painting. To make notice of these new capabilities, much use was made of elongated shadows. Cuyp was one of the first Dutch painters to appreciate this new leap forward in style and while his own Both-inspired phase was quite short (limited to the mid-1640s) he did, more than any other contemporary Dutch artist, maximize the full chromatic scale for sunsets and sunrises.\n\nCuyp's third stylistic phase (which occurred throughout his career) is based on the influence of his father. While it is assumed that the younger Cuyp did work with his father initially to develop rudimentary talents, Aelbert became more focused on landscape paintings while Jacob was a portrait painter by profession. As has been mentioned and as will be explained in depth below, there are pieces where Aelbert provided the landscape background for his father's portraits. What is meant by stating that Aelbert learned form from his father is that his eventual transition from a specifically landscape painter to the involvement of foreground figures is attributed to his interaction with his father Jacob. The evidence for Aelbert's evolution to foreground figure painter is in the production of some paintings from 1645-50 featuring foreground animals that do not fit with Jacob's style. Adding to the confusion that is, Aelbert's stylistic development and the problem of attribution is of course the fact that Jacob's style was not stagnant either. Their converging styles make it difficult to exactly understand the influences each had on the other, although it is clear enough to say that Aelbert started representing large scale forms (something he had not done previously) and placing animals as the focus of his paintings (something that was specific to him).\n\nSunlight in his paintings rakes across the panel, accentuating small bits of detail in the golden light. In large, atmospheric panoramas of the countryside, the highlights on a blade of meadow grass, the mane of a tranquil horse, the horn of a dairy cow reclining by a stream, or the tip of a peasant's hat are all caught in a bath of yellow ocher light. The richly varnished medium refracts the rays of light like a jewel as it dissolves into numerous glazed layers. Cuyp's landscapes were based on reality and on his own invention of what an enchanting landscape should be.\n\nCuyp's drawings reveal him to be a draftsman of superior quality. Light-drenched washes of golden brown ink depict a distant view of the city of Dordrecht or Utrecht.\nA Cuyp drawing may look like he intended it to be a finished work of art, but it was most likely taken back to the studio and used as a reference for his paintings. Often the same section of a sketch can be found in several different pictures.\n\nCuyp signed many of his works but rarely dated them, so that a chronology of his career has not been satisfactorily reassembled. A phenomenal number of paintings are ascribed to him, some of which are likely to be by other masters of the golden landscape, such as Abraham Calraet (1642–1722), whose initials \"A.C.\" may be mistaken for Cuyp's.\n\nHowever, not everyone appreciates his work and \"River Landscape\" (1660), despite being widely regarded as amongst his best work, has been described as having \"chocolate box blandness\".\n\nIn addition to the scarcely documented and confirmed biography of Cuyp's life, and even more so than his amalgamated style from his three main influences, there are yet other factors that have led to the misattribution and confusion over Aelbert Cuyp's works for hundreds of years. His highly influenced style which incorporated Italianate lighting from Jan Both, broken brush technique and atonality from Jan van Goyen, and his ever-developing style from his father Jacob Gerritsz Cuyp was studied acutely by his most prominent follower, Abraham van Calraet. Calraet mimicked Cuyp's style, incorporating the same aspects, and produced similar landscapes to that of the latter. This made it quite difficult to tell whose paintings where whose. Adding to the confusion is the similar initials between the two and the inconsistent signing of paintings which were produced by Cuyp's studio.\n\nAlthough Aelbert Cuyp signed many of his paintings with a script \"A. Cuyp\" insignia, many paintings were left unsigned (not to mention undated) after being painted, and so a similar signature was added later on, presumably by collectors who inherited or discovered the works. Furthermore, many possible Cuyp paintings were not signed but rather initialed \"A. C.\" referring to his name. However, Abraham van Calraet could also have used the same initials to denote a painting. Although this is unlikely (as Calraet would likely have signed his paintings \"A. v.C.\"), this brings up the question of how paintings were signed to show ownership. Most original Cuyp paintings were signed by him, and in the script manner in which his name was inscribed. This would denote that the painting was done almost entirely by him. Conversely, paintings which came out of his workshop that were not necessarily physically worked on by Cuyp but merely overseen by him technically, were marked with A.C. to show that it was his instruction which saw the paintings' completion. Cuyp's pupils and assistants often worked on paintings in his studio, and so most of the work of a painting could be done without Cuyp ever touching the canvas, but merely approving its finality. Hence, the initialed inscription rather than a signature.\n\nCommon among the mislabeled works are all of the reasons identified for misattributing Cuyp's works: the lack of biography and chronology of his works made it difficult to discern when paintings were created (making it difficult to pinpoint an artist); contentious signatures added to historians' confusion as to who actually painted the works; and the collaborations and influences by different painters makes it hard to justify that a painting is genuinely that of Aelbert Cuyp; and finally, accurate identification is made extremely difficult by the fact that this same style was copied (rather accurately) by his predecessor. As it turns out, even the historians and expert researchers have been fooled and forced to reassess their conclusions over \"Cuyp's\" paintings over the years.\n\nAfter he married Cornelia Boschman in 1658, the number of works produced by him declined almost to nothing. This may have been because his wife was a very religious woman and a not very big patron of the arts. It could also be that he became more active in the church under his wife's guidance. He was also active as deacon and elder of the Reformed Church.\n\nUpon close examination of the works attributed to Aelbert Cuyp it is easily understood why his unique style developed the way it did, and how his works have been misinterpreted over the years. A lacking biography and weak chronology of works as well as his style which emerged from various influences makes his works distinctive, yet often questionable in determination. Furthermore, his evolving technique and collaborations with his father add to the puzzle over which works should be attributed to Cuyp. Lastly and most importantly, the precision in mimicking Cuyp's style by his follower Abraham van Calraet and their contentious signatures makes it all the more difficult to determine which paintings are genuinely that of Cuyp and which ones are actually accurate reproductions in his style.\n\nSuch a thin chronology and little background knowledge has led to gross misinterpretations of his works, and thus further investigation must always be done to conclude with confidence that Aelbert Cuyp is the genuine source of such great paintings. It is this felt reluctance which led the Rijksmuseum to reattribute works to other painters (Abraham van Calraet does not even appear in a Museum catalogue until 1926, and even then he is not given his own entry) which shows how important it is to art historians that painters are accurately connected to their works—and this is continuously necessary for those of Aelbert Cuyp, as Dordrecht's most famous painter may not in fact be Dordrecht's most famous painter.\n\n", "id": "2758", "title": "Aelbert Cuyp"}
{"url": "https://en.wikipedia.org/wiki?curid=2761", "text": "Alkene\n\nIn organic chemistry, an alkene is an unsaturated hydrocarbon that contains at least one carbon–carbon double bond. The words alkene and olefin are often used interchangeably (see nomenclature section below). Acyclic alkenes, with only one double bond and no other functional groups, known as mono-enes, form a homologous series of hydrocarbons with the general formula . Alkenes have two hydrogen atoms less than the corresponding alkane (with the same number of carbon atoms). The simplest alkene, ethylene (CH), with the International Union of Pure and Applied Chemistry (IUPAC) name \"ethene\", is the organic compound produced on the largest scale industrially. Aromatic compounds are often drawn as cyclic alkenes, but their structure and properties are different and they are not considered to be alkenes.\n\nLike a single covalent bond, double bonds can be described in terms of overlapping atomic orbitals, except that, unlike a single bond (which consists of a single sigma bond), a carbon–carbon double bond consists of one sigma bond and one pi bond. This double bond is stronger than a single covalent bond (611 kJ/mol for C=C vs. 347 kJ/mol for C–C) and also shorter, with an average bond length of 1.33 ångströms (133 pm).\n\nEach carbon of the double bond uses its three sp hybrid orbitals to form sigma bonds to three atoms (the other carbon and two hydrogen atoms). The unhybridized 2p atomic orbitals, which lie perpendicular to the plane created by the axes of the three sp² hybrid orbitals, combine to form the pi bond. This bond lies outside the main C–C axis, with half of the bond on one side of the molecule and half on the other.\n\nRotation about the carbon–carbon double bond is restricted because it incurs an energetic cost to break the alignment of the p orbitals on the two carbon atoms. As a consequence, substituted alkenes may exist as one of two isomers, called \"cis\" or \"trans\" isomers. More complex alkenes may be named with the \"E\"–\"Z\" notation for molecules with three or four different substituents (side groups). For example, of the isomers of butene, the two methyl groups of (\"Z\")-but-2-ene (a.k.a. \"cis\"-2-butene) appear on the same side of the double bond, and in (\"E\")-but-2-ene (a.k.a. \"trans\"-2-butene) the methyl groups appear on opposite sides. These two isomers of butene are slightly different in their chemical and physical properties.\n\nA 90° twist of the C=C bond (which may be determined by the positions of the groups attached to the carbons) requires less energy than the strength of a pi bond, and the bond still holds. This contradicts a common textbook assertion that the p orbitals would be unable sustain such a bond. In truth, the misalignment of the p orbitals is less than expected because pyramidalization takes place (See: pyramidal alkene). \"trans\"-Cyclooctene is a stable strained alkene and the orbital misalignment is only 19° with a dihedral angle of 137° (normal 120°) and a degree of pyramidalization of 18°. The \"trans\" isomer of cycloheptene is stable only at low temperatures.\n\nAs predicted by the VSEPR model of electron pair repulsion, the molecular geometry of alkenes includes bond angles about each carbon in a double bond of about 120°. The angle may vary because of steric strain introduced by nonbonded interactions between functional groups attached to the carbons of the double bond. For example, the C–C–C bond angle in propylene is 123.9°.\n\nFor bridged alkenes, Bredt's rule states that a double bond cannot occur at the bridgehead of a bridged ring system unless the rings are large enough (8 or more atoms).\n\nThe physical properties of alkenes and alkanes are similar. They are colourless, nonpolar, combustable, and almost odorless. The physical state depends on molecular mass: like the corresponding saturated hydrocarbons, the simplest alkenes, ethene, propene, and butene are gases at room temperature. Linear alkenes of approximately five to sixteen carbons are liquids, and higher alkenes are waxy solids.\n\nAlkenes are relatively stable compounds, but are more reactive than alkanes, either because of the reactivity of the carbon–carbon pi-bond or the presence of allylic CH centers. Most reactions of alkenes involve additions to this pi bond, forming new single bonds. Alkenes serve as a feedstock for the petrochemical industry because they can participate in a wide variety of reactions, prominently polymerization and alkylation.\n\nAlkenes react in many addition reactions, which occur by opening up the double-bond. Most of these addition reactions follow the mechanism of electrophilic addition. Examples are hydrohalogenation, halogenation, halohydrin formation, oxymercuration, hydroboration, dichlorocarbene addition, Simmons–Smith reaction, catalytic hydrogenation, epoxidation, radical polymerization and hydroxylation.\n\nHydrogenation of alkenes produces the corresponding alkanes. The reaction is carried out under pressure at a temperature of 200 °C in the presence of a metallic catalyst. Common industrial catalysts are based on platinum, nickel or palladium. For laboratory syntheses, Raney nickel (an alloy of nickel and aluminium) is often employed. The simplest example of this reaction is the catalytic hydrogenation of ethylene to yield ethane:\n\nHydration, the addition of water across the double bond of alkenes, yields alcohols. The reaction is catalyzed by strong acids such as sulfuric acid. This reaction is carried out on an industrial scale to produce ethanol.\n\nAlkenes can also be converted into alcohols via the [oxymercuration–demercuration reaction] or [hydroboration–oxidation reaction].\n\nIn electrophilic halogenation the addition of elemental bromine or chlorine to alkenes yields vicinal dibromo- and dichloroalkanes (1,2-dihalides or ethylene dihalides), respectively. The decoloration of a solution of bromine in water is an analytical test for the presence of alkenes:\n\nRelated reactions are also used as quantitative measures of unsaturation, expressed as the bromine number and iodine number of a compound or mixture.\n\nHydrohalogenation is the addition of hydrogen halides such as HCl or HI to alkenes to yield the corresponding haloalkanes:\n\nIf the two carbon atoms at the double bond are linked to a different number of hydrogen atoms, the halogen is found preferentially at the carbon with fewer hydrogen substituents. This patterns is known as Markovnikov's rule. The use of radical initiators or other compounds can lead to the opposite product result. Hydrobromic acid in particular is prone to forming radicals in the presence of various impurities or even atmospheric oxygen, leading to the reversal of the Markovnikov result:\n\nAlkenes react with water and halogens to form halohydrins by an addition reaction. Markovnikov regiochemistry and anti stereochemistry occur.\n\nAlkenes are oxidized with a large number of oxidizing agents. In the presence of oxygen, alkenes burn with a bright flame to produce carbon dioxide and water. Catalytic oxidation with oxygen or the reaction with percarboxylic acids yields epoxides. Reaction with ozone in ozonolysis leads to the breaking of the double bond, yielding two aldehydes or ketones. Reaction with concentrated, hot KMnO (or other oxidizing salts) in an acidic solution will yield ketones or carboxylic acids.\n\nThis reaction can be used to determine the position of a double bond in an unknown alkene.\n\nThe oxidation can be stopped at the vicinal diol rather than full cleavage of the alkene by using milder (dilute,lower temperature) KMnO or with osmium tetroxide or other oxidants.\n\nIn the presence of an appropriate photosensitiser, such as methylene blue and light, alkenes can undergo reactions with reactive oxygen species generated by the photosensitiser, such as hydroxyl radicals, singlet oxygen or superoxide ion. These reactive photochemical intermediates are generated in what are known as Type I, Type II, and Type III processes, respectively. These various alternative processes and reactions can be controlled by choice of specific reaction conditions, leading to a wide range of different products. A common example is the [4+2]-cycloaddition of singlet oxygen with a diene such as cyclopentadiene to yield an endoperoxide:\n\nAnother example is the Schenck ene reaction, in which singlet oxygen reacts with an allylic structure to give a transposed allyl peroxide:\n\nPolymerization of alkenes is a reaction that yields polymers of high industrial value at great economy, such as the plastics polyethylene and polypropylene. Polymers from alkene monomers are referred to in a general way as \"polyolefins\" or in rare instances as \"polyalkenes\". A polymer from alpha-olefins is called a polyalphaolefin (PAO). Polymerization can proceed via either a free-radical or an ionic mechanism, converting the double to a single bond and forming single bonds to join the other monomers. Polymerization of conjugated dienes such as buta-1,3-diene or isoprene (2-methylbuta-1,3-diene) results in largely 1,4-addition with possibly some 1,2-addition of the diene monomer to a growing polymer chain.\n\nAlkenes are ligands in transition metal alkene complexes. The two carbon centres bond to the metal using the C–C pi- and pi*-orbitals. Mono- and diolefins are often used as ligands in stable complexes. Cyclooctadiene and norbornadiene are popular chelating agents, and even ethylene itself is sometimes used as a ligand, for example, in Zeise's salt. In addition, metal–alkene complexes are intermediates in many metal-catalyzed reactions including hydrogenation, hydroformylation, and polymerization.\n\nAlkenes are produced by hydrocarbon cracking. Raw materials are mostly natural gas condensate components (principally ethane and propane) in the US and Mideast and naphtha in Europe and Asia. Alkanes are broken apart at high temperatures, often in the presence of a zeolite catalyst, to produce a mixture of primarily aliphatic alkenes and lower molecular weight alkanes. The mixture is feedstock and temperature dependent, and separated by fractional distillation. This is mainly used for the manufacture of small alkenes (up to six carbons).\nRelated to this is catalytic dehydrogenation, where an alkane loses hydrogen at high temperatures to produce a corresponding alkene. This is the reverse of the catalytic hydrogenation of alkenes.\n\nThis process is also known as reforming. Both processes are endothermic and are driven towards the alkene at high temperatures by entropy.\n\nCatalytic synthesis of higher α-alkenes (of the type RCH=CH) can also be achieved by a reaction of ethylene with the organometallic compound triethylaluminium in the presence of nickel, cobalt, or platinum.\n\nOne of the principal methods for alkene synthesis in the laboratory is the room elimination of alkyl halides, alcohols, and similar compounds. Most common is the β-elimination via the E2 or E1 mechanism, but α-eliminations are also known.\n\nThe E2 mechanism provides a more reliable β-elimination method than E1 for most alkene syntheses. Most E2 eliminations start with an alkyl halide or alkyl sulfonate ester (such as a tosylate or triflate). When an alkyl halide is used, the reaction is called a dehydrohalogenation. For unsymmetrical products, the more substituted alkenes (those with fewer hydrogens attached to the C=C) tend to predominate (see Zaitsev's rule). Two common methods of elimination reactions are dehydrohalogenation of alkyl halides and dehydration of alcohols. A typical example is shown below; note that if possible, the H is \"anti\" to the leaving group, even though this leads to the less stable \"Z\"-isomer.\n\nAlkenes can be synthesized from alcohols via dehydration, in which case water is lost via the E1 mechanism. For example, the dehydration of ethanol produces ethene:\n\nAn alcohol may also be converted to a better leaving group (e.g., xanthate), so as to allow a milder \"syn\"-elimination such as the Chugaev elimination and the Grieco elimination. Related reactions include eliminations by β-haloethers (the Boord olefin synthesis) and esters (ester pyrolysis).\n\nAlkenes can be prepared indirectly from alkyl amines. The amine or ammonia is not a suitable leaving group, so the amine is first either alkylated (as in the Hofmann elimination) or oxidized to an amine oxide (the Cope reaction) to render a smooth elimination possible. The Cope reaction is a \"syn\"-elimination that occurs at or below 150 °C, for example:\n\nThe Hofmann elimination is unusual in that the \"less\" substituted (non-Saytseff) alkene is usually the major product.\n\nAlkenes are generated from α-halosulfones in the Ramberg–Bäcklund reaction, via a three-membered ring sulfone intermediate.\n\nAnother important method for alkene synthesis involves construction of a new carbon–carbon double bond by coupling of a carbonyl compound (such as an aldehyde or ketone) to a carbanion equivalent. Such reactions are sometimes called \"olefinations\". The most well-known of these methods is the Wittig reaction, but other related methods are known.\n\nThe Wittig reaction involves reaction of an aldehyde or ketone with a Wittig reagent (or phosphorane) of the type PhP=CHR to produce an alkene and PhP=O. The Wittig reagent is itself prepared easily from triphenylphosphine and an alkyl halide. The reaction is quite general and many functional groups are tolerated, even esters, as in this example:\n\nRelated to the Wittig reaction is the Peterson olefination. This uses a less accessible silicon-based reagent in place of the phosphorane, but it allows for the selection of \"E\"- or \"Z\"-products. If an \"E\"-product is desired, another alternative is the Julia olefination, which uses the carbanion generated from a phenyl sulfone. The Takai olefination based on an organochromium intermediate also delivers E-products. A titanium compound, Tebbe's reagent, is useful for the synthesis of methylene compounds; in this case, even esters and amides react.\n\nA pair of carbonyl compounds can also be reductively coupled together (with reduction) to generate an alkene. Symmetrical alkenes can be prepared from a single aldehyde or ketone coupling with itself, using titanium metal reduction (the McMurry reaction). If two different ketones are to be coupled, a more complex, indirect method such as the Barton–Kellogg reaction may be used.\n\nA single ketone can also be converted to the corresponding alkene via its tosylhydrazone, using sodium methoxide (the Bamford–Stevens reaction) or an alkyllithium (the Shapiro reaction).\n\nAlkenes can be prepared by exchange with other alkenes, in a reaction known as olefin metathesis. Frequently, loss of ethene gas is used to drive the reaction towards a desired product. In many cases, a mixture of geometric isomers is obtained, but the reaction tolerates many functional groups. The method is particularly effective for the preparation of cyclic alkenes, as in this synthesis of muscone:\nTransition metal catalyzed hydrovinylation is another important alkene synthesis process starting from alkene itself. In general, it involves the addition of a hydrogen and a vinyl group (or an alkenyl group) across a double bond. The hydrovinylation reaction was first reported by Alderson, Jenner, and Lindsey by using rhodium and ruthenium salts, other metal catalysts commonly employed nowadays included iron, cobalt, nickel, and palladium. The addition can be done highly regio- and stereoselectively, the choices of metal centers, ligands, substrates and counterions often play very important role. Recent studies showed that the use of N-heterocyclic carbene with Ni can be useful for the selective preparations of functionalized geminal olefins or 1,1-disubstituted alkenes.\n\nReduction of alkynes is a useful method for the stereoselective synthesis of disubstituted alkenes. If the \"cis\"-alkene is desired, hydrogenation in the presence of Lindlar's catalyst (a heterogeneous catalyst that consists of palladium deposited on calcium carbonate and treated with various forms of lead) is commonly used, though hydroboration followed by hydrolysis provides an alternative approach. Reduction of the alkyne by sodium metal in liquid ammonia gives the \"trans\"-alkene.\n\nFor the preparation multisubstituted alkenes, carbometalation of alkynes can give rise to a large variety of alkene derivatives.\n\nAlkenes can be synthesized from other alkenes via rearrangement reactions. Besides olefin metathesis (described above), a large number of pericyclic reactions can be used such as the ene reaction and the Cope rearrangement.\n\nIn the Diels–Alder reaction, a cyclohexene derivative is prepared from a diene and a reactive or electron-deficient alkene.\n\nAlthough the nomenclature is not followed widely, according to IUPAC, alkenes are acyclic hydrocarbons with one double bond between carbon centers. Olefins comprise a larger collection of cyclic and acyclic alkenes as well as dienes and polyenes.\n\nTo form the root of the IUPAC names for alkenes, simply change the \"-an-\" infix of the parent to \"-en-\". For example, CH-CH is the alkane \"ethANe\". The name of CH=CH is therefore \"ethENe\".\n\nIn higher alkenes, where isomers exist that differ in location of the double bond, the following numbering system is used:\n\nIn the specific case of disubstituted alkenes where the two carbons have one substituent each, \"cis\"–\"trans\" notation may be used. If both substituents are on the same side of the bond, it is defined as \"cis\"-. If the substituents are on either side of the bond, it is defined as \"trans\"-.\n\nWhen an alkene has more than one substituent (especially necessary with 3 or 4 substituents), the double bond geometry is described using the labels \"E\" and \"Z\". These labels come from the German words \"entgegen\", meaning \"opposite\", and \"zusammen\", meaning \"together\". Alkenes with the higher priority groups (as determined by CIP rules) on the same side of the double bond have these groups together and are designated \"Z\". Alkenes with the higher priority groups on opposite sides are designated \"E\". A mnemonic to remember this: \"Z\" notation has the higher priority groups on \"ze zame zide.\"\n\nIUPAC recognizes two names for hydrocarbon groups containing carbon–carbon double bonds, the vinyl group and the allyl group.\n\n", "id": "2761", "title": "Alkene"}
{"url": "https://en.wikipedia.org/wiki?curid=2762", "text": "Allene\n\nAn allene is a compound in which one carbon atom has double bonds with each of its two adjacent carbon centres. Allenes are classified as polyenes with cumulated dienes. The parent compound of allene is propadiene. Compounds with an allene-type structure but with more than three carbon atoms are called cumulenes. Allenes are much more reactive than most other alkenes. For example, their reactivity with gaseous chlorine is more like the reactivity of alkynes than that of alkenes.\n\nThe central carbon atom of allene forms two sigma bonds and two pi bonds. The central carbon is sp-hybridized, and the two terminal carbon atoms are sp-hybridized. The bond angle formed by the three carbon atoms is 180°, indicating linear geometry for the carbon atoms of allene. It can also be viewed as an \"extended tetrahedral\" with a similar shape to methane.\n\nThe symmetry and isomerism of allenes has long fascinated organic chemists. For allenes with four identical substituents, there exist two twofold axes of rotation through the center carbon, inclined at 45° to the CH planes at either end of the molecule. The molecule can thus be thought of as a two-bladed propeller. A third twofold axis of rotation passes through the C=C=C bonds, and there is a mirror plane passing through both CH planes. Thus this class of molecules belong to the D point group. Because of the symmetry, an unsubstituted allene has no net dipole moment.\n\nAn allene with two different substituents on each of the two carbon atoms will be chiral because there will no longer be any mirror planes. Where A has a greater priority than B according to the Cahn-Ingold-Prelog priority rule, the configuration of the axial chirality can be determined by considering the substituents on the front atom followed by the back atom when viewed along the allene axis. For the bottom, only the group of higher priority need be considered. Chiral allenes have been recently used as building blocks in the construction of organic materials with exceptional chiroptical properties. \nAlthough allenes often require specialized syntheses, the parent, propadiene is produced on a large scale as an equilibrium mixture with methylacetylene:\nThis mixture, known as MAPP gas, is commercially available.\n\nLaboratory methods for the formation of allenes include:\n\nAllenes function as ligands, not unlike alkenes. A typical complex is Pt(η-allene)(PPh). Ni(0) reagents catalyze the cyclooligomerization of allene. Using a suitable catalyst (e.g. Wilkinson's catalyst), it is possible to reduce just one of the double bonds of an allene.\n\nMany rings or ring systems are known by semisystematic names that assume a maximum number of noncumulative bonds. To unambiguously specify derivatives that include cumulated bonds (and hence fewer hydrogens than would be expected from the skeleton), a lowercase delta may be used with a subscript indicating the number of cumulated double bonds from that atom, e.g. 8δ-Benzocyclononene. This may be combined with the λ-convention for specifying nonstandard valency states, e.g. 2λδ,5λδ-Thieno[3,4-c]thiophene.\n\n\n\n", "id": "2762", "title": "Allene"}
{"url": "https://en.wikipedia.org/wiki?curid=2763", "text": "Alkyne\n\nIn organic chemistry, an alkyne is an unsaturated hydrocarbon containing at least one carbon—carbon triple bond. The simplest acyclic alkynes with only one triple bond and no other functional groups form a homologous series with the general chemical formula . Alkynes are traditionally known as acetylenes, although the name \"acetylene\" also refers specifically to CH, known formally as ethyne using IUPAC nomenclature. Like other hydrocarbons, alkynes are generally hydrophobic but tend to be more reactive.\n\nAlkynes are characteristically more unsaturated than alkenes. Thus they add two equivalents of bromine whereas an alkene adds only one equivalent in the reaction. Other reactions are listed below. In some reactions, alkynes are less reactive than alkenes. For example, in a molecule with an -ene and an -yne group, addition occurs preferentially at the -ene. Possible explanations involve the two π-bonds in the alkyne delocalising, which would reduce the energy of the π-system or the stability of the intermediates during the reaction.\nThey show greater tendency to polymerize or oligomerize than alkenes do. The resulting polymers, called polyacetylenes (which do not contain alkyne units) are conjugated and can exhibit semiconducting properties.\n\nIn acetylene, the H–C≡C bond angles are 180°. By virtue of this bond angle, alkynes are rod-like. Correspondingly, cyclic alkynes are rare. Benzyne is highly unstable. The C≡C bond distance of 121 picometers is much shorter than the C=C distance in alkenes (134 pm) or the C–C bond in alkanes (153 pm).\n\nThe triple bond is very strong with a bond strength of 839 kJ/mol. The sigma bond contributes 369 kJ/mol, the first pi bond contributes 268 kJ/mol and the second pi-bond of 202 kJ/mol bond strength. Bonding usually discussed in the context of molecular orbital theory, which recognizes the triple bond as arising from overlap of s and p orbitals. In the language of valence bond theory, the carbon atoms in an alkyne bond are sp hybridized: they each have two unhybridized p orbitals and two sp hybrid orbitals. Overlap of an sp orbital from each atom forms one sp–sp sigma bond. Each p orbital on one atom overlaps one on the other atom, forming two pi bonds, giving a total of three bonds. The remaining sp orbital on each atom can form a sigma bond to another atom, for example to hydrogen atoms in the parent acetylene. The two sp orbitals project on opposite sides of the carbon atom.\n\nInternal alkynes feature carbon substituents on each acetylenic carbon. Symmetrical examples include diphenylacetylene and 3-hexyne.\n\nTerminal alkynes have the formula RCH. An example is methylacetylene (propyne using IUPAC nomenclature). Terminal alkynes, like acetylene itself, are mildly acidic, with p\"K\" values of around 25. They are far more acidic than alkenes and alkanes, which have p\"K\" values of around 40 and 50, respectively. The acidic hydrogen on terminal alkynes can be replaced by a variety of groups resulting in halo-, silyl-, and alkoxoalkynes. The carbanions generated by deprotonation of terminal alkynes are called acetylides.\n\nIn systematic chemical nomenclature, alkynes are named with the Greek prefix system without any additional letters. Examples include ethyne or octyne. In parent chains with four or more carbons, it is necessary to say where the triple bond is located. For octyne, one can either write 3-octyne or oct-3-yne when the bond starts at the third carbon. The lowest number possible is given to the triple bond. When no superior functional groups are present, the parent chain must include the triple bond even if it is not the longest possible carbon chain in the molecule. Ethyne is commonly called by its trivial name acetylene.\n\nIn chemistry, the suffix -yne is used to denote the presence of a triple bond. In organic chemistry, the suffix often follows IUPAC nomenclature. However, inorganic compounds featuring unsaturation in the form of triple bonds may be denoted by substitutive nomenclature with the same methods used with alkynes (i.e. the name of the corresponding saturated compound is modified by replacing the \"-ane\" ending with \"-yne\"). \"-diyne\" is used when there are two triple bonds, and so on. The position of unsaturation is indicated by a numerical locant immediately preceding the \"-yne\" suffix, or 'locants' in the case of multiple triple bonds. Locants are chosen so that the numbers are low as possible. \"-yne\" is also used as an infix to name substituent groups that are triply bound to the parent compound.\n\nSometimes a number between hyphens is inserted before it to state which atoms the triple bond is between. This suffix arose as a collapsed form of the end of the word \"acetylene\". The final \"-e\" disappears if it is followed by another suffix that starts with a vowel.\n\nCommercially, the dominant alkyne is acetylene itself, which is used as a fuel and a precursor to other compounds, e.g., acrylates. Hundreds of millions of kilograms are produced annually by partial oxidation of natural gas:\nPropyne, also industrially useful, is also prepared by thermal cracking of hydrocarbons. Most other industrially useful alkyne derivatives are prepared from acetylene, e.g. via condensation with formaldehyde.\n\nSpecialty alkynes are prepared by dehydrohalogenation of vicinal alkyl dihalides or vinyl halides. Metal acetylides can be coupled with primary alkyl halides. Via the Fritsch–Buttenberg–Wiechell rearrangement, alkynes are prepared from vinyl bromides. Alkynes can be prepared from aldehydes using the Corey–Fuchs reaction and from aldehydes or ketones by the Seyferth–Gilbert homologation. In the alkyne zipper reaction, alkynes are generated from other alkynes by treatment with a strong base.\n\nFeaturing a reactive functional group, alkynes participate in many organic reactions.\n\nAlkynes characteristically undergo reactions that show that they are \"doubly unsaturated\", meaning that each alkyne unit is capable of adding two equivalents of H, halogens or related HX reagents (X = halide, pseudohalide, etc.). Depending on catalysts and conditions, alkynes add one or two equivalents of hydrogen. Partial hydrogenation, stopping after the addition of only one equivalent to give the alkene, is usually more desirable since alkanes are less useful:\nThe largest scale application of this technology is the conversion of acetylene to ethylene in refineries. The steam cracking of alkanes yields a few percent acetylene, which is selectively hydrogenated in the presence of a palladium/silver catalyst. For more complex alkynes, the Lindlar catalyst is widely recommended to avoid formation of the alkane, for example in the conversion of phenylacetylene to styrene.\n\nSimilarly, halogenation of alkynes gives the vinyl dihalides or alkyl tetrahalides:\n\nThe addition of nonpolar E–H bonds across C≡C is general for silanes, boranes, and related hydrides. The hydroboration of alkynes gives vinylic boranes which oxidize to the corresponding aldehyde or ketone. In the thiol-yne reaction the substrate is a thiol.\n\nAcid-promoted addition reactions are likewise analogous to those of alkenes, including Markovnikov selectivity. Hydrohalogenation gives the corresponding vinyl halides or alkyl dihalides, again depending on the number of equivalents of HX added. The hydration reaction gives an enol via the addition of one equivalent of water, a structure that tautomerizes to form a ketone or aldehyde. For example, the hydration of phenylacetylene gives acetophenone, and the (PhP)AuCH-catalyzed hydration of 1,8-nonadiyne to 2,8-nonanedione:\n\nAlkynes undergo diverse cycloaddition reactions. Most notable is the Diels–Alder reaction with 1,3-dienes to give 1,4-cyclohexadienes. This general reaction has been extensively developed and electrophilic alkynes are especially effective dienophiles. The \"cycloadduct\" derived from the addition of alkynes to 2-pyrone eliminates carbon dioxide to give the aromatic compound. Other specialized cycloadditions include multicomponent reactions such as alkyne trimerisation to give aromatic compounds and the [2+2+1]-cycloaddition of an alkyne, alkene and carbon monoxide in the Pauson–Khand reaction. Non-carbon reagents also undergo cyclization, e.g. Azide alkyne Huisgen cycloaddition to give triazoles. Cycloaddition processes involving alkynes are often catalyzed by metals, e.g. enyne metathesis and alkyne metathesis, which allows the scrambling of carbyne (RC) centers:\nOxidative cleavage of alkynes proceeds via cycloaddition to metal oxides. Most famously, potassium permanganate converts alkynes to a pair of carboxylic acids.\n\nIn addition to undergoing the reactions characteristic of internal alkynes, terminal alkynes are reactive as weak acids, with p\"K\" values (25) between that of ammonia (35) and ethanol (16). The acetylide conjugate base is stabilized as a result of the high s character of the sp orbital, in which the electron pair resides. Electrons in an s orbital benefit from closer proximity to the positively charged atom nucleus, and are therefore lower in energy. Treatment of terminal alkynes with a strong base gives the corresponding metal acetylides:\nThe reactions of alkynes with certain metal cations, e.g. Ag also gives acetylides. Thus, few drops of diamminesilver(I) hydroxide (Ag(NH)OH) reacts with terminal alkynes signaled by formation of a white precipitate of the silver acetylide.\nAcetylide derivatives are synthetically useful nucleophiles that participate in C–C bond forming reactions, as illustrated in the area called \"Reppe Chemistry\".\n\nIn the Favorskii reaction and in alkynation in general, terminal alkynes add to carbonyl compounds to give the hydroxyalkyne. Coupling of terminal alkynes to give dialkynes is effected in the Cadiot–Chodkiewicz coupling, Glaser coupling, and the Eglinton coupling reactions. Terminal alkynes can also be coupled to aryl or vinyl halides as in the Sonogashira coupling.\n\nTerminal alkynes, including acetylene itself, can react with water to give aldehydes. The transformation typically requires special metal catalysts to give this anti-Markovnikov addition result.\n\nAlkynes form complexes with transition metals. Such compounds are sometimes useful reagents or illustrate the role that metals play in catalytic transformations of alkynes.\n\nAccording to Ferdinand Bohlmann, the first naturally occurring acetylenic compound, dehydromatricaria ester, was isolated from an \"Artemisia\" species in 1826. In the nearly two centuries that have followed, well over a thousand naturally occurring acetylenes have been discovered and reported. Polyynes, a subset of this class of natural products, have been isolated from a wide variety of plant species, cultures of higher fungi, bacteria, marine sponges, and corals. Some acids like tariric acid contains an alkyne group. Diynes and triynes, species with the linkage RC≡C–C≡CR′ and RC≡C–C≡C–C≡CR′ respectively, occur in certain plants (\"Ichthyothere\", \"Chrysanthemum\", \"Cicuta\", \"Oenanthe\" and other members of the Asteraceae and Apiaceae families). Some examples are cicutoxin, oenanthotoxin, falcarinol and carotatoxin. These compounds are highly bioactive, e.g. as nematocides. 1-Phenylhepta-1,3,5-triyne is illustrative of a naturally occurring triyne.\n\nAlkynes occur in some pharmaceuticals, including the contraceptive noretynodrel. A carbon–carbon triple bond is also present in marketed drugs such as the antiretroviral Efavirenz and the antifungal Terbinafine. Molecules called ene-diynes feature a ring containing an alkene (\"ene\") between two alkyne groups (\"diyne\"). These compounds, e.g. calicheamicin, are some of the most aggressive antitumor drugs known, so much so that the ene-diyne subunit is sometimes referred to as a \"warhead\". Ene-diynes undergo rearrangement via the Bergman cyclization, generating highly reactive radical intermediates that attack DNA within the tumor.\n\n", "id": "2763", "title": "Alkyne"}
{"url": "https://en.wikipedia.org/wiki?curid=2764", "text": "AbiWord\n\nAbiWord () is a free and open-source software word processor written in C++. Since version 3 it is based on GTK+ 3. The name \"AbiWord\" is derived from the root of the Spanish word \"\"abierto\"\", meaning \"open\".\n\nAbiWord was originally started by SourceGear Corporation as the first part of a proposed AbiSuite but was adopted by open source developers after SourceGear changed its business focus and ceased development. It now runs on Linux, Microsoft Windows (Last 2.8.6, 2.9.4 beta ), ReactOS, Solaris, AmigaOS 4.0 (through its Cygnix X11 engine), MeeGo (on the Nokia N9 smartphone), Maemo (on the Nokia N810) QNX and other operating systems.\n\nThe macOS port has remained on version 2.4 since 2005, although the current version does run non-natively on macOS through XQuartz.\n\nAbiWord is part of the AbiSource project which develops a number of office-related technologies.\n\nThe software is available on Android devices as part of the \"Debian noroot\" package from the Google Play Store.\n\nAbiWord supports both basic word processing features such as lists, indents and character formats, and more sophisticated features including tables, styles, page headers and footers, footnotes, templates, multiple views, page columns, spell checking, and grammar checking. Starting with version 2.8.0, AbiWord includes a collaboration plugin that allows integration with AbiCollab.net, a Web-based service that permits multiple users to work on the same document in real time, in full synchronization. The Presentation view of AbiWord, which permits easy display of presentations created in AbiWord on \"screen-sized\" pages, is another feature not often found in word processors.\n\nAbiWord generally works similarly to classic versions (pre-Office 2007) of Microsoft Word, as direct ease of migration was a high priority early goal. While many interface similarities remain, cloning the Word interface is no longer a top priority. The interface is intended to follow user interface guidelines for each respective platform.\n\nAbiWord comes with several import and export filters providing a partial support for such formats as HTML, Microsoft Word (.doc), Office Open XML (.docx), OpenDocument Text (.odt), Rich Text Format (.rtf), and text documents (.txt). LaTeX is supported for export only. Plug-in filters are available to deal with many other formats, notably WordPerfect documents. The native file format, .abw, uses XML, so as to mitigate vendor lock-in concerns with respect to interoperability and digital archiving.\n\nThe AbiWord project includes a US English-only grammar checking plugin using Link Grammar. AbiWord had grammar checking before any other open source word processor, although a grammar checker was later added to OpenOffice.org. Link Grammar is both a theory of syntax and an open source parser which is now developed by the AbiWord project.\n\n\n", "id": "2764", "title": "AbiWord"}
{"url": "https://en.wikipedia.org/wiki?curid=2766", "text": "Ames test\n\nThe Ames test is a widely employed method that uses bacteria to test whether a given chemical can cause mutations in the DNA of the test organism. More formally, it is a biological assay to assess the mutagenic potential of chemical compounds. A positive test indicates that the chemical is mutagenic and therefore may act as a carcinogen, because cancer is often linked to mutation. The test serves as a quick and convenient assay to estimate the carcinogenic potential of a compound because standard carcinogen assays on mice and rats are time-consuming (taking two to three years to complete) and expensive. However, false-positives and false-negatives are known.\n\nThe procedure was described in a series of papers in the early 1970s by Bruce Ames and his group at the University of California, Berkeley.\n\nThe Ames test uses several strains of the bacterium \"Salmonella typhimurium\" that carry mutations in genes involved in histidine synthesis. These strains are auxotrophic mutants, i.e. they require histidine for growth, but cannot produce it. The method tests the capability of the tested substance in creating mutations that result in a return to a \"prototrophic\" state, so that the cells can grow on a histidine-free medium.\n\nThe tester strains are specially constructed to detect either frameshift (e.g. strains TA-1537 and TA-1538) or point (e.g. strain TA-1531) mutations in the genes required to synthesize histidine, so that mutagens acting via different mechanisms may be identified. Some compounds are quite specific, causing reversions in just one or two strains. The tester strains also carry mutations in the genes responsible for lipopolysaccharide synthesis, making the cell wall of the bacteria more permeable, and in the excision repair system to make the test more sensitive. Rat liver extract is optionally added to simulate the effect of metabolism, as some compounds, like benzo[\"a\"]pyrene, are not mutagenic themselves but their metabolic products are.\n\nThe bacteria are spread on an agar plate with small amount of histidine. This small amount of histidine in the growth medium allows the bacteria to grow for an initial time and have the opportunity to mutate.\nWhen the histidine is depleted only bacteria that have mutated to gain the ability to produce its own histidine will survive. The plate is incubated for 48 hours. The mutagenicity of a substance is proportional to the number of colonies observed.\n\nMutagens identified via Ames test are also possible carcinogens, and early studies by Ames showed that 90% of known carcinogens may be identified via this test. Later studies however showed identification of 50–70% of known carcinogens. The test was used to identify a number of compounds previously used in commercial products as potential carcinogens. Examples include tris(2,3-dibromopropyl)phosphate, which was used as a flame retardant in plastic and textiles such as children's sleepwear, and furylfuramide which was used as an antibacterial additive in food in Japan in 1960s and 1970s. Furylfuramide in fact had previously passed animal test, but more vigorous tests after its identification in the Ames test showed it to be carcinogenic. Their positive tests resulted in those chemicals being withdrawn from use in consumer products.\n\nOne interesting result from the Ames test is that the dose response curve using varying concentrations of chemical is almost always linear, indicating that there is no threshold concentration for mutagenesis. It therefore suggests that, as with radiations, there may be no safe threshold for chemical mutagens or carcinogens. However some proposed that organisms can tolerate low level of mutagens due to protective mechanisms such as DNA repair, and threshold may exist for certain chemical mutagens. Bruce Ames himself argued against linear dose-response extrapolation from the high dose used in carcinogenesis tests in animal systems to the lower dose of chemicals normally encountered in human exposure, as the results may be false positives due to mitogenic response caused by the artificially high dose of chemicals used in such tests. He also cautioned against the \"hysteria over tiny traces of chemicals that may or may not cause cancer\", that \"completely drives out the major risks you should be aware of.\"\n\nThe Ames test is often used as one of the initial screens for potential drugs to weed out possible carcinogens, and it is one of the eight tests required under the Pesticide Act (USA) and one of six tests required under the Toxic Substances Control Act (USA).\n\n\"Salmonella typhimurium\" is a prokaryote, therefore it is not a perfect model for humans. Rat liver S9 fraction is used to mimic the mammalian metabolic conditions so that the mutagenic potential of metabolites formed by a parent molecule in the hepatic system can be assessed; however, there are differences in metabolism between human and rat that can affect the mutagenicity of chemicals being tested. The test may therefore be improved by the use of human liver S9 fraction; its use was previously limited by its availability, but it is now available commercially and therefore may be more feasible. An adapted \"in vitro\" model has been made for eukaryotic cells, for example yeast.\n\nMutagens identified in the Ames test need not necessarily be carcinogenic, and further tests are required for any potential carcinogen identified in the test. Drugs that contain the nitrate moiety sometimes come back positive for Ames when they are indeed safe. The nitrate compounds may generate nitric oxide, an important signal molecule that can give a false positive. Nitroglycerin is an example that gives a positive Ames yet is still used in treatment today. Nitrates in food however may be reduced by bacterial action to nitrites which are known to generate carcinogens by reacting with amines and amides. Long toxicology and outcome studies are needed with such compounds to disprove a positive Ames test.\n\nThe Ames test was initially developed using agar plates (the plate incorporation technique), as described above. Since that time, a popular alternative to performing the Ames test has been developed, which is known as the \"fluctuation method\". This technique is the same in concept as the agar-based method, with bacteria being added to a reaction mixture with a small amount of histidine, which allows the bacteria to grow and mutate, returning to synthesize their own histidine. By including a pH indicator, the frequency of mutation is counted in microplates as the number of wells which have changed color (caused by a drop in pH due to metabolic processes of reproducing bacteria). As with the traditional Ames test, the sample is compared to the natural background rate of reverse mutation in order to establish the genotoxicity of a substance.The fluctuation method is performed entirely in liquid culture and is scored by counting the number of wells that turn yellow from purple in 96-well or 384-well microplates. \nIn the 96-well plate method the frequency of mutation is counted as the number of wells out of 96 which have changed color. The plates are incubated for up to five days, with mutated (yellow) colonies being counted each day and compared to the background rate of reverse mutation using established tables of significance to determine the significant differences between the background rate of mutation and that for the tested samples.\n\nIn the more scaled-down 384-well plate microfluctuation method the frequency of mutation is counted as the number of wells out of 48 which have changed color after 2 days of incubation. A test sample is assayed across 6 dose levels with concurrent zero-dose (background) and positive controls which all fit into one 384-well plate. The assay is performed in triplicates to provide statistical robustness. It uses the recommended OECD Guideline 471 tester strains (histidine auxotrophs and tryptophan auxotrophs).\n\nThe fluctuation method is comparable to the traditional pour plate method in terms of sensitivity and accuracy, however, it does have a number of advantages: it needs less test sample, it has a simple colorimetric endpoint, counting the number of positive wells out of possible 96 or 48 wells is much less time consuming than counting individual colonies on an agar plate. Several commercial kits are available. Most kits have consumable components in a ready-to-use state, including lyophilized bacteria, and tests can be performed using multichannel pipettes. The fluctuation method also allows for testing higher volumes of aqueous samples (up to 75% v/v), increasing the sensitivity and extending its application to low-level environmental mutagens.\n", "id": "2766", "title": "Ames test"}
{"url": "https://en.wikipedia.org/wiki?curid=2767", "text": "ACE inhibitor\n\nAn angiotensin-converting-enzyme inhibitor (ACE inhibitor) is a pharmaceutical drug used primarily for the treatment of hypertension (elevated blood pressure) and congestive heart failure.\n\nThis group of drugs causes relaxation of blood vessels as well as a decrease in blood volume, which leads to lower blood pressure and decreased oxygen demand from the heart. They inhibit the angiotensin-converting enzyme, an important component of the renin–angiotensin system.\n\nFrequently prescribed ACE inhibitors include zofenopril, perindopril, trandolapril, captopril, enalapril, lisinopril, and ramipril.\n\nACE inhibitors were initially approved for the treatment of hypertension and can be used alone or in combination with other antihypertensive medications. Later, they were found useful for other cardiovascular and kidney diseases including:\n\nIn treating heart disease, ACE inhibitors are usually used with other medications. A typical treatment plan often includes an ACE inhibitor, a beta blocker, a long-acting nitrate, and a calcium channel blocker, in combinations that are adjusted to the individual patient's needs. There are fixed-dose combination drugs, such as ACE inhibitor and thiazide combinations.\n\nACE inhibitors have also been used in chronic kidney failure and kidney involvement in systemic sclerosis (hardening of tissues, as scleroderma renal crisis).\n\nFurthermore, ACE inhibitors may also be used to help decrease excessive water consumption in schizophrenic patients with psychogenic polydipsia. A double-blind, placebo-controlled trial showed that when used for this purpose, enalapril lead to decreased consumption (determined by urine output and osmality) in 60% of patients; the same effect has been demonstrated in other ACE inhibitors.\n\nACE inhibitors reduce the activity of the renin-angiotensin-aldosterone system (RAAS) as the primary etiologic (causal) event in the development of hypertension in people with diabetes mellitus, as part of the insulin-resistance syndrome or as a manifestation of renal disease.\n\nOne mechanism for maintaining the blood pressure is the release of renin, an enzyme, from cells in the kidney (to be specific, the juxtaglomerular apparatus). This proteolytically cleaves and activates another circulating protein, angiotensin. This system is activated in response to a fall in blood pressure (hypotension) and markers of problems with the salt-water balance of the body, such as decreased sodium concentration in the distal tubules of the kidney, decreased blood volume, and stimulation of the kidney by the sympathetic nervous system. In such situations, the kidneys release renin, which acts as an enzyme and cuts off all but the first ten amino acid residues of angiotensinogen (a protein made in the liver, and which circulates in the blood). These ten residues are then known as angiotensin I. ACE then removes a further two residues, converting angiotensin I into angiotensin II. ACE is found in the pulmonary circulation and in the endothelium of many blood vessels. The system increases blood pressure by increasing the amount of salt and water the body retains, although angiotensin is also very good at causing the blood vessels to tighten (a potent vasoconstrictor).\n\nACE inhibitors block the conversion of angiotensin I (AI) to angiotensin II (AII). They thereby lower arteriolar resistance and increase venous capacity; decrease cardiac output, cardiac index, stroke work, and volume; lower resistance in blood vessels in the kidneys; and lead to increased natriuresis (excretion of sodium in the urine).\nRenin increases in concentration in the blood as a result of negative feedback of conversion of AI to AII. AI increases for the same reason; AII and aldosterone decrease. Bradykinin increases because of less inactivation by ACE.\n\nUnder normal conditions, angiotensin II has these effects:\n\nWith ACE inhibitor use, the production of AII is decreased, leading to decreased blood pressure.\n\nEpidemiological and clinical studies have shown ACE inhibitors reduce the progress of diabetic nephropathy independently from their blood pressure-lowering effect. This action of ACE inhibitors is used in the prevention of diabetic renal failure.\n\nACE inhibitors have been shown to be effective for indications other than hypertension even in patients with normal blood pressure. The use of a maximum dose of ACE inhibitors in such patients (including for prevention of diabetic nephropathy, congestive heart failure, and prophylaxis of cardiovascular events) is justified, because it improves clinical outcomes independently of the blood pressure-lowering effect of ACE inhibitors. Such therapy, of course, requires careful and gradual titration of the dose to prevent the effects of rapidly decreasing blood pressure (dizziness, fainting, etc.).\n\nACE inhibitors have also been shown to cause a central enhancement of parasympathetic nervous system activity in healthy volunteers and patients with heart failure. This action may reduce the prevalence of malignant cardiac arrhythmias, and the reduction in sudden death reported in large clinical trials.\nACE Inhibitors also reduce plasma norepinephrine levels, and its resulting vasoconstriction effects, in heart failure patients, thus breaking the vicious circles of sympathetic and renin angiotensin system activation, which sustains the downward spiral in cardiac function in congestive heart failure\n\nThe ACE inhibitor enalapril has also been shown to reduce cardiac cachexia in patients with chronic heart failure. Cachexia is a poor prognostic sign in patients with chronic heart failure.\nACE inhibitors are under early investigation for the treatment of frailty and muscle wasting (sarcopenia) in elderly patients without heart failure.\n\nCommon adverse drug reactions include: hypotension, cough, hyperkalemia, headache, dizziness, fatigue, nausea, and renal impairment. ACE inhibitors might increase inflammation-related pain, perhaps mediated by the buildup of bradykinin that accompanies ACE inhibition.\nThe main adverse effects of ACE inhibition can be understood from their pharmacological action. The other reported adverse effects are hepatotoxicity and effect on the fetus.\nRenal impairment is a significant potential adverse effect of all ACE inhibitors that directly follows from their mechanism of action. Patients starting on an ACE inhibitor usually have a modest reduction in glomerular filtration rate (GFR) that stabilizes after several days. However, the decrease may be significant in conditions of decreased renal perfusion, such as renal artery stenosis, heart failure, polycystic kidney disease, or volume depletion. In these patients, maintenance of GFR depends on angiotensin-II-dependent efferent vasomotor tone. Therefore, renal function should be closely monitored over the first few days after initiation of treatment with ACE inhibitor in patients with decreased renal perfusion. A moderate reduction in renal function, no greater than 30% rise in serum creatinine, that is stabilized after a week of treatment is deemed acceptable as part of the therapeutic effect, providing the residual renal function is sufficient. This is especially a problem if the patient is concomitantly taking an NSAID and a diuretic. When the three drugs are taken together, the risk of developing renal failure is significantly increased.\n\nHyperkalemia (high concentration of potassium in the blood) is another possible complication of treatment with an ACE inhibitor due to its effect on aldosterone. Suppression of angiotensin II leads to a decrease in aldosterone levels. Since aldosterone is responsible for increasing the excretion of potassium, ACE inhibitors can cause retention of potassium. Some people, however, can continue to lose potassium while on an ACE inhibitor. Hyperkalemia may decrease the velocity of impulse conduction in the nerves and muscles, including cardiac tissues. This leads to cardiac dysfunction and neuromuscular consequences, such as muscle weakness, paresthesia, nausea, diarrhea, and others. Close monitoring of potassium levels is required in patients receiving treatment with ACE inhibitors who are at risk of hyperkalemia.\n\nAnother possible adverse effect specific for ACE inhibitors, but not for other RAAS blockers, is an increase in bradykinin level. Elevated bradykinin level due to ACE inhibition can be a cause of dry cough, angioedema and/or rash, hypotension, and inflammation-related pain.\n\nA persistent dry cough is a relatively common adverse effect believed to be associated with the increases in bradykinin levels produced by ACE inhibitors, although the role of bradykinin in producing these symptoms has been disputed. Patients who experience this cough are often switched to angiotensin II receptor antagonists.\n\nSome patients develop angioedema due to increased bradykinin levels. A genetic predisposition may exist toward this adverse effect in patients who degrade bradykinin more slowly than average.\n\nRash and taste disturbances, infrequent with most ACE inhibitors, are more prevalent in captopril, and this is attributed to its sulfhydryl moiety. This has led to decreased use of captopril in clinical setting, although it is still used in scintigraphy of the kidney.\n\nA severe rare allergic reaction can affect the bowel wall and secondarily cause abdominal pain.\n\nHematologic effects, such as neutropenia, agranulocytosis and other blood dyscrasias, have occurred during therapy with ACE inhibitors, especially in patients with additional risk factors (see Warnings). Patients should be advised to report symptoms such as sore throat or fever to their physician.\n\nIn pregnant women, ACE inhibitors taken during all the trimesters have been reported to cause congenital malformations, stillbirths, and neonatal deaths. Commonly reported fetal abnormalities include hypotension, renal dysplasia, anuria/oliguria, oligohydramnios, intrauterine growth retardation, pulmonary hypoplasia, patent ductus arteriosus, and incomplete ossification of the skull. Overall, about half of newborns exposed to ACE inhibitors are adversely affected.\n\nSymptoms and Treatment: There are few reports of ACE inhibitor overdose in the literature. The most likely manifestations are hypotension, which may be severe, hyperkalemia, hyponatremia and renal impairment with metabolic acidosis. Treatment should be mainly symptomatic and supportive, with volume expansion using normal saline to correct hypotension and improve renal function, and gastric lavage followed by activated charcoal and a cathartic to prevent further absorption of the drug. Captopril, enalapril, lisinopril and perindopril are known to be removable by hemodialysis.\n\nThe ACE inhibitors are contraindicated in patients with:\n\nACE inhibitors should be used with caution in patients with:\n\nACE inhibitors are ADEC pregnancy category D, and should be avoided in women who are likely to become pregnant. In the U.S., ACE inhibitors must be labeled with a boxed warning concerning the risk of birth defects when taken during the second and third trimester. Their use in the first trimester is also associated with a risk of major congenital malformations, particularly affecting the cardiovascular and central nervous systems.\n\nA combination of ACE inhibitor with other drugs may increase effects of these drugs, but also the risk of adverse effects. The commonly reported adverse effects of drug combination with ACE are acute renal failure, hypotension, and hyperkalemia. The drugs interacting with ACE inhibitor should be prescribed with caution. Special attention should be given to combinations of ACE inhibitor with other RAAS blockers, diuretics (especially potassium-sparing diuretics), NSAIDs, anticoagulants, cyclosporine, DPP-4 inhibitors, and potassium supplements.\n\nPotassium supplementation should be used with caution and under medical supervision owing to the hyperkalemic effect of ACE inhibitors.\n\nACE inhibitors are easily identifiable by their common suffix, '-pril'. ACE inhibitors can be divided into three groups based on their molecular structure:\n\n\nThis is the largest group, including:\n\n\n\nAll ACE inhibitors have similar antihypertensive efficacy when equivalent doses are administered. The main differences lie with captopril, the first ACE inhibitor. Captopril has a shorter duration of action and an increased incidence of adverse effects. It is also the only ACE inhibitor capable of passing through the blood–brain barrier, although the significance of this characteristic has not been shown to have any positive clinical effects.\n\nIn a large clinical study, one of the agents in the ACE inhibitor class, ramipril (Altace), demonstrated an ability to reduce the mortality rates of patients suffering from a myocardial infarction, and to slow the subsequent development of heart failure. This finding was made after it was discovered that regular use of ramipril reduced mortality rates even in test subjects not having suffered from hypertension.\n\nSome believe ramipril's additional benefits may be shared by some or all drugs in the ACE-inhibitor class. However, ramipril currently remains the only ACE inhibitor for which such effects are actually evidence-based.\n\nA meta-analysis confirmed that ACE inhibitors are effective and certainly the first-line choice in hypertension treatment. This meta-analysis was based on 20 trials and a cohort of 158,998 patients, of whom 91% were hypertensive. ACE inhibitors were used as the active treatment in seven trials (n=76,615) and angiotensin receptor blocker (ARB) in 13 trials (n=82,383).\nACE inhibitors were associated with a statistically significant 10% mortality reduction: (HR 0.90; 95% CI, 0.84-0.97; P=0.004). In contrast, no significant mortality reduction was observed with ARB treatment (HR 0.99; 95% CI, 0.94-1.04; P=0.683). Analysis of mortality reduction by different ACE inhibitors showed that perindopril-based regimens are associated with a statistically significant 13% all-cause mortality reduction.\nTaking into account the broad spectrum of the hypertensive population, one might expect that an effective treatment with ACE inhibitors, in particular with perindopril, would result in an important gain of lives saved.\n\nThe ACE inhibitors have different strengths with different starting dosages. Dosage should be adjusted according to the clinical response.\nACE inhibitors possess many common characteristics with another class of cardiovascular drugs, angiotensin II receptor antagonists, which are often used when patients are intolerant of the adverse effects produced by ACE inhibitors. ACE inhibitors do not completely prevent the formation of angiotensin II, as blockage is dose-dependent, so angiotensin II receptor antagonists may be useful because they act to prevent the action of angiotensin II at the AT receptor, leaving AT receptor unblocked; the latter may have consequences needing further study.\n\nThe combination therapy of angiotensin II receptor antagonists with ACE inhibitors may be superior to either agent alone. This combination may increase levels of bradykinin while blocking the generation of angiotensin II and its activity at the AT receptor. This 'dual blockade' may be more effective than using an ACE inhibitor alone, because angiotensin II can be generated via non-ACE-dependent pathways. Preliminary studies suggest this combination of pharmacologic agents may be advantageous in the treatment of essential hypertension, chronic heart failure, and nephropathy. However, the more recent ONTARGET study showed no benefit of combining the agents and more adverse events. While statistically significant results have been obtained for its role in treating hypertension, clinical significance may be lacking. There are warnings about the combination of ACE inhibitors with ARBs.\n\nPatients with heart failure may benefit from the combination in terms of reducing morbidity and ventricular remodeling.\n\nThe most compelling evidence for the treatment of nephropathy has been found: This combination therapy partially reversed the proteinuria and also exhibited a renoprotective effect in patients afflicted with diabetic nephropathy, and pediatric IgA nephropathy.\n\nThe first step in the development of ACE inhibitors was the discovery of ACE in plasma by Leonard T. Skeggs and his colleagues in 1956. Brazilian scientist Sérgio Henrique Ferreira reported a bradykinin-potentiating factor (BPF) present in the venom of \"Bothrops jararaca\", a South American pit viper, in 1965. Ferreira then went to John Vane's laboratory as a postdoctoral fellow with his already-isolated BPF. The conversion of the inactive angiotensin I to the potent angiotensin II was thought to take place in the plasma. However, in 1967, Kevin K. F. Ng and John R. Vane showed plasma ACE is too slow to account for the conversion of angiotensin I to angiotensin II \"in vivo\". Subsequent investigation showed rapid conversion occurs during its passage through the pulmonary circulation.\n\nBradykinin is rapidly inactivated in the circulating blood, and it disappears completely in a single pass through the pulmonary circulation. Angiotensin I also disappears in the pulmonary circulation because of its conversion to angiotensin II. Furthermore, angiotensin II passes through the lungs without any loss. The inactivation of bradykinin and the conversion of angiotensin I to angiotensin II in the lungs was thought to be caused by the same enzyme. In 1970, Ng and Vane, using BPF provided by Ferreira, showed the conversion is inhibited during its passage through the pulmonary circulation.\n\nBPFs are members of a family of peptides whose potentiating action is linked to inhibition of bradykinin by ACE. Molecular analysis of BPF yielded a nonapeptide BPF teprotide (SQ 20,881), which showed the greatest ACE inhibition potency and hypotensive effect \"in vivo\". Teprotide had limited clinical value as a result of its peptide nature and lack of activity when given orally. In the early 1970s, knowledge of the structure-activity relationship required for inhibition of ACE was growing. David Cushman, Miguel Ondetti and colleagues used peptide analogues to study the structure of ACE, using carboxypeptidase A as a model. Their discoveries led to the development of captopril, the first orally-active ACE inhibitor, in 1975.\n\nCaptopril was approved by the United States Food and Drug Administration in 1981. The first nonsulfhydryl-containing ACE inhibitor, enalapril, was marketed two years later. At least 12 other ACE inhibitors have since been marketed.\n\nIn 1991, Japanese scientists created the first milk-based ACE inhibitor, in the form of a fermented milk drink, using specific cultures to liberate the tripeptide isoleucine-proline-proline (IPP) from the dairy protein. Valine-proline-proline (VPP) is also liberated in this process—another milk tripeptide with a very similar chemical structure to IPP. Together, these peptides are now often referred to as lactotripeptides. In 1996, the first human study confirmed the blood pressure-lowering effect of IPP in fermented milk. Although twice the amount of VPP is needed to achieve the same ACE-inhibiting activity as the originally discovered IPP, VPP also is assumed to add to the total blood pressure lowering effect.\nSince the first lactotripeptides discovery, more than 20 human clinical trials have been conducted in many different countries.\n\n\n", "id": "2767", "title": "ACE inhibitor"}
{"url": "https://en.wikipedia.org/wiki?curid=2769", "text": "Antianginal\n\nAn antianginal is any drug used in the treatment of \"angina pectoris\", a symptom of ischaemic heart disease.\n\nDrugs used are nitrates, beta blockers, or calcium channel blockers.\n\nNitrates cause vasodilation of the venous capacitance vessels by stimulating the endothelium-derived relaxing factor (EDRF). Used to relieve both exertional and vasospastic angina by allowing venous pooling, reducing the pressure in the ventricles and so reducing wall tension and oxygen requirements in, the heart. Short-acting nitrates are used to abort angina attacks that have occurred, while longer-acting nitrates are used in the prophylactic management of the condition.\n\nAgents include nitroglycerin (glyceryl trinitrate) or pentaerythritol tetranitrate, isosorbide dinitrate and isosorbide mononitrate.triglycerol nitrate\n\nBeta blockers are used in the prophylaxis of exertional angina by reducing the myocardial oxygen demand below the level that would provoke an angina attack.\n\nThey are contraindicated in variant angina and can precipitate heart failure. They are also contraindicated in severe asthmatics due to bronchoconstriction, and should be used cautiously in diabetics as they can mask symptoms of hypoglycemia.\n\nAgents include either cardioselectives such as acebutolol or metoprolol, or non-cardioselectives such as oxprenolol or sotalol.\n\nCalcium ion (Ca) antagonists (Calcium channel blockers) are used in the treatment of chronic stable angina, and most effectively in the treatment of variant angina (directly preventing coronary artery vasospasm). They are not used in the treatment of unstable angina .\n\nIn vitro, they dilate the coronary and peripheral arteries and have negative inotropic and chronotropic effects - decreasing afterload, improving myocardial efficiency, reducing heart rate and improving coronary blood flow.\n\"In vivo\", the vasodilation and hypotension trigger the baroreceptor reflex. Therefore, the net effect is the interplay of direct and reflex actions.\n\n\nExamples include Class I agents (\"e.g.\", verapamil), Class II agents (\"e.g.\", amlodipine, nifedipine), or the Class III agent diltiazem.\n\nNifedipine is more a potent vasodilator and more effective in angina. It is in the class of dihydropyridines and does not affect refrectory period on SA node conduction.\n", "id": "2769", "title": "Antianginal"}
{"url": "https://en.wikipedia.org/wiki?curid=2770", "text": "Anatomical Therapeutic Chemical Classification System\n\nThe Anatomical Therapeutic Chemical (ATC) Classification System is used for the classification of active ingredients of drugs according to the organ or system on which they act and their therapeutic, pharmacological and chemical properties. It is controlled by the World Health Organization Collaborating Centre for Drug Statistics Methodology (WHOCC), and was first published in 1976.\n\nThis pharmaceutical coding system divides drugs into different groups according to the organ or system on which they act and/or their therapeutic and chemical characteristics. Each bottom-level ATC code stands for a pharmaceutically used substance, or a combination of substances, in a single indication (or use). This means that one drug can have more than one code: acetylsalicylic acid (aspirin), for example, has as a drug for local oral treatment, as a platelet inhibitor, and as an analgesic and antipyretic. On the other hand, several different brands share the same code if they have the same active substance and indications.\n\nThe ATC system is based on the earlier Anatomical Classification System, which is intended as a tool for the pharmaceutical industry to classify pharmaceutical products (as opposed to their active ingredients). This system, confusingly also called ATC, was initiated in 1971 by the European Pharmaceutical Market Research Association (EphMRA) and is being maintained by the EphMRA and the Pharmaceutical Business Intelligence and Research Group (PBIRG). Its codes are organised into four levels. The WHO's system, having five levels, is an extension and modification of the EphMRA's. It was first published in 1976.\n\nIn this system, drugs are classified into groups at five different levels:\n\nThe first level of the code indicates the anatomical main group and consists of one letter. There are 14 main groups:\n\n\"Example\": C Cardiovascular system\n\nThe second level of the code indicates the therapeutic main group and consists of two digits.\n\n\"Example\": C03 Diuretics\n\nThe third level of the code indicates the therapeutic/pharmacological subgroup and consists of one letter.\n\n\"Example\": C03C High-ceiling diuretics\n\nThe fourth level of the code indicates the chemical/therapeutic/pharmacological subgroup and consists of one letter.\n\n\"Example\": C03CA Sulfonamides\n\nThe fifth level of the code indicates the chemical substance and consists of two digits.\n\n\"Example\": C03CA01 Furosemide\n\nThe \"Anatomical Therapeutic Chemical Classification System for veterinary medicinal products\" (ATCvet) is used to classify veterinary drugs. ATCvet codes can be created by placing the letter Q in front of the ATC code of most human medications. For example, furosemide for veterinary use has the code QC03CA01.\n\nSome codes are used exclusively for veterinary drugs, such as \"QI Immunologicals\", \"QJ51 Antibacterials for intramammary use\" or \"QN05AX90 amperozide\".\n\nThe ATC system also includes defined daily doses (DDDs) for many drugs. This is a measurement of drug consumption based on the usual daily dose for a given drug. According to the definition, \"[t]he DDD is the assumed average maintenance dose per day for a drug used for its main indication in adults.\"\n\nNational issues of the ATC classification, such as the German \"Anatomisch-therapeutisch-chemische Klassifikation mit Tagesdosen\", may include additional codes and DDDs not present in the WHO version.\n\nATC follows guidelines in creating new codes for newly approved drugs. In order to create a new ATC code, an application has to be sent to the WHO. New ATC codes are published twice annually. A formal release of new ATC edition occurs once a year.\n\n\n", "id": "2770", "title": "Anatomical Therapeutic Chemical Classification System"}
{"url": "https://en.wikipedia.org/wiki?curid=2778", "text": "Parallel ATA\n\nParallel ATA (PATA), originally ', is an interface standard for the connection of storage devices such as hard disk drives, floppy disk drives, and optical disc drives in computers. The standard is maintained by the X3/INCITS committee. It uses the underlying ' (ATA) and Packet Interface (ATAPI) standards.\n\nThe Parallel ATA standard is the result of a long history of incremental technical development, which began with the original AT Attachment interface, developed for use in early PC AT equipment. The ATA interface itself evolved in several stages from Western Digital's original Integrated Drive Electronics (IDE) interface. As a result, many near-synonyms for ATA/ATAPI and its previous incarnations are still in common informal use, in particular Extended IDE (EIDE) and Ultra ATA (UATA). After the introduction of Serial ATA (SATA) in 2003, the original ATA was renamed to Parallel ATA, or PATA for short.\n\nParallel ATA cables have a maximum allowable length of only . Because of this limit, the technology normally appears as an internal computer storage interface. For many years, ATA provided the most common and the least expensive interface for this application. It has largely been replaced by SATA in newer systems.\n\nThe PATA standard was originally conceived as the \"AT Bus Attachment,\" abbreviated \"ATA\" because its primary feature was a direct connection to the 16-bit ISA bus introduced with the IBM PC/AT. The \"AT\" in \"IBM PC/AT\" refers to \"Advanced Technology\", but the ATA specifications published by the several standards committees simply use the name \"AT Attachment\" with no reference to advanced technology.\n\nThe first version of what is now called the ATA/ATAPI interface was developed by Western Digital under the name \"Integrated Drive Electronics\" (IDE). Together with Control Data Corporation (the hard drive manufacturer) and Compaq Computer (the initial customer), they developed the connector, the signaling protocols and so on, with the goal of remaining software compatible with the existing ST-506 hard drive interface. The first such drives appeared in Compaq PCs in 1986.\n\nThe term \"Integrated Drive Electronics\" refers not just to the connector and interface definition, but also to the fact that the drive controller is integrated into the drive, as opposed to a separate controller on or connected to the motherboard. The interface cards used to connect a parallel ATA drive to, for example, a PCI slot are not drive controllers: they are merely bridges between the host bus and the ATA interface. Since the original ATA interface is essentially just a 16-bit ISA bus in disguise, the bridge was especially simple in case of an ATA connector being located on an ISA interface card. The integrated controller presented the drive to the host computer as an array of 512-byte blocks with a relatively simple command interface. This relieved the mainboard and interface cards in the host computer of the chores of stepping the disk head arm, moving the head arm in and out, and so on, as had to be done with earlier ST-506 and ESDI hard drives. All of these low-level details of the mechanical operation of the drive were now handled by the controller on the drive itself. This also eliminated the need to design a single controller that could handle many different types of drives, since the controller could be unique for the drive. The host need only ask for a particular sector, or block, to be read or written, and either accept the data from the drive or send the data to it.\n\nThe interface used by these drives was standardized in 1994 as ANSI standard X3.221-1994, \"AT Attachment Interface for Disk Drives\". After later versions of the standard were developed, this became known as \"ATA-1\".\n\nA short-lived, seldom-used implementation of ATA was created for the IBM XT and similar machines that used the 8-bit version of the ISA bus. It has been referred to as \"XT-IDE\", \"XTA\" or \"XT Attachment\".\n\nWhen PC motherboard makers started to include onboard ATA interfaces in place of the earlier ISA plug-in cards, there was usually only one ATA connector on the board, which could support up to two hard drives. At the time, in combination with the floppy drive, this was sufficient for most people. When the CD-ROM was developed, many computers would have been unable to accept these drives if they had been ATA devices, due to already having two hard drives installed. Adding the CD-ROM drive would have required removal of one of the drives.\n\nSCSI was available as a CD-ROM expansion option at the time, but devices with SCSI were more expensive than ATA devices due to the need for a smart interface that is capable of bus arbitration. SCSI typically added to the cost of a storage device, in addition to the cost of a SCSI host adapter.\n\nThe less expensive solution was the addition of a dedicated CD-ROM interface, which was typically included as an expansion option on a sound card. PC motherboards initially did not come with support for more than simple beeps from internal speakers; thus, sound cards (such as the Sound Blaster Pro) were available for use with games, operating system and software event sounds, or to listen to audio CDs. Also, sound cards commonly included a gameport joystick/gamepad port along with interfaces to control a CD-ROM and transmit CD audio to the system.\n\nInitially, the second drive interface was not well defined. It was first introduced with interfaces specific to certain CD-ROM drives such as Mitsumi, Sony or Panasonic drives, and it was common to find early sound cards with two or three separate connectors each designed to match a certain brand of CD-ROM drive. This evolved into the standard ATA interface for ease of cross-compatibility, though the sound card ATA interface still usually supported only a single CD-ROM and not hard drives.\n\nThis second ATA interface on the sound card eventually evolved into the second motherboard ATA interface which was long included as a standard component in all PCs.\nCalled the \"primary\" and \"secondary\" ATA interfaces, they were assigned to base addresses 0x1F0 and 0x170 on ISA bus systems.\n\nIn 1994, about the same time that the ATA-1 standard was adopted, Western Digital introduced drives under a newer name, Enhanced IDE (EIDE). These included most of the features of the forthcoming ATA-2 specification and several additional enhancements. Other manufacturers introduced their own variations of ATA-1 such as \"Fast ATA\" and \"Fast ATA-2\".\n\nThe new version of the ANSI standard, \"AT Attachment Interface with Extensions ATA-2\" (X3.279-1996), was approved in 1996. It included most of the features of the manufacturer-specific variants.\n\nATA-2 also was the first to note that devices other than hard drives could be attached to the interface:\nAs mentioned in the previous sections, ATA was originally designed for, and worked only with hard disk drives and devices that could emulate them. The introduction of ATAPI (ATA Packet Interface) by a group called the Small Form Factor committee (SFF) allowed ATA to be used for a variety of other devices that require functions beyond those necessary for hard disk drives. For example, any removable media device needs a \"media eject\" command, and a way for the host to determine whether the media is present, and these were not provided in the ATA protocol.\n\nThe Small Form Factor committee approached this problem by defining ATAPI, the \"ATA Packet Interface\". ATAPI is actually a protocol allowing the ATA interface to carry SCSI commands and responses; therefore, all ATAPI devices are actually \"speaking SCSI\" other than at the electrical interface. In fact, some early ATAPI devices were simply SCSI devices with an ATA/ATAPI to SCSI protocol converter added on. The SCSI commands and responses are embedded in \"packets\" (hence \"ATA Packet Interface\") for transmission on the ATA cable. This allows any device class for which a SCSI command set has been defined to be interfaced via ATA/ATAPI.\n\nATAPI devices are also \"speaking ATA\", as the ATA physical interface and protocol are still being used to send the packets. On the other hand, ATA hard drives and solid state drives do not use ATAPI.\n\nATAPI devices include CD-ROM and DVD-ROM drives, tape drives, and large-capacity floppy drives such as the Zip drive and SuperDisk drive.\n\nThe SCSI commands and responses used by each class of ATAPI device (CD-ROM, tape, etc.) are described in other documents or specifications specific to those device classes\nand are not within ATA/ATAPI or the T13 committee's purview. One commonly used set is defined in the MMC SCSI command set.\n\nATAPI was adopted as part of ATA in INCITS 317-1998, \"AT Attachment with Packet Interface Extension (ATA/ATAPI-4)\".\n\nThe ATA/ATAPI-4 standard also introduced several \"Ultra DMA\" transfer modes. These initially supported speeds from 16 MByte/s to 33 MByte/second. In later versions, faster Ultra DMA modes were added, requiring new 80-wire cables to reduce crosstalk. The latest versions of Parallel ATA support up to 133 MByte/s.\n\nUltra ATA, abbreviated UATA, is a designation that has been primarily used by Western Digital for different speed enhancements to the ATA/ATAPI standards. For example, in 2000 Western Digital published a document describing \"Ultra ATA/100\", which brought performance improvements for the then-current ATA/ATAPI-5 standard by improving maximum speed of the Parallel ATA interface from 66 to 100 MB/s. Most of Western Digital's changes, along with others, were included in the ATA/ATAPI-6 standard (2002).\n\nThe terms \"integrated drive electronics\" (IDE), \"enhanced IDE\" and \"EIDE\" have come to be used interchangeably with ATA (now Parallel ATA, or PATA).\n\nIn addition, there have been several generations of \"EIDE\" drives marketed, compliant with various versions of the ATA specification. An early \"EIDE\" drive might be compatible with ATA-2, while a later one with ATA-6.\n\nNevertheless, a request for an \"IDE\" or \"EIDE\" drive from a computer parts vendor will almost always yield a drive that will work with most Parallel ATA interfaces.\n\nAnother common usage is to refer to the specification version by the fastest mode supported. For example, ATA-4 supported Ultra DMA modes 0 through 2, the latter providing a maximum transfer rate of 33 megabytes per second. ATA-4 drives are thus sometimes called \"UDMA-33\" drives, and sometimes \"ATA-33\" drives. Similarly, ATA-6 introduced a maximum transfer speed of 100 megabytes per second, and some drives complying to this version of the standard are marketed as \"PATA/100\" drives.\n\nInitially, the size of an ATA drive was stored in the system x86 BIOS using a type number (1 through 45) that predefined the C/H/S parameters and also often the landing zone, in which the drive heads are parked while not in use. Later, a \"user definable\" format called C/H/S or cylinders, heads, sectors was made available. These numbers were important for the earlier ST-506 interface, but were generally meaningless for ATA—the CHS parameters for later ATA large drives often specified impossibly high numbers of heads or sectors that did not actually define the internal physical layout of the drive at all. From the start, and up to ATA-2, every user had to specify explicitly how large every attached drive was. From ATA-2 on, an \"identify drive\" command was implemented that can be sent and which will return all drive parameters.\n\nOwing to a lack of foresight by motherboard manufacturers, the system BIOS was often hobbled by artificial C/H/S size limitations due to the manufacturer assuming certain values would never exceed a particular numerical maximum.\n\nThe first of these BIOS limits occurred when ATA drives reached sizes in excess of 504 megabytes, because some motherboard BIOSes would not allow C/H/S values above 1024 cylinders, 16 heads, and 63 sectors. Multiplied by 512 bytes per sector, this totals bytes which, divided by bytes per megabyte, equals 504 megabytes.\n\nThe second of these BIOS limitations occurred at 1024 cylinders, 256 heads, and 63 sectors, and a bug in MS-DOS and MS-Windows 95 limited the number of heads to 255. This totals to bytes, commonly referred to as the 8.4 gigabyte barrier. This is again a limit imposed by x86 BIOSes, and not a limit imposed by the ATA interface.\n\nIt was eventually determined that these size limitations could be overridden with a tiny program loaded at startup from a hard drive's boot sector. Some hard drive manufacturers, such as Western Digital, started including these override utilities with new large hard drives to help overcome these problems. However, if the computer was booted in some other manner without loading the special utility, the invalid BIOS settings would be used and the drive could either be inaccessible or appear to the operating system to be damaged.\n\nLater, an extension to the x86 BIOS disk services called the \"Enhanced Disk Drive\" (EDD) was made available, which makes it possible to address drives as large as 2 sectors.\n\nThe first drive interface used 22-bit addressing mode which resulted in a maximum drive capacity of two gigabytes. Later, the first formalized ATA specification used a 28-bit addressing mode through LBA28, allowing for the addressing of 2 () sectors (blocks) of 512 bytes each, resulting in a maximum capacity of 128 GiB (137 GB).\n\nATA-6 introduced 48-bit addressing, increasing the limit to 128 PiB (144 PB). As a consequence, any ATA drive of capacity larger than about 137 GB must be an ATA-6 or later drive. Connecting such a drive to a host with an ATA-5 or earlier interface will limit the usable capacity to the maximum of the interface.\n\nSome operating systems, including Windows XP pre-SP1, and Windows 2000 pre-SP3, disable LBA48 by default, requiring the user to take extra steps to use the entire capacity of an ATA drive larger than about 137 gigabytes.\n\nOlder operating systems, such as Windows 98, do not support 48-bit LBA at all. However, members of the third-party group MSFN have modified the Windows 98 disk drivers to add unofficial support for 48-bit LBA to Windows 95 OSR2, Windows 98, Windows 98 SE and Windows ME.\n\nSome 16-bit and 32-bit operating systems supporting LBA48 may still not support disks larger than 2 TiB due to using 32-bit arithmetics only; a limitation also applying to many boot sectors.\n\nParallel ATA (then simply called ATA or IDE) became the primary storage device interface for PCs soon after \nits introduction. In some systems, a third and fourth motherboard interface was provided, allowing up to eight ATA devices to be attached to the motherboard. Often, these additional connectors were implemented by inexpensive RAID controllers.\n\nSoon after the introduction of Serial ATA (SATA) in 2003, use of Parallel ATA declined. \nThe first motherboards with built-in SATA interfaces usually had only a single PATA connector \n(for up to two PATA devices), along with multiple SATA connectors.\n\nAs of 2007, some PC chipsets, for example the Intel ICH10, had removed support for PATA. Motherboard vendors still wishing to offer Parallel ATA with those chipsets must include an additional interface chip. In more recent computers, the Parallel ATA interface is rarely used even if present, as four or more Serial ATA connectors are usually provided on the motherboard and SATA devices of all types are common.\n\nWith Western Digital's withdrawal from the PATA market, hard disk drives with the PATA interface were no longer in production after December 2013 for other than specialty applications.\n\nParallel ATA cables transfer data 16 bits at a time. The traditional cable uses 40-pin connectors attached to a ribbon cable. Each cable has two or three connectors, one of which plugs into an adapter interfacing with the rest of the computer system. The remaining connector(s) plug into storage devices, most commonly hard disk drives or optical drives.\n\nATA's cables have had 40 wires for most of its history (44 conductors for the smaller form-factor version used for 2.5\" drives—the extra four for power), but an 80-wire version appeared with the introduction of the \"UDMA/66\" mode. All of the additional wires in the new cable are ground wires, interleaved with the previously defined wires to reduce the effects of capacitive coupling between neighboring signal wires, reducing crosstalk. Capacitive coupling is more of a problem at higher transfer rates, and this change was necessary to enable the 66 megabytes per second (MB/s) transfer rate of \"UDMA4\" to work reliably. The faster \"UDMA5\" and \"UDMA6\" modes also require 80-conductor cables.\n\nThough the number of wires doubled, the number of connector pins and the pinout remain the same as 40-conductor cables, and the external appearance of the connectors is identical. Internally, the connectors are different; the connectors for the 80-wire cable connect a larger number of ground wires to the ground pins, while the connectors for the 40-wire cable connect ground wires to ground pins one-for-one. 80-wire cables usually come with three differently colored connectors (blue, black, and gray for controller, master drive, and slave drive respectively) as opposed to uniformly colored 40-wire cable's connectors (commonly all gray). The gray connector on 80-conductor cables has pin 28 CSEL not connected, making it the slave position for drives configured cable select.\n\nRound parallel ATA cables (as opposed to ribbon cables) were eventually made available for 'case modders' for cosmetic reasons, as well as claims of improved computer cooling and were easier to handle; however, only ribbon cables are supported by the ATA specifications.\n\nIn the ATA standard, pin 20 is defined as (mechanical) key and is not used. This socket on the female connector is often obstructed, requiring pin 20 to be omitted from the male cable or drive connector, making it impossible to plug it in the wrong way round; a male connector with pin 20 present cannot be used. However, some flash memory drives can use pin 20 as VCC_in to power the drive without requiring a special power cable; this feature can only be used if the equipment supports this use of pin 20.\n\nPin 28 of the gray (slave/middle) connector of an 80-conductor cable is not attached to any conductor of the cable. It is attached normally on the black (master drive end) and blue (motherboard end) connectors.\n\nPin 34 is connected to ground inside the blue connector of an 80-conductor cable but not attached to any conductor of the cable. It is attached normally on the gray and black connectors.\n\nThe image on the right shows PATA connectors after removal of strain relief, cover, and cable. Pin one is at bottom left of the connectors, pin 2 is top left, etc., except that the lower image of the blue connector shows the view from the opposite side, and pin one is at top right. \n\nThe connector is an insulation-displacement connector—in other words, each contact comprises a pair of points which together pierce the insulation of the ribbon cable with such precision that they make a connection to the desired conductor without harming the insulation on the neighboring wires. The center row of contacts are all connected to the common ground bus and attached to the odd numbered conductors of the cable. The top row of contacts are the even-numbered sockets of the connector (mating with the even-numbered pins of the receptacle) and attach to every other even-numbered conductor of the cable. The bottom row of contacts are the odd-numbered sockets of the connector (mating with the odd-numbered pins of the receptacle) and attach to the remaining even-numbered conductors of the cable.\n\nNote the connections to the common ground bus from sockets 2 (top left), 19 (center bottom row), 22, 24, 26, 30, and 40 on all connectors. Also note (enlarged detail, bottom, looking from the opposite side of the connector) that socket 34 of the blue connector does not contact any conductor but unlike socket 34 of the other two connectors, it does connect to the common ground bus. On the gray connector, note that socket 28 is completely missing, so that pin 28 of the drive attached to the gray connector will be open. On the black connector, sockets 28 and 34 are completely normal, so that pins 28 and 34 of the drive attached to the black connector will be connected to the cable. Pin 28 of the black drive reaches pin 28 of the host receptacle but not pin 28 of the gray drive, while pin 34 of the black drive reaches pin 34 of the gray drive but not pin 34 of the host. Instead, pin 34 of the host is grounded.\n\nThe standard dictates color-coded connectors for easy identification by both installer and cable maker. All three connectors are different from one another. The blue (host) connector has the socket for pin 34 connected to ground inside the connector but not attached to any conductor of the cable. Since the old 40 conductor cables do not ground pin 34, the presence of a ground connection indicates that an 80 conductor cable is installed. The wire for pin 34 is attached normally on the other types and is not grounded. Installing the cable backwards (with the black connector on the system board, the blue connector on the remote device and the gray connector on the center device) will ground pin 34 of the remote device and connect host pin 34 through to pin 34 of the center device. The gray center connector omits the connection to pin 28 but connects pin 34 normally, while the black end connector connects both pins 28 and 34 normally.\n\nIf two devices are attached to a single cable, one must be designated as \"device 0\" (commonly referred to as \"master\") and the other as \"device 1\" (\"slave\"). This distinction is necessary to allow both drives to share the cable without conflict. The \"master\" drive is the drive that usually appears \"first\" to the computer's BIOS and/or operating system. On old BIOSes (Intel 486 era and older), the drives are often referred to by the BIOS as \"C\" for the master and \"D\" for the slave following the way DOS would refer to the active primary partitions on each.\n\nThe mode that a drive must use is often set by a jumper setting on the drive itself, which must be manually set to \"master\" or \"slave\". If there is a single device on a cable, it should be configured as \"master\". However, some hard drives have a special setting called \"single\" for this configuration (Western Digital, in particular). Also, depending on the hardware and software available, a single drive on a cable will often work reliably even though configured as the \"slave\" drive (most often seen where an optical drive is the only device on the secondary ATA interface).\n\nA drive mode called \"cable select\" was described as optional in ATA-1 and has come into fairly widespread use with ATA-5 and later. A drive set to \"cable select\" automatically configures itself as master or slave, according to its position on the cable. Cable select is controlled by pin 28. The host adapter grounds this pin; if a device sees that the pin is grounded, it becomes the master device; if it sees that pin 28 is open, the device becomes the slave device.\n\nThis setting is usually chosen by a jumper setting on the drive called \"cable select\", usually marked \"CS\", which is separate from the \"master\" or \"slave\" setting.\n\nNote that if two drives are configured as \"master\" and \"slave\" manually, this configuration does not need to correspond to their position on the cable. Pin 28 is only used to let the drives know their position on the cable; it is not used by the host when communicating with the drives.\n\nWith the 40-wire cable, it was very common to implement cable select by simply cutting the pin 28 wire between the two device connectors; putting the slave device at the end of the cable, and the master on the middle connector. This arrangement eventually was standardized in later versions. If there is just one device on the cable, this results in an unused stub of cable, which is undesirable for physical convenience and electrical reasons. The stub causes signal reflections, particularly at higher transfer rates.\n\nStarting with the 80-wire cable defined for use in ATAPI5/UDMA4, the master device goes at the end of the cable—the black connector—and the slave device goes on the middle connector—the gray one—and the blue connector goes onto the motherboard. So, if there is only one (master) device on the cable, there is no cable stub to cause reflections. Also, cable select is now implemented in the slave device connector, usually simply by omitting the contact from the connector body.\n\nAlthough they are in extremely common use, the terms \"master\" and \"slave\" do not actually appear in current versions of the ATA specifications. The two devices are simply referred to as \"device 0\" and \"device 1\", respectively, in ATA-2 and later.\n\nIt is a common myth that the controller on the master drive assumes control over the slave drive, or that the master drive may claim priority of communication over the other device on the same ATA interface. In fact, the drivers in the host operating system perform the necessary arbitration and serialization, and each drive's onboard controller operates independently of the other.\n\nThe parallel ATA protocols up through ATA-3 require that once a command has been given on an ATA interface, it must complete before any subsequent command may be given. Operations on the devices must be serializedwith only one operation in progress at a timewith respect to the ATA host interface. A useful mental model is that the host ATA interface is busy with the first request for its entire duration, and therefore can not be told about another request until the first one is complete. The function of serializing requests to the interface is usually performed by a device driver in the host operating system.\n\nThe ATA-4 and subsequent versions of the specification have included an \"overlapped feature set\" and a \"queued feature set\" as optional features, both being given the name \"Tagged Command Queuing\" (TCQ), a reference to a set of features from SCSI which the ATA version attempts to emulate. However, support for these is extremely rare in actual parallel ATA products and device drivers because these feature sets were implemented in such a way as to maintain software compatibility with its heritage as originally an extension of the ISA bus. This implementation resulted in excessive CPU utilization which largely negated the advantages of command queuing. By contrast, overlapped and queued operations have been common in other storage buses, in particular, SCSI's version of tagged command queuing had no need to be software compatible with ISA's APIs, allowing it to attain high performance with low overhead on buses which supported first party DMA like PCI. This has long been seen as a major advantage of SCSI.\n\nThe Serial ATA standard has supported native command queueing (NCQ) since its first release, but it is an optional feature for both host adapters and target devices. Many obsolete PC motherboards do not support NCQ, but modern SATA hard disk drives and SATA solid-state drives usually support NCQ, which is not the case for removable (CD/DVD) drives because the ATAPI command set used to control them prohibits queued operations.\n\nThere are many debates about how much a slow device can impact the performance of a faster device on the same cable. There is an effect, but the debate is confused by the blurring of two quite different causes, called here \"Lowest speed\" and \"One operation at a time\".\n\nIt is a common misconception that, if two devices of different speed capabilities are on the same cable, both devices' data transfers will be constrained to the speed of the slower device.\n\nFor all modern ATA host adapters, this is not true, as modern ATA host adapters support \"independent device timing\". This allows each device on the cable to transfer data at its own best speed. Even with older adapters without independent timing, this effect applies only to the data transfer phase of a read or write operation. This is usually the shortest part of a complete read or write operation.\n\nThis is caused by the omission of both overlapped and queued feature sets from most parallel ATA products. Only one device on a cable can perform a read or write operation at one time, therefore, a fast device on the same cable as a slow device under heavy use will find it has to wait for the slow device to complete its task first.\n\nHowever, most modern devices will report write operations as complete once the data is stored in its onboard cache memory, before the data is written to the (slow) magnetic storage. This allows commands to be sent to the other device on the cable, reducing the impact of the \"one operation at a time\" limit.\n\nThe impact of this on a system's performance depends on the application. For example, when copying data from an optical drive to a hard drive (such as during software installation), this effect probably will not matter: Such jobs are necessarily limited by the speed of the optical drive no matter where it is. But if the hard drive in question is also expected to provide good throughput for other tasks at the same time, it probably should not be on the same cable as the optical drive.\n\nThe disk lock is a built-in security feature in the disk. It is part of the ATA specification, and thus not specific to any brand or device. The disk lock can be enabled and disabled by sending special ATA commands to the drive. If a disk is locked, it will refuse all access until it is unlocked.\n\nA disk always has two passwords: A User password and a Master password. Most disks support a Master Password Revision Code. Reportedly, some disks can report if the Master password has been changed, or if it still is the factory default. The revision code is word 92 in the IDENTIFY response. Reportedly, on some disks, a value of 0xFFFE means the Master password is unchanged. The standard does not distinguish this value.\n\nA disk can be locked in two modes: High security mode or Maximum security mode. Bit 8 in word 128 of the IDENTIFY response shows which mode the disk is in: 0 = High, 1 = Maximum.\n\nIn High security mode, the disk can be unlocked with either the User or Master password, using the \"SECURITY UNLOCK DEVICE\" ATA command. There is an attempt limit, normally set to 5, after which the disk must be power cycled or hard-reset before unlocking can be attempted again. Also in High security mode, the SECURITY ERASE UNIT command can be used with either the User or Master password.\n\nIn Maximum security mode, the disk can be unlocked only with the User password. If the User password is not available, the only remaining way to get at least the bare hardware back to a usable state is to issue the SECURITY ERASE PREPARE command, immediately followed by SECURITY ERASE UNIT. In Maximum security mode, the SECURITY ERASE UNIT command requires the Master password and will completely erase all data on the disk. Word 89 in the IDENTIFY response indicates how long the operation will take. \n\nWhile the ATA disk lock is intended to be impossible to defeat without a valid password, there are workarounds to unlock a drive. Many data recovery companies offer unlocking services, so while the disk lock will deter a casual attacker, it is not secure against a qualified adversary.\n\nIt is extremely uncommon to find external PATA devices that directly use the interface for connection to a computer. PATA is primarily restricted to devices installed internally, due to the short data cable specification. A device connected externally needs additional cable length to form a U-shaped bend so that the external device may be placed alongside, or on top of the computer case, and the standard cable length is too short to permit this.\n\nFor ease of reach from motherboard to device, the connectors tend to be positioned towards the front edge of motherboards, for connection to devices protruding from the front of the computer case. This front-edge position makes extension out the back to an external device even more difficult. Ribbon cables are poorly shielded, and the standard relies upon the cabling to be installed inside a shielded computer case to meet RF emissions limits.\n\nAll external PATA devices, such as external hard drives, use some other interface technology to bridge the distance between the external device and the computer. USB is the most common external interface, followed by Firewire. A bridge chip inside the external devices converts from the USB interface to PATA, and typically only supports a single external device without cable select or master/slave.\n\nCompact Flash in its \"IDE mode\" is essentially just a miniaturized ATA interface, intended for use on devices that use flash memory storage. No interfacing chips or circuitry are required, other than to directly adapt the smaller CF socket onto the larger ATA connector.\n\nThe ATA connector specification does not include pins for supplying power to a CF device, so power is inserted into the connector from a separate source. The exception to this is when the CF device is connected to a 44-pin ATA bus designed for 2.5-inch hard disk drives, commonly found in notebook computers, as this bus implementation must provide power to a standard hard disk drive.\n\nCF devices can be designated as master or slave on an ATA interface, though since most CF devices offer only a single socket, it is not necessary to offer this selection to end users. Although CF can be hot-pluggable with additional design methods, by default when wired directly to an ATA interface, it is not intended to be hot-pluggable.\n\nThe following table shows the names of the versions of the ATA standards and the transfer modes and rates supported by each. Note that the transfer rate for each mode (for example, 66.7 MB/s for UDMA4, commonly called \"Ultra-DMA 66\", defined by ATA-5) gives its maximum theoretical transfer rate on the cable. This is simply two bytes multiplied by the effective clock rate, and presumes that every clock cycle is used to transfer end-user data. In practice, of course, protocol overhead reduces this value.\n\nCongestion on the host bus to which the ATA adapter is attached may also limit the maximum burst transfer rate. For example, the maximum data transfer rate for conventional PCI bus is 133 MB/s, and this is shared among all active devices on the bus.\n\nIn addition, no ATA hard drives existed in 2005 that were capable of measured sustained transfer rates of above 80 MB/s. Furthermore, sustained transfer rate tests do not give realistic throughput expectations for most workloads: They use I/O loads specifically designed to encounter almost no delays from seek time or rotational latency. Hard drive performance under most workloads is limited first and second by those two factors; the transfer rate on the bus is a distant third in importance. Therefore, transfer speed limits above 66 MB/s really affect performance only when the hard drive can satisfy all I/O requests by reading from its internal cache—a very unusual situation, especially considering that such data is usually already buffered by the operating system.\n\n, mechanical hard disk drives can transfer data at up to 157 MB/s, which is beyond the capabilities of the PATA/133 specification. High-performance solid state drives can transfer data at up to 308 MB/s.\n\nOnly the Ultra DMA modes use CRC to detect errors in data transfer between the controller and drive. This is a 16-bit CRC, and it is used for data blocks only. Transmission of command and status blocks do not use the fast signaling methods that would necessitate CRC. For comparison, in Serial ATA, 32-bit CRC is used for both commands and data.\n\nATAPI devices with removable media, other than CD and DVD drives, are classified as ARMD (ATAPI Removable Media Device) and can appear as either a super-floppy (non-partitioned media) or a hard drive (partitioned media) to the operating system. These can be supported as bootable devices by a BIOS complying with the ATAPI Removable Media Device BIOS Specification, originally developed by Compaq Computer Corporation and Phoenix Technologies. It specifies provisions in the BIOS of a personal computer to allow the computer to be bootstrapped from devices such as Zip drives, Jaz drives, SuperDisk (LS-120) drives, and similar devices.\n\nThese devices have removable media like floppy disk drives, but capacities more commensurate with hard drives, and programming requirements unlike either. Due to limitations in the floppy controller interface most of these devices were ATAPI devices, connected to one of the host computer's ATA interfaces, similarly to a hard drive or CD-ROM device. However, existing BIOS standards did not support these devices. An ARMD-compliant BIOS allows these devices to be booted from and used under the operating system without requiring device-specific code in the OS.\n\nA BIOS implementing ARMD allows the user to include ARMD devices in the boot search order. Usually an ARMD device is configured earlier in the boot order than the hard drive. Similarly to a floppy drive, if bootable media is present in the ARMD drive, the BIOS will boot from it; if not, the BIOS will continue in the search order, usually with the hard drive last.\n\nThere are two variants of ARMD, ARMD-FDD and ARMD-HDD. Originally ARMD caused the devices to appear as a sort of very large floppy drive, either the primary floppy drive device 00h or the secondary device 01h. Some operating systems required code changes to support floppy disks with capacities far larger than any standard floppy disk drive. Also, standard-floppy disk drive emulation proved to be unsuitable for certain high-capacity floppy disk drives such as Iomega Zip drives. Later the ARMD-HDD, ARMD-\"Hard disk device\", variant was developed to address these issues. Under ARMD-HDD, an ARMD device appears to the BIOS and the operating system as a hard drive.\n\nIn August 2004, Sam Hopkins and Brantley Coile of Coraid specified a lightweight ATA over Ethernet protocol to carry ATA commands over Ethernet instead of directly connecting them to a PATA host adapter. This permitted the established block protocol to be reused in storage area network (SAN) applications.\n\n", "id": "2778", "title": "Parallel ATA"}
{"url": "https://en.wikipedia.org/wiki?curid=2779", "text": "Atari 2600\n\nThe Atari 2600 (or Atari VCS before 1982) is a home video game console by Atari, Inc. Released on September 11, 1977, it is credited with popularizing the use of microprocessor-based hardware and ROM cartridges containing game code, a format first used with the Fairchild Channel F video game console in 1976. This format contrasts with the older model of having non-microprocessor dedicated hardware, which could only play the games that were physically built into the unit.\n\nThe console was originally sold as the Atari VCS, an abbreviation for Video Computer System. Following the release of the Atari 5200 in 1982, the VCS was renamed to the \"Atari 2600\", after the unit's Atari part number, CX2600. The 2600 was typically bundled with two joystick controllers, a conjoined pair of paddle controllers, and a game cartridge: initially \"Combat\", and later \"Pac-Man\".\n\nTed Dabney and Nolan Bushnell developed the Atari gaming system in the 1970s. Originally operating under the name \"Syzygy\", Bushnell and Dabney changed the name of their company to \"Atari\" in 1972. In 1973, Atari Inc. had purchased an engineering think tank called Cyan Engineering to research next-generation video game systems, and had been working on a prototype known as \"Stella\" (named after one of the engineers' bicycles) for some time. Unlike prior generations of machines that use custom logic to play a small number of games, its core is a complete CPU, the famous MOS Technology 6502 in a cost-reduced version known as the 6507. It was combined with a RAM-and-I/O chip, the MOS Technology 6532, and a display and sound chip known as the Television Interface Adaptor (TIA). The first two versions of the machine contain a fourth chip, a standard CMOS logic buffer IC, making Stella cost-effective. Some later versions of the console eliminated the buffer chip. \n\nPrograms for small computers of the time were generally stored on cassette tapes, floppy disks, or paper tape. By the early 1970s, Hewlett-Packard manufactured desktop computers costing thousands of dollars such as the HP 9830, which packaged Read Only Memory (ROM) into removable cartridges to add special programming features, and these were being considered for use in games. At first, the design was not going to be cartridge-based, but after seeing a \"fake\" cartridge system on another machine, they realized they could place the games on cartridges essentially for the price of the connector and packaging.\n\nIn 1976, Fairchild Semiconductor released their own CPU-based system, the Video Entertainment System. Stella was still not ready for production, but it was clear that it needed to be before there were a number of \"me too\" products filling up the market, which had happened after they released \"Pong\". Atari Inc. didn't have the cash flow to complete the system quickly, given that sales of their \"Pong\" systems were cooling. Nolan Bushnell eventually turned to Warner Communications, and sold the company to them in 1976 for US$28 million on the promise that Stella would be produced as soon as possible.\n\nKey to the eventual success of the machine was the hiring of Jay Miner, a chip designer who managed to squeeze an entire wire wrap of equipment making up the TIA into a single chip. Once that was completed and debugged, the system was ready for shipping.\n\nThe unit was originally priced at US$199 ($ adjusted for inflation), and shipped with two joysticks and a \"Combat\" cartridge (eight additional games were available at launch and sold separately). In a move to compete directly with the Channel F, Atari Inc. named the machine the Video Computer System (or VCS for short), as the Channel F was at that point known as the VES, for \"Video Entertainment System\". The VCS was also rebadged as the Sears Video Arcade and sold through Sears, Roebuck and Company stores. Another breakthrough for gaming systems was Atari's invention of a computer-controlled opponent, rather than the usual two-player or asymmetric challenges of the past.\nWhen Fairchild learned of Atari Inc.'s naming, they quickly changed the name of their system to become the Channel F. However, both systems were now in the midst of a vicious round of price-cutting: \"Pong\" clones that had been made obsolete by these newer and more powerful machines were sold off to discounters for ever-lower prices. Soon many of the clone companies were out of business, and both Fairchild and Atari Inc. were selling to a public that was completely burnt out on Pong. In 1977, Atari Inc. sold 250,000 Video Computer Systems.\n\nFor the first year of production, the Video Computer System was manufactured in Sunnyvale, California. The consoles manufactured there had thick plastic molding around the sides and bottom. These added weight to the console, and because all six switches were on the front, these consoles were nicknamed \"Heavy Sixers\". After this first year, production moved to Hong Kong, and the consoles manufactured there had thinner plastic molding. In 1978, only 550,000 units from a production run of 800,000 were sold, requiring further financial support from Warner to cover losses. This led directly to the disagreements that caused Atari Inc. founder Nolan Bushnell to leave the company in 1978. Despite Bushnell's retirement in 1978, Warren Robinett's invention of the first graphical adventure game, \"Adventure\", was developed the same year and changed the fundamentals of gaming as it unlocked a game with a \"virtual space bigger than the screen\".\nOnce the public realized it was possible to play video games other than \"Pong\", and programmers learned how to push its hardware's capabilities, the VCS gained popularity. By this point, Fairchild had given up, thinking video games were a passing fad, thereby handing the entire quickly growing market to Atari Inc. By 1979, the VCS was the best-selling Christmas gift (and console), due to its exclusive content, and 1 million units were sold that year.\nAtari Inc. then licensed the smash arcade hit \"Space Invaders\" by Taito, which greatly increased the unit's popularity when it was released in January 1980, doubling sales to over 2 million units. The VCS and its cartridges were the main factor behind Atari Inc. grossing more than $2 billion in 1980. Sales then doubled again for the next two years; by 1982, the console had sold 10 million units, while its best-selling game \"Pac-Man\" sold 7 million copies. The console also sold 450,000 units in West Germany by 1984. By 1982 the 2600 console cost Atari about $40 to make and was sold for an average of $125. The company spent $4.50 to $6 to manufacture each cartridge and $1 to $2 for advertising, and sold it for $18.95 wholesale.\nIn 1980, the VCS was given a minor revision in which the left and right difficulty switches were moved to the back of the console, leaving four switches on the front. Other than this, these four-switch consoles looked nearly identical to the earlier six-switch models. In 1982, another version of the four-switch console was released without woodgrain. They were nicknamed \"Darth Vader\" consoles due to their all-black appearance. These were also the first consoles to be officially called \"Atari 2600\", as the Atari 5200 was released the same year.\nDuring this period, Atari Inc. expanded the 2600 family with two other compatible consoles. Despite the faux-wood panels and what would now appear to be primitive graphics, the game console became widely popular for the time. Later however, they designed the Atari 2700, a wireless version of the console that was never released because of a design flaw. The company also built a sleeker version of the machine dubbed the Atari 2800 to sell directly to the Japanese market in early 1983, but it suffered from competition with the newly released Nintendo Famicom.\n\nIn a survey mentioned by Jeff Rovin it is reported that more stores reported breakdowns of the Atari 2600 system than any other, and that Atari repair centers seemed to have the most trouble with consoles manufactured in 1980. In one case it is stated that a system was repaired five times before static electricity from a carpet was discovered as having caused the problem. The controllers were also a source of breakage because of the way they could be gripped by a player holding it with their fist, allowing players to get carried away and over control, which was less likely with other systems released at the time, such as the Magnavox Odyssey², which has controllers that are nearly half its size.\n\nAtari Inc. also continued their OEM relationship with Sears under the latter's Tele-Games brand label, which started in 1975 with the original \"Pong\". Sears released several versions of the 2600 as the Sears Video Arcade series from 1977 to 1983. These include the Rev. A \"Heavy Sixer\" model in 1977, the Rev. B \"4 switch\" model in 1980, and the US version of the Atari 2800 branded as the Sears Video Arcade II in 1983.\n\nSears also released their own versions of Atari Inc.'s games under the Tele-Games brand — often with different titles — which included the Tele-Games branded variations of text and picture labels. Three games were also produced by Atari Inc. for Sears as exclusive releases under the Tele-Games brand: \"Steeplechase\", \"Stellar Track\", and \"Submarine Commander\".\n\nSears's Tele-Games brand was unrelated to the company Telegames, which also produced cartridges for the Atari 2600 — mostly re-issues of M Network games.\n\nDuring the 1970s, Atari Inc. continued to grow until it had one of the largest R&D divisions in Silicon Valley. However, it spent much of its R&D budget on projects that seemed out of place at a video game (or even home computer) company; many of these projects never saw the light of day. Meanwhile, several attempts to bring out newer consoles failed for one reason or another, although Atari Inc.'s home computer system (the Atari 8-bit family) sold reasonably well, Warner was pleased as it seemed to have no end to the sales of the 2600, and Atari Inc. was responsible for over half of the company's income.\n\nThe programmers of many of Atari Inc.'s biggest hits grew disgruntled with the company for not crediting game developers and many left the company and formed their own independent software companies. The most prominent and longest-lasting of these third-party developers was Activision, founded in 1980, whose titles quickly became more popular than those of Atari Inc. itself. Atari Inc. attempted to block third-party development for the 2600 in court but failed, and soon other publishers, such as Imagic and Coleco, entered the market. Atari Inc. suffered from an image problem when a company named Mystique produced a number of pornographic games for the 2600. The most notorious of these, \"Custer's Revenge\", was protested by women's and Native American groups because it depicted General George Armstrong Custer raping a bound Native American woman. Atari Inc. sued Mystique in court over the release of the game.\n\nAtari Inc. continued to acquire licenses for the 2600, the most prominent of which included \"Pac-Man\" and \"E.T.\" Public disappointment with these two titles and the market saturation of poor third-party titles are cited as major contributors to the video game crash of 1983. Suddenly, Atari Inc.'s growth meant it was losing massive amounts of money during the crash, at one point about $10,000 a day. This in part led to the Atari video game burial of 1000s of unsold Atari 2600 games in the desert in New Mexico. Warner quickly grew tired of supporting Atari Inc., and started looking for buyers in 1984.\n\nBy mid-1984 most software development for the 2600 had stopped except by Atari and Activision, with third-party developers emphasizing ColecoVision games. Although not formally discontinued, the 2600 was de-emphasized for two years after Warner's 1984 sale of Atari Inc.'s Consumer Division to Commodore Business Machines founder Jack Tramiel, who wanted to concentrate on home computers. He ended all development of console games, including a 2600 \"Garfield\" game and an Atari 5200 port of \"Super Pac-Man\". Due to a large library and a low price point, the 2600 and the 2600jr, continued to sell into the late 1980s and was not discontinued until 1992. The 2600 ended up outdoing all other hardware that Atari released, in attempt to replicate its success.\n\nThe Atari 2800 is the Japanese version of the Atari 2600, released in October 1983. It was the first release of a 2600 designed specifically for the Japanese market, despite companies like Epoch distributing the 2600 in Japan previously. In fact, Atari's name was inspired by the Japanese game 'Go'.\n\nThe 2800 never captured a large market in Japan. It was released a short time after Nintendo's Family Computer, which became the dominant console in the Japanese video game market of the time.\n\nCodenamed \"Cindy\", and designed by Atari engineer Joe Tilly, the Atari 2800 had four controller ports instead of the standard two on the Atari 2600's. The controllers are an all-in one design using a combination of an 8-direction digital joystick and a 270-degree paddle, designed by John Amber.\n\nThe 2800's case design departed from the standard 2600 format, using a wedge shape with non-protruding switches.\n\nAround 30 specially branded games were released for the 2800. Their boxes are in Japanese and have a silver/red color scheme similar to the packaging of Atari's 2600 branded games of the time. The ROM cartridges themselves had identical labels as their 2600 branded counterparts.\n\nSears liked the design of the Atari 2800 so much, they opted to sell a version under their Tele-Games label. It was released in the US in 1983 as the Sears Video Arcade II, and was packaged with 2 controllers and \"Space Invaders\".\n\nThe Atari 2800's case style was used as the basis for the Atari 7800's case style by Barney Huang.\n\nIn 1986, a new version of the 2600 was released. The newly redesigned version of the 2600, unofficially referred to as the 2600 Jr., features a smaller cost-reduced form factor with a modernized Atari 7800-like appearance. The redesigned 2600 was advertised as a budget gaming system (under US$50) that has the ability to run a large collection of classic games.\n\nThe Atari 2600 continued to sell in North America and Europe until 1991, and in Asia until the early 1990s. Its final Atari-licensed release is \"KLAX\" in 1990. In 2007, the Atari 2600 was inducted into the Toy Hall of Fame, with 40 million units sold in its lifetime, and the youngest toy to be inducted. In Brazil, the console became extremely popular in the mid-1980s. The Atari 2600 was officially retired by Atari Corp. on January 1, 1992, making it, at the time, the longest-lived home video game console (14 years, 4 months) in video game history. It was later surpassed by the Sega Master System, a console that never formally ended production in Brazil.\n\nThe Atari 2600 was also, at the time, the best-selling American-made console, selling 30 million units. \n\nThe system was promoted on a United Kingdom TV ad in 1989 in the run-up to Christmas, in which it claimed \"The fun is back!\". The advertising campaign used its price of under £50 as a selling point. The advert was a re-dubbed version of the early original campaign in the United States. Also, the 2600 Jr. was originally to be packaged with a Pro-Line joystick (the same one used on the Atari 7800), but when it was released, it instead included the original CX-40 Joystick. Later European versions of the 2600 Jr. included a joypad, which was also featured with the European 7800.\n\nThe CPU was the MOS Technology 6507, a stripped-down version of the 6502, running at 1.19 MHz in the 2600. Though their internal silicon wafer was identical, the 6507 was cheaper than the 6502 because its package included fewer memory-address pins—13 instead of 16. Smaller packaging was, and still is, an important factor in overall system cost, and since memory was very expensive at the time, the 6507's small 8 kB of maximum external memory space was not going to be used up anyway.\n\nThe designers of the Atari 2600 selected an inexpensive cartridge interface that had one fewer address than the 13 allowed by the 6507, further reducing the already limited addressable memory to 4 kB (2^12 = 4096). This was believed to be sufficient as \"Combat\" was itself only 2 kB. Later games get around this limitation with bank switching. The maximum supported cartridge size is 32 kilobytes. Atari established their system design in order to be compatible with the cathode-ray tube television sets in the late 1970s and early 1980s.\n\nThe console has only 128 bytes of RAM for run-time data that includes the call stack and the state of the game world. There is no frame buffer. Instead the video device has two bitmapped sprites, two 1-pixel \"missile\" sprites, a 1-pixel \"ball,\" and a 40-pixel \"playfield\" that is drawn by writing a bit pattern for each line into a register just before the television scans that line. As each line is scanned, a game must identify the non-sprite objects that overlaps the next line, assemble the appropriate bit patterns to draw for those objects, and write the pattern into the register. In a telling reveal of its Pong heritage, by default, the right side of the screen is a mirrored duplicate of the left; to control it separately, the software may modify the patterns as the scan line is drawn. After the controller scans the last active line, a more leisurely vertical blanking interval begins, during which the game can process inputs and update the positions & states of objects in the game world. Any mistake in timing produces visual artifacts, a problem that programmers call \"racing the beam\".\n\nThe 2600's video hardware is therefore highly flexible, but also challenging to program. One advantage the 2600 has over more powerful contemporary competitors such as the ColecoVision is that the 2600 has no protection against altering settings in mid-line. For example, although each sprite nominally has only one color, it is possible to color the rows differently by changing the sprite's color as it is drawn. If the two hardware sprites are not enough for a game, a developer may share one sprite among several objects (as with the ghosts in \"Pac-Man\") or draw software sprites, which is only a little more difficult than drawing a fixed playfield. The \"Pitfall!\" screenshot below (section: \"Games\") demonstrates some of these tricks: the player is a multicolor sprite, one sprite is multiplexed for the logs and the scorpion, and the swinging vine is drawn by shifting the position of the \"ball\" on each scan line. Despite the hardware limitations, many Atari 2600 games have a lot of action on the screen, creating an engaging experience. Furthermore, the Atari 2600 was one of the first consoles to introduce video game cartridges instead of having hardwired games built into it, allowing for the play of multiple different games rather than the usual one built in.\n\nThe Atari originally shipped with two types of controllers, a joystick as well as a pair of paddle controllers. Later, new controllers were added to the game system including a driving controller, a trak-ball controller, and finally keypad controllers. Additionally, the 2600 supports several types of input devices as well as third-party peripherals. Because the Atari joystick port and CX40 joystick became industry standards, many peripherals are interchangeable with the MSX and other Japanese systems, the Commodore 64, Commodore 128, Amiga, Sega Master System, and Mega Drive/Genesis, though functionality may be somewhat limited. Also, although Master System and Mega Drive/Genesis controllers work on the Atari 2600, only the \"B\" button can be used in most games. Another adapter is the Starpath Supercharger, an add-on created by Starpath to expand the game capabilities of the Atari 2600. The Supercharger's interface adds an extra 6 kB to the Atari 2600's 128 bytes of RAM, allowing for larger games with higher-resolution graphics. A cord coming out of the side of the cartridge plugs into the earphone jack of any standard cassette player. Games for the Supercharger are stored on standard audio cassettes.\n\nThird-party accessories include Wico's Command Control joystick.\n\nThe Atari 2600 uses different color palettes depending on the television signal format used. With the NTSC format, a 128-color palette is available, while in PAL, only 104 colors are available. Additionally, the SECAM palette consists of only 8 colors.\n\nIn 1977, nine games were released on cartridge to accompany the launch of the machine, including Outlaw, Space War and Breakout. During the console's lifetime, Atari, Inc. and Atari Corp. published many titles: these games included \"Adventure\" (often credited as starting the action-adventure game genre), \"Breakout\", and \"Yars' Revenge\". The console's popularity attracted many third-party developers, which led to popular titles such as Activision's \"Pitfall!\" and Imagic's \"Atlantis\". However, two Atari published titles, \"E.T. the Extra-Terrestrial\" and \"Pac-Man\", are frequently blamed for contributing to the video game crash of 1983.\n\nThe Atari 2600 was wildly successful, and during much of the 1980s, \"Atari\" was a synonym for this model in mainstream media and, by extension, for video games in general.\n\nThe Atari 2600 was inducted into the National Toy Hall of Fame at The Strong in Rochester, New York, in 2007. In 2009, the Atari 2600 was named the second greatest video game console of all time by IGN, who cited its remarkable role as the console behind both the first video game boom and the video game crash of 1983, and called it \"the console that our entire industry is built upon\".\n\nThe Atari 2000 (model number CX-2000) was a prototype version of the Atari 2600 that was intended to be released as a cheaper alternative for children in 1982. Although identical in specification to the original 2600, the 2000 included built-in controllers and an innovative case design. The 2000 was originally intended to be black, but it was later recolored blue to appeal more to children. While Atari never officially stated the reason for not releasing the 2000, experts have cited the poor quality and durability of its built-in joysticks and the greater in-house popularity of the competing 2600 Jr. design as the most likely reasons.\n\nAtari started work on a replacement to the 2600, called the Atari 3200, with codenames including Super Stella, Sylvia, and PAM (a note attached reads \"Super Stella: Multipurpose\"). The system was to have compatibility with Atari 2600 cartridges, and was rumored to be based on a 10-bit processor, although design documents shows it was to actually be based around the 6502 8-bit CPU. It was still unfinished when preliminary game programmers discovered that it was difficult to program. The project was cancelled, and Atari went with the second \"System X\", also titled PAM, that would later become the Atari 5200. Atari also cloned the Atari 3200 into the Sears Super Arcade II, but this was never released.\n\nThe console and its old and new games are very popular with collectors because of its significant impact on video game and consumer electronics history and also due to its nostalgic value for many people, along with a number of games that are still considered highly playable. In addition, modern Atari 2600 clones remain on the market. One example is the Atari Classics 10-in-1 TV Game, manufactured by Jakks Pacific, which emulates the 2600 console, and includes converted versions of 10 games into a single Atari-brand-lookalike joystick with composite-video outputs for connecting directly to modern televisions or VCRs. Another is the TV Boy, which includes 127 games in an enlarged joypad.\n\nThe Atari Flashback 2 console, released in 2005, contains 40 games (with four additional programs unlockable by a cheat code). The console implements the original 2600 architecture and can be modified to play original 2600 cartridges by adding a cartridge port, and is also compatible with original 2600 controllers.\n\nMany games for the Atari 2600 have detailed and easily identifiable music, and its distinctive sound makes it ideal for use in modern lo-fi and industrial music. In 2002, Dallas musician and visual artist Paul Slocum developed a cartridge called Synthcart for the Atari 2600, which allows the user to turn an Atari 2600 into a two-voice synthesizer and drum machine. Adapters have also been developed by amateurs enabling the Atari 2600's use with MIDI devices. A number of bands, such as 8 Bit Weapon, Black Moth Super Rainbow and Slocum's own band Tree Wave, use Synthcart to make modern music on the Atari 2600. Some effects units like the MXR Blue Box are often cited for their ability to produce an Atari-like sound. Phonte from the hip-hop group Little Brother, along with fellow lyricist Eccentric, formed a mock group named Unheralded Symmetrics, and recorded a tribute to the system, entitled \"Atari 2600\".\n\n\n\n\n", "id": "2779", "title": "Atari 2600"}
{"url": "https://en.wikipedia.org/wiki?curid=2780", "text": "Atari 5200\n\nThe Atari 5200 SuperSystem, commonly known as the Atari 5200, is a home video game console that was introduced in 1982 by Atari Inc. as a higher-end complementary console for the popular Atari 2600. The 5200 was created to compete with the Intellivision, but wound up more directly competing with the ColecoVision shortly after its release.\n\nThe 5200's internal hardware is almost identical that of Atari's 8-bit computers, although software is not directly compatible between the two systems. The 5200's controllers have an analog joystick and a numeric keypad along with start, pause and reset buttons. The 360-degree non-centering joystick was touted as offering more control than the eight-way joystick controller offered with the Atari 2600.\n\nMuch of the technology in the Atari 8-bit family of home computer systems was originally developed as a second-generation games console intended to replace the 2600. However, as the system was reaching completion, the personal computer revolution was starting with the release of machines like the Commodore PET, TRS-80 and Apple II. These machines had less advanced hardware than the new Atari technology, but sold for much higher prices with associated higher profit margins. Atari's management decided to enter this market, and the technology was repackaged into the Atari 400 and 800. The chipset used in these machines was created with the mindset that the 2600 would likely be obsolete by the 1980 time frame.\n\nAtari later decided to re-enter the games market with a design that closely matched their original 1978 specifications. In its prototype stage, the Atari 5200 was originally called the \"Atari Video System X - Advanced Video Computer System\", and was codenamed \"Pam\" after a female employee at Atari Inc. It is also rumored that PAM actually stood for \"Personal Arcade Machine\", as the majority of games for the system ended up being arcade conversions. Actual working \"Atari Video System X\" machines, whose hardware is 100% identical to the Atari 5200 do exist, but are extremely rare.\n\nThe initial 1982 release of the system featured four controller ports, where nearly all other systems of the day had only one or two ports. The 5200 also featured a new style of controller with an analog joystick, numeric keypad, two fire buttons on each side of the controller and game function keys for Start, Pause, and Reset. The 5200 also featured the innovation of the first automatic TV switchbox, allowing it to automatically switch from regular TV viewing to the game system signal when the system was activated. Previous RF adapters required the user to slide a switch on the adapter by hand. The RF box was also where the power supply connected in a unique dual power/television signal setup similar to the RCA Studio II's. A single cable coming out of the 5200 plugged into the switch box and was used for both electricity and the television signal.\n\nThe 1983 revision of the Atari 5200 has two controller ports instead of four, and a change back to the more conventional separate power supply and standard non-autoswitching RF switch. It also has changes in the cartridge port address lines to allow for the Atari 2600 adapter released that year. While the adapter was only made to work on the two-port version, modifications can be made to the four-port to make it line-compatible. In fact, towards the end of the four-port model's production run, there were a limited number of consoles produced which included these modifications. These consoles can be identified by an asterisk in their serial number.\n\nThe controller prototypes used in the electrical development lab employed a yoke and gimbal mechanism that came from an RC airplane controller kit. This simple design gave smooth linear control and was highly reliable. The design of the analog joystick, which used a weak rubber boot rather than springs to provide centering, proved to be ungainly and unreliable. They quickly became the Achilles' heel of the system because of their combination of an overly complex mechanical design with a very low-cost internal flex circuit system. Another major flaw of the controllers was that the design did not translate into a linear acceleration from the center through the arc of the stick travel. The controllers did, however, include a pause button, a unique feature at the time. Various third-party replacement joysticks were also released, including those made by Wico.\n\nAtari Inc. released the Pro-Line Trak-Ball controller for the system, which was used primarily for gaming titles such as \"Centipede\" and \"Missile Command\". A paddle controller and an updated self-centering version of the original controller were also in development, but never made it to market.\n\nGames shipped with plastic card overlays that snapped in over the keypad. The card would indicate which game functions, such as changing the view or vehicle speed, were assigned to each key.\n\nThe primary controller was ranked the 10th worst video game controller by IGN editor Craig Harris. An editor for \"Next Generation\" said that their non-centering joysticks \"rendered many games nearly unplayable\".\n\nThe Atari 5200's internal design was extensively based on that of the 400/800 home computers. Software designed for one does not run on the other, although porting the source code is not difficult as long as it does not use computer-specific features. John J. Anderson of \"Creative Computing\" alluded to the incompatibility being intentional, caused by rivalries between Atari's computer and console divisions.\n\nBesides the 5200's lack of a computer keyboard, other differences include:\n\nAtari Corp.'s 1987 XE Game System is a repackaged 65XE computer with a detachable keyboard that can run home computer titles directly, unlike the 5200. Anderson wrote in 1984 that Atari could have released a console compatible with computer software in 1981.\n\nThe Atari 5200 did not fare well commercially, compared to its predecessor, the Atari 2600. While it touted superior graphics to the 2600 and Mattel's Intellivision, the system was initially incompatible with the 2600's expansive library of games, and some market analysts have speculated that this hurt its sales, especially since an Atari 2600 cartridge adapter had been released for the Intellivision II. (A revised 2-port model was released in 1983, along with a game adapter that allowed gamers to play all 2600 games.) This lack of new games was due in part to a lack of funding, with Atari continuing to develop most of its games for the saturated 2600 market.\n\nMany of the 5200's games appeared simply as updated versions of 2600 titles, which failed to excite consumers. Its pack-in game, \"Super Breakout\", was particularly criticized for not doing enough to demonstrate the system's capabilities, and this gave the ColecoVision a significant advantage when its pack-in, \"Donkey Kong\", delivered a more authentic arcade experience than any previous game cartridge. In its list of the top 25 game consoles of all time, IGN claimed that the main reason for the 5200's market failure was the technological superiority of its competitor, while other sources maintain that the two consoles are roughly equivalent in power.\n\nThe 5200 received much criticism for the \"sloppy\" design of its non-centering analog controllers. Anderson described the controllers as \"absolutely atrocious\".\n\nAt one point following the 5200's release, Atari had planned a smaller, cost-reduced version of the Atari 5200, which would have removed the controller storage bin. Code-named the \"Atari 5100\" (a.k.a. \"Atari 5200 Jr.\"), only a few fully working prototype 5100s were made before the project was canceled.\n\nOn May 21, 1984, during a press conference at which the Atari 7800 was introduced, company executives revealed that the 5200 had been discontinued after just two years on the market. Total sales of the 5200 were reportedly in excess of 1 million units.\n\n\n\n", "id": "2780", "title": "Atari 5200"}
{"url": "https://en.wikipedia.org/wiki?curid=2781", "text": "Atari 7800\n\nThe Atari 7800 ProSystem, or simply the Atari 7800, is a home video game console officially released by Atari Corporation in 1986. It is almost fully backward-compatible with the Atari 2600, the first console to have backward compatibility without the use of additional modules. It was considered affordable at a price of US$140.\n\nThe 7800 has significantly improved graphics hardware over the 2600, but uses the same audio chip. It also shipped with a different model of joystick than the 2600-standard CX40.\n\nThe 1986 launch is sometimes referred to as a \"re-release\" or \"relaunch\" because the Atari 7800 had originally been announced on May 21, 1984, to replace Atari Inc.'s Atari 5200, but a general release was shelved due to the sale of the company. A few units were released to test markets in June 1984 though.\n\nThe Atari 7800 ProSystem was the first game system from Atari Inc. designed by an outside company, General Computer Corporation (GCC). The system was designed in 1983-84 with an intended mass market rollout in June 1984, but was canceled shortly thereafter due to the sale of the company to Tramel Technology Ltd on July 2, 1984. The project was originally called the Atari 3600, though was later renamed the Atari 7800.\n\nAtari had been facing mounting pressure in the form of competition from the ColecoVision, which boasted graphics that more closely mirrored arcade games of the time than Atari’s 2600 system. At the same time, the Atari 5200 (the original intended successor to the Atari 2600) had been widely criticized for not being able to play Atari 2600 games without an adapter.\n\nGCC, which had a background in creating arcade games, designed their new system with a graphical architecture similar to arcade machines of the time. The 7800 allows a large number of moving objects (75 to 100) that far exceeds previous consoles. Powering the system is a slightly customized 6502 processor, the Atari SALLY (sometimes described as a \"6502C\"), running at 1.79 MHz.\n\nIn contrast to the Atari 5200, the Atari 7800 can play almost all Atari 2600 games out of the box, without the need for an adapter. In addition, it features a return to a digital controller. Then as an added bonus, GCC's programmers would also do almost all of the Atari 2600, 5200 games in 1983-1984 for Atari.To make sure the system had every bell and whistle possible, the system was slated to be released with not only a computer keyboard, but also a High Score cartridge (Designed by GCC), and a new add-on module for the Atari 5200 which would have given the Atari 5200 system full Atari 7800/2600 compatibility to ensure its existing base of 5200 owners could immediately take advantage of all the hot new games that the 7800 was capable of producing <http://www.atarimuseum.com/videogames/consoles/7800/7800menu/>\n\nTo address the concerns of parents that home computers were a better investment than consoles, the system was designed to be upgraded to a full-fledged home computer. A keyboard was developed, and the keyboard had an expansion port (which was the SIO port from Atari's 8-bit computer line, though the 7800 could not run Atari computer programs) that allowed for the addition of peripherals such as disk drives and printers.\n\nTo further enhance the gaming experience, GCC had also designed a \"high score cartridge\", a battery-backed RAM cartridge designed for storing game scores. On the side of the 7800 was an expansion port, reportedly for a planned connection with a laserdisc player.\n\nThe 7800 was initially released in southern California in June 1984, following an announcement on May 21, 1984 at the Summer Consumer Electronics Show. Thirteen games were announced for the system's launch: \"Ms. Pac-Man\", \"Pole Position II\", \"Centipede\", \"Joust\", \"Dig Dug\", \"Desert Falcon\", \"\", \"Galaga\", \"Food Fight\", \"Ballblazer\", \"Rescue on Fractalus!\", \"Track & Field\", and \"Xevious\", . Atari was a sponsor of the 1984 Summer Olympics and planned to push the 7800 aggressively in time for Christmas that year. \n\nOn July 2, 1984, Warner Communications sold Atari's Consumer Division to Jack Tramiel. All projects were halted during an initial evaluation period. Modern publications have often incorrectly asserted that Jack Tramiel mothballed the Atari 7800, feeling video games were a past fad, and subsequently asserted that he dusted off the Atari 7800 once the NES became successful. The reality was that a contractual issue arose in that GCC had not been paid for their development of the 7800. Warner and Tramiel battled back and forth over who was accountable, with Tramiel believing that the 7800 should have been covered as part of his acquisition deal. In May 1985, Jack relented and paid GCC the overdue payment. This led to additional negotiations regarding the initial launch titles that GCC had developed and then an effort to find someone to lead their new video game division, which was completed in November 1985.\n\nThe original production run of the Atari 7800 languished on warehouse shelves until it was re-introduced in January 1986, after strong 2600 sales the previous Christmas. The console was released nationwide in May 1986.\n\nAtari's launch of the 7800 under Tramiel was far more subdued than Warner had planned for the system in 1984 with a marketing budget of just $300,000. Additionally, the keyboard and high score cartridge were canceled, the expansion port was removed from later production runs of the system and, in lieu of new titles, the system was launched with titles intended for the 7800's debut in 1984.\n\nBy the end of 1986, Computer Entertainer claimed the Atari 7800 had sold 100,000 consoles in the United States, less than the Sega Master System's 125,000 and the Nintendo Entertainment System's 1.1 million. According to Atari, due to manufacturing problems, it only managed to produce and sell 100,000 units by 1986, including units that had been in a warehouse since 1984. A common complaint in 1986 was a lack of games, including a gap of months between new releases (\"Galaga\"s release in August was followed by \"Xevious\" in November). By the end of 1986, the 7800 had 10 games, compared to Sega's 20 and Nintendo's 36; nine of the NES games were third-party, whereas the 7800 and Master System had no third-party games. A reason cited for the lack of third-party interest in the 7800 was its small 100,000 install base and low market penetration.\n\nAtari's lineup for the 7800 emphasized high-quality versions of popular arcade games like \"Joust\" and \"Asteroids\". This had been a primary reason for the success of the Atari 2600, but \"Joust\" was four years old in 1986, and \"Asteroids\" seven.\n\nDuring the Atari 7800’s life cycle, Atari found themselves struggling to get developers to create 7800 versions of then-popular arcade titles because of a controversial policy employed by Nintendo. When Nintendo revived the industry, it signed up software development companies to create Nintendo Entertainment System games under a strict license agreement which imposed serious restrictions on what they were allowed to do. One of the key clauses was that companies who made Nintendo games were not allowed to make that game on a competing system for a period of two years. Because of the market success of the Nintendo Entertainment System, companies chose to develop for it first and were thus barred from developing the same games on competing systems for two years. The software libraries of the Atari 7800 and Sega Master System suffered tremendously as a result.\n\nEleven titles were developed and sold by three third-party companies under their own labels for the 7800 (Absolute Entertainment, Activision, and Froggo) with the rest published by Atari themselves. However, most Atari development was contracted out. \n\nSome NES titles were developed by companies who had licensed their title from a different arcade manufacturer. While the creator of the NES version would be restricted from making a competitive version of an NES game, the original arcade copyright holder was not precluded from licensing out rights for a home version of an arcade game to multiple systems. Through this loophole, Atari 7800 conversions of \"Mario Bros.\", \"Double Dragon\", \"Commando\", \"Rampage\", \"Xenophobe\", \"Ikari Warriors\", and \"Kung-Fu Master\" were licensed and developed.\n\nBy June 1988, the Atari 7800 had sold 1 million units worldwide.\n\nThe Atari 7800 remained officially active in the United States between 1986 and 1991 and in Europe between 1989 and 1991. On January 1, 1992, Atari Corp. formally announced that production of the Atari 7800, the Atari 2600, the Atari 8-bit computer line, and the Atari XE Game System would cease. (It has since been discovered that Atari Corp. continued to develop games such as \"Toki\" for the Atari 7800 until all development was shut down in May 1993.) By the time of the cancellation, Nintendo's NES dominated the North American market, controlling 80% while Atari Corp. controlled just 12%.\n\nDespite trailing the Nintendo Entertainment System in terms of number of units sold, the 7800 was a profitable enterprise for Atari Corp., benefiting largely from Atari’s name and the system's 2600 compatibility. Profits were strong owing to low investment in game development and marketing.\n\n\nThe graphics are generated by a custom graphics chip called MARIA, which uses an approach to graphics commonly used in arcade game system boards at the time. It was very different from other second and third generation consoles. Instead of a limited number of hardware sprites, MARIA allows for a much larger number of sprites described in a series of display lists. Each display list contains sprite entries with pointers to graphics data, color information, and horizontal positioning. The same display list is used for multiple rasters with the pointers being automatically adjusted. However, managing and displaying a large number of sprites required much more CPU time (both directly and indirectly since the MARIA would halt the CPU when drawing sprites) than consoles with hardware sprites and backgrounds.\n\nMARIA has a number of different graphics modes which are either 160 pixels wide or 320 pixels wide. While the 320 pixel modes theoretically enable the 7800 to create games at higher resolution than the 256 pixel wide graphics found in the Nintendo Entertainment System and Sega Master System, the intense processing demands of MARIA typically meant that programmers created their games using the lower 160 pixel modes.\n\nThe 7800 features a broad (for its time) palette of 256 colors. Depending on various parameters, each individual sprite can use from 1 to 12 colors, with 3 colors (plus a 4th \"transparency\" color) being the most common. In this format, the sprite is referenced to one of 8 palettes, where each palette holds 3 assignable colors. There is also an assignable background color, which will be visible wherever another object has not covered it up. In total the system can utilize 25 colors on a scanline at one time.\n\nThe graphics resolution, color palette assignments, and background color can be adjusted in between scanlines. This technique is documented in the original 1983 \"Atari 3600 Software Guide\". Games often used this feature to render high resolution text in one area of the screen, while displaying more colorful graphics with less resolution in the gameplay area. Demos also exist which use this feature to place all 256 colors on the screen at the same time.\n\nThe MARIA’s approach had advantages and disadvantages when it came to generating graphics in software during the lifespan of the 7800. It excelled at moving around large numbers of sprites on a static screen without the screen flickering that plagued other 8-bit systems. Its flexible design enabled it to play games which used display list manipulation to generate a pseudo 3D appearance such as \"Ballblazer\" (1987) and \"F-18 Hornet\" (1988). While side-scrolling games in the vein of \"Super Mario Bros.\" are possible on the system (1990's \"Scrapyard Dog\" is the best example), it is significantly harder to develop such a title than on a tile-based system such as the Nintendo Entertainment System.\n\nA common criticism of the 7800 regards its use of the TIA to provide 2-channel sound effects and music, resulting in sound quality that is virtually identical to the Atari 2600 VCS from 1977. While the inclusion of 2600 hardware is required to maintain compatibility with the older system, this drove up production costs and reduced available space on the 7800’s motherboard. As such, the 7800 does not include additional hardware for generating sound as it does with graphics and the sound hardware is considered the weakest part of the system.\n\nTo compensate for this, GCC’s engineers allowed games to include a POKEY audio chip in the cartridge which substantially improved the audio quality. To ensure software developers had an economical means of producing better sound than TIA, GCC had originally planned to make a low-cost, high performance sound chip, GUMBY, which could also be placed in 7800 cartridges to enhance its sound capabilities further. This project was cancelled when Atari was sold to Jack Tramiel.\n\nDespite having the capability to support sound chips in cartridges, almost no 7800 cartridges feature POKEY hardware for enhanced sound. \"Ballblazer\", released in 1987, uses the POKEY to generate all music and sound effects. Similarly, \"Commando\", released in 1989, uses a POKEY to generate in-game music while the TIA generates the game's sound effects for a total of 6 channels of sound.\n\nFollowing the debate over \"Custer's Revenge\", an Atari 2600 VCS title with adult themes, Atari had concerns over similar adult titles finding their way onto the 7800 and displaying adult graphics on the significantly improved graphics of the MARIA chip. To combat this, they included a digital signature protection method which prevented unauthorized 7800 games from being played on the system.\n\nWhen a cartridge was inserted into the system, the 7800 BIOS included code which would generate a digital signature of the cartridge ROM and compare it to the signature stored on the cartridge. If a correct signature was located on the cartridge, the 7800 would operate in 7800 mode, granting the game access to MARIA and other features. If a signature was not located, the 7800 remained in 2600 mode and MARIA was unavailable. All 7800 games released in North America had to be digitally signed by Atari. This digital signature code is not present in PAL 7800s, which use various heuristics to detect 2600 cartridges, due to export restrictions. The signing utility was found and released by Classic Gaming Expo in 2001.\n\nThe Atari 7800 differs from the 2600 in several key areas. It features a full Atari SALLY 6502 processor whereas the 2600 VCS has a stripped-down 6507 processor running at a slower speed. It has additional RAM (Random Access Memory) and the ability to access more cartridge data at one time than the 2600. The most substantial difference, however, is a graphics architecture which differs markedly from either the Atari 2600 VCS or Atari’s 8-bit line of computers.\n\nThe 7800's compatibility with the Atari 2600 is made possible by including many of the same chips used in the Atari 2600. When operating in “2600” mode to play Atari 2600 titles, the 7800 uses a Television Interface Adapter (TIA) chip to generate graphics and sound. The processor is slowed to 1.19 MHz, enabling the 7800 to mirror the performance of the 2600's stripped-down 6507 processor. RAM is limited to 128 bytes found in the RIOT and game data is accessed in 4K blocks.\n\nWhen in “7800” mode (signified by the appearance of the full-screen Atari logo), the graphics are generated entirely by the MARIA graphics processing unit, all system RAM is available and game data is accessed in larger 48K blocks. The system’s SALLY 6502 runs at its normal 1.79 MHz instead of the reduced speed of 2600 mode. The 2600 chips are used in 7800 mode to generate sound as well as switch and controller interfaces.\n\nThe Atari 7800 does not support backward compatibility for Atari 5200 games or accessories.\n\nPrototypes:\n\nProduction:\n\nThe Atari 7800 came bundled with the Atari Proline Joystick, a two button controller with a joystick for movement. In response to criticism over ergonomic issues in the 7800’s Pro-Line controllers, Atari later released joypad controllers with European 7800s, which were similar in style to controllers found on Nintendo and Sega Systems. The Joypad was not available in the United States.\n\nUnlike the NES or Sega Master System, there were few add-on peripherals for the 7800, though its backwards compatibility feature allowed it to be compatible with most Atari 2600 peripherals.\n\nThe most notable exception was the XG-1 lightgun, which came bundled with the Atari XE Game System. The XG-1 was fully compatible with the 7800 and was sold separately for other Atari systems. Atari released four 7800 light gun games: \"Alien Brigade\", \"Crossbow\", \"Meltdown\", and \"Barnyard Blaster\".\n\nDue to the acquisition of the Atari Consumer Division by Jack Tramiel in 1984, a number of planned peripherals for the system were canceled.\n\n\nWhile the 7800 can actually play hundreds of titles due to its compatibility with the Atari 2600, there was limited third party support for the 7800 and fewer than 100 titles were specifically designed for it.\n\nAs with most game consoles, there were many more games in development for the 7800 than were actually released. However, very few prototypes have been located, due to Tramiel Atari’s reluctance to make them in the first place. Atari 7800 prototypes tend to be highly coveted by collectors, often fetching hundreds of dollars when sold. Some collectors are unwilling to share the rare items publicly as doing so is assumed to decrease the value of their prototype.\n\nNonetheless, some unreleased Atari 7800 games, as well as early versions of released games have been released to the public. A few have been manufactured and sold.\n\nThese include\n\nEngineering Notes list \"Tempest\" as a game that was between 15–20% completed for the Atari 7800; no code to date has been found. The Atari Museum located and posted unreleased box art and notes for a 7800 version of \"Crystal Castles\", but no code to date has been found for that game, either. Atari's earlier 7800 games listing showed \"Millipede\" as one of the games in the line up; however, it does not appear that it was ever started or worked on.\n\nThe source code for 13 games, as well as the OS and development tools (for the Atari ST computer system) were discovered in a dumpster behind the Atari building in Sunnyvale, California. Commented assembly language source code was made available for \"Centipede\", \"Commando\", \"Crossbow\", \"Desert Falcon\", \"Dig Dug\", \"Food Fight\", \"Galaga\", \"Hat Trick\", \"Joust\", \"Ms. Pac-Man\", \"Super Stunt Cycle\", \"Robotron: 2084\" and \"Xevious\" game titles.\n\nWhen emulators of 1980s video game consoles began to appear on home computers in the late 1990s, the Atari 7800 was one of the last to be emulated. The lack of awareness of the system, the lack of understanding of the hardware, and fears about the digital signature lockout initially caused concerns. Since that time, however, the 7800 has been emulated successfully and is now common on emulation sites. One such program is ProSystem, written in C/C++ for the Microsoft Windows operating system. It uses the Windows API and DirectX to display what it emulates in both PAL and NTSC.\n\nThe digital signature long prevented homebrew games from being developed until the original encryption generating software was discovered. When the original digital signature generating software was turned over to the Atari community, development of new Atari 7800 titles began. In addition, the Atari community has slowly uncovered the original 7800 development tools and released them into the public domain. New tools, documentation, source code and utilities for development have since been created which has sponsored additional homebrew development. Several new commercial Atari 7800 titles such as \"Beef Drop\", \"B*nQ\", \"Pac-Man Collection\", \"Combat 1990\", \"Santa Simon\", and \"Space War\" have been created and released.\n\nIn 2004, Atari (now owned by Infogrames) released the first Atari Flashback console. This system resembled a miniature Atari 7800 and joysticks and had 20 built in games (five 7800 and fifteen 2600 titles). While the unit sold well, it was controversial among Atari fans. Atari had given the engineering firm, Legacy Engineering, extremely limited development timelines. The firm was forced to build the Flashback using NES-On-A-Chip hardware instead of recreating the Atari 7800 hardware. As a result, the Flashback has been criticized for failing to properly replicate the actual Atari gaming experience.\n\nLegacy Engineering was later commissioned to create another 7800 project that was subsequently cancelled after prototypes were made.\n\n\n", "id": "2781", "title": "Atari 7800"}
{"url": "https://en.wikipedia.org/wiki?curid=2782", "text": "Atari Jaguar\n\nThe Atari Jaguar is a home video game console that was developed by Atari Corporation. The console was the sixth and last programmable console to be developed under the Atari brand, originally released in North America in November 1993. Controversially, Atari marketed the Jaguar as being the first 64-bit video game console, while competing with the existing 16-bit consoles (Sega Genesis and Super Nintendo Entertainment System) and the 32-bit 3DO Interactive Multiplayer platform (which launched the same year).\n\nDevelopment on the Atari Jaguar started in the early 1990s, and was designed by Flare Technology, who were tasked by Atari to create two consoles; the Atari Panther, which would compete with the Genesis and the Super NES, and a successor, the Jaguar, which would surpass the capabilities of any other console on the market at the time. With development of the Jaguar running ahead of schedule, the Panther was cancelled, and the release of the Jaguar was pushed forward. It was originally released to test markets in New York City and San Francisco in November 1993, and to the general public in 1994, with \"Cybermorph\" as the pack-in launch game.\n\nThe console's multi-chip architecture made game development for the console difficult, and underwhelming sales further contributed to the console's lack of third party support. This, in addition to the lack of internal development at Atari, led to a limited games library, comprising only 67 licensed titles.\n\nAtari attempted to extend the lifespan of the Jaguar by releasing a CD-ROM add-on known as the Atari Jaguar CD and marketing the Jaguar as the low-cost next generation console, with a price tag over $100 less than any of its competitors. With the release of the Sega Saturn and Sony's PlayStation in 1995, sales of the Jaguar continued to fall, ultimately selling no more than 250,000 units before it was discontinued in 1996. The Jaguar was deemed a commercial failure, and prompted Atari to leave the home video game console market. After Hasbro Interactive bought out Atari in the late 1990s, the patents to the Jaguar were released into the public domain, with the console being declared an open platform. Since then, the Jaguar has gained a cult following, with a developer base that produces homebrew games for the console.\n\nThe Jaguar was developed by the members of Flare Technology, a company formed by Martin Brennan and John Mathieson. The team had claimed that they could not only make a console superior to the Genesis or the Super NES, but they could also be cost-effective. Impressed by their work on the Konix Multisystem, Atari persuaded them to close Flare and form a new company called Flare II, with Atari providing the funding. Flare II initially set to work designing two consoles for Atari Corp. One was a 32-bit architecture (codenamed \"Panther\"), and the other was a 64-bit system (codenamed \"Jaguar\"); however, work on the Jaguar design progressed faster than expected, so Atari Corp. canceled the Panther project to focus on the more promising Jaguar.\n\nThe Jaguar was unveiled in August 1993 at the Chicago Consumer Entertainment Show.\n\nThe Jaguar was introduced in 1993 at a price of $249.99, under a $500 million manufacturing deal with IBM. The system was initially available only in the test markets of New York City and San Francisco, under the slogan \"Do the Math\", claiming superiority over competing 16-bit and 32-bit systems. A U.S.-wide release followed six months later, in early 1994.\n\nThe Atari Jaguar struggled to attain a substantial user base. In 1993, Atari reported that it had shipped 17,000 units as part of the system's initial test market. By the end of 1994, Atari reported that it had sold approximately 100,000 systems and had reduced the price to improve the competitive nature of the console. By the end of 1995, Sony and Sega had entered the marketplace with competing consoles and Atari's sales declined rapidly. In Atari's 1995 annual report, it noted:\n\n\"Jaguar sales were substantially below Atari's expectations, and Atari's business and financial results were materially adversely affected in 1995 as Atari continued to invest heavily in Jaguar game development, entered into arrangements to publish certain licensed titles and reduced the retail price for its Jaguar console unit. Atari attributes the poor performance of Jaguar to a number of factors including (i) extensive delays in development of software for the Jaguar which resulted in reduced orders due to consumer concern as to when titles for the platform would be released and how many titles would ultimately be available, and (ii) the introduction of competing products by Sega and Sony in May 1995 and September 1995, respectively.\"\n\nThe lack of titles was attributable to two main factors: the Jaguar's questionable long-term prospects among third-party game-publishers and the problematic nature of developing games for the Jaguar. Atari had one opportunity to convince third-party developers, vital for the diversity of Jaguar's game library, with a solid retail-performance, but as things played out, post-holiday sales figures questioned the viability of Atari's business; Atari failed to attract many third-party developers already committed to other game platforms. In addition, the Jaguar's underlying hardware was crippled by a flaw in the CPU's memory controller, which prevented code execution out of system RAM. Less severe defects included a buggy UART. The memory controller flaw could have been mitigated by a mature code-development environment, to unburden the programmer from having to micromanage small chunks of code. Jaguar's development tools left much to the programmer's own implementation, as documentation was incomplete. Writing game-code was often an endurance exercise in the tedious assembler.\n\nIn a July 1995 interview with \"Next Generation\", then-CEO Sam Tramiel declared that the Jaguar was as powerful, if not more powerful, than the Sega Saturn, and slightly weaker than the PlayStation. \"Next Generation\" received a deluge of letters in response to Tramiel's comments, particularly his threat to bring Sony to court for price dumping if the PlayStation entered the U.S. market at a retail price below $300 and his remark that the small number of third party Jaguar games was good for Atari's profitability (which angered Jaguar owners who were already frustrated at how few games were coming out for the system).\n\nBy the end of 1995, Atari's revenues declined by more than half, from US$38.7 million in 1994 to $14.6 million in 1995. In late 1995, Atari Corp. ran early-morning infomercial advertisements with enthusiastic salesmen touting the powerful game system. The infomercials ran most of the year, but did not significantly sell the remaining stock of Jaguar systems. By November 1995, mass layoffs and insider statements were fueling journalistic speculation that Atari had ceased both development and manufacturing for the Jaguar and was simply trying to sell off existing stock before exiting the video game industry. Though Atari Corp. continued to deny these theories going into 1996, core Jaguar developers such as High Voltage Software and Beyond Games stated that they were no longer receiving communications from Atari regarding Jaguar projects. In its 10-K405 SEC Filing, filed April 12, 1996, Atari informed their stockholders of the truly dire nature of the Jaguar business: \n\nProduction of the Jaguar ceased after Atari Corp. merged with JT Storage in a reverse takeover. In a last-ditch effort to revive the Jaguar, Atari Corp. tried to play down the other two consoles by proclaiming the Jaguar was the only \"64-bit\" system. This claim is questioned by some, because the CPU (68000) and GPU executed a 32-bit instruction-set, but sent control signals to the 64-bit graphics co-processors (or \"graphics accelerators\"). Atari Corp.'s reasoning that the 32-bit \"Tom\" and \"Jerry\" chips work in tandem to add up to a 64-bit system was ridiculed in a mini-editorial by \"Electronic Gaming Monthly\", which commented that \"If Sega did the math for the Sega Saturn the way Atari did the math for their 64-bit Jaguar system, the Sega Saturn would be a 112-bit monster of a machine.\" On the other side, \"Next Generation\", while giving a mostly negative review of the Jaguar, maintained that it is a true 64-bit system, since the data path from the DRAM to the CPU and Tom and Jerry chips is 64 bits wide. Design specs for the console allude to the GPU or DSP being capable of acting as a CPU, leaving the Motorola 68000 to read controller inputs. In practice, however, many developers used the Motorola 68000 to drive gameplay logic.\n\nFrom the Jaguar Software Reference manual, page 1:\n\nJaguar is a custom chip set primarily intended to be the heart of a very high-performance games/leisure computer. It may also be used as a graphics accelerator in more complex systems, and applied to workstation and business uses. As well as a general purpose CPU, Jaguar contains four processing units. These are the Object Processor, Graphics Processor, Blitter, and Digital Sound Processor. Jaguar provides these blocks with a 64-bit data path to external memory devices, and is capable of a very high data transfer rate into external dynamic RAM.\n\n\n\nAtari Games licensed the Atari Jaguar's chipset for use in its arcade games. The system, named COJAG (for \"Coin-Op Jaguar\"), replaced the 68000 with a 68020 or MIPS R3000-based CPU (depending on the board version), and added a hard drive and more RAM. It ran the lightgun games \"Area 51\" and \"Maximum Force\", which were released by Atari as dedicated cabinets or as the Area 51/Maximum Force combo machine. Other games (\"3 On 3 Basketball\"; \"Fishin' Frenzy\"; \"Freeze\"; \"Vicious Circle\") were developed but never released.\n\nThe Atari Jaguar Duo was a proposed console similar to the TurboDuo and Genesis CDX. It was an attempt by Atari to combine the Atari Jaguar and Atari Jaguar CD to make a new console. A prototype model, described by journalists as resembling a bathroom scale, was unveiled at the 1995 Winter Consumer Electronics Show, but the console was cancelled before production could begin.\n\nPrior to the launch of the console in November 1993, Atari had announced a variety of peripherals and add-ons for the Jaguar to be released over the console's lifespan. This included a CD-ROM-based add-on console, a dial-up internet link with support for online gaming, a virtual reality headset, and an MPEG-2 video card. However, due to the poor sales and eventual commercial failure of the Jaguar, most of the peripherals in development were scrapped. The only peripherals and add-ons released by Atari for the Jaguar were a redesigned controller, an adapter for four-players, a CD console add-on and a link cable for Local area network (LAN) gaming.\n\nThe redesigned second controller for the Jaguar, named the \"ProController\" by Atari, added three more face buttons, two triggers, and had a flat interface. The controller was created in response to the criticism of the original controller that the console came with. Sold independently, however, it was never bundled with the system after its release. A peripheral that allowed 4 controllers to be plugged into the console was also released. Dubbed the \"Team Tap\", it was released independently and as a bundle with \"White Men Can't Jump\". However, the Team Tap was only compatible with \"White Men Can't Jump\" and \"NBA Jam Tournament Edition\". Eight player gameplay with the Team Tap peripheral is also possible if a second Team Tap is plugged into the second controller port on the console. Local area network multiplayer gameplay was achieved through the use of the Jaglink Interface, which allowed two Jaguar consoles to be linked together through a modular extension and a UTP phone cable. The Jaglink was compatible with three games: \"AirCars\", \"BattleSphere\" and \"Doom\".\n\nIn 1994 at the CES, Atari announced that it partnered up with Phylon, Inc. to create the Jaguar Voice/Data Communicator. The unit was delayed and eventually in 1995 mass production was canceled all together, but not before an estimated 100 or so were made. The JVM as it became known, utilized a 19.9kbit/s dial up modem and had the ability to answer incoming phone calls and store up to 18 phone numbers. Players were required to directly dial each other for online game play. The only Jaguar game that supports the JVM is Ultra Vortek, the modem is initialized in the Ultra Vortek start up screen by entering 911 on the key pad.\n\nThe Atari Jaguar CD is an add-on to the Jaguar that made use of CD-ROMs to distribute games. It was released in September 1995, two years after the Jaguar's launch. Twelve games were released for the system during its manufacturing lifetime, with more being made after by homebrew developers. Each Jaguar CD unit came with a Virtual Light Machine, which displayed light patterns corresponding to music, if the user inserts an audio CD into the console. It was developed by Jeff Minter, who had created the program after experimenting with graphics during the development of \"Tempest 2000\". The program was deemed a spiritual successor to the Atari Video Music, a system which served a similar purpose, released in 1976.\n\nAn additional accessory for the Jaguar CD, which allowed Jaguar CD games to save persistent data such as preferences and saved games, was also released. Known as the Memory Track, it was a cartridge that contained a 128 K EEPROM, and was to be inserted into the cartridge slot on the Jaguar CD while the user played a Jaguar CD game. The program manager for the Memory Track is accessed by pushing the option button while the system is starting, and exited by pushing the * and # keys simultaneously. There were plans to make a second model of the Jaguar console that combined both the Jaguar and the Jaguar CD into one unit, a la the TurboDuo. Originally codenamed the Jaguar III, and later the Jaguar Duo, the proposed model was scrapped after the discontinuation of the Jaguar.\n\nA virtual reality headset compatible with the console, tentatively titled the Jaguar VR, was unveiled by Atari at the 1995 Winter Consumer Electronics Show. The development of the peripheral was a response to Nintendo's virtual reality console, the Virtual Boy, which had been announced the previous year. The headset was developed in cooperation with Virtuality, who had previously created many virtual reality arcade systems, and was already developing a similar headset for practical purposes, named Project Elysium, for IBM. The peripheral was targeted for a commercial release before Christmas 1995. However, the deal with Virtuality was abandoned in October 1995. After Atari's merger with JTS in 1996, all prototypes of the headset were allegedly destroyed. However, two working units, one low-resolution prototype with red and grey-colored graphics, and one high-resolution prototype with blue and grey-colored graphics, have since been recovered, and are regularly showcased at retrogaming-themed conventions and festivals. Only one game was developed for the Jaguar VR prototype; a 3D-rendered version of the 1980 arcade game \"Missile Command\", entitled \"Missile Command 3D\", though a demo of Virtuality's \"Zone Hunter\" was also created for Jaguar VR demonstrations.\n\nAn unofficial expansion peripheral for the Atari Jaguar dubbed the \"Catbox\" was released by the Rockford, Illinois company ICD. It was originally slated to be released early in the Jaguar's life, in the second quarter of 1994, but was not actually released until mid-1995. The ICD CatBox plugs directly into the AV/DSP connectors located in the rear of the Jaguar console and provides three main functions. These are audio, video, and communications. It features six output formats, three for audio (line level stereo, RGB monitor, headphone jack with volume control) and three for video (composite, S-Video, and RGB analog component video) making the Jaguar compatible with multiple high quality monitor systems and multiple monitors at the same time. It is capable of communications methods known as CatNet and RS-232 as well as DSP pass through, allowing the user to connect two or more Jaguars together for multi player games either directly or with modems. The ICD CatBox features a polished stainless steel casing and red LEDs in the jaguar's eyes on the logo that indicate communications activity. An IBM AT type null modem cable may be used to connect two Jaguars together. The CatBox is also compatible with Atari's Jaglink Interface peripheral.\n\nAn adaptor for the Jaguar that allows for WebTV access was revealed in 1998; one prototype is known to exist.\n\nReviewing the Jaguar just a few weeks prior to its launch, \"GamePro\" gave it a \"thumbs sideways\". They praised the power of the hardware but criticized the controller, and were dubious of how the software lineup would turn out, commenting that Atari's failure to secure support from key third party publishers such as Capcom was a bad sign. They concluded that \"Like the 3DO, the Jaguar is a risky investment - just not quite as expensive.\"\n\nThe small size and poor quality of the Jaguar's game library became the most commonly cited reason for its failure in the marketplace. Jaguar did earn praise with titles such as \"Tempest 2000\", \"Doom\", and \"Wolfenstein 3D\". The most successful title during the Jaguar's first year was \"Alien vs. Predator\". Both it and \"Tempest 2000\" were named among the system's defining titles by \"GamePro\" in 2007. However, these occasional successes were seen as insufficient while the Jaguar's competitors were receiving a continuous stream of critically acclaimed software; \"GamePro\" concluded their rave review of \"Alien vs.Predator\" by remarking \"If Atari can turn out a dozen more games like AvP, Jaguar owners could truly rest easy and enjoy their purchase.\" In a late 1995 review of the Jaguar, \"Next Generation\" commented that \"thus far, Atari has spectacularly failed to deliver on the software side, leaving many to question the actual quality and capability of the hardware. With only one or two exceptions - \"Tempest 2000\" is cited most frequently - there have just been no truly great games for the Jaguar up to now.\" They further noted that while Atari is well known by older gamers, the company had much less overall brand recognition than Sega, Sony, Nintendo, or even The 3DO Company. However, they argued that with its low price point, the Jaguar might still compete if Atari could improve the software situation. They gave the system two out of five stars. With such a small library of games to challenge the incumbent 16-bit game consoles, Jaguar's appeal never grew beyond a small gaming audience. Digital Spy commented: \"Like many failed hardware ventures, it still maintains something of a cult following but can only be considered a misstep for Atari.\"\n\nIn 2006 IGN editor Craig Harris rated the standard Jaguar controller as the worst game controller ever, criticizing the unwarranted recycling of the 1980s \"phone keypad\" format and the small number of action buttons, which he found particularly unwise given that Atari was actively trying to court fighting game fans to the system. Ed Semrad of \"Electronic Gaming Monthly\" commented that many Jaguar games gratuitously used all of the controller's phone keypad buttons, making the controls much more difficult than they needed to be.\n\nAfter the Atari Corporation properties were bought out by Hasbro Interactive in the late 1990s, Hasbro released the rights to the Jaguar, declaring the console an open platform and opening the doors for homebrew development. A few developers, including Telegames and Songbird Productions, released previously unfinished materials from the Jaguar's past and several brand new titles to satisfy the system's cult following.\n\nIn the United Kingdom in 2001, a deal was struck between Telegames and retailer Game to bring the Jaguar to Game's retail outlets. The machine was initially sold for £29.99 brand new and software prices ranged between £9.99 for more common games such as \"Doom\" and \"Ruiner Pinball\", and £39.99 for more sought-after releases such as \"Defender 2000\" and \"Checkered Flag\". The machine had a presence in the stores until 2007 when remaining consoles were sold off for £9.99 and games were sold for as low as 97p.\n\nThis deal was seen as a move to remain competitive with Game's rival at the time, Gamestation, who were well known for stocking retro formats.\n\nImagin Systems, a manufacturer of dental imaging equipment, has since purchased the molding plates for the Jaguar's casing as with minor modification they were found to be the right size for housing their HotRod camera. The game cartridge molds were reused to create an optional memory expansion card.\n\nIn December 2014, the molds for the console and cartridges were purchased from Imagin Systems by Mike Kennedy, owner of the Kickstarter funded \"Retro Videogame Magazine\", to propose a new crowdfunded video game console called the \"Retro VGS\", later rebranded the \"Coleco Chameleon\" after entering a licensing agreement with Coleco. The purchase of the molds from Imagin Systems was far cheaper than designing and manufacturing entirely new molds, and Kennedy described their acquisition as \"the entire reason [the Retro VGS] is possible\". However, the project was ultimately terminated in March 2016 following a long period of heavy criticism and controversy surrounding Kennedy's perceived dishonesty, unprofessionalism, and lack of technical knowledge in addition to the perceived lack of market demand for the proposed console. The project culminated with the production of two \"prototypes\" that were quickly proven to be fake, and Coleco removing their involvement from the project after Kennedy and his team failed to produce a prototype for investigation. After the project's termination, the molds were sold to Albert Yarusso, the founder of the AtariAge website.\n\n\n", "id": "2782", "title": "Atari Jaguar"}
{"url": "https://en.wikipedia.org/wiki?curid=2783", "text": "Atari Lynx\n\nThe Atari Lynx is a 16-bit handheld game console that was released by Atari Corporation in September 1989 in North America, and in Europe and Japan in 1990. The Lynx holds the distinction of being the world's first handheld electronic game with a color LCD. The system is also notable for its forward-looking features, advanced graphics, and ambidextrous layout. The Lynx competed with the Game Boy (released just 2 months earlier), as well as the Game Gear and TurboExpress, both released the following year. It was discontinued when Atari was acquired by Hasbro Interactive in 1995.\n\nThe Atari Lynx's innovative features include being the first color handheld, with a backlit display, a switchable right-handed/left-handed (upside down) configuration, and the ability to network with up to 17 other units via its \"Comlynx\" system (though most games would network eight or fewer players). Comlynx was originally developed to run over infrared links (and was codenamed RedEye). This was changed to a cable-based networking system before the final release.\nThe Lynx was cited as the \"first gaming console with hardware support for zooming and distortion of sprites\". Featuring a 4096 color palette and integrated math and graphics co-processors (including a blitter unit), its pseudo-3D color graphics display was said to be the key defining feature in the system's competition against Nintendo's monochromatic Game Boy. The fast pseudo-3D graphics features were made possible on a minimal hardware system by codesigner Dave Needle having \"invented the technique for planar expansion/shrinking capability\" and using stretched, textured, triangles instead of full polygons. These particular features were achieved over a year prior to the launch of the Super NES, whose stock hardware features the comparable Mode 7 but which cannot scale sprites.\n\nThe Lynx was the second handheld game system to be released with the Atari name. The first was Atari Inc.'s handheld electronic game \"Touch Me\". Atari Inc. had previously worked on several other handheld projects including the \"Breakout\", \"Space Invaders\", and the Atari Cosmos portable/tabletop console. However, those projects were shut down during development, some just short of their intended commercial release.\n\nThe Lynx system was originally developed by Epyx as the Handy Game. In 1986, two former Amiga designers, R. J. Mical and Dave Needle, had been asked by former manager at Amiga, David Morse, if they could come up with a design for a portable gaming system. Morse now worked at Epyx, a game software company that had a recent string of hit games. Morse's son had asked him if he could make a portable gaming system, prompting the lunch with Mical and Needle to discuss the idea. Morse convinced Mical and Needle to develop the idea and they were hired by Epyx to be a part of the design team. Planning and design of the console began in 1986 and was completed in 1987. Epyx first showed the Handy system at the Winter Consumer Electronics Show (CES) in January 1989. Facing financial difficulties, Epyx sought out partners. Nintendo, Sega, and other companies declined, but Atari Corp. and Epyx eventually agreed that Atari Corp. would handle production and marketing, while Epyx would handle software development. Epyx declared bankruptcy by the end of the year, and Atari essentially owned the entire project; both Atari and others, however, had to purchase Amigas from Atari archrival Commodore to develop Lynx software.\n\nThe Handy was designed to run games from the cartridge format, and the game data must be copied from ROM to RAM before it can be used. Thus, less RAM is available and the games initially load relatively slowly. There are trace remnants of a cassette tape interface physically capable of being programmed to read a tape. Lynx developers have noted that \"there is still reference of the tape and some hardware addresses\" and an updated vintage Epyx manual describes the bare existence of what could be utilized for tape support. A 2009 retrospective interview clarifies that although some early reports claimed that games were loaded from tape, Mical says there was no truth in them: \"We did think about hard disk a little\".\n\nAtari Corp. changed the internal speaker and removed the thumb-stick on the control pad before releasing it as the Lynx, initially retailing in the US at . Atari Corp. then showed the Lynx to the press at the Summer 1989 CES as the \"Portable Color Entertainment System\", which was changed to \"Lynx\" when actual consoles were distributed to resellers.\n\nThe Lynx started off successfully. Atari reported that they had sold 90% of the 50,000 units it shipped in its launch month in the U.S. with a limited launch in New York. US sales in 1990 were approximately 500,000 units according to the Associated Press. In late 1991, it was reported that Atari sales estimates were about 800,000, which Atari claimed was within their expected projections. Lifetime sales by 1995 amounted to fewer than 7 million units when combined with the Game Gear. In comparison, the Game Boy sold 16 million units by 1995 because it was more rugged, cost half as much, had much longer battery life, was bundled with \"Tetris\", and had a superior software library. In issue 129 of \"Retro Gamer\" magazine, a special article was published to celebrate the 25th anniversary of the console which included interviews with numerous ex-Atari and ex-Epyx staff where lifetime Lynx sales figures were confirmed as being in the region of 3 million.\n\nAs with the actual console units, the game cartridges themselves evolved over the first year of the console's release. The first generation of cartridges were flat, and were designed to be stackable for ease of storage. However, this design proved to be very difficult to remove from the console and was replaced by a second design. This style, called \"tabbed\" or \"ridged\", used the same basic design as the original cartridges with the addition of two small tabs on the cartridge's underside to aid in removal. The original flat style cartridges could be stacked on top of the newer cartridges, but the newer cartridges could not be easily stacked on each other, nor were they stored easily. Thus a third style, the \"curved lip\" style was produced, and all official and third-party cartridges during the console's lifespan were released (or re-released) using this style.\n\nIn May 1991, Sega launched its Game Gear portable gaming handheld. Also a color handheld, in comparison to the Lynx it had a higher cost and shorter battery life (3–4 hours as opposed to 4-5 for the Lynx), but it was slightly smaller and was backed up by significantly more games. In North America the Game Gear took second place, and while in Europe sales of the Lynx were initially quite strong on the back of the popular Atari ST, it still could not compete with the software library of the Game Gear and was eventually pushed into third place. Retailers such as Game and Toys R Us continued to sell the Lynx well into the mid-1990s on the back of the Atari Jaguar launch, helped by magazines such as \"Ultimate Future Games\" who continued to cover the Lynx alongside the new generation of 32-bit and 64-bit consoles.\n\nDuring 1990, the Lynx had moderate sales. In July 1991, Atari Corp. introduced the Lynx II with a new marketing campaign, new packaging, slightly improved hardware, better battery life and a new sleeker look. The new system (referred to within Atari Corp. as the \"Lynx II\") featured rubber hand grips and a clearer backlit color screen with a power save option (which turned off the LCD panel's backlighting). It also replaced the monaural headphone jack of the original Lynx with one wired for stereo. The new packaging made the Lynx available without any accessories, dropping the price to $99. Although sales improved, Nintendo still dominated the handheld market.\n\nIn 1995, Atari Corp. shifted its focus away from the Lynx. As the Super NES and Genesis filled retailers' shelves, Atari Corp. refocused its efforts on its Jaguar console and its CD-ROM add-on. A handful of games were released during this time, including \"Battlezone 2000\". In 1996, Atari shut down its internal game development.\n\nThe game system was reviewed in 1990 in \"Dragon\", giving the Lynx 5 out of 5 stars. The review states that the Lynx \"throws the into the prehistoric age\"; and praises the built-in object scaling capabilities, the multiplayer feature of the ComLynx cable, and the strong set of launch games.\n\nThe infrequency of Lynx software releases and the system's minimal marketing budget have been cited as the main factors in its commercial failure.\n\nTelegames released a number of games in the second half of the 1990s, including a port of \"Raiden\" and a platformer called \"Fat Bobby\" in 1997, as well as an action sports game called \"Hyperdrome\" in 1999. At the end of the 1990s, Hasbro, the owners of the Atari properties at the time, released the rights to develop for the system to the public domain. Since then a number of independent developers released games into the new decade, like \"Championship Rally\", \"CyberVirus\", and \"Alpine Games\". Some of the late 1990s/early 2000s games were under development by other companies at one time, but rights to the game programs and all of the existing code was bought and finished by other developers.\n\nIn 2008 Atari was honored at the 59th Annual Technology & Engineering Emmy Awards for pioneering the development of handheld games with its Lynx game unit.\n\nOn October 24, 2009, North American company Super Fighter Team released \"Zaku\", a horizontal shooter for the Lynx developed by PenguiNet. It was the first new game for the system since the 1990s whose game card has an authentic \"curved lip\" plastic shell instead of a custom bare circuit board.\n\nThere is a retrogaming community, creating and selling games for the system.\n\n\n2 x 256KB Dram chips for ripping the rom from the cartridge,an audin pin can switch between those 2 256KB blocks if needed\n\n\n", "id": "2783", "title": "Atari Lynx"}
{"url": "https://en.wikipedia.org/wiki?curid=2784", "text": "Ahimsa\n\nAhimsa (; IAST: ', Pāli: ') means 'not to injure' and 'compassion' and refers to a key virtue in Indian religions. The word is derived from the Sanskrit root \"hiṃs\" – to strike; \"hiṃsā\" is injury or harm, \"a-hiṃsā\" is the opposite of this, i.e. cause no injury, do no harm. Ahimsa is also referred to as nonviolence, and it applies to all living beings—including all animals—in ancient Indian religions.\n\nAhimsa is one of the cardinal virtues and an important tenet of Jainism, Hinduism, and Buddhism. Ahimsa is a multidimensional concept, inspired by the premise that all living beings have the spark of the divine spiritual energy; therefore, to hurt another being is to hurt oneself. Ahimsa has also been related to the notion that any violence has karmic consequences. While ancient scholars of Hinduism pioneered and over time perfected the principles of Ahimsa, the concept reached an extraordinary status in the ethical philosophy of Jainism. Most popularly, Mahatma Gandhi strongly believed in the principle of \"ahimsa\".\n\nAhimsa's precept of 'cause no injury' includes one's deeds, words, and thoughts. Classical literature of Hinduism such as Mahabharata and Ramayana, as well as modern scholars debate principles of Ahimsa when one is faced with war and situations requiring self-defence. The historic literature from India and modern discussions have contributed to theories of Just War, and theories of appropriate self-defence.\n\nThe word \"Ahimsa\"—sometimes spelled as \"Ahinsa\"—is derived from the Sanskrit root \"hiṃs\" – to strike; \"hiṃsā\" is injury or harm, \"a-hiṃsā\" is the opposite of this, i.e. \"non harming\" or \"nonviolence\".\n\nThere is a debate on the origins of the word \"Ahimsa\", and how its meaning evolved. Mayrhofer as well as Dumot suggest the root word may be \"han\" which means kill, which leads to the interpretation that \"ahimsa\" means \"do not kill\". Schmidt as well as Bodewitz explain the proper root word is \"hiṃs\" and the Sanskrit verb \"hinasti\", which leads to the interpretation \"ahimsa\" means \"do not injure\", or \"do not hurt\". Wackernagel-Debrunner concur with the latter explanation.\n\nAncient texts use ahimsa to mean non-injury, a broader concept than non-violence. Non-injury implies not killing others, as well as not hurting others mentally or verbally; it includes avoiding all violent means—including physical violence—anything that injures others. In classical Sanskrit literature of Hinduism, another word \"Adrohi\" is sometimes used instead of \"Ahimsa\", as one of the cardinal virtues necessary for moral life. One example is in Baudhayana Dharmasutra 2.6.23: वाङ्-मनः-कर्म-दण्डैर् भूतानाम् अद्रोही (One who does not injure others with words, thoughts or acts is named \"Adrohi\").\n\nAhimsa as an ethical concept evolved in Vedic texts. The oldest scripts, along with discussing ritual animal sacrifices, indirectly mention Ahimsa, but do not emphasise it. Over time, the Hindu scripts revise ritual practices and the concept of Ahimsa is increasingly refined and emphasised, ultimately Ahimsa becomes the concept that describes the highest virtue by the late Vedic era (about 500 BC). For example, hymn 10.22.25 in the Rig Veda uses the words Satya (truthfulness) and Ahimsa in a prayer to deity Indra; later, the Yajur Veda dated to be between 1000 BC and 600 BC, states, \"may all beings look at me with a friendly eye, may I do likewise, and may we look at each other with the eyes of a friend\".\n\nThe term \"Ahimsa\" appears in the text Taittiriya Shakha of the Yajurveda (TS 5.2.8.7), where it refers to non-injury to the sacrificer himself. It occurs several times in the \"Shatapatha Brahmana\" in the sense of \"non-injury\". The Ahimsa doctrine is a late Vedic era development in Brahmanical culture. The earliest reference to the idea of non-violence to animals (\"pashu-Ahimsa\"), apparently in a moral sense, is in the Kapisthala Katha Samhita of the Yajurveda (KapS 31.11), which may have been written in about the 8th century BCE.\n\nBowker states the word appears but is uncommon in the principal Upanishads. Kaneda gives examples of the word \"Ahimsa\" in these Upanishads. Other scholars suggest \"Ahimsa\" as an ethical concept that started evolving in the Vedas, becoming an increasingly central concept in Upanishads.\n\nThe Chāndogya Upaniṣad, dated to the 8th or 7th century BCE, one of the oldest Upanishads, has the earliest evidence for the use of the word \"Ahimsa\" in the sense familiar in Hinduism (a code of conduct). It bars violence against \"all creatures\" (\"sarvabhuta\") and the practitioner of Ahimsa is said to escape from the cycle of metempsychosis (CU 8.15.1). A few scholars are of the opinion that this might have been a concession to the growing influence of Jainism, in Vedic Hinduism.\n\nChāndogya Upaniṣad also names Ahimsa, along with Satyavacanam (truthfulness), Arjavam (sincerity), Danam (charity), Tapo (penance/meditation), as one of five essential virtues (CU 3.17.4).\n\nThe Sandilya Upanishad lists ten forbearances: Ahimsa, Satya, Asteya, Brahmacharya, Daya, Arjava, Kshama, Dhriti, Mitahara and Saucha. According to Kaneda, the term Ahimsa is an important spiritual doctrine shared by Hinduism, Buddhism and Jainism. It literally means 'non-injury' and 'non-killing'. It implies the total avoidance of harming of any kind of living creatures not only by deeds, but also by words and in thoughts.\n\nThe Mahabharata, one of the epics of Hinduism, has multiple mentions of the phrase \"Ahimsa Paramo Dharma\" (अहिंसा परमॊ धर्मः), which literally means: non-violence is the highest moral virtue. For example, Mahaprasthanika Parva has the verse:\n<poem>\nअहिंसा परमॊ धर्मस तथाहिंसा परॊ दमः।\nअहिंसा परमं दानम अहिंसा परमस तपः।\nअहिंसा परमॊ यज्ञस तथाहिस्मा परं बलम।\nअहिंसा परमं मित्रम अहिंसा परमं सुखम।\nअहिंसा परमं सत्यम अहिंसा परमं शरुतम॥\n</poem>\nThe above passage from Mahabharata emphasises the cardinal importance of Ahimsa in Hinduism, and literally means: Ahimsa is the highest virtue, Ahimsa is the highest self-control, Ahimsa is the greatest gift, Ahimsa is the best suffering, Ahimsa is the highest sacrifice, Ahimsa is the finest strength, Ahimsa is the greatest friend, Ahimsa is the greatest happiness, Ahimsa is the highest truth, and Ahimsa is the greatest teaching. Some other examples where the phrase \"Ahimsa Paramo Dharma\" are discussed include Adi Parva, Vana Parva and Anushasana Parva. The Bhagavad Gita, among other things, discusses the doubts and questions about appropriate response when one faces systematic violence or war. These verses develop the concepts of lawful violence in self-defence and the theories of just war. However, there is no consensus on this interpretation. Gandhi, for example, considers this debate about non-violence and lawful violence as a mere metaphor for the internal war within each human being, when he or she faces moral questions.\n\nThe classical texts of Hinduism devote numerous chapters discussing what people who practice the virtue of Ahimsa, can and must do when they are faced with war, violent threat or need to sentence someone convicted of a crime. These discussions have led to theories of just war, theories of reasonable self-defence and theories of proportionate punishment. Arthashastra discusses, among other things, why and what constitutes proportionate response and punishment.\n\nThe precepts of Ahimsa under Hinduism require that war must be avoided, with sincere and truthful dialogue. Force must be the last resort. If war becomes necessary, its cause must be just, its purpose virtuous, its objective to restrain the wicked, its aim peace, its method lawful. War can only be started and stopped by a legitimate authority. Weapons used must be proportionate to the opponent and the aim of war, not indiscriminate tools of destruction. All strategies and weapons used in the war must be to defeat the opponent, not designed to cause misery to the opponent; for example, use of arrows is allowed, but use of arrows smeared with painful poison is not allowed. Warriors must use judgment in the battlefield. Cruelty to the opponent during war is forbidden. Wounded, unarmed opponent warriors must not be attacked or killed, they must be brought to your realm and given medical treatment. Children, women and civilians must not be injured. While the war is in progress, sincere dialogue for peace must continue.\n\nIn matters of self-defence, different interpretations of ancient Hindu texts have been offered. For example, Tähtinen suggests self-defence is appropriate, criminals are not protected by the rule of Ahimsa, and Hindu scriptures support the use of violence against an armed attacker. Ahimsa is not meant to imply pacifism.\n\nAlternate theories of self-defence, inspired by Ahimsa, build principles similar to theories of just war. Aikido, pioneered in Japan, illustrates one such principles of self-defence. Morihei Ueshiba, the founder of Aikido, described his inspiration as Ahimsa. According to this interpretation of Ahimsa in self-defence, one must not assume that the world is free of aggression. One must presume that some people will, out of ignorance, error or fear, attack other persons or intrude into their space, physically or verbally. The aim of self-defence, suggested Ueshiba, must be to neutralise the aggression of the attacker, and avoid the conflict. The best defence is one where the victim is protected, as well as the attacker is respected and not injured if possible. Under Ahimsa and Aikido, there are no enemies, and appropriate self-defence focuses on neutralising the immaturity, assumptions and aggressive strivings of the attacker.\n\nTähtinen concludes that Hindus have no misgivings about death penalty; their position is that evil-doers who deserve death should be killed, and that a king in particular is obliged to punish criminals and should not hesitate to kill them, even if they happen to be his own brothers and sons.\n\nOther scholars conclude that the scriptures of Hinduism suggest sentences for any crime must be fair, proportional and not cruel.\n\nThere is no universal consensus on pacifism among Hindu scholars of modern times. The conflict between pacifistic interpretations of Ahimsa and the theories of just war prescribed by the Gita has been resolved by some scholars such as Mohandas Karamchand Gandhi, as being an allegory, wherein the battlefield is the soul and Arjuna, the war is within each human being, where man's higher impulses struggle against his own evil impulses.\n\nThe Hindu precept of 'cause no injury' applies to animals and all life forms. This precept isn't found in the oldest verses of Vedas, but increasingly becomes one of the central ideas between 500 BC and 400 AD. In the oldest texts, numerous ritual sacrifices of animals, including cows and horses, are highlighted and hardly any mention is made of Ahimsa to non-human life.\n\nHindu scriptures, dated to between 5th century and 1st century BC, while discussing human diet, initially suggest \"kosher\" meat may be eaten, evolving it with the suggestion that only meat obtained through ritual sacrifice can be eaten, then that one should eat no meat because it hurts animals, with verses describing the noble life as one that lives on flowers, roots and fruits alone.\n\nLater texts of Hinduism declare Ahimsa one of the primary virtues, declare any killing or harming any life as against \"dharma\" (moral life). Finally, the discussion in Upanishads and Hindu Epics shifts to whether a human being can ever live his or her life without harming animal and plant life in some way; which and when plants or animal meat may be eaten, whether violence against animals causes human beings to become less compassionate, and if and how one may exert least harm to non-human life consistent with ahimsa precept, given the constraints of life and human needs. The Mahabharata permits hunting by warriors, but opposes it in the case of hermits who must be strictly non-violent. Sushruta Samhita, a Hindu text written in the 3rd or 4th century, in Chapter XLVI suggests proper diet as a means of treating certain illnesses, and recommends various fishes and meats for different ailments and for pregnant women, and the Charaka Samhita describes meat as superior to all other kinds of food for convalescents.\n\nAcross the texts of Hinduism, there is a profusion of ideas about the virtue of Ahimsa when applied to non-human life, but without a universal consensus. Alsdorf claims the debate and disagreements between supporters of vegetarian lifestyle and meat eaters was significant. Even suggested exceptions – ritual slaughter and hunting – were challenged by advocates of Ahimsa. In the Mahabharata both sides present various arguments to substantiate their viewpoints. Moreover, a hunter defends his profession in a long discourse.\n\nMany of the arguments proposed in favor of non-violence to animals refer to the bliss one feels, the rewards it entails before or after death, the danger and harm it prevents, as well as to the karmic consequences of violence.\n\nThe ancient Hindu texts discuss Ahimsa and non-animal life. They discourage wanton destruction of nature including of wild and cultivated plants. Hermits (sannyasins) were urged to live on a fruitarian diet so as to avoid the destruction of plants. Scholars claim the principles of ecological non-violence is innate in the Hindu tradition, and its conceptual fountain has been Ahimsa as their cardinal virtue.\n\nThe classical literature of Hinduism exists in many Indian languages. For example, \"Tirukkuṛaḷ,\" written between 200 BC and 400 AD, and sometimes called the Tamil Veda, is one of the most cherished classics on Hinduism written in a South Indian language. Tirukkuṛaḷ dedicates Chapters 26, 32 and 33 of Book 1 to the virtue of Ahimsa, namely, vegetarianism, non-harming, and non-killing, respectively. \"Tirukkuṛaḷ\" says that Ahimsa applies to all life forms.\n\nIn the 19th and 20th centuries, prominent figures of Indian spirituality such as Swami Vivekananda, Ramana Maharshi, Swami Sivananda, A. C. Bhaktivedanta Swami and in the present time Vijaypal Baghel emphasised the importance of Ahimsa.\n\nMohandas Karamchand Gandhi promoted the principle of Ahimsa, very successful by applying it to all spheres of life, particularly to politics (Swaraj). His non-violent resistance movement satyagraha had an immense impact on India, impressed public opinion in Western countries, and influenced the leaders of various civil and political rights movements such as the American civil rights movement's Martin Luther King, Jr. and James Bevel. In Gandhi's thought, Ahimsa precludes not only the act of inflicting a physical injury, but also mental states like evil thoughts and hatred, unkind behavior such as harsh words, dishonesty and lying, all of which he saw as manifestations of violence incompatible with Ahimsa. Gandhi believed Ahimsa to be a creative energy force, encompassing all interactions leading one's self to find satya, \"Divine Truth\". Sri Aurobindo criticised the Gandhian concept of Ahimsa as unrealistic and not universally applicable; he adopted a pragmatic non-pacifist position, saying that the justification of violence depends on the specific circumstances of the given situation. Sri Aurobindo also indicated that Gandhi's Ahimsa led to partition of India as it blocked the forceful action that the Indian people were engaged in during the 1920s and 30s, which caused delay in independence, allowing other forces to take root, including those who wanted India divided.\n\nGandhi stated that he viewed \"Ahimsa is in Hinduism, it is in Christianity as well as in Islam.\" He added, \"Nonviolence is common to all religions, but it has found the highest expression and application in Hinduism (I do not regard Jainism or Buddhism as separate from Hinduism).\" When questioned whether violence and non-violence is both taught in Quran, he stated, \"I have heard it from many Muslim friends that the Koran teaches the use of non-violence. (... The) argument about non-violence in the Holy Koran is an interpolation, not necessary for my thesis.\"\n\nA historical and philosophical study of Ahimsa was instrumental in the shaping of Albert Schweitzer's principle of \"reverence for life\". Schweitzer praised Indian philosophical and religious traditions for ethics of Ahimsa as, \"the laying down of the commandment not to kill and not to damage is one of the greatest events in the spiritual history of mankind\", but suggested that \"not-killing and not-harming\" is not always practically possible as in self-defence, nor ethical as in chronic starving during a famine case.\n\nAhimsa is imperative for practitioners of Patañjali's eight limb Raja yoga system. It is included in the first limb and is the first of five Yamas (self restraints) which, together with the second limb, make up the code of ethical conduct in Yoga philosophy. Ahimsa is also one of the ten \"Yamas\" in Hatha Yoga according to verse 1.1.17 of its classic manual \"Hatha Yoga Pradipika\".\nThe significance of Ahimsa as the very first restraint in the very first limb of Yoga (Yamas), is that it defines the necessary foundation for progress through Yoga. It is a precursor to Asana, implying that success in Yogasana can be had only if the self is purified in thought, word and deed through the self-restraint of Ahimsa.\n\nIn Jainism, the understanding and implementation of \"Ahimsā\" is more radical, scrupulous, and comprehensive than in any other religion. Killing any living being out of passions is considered \"hiṃsā\" (to injure) and abstaining from such an act is \"ahimsā\" (noninjury). The vow of ahimsā is considered the foremost among the 'five vows of Jainism'. Other vows like truth (satya) are meant for safeguarding the vow of ahimsā. In the practice of Ahimsa, the requirements are less strict for the lay persons (sravakas) who have undertaken \"anuvrata\" (Smaller Vows) than for the Jain monastics who are bound by the Mahavrata \"Great Vows\". The statement \"\" is often found inscribed on the walls of the Jain temples. Like in Hinduism, the aim is to prevent the accumulation of harmful karma. When Mahavira revived and reorganised the Jain faith in the 6th or 5th century BCE, Ahimsa was already an established, strictly observed rule. Rishabhanatha (Ādinātha), the first Jain Tirthankara, whom modern Western historians consider to be a historical figure, followed by Parshvanatha (Pārśvanātha) the twenty-third Tirthankara lived in about the 8th century BCE. He founded the community to which Mahavira's parents belonged. Ahimsa was already part of the \"Fourfold Restraint\" (\"Caujjama\"), the vows taken by Parshva's followers. In the times of Mahavira and in the following centuries, Jains were at odds with both Buddhists and followers of the Vedic religion or Hindus, whom they accused of negligence and inconsistency in the implementation of Ahimsa. According to the Jain tradition either lacto vegetarianism or veganism is mandatory.\n\nThe Jain concept of Ahimsa is characterised by several aspects. It does not make any exception for ritual sacrificers and professional warrior-hunters. Killing of animals for food is absolutely ruled out. Jains also make considerable efforts not to injure plants in everyday life as far as possible. Though they admit that plants must be destroyed for the sake of food, they accept such violence only inasmuch as it is indispensable for human survival, and there are special instructions for preventing unnecessary violence against plants. Jains go out of their way so as not to hurt even small insects and other minuscule animals. For example, Jains often do not go out at night, when they are more likely to step upon an insect. In their view, injury caused by carelessness is like injury caused by deliberate action. Eating honey is strictly outlawed, as it would amount to violence against the bees. Some Jains abstain from farming because it inevitably entails unintentional killing or injuring of many small animals, such as worms and insects, but agriculture is not forbidden in general and there are Jain farmers.\n\nTheoretically, all life forms are said to deserve full protection from all kinds of injury, but Jains recognise a hierarchy of life. Mobile beings are given higher protection than immobile ones. For the mobile beings, they distinguish between one-sensed, two-sensed, three-sensed, four-sensed and five-sensed ones; a one-sensed animal has touch as its only sensory modality. The more senses a being has, the more they care about non-injuring it. Among the five-sensed beings, the precept of non-injury and non-violence to the rational ones (humans) is strongest in Jain Ahimsa.\n\nJains agree with Hindus that violence in self-defence can be justified, and they agree that a soldier who kills enemies in combat is performing a legitimate duty. Jain communities accepted the use of military power for their defence, there were Jain monarchs, military commanders, and soldiers.\n\nIn Buddhist texts \"Ahimsa\" (or its Pāli cognate ) is part of the Five Precepts (), the first of which has been to abstain from killing. This precept of Ahimsa is applicable to both the Buddhist layperson and the monk community.\n\nThe Ahimsa precept is not a commandment and transgressions did not invite religious sanctions for layperson, but their power has been in the Buddhist belief in karmic consequences and their impact in afterlife during rebirth. Killing, in Buddhist belief, could lead to rebirth in the hellish realm, and for a longer time in more severe conditions if the murder victim was a monk. Saving animals from slaughter for meat, is believed to be a way to acquire merit for better rebirth. These moral precepts have been voluntarily self-enforced in lay Buddhist culture through the associated belief in karma and rebirth. The Buddhist texts not only recommended Ahimsa, but suggest avoiding trading goods that contribute to or are a result of violence:\n\nUnlike lay Buddhists, transgressions by monks do invite sanctions. Full expulsion of a monk from \"sangha\" follows instances of killing, just like any other serious offense against the monastic \"nikaya\" code of conduct.\n\nViolent ways of punishing criminals and prisoners of war was not explicitly condemned in Buddhism, but peaceful ways of conflict resolution and punishment with the least amount of injury were encouraged. The early texts condemn the mental states that lead to violent behavior.\n\nNonviolence is an overriding theme within the Pali Canon. While the early texts condemn killing in the strongest terms, and portray the ideal king as a pacifist, such a king is nonetheless flanked by an army. It seems that the Buddha's teaching on nonviolence was not interpreted or put into practice in an uncompromisingly pacifist or anti-military-service way by early Buddhists. The early texts assume war to be a fact of life, and well-skilled warriors are viewed as necessary for defensive warfare. In Pali texts, injunctions to abstain from violence and involvement with military affairs are directed at members of the sangha; later Mahayana texts, which often generalise monastic norms to laity, require this of lay people as well.\n\nThe early texts do not contain just-war ideology as such. Some argue that a sutta in the \"Gamani Samyuttam\" rules out all military service. In this passage, a soldier asks the Buddha if it is true that, as he has been told, soldiers slain in battle are reborn in a heavenly realm. The Buddha reluctantly replies that if he is killed in battle while his mind is seized with the intention to kill, he will undergo an unpleasant rebirth. In the early texts, a person's mental state at the time of death is generally viewed as having a great impact on the next birth.\n\nSome Buddhists point to other early texts as justifying defensive war. One example is the \"Kosala Samyutta\", in which King Pasenadi, a righteous king favored by the Buddha, learns of an impending attack on his kingdom. He arms himself in defence, and leads his army into battle to protect his kingdom from attack. He lost this battle but won the war. King Pasenadi eventually defeated King Ajatasattu and captured him alive. He thought that, although this King of Magadha has transgressed against his kingdom, he had not transgressed against him personally, and Ajatasattu was still his nephew. He released Ajatasattu and did not harm him. Upon his return, the Buddha said (among other things) that Pasenadi \"is a friend of virtue, acquainted with virtue, intimate with virtue\", while the opposite is said of the aggressor, King Ajatasattu.\n\nAccording to Theravada commentaries, there are five requisite factors that must all be fulfilled for an act to be both an act of killing and to be karmically negative. These are: (1) the presence of a living being, human or animal; (2) the knowledge that the being is a living being; (3) the intent to kill; (4) the act of killing by some means; and (5) the resulting death. Some Buddhists have argued on this basis that the act of killing is complicated, and its ethicization is predicated upon intent. Some have argued that in defensive postures, for example, the primary intention of a soldier is not to kill, but to defend against aggression, and the act of killing in that situation would have minimal negative karmic repercussions.\n\nAccording to Dr. Babasaheb Ambedkar, there is circumstantial evidence encouraging Ahimsa, from the Buddha's doctrine, \"\"Love all, so that you may not wish to kill any.\"\" Gautama Buddha distinguished between a principle and a rule. He did not make Ahimsa a matter of rule, but suggested it as a matter of principle. This gives Buddhists freedom to act.\n\nThe emperors of Sui dynasty, Tang dynasty and early Song dynasty banned killing in Lunar calendar 1st, 5th, and 9th month. Empress Wu Tse-Tien banned killing for more than half a year in 692. Some also banned fishing for some time each year.\n\nThere were bans after death of emperors, Buddhist and Taoist prayers, and natural disasters such as after a drought in 1926 summer Shanghai and an 8 days ban from August 12, 1959 after the August 7 flood (), the last big flood before the 88 Taiwan Flood.\n\nPeople avoid killing during some festivals, like the Taoist Ghost Festival, the Nine Emperor Gods Festival, the Vegetarian Festival and many others.\n\n\n", "id": "2784", "title": "Ahimsa"}
{"url": "https://en.wikipedia.org/wiki?curid=2785", "text": "Annals of Mathematics\n\nThe Annals of Mathematics is a bimonthly mathematical journal published by Princeton University and the Institute for Advanced Study.\nAlthough its ISO 4 abbreviation is \"Ann. Math.\", \"Mathematical Reviews\" and many other mathematical publications abbreviate it as \"Ann. of Math.\" instead.\n\nThe journal was established as \"The Analyst\" in 1874 and with Joel E. Hendricks as the founding editor-in-chief. It was \"intended to afford a medium for the presentation and analysis of any and all questions of interest or importance in pure and applied Mathematics, embracing especially all new and interesting discoveries in theoretical and practical astronomy, mechanical philosophy, and engineering\". It was published in Des Moines, Iowa, and was the earliest American mathematics journal to be published continuously for more than a year or two. This incarnation of the journal ceased publication after its tenth year, in 1883, giving as an explanation Hendricks' declining health, but Hendricks made arrangements to have it taken over by new management, and it was continued from March 1884 as the \"Annals of Mathematics\". The new incarnation of the journal was edited by Ormond Stone (University of Virginia). It moved to Harvard in 1899 before reaching its current home in Princeton in 1911.\n\nAn important period for the journal was 1928–1958 with Solomon Lefschetz as editor. During this time, it became an increasingly well-known and respected journal. Its rise, in turn, stimulated American mathematics. Norman Steenrod characterized Lefschetz' impact as editor as follows: \"\"The importance to American mathematicians of a first-class journal is that it sets high standards for them to aim at. In this somewhat indirect manner, Lefschetz profoundly affected the development of mathematics in the United States.\"\"\n\nPrinceton University continued to publish the annals on its own until 1933, when the Institute for Advanced Study took joint editorial control. Since 1998 it has been available in an electronic edition, alongside its regular print edition. The electronic edition was available without charge, as an open access journal, but since 2008 this is no longer the case. Issues from before 2003 were transferred to the non-free JSTOR archive, and articles are not freely available until 5 years after publication.\n\nThe current editors of the \"Annals of Mathematics\" are David Gabai, Charles Fefferman, Nicholas M. Katz, Sergiu Klainerman, and Gang Tian (all from Princeton University) and Peter Sarnak (from the Institute for Advanced Study).\n\nThe journal is abstracted and indexed in the Science Citation Index, Current Contents/Physical, Chemical & Earth Sciences, and Scopus. According to the \"Journal Citation Reports\", the journal has a 2012 impact factor of 3.027, ranking it third out of 296 journals in the category \"Mathematics\".\n", "id": "2785", "title": "Annals of Mathematics"}
{"url": "https://en.wikipedia.org/wiki?curid=2786", "text": "Andrei Sakharov\n\nAndrei Dmitrievich Sakharov (; 21 May 192114 December 1989) was a Russian nuclear physicist, Soviet dissident, an activist for disarmament, peace and human rights.\n\nHe became renowned as the designer of the Soviet Union's RDS-37, a codename for Soviet development of thermonuclear weapons. Sakharov later became an advocate of civil liberties and civil reforms in the Soviet Union, for which he faced state persecution; these efforts earned him the Nobel Peace Prize in 1975. The Sakharov Prize, which is awarded annually by the European Parliament for people and organizations dedicated to human rights and freedoms, is named in his honour.\n\nSakharov was born in Moscow on May 21, 1921. His father was Dmitri Ivanovich Sakharov, a private school physics teacher and an amateur pianist. His father later taught at the Second Moscow State University. Andrei's grandfather Ivan had been a prominent lawyer in the Russian Empire who had displayed respect for social awareness and humanitarian principles (including advocating the abolition of capital punishment) that would later influence his grandson. Sakharov's mother was Yekaterina Alekseyevna Sakharova, a great-granddaughter of the prominent military commander Alexey Semenovich Sofiano (who was of Greek ancestry). Sakharov's parents and paternal grandmother, Maria Petrovna, largely shaped his personality. Although Sakharov's paternal great-grandfather had been a priest in the Russian Orthodox Church, and his pious mother had him baptised, Sakharov was an atheist in later life. However, he did believe that a \"guiding principle\" governed the universe and human life.\n\nSakharov entered Moscow State University in 1938. Following evacuation in 1941 during the Great Patriotic War (World War II), he graduated in Aşgabat, in today's Turkmenistan. He was then assigned to laboratory work in Ulyanovsk. In 1943, he married Klavdia Alekseyevna Vikhireva, with whom he raised two daughters and a son before she died in 1969. He returned to Moscow in 1945 to study at the Theoretical Department of FIAN (the Physical Institute of the Soviet Academy of Sciences). He received his Ph.D. in 1947.\n\nAfter World War II, he researched cosmic rays. In mid-1948 he participated in the Soviet atomic bomb project under Igor Kurchatov and Igor Tamm. Sakharov's study group at FIAN in 1948 came up with a second concept in August–September 1948. Adding a shell of natural, unenriched uranium around the deuterium would increase the deuterium concentration at the uranium-deuterium boundary and the overall yield of the device, because the natural uranium would capture neutrons and itself fission as part of the thermonuclear reaction. This idea of a layered fission-fusion-fission bomb led Sakharov to call it the sloika, or layered cake. The first Soviet atomic device was tested on August 29, 1949. After moving to Sarov in 1950, Sakharov played a key role in the development of the first megaton-range Soviet hydrogen bomb using a design known as \"Sakharov's Third Idea\" in Russia and the Teller-Ulam design in the United States. Before his \"Third Idea\", Sakharov tried a \"layer cake\" of alternating layers of fission and fusion fuel. The results were disappointing, yielding no more than a typical fission bomb. However the design was seen to be worth pursuing because deuterium is abundant and uranium is scarce, and he had no idea how powerful the US design was. One of the Bikini atomic experiments changed that, because the magnitude of the explosion became public knowledge when there was a dispute between Japan and the US over the contamination of a large area of ocean. Sakharov was surprised by the size of the explosion and realized that the Americans had harnessed the power of a separate fission explosion to compress the fusion fuel. Sakharov realised that in order to cause the explosion of one side of the fuel to symmetrically compress the fusion fuel, a mirror could be used to reflect the radiation. The details had not been officially declassified in Russia when Sakharov was writing his memoirs, but in the Teller-Ulam design, soft X-rays emitted by the fission bomb were focused onto a cylinder of lithium deuteride to compress it symmetrically. This is called radiation implosion. The Teller-Ulam design also had a secondary fission device inside the fusion cylinder to assist with the compression of the fusion fuel and generate neutrons to convert some of the lithium to tritium, producing a mixture of deuterium and tritium. Sakharov's idea was first tested as RDS-37 in 1955. A larger variation of the same design which Sakharov worked on was the 50 Mt Tsar Bomba of October 1961, which was the most powerful nuclear device ever detonated.\n\nSakharov saw \"striking parallels\" between his fate and those of J. Robert Oppenheimer and Edward Teller in the USA. Sakharov believed that in this \"tragic confrontation of two outstanding people\", both deserved respect, because \"each of them was certain he had right on his side and was morally obligated to go to the end in the name of truth.\" While Sakharov strongly disagreed with Teller over nuclear testing in the atmosphere and the Strategic Defense Initiative, he believed that American academics had been unfair to Teller's resolve to get the H-bomb for the United States since \"all steps by the Americans of a temporary or permanent rejection of developing thermonuclear weapons would have been seen either as a clever feint, or as the manifestation of stupidity. In both cases, the reaction would have been the same – avoid the trap and immediately take advantage of the enemy's stupidity.\"\n\nSakharov never felt that by creating nuclear weapons he had \"known sin\", in Oppenheimer's expression. He later wrote: \"After more than forty years, we have had no third world war, and the balance of nuclear terror ... may have helped to prevent one. But I am not at all sure of this; back then, in those long-gone years, the question didn't even arise. What most troubles me now is the instability of the balance, the extreme peril of the current situation, the appalling waste of the arms race ... Each of us has a responsibility to think about this in global terms, with tolerance, trust, and candor, free from ideological dogmatism, parochial interests, or national egotism.\"\n\nIn 1950 he proposed an idea for a controlled nuclear fusion reactor, the tokamak, which is still the basis for the majority of work in the area. Sakharov, in association with Igor Tamm, proposed confining extremely hot ionized plasma by torus shaped magnetic fields for controlling thermonuclear fusion that led to the development of the tokamak device.\n\nIn 1951 he invented and tested the first explosively pumped flux compression generators, compressing magnetic fields by explosives. He called these devices MC or MK (for \"magnetocumulative\") generators. The radial MK-1 produced a pulsed magnetic field of 25 megagauss (2500 teslas). The resulting helical MK-2 generated 1000 million amperes in 1953.\n\nSakharov then tested a MK-driven \"plasma cannon\" where a small aluminum ring was vaporized by huge eddy currents into a stable, self-confined toroidal plasmoid and was accelerated to 100 km/s. Sakharov later suggested replacing the copper coil in MK generators with a large superconductor solenoid to magnetically compress and focus underground nuclear explosions into a shaped charge effect. He theorized this could focus 10 protons per second on a 1 mm surface.\n\nAfter 1965 Sakharov returned to fundamental science and began working on particle physics and physical cosmology.\n\nHe tried to explain the baryon asymmetry of the universe, being the first scientist to introduce two universes called \"sheets\", linked by the Big Bang. Sakharov achieved there a complete CPT symmetry since the second sheet is enantiomorph (P-symmetry), has an opposite arrow of time (T-symmetry) and is mainly populated by antimatter (C-symmetry) because of an opposite CP-violation. In this model the two universes do not interact, except via local matter accumulation whose density and pressure become high enough to connect the two sheets through a bridge without spacetime between them, but with geodesics continuity beyond the radius limit allowing an exchange of matter. Sakharov called such singularities a \"collapse\" and an \"anticollapse\", which are an alternative to the couple black hole and white hole in the wormhole theory. Sakharov also proposed the idea of induced gravity as an alternative theory of quantum gravity.\n\nSince the late 1950s Sakharov had become concerned about the moral and political implications of his work. Politically active during the 1960s, Sakharov was against nuclear proliferation. Pushing for the end of atmospheric tests, he played a role in the 1963 Partial Test Ban Treaty, signed in Moscow.\n\nSakharov was also involved in an event with political consequences in 1964, when the USSR Academy of Sciences nominated for full membership Nikolai Nuzhdin, a follower of Trofim Lysenko (initiator of the Stalin-supported anti-genetics campaign Lysenkoism). Contrary to normal practice Sakharov, a member of the Academy, publicly spoke out against full membership for Nuzhdin, holding him responsible for \"for the defamation, firing, arrest, even death, of many genuine scientists.\" In the end, Nuzhdin was not elected, but the episode prompted Sergei Khrushchev to order the KGB to gather compromising material on Sakharov.\n\nThe major turn in Sakharov's political evolution came in 1967, when anti-ballistic missile defense became a key issue in US–Soviet relations. In a secret detailed letter to the Soviet leadership of July 21, 1967, Sakharov explained the need to \"take the Americans at their word\" and accept their proposal for a \"bilateral rejection by the USA and the Soviet Union of the development of antiballistic missile defense\", because otherwise an arms race in this new technology would increase the likelihood of nuclear war. He also asked permission to publish his manuscript (which accompanied the letter) in a newspaper to explain the dangers posed by this kind of defense. The government ignored his letter and refused to let him initiate a public discussion of ABMs in the Soviet press.\n\nIn May 1968 Sakharov completed an essay entitled \"Reflections on Progress, Peaceful Coexistence, and Intellectual Freedom\". In it, he described the anti-ballistic missile defense as a major threat of world nuclear war. After this essay was circulated in \"samizdat\" and then published outside the Soviet Union, Sakharov was banned from conducting any military-related research and returned to FIAN to study fundamental theoretical physics.\n\nOver the next twelve years, until his exile to Gorky (Nizhny Novgorod) in January 1980, Andrei Sakharov assumed the role of a widely recognized and open dissident in Moscow. He stood vigil outside of closed courtrooms, wrote appeals on behalf of more than two hundred individual prisoners, and continued to write essays about the need for democratization.\n\nIn 1970 Sakharov was among the three founding members of the Committee on Human Rights in the USSR along with Valery Chalidze and Andrei Tverdokhlebov. The Committee wrote appeals, collected signatures for petitions and succeeded in affiliating with several international human rights organizations. Its work was the subject of many KGB reports and brought Sakharov under increasing pressure from the government.\n\nSakharvov married a fellow human rights activist, Yelena Bonner, in 1972.\n\nBy 1973 Sakharov was meeting regularly with Western correspondents, holding press conferences in his apartment. He appealed to the U.S. Congress to approve the 1974 Jackson-Vanik Amendment to a trade bill, which coupled trade tariffs to the Kremlin's willingness to allow freer emigration.\n\nIn 1972 Sakharov became the target of sustained pressure and intimidation, from his fellow scientists in the USSR Academy of Sciences, the Soviet press and direct threats of physical assault. Dissident activists, including the writer Solzhenitsyn, sprang to his defence.\n\nIn 1973 and 1974, the Soviet media campaign continued, targeting both Sakharov and Aleksandr Solzhenitsyn. While Sakharov disagreed with Solzhenitsyn's vision of Russian revival, he deeply respected him for his courage. Only a few individuals in the Soviet Union were willing to defend 'traitors' like Sakharov and Solzhenitsyn, and those who had dared were inevitably punished.\n\nSakharov later described that it took \"years\" for him to \"understand how much substitution, deceit, and lack of correspondence with reality there was\" in the Soviet ideals. \"At first I thought, despite everything that I saw with my own eyes, that the Soviet State was a breakthrough into the future, a kind of prototype for all countries\". Then he came, in his words, to \"the theory of symmetry: all governments and regimes to a first approximation are bad, all peoples are oppressed, and all are threatened by common dangers.\"\n\nAfter that he realized that there is not much \"symmetry between a cancer cell and a normal one. Yet our state is similar to a cancer cell – with its messianism and expansionism, its totalitarian suppression of dissent, the authoritarian structure of power, with a total absence of public control in the most important decisions in domestic and foreign policy, a closed society that does not inform its citizens of anything substantial, closed to the outside world, without freedom of travel or the exchange of information.\" Sakharov's ideas on social development led him to put forward the principle of human rights as a new basis of all politics. In his works he declared that \"the principle 'what is not prohibited is allowed' should be understood literally\", defying the unwritten ideological rules imposed by the Communist ruling elite on the society in spite of the seemingly democratic (1936) USSR Constitution.\n\nIn no way did Sakharov consider himself a prophet or the like: \"I am no volunteer priest of the idea, but simply a man with an unusual fate. I am against all kinds of self-immolation (for myself and for others, including the people closest to me).\" In a letter written from exile, he cheered up a fellow physicist and human rights activist with the words: \"Fortunately, the future is unpredictable and also – because of quantum effects – uncertain.\" For Sakharov the indeterminacy of the future supported his belief that he could, and should, take personal responsibility for it.\n\nIn 1973, Sakharov was nominated for the Nobel Peace Prize and in 1974 was awarded the Prix mondial Cino Del Duca.\n\nSakharov was awarded the Nobel Peace Prize in 1975. The Norwegian Nobel Committee called him \"a spokesman for the conscience of mankind\". In the words of the Nobel Committee's citation: \"In a convincing manner Sakharov has emphasised that Man's inviolable rights provide the only safe foundation for genuine and enduring international cooperation.\"\n\nSakharov was not allowed to leave the Soviet Union to collect the prize. His wife Yelena Bonner read his speech at the ceremony in Oslo, Norway. On the day the prize was awarded, Sakharov was in Vilnius, where human rights activist Sergei Kovalev was being tried. In his Nobel lecture, titled \"Peace, Progress, Human Rights\", Sakharov called for an end to the arms race, greater respect for the environment, international cooperation, and universal respect for human rights. He included a list of prisoners of conscience and political prisoners in the USSR, stating that he shares the prize with them.\n\nBy 1976 the head of the KGB Yuri Andropov was prepared to call Sakharov \"Domestic Enemy Number One\" before a group of KGB officers.\n\nSakharov was arrested on January 22, 1980, following his public protests against the Soviet intervention in Afghanistan in 1979, and was sent to internal exile in the city of Gorky, now Nizhny Novgorod, a city that was off limits to foreigners.\n\nBetween 1980 and 1986, Sakharov was kept under tight Soviet police surveillance. In his memoirs he mentions that their apartment in Gorky was repeatedly subjected to searches and heists. Sakharov was named the 1980 Humanist of the Year by the American Humanist Association.\n\nIn May 1984, Sakharov's wife, Yelena Bonner, was detained and Sakharov began a hunger strike, demanding permission for his wife to travel to the United States for heart surgery. He was forcibly hospitalized and force-fed. He was held in isolation for four months. In August 1984 Yelena Bonner was sentenced by a court to five years of exile in Gorky.\n\nIn April 1985, Sakharov started a new hunger strike for his wife to travel abroad for medical treatment. He again was taken to a hospital and force-fed. In August the Politburo discussed what to do about Sakharov. He remained in the hospital until October 1985 when his wife was allowed to travel to the United States. She had heart surgery in the United States and returned to Gorky in June 1986.\n\nIn December 1985, the European Parliament established the Sakharov Prize for Freedom of Thought, to be given annually for outstanding contributions to human rights.\n\nOn December 19, 1986, Mikhail Gorbachev, who had initiated the policies of perestroika and glasnost, called Sakharov to tell him that he and his wife could return to Moscow.\n\nIn 1988, Sakharov was given the International Humanist Award by the International Humanist and Ethical Union. He helped to initiate the first independent legal political organizations and became prominent in the Soviet Union's growing political opposition. In March 1989, Sakharov was elected to the new parliament, the All-Union Congress of People's Deputies and co-led the democratic opposition, the Inter-Regional Deputies Group. In November the head of the KGB reported to Mikhail Gorbachev on Sakharov's encouragement and support for the coal-miners' strike in Vorkuta.\n\nSoon after 21:00 on December 14, 1989, Sakharov went to his study to take a nap before preparing an important speech he was to deliver the next day in the Congress. His wife went to wake him at 23:00 as he had requested but she found Sakharov dead on the floor. According to the notes of Yakov Rapoport, a senior pathologist present at the autopsy, it is most likely that Sakharov died of an arrhythmia consequent to dilated cardiomyopathy at the age of 68. He was interred in the Vostryakovskoye Cemetery in Moscow.\n\nThe Sakharov Prize for Freedom of Thought was established in 1988 by the European Parliament in his honour, and is the highest tribute to human rights endeavours awarded by the European Union. It is awarded annually by the parliament to \"those who carry the spirit of Soviet dissident Andrei Sakharov\"; to \"Laureates who, like Sakharov, dedicate their lives to peaceful struggle for human rights.\"\n\nAn Andrei Sakharov prize has also been awarded by the American Physical Society every second year since 2006 \"to recognize outstanding leadership and/or achievements of scientists in upholding human rights\".\n\nThe Andrei Sakharov Prize For Writer's Civic Courage was established in October 1990.\n\nIn 2004, with the approval of Elena Bonner, an annual Sakharov Prize for journalism was established for reporters and commentators in Russia. Funded by former Soviet dissident Pyotr Vins, now a businessman in the USA, the prize is administered by the Glasnost Defence Foundation in Moscow. The prize \"for journalism as an act of conscience\" has been won over the years by famous journalists such as Anna Politkovskaya and young reporters and editors working far from Russia's media capital, Moscow. The 2015 winner was Yelena Kostyuchenko.\n\nThe Andrei Sakharov Archives and Human Rights Center, established at Brandeis University in 1993, are now housed at Harvard University.\nThe documents from that archive were published by the Yale University Press in 2005. These documents are available online.\nMost of documents of the archive are letters from the head of the KGB to the Central Committee about activities of Soviet dissidents and recommendations about the interpretation in newspapers. The letters cover the period from 1968 to 1991 (Brezhnev stagnation). The documents characterize not only Sakharov's activity, but that of other dissidents, as well as that of highest-position apparatchiks and the KGB. No Russian equivalent of the KGB archive is available.\n\n\n\n\nIn 1980, Sakharov was stripped of all Soviet awards for \"anti-Soviet activities\". Later, during glasnost, he declined the return of his awards and, consequently, Mikhail Gorbachev did not sign the necessary decree.\n\n\n\n\n\n\n\n", "id": "2786", "title": "Andrei Sakharov"}
{"url": "https://en.wikipedia.org/wiki?curid=2787", "text": "Astrobiology\n\nAstrobiology is the study of the origin, evolution, distribution, and future of life in the universe: extraterrestrial life and life on Earth. Astrobiology addresses the question of whether life exists beyond Earth, and how humans can detect it if it does (the term exobiology is similar but more specific—it covers the search for life beyond Earth, and the effects of extraterrestrial environments on living things).\n\nAstrobiology makes use of physics, chemistry, astronomy, biology, molecular biology, ecology, planetary science, geography, and geology to investigate the possibility of life on other worlds and help recognize biospheres that might be different from that on Earth. The origin and early evolution of life is an inseparable part of the discipline of astrobiology. Astrobiology concerns itself with interpretation of existing scientific data; given more detailed and reliable data from other parts of the universe, the roots of astrobiology itself—physics, chemistry and biology—may have their theoretical bases challenged. Although speculation is entertained to give context, astrobiology concerns itself primarily with hypotheses that fit firmly into existing scientific theories.\n\nThis interdisciplinary field encompasses research on the origin and evolution of planetary systems, origins of organic compounds in space, rock-water-carbon interactions, abiogenesis on Earth, planetary habitability, research on biosignatures for life detection, and studies on the potential for life to adapt to challenges on Earth and in outer space.\n\nThe chemistry of life may have begun shortly after the Big Bang, 13.8 billion years ago, during a habitable epoch when the Universe was only 10–17 million years old. According to the panspermia hypothesis, microscopic life—distributed by meteoroids, asteroids and other small Solar System bodies—may exist throughout the universe. According to research published in August 2015, very large galaxies may be more favorable to the creation and development of habitable planets than such smaller galaxies as the Milky Way. Nonetheless, Earth is the only place in the universe humans know to harbor life. Estimates of habitable zones around other stars, sometimes referred to as \"Goldilocks zones,\" along with the discovery of hundreds of extrasolar planets and new insights into extreme habitats here on Earth, suggest that there may be many more habitable places in the universe than considered possible until very recently.\n\nCurrent studies on the planet Mars by the \"Curiosity\" and \"Opportunity\" rovers are searching for evidence of ancient life as well as plains related to ancient rivers or lakes that may have been habitable. The search for evidence of habitability, taphonomy (related to fossils), and organic molecules on the planet Mars is now a primary NASA and ESA objective.\n\n\"Astrobiology\" is etymologically derived from the Greek , \"astron\", \"constellation, star\"; , \"bios\", \"life\"; and , \"-logia\", \"study\". The synonyms of astrobiology are diverse; however, the synonyms were structured in relation to the most important sciences implied in its development: astronomy and biology. A close synonym is \"exobiology\" from the Greek , \"external\"; Βίος, \"bios\", \"life\"; and λογία, -logia, \"study\". The term exobiology was coined by molecular biologist Joshua Lederberg. Exobiology is considered to have a narrow scope limited to search of life external to Earth, whereas subject area of astrobiology is wider and investigates the link between life and the universe, which includes the search for extraterrestrial life, but also includes the study of life on Earth, its origin, evolution and limits. \n\nAnother term used in the past is xenobiology, (\"biology of the foreigners\") a word used in 1954 by science fiction writer Robert Heinlein in his work The Star Beast. The term \"xenobiology\" is now used in a more specialized sense, to mean \"biology based on foreign chemistry\", whether of extraterrestrial or terrestrial (possibly synthetic) origin. Since alternate chemistry analogs to some life-processes have been created in the laboratory, xenobiology is now considered as an extant subject.\n\nWhile it is an emerging and developing field, the question of whether life exists elsewhere in the universe is a verifiable hypothesis and thus a valid line of scientific inquiry. Though once considered outside the mainstream of scientific inquiry, astrobiology has become a formalized field of study. Planetary scientist David Grinspoon calls astrobiology a field of natural philosophy, grounding speculation on the unknown, in known scientific theory. NASA's interest in exobiology first began with the development of the U.S. Space Program. In 1959, NASA funded its first exobiology project, and in 1960, NASA founded an Exobiology Program, which is now one of four main elements of NASA's current Astrobiology Program. In 1971, NASA funded the search for extraterrestrial intelligence (SETI) to search radio frequencies of the electromagnetic spectrum for interstellar communications transmitted by extraterrestrial life outside the Solar System. NASA's Viking missions to Mars, launched in 1976, included three biology experiments designed to look for metabolism of present life on Mars.\n\nAdvancements in the fields of astrobiology, observational astronomy and discovery of large varieties of extremophiles with extraordinary capability to thrive in the harshest environments on Earth, have led to speculation that life may possibly be thriving on many of the extraterrestrial bodies in the universe. A particular focus of current astrobiology research is the search for life on Mars due to its proximity to Earth and geological history. There is a growing body of evidence to suggest that Mars has previously had a considerable amount of water on its surface, water being considered an essential precursor to the development of carbon-based life.\n\nMissions specifically designed to search for current life on Mars were the Viking program and Beagle 2 probes. The Viking results were inconclusive, and Beagle 2 failed minutes after landing. A future mission with a strong astrobiology role would have been the Jupiter Icy Moons Orbiter, designed to study the frozen moons of Jupiter—some of which may have liquid water—had it not been cancelled. In late 2008, the Phoenix lander probed the environment for past and present planetary habitability of microbial life on Mars, and to research the history of water there.\n\nIn November 2011, NASA launched the Mars Science Laboratory mission carrying the \"Curiosity\" rover, which landed on Mars at Gale Crater in August 2012. The \"Curiosity\" rover is currently probing the environment for past and present planetary habitability of microbial life on Mars. On 9 December 2013, NASA reported that, based on evidence from \"Curiosity\" studying Aeolis Palus, Gale Crater contained an ancient freshwater lake which could have been a hospitable environment for microbial life.\n\nThe European Space Agency is currently collaborating with the Russian Federal Space Agency (Roscosmos) and developing the ExoMars astrobiology rover, which is to be launched in 2018. While NASA is developing the Mars 2020 astrobiology rover and sample cacher for a later return to Earth.\n\nWhen looking for life on other planets like Earth, some simplifying assumptions are useful to reduce the size of the task of the astrobiologist. One is the informed assumption that the vast majority of life forms in our galaxy are based on carbon chemistries, as are all life forms on Earth. Carbon is well known for the unusually wide variety of molecules that can be formed around it. Carbon is the fourth most abundant element in the universe and the energy required to make or break a bond is at just the appropriate level for building molecules which are not only stable, but also reactive. The fact that carbon atoms bond readily to other carbon atoms allows for the building of extremely long and complex molecules.\n\nThe presence of liquid water is an assumed requirement, as it is a common molecule and provides an excellent environment for the formation of complicated carbon-based molecules that could eventually lead to the emergence of life. Some researchers posit environments of ammonia, or more likely, water-ammonia mixtures as possible solvents for hypothetical types of biochemistry.\n\nA third assumption is to focus on planets orbiting Sun-like stars for increased probabilities of planetary habitability. Very large stars have relatively short lifetimes, meaning that life might not have time to emerge on planets orbiting them. Very small stars provide so little heat and warmth that only planets in very close orbits around them would not be frozen solid, and in such close orbits these planets would be tidally \"locked\" to the star. The long lifetimes of red dwarfs could allow the development of habitable environments on planets with thick atmospheres. This is significant, as red dwarfs are extremely common. (See Habitability of red dwarf systems).\n\nSince Earth is the only planet known to harbor life, there is no evident way to know if any of these simplifying assumptions are correct.\n\nResearch on communication with extraterrestrial intelligence (CETI) focuses on composing and deciphering messages that could theoretically be understood by another technological civilization. Communication attempts by humans have included broadcasting mathematical languages, pictorial systems such as the Arecibo message and computational approaches to detecting and deciphering 'natural' language communication. The SETI program, for example, uses both radio telescopes and optical telescopes to search for deliberate signals from an extraterrestrial intelligence.\n\nWhile some high-profile scientists, such as Carl Sagan, have advocated the transmission of messages, scientist Stephen Hawking has warned against it, suggesting that aliens might simply raid Earth for its resources and then move on.\n\nMost astronomy-related astrobiology research falls into the category of extrasolar planet (exoplanet) detection, the hypothesis being that if life arose on Earth, then it could also arise on other planets with similar characteristics. To that end, a number of instruments designed to detect Earth-sized exoplanets have been considered, most notably NASA's Terrestrial Planet Finder (TPF) and ESA's Darwin programs, both of which have been cancelled. NASA launched the Kepler mission in March 2009, and the French Space Agency launched the COROT space mission in 2006. There are also several less ambitious ground-based efforts underway.\n\nThe goal of these missions is not only to detect Earth-sized planets, but also to directly detect light from the planet so that it may be studied spectroscopically. By examining planetary spectra, it would be possible to determine the basic composition of an extrasolar planet's atmosphere and/or surface. Given this knowledge, it may be possible to assess the likelihood of life being found on that planet. A NASA research group, the Virtual Planet Laboratory, is using computer modeling to generate a wide variety of virtual planets to see what they would look like if viewed by TPF or Darwin. It is hoped that once these missions come online, their spectra can be cross-checked with these virtual planetary spectra for features that might indicate the presence of life.\n\nAn estimate for the number of planets with intelligent \"communicative\" extraterrestrial life can be gleaned from the Drake equation, essentially an equation expressing the probability of intelligent life as the product of factors such as the fraction of planets that might be habitable and the fraction of planets on which life might arise:\nwhere:\n\nHowever, whilst the rationale behind the equation is sound, it is unlikely that the equation will be constrained to reasonable limits of error any time soon. The first term, R*, number of stars, is generally constrained within a few orders of magnitude. The second and third terms, \"f\", stars with planets and \"f\", planets with habitable conditions, are being evaluated for the star's neighborhood. The problem with the formula is that it is not usable to generate or support hypotheses because it contains factors that can never be verified. Drake originally formulated the equation merely as an agenda for discussion at the Green Bank conference, but some applications of the formula had been taken literally and related to simplistic or pseudoscientific arguments. Another associated topic is the Fermi paradox, which suggests that if intelligent life is common in the universe, then there should be obvious signs of it.\n\nAnother active research area in astrobiology is planetary system formation. It has been suggested that the peculiarities of the Solar System (for example, the presence of Jupiter as a protective shield) may have greatly increased the probability of intelligent life arising on our planet.\n\nBiology cannot state that a process or phenomenon, by being mathematically possible, has to exist forcibly in an extraterrestrial body. Biologists specify what is speculative and what is not.\n\nUntil the 1970s, life was thought to be entirely dependent on energy from the Sun. Plants on Earth's surface capture energy from sunlight to photosynthesize sugars from carbon dioxide and water, releasing oxygen in the process that is then consumed by oxygen-respiring organisms, passing their energy up the food chain. Even life in the ocean depths, where sunlight cannot reach, was thought to obtain its nourishment either from consuming organic detritus rained down from the surface waters or from eating animals that did. The world's ability to support life was thought to depend on its access to sunlight. However, in 1977, during an exploratory dive to the Galapagos Rift in the deep-sea exploration submersible \"Alvin\", scientists discovered colonies of giant tube worms, clams, crustaceans, mussels, and other assorted creatures clustered around undersea volcanic features known as black smokers. These creatures thrive despite having no access to sunlight, and it was soon discovered that they comprise an entirely independent ecosystem. Although most of these multicellular lifeforms need dissolved oxygen (produced by oxygenic photosynthesis) for their aerobic cellular respiration and thus are not completely independent from sunlight by themselves, the basis for their food chain is a form of bacterium that derives its energy from oxidization of reactive chemicals, such as hydrogen or hydrogen sulfide, that bubble up from the Earth's interior. Other lifeforms entirely decoupled from the energy from sunlight are green sulphur bacteria which are capturing geothermal light for anoxygenic photosynthesis or bacteria running chemolithoautotrophy based on the radioactive decay of uranium. This chemosynthesis revolutionized the study of biology and astrobiology by revealing that life need not be sun-dependent; it only requires water and an energy gradient in order to exist.\n\nExtremophiles, organisms able to survive in extreme environments, are a core research element for astrobiologists. Such organisms include biota which are able to survive several kilometers below the ocean's surface near hydrothermal vents and microbes that thrive in highly acidic environments. It is now known that extremophiles thrive in ice, boiling water, acid, alkali, the water core of nuclear reactors, salt crystals, toxic waste and in a range of other extreme habitats that were previously thought to be inhospitable for life. It opened up a new avenue in astrobiology by massively expanding the number of possible extraterrestrial habitats. Characterization of these organisms, their environments and their evolutionary pathways, is considered a crucial component to understanding how life might evolve elsewhere in the universe. For example, some organisms able to withstand exposure to the vacuum and radiation of outer space include the lichen fungi \"Rhizocarpon geographicum\" and \"Xanthoria elegans\", the bacterium \"Bacillus safensis\", \"Deinococcus radiodurans\", \"Bacillus subtilis\", yeast \"Saccharomyces cerevisiae\", seeds from \"Arabidopsis thaliana\" ('mouse-ear cress'), as well as the invertebrate animal Tardigrade.\n\nJupiter's moon, Europa, and Saturn's moon, Enceladus, are now considered the most likely locations for extant extraterrestrial life in the Solar System due to their subsurface water oceans where radiogenic and tidal heating enables liquid water to exist.\n\nThe origin of life, known as abiogenesis, distinct from the evolution of life, is another ongoing field of research. Oparin and Haldane postulated that the conditions on the early Earth were conducive to the formation of organic compounds from inorganic elements and thus to the formation of many of the chemicals common to all forms of life we see today. The study of this process, known as prebiotic chemistry, has made some progress, but it is still unclear whether or not life could have formed in such a manner on Earth. The alternative hypothesis of panspermia is that the first elements of life may have formed on another planet with even more favorable conditions (or even in interstellar space, asteroids, etc.) and then have been carried over to Earth — the panspermia hypothesis.\n\nThe cosmic dust permeating the universe contains complex organic matter (\"amorphous organic solids with a mixed aromatic-aliphatic structure\") that could be created naturally, and rapidly, by stars. Further, a scientist suggested that these compounds may have been related to the development of life on Earth and said that, \"If this is the case, life on Earth may have had an easier time getting started as these organics can serve as basic ingredients for life.\" In September 2012, NASA scientists reported that polycyclic aromatic hydrocarbons (PAHs), subjected to interstellar medium conditions, are transformed through hydrogenation, oxygenation and hydroxylation, to more complex organics – \"a step along the path toward amino acids and nucleotides, the raw materials of proteins and DNA, respectively\".\n\nMore than 20% of the carbon in the universe may be associated with PAHs, possible starting materials for the formation of life. PAHs seem to have been formed shortly after the Big Bang, are widespread throughout the universe, and are associated with new stars and exoplanets.\n\nAstroecology concerns the interactions of life with space environments and resources, in planets, asteroids and comets. On a larger scale, astroecology concerns resources for life about stars in the galaxy through the cosmological future. Astroecology attempts to quantify future life in space, addressing this area of astrobiology.\n\nExperimental astroecology investigates resources in planetary soils, using actual space materials in meteorites. The results suggest that Martian and carbonaceous chondrite materials can support bacteria, algae and plant (asparagus, potato) cultures, with high soil fertilities. The results support that life could have survived in early aqueous asteroids and on similar materials imported to Earth by dust, comets and meteorites, and that such asteroid materials can be used as soil for future space colonies.\n\nOn the largest scale, cosmoecology concerns life in the universe over cosmological times. The main sources of energy may be red giant stars and white and red dwarf stars, sustaining life for 10 years. Astroecologists suggest that their mathematical models may quantify the potential amounts of future life in space, allowing a comparable expansion in biodiversity, potentially leading to diverse intelligent life forms.\n\nAstrogeology is a planetary science discipline concerned with the geology of the celestial bodies such as the planets and their moons, asteroids, comets, and meteorites. The information gathered by this discipline allows the measure of a planet's or a natural satellite's potential to develop and sustain life, or planetary habitability.\n\nAn additional discipline of astrogeology is geochemistry, which involves study of the chemical composition of the Earth and other planets, chemical processes and reactions that govern the composition of rocks and soils, the cycles of matter and energy and their interaction with the hydrosphere and the atmosphere of the planet. Specializations include cosmochemistry, biochemistry and organic geochemistry.\n\nThe fossil record provides the oldest known evidence for life on Earth. By examining the fossil evidence, paleontologists are able to better understand the types of organisms that arose on the early Earth. Some regions on Earth, such as the Pilbara in Western Australia and the McMurdo Dry Valleys of Antarctica, are also considered to be geological analogs to regions of Mars, and as such, might be able to provide clues on how to search for past life on Mars.\n\nThe various organic functional groups, composed of hydrogen, oxygen, nitrogen, phosphorus, sulfur, and a host of metals, such as iron, magnesium, and zinc, provide the enormous diversity of chemical reactions necessarily catalyzed by a living organism. Silicon, in contrast, interacts with only a few other atoms, and the large silicon molecules are monotonous compared with the combinatorial universe of organic macromolecules. Indeed, it seems likely that the basic building blocks of life anywhere will be similar those on Earth, in the generality if not in the detail. Although terrestrial life and life that might arise independently of Earth are expected to use many similar, if not identical, building blocks, they also are expected to have some biochemical qualities that are unique. If life has had a comparable impact elsewhere in the Solar System, the relative abundances of chemicals key for its survival – whatever they may be – could betray its presence. Whatever extraterrestrial life may be, its tendency to chemically alter its environment might just give it away.\n\nPeople have long speculated about the possibility of life in settings other than Earth, however, speculation on the nature of life elsewhere often has paid little heed to constraints imposed by the nature of biochemistry. The likelihood that life throughout the universe is probably carbon-based is suggested by the fact that carbon is one of the most abundant of the higher elements. Only two of the natural atoms, carbon and silicon, are known to serve as the backbones of molecules sufficiently large to carry biological information. As the structural basis for life, one of carbon's important features is that unlike silicon, it can readily engage in the formation of chemical bonds with many other atoms, thereby allowing for the chemical versatility required to conduct the reactions of biological metabolism and propagation.\n\nThought on where in the Solar System life might occur, was limited historically by the understanding that life relies ultimately on light and warmth from the Sun and, therefore, is restricted to the surfaces of planets. The three most likely candidates for life in the Solar System are the planet Mars, the Jovian moon Europa, and Saturn's moon Titan. More recently, Saturn's moon Enceladus may be considered a likely candidate as well.\n\nMars, Enceladus and Europa are considered likely candidates in the search for life primarily because they may have liquid water, a molecule essential for life as we know it for its use as a solvent in cells. Water on Mars is found in its polar ice caps, and newly carved gullies recently observed on Mars suggest that liquid water may exist, at least transiently, on the planet's surface. At the Martian low temperatures and low pressure, liquid water is likely to be highly saline. As for Europa, liquid water likely exists beneath the moon's icy outer crust. This water may be warmed to a liquid state by volcanic vents on the ocean floor, but the primary source of heat is probably tidal heating. On 11 December 2013, NASA reported the detection of \"clay-like minerals\" (specifically, phyllosilicates), often associated with organic materials, on the icy crust of Europa. The presence of the minerals may have been the result of a collision with an asteroid or comet according to the scientists.\n\nAnother planetary body that could potentially sustain extraterrestrial life is Saturn's largest moon, Titan. Titan has been described as having conditions similar to those of early Earth. On its surface, scientists have discovered the first liquid lakes outside Earth, but they seem to be composed of ethane and/or methane, not water. Some scientists think it possible that these liquid hydrocarbons might take the place of water in living cells different from those on Earth. After Cassini data was studied, it was reported on March 2008 that Titan may also have an underground ocean composed of liquid water and ammonia. Additionally, Saturn's moon Enceladus may have an ocean below its icy surface and, according to NASA scientists in May 2011, \"is emerging as the most habitable spot beyond Earth in the Solar System for life as we know it\".\n\nMeasuring the ratio of hydrogen and methane levels on Mars may help determine the likelihood of life on Mars. According to the scientists, \"...low H/CH ratios (less than approximately 40) indicate that life is likely present and active.\" Other scientists have recently reported methods of detecting hydrogen and methane in extraterrestrial atmospheres.\n\nComplex organic compounds of life, including uracil, cytosine and thymine, have been formed in a laboratory under outer space conditions, using starting chemicals such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe.\n\nThe Rare Earth hypothesis postulates that multicellular life forms found on Earth may actually be more of a rarity than scientists assume. It provides a possible answer to the Fermi paradox which suggests, \"If extraterrestrial aliens are common, why aren't they obvious?\" It is apparently in opposition to the principle of mediocrity, assumed by famed astronomers Frank Drake, Carl Sagan, and others. The Principle of Mediocrity suggests that life on Earth is not exceptional, but rather that life is more than likely to be found on innumerable other worlds.\n\nThe anthropic principle states that fundamental laws of the universe work specifically in a way that life would be possible. The anthropic principle supports the Rare Earth Hypothesis by arguing the overall elements that are needed to support life on Earth are so fine-tuned that it is nearly impossible for another just like it to exist by random chance.\n\nThe systematic search for possible life outside Earth is a valid multidisciplinary scientific endeavor. However, hypotheses and predictions as to its existence and origin vary widely, and at the present, the development of hypotheses firmly grounded on science may be considered astrobiology's most concrete practical application. It has been proposed that viruses are likely to be encountered on other life-bearing planets.\n\n, no evidence of extraterrestrial life has been identified. Examination of the Allan Hills 84001 meteorite, which was recovered in Antarctica in 1984 and originated from Mars, is thought by David McKay, as well as few other scientists, to contain microfossils of extraterrestrial origin; this interpretation is controversial.\n\nYamato 000593 is the second largest meteorite from Mars, and was found on Earth in 2000. At a microscopic level, spheres are found in the meteorite that are rich in carbon compared to surrounding areas that lack such spheres. The carbon-rich spheres may have been formed by biotic activity according to some NASA scientists.\n\nOn 5 March 2011, Richard B. Hoover, a scientist with the Marshall Space Flight Center, speculated on the finding of alleged microfossils similar to cyanobacteria in CI1 carbonaceous meteorites in the fringe \"Journal of Cosmology\", a story widely reported on by mainstream media. However, NASA formally distanced itself from Hoover's claim. According to American astrophysicist Neil deGrasse Tyson: \"At the moment, life on Earth is the only known life in the universe, but there are compelling arguments to suggest we are not alone.\"\n\n\nOn 17 March 2013, researchers reported that microbial life forms thrive in the Mariana Trench, the deepest spot on the Earth. Other researchers reported related studies that microbes thrive inside rocks up to 1900 feet below the sea floor under 8500 feet of ocean off the coast of the northwestern United States. According to one of the researchers, \"You can find microbes everywhere — they're extremely adaptable to conditions, and survive wherever they are.\" These finds expand the potential habitability of certain niches of other planets.\n\nIn 2004, the spectral signature of methane () was detected in the Martian atmosphere by both Earth-based telescopes as well as by the Mars Express orbiter. Because of solar radiation and cosmic radiation, methane is predicted to disappear from the Martian atmosphere within several years, so the gas must be actively replenished in order to maintain the present concentration. The \"Curiosity\" rover will perform precision measurements of oxygen and carbon isotope ratios in carbon dioxide (CO) and methane (CH) in the atmosphere of Mars in order to distinguish between a geochemical and a biological origin.\n\nIt is possible that some exoplanets may have moons with solid surfaces or liquid oceans that are hospitable. Most of the planets so far discovered outside the Solar System are hot gas giants thought to be inhospitable to life, so it is not yet known whether the Solar System, with a warm, rocky, metal-rich inner planet such as Earth, is of an aberrant composition. Improved detection methods and increased observing time will undoubtedly discover more planetary systems, and possibly some more like ours. For example, NASA's Kepler Mission seeks to discover Earth-sized planets around other stars by measuring minute changes in the star's light curve as the planet passes between the star and the spacecraft. Progress in infrared astronomy and submillimeter astronomy has revealed the constituents of other star systems.\n\n\nEfforts to answer questions such as the abundance of potentially habitable planets in habitable zones and chemical precursors have had much success. Numerous extrasolar planets have been detected using the wobble method and transit method, showing that planets around other stars are more numerous than previously postulated. The first Earth-sized extrasolar planet to be discovered within its star's habitable zone is Gliese 581 c.\n\nResearch into the environmental limits of life and the workings of extreme ecosystems is ongoing, enabling researchers to better predict what planetary environments might be most likely to harbor life. Missions such as the Phoenix lander, Mars Science Laboratory, ExoMars, Mars 2020 rover to Mars, and the \"Cassini\" probe to Saturn's moons aim to further explore the possibilities of life on other planets in the Solar System.\n\nThe two Viking landers each carried four types of biological experiments to the surface of Mars in the late 1970s. These were the only Mars landers to carry out experiments to look specifically for metabolism by current microbial life on Mars. The landers used a robotic arm to collect soil samples into sealed test containers on the craft. The two landers were identical, so the same tests were carried out at two places on Mars' surface; Viking 1 near the equator and Viking 2 further north. The result was inconclusive, and is still disputed by some scientists.\n\n\"Beagle 2\" was an unsuccessful British Mars lander that formed part of the European Space Agency's 2003 Mars Express mission. Its primary purpose was to search for signs of life on Mars, past or present. Although it landed safely, it was unable to correctly deploy its solar panels and telecom antenna.\n\nEXPOSE is a multi-user facility mounted in 2008 outside the International Space Station dedicated to astrobiology. EXPOSE was developed by the European Space Agency (ESA) for long-term spaceflights that allows to expose organic chemicals and biological samples to outer space in low Earth orbit.\n\nThe Mars Science Laboratory (MSL) mission landed a rover that is currently in operation on Mars. It was launched 26 November 2011, and landed at Gale Crater on 6 August 2012. Mission objectives are to help assess Mars' habitability and in doing so, determine whether Mars is or has ever been able to support life, collect data for a future human mission, study Martian geology, its climate, and further assess the role that water, an essential ingredient for life as we know it, played in forming minerals on Mars.\n\nExoMars is a robotic mission to Mars to search for possible biosignatures of Martian life, past or present. This astrobiological mission is currently under development by the European Space Agency (ESA) in partnership with the Russian Federal Space Agency (Roscosmos); it is planned for a 2018 launch.\n\nRed Dragon is a planned series low-cost Mars lander missions that will utilize the SpaceX Falcon Heavy launch vehicle, and a modified Dragon V2 capsule to enter the Martian atmosphere and land using retrorockets. The lander's primary mission would be a technology demonstration, and to search for evidence of life on Mars (biosignatures), past or present. The concept had been meant to compete for funding on 2012/2013 as a NASA Discovery mission. On April 2016, SpaceX announced that they will proceed with the mission, with technical support from NASA, to be launched with a Falcon Heavy rocket in 2018. These Mars missions will also be pathfinders for the much larger SpaceX Mars colonization architecture that will be announced in September 2016.\n\nThe 'Mars 2020' rover mission is a concept under development by NASA with a possible launch in 2020. It is intended to investigate environments on Mars relevant to astrobiology, investigate its surface geological processes and history, including the assessment of its past habitability and potential for preservation of biosignatures and biomolecules within accessible geological materials. The Science Definition Team is proposing the rover collect and package at least 31 samples of rock cores and soil for a later mission to bring back for more definitive analysis in laboratories on Earth. The rover could make measurements and technology demonstrations to help designers of a human expedition understand any hazards posed by Martian dust and demonstrate how to collect carbon dioxide (CO), which could be a resource for making molecular oxygen (O) and rocket fuel.\n\n\"Icebreaker Life\" is a lander mission that is being proposed for NASA's Discovery Program for the 2018 launch opportunity. If selected and funded, the stationary lander would be a near copy of the successful 2008 \"Phoenix\" and it would carry an upgraded astrobiology scientific payload, including a 1-meter-long core drill to sample ice-cemented ground in the northern plains to conduct a search for organic molecules and evidence of current or past life on Mars. One of the key goals of the \"Icebreaker Life\" mission is to test the hypothesis that the ice-rich ground in the polar regions has significant concentrations of organics due to protection by the ice from oxidants and radiation.\n\nJourney to Enceladus and Titan (JET) is an orbiter astrobiology mission concept to assess the habitability potential of Saturn's moons Enceladus and Titan.\n\nEnceladus Life Finder (ELF) is a proposed astrobiology mission concept for a space probe intended to assess the habitability of the internal aquatic ocean of Enceladus, Saturn's sixth-largest moon.\n\nLife Investigation For Enceladus (LIFE) is a proposed astrobiology sample-return mission concept for Enceladus. The spacecraft would enter into Saturn orbit and enable multiple flybys through Enceladus' icy plumes to collect icy plume particles and volatiles and return them to Earth on a capsule. The spacecraft may sample Enceladus' plumes, the E ring of Saturn, and the Titan upper atmosphere.\n\nEuropa Clipper is a mission planned by NASA for a 2025 launch that will conduct detailed reconnaissance of Jupiter's moon Europa and will investigate whether the icy moon could harbor conditions suitable for life. It will also aid in the selection of future landing sites.\n\n\n\n", "id": "2787", "title": "Astrobiology"}
{"url": "https://en.wikipedia.org/wiki?curid=2790", "text": "Air show\n\nAn air show, (also airshow, air fair, or air tattoo) is a public event at which aviators display their flying skills and the capabilities of their aircraft to spectators, usually by means of aerobatics. Air shows without aerobatic displays, having only aircraft displayed parked on the ground, are called \"static air shows\".\n\nIn the United States, some of the larger airshows are headlined by military jet demonstration teams including the U.S. Navy Blue Angels and USAF Thunderbirds. The Canadian Forces Snowbirds will headline many airshows in Canada and the United States.\n\nSome air shows are held as a business venture or as a trade event where aircraft, avionics and other services are promoted to potential customers. Many air shows are held in support of local, national or military charities. Military air firms often organise air shows at military airfields as a public relations exercise to thank the local community, promote military careers and raise the profile of the military.\n\nAir show \"seasons\" vary around the world. The United States enjoys a long season that generally runs from March to November, covering the spring, summer, and fall seasons. Other countries often have much shorter seasons. In Japan air shows are generally events held at Japan Self-Defense Forces bases regularly throughout the year. The European season usually starts in late April or Early May and is usually over by mid October. The Middle East, Australia and New Zealand hold their events between January and March. However, for many acts, the \"off-season\" does not mean a period of inactivity; pilots and performers use this time for maintenance and practice.\n\nThe type of displays seen at an event are constrained by a number of factors, including the weather and visibility. Most aviation authorities now publish rules and guidance on minimum display heights and criteria for differing conditions. In addition to the weather, pilots and organizers must also consider local airspace restrictions. Most exhibitors will plan \"full,\" \"rolling\" and \"flat\" display for varying weather and airspace conditions.\n\nThe types of shows vary greatly. Some are large scale military events with large flying displays and ground exhibitions while others held at small local airstrips can often feature just one or two hours of flying with just a few stalls on the ground. Air Displays can be held during day or night with the latter becoming increasingly popular. Shows don't always take place over airfields; some have been held over the grounds of stately homes or castles and over the sea at coastal resorts.\n\nBefore the Second World War, air shows were associated with long distance air races, often lasting many days and covering thousands of miles. While the Reno Air Races keep this tradition alive, most air shows today primarily feature a series of aerial demos of short duration.\n\nMost air shows feature warbirds, aerobatics, and demonstrations of modern military aircraft, and many air shows offer a variety of other aeronautical attractions as well, such as wing-walking, radio-controlled aircraft, water/slurry drops from firefighting aircraft, simulated helicopter rescues and sky diving.\n\nSpecialist aerobatic aircraft have powerful piston engines, light weight and big control surfaces, making them capable of very high roll rates and accelerations. A skilled pilot will be able to climb vertically, perform very tight turns, tumble his aircraft end-over-end and perform manoeuvres during loops.\n\nSolo military jet demos, also known as tactical demo, feature one aircraft, usually a strike fighter or an advanced trainer. The demonstration focuses on the capabilities of modern aircraft used in combat operations. The display will usually demonstrate the aircraft's very short (and often very loud) takeoff rolls, fast speeds, slow approach speeds, as well as their ability to quickly make tight turns, to climb quickly, and their ability to be precisely controlled at a large range of speeds. Manoeuvres include aileron rolls, barrel rolls, hesitation rolls, Cuban-8s, tight turns, high-alpha flight, a high-speed pass, double Immelmans, and touch-and-gos. Tactical demos may include simulated bomb drops, sometimes with pyrotechnics on the ground for effect. Aircraft with special characteristics that give them unique capabilities will often display those in their demos; For example, Russian fighters with Thrust vectoring may be used to perform Pugachev's Cobra or the Kulbit, among other difficult manoeuvers that cannot be performed by other aircraft. Similarly, an F-22 pilot may hover his jet in the air with the nose pointed straight up, a Harrier or Osprey pilot may perform a vertical landing or vertical takeoff, and so on.\n\nAir shows may present some risk to spectators and aviators. Accidents have occurred, sometimes with a large loss of life, such as the 1988 disaster at Ramstein Air Base in Germany and the 2002 air show crash at Lviv, Ukraine. Because of these accidents, the various aviation authorities around the world have created set rules and guidance for those running and participating in air displays. Air displays are often monitored by aviation authorities to ensure safe procedures.\n\nIn the United Kingdom, local authorities will first need to approve any application for an event to which the public is admitted. No approval, no event. The first priority must be to arrange insurance cover and details can be obtained from your local authority. An added complication is a whole new raft of legislation concerning Health & Safety in particular Corporate Manslaughter, which can involve the event organiser being charged with a criminal offence if any of the insurances and risk assessments are not fully completed well in advance of the event. If this very basic step isn't completed then any further activity should be halted until it is.\n\nRules govern the distance from the crowds that aircraft must fly. These vary according to the rating of the pilot/crew, the type of aircraft and the way the aircraft is being flown. For instance, slower lighter aircraft are usually allowed closer and lower to the crowd than larger, faster types. Also, a fighter jet flying straight and level will be able to do so closer to the crowd and lower than if it were performing a roll or a loop.\n\nPilots can get authorizations for differing types of displays (i.e. limbo flying, basic aerobatics to unlimited aerobatics) and to differing minimum base heights above the ground. To gain such authorizations, the pilots will have to demonstrate to an examiner that they can perform to those limits without endangering themselves, ground crew or spectators.\n\nDespite display rules and guidances, accidents have continued to happen. However, air show accidents are rare and where there is proper supervision air shows have impressive safety records. Each year, organizations such as International Council of Air Shows and European Airshow Council meet and discuss various subjects including air show safety where accidents are discussed and lessons learned.\n\n\n", "id": "2790", "title": "Air show"}
{"url": "https://en.wikipedia.org/wiki?curid=2792", "text": "Anthropic principle\n\nThe anthropic principle is a philosophical consideration that observations of the Universe must be compatible with the conscious and sapient life that observes it. Some proponents of the anthropic principle reason that it explains why this universe has the age and the fundamental physical constants necessary to accommodate conscious life. As a result, they believe it is unremarkable that this universe has fundamental constants that happen to fall within the narrow range thought to be compatible with life.\nThe strong anthropic principle (SAP) as explained by John D. Barrow and Frank Tipler states that this is all the case because the universe is in some sense compelled to eventually have conscious and sapient life emerge within it. Some critics of the SAP argue in favor of a weak anthropic principle (WAP) similar to the one defined by Brandon Carter, which states that the universe's ostensible fine tuning is the result of selection bias: i.e., only in a universe capable of eventually supporting life will there be living beings capable of observing and reflecting upon fine tuning. Most often such arguments draw upon some notion of the multiverse for there to be a statistical population of universes to select from and from which selection bias (our observance of \"only\" this universe, compatible with \"our\" life) could occur.\n\nThe principle was formulated as a response to a series of observations that the laws of nature and parameters of the universe take on values that are consistent with conditions for life as we know it rather than a set of values that would not be consistent with life on Earth. The anthropic principle states that this is a necessity, because if life were impossible, no living entity would be there to observe it, and thus would not be known. That is, it must be possible to observe \"some\" universe, and hence, the laws and constants of any such universe must accommodate that possibility.\n\nThe term \"anthropic\" in \"anthropic principle\" has been argued to be a misnomer. While singling out our kind of carbon-based life, none of the finely tuned phenomena require human life or some kind of carbon chauvinism. Any form of life or any form of heavy atom, stone, star or galaxy would do; nothing specifically human or anthropic is involved.\n\nThe anthropic principle has given rise to some confusion and controversy, partly because the phrase has been applied to several distinct ideas. All versions of the principle have been accused of discouraging the search for a deeper physical understanding of the universe. The anthropic principle is often criticized for lacking falsifiability and therefore critics of the anthropic principle may point out that the anthropic principle is a non-scientific concept, even though the weak anthropic principle, \"conditions that are observed in the universe must allow the observer to exist\", is \"easy\" to support in mathematics and philosophy, i.e. it is a tautology or truism. However, building a substantive argument based on a tautological foundation is problematic. Stronger variants of the anthropic principle are not tautologies and thus make claims considered controversial by some and that are contingent upon empirical verification.\n\nIn 1961, Robert Dicke noted that the age of the universe, as seen by living observers, cannot be random. Instead, biological factors constrain the universe to be more or less in a \"golden age\", neither too young nor too old. If the universe were one tenth as old as its present age, there would not have been sufficient time to build up appreciable levels of\nmetallicity (levels of elements besides hydrogen and helium) especially carbon, by nucleosynthesis. Small rocky planets did not yet exist. If the universe were 10 times older than it actually is, most stars would be too old to remain on the main sequence and would have turned into white dwarfs, aside from the dimmest red dwarfs, and stable planetary systems would have already come to an end. Thus, Dicke explained the coincidence between large dimensionless numbers constructed from the constants of physics and the age of the universe, a coincidence which had inspired Dirac's varying-G theory.\n\nDicke later reasoned that the density of matter in the universe must be almost exactly the critical density needed to prevent the Big Crunch (the \"Dicke coincidences\" argument). The most recent measurements may suggest that the observed density of baryonic matter, and some theoretical predictions of the amount of dark matter account for about 30% of this critical density, with the rest contributed by a cosmological constant. Steven Weinberg gave an anthropic explanation for this fact: he noted that the cosmological constant has a remarkably low value, some 120 orders of magnitude smaller than the value particle physics predicts (this has been described as the \"worst prediction in physics\"). However, if the cosmological constant were only one order of magnitude larger than its observed value, the universe would suffer catastrophic inflation, which would preclude the formation of stars, and hence life.\n\nThe observed values of the dimensionless physical constants (such as the fine-structure constant) governing the four fundamental interactions are balanced as if fine-tuned to permit the formation of commonly found matter and subsequently the emergence of life. A slight increase in the strong interaction would bind the dineutron and the diproton, and nuclear fusion would have converted all hydrogen in the early universe to helium. Water, as well as sufficiently long-lived stable stars, both essential for the emergence of life as we know it, would not exist. More generally, small changes in the relative strengths of the four fundamental interactions can greatly affect the universe's age, structure, and capacity for life.\n\nThe phrase \"anthropic principle\" first appeared in Brandon Carter's contribution to a 1973 Kraków symposium honouring Copernicus's 500th birthday. Carter, a theoretical astrophysicist, articulated the Anthropic Principle in reaction to the Copernican Principle, which states that humans do not occupy a privileged position in the Universe. As Carter said: \"Although our situation is not necessarily \"central\", it is inevitably privileged to some extent.\" Specifically, Carter disagreed with using the Copernican principle to justify the Perfect Cosmological Principle, which states that all large regions \"and times\" in the universe must be statistically identical. The latter principle underlay the steady-state theory, which had recently been falsified by the 1965 discovery of the cosmic microwave background radiation. This discovery was unequivocal evidence that the universe has changed radically over time (for example, via the Big Bang).\n\nCarter defined two forms of the anthropic principle, a \"weak\" one which referred only to anthropic selection of privileged spacetime locations in the universe, and a more controversial \"strong\" form which addressed the values of the fundamental constants of physics.\n\nRoger Penrose explained the weak form as follows:\n\nOne reason this is plausible is that there are many other places and times in which we can imagine finding ourselves. But when applying the strong principle, we only have one universe, with one set of fundamental parameters, so what exactly is the point being made? Carter offers two possibilities: First, we can use our own existence to make \"predictions\" about the parameters. But second, \"as a last resort\", we can convert these predictions into \"explanations\" by assuming that there \"is\" more than one universe, in fact a large and possibly infinite collection of universes, something that is now called the multiverse (\"world ensemble\" was Carter's term), in which the parameters (and perhaps the laws of physics) vary across universes. The strong principle then becomes an example of a selection effect, exactly analogous to the weak principle. Postulating a multiverse is certainly a radical step, but taking it could provide at least a partial answer to a question which had seemed to be out of the reach of normal science: \"why do the fundamental laws of physics take the particular form we observe and not another?\"\n\nSince Carter's 1973 paper, the term \"anthropic principle\" has been extended to cover a number of ideas which differ in important ways from those he espoused. Particular confusion was caused in 1986 by the book \"The Anthropic Cosmological Principle\" by John D. Barrow and Frank Tipler, published that year which distinguished between \"weak\" and \"strong\" anthropic principle in a way very different from Carter's, as discussed in the next section.\n\nCarter was not the first to invoke some form of the anthropic principle. In fact, the evolutionary biologist Alfred Russel Wallace anticipated the anthropic principle as long ago as 1904: \"Such a vast and complex universe as that which we know exists around us, may have been absolutely required [...] in order to produce a world that should be precisely adapted in every detail for the orderly development of life culminating in man.\" In 1957, Robert Dicke wrote: \"The age of the Universe 'now' is not random but conditioned by biological factors [...] [changes in the values of the fundamental constants of physics] would preclude the existence of man to consider the problem.\"\n\nWeak anthropic principle (WAP) (Carter): \"[W]e must be prepared to take account of the fact that our location in the universe is \"necessarily\" privileged to the extent of being compatible with our existence as observers.\" Note that for Carter, \"location\" refers to our location in time as well as space.\n\nStrong anthropic principle (SAP) (Carter): \"[T]he universe (and hence the fundamental parameters on which it depends) must be such as to admit the creation of observers within it at some stage. To paraphrase Descartes, \"cogito ergo mundus talis est\".\"<br>The Latin tag (\"I think, therefore the world is such [as it is]\") makes it clear that \"must\" indicates a deduction from the fact of our existence; the statement is thus a truism.\n\nIn their 1986 book, \"The Anthropic Cosmological Principle\", John Barrow and Frank Tipler depart from Carter and define the WAP and SAP as follows:\n\nWeak anthropic principle (WAP) (Barrow and Tipler): \"The observed values of all physical and cosmological quantities are not equally probable but they take on values restricted by the requirement that there exist sites where carbon-based life can evolve and by the requirements that the universe be old enough for it to have already done so.\"<br>Unlike Carter they restrict the principle to carbon-based life, rather than just \"observers\". A more important difference is that they apply the WAP to the fundamental physical constants, such as the fine structure constant, the number of spacetime dimensions, and the cosmological constant—topics that fall under Carter's SAP.\n\nStrong anthropic principle (SAP) (Barrow and Tipler): \"The Universe must have those properties which allow life to develop within it at some stage in its history.\"<br>This looks very similar to Carter's SAP, but unlike the case with Carter's SAP, the \"must\" is an imperative, as shown by the following three possible elaborations of the SAP, each proposed by Barrow and Tipler:\n\nModified anthropic principle (MAP) (Schmidhuber): The 'problem' of existence is only relevant to a species capable of formulating the question. Prior to \"Homo sapiens\" intellectual evolution to the point where the nature of the observed universe—and humans' place within same—spawned deep inquiry into its origins, the 'problem' simply did not exist.\n\nThe philosophers John Leslie and Nick Bostrom reject the Barrow and Tipler SAP as a fundamental misreading of Carter. For Bostrom, Carter's anthropic principle just warns us to make allowance for \"anthropic bias\"—that is, the bias created by anthropic selection effects (which Bostrom calls \"observation\" selection effects)—the necessity for observers to exist in order to get a result. He writes:\n\nStrong self-sampling assumption (SSSA) (Bostrom): \"Each observer-moment should reason as if it were randomly selected from the class of all observer-moments in its reference class.\"<br> Analysing an observer's experience into a sequence of \"observer-moments\" helps avoid certain paradoxes; but the main ambiguity is the selection of the appropriate \"reference class\": for Carter's WAP this might correspond to all real or potential observer-moments in our universe; for the SAP, to all in the multiverse. Bostrom's mathematical development shows that choosing either too broad or too narrow a reference class leads to counter-intuitive results, but he is not able to prescribe an ideal choice.\n\nAccording to Jürgen Schmidhuber, the anthropic principle essentially just says that the conditional probability of finding yourself in a universe compatible with your existence is always 1. It does not allow for any additional nontrivial predictions such as \"gravity won't change tomorrow\". To gain more predictive power, additional assumptions on the prior distribution of alternative universes are necessary.\n\nPlaywright and novelist Michael Frayn describes a form of the Strong Anthropic Principle in his 2006 book \"The Human Touch\", which explores what he characterises as \"the central oddity of the Universe\":\n\nCarter chose to focus on a tautological aspect of his ideas, which has resulted in much confusion. In fact, anthropic reasoning interests scientists because of something that is only implicit in the above formal definitions, namely that we should give serious consideration to there being other universes with different values of the \"fundamental parameters\"—that is, the dimensionless physical constants and initial conditions for the Big Bang. Carter and others have argued that life as we know it would not be possible in most such universes. In other words, the universe we are in is fine tuned to permit life. Collins & Hawking (1973) characterized Carter's then-unpublished big idea as the postulate that \"there is not one universe but a whole infinite ensemble of universes with all possible initial conditions\". If this is granted, the anthropic principle provides a plausible explanation for the fine tuning of our universe: the \"typical\" universe is not fine-tuned, but given enough universes, a small fraction thereof will be capable of supporting intelligent life. Ours must be one of these, and so the observed fine tuning should be no cause for wonder.\n\nAlthough philosophers have discussed related concepts for centuries, in the early 1970s the only genuine physical theory yielding a multiverse of sorts was the many-worlds interpretation of quantum mechanics. This would allow variation in initial conditions, but not in the truly fundamental constants. Since that time a number of mechanisms for producing a multiverse have been suggested: see the review by Max Tegmark. An important development in the 1980s was the combination of inflation theory with the hypothesis that some parameters are determined by symmetry breaking in the early universe, which allows parameters previously thought of as \"fundamental constants\" to vary over very large distances, thus eroding the distinction between Carter's weak and strong principles. At the beginning of the 21st century, the string landscape emerged as a mechanism for varying essentially all the constants, including the number of spatial dimensions.\n\nThe anthropic idea that fundamental parameters are selected from a multitude of different possibilities (each actual in some universe or other) contrasts with the traditional hope of physicists for a theory of everything having no free parameters. As Einstein said: \"What really interests me is whether God had any choice in the creation of the world.\" In 2002, proponents of the leading candidate for a \"theory of everything\", string theory, proclaimed \"the end of the anthropic principle\" since there would be no free parameters to select. Ironically, string theory now seems to offer no hope of predicting fundamental parameters, and now some who advocate it invoke the anthropic principle as well (see below).\n\nThe modern form of a design argument is put forth by intelligent design. Proponents of intelligent design often cite the fine-tuning observations that (in part) preceded the formulation of the anthropic principle by Carter as a proof of an intelligent designer. Opponents of intelligent design are not limited to those who hypothesize that other universes exist; they may also argue, anti-anthropically, that the universe is less fine-tuned than often claimed, or that accepting fine tuning as a brute fact is less astonishing than the idea of an intelligent creator. Furthermore, even accepting fine tuning, Sober (2005) and Ikeda and Jefferys, argue that the Anthropic Principle as conventionally stated actually undermines intelligent design; see fine-tuned universe.\n\nPaul Davies's book \"The Goldilocks Enigma\" (2006) reviews the current state of the fine tuning debate in detail, and concludes by enumerating the following responses to that debate:\n\nOmitted here is Lee Smolin's model of cosmological natural selection, also known as \"fecund universes\", which proposes that universes have \"offspring\" which are more plentiful if they resemble our universe. Also see Gardner (2005).\n\nClearly each of these hypotheses resolve some aspects of the puzzle, while leaving others unanswered. Followers of Carter would admit only option 3 as an anthropic explanation, whereas 3 through 6 are covered by different versions of Barrow and Tipler's SAP (which would also include 7 if it is considered a variant of 4, as in Tipler 1994).\n\nThe anthropic principle, at least as Carter conceived it, can be applied on scales much smaller than the whole universe. For example, Carter (1983) inverted the usual line of reasoning and pointed out that when interpreting the evolutionary record, one must take into account cosmological and astrophysical considerations. With this in mind, Carter concluded that given the best estimates of the age of the universe, the evolutionary chain culminating in \"Homo sapiens\" probably admits only one or two low probability links. Antonio Feoli and Salvatore Rampone dispute this conclusion, arguing instead that the estimated size of our universe and the number of planets in it allows for a higher bound, so that there is no need to invoke intelligent design to explain evolution.\n\nNo possible observational evidence bears on Carter's WAP, as it is merely advice to the scientist and asserts nothing debatable. The obvious test of Barrow's SAP, which says that the universe is \"required\" to support life, is to find evidence of life in universes other than ours. Any other universe is, by most definitions, unobservable (otherwise it would be included in \"our\" portion of \"this\" universe). Thus, in principle Barrow's SAP cannot be falsified by observing a universe in which an observer cannot exist.\n\nPhilosopher John Leslie states that the Carter SAP (with multiverse) predicts the following:\n\nHogan has emphasised that it would be very strange if all fundamental constants were strictly determined, since this would leave us with no ready explanation for apparent fine tuning. In fact we might have to resort to something akin to Barrow and Tipler's SAP: there would be no option for such a universe \"not\" to support life.\n\nProbabilistic predictions of parameter values can be made given:\nThe probability of observing value \"X\" is then proportional to \"N\"(\"X\") \"P\"(\"X\"). A generic feature of an analysis of this nature is that the expected values of the fundamental physical constants should not be \"over-tuned\", i.e. if there is some perfectly tuned predicted value (e.g. zero), the observed value need be no closer to that predicted value than what is required to make life possible. The small but finite value of the cosmological constant can be regarded as a successful prediction in this sense.\n\nOne thing that would \"not\" count as evidence for the Anthropic Principle is evidence that the Earth or the solar system occupied a privileged position in the universe, in violation of the Copernican principle (for possible counterevidence to this principle, see Copernican principle), unless there was some reason to think that that position was a necessary condition for our existence as observers.\n\nFred Hoyle may have invoked anthropic reasoning to predict an astrophysical phenomenon. He is said to have reasoned from the prevalence on Earth of life forms whose chemistry was based on carbon-12 atoms, that there must be an undiscovered resonance in the carbon-12 nucleus facilitating its synthesis in stellar interiors via the triple-alpha process. He then calculated the energy of this undiscovered resonance to be 7.6 million electronvolts. Willie Fowler's research group soon found this resonance, and its measured energy was close to Hoyle's prediction.\n\nHowever, a recently released paper argues that Hoyle did not use anthropic reasoning to make this prediction.\n\nDon Page criticized the entire theory of cosmic inflation as follows. He emphasized that initial conditions which made possible a thermodynamic arrow of time in a universe with a Big Bang origin, must include the assumption that at the initial singularity, the entropy of the universe was low and therefore extremely improbable. Paul Davies rebutted this criticism by invoking an inflationary version of the anthropic principle. While Davies accepted the premise that the initial state of the visible universe (which filled a microscopic amount of space before inflating) had to possess a very low entropy value—due to random quantum fluctuations—to account for the observed thermodynamic arrow of time, he deemed this fact an advantage for the theory. That the tiny patch of space from which our observable universe grew had to be extremely orderly, to allow the post-inflation universe to have an arrow of time, makes it unnecessary to adopt any \"ad hoc\" hypotheses about the initial entropy state, hypotheses other Big Bang theories require.\n\nString theory predicts a large number of possible universes, called the \"backgrounds\" or \"vacua\". The set of these vacua is often called the \"multiverse\" or \"anthropic landscape\" or \"string landscape\". Leonard Susskind has argued that the existence of a large number of vacua puts anthropic reasoning on firm ground: only universes whose properties are such as to allow observers to exist are observed, while a possibly much larger set of universes lacking such properties go unnoticed.\n\nSteven Weinberg believes the Anthropic Principle may be appropriated by cosmologists committed to nontheism, and refers to that Principle as a \"turning point\" in modern science because applying it to the string landscape \" [...] may explain how the constants of nature that we observe can take values suitable for life without being fine-tuned by a benevolent creator\". Others—most notably David Gross but also Lubos Motl, Peter Woit, and Lee Smolin—argue that this is not predictive. Max Tegmark, Mario Livio, and Martin Rees argue that only some aspects of a physical theory need be observable and/or testable for the theory to be accepted, and that many well-accepted theories are far from completely testable at present.\n\nJürgen Schmidhuber (2000–2002) points out that Ray Solomonoff's theory of universal inductive inference and its extensions already provide a framework for maximizing our confidence in any theory, given a limited sequence of physical observations, and some prior distribution on the set of possible explanations of the universe.\n\nThere are two kinds of dimensions, spatial (bidirectional) and temporal (unidirectional). Let the number of spatial dimensions be \"N\" and the number of temporal dimensions be \"T\". That \"N\" = 3 and \"T\" = 1, setting aside the compactified dimensions invoked by string theory and undetectable to date, can be explained by appealing to the physical consequences of letting \"N\" differ from 3 and \"T\" differ from 1. The argument is often of an anthropic character and possibly the first of its kind, albeit before the complete concept came into vogue. Immanuel Kant argued that 3-dimensional space was a consequence of the inverse square law of universal gravitation. While Kant's argument is historically important, John D. Barrow says that it \"[...] gets the punch-line back to front: it is the three-dimensionality of space that explains why we see inverse-square force laws in Nature, not vice-versa\" (Barrow 2002: 204). This is because the law of gravitation (or any other inverse-square law) follows from the concept of flux and the proportional relationship of flux density and the strength of field. If \"N\" = 3, then 3-dimensional solid objects have surface areas proportional to the square of their size in any selected spatial dimension. In particular, a sphere of radius \"r\" has area of 4π\"r\" ². More generally, in a space of \"N\" dimensions, the strength of the gravitational attraction between two bodies separated by a distance of \"r\" would be inversely proportional to \"r\".\n\nIn 1920, Paul Ehrenfest showed that if there is only one time dimension and greater than three spatial dimensions, the orbit of a planet about its Sun cannot remain stable. The same is true of a star's orbit around the center of its galaxy. Ehrenfest also showed that if there are an even number of spatial dimensions, then the different parts of a wave impulse will travel at different speeds. If there are formula_1 spatial dimensions, where \"k\" is a whole number, then wave impulses become distorted. In 1922, Hermann Weyl showed that Maxwell's theory of electromagnetism works only with three dimensions of space and one of time. Finally, Tangherlini showed in 1963 that when there are more than three spatial dimensions, electron orbitals around nuclei cannot be stable; electrons would either fall into the nucleus or disperse.\n\nMax Tegmark expands on the preceding argument in the following anthropic manner. If \"T\" differs from 1, the behavior of physical systems could not be predicted reliably from knowledge of the relevant partial differential equations. In such a universe, intelligent life capable of manipulating technology could not emerge. Moreover, if \"T\" > 1, Tegmark maintains that protons and electrons would be unstable and could decay into particles having greater mass than themselves. (This is not a problem if the particles have a sufficiently low temperature.)\n\nSome of the metaphysical disputes and speculations include, for example, attempts to back Teilhard de Chardin's earlier interpretation of the universe as being christ centered (compare Omega Point), expressing a \"creatio evolutiva\" instead the elder notion of \"creatio continua\". From a strictly secular, humanist perspective, it allows as well to put human beings back in the center, an anthropogenic shift in cosmology. Karl W. Giberson has been sort of laconic in stating that\n\nA thorough extant study of the anthropic principle is the book \"The Anthropic Cosmological Principle\" by John D. Barrow, a cosmologist, and Frank J. Tipler, a cosmologist and mathematical physicist. This book sets out in detail the many known anthropic coincidences and constraints, including many found by its authors. While the book is primarily a work of theoretical astrophysics, it also touches on quantum physics, chemistry, and earth science. An entire chapter argues that \"Homo sapiens\" is, with high probability, the only intelligent species in the Milky Way.\n\nThe book begins with an extensive review of many topics in the history of ideas the authors deem relevant to the anthropic principle, because the authors believe that principle has important antecedents in the notions of teleology and intelligent design. They discuss the writings of Fichte, Hegel, Bergson, and Alfred North Whitehead, and the Omega Point cosmology of Teilhard de Chardin. Barrow and Tipler carefully distinguish teleological reasoning from \"eutaxiological\" reasoning; the former asserts that order must have a consequent purpose; the latter asserts more modestly that order must have a planned cause. They attribute this important but nearly always overlooked distinction to an obscure 1883 book by L. E. Hicks.\n\nSeeing little sense in a principle requiring intelligent life to emerge while remaining indifferent to the possibility of its eventual extinction, Barrow and Tipler propose the final anthropic principle (FAP): Intelligent information-processing must come into existence in the universe, and, once it comes into existence, it will never die out.\n\nBarrow and Tipler submit that the FAP is both a valid physical statement and \"closely connected with moral values\". FAP places strong constraints on the structure of the universe, constraints developed further in Tipler's \"The Physics of Immortality\". One such constraint is that the universe must end in a big crunch, which seems unlikely in view of the tentative conclusions drawn since 1998 about dark energy, based on observations of very distant supernovas.\n\nIn his review of Barrow and Tipler, Martin Gardner ridiculed the FAP by quoting the last two sentences of their book as defining a Completely Ridiculous Anthropic Principle (CRAP):\n\nCarter has frequently regretted his own choice of the word \"anthropic\", because it conveys the misleading impression that the principle involves humans specifically, rather than intelligent observers in general. Others have criticised the word \"principle\" as being too grandiose to describe straightforward applications of selection effects.\n\nA common criticism of Carter's SAP is that it is an easy deus ex machina which discourages searches for physical explanations. To quote Penrose again: \"[I]t tends to be invoked by theorists whenever they do not have a good enough theory to explain the observed facts.\"\n\nCarter's SAP and Barrow and Tipler's WAP have been dismissed as truisms or trivial tautologies—that is, statements true solely by virtue of their logical form (the conclusion is identical to the premise) and not because a substantive claim is made and supported by observation of reality. As such, they are criticized as an elaborate way of saying \"if things were different, they would be different\", which is a valid statement, but does not make a claim of some factual alternative over another.\n\nCritics of the Barrow and Tipler SAP claim that it is neither testable nor falsifiable, and thus is not a scientific statement but rather a philosophical one. The same criticism has been leveled against the hypothesis of a multiverse, although some argue that it does make falsifiable predictions. A modified version of this criticism is that we understand so little about the emergence of life, especially intelligent life, that it is effectively impossible to calculate the number of observers in each universe. Also, the prior distribution of universes as a function of the fundamental constants is easily modified to get any desired result.\n\nMany criticisms focus on versions of the strong anthropic principle, such as Barrow and Tipler's \"anthropic cosmological principle\", which are teleological notions that tend to describe the existence of life as a \"necessary prerequisite\" for the observable constants of physics. Similarly, Stephen Jay Gould, Michael Shermer, and others claim that the stronger versions of the anthropic principle seem to reverse known causes and effects. Gould compared the claim that the universe is fine-tuned for the benefit of our kind of life to saying that sausages were made long and narrow so that they could fit into modern hotdog buns, or saying that ships had been invented to house barnacles. These critics cite the vast physical, fossil, genetic, and other biological evidence consistent with life having been fine-tuned through natural selection to adapt to the physical and geophysical environment in which life exists. Life appears to have adapted to the universe, and not vice versa.\n\nSome applications of the anthropic principle have been criticized as an argument by lack of imagination, for tacitly assuming that carbon compounds and water are the only possible chemistry of life (sometimes called \"carbon chauvinism\", see also alternative biochemistry). The range of fundamental physical constants consistent with the evolution of carbon-based life may also be wider than those who advocate a fine tuned universe have argued. For instance, Harnik et al. propose a weakless universe in which the weak nuclear force is eliminated. They show that this has no significant effect on the other fundamental interactions, provided some adjustments are made in how those interactions work. However, if some of the fine-tuned details of our universe were violated, that would rule out complex structures of any kind—stars, planets, galaxies, etc.\n\nLee Smolin has offered a theory designed to improve on the lack of imagination that anthropic principles have been accused of. He puts forth his fecund universes theory, which assumes universes have \"offspring\" through the creation of black holes whose offspring universes have values of physical constants that depend on those of the mother universe.\n\nSome versions of the anthropic principle are only interesting if the range of physical constants that allow certain kinds of life are unlikely in a landscape of possible universes. But Lee Smolin assumes that conditions for carbon based life are similar to conditions for black hole creation, which would change the a priori distribution of universes such that universes containing life would be likely. In Smolin vs. Susskind: The Anthropic Principle the string theorist Leonard Susskind disagrees about some assumptions in Lee Smolin's theory, while Smolin defends his theory.\n\nThe philosophers of cosmology John Earman, Ernan McMullin, and Jesús Mosterín contend that \"in its weak version, the anthropic principle is a mere tautology, which does not allow us to explain anything or to predict anything that we did not already know. In its strong version, it is a gratuitous speculation\". A further criticism by Mosterín concerns the flawed \"anthropic\" inference from the assumption of an infinity of worlds to the existence of one like ours:\n\n", "id": "2792", "title": "Anthropic principle"}
{"url": "https://en.wikipedia.org/wiki?curid=2795", "text": "Australian Army\n\nThe Australian Army is Australia's military land force. It is part of the Australian Defence Force (ADF) along with the Royal Australian Navy and the Royal Australian Air Force. While the Chief of the Defence Force (CDF) commands the ADF, the Army is commanded by the Chief of Army (CA). The CA is therefore subordinate to the CDF, but is also directly responsible to the Minister for Defence. Although Australian soldiers have been involved in a number of minor and major conflicts throughout its history, only in World War II has Australian territory come under direct attack.\n\nFormed in March 1901, with the amalgamation of the six separate colonial military forces, the history of the Australian Army can be divided into two periods:\n\nDuring its history the Australian Army has fought in a number of major wars, including: Second Boer War (1899–1902), First World War (1914–18), the Second World War (1939–45), Korea War (1950–53), Malayan Emergency (1950–60), Indonesia-Malaysia Confrontation (1962–66), Vietnam War (1962–73), and more recently in Afghanistan (2001 – present) and Iraq (2003–09). Since 1947 the Australian Army has also been involved in many peacekeeping operations, usually under the auspices of the United Nations, however the non-United Nations sponsored Multinational Force and Observers in the Sinai is a notable exception. Australia's largest peacekeeping deployment began in 1999 in East Timor, while other ongoing operations include peacekeeping on Bougainville, in the Sinai, and in the Solomon Islands. Humanitarian relief after 2004 Indian Ocean earthquake in Aceh Province, Indonesia, Operation Sumatra Assist, ended on 24 March 2005.\n\nThe 1st Division comprises a deployable headquarters, while 2nd Division under the command of Forces Command is the main home-defence formation, containing Army Reserve units. 2nd Division's headquarters only performs administrative functions. The Australian Army has not deployed a divisional-sized formation since 1945 and does not expect to do so in the future.\n\n1st Division carries out high-level training activities and deploys to command large-scale ground operations. It does not have any combat units permanently assigned.\n\nForces Command controls for administrative purposes all non-special-forces assets of the Australian Army. It is neither an operational nor a deployable command.\n\nAdditionally, Forces Command includes the following training establishments:\nSpecial Operations Command comprises a command formation of equal status to the other commands in the ADF. It includes all of Army's special forces assets.\n\nUnder a restructuring program known as Plan Beersheba announced in late 2011, the 1st, 3rd and 7th Brigades will be re-formed as combined-arms multi-role manoeuvre brigades with the 2nd Battalion, Royal Australian Regiment (part of the 3rd Brigade) forming the core of a future amphibious force. The force will be known as the Amphibious Ready Element and will be embarked on the Navy's new \"Canberra\"-class amphibious assault ships.\n\nInfantry, and some other combat units of the Australian Army carry flags called the Queen's Colour and the Regimental Colour, known as \"the Colours\". Armoured units carry Standards and Guidons – flags smaller than Colours and traditionally carried by Cavalry, Lancer, Light Horse and Mounted Infantry units. The 1st Armoured Regiment is the only unit in the Australian Army to carry a Standard, in the tradition of heavy armoured units. Artillery units' guns are considered to be their Colours, and on parade are provided with the same respect. Non-combat units (combat service support corps) do not have Colours, as Colours are battle flags and so are only available to combat units. As a substitute, many have Standards or Banners. Units awarded battle honours have them emblazoned on their Colours, Standards and Guidons. They are a link to the unit's past and a memorial to the fallen. Artillery do not have Battle Honours – their single Honour is \"Ubique\" which means \"Everywhere\" – although they can receive Honour Titles.\n\nThe Army is the guardian of the National Flag and as such, unlike the Royal Australian Air Force, does not have a flag or Colours. The Army, instead, has a banner, known as the Army Banner. To commemorate the centenary of the Army, the Governor General Sir William Deane, presented the Army with a new Banner at a parade in front of the Australian War Memorial on 10 March 2001. The Banner was presented to the Regimental Sergeant Major of the Army (RSM-A), Warrant Officer Peter Rosemond.\n\nThe Army Banner bears the Australian Coat of Arms on the obverse, with the dates \"1901–2001\" in gold in the upper hoist. The reverse bears the \"rising sun\" badge of the Australian Army, flanked by seven campaign honours on small gold-edged scrolls: South Africa, World War I, World War II, Korea, Malaya-Borneo, South Vietnam, and Peacekeeping. The banner is trimmed with gold fringe, has gold and crimson cords and tassels, and is mounted on a pike with the usual British royal crest finial.\n\nIn the 2014–15 financial year the Army had an average strength of 43,667 personnel: 29,366 permanent (regular) and 14,301 active reservists (part-time). In addition, there are another 12,496 members of the Standby Reserve. The regular Army is targeted to expand to 30,464 (regular) and 15,250 (part-time) personnel by 2015–16. Personnel numbers have trended upwards since a peak in 2010–11 with an actual strength of 29,366 full-time personnel. Army Reserve numbers are 14,301, which does not include Standby Reserves. This gives the Army a combined strength of 43,667 active personnel for the year 2014–15.\n\nThe ranks of the Australian Army are based on the ranks of the British Army, and carry mostly the same actual insignia. For officers the ranks are identical except for the shoulder title \"Australia\". The Non-Commissioned Officer insignia are the same up until Warrant Officer, where they are stylised for Australia (for example, using the Australian, rather than the British coat of arms).\nThe ranks of the Australian Army are as follows:\n\nThe Army's operational headquarters, Forces Command, is located at Victoria Barracks in Sydney. The Australian Army's three regular brigades are based at Robertson Barracks near Darwin, Lavarack Barracks in Townsville and Gallipoli Barracks in Brisbane. The Deployable Joint Force Headquarters is also located at Gallipoli Barracks.\n\nOther important Army bases include the Army Aviation Centre near Oakey, Queensland, Holsworthy Barracks near Sydney, Lone Pine Barracks in Singleton, New South Wales and Woodside Barracks near Adelaide, South Australia. The SASR is based at Campbell Barracks Swanbourne, a suburb of Perth, Western Australia.\n\nPuckapunyal north of Melbourne houses the Australian Army's Combined Arms Training Centre, Land Warfare Development Centre, and three of the five principal Combat Arms schools. Further barracks include Steele Barracks in Sydney, Keswick Barracks in Adelaide, and Irwin Barracks at Karrakatta in Perth. Dozens of Australian Army Reserve depots are located across Australia.\n\nSince 1948, the Australian Army has published its own journal titled the \"Australian Army Journal\". Covering a broad range of topics including essays, book reviews and editorials, with submissions from serving members as well as professional authors, the journal's stated goal is to provide \"...the primary forum for Army's professional discourse... [and to facilitate]... debate within the Australian Army ...[and raise] ...the quality and intellectual rigor of that debate by adhering to a strict and demanding standard of quality\". In 1976, the journal was placed on hiatus; however, publishing began again in 1999 and since then the journal has been published largely on a quarterly basis, with only minimal interruptions.\n\nThis list includes equipment currently on order or a requirement which has been identified:\n\n\n", "id": "2795", "title": "Australian Army"}
{"url": "https://en.wikipedia.org/wiki?curid=2799", "text": "American Registry for Internet Numbers\n\nThe American Registry for Internet Numbers (ARIN) is the Regional Internet Registry (RIR) for Canada, the United States, and many Caribbean and North Atlantic islands. ARIN manages the distribution of Internet number resources, including IPv4 and IPv6 address space and AS numbers. ARIN opened its doors for business on December 22, 1997 after incorporating on April 18, 1997. ARIN is a nonprofit corporation with headquarters in Chantilly, Virginia, USA.\n\nARIN is one of five Regional Internet Registries (RIRs) in the world. Like the other RIRs, ARIN:\n\n\nARIN provides services related to the technical coordination and management of Internet number resources. The nature of these services is described in ARIN's mission statement:\n\nThese services are grouped in three areas: Registration, Organization, and Policy Development.\n\nRegistration services pertain to the technical coordination and inventory management of Internet number resources. Services include:\n\n\nFor information on requesting Internet number resources from ARIN, see https://www.arin.net/resources/index.html. This section includes the request templates, specific distribution policies, and guidelines for requesting and managing Internet number resources.\n\nOrganization services pertain to interaction between stakeholders, ARIN members, and ARIN. Services include:\n\n\nPolicy development services facilitate the development of policy for the technical coordination and management of Internet number resources.\n\nAll ARIN policies are set by the community. Everyone is encouraged to participate in the policy development process at public policy meetings and on the Public Policy Mailing List. The ARIN Board of Trustees ratifies policies only after:\n\n\nThe community develops policies by following a formal Policy Development Process as outlined at https://www.arin.net/policy/pdp.html. The Number Resource Policy Manual, ARIN’s complete set of current policies, is available at https://www.arin.net/policy/nrpm.html.\n\nMembership is not required to participate in ARIN’s policy development process or to apply for Internet number resources.\n\nServices include:\n\n\nARIN consists of the Internet community within its region, its members, a 7-member Board of Trustees, a 15-member Advisory Council, and a professional staff of about 50. The Board of Trustees and Advisory Council are elected by ARIN members for three-year terms.\n\nThe ARIN membership elects the Board of Trustees (BoT), which has ultimate responsibility for the business affairs and financial health of ARIN, and manages ARIN's operations in a manner consistent with the guidance received from the Advisory Council and the goals set by the registry's members. The BoT is responsible for determining the disposition of all revenues received to ensure all services are provided in an equitable manner. The BoT ratifies proposals generated from the membership and submitted through the Advisory Council. Executive decisions are carried out following approval by the BoT. The BoT consists of 7 members consisting of a President and CEO, a Chairman, a Treasurer, and others.\n\nIn addition to the BoT, ARIN has an advisory council that advises ARIN and the BoT on IP address allocation policy and related matters. Adhering to the procedures in the Internet Resource Policy Evaluation Process, the advisory council forwards consensus-based policy proposals to the BoT for ratification. The advisory council consists of 15 elected members consisting of a Chair, Vice Chair, and others.\n\nThe organization was formed in December 1997 to \"provide IP registration services as an independent, nonprofit corporation.\" Until this time, IP address registration (outside of RIPE and APNIC regions) was done in accordance with policies set by the IETF by Network Solutions corporation as part of the InterNIC project. The National Science Foundation approved the plan for the creation of the not-for-profit organization to \"\"give the users of IP numbers (mostly Internet service providers, corporations and other large institutions) a voice in the policies by which they are managed and allocated within the North American region.\"\". As part of the transition, Network Solutions corporation transitioned these tasks as well as initial staff and computer infrastructure to ARIN.\n\nThe initial Board of Trustees consisted of Scott Bradner, John Curran, Kim Hubbard, Don Telage, Randy Bush, Raymundo Vega Aguilar, and Jon Postel (IANA) as an ex-officio member.\n\nThe first president of ARIN was Kim Hubbard, from 1997 until 2000. Kim was succeeded by Raymond \"Ray\" Plzak until the end of 2008. Trustee John Curran was acting President until July 1 of 2009 when he assumed the CEO role permanently.\n\nUntil late 2002 it served Mexico, Central America, South America and all of the Caribbean. LACNIC now handles parts of the Caribbean, Mexico, Central America, and South America. Also, Sub-Saharan Africa was part of its region until April 2005, when AfriNIC was officially recognized by ICANN as the fifth Regional Internet Registry.\n\nOn 24 September 2015 ARIN has declared exhaustion of the ARIN IPv4 addresses pool.\n\nThe countries in the ARIN service region are:\n\n\nARIN formerly covered Angola, Botswana, Burundi, Republic of Congo, Democratic Republic of Congo, Malawi, Mozambique, Namibia, Rwanda, South Africa, Swaziland, Tanzania, Zambia, and Zimbabwe until AfriNIC was formed.\n\nARIN formerly covered Argentina, Aruba, Belize, Bolivia, Brazil, Chile, Colombia, Costa Rica, Cuba, Dominican Republic, Dutch West Indies, Ecuador, El Salvador, Falkland Islands (UK), French Guiana, Guatemala, Guyana, Haiti, Honduras, Mexico, Nicaragua, Panama, Paraguay, Peru, South Georgia and the South Sandwich Islands, Suriname, Trinidad and Tobago, Uruguay, and Venezuela until LACNIC was formed.\n\n", "id": "2799", "title": "American Registry for Internet Numbers"}
{"url": "https://en.wikipedia.org/wiki?curid=2800", "text": "Asimov (disambiguation)\n\nIsaac Asimov (1920–1992) was a science fiction writer.\n\nAsimov may also refer to:\n\n\n\n", "id": "2800", "title": "Asimov (disambiguation)"}
{"url": "https://en.wikipedia.org/wiki?curid=2802", "text": "Akihabara\n\nAkihabara gained the nickname shortly after World War II for being a major shopping center for household electronic goods and the post-war black market. Nowadays, Akihabara is considered by many to be an otaku cultural center and a shopping district for video games, anime, manga, and computer goods. Icons from popular anime and manga are displayed prominently on the shops in the area, and numerous maid cafés are found throughout the district.\n\nThe main area of Akihabara is located on a street just west of Akihabara Station, where most of the major shops are situated. Most of the electronics shops are just west of the station, and the anime and manga shops and the cosplay cafés are north of them.\n\nAs mentioned above, the area called Akihabara now ranges over some districts in Chiyoda ward: , , and . The administrative district called Akihabara exists in Taitō ward and borders on Sotokanda at the middle of Akihabara and Okachimachi stations, but its half is occupied by JR tracks.\n\nThe area that is now Akihabara was once near a city gate of Edo and served as a passage between the city and northwestern Japan. This made the region a home to many craftsmen and tradesmen, as well as some low class samurai. One of Tokyo's frequent fires destroyed the area in 1869, and the people decided to replace the buildings of the area with a shrine called Chinkasha (now known as ), meaning fire extinguisher shrine, in an attempt to prevent the spread of future fires. The locals nicknamed the shrine Akiba after the deity that could control fire, and the area around it became known as Akibagahara and later Akihabara. After Akihabara Station was built in 1888, the shrine was moved to the Taitō ward where it still resides today.\nSince its opening in 1890, Akihabara Station became a major freight transit point, which allowed a vegetable and fruit market to spring up in the district. Then, in the 1920s, the station saw a large volume of passengers after opening for public transport, and after World War II, the black market thrived in the absence of a strong government. This disconnection of Akihabara from government authority has allowed the district to grow as a market city and given rise to an excellent atmosphere for entrepreneurship. In the 1930s, this climate turned Akihabara into a future-oriented market region specializing in household electronics, such as washing machines, refrigerators, televisions, and stereos, earning Akihabara the nickname \"Electric Town\".\n\nAs household electronics began to lose their futuristic appeal in about the 1980s, the shops of Akihabara shifted their focus to home computers at a time when they were only used by specialists and hobbyists. This new specialization brought in a new type of consumer, computer nerds or \"otaku\". The market in Akihabara naturally latched onto their new customer base that was focused on anime, manga, and video games. The connection between Akihabara and otaku has survived and grown to the point that the region is now known worldwide as a center for otaku culture, and some otaku even consider Akihabara to be a sacred place.\n\nOn Sunday 8 June 2008 at 12:33 JST, a man drove into a crowd with a truck, then stabbed at least 17 people using a dagger. Seven died and ten were injured. Tokyo Metropolitan Police Department arrested , 25, on suspicion of attempted murder, and arrested him again weeks later on suspicion of murder. Kato was eventually sentenced to death by the Tokyo District Court in 2011, and the sentence was upheld on appeal in 2012.\n\nThe influence of \"otaku\" culture has shaped Akihabara's businesses and buildings to reflect the interests of \"otaku\" and gained the district worldwide fame for its distinctive imagery. Akihabara tries to create an atmosphere as close as possible to the game and anime worlds of customers' interest. The streets of Akihabara are covered with anime and manga icons, and cosplayers line the sidewalks handing out advertisements, especially for maid cafés. The idol group AKB48, one of Japan's highest selling contemporary musical acts, runs its own theater in Akihabara, from which the group's name is derived.\n\nRelease events, special events, and conventions in Akihabara give anime and manga fans frequent opportunities to meet the creators of the works they follow so closely and strengthen the connection between the region and \"otaku\" culture. The design of many of the buildings serves to create the sort of atmosphere that draws in \"otaku\". Architects design the stores of Akihabara to be more opaque and closed to reflect the general desire of many \"otaku\" to live in their anime worlds rather than display their interests to the world at large.\n\nAkihabara's role as a free market has also allowed a large amount of amateur work to find a passionate audience in the otaku who frequent the area. \"Doujinshi,\" amateur manga (or fanmade manga based on an anime/manga/game) has been growing in Akihabara since the 1970s when publishers began to drop manga that were not ready for large markets.\n\n\n", "id": "2802", "title": "Akihabara"}
{"url": "https://en.wikipedia.org/wiki?curid=2807", "text": "Active Directory\n\nActive Directory (AD) is a directory service that Microsoft developed for Windows domain networks. It is included in most Windows Server operating systems as a set of processes and services. Initially, Active Directory was only in charge of centralized domain management. Starting with Windows Server 2008, however, Active Directory became an umbrella title for a broad range of directory-based identity-related services.\n\nA server running Active Directory Domain Services (AD DS) is called a domain controller. It authenticates and authorizes all users and computers in a Windows domain type network—assigning and enforcing security policies for all computers and installing or updating software. For example, when a user logs into a computer that is part of a Windows domain, Active Directory checks the submitted password and determines whether the user is a system administrator or normal user. Also, it allows management and storage of information at admin level and provides authentication and authorization mechanisms and a framework to deploy other related services (AD Certificate Services, AD Federated Services, etc.).\n\nActive Directory uses Lightweight Directory Access Protocol (LDAP) versions 2 and 3, Microsoft's version of Kerberos, and DNS.\nActive Directory, like many information-technology efforts, originated out of a democratization of design using Request for Comments or RFCs. The Internet Engineering Task Force (IETF), which oversees the RFC process, has accepted numerous RFCs initiated by widespread participants. Active Directory incorporates decades of communication technologies into the overarching Active Directory concept then makes improvements upon them. For example, LDAP underpins Active Directory. Also X.500 directories and the Organizational Unit preceded the Active Directory concept that makes use of those methods. The LDAP concept began to emerge even before the founding of Microsoft in April 1975, with RFCs as early as 1971. RFCs contributing to LDAP include RFC 1823 (on the LDAP API, August 1995), RFC 2307, RFC 3062, and RFC 4533.\n\nMicrosoft previewed Active Directory in 1999, released it first with Windows 2000 Server edition, and revised it to extend functionality and improve administration in Windows Server 2003. Additional improvements came with subsequent versions of Windows Server. In Windows Server 2008, additional services were added to Active Directory, such as Active Directory Federation Services. The part of the directory in charge of management of domains, which was previously a core part of the operating system, was renamed Active Directory Domain Services (ADDS) and became a server role like others. \"Active Directory\" became the umbrella title of a broader range of directory-based services. According to Bryon Hynes, everything related to identity was brought under Active Directory's banner.\n\nActive Directory Services consist of multiple directory services. The best known is Active Directory Domain Services, commonly abbreviated as AD DS or simply AD.\n\nActive Directory Domain Services (AD DS) is the cornerstone of every Windows domain network. It stores information about members of the domain, including devices and users, verifies their credentials and defines their access rights. The server (or the cluster of servers) running this service is called a domain controller. A domain controller is contacted when a user logs into a device, accesses another device across the network, or runs a line-of-business Metro-style app sideloaded into a device.\n\nOther Active Directory services (excluding LDS, as described below) as well as most of Microsoft server technologies rely on or use Domain Services; examples include Group Policy, Encrypting File System, BitLocker, Domain Name Services, Remote Desktop Services, Exchange Server and SharePoint Server.\n\nActive Directory Lightweight Directory Services (\"AD LDS\"), formerly known as \"Active Directory Application Mode\" (ADAM), is a light-weight implementation of AD DS. AD LDS runs as a service on Windows Server. AD LDS shares the code base with AD DS and provides the same functionality, including an identical API, but does not require the creation of domains or domain controllers. It provides a \"Data Store\" for storage of directory data and a \"Directory Service\" with an LDAP \"Directory Service Interface\". Unlike AD DS, however, multiple AD LDS instances can run on the same server.\n\nActive Directory Certificate Services (AD CS) establishes an on-premises public key infrastructure. It can create, validate and revoke public key certificates for internal uses of an organization. These certificates can be used to encrypt files (when used with Encrypting File System), emails (per S/MIME standard), network traffic (when used by virtual private networks, Transport Layer Security protocol or IPSec protocol).\n\nAD CS predates Windows Server 2008, but its name was simply Certificate Services.\n\nAD CS requires an AD DS infrastructure.\n\nActive Directory Federation Services (AD FS) is a single sign-on service. With an AD FS infrastructure in place, users may use several web-based services (e.g. internet forum, blog, online shopping, webmail) or network resources using only one set of credentials stored at a central location, as opposed to having to be granted a dedicated set of credentials for each service. AD FS's purpose is an extension of that of AD DS: The latter enables users to authenticate with and use the devices that are part of the same network, using one set of credentials. The former enables them to use the same set of credentials in a different network.\n\nAs the name suggests, AD FS works based on the concept of federated identity.\n\nAD FS requires an AD DS infrastructure, although its federation partner may not.\n\nActive Directory Rights Management Services (AD RMS, known as Rights Management Services or RMS before Windows Server 2008) is a server software for information rights management shipped with Windows Server. It uses encryption and a form of selective functionality denial for limiting access to documents such as corporate e-mails, Microsoft Word documents, and web pages, and the operations authorized users can perform on them.\n\nAs a directory service, an Active Directory instance consists of a database and corresponding executable code responsible for servicing requests and maintaining the database. The executable part, known as Directory System Agent, is a collection of Windows services and processes that run on Windows 2000 and later. Objects in Active Directory databases can be accessed via LDAP, ADSI (a component object model interface), messaging API and Security Accounts Manager services.\n\nActive Directory structures are arrangements of information about objects. The objects fall into two broad categories: resources (e.g., printers) and security principals (user or computer accounts and groups). Security principals are assigned unique security identifiers (SIDs).\n\nEach object represents a single entity—whether a user, a computer, a printer, or a group—and its attributes. Certain objects can contain other objects. An object is uniquely identified by its name and has a set of attributes—the characteristics and information that the object represents— defined by a schema, which also determines the kinds of objects that can be stored in Active Directory.\n\nThe schema object lets administrators extend or modify the schema when necessary. However, because each schema object is integral to the definition of Active Directory objects, deactivating or changing these objects can fundamentally change or disrupt a deployment. Schema changes automatically propagate throughout the system. Once created, an object can only be deactivated—not deleted. Changing the schema usually requires planning.\n\nThe Active Directory framework that holds the objects can be viewed at a number of levels. The forest, tree, and domain are the logical divisions in an Active Directory network.\n\nWithin a deployment, objects are grouped into domains. The objects for a single domain are stored in a single database (which can be replicated). Domains are identified by their DNS name structure, the namespace.\n\nA domain is defined as a logical group of network objects (computers, users, devices) that share the same Active Directory database.\n\nA tree is a collection of one or more domains and domain trees in a contiguous namespace, linked in a transitive trust hierarchy.\n\nAt the top of the structure is the \"forest.\" A forest is a collection of trees that share a common global catalog, directory schema, logical structure, and directory configuration. The forest represents the security boundary within which users, computers, groups, and other objects are accessible.\n\nThe objects held within a domain can be grouped into Organizational Units (OUs). OUs can provide hierarchy to a domain, ease its administration, and can resemble the organization's structure in managerial or geographical terms. OUs can contain other OUs—domains are containers in this sense. Microsoft recommends using OUs rather than domains for structure and to simplify the implementation of policies and administration. The OU is the recommended level at which to apply group policies, which are Active Directory objects formally named Group Policy Objects (GPOs), although policies can also be applied to domains or sites (see below). The OU is the level at which administrative powers are commonly delegated, but delegation can be performed on individual objects or attributes as well.\n\nOrganizational units do not each have a separate namespace; e.g. user accounts with an identical username (sAMAccountName) in separate OUs within a domain are not allowed, such as \"fred.staff-ou.domain\" and \"fred.student-ou.domain\", where \"staff-ou\" and \"student-ou\" are the OUs. This is because sAMAccountName, a user object attribute, must be unique within the domain. However, two users in different OUs can have the same Common Name (CN), the name under which they are stored in the directory itself.\n\nIn general the reason for this lack of allowance for duplicate names through hierarchical directory placement, is that Microsoft primarily relies on the principles of NetBIOS, which is a flat-file method of network object management that for Microsoft software, goes all the way back to Windows NT 3.1 and MS-DOS LAN Manager. Allowing for duplication of object names in the directory, or completely removing the use of NetBIOS names, would prevent backward compatibility with legacy software and equipment. However, disallowing duplicate object names in this way is a violation of the LDAP RFCs on which Active Directory is supposedly based.\n\nAs the number of users in a domain increases, conventions such as \"first initial, middle initial, last name\" (Western order) or the reverse (Eastern order) fail for common family names like \"Li (李)\", \"Smith\" or \"Garcia\". Workarounds include adding a digit to the end of the username. Alternatives include creating a separate ID system of unique employee/student id numbers to use as account names in place of actual user's names, and allowing users to nominate their preferred word sequence within an acceptable use policy.\n\nBecause duplicate usernames cannot exist within a domain, account name generation poses a significant challenge for large organizations that cannot be easily subdivided into separate domains, such as students in a public school system or university who must be able to use any computer across the network.\n\nIn Microsoft's Active Directory, OUs do not confer access permissions, and objects placed within OUs are not automatically assigned access privileges based on their containing OU. This is a design limitation specific to Active Directory. Other competing directories such as Novell NDS are able to assign access privileges through object placement within an OU.\n\nActive Directory requires a separate step for an administrator to assign an object in an OU as a member of a group also within that OU. Relying on OU location alone to determine access permissions is unreliable, because the object may not have been assigned to the group object for that OU.\n\nA common workaround for an Active Directory administrator is to write a custom PowerShell or Visual Basic script to automatically create and maintain a \"user group\" for each OU in their directory. The scripts are run periodically to update the group to match the OU's account membership, but are unable to instantly update the security groups anytime the directory changes, as occurs in competing directories where security is directly implemented into the directory itself. Such groups are known as \"Shadow Groups\". Once created, these shadow groups are selectable in place of the OU in the administrative tools.\n\nMicrosoft refers to shadow groups in the Server 2008 Reference documentation, but does not explain how to create them. There are no built-in server methods or console snap-ins for managing shadow groups.\n\nThe division of an organization's information infrastructure into a hierarchy of one or more domains and top-level OUs is a key decision. Common models are by business unit, by geographical location, by IT Service, or by object type and hybrids of these. OUs should be structured primarily to facilitate administrative delegation, and secondarily, to facilitate group policy application. Although OUs form an administrative boundary, the only true security boundary is the forest itself and an administrator of any domain in the forest must be trusted across all domains in the forest.\n\nThe Active Directory database is organized in \"partitions\", each holding specific object types and following a specific replication pattern. Microsoft often refers to these partitions as 'naming contexts'. The 'Schema' partition contains the definition of object classes and attributes within the Forest. The 'Configuration' partition contains information on the physical structure and configuration of the forest (such as the site topology). Both replicate to all domains in the Forest. The 'Domain' partition holds all objects created in that domain and replicates only within its domain.\n\n\"Sites\" are physical (rather than logical) groupings defined by one or more IP subnets. AD also holds the definitions of connections, distinguishing low-speed (e.g., WAN, VPN) from high-speed (e.g., LAN) links. Site definitions are independent of the domain and OU structure and are common across the forest. Sites are used to control network traffic generated by replication and also to refer clients to the nearest domain controllers (DCs). Microsoft Exchange Server 2007 uses the site topology for mail routing. Policies can also be defined at the site level.\n\nPhysically, the Active Directory information is held on one or more peer domain controllers, replacing the NT PDC/BDC model. Each DC has a copy of the Active Directory. Servers joined to Active Directory that are not domain controllers are called Member Servers. A subset of objects in the domain partition replicate to domain controllers that are configured as global catalogs. Global catalog (GC) servers provide a global listing of all objects in the Forest.\nGlobal Catalog servers replicate to themselves all objects from all domains and hence, provide a global listing of objects in the forest. However, to minimize replication traffic and keep the GC's database small, only selected attributes of each object are replicated. This is called the partial attribute set (PAS). The PAS can be modified by modifying the schema and marking attributes for replication to the GC. Earlier versions of Windows used NetBIOS to communicate. Active Directory is fully integrated with DNS and requires TCP/IP—DNS. To be fully functional, the DNS server must support SRV resource records, also known as service records.\n\nActive Directory synchronizes changes using \"multi-master replication\". Replication by default is 'pull' rather than 'push', meaning that replicas pull changes from the server where the change was effected. The \"Knowledge Consistency Checker\" (KCC) creates a replication topology of \"site links\" using the defined \"sites\" to manage traffic. Intrasite replication is frequent and automatic as a result of change notification, which triggers peers to begin a pull replication cycle. Intersite replication intervals are typically less frequent and do not use change notification by default, although this is configurable and can be made identical to intrasite replication.\n\nEach link can have a 'cost' (e.g., DS3, T1, ISDN etc.) and the KCC alters the site link topology accordingly. Replication may occur transitively through several site links on same-protocol \"site link bridges\", if the cost is low, although KCC automatically costs a direct site-to-site link lower than transitive connections. Site-to-site replication can be configured to occur between a \"bridgehead server\" in each site, which then replicates the changes to other DCs within the site. Replication for Active Directory zones is automatically configured when DNS is activated in the domain based by site.\n\nReplication of Active Directory uses Remote Procedure Calls (RPC) over IP (RPC/IP). Between Sites SMTP can be used for replication, but only for changes in the Schema, Configuration, or Partial Attribute Set (Global Catalog) GCs. SMTP cannot be used for replicating the default Domain partition.\n\nIn general, a network utilizing Active Directory has more than one licensed Windows server computer. Backup and restore of Active Directory is possible for a network with a single domain controller, but Microsoft recommends more than one domain controller to provide automatic failover protection of the directory. Domain controllers are also ideally single-purpose for directory operations only, and should not run any other software or role.\n\nCertain Microsoft products such as SQL Server and Exchange can interfere with the operation of a domain controller, necessitating isolation of these products on additional Windows servers. Combining them can make configuration or troubleshooting of either the domain controller or the other installed software more difficult. A business intending to implement Active Directory is therefore recommended to purchase a number of Windows server licenses, to provide for at least two separate domain controllers, and optionally, additional domain controllers for performance or redundancy, a separate file server, a separate Exchange server, a separate SQL Server, and so forth to support the various server roles.\n\nPhysical hardware costs for the many separate servers can be reduced through the use of virtualization, although for proper failover protection, Microsoft recommends not running multiple virtualized domain controllers on the same physical hardware.\n\nThe Active-Directory database, the \"directory store\", in Windows 2000 Server uses the JET Blue-based Extensible Storage Engine (ESE98) and is limited to 16 terabytes and 2 billion objects (but only 1 billion security principals) in each domain controller's database. Microsoft has created NTDS databases with more than 2 billion objects. (NT4's Security Account Manager could support no more than 40,000 objects). Called NTDS.DIT, it has two main tables: the \"data table\" and the \"link table\". Windows Server 2003 added a third main table for security descriptor single instancing.\n\nPrograms may access the features of Active Directory via the COM interfaces provided by \"Active Directory Service Interfaces\".\n\nFlexible Single Master Operations Roles (FSMO, pronounced \"fizz-mo\") operations are also known as operations master roles. Although domain controllers allow simultaneous updates in multiple places, certain operations are supported only on a single server. These operations are performed using the roles listed below:\n\nTo allow users in one domain to access resources in another, Active Directory uses trusts.\n\nTrusts inside a forest are automatically created when domains are created. The forest sets the default boundaries of trust, and implicit, transitive trust is automatic for all domains within a forest.\n\n\nWindows Server 2003 introduced the \"forest root trust\". This trust can be used to connect Windows Server 2003 forests if they are operating at the 2003 forest functional level. Authentication across this type of trust is Kerberos-based (as opposed to NTLM).\n\nForest trusts are transitive for all the domains within the trusted forests. However, forest trusts are \"not\" transitive between forests.\n\nExample: Suppose that a two-way transitive forest trust exists between the forest root domains in Forest A and Forest B, and another two-way transitive forest trust exists between the forest root domains in Forest B and Forest C. Such a configuration lets users in Forest B access resources in any domain in either Forest A or Forest C, and users in Forest A or C can access resources in any domain in Forest B. However, it does \"not\" let users in Forest A access resources in Forest C, or vice versa. To let users in Forest A and Forest C share resources, a two-way transitive trust must exist between both forests.\n\nMicrosoft Active Directory management tools include:\n\nThese management tools may not provide enough functionality for efficient workflow in large environments. Some third-party solutions extend the administration and management capabilities. They provide essential features for a more convenient administration processes, such as automation, reports, integration with other services, etc.\n\nVarying levels of interoperability with Active Directory can be achieved on most Unix-like operating systems (including Unix, Linux, Mac OS X or Java and Unix-based programs) through standards-compliant LDAP clients, but these systems usually do not interpret many attributes associated with Windows components, such as Group Policy and support for one-way trusts.\n\nThird parties offer Active Directory integration for Unix-like platforms, including:\n\nThe schema additions shipped with Windows Server 2003 R2 include attributes that map closely enough to RFC 2307 to be generally usable. The reference implementation of RFC 2307, nss_ldap and pam_ldap provided by PADL.com, support these attributes directly. The default schema for group membership complies with RFC 2307bis (proposed). Windows Server 2003 R2 includes a Microsoft Management Console snap-in that creates and edits the attributes.\n\nAn alternate option is to use another directory service as non-Windows clients authenticate to this while Windows Clients authenticate to AD. Non-Windows clients include 389 Directory Server (formerly Fedora Directory Server, FDS), ViewDS Identity Solutions - ViewDS v7.2 XML Enabled Directory and Sun Microsystems Sun Java System Directory Server. The latter two both being able to perform two-way synchronization with AD and thus provide a \"deflected\" integration.\n\nAnother option is to use OpenLDAP with its \"translucent\" overlay, which can extend entries in any remote LDAP server with additional attributes stored in a local database. Clients pointed at the local database see entries containing both the remote and local attributes, while the remote database remains completely untouched.\n\nAdministration (querying, modifying, and monitoring) of Active Directory can be achieved via many scripting languages, including PowerShell, VBScript, JScript/JavaScript, Perl, Python, and Ruby. Free and non-free AD administration tools can help to simplify and possibly automate AD management tasks.\n\n\n", "id": "2807", "title": "Active Directory"}
{"url": "https://en.wikipedia.org/wiki?curid=2809", "text": "Arian (disambiguation)\n\nArian may refer to:\n\n", "id": "2809", "title": "Arian (disambiguation)"}
{"url": "https://en.wikipedia.org/wiki?curid=2810", "text": "Aldona of Lithuania\n\nAldona (baptized \"Ona\" or \"Anna\"; her pagan name, Aldona, is known only from the writings of Maciej Stryjkowski; – 26 May 1339) was Queen consort of Poland (1333–1339), and a princess of the Grand Duchy of Lithuania. She was the daughter of Gediminas, Grand Duke of Lithuania.\n\nAldona married Casimir III of Poland, when he was 15 or 16 years old. The bride was probably of about the same age. The marriage took place on 30 April or 16 October 1325 and was a purely political maneuver to strengthen the first Polish–Lithuanian coalition against the Teutonic Knights. Casimir was seeking allies in the dispute over Pomerania with the Order. Gediminas had just undertaken an unsuccessful attempt to Christianize Lithuania. This coalition was a prelude to the Union of Krewo in 1385, and the Union of Lublin in 1569, which resulted in the creation of a new state, the Polish–Lithuanian Commonwealth. The details of the agreement are not known; however, it is known that Gediminas released all Polish captives, some 25,000 people, who returned to Poland. The importance of the marriage was attested by the fact that Władysław abandoned his earlier plans to marry his son to Jutta of Bohemia. The alliance was put into effect when joint Polish–Lithuanian forces organized an attack against the Margraviate of Brandenburg in 1326. However, the coalition was not strong and collapsed c. 1330. Yet, there is no evidence of fighting between Poland and Lithuania while Aldona was alive. Aldona died suddenly at the end of May 1339, and was buried in Kraków.\n\nAldona was remembered for her piety and devotion to music. She was accompanied by court musicians wherever she went. It was even suggested by Jan Długosz that the cymbals which were played in procession before her represented a pagan Lithuanian tradition. Her husband Casimir is known for his romantic affairs: after Aldona's death he married three more times. Aldona had two daughters:\n\n", "id": "2810", "title": "Aldona of Lithuania"}
{"url": "https://en.wikipedia.org/wiki?curid=2812", "text": "Aron Nimzowitsch\n\nAron Nimzowitsch (, , \"Aron Isayevich Nimtsovich\"; born Aron Niemzowitsch; 7 November 1886 – 16 March 1935) was a Russian-born, Danish leading chess master and a very influential chess writer. He was the foremost figure amongst the \"hypermoderns\".\n\nBorn in part of the Russian Empire, the Jewish German-speaking Nimzowitsch came from a wealthy family, where he learned chess from his father, who was a merchant. In 1904, he travelled to Berlin to study philosophy, but set aside his studies soon and began a career as a professional chess player that same year. He won his first international tournament at Munich 1906. Then, he tied for first with Alexander Alekhine at St. Petersburg 1913/14 (the eighth All-Russian Masters' Tournament).\n\nDuring the 1917 Russian Revolution, Nimzowitsch was in the Baltic war zone. He escaped being drafted into one of the armies by feigning madness, insisting that a fly was on his head. He then escaped to Berlin, and gave his first name as Arnold, possibly to avoid anti-Semitic persecution.\n\nNimzowitsch eventually moved to Copenhagen in 1922, which coincided with his rise to the world chess elite, where he lived for the rest of his life in one small rented room. In Copenhagen, he twice won the Nordic Chess Championship, in 1924 and 1934. He obtained Danish citizenship and lived in Denmark until his death in 1935.\n\nThe height of Nimzowitsch's career was the late 1920s and early 1930s. Chessmetrics places him as the third best player in the world from 1927 to 1931, behind Alexander Alekhine and José Capablanca. His most notable successes were first-place finishes at Copenhagen 1923, Marienbad 1925, Dresden 1926, Hanover 1926, the Carlsbad 1929 chess tournament, and second place behind Alekhine at the San Remo 1930 chess tournament. Nimzowitsch never developed a knack for match play, though; his best match success was a draw with Alekhine, but the match consisted of only two games and took place in 1914, thirteen years before Alekhine became world champion.\n\nNimzowitsch never beat Capablanca, but fared better against Alekhine. He even beat Alekhine with the black pieces, in their short 1914 match at St. Petersburg. One of Nimzowitsch's most famous games is his celebrated immortal zugzwang game against Sämisch at Copenhagen 1923. Another game on this theme is his win over Paul Johner at Dresden 1926. When in form, Nimzowitsch was very dangerous with the black pieces, scoring many fine wins over top players.\n\nNimzowitsch is considered one of the most important players and writers in chess history. His works influenced numerous other players, including Savielly Tartakower, Milan Vidmar, Richard Réti, Akiba Rubinstein, Bent Larsen and Tigran Petrosian, and his influence is still felt today.\n\nHe wrote three books on chess strategy: \"Mein System (My System)\", 1925, \"Die Praxis meines Systems (The Practice of My System)\", 1929, commonly known as \"Chess Praxis\", and \"Die Blockade\" (\"The Blockade\"), 1925, though much in the latter book is generally held to be a rehash of material already presented in \"Mein System\". \"Mein System\" is considered to be one of the most influential chess books of all time. It sets out Nimzowitsch's most important ideas, while his second most influential work, \"Chess Praxis\", elaborates upon these ideas, adds a few new ones, and has immense value as a stimulating collection of Nimzowitsch's own games accompanied by his idiosyncratic, hyperbolic commentary which is often as entertaining as instructive.\n\nNimzowitsch's chess theories, when first propounded flew in the face of widely held orthodoxies enunciated by the dominant theorist of the era, Siegbert Tarrasch, and his disciples. Tarrasch's rigid generalizations drew on the earlier work of Wilhelm Steinitz, and were upheld by Tarrasch's sharp tongue when dismissing the opinions of doubters. While the greatest players of the time, among them Alekhine, Emanuel Lasker and Capablanca, clearly did not allow their play to be hobbled by blind adherence to general concepts that the center had to be controlled by pawns, that development had to happen in support of this control, that rooks always belong on open files, that wing openings were unsound—core ideas of Tarrasch's chess philosophy as popularly understood—beginners were taught to think of these generalizations as unalterable principles.\n\nNimzowitsch supplemented many of the earlier simplistic assumptions about chess strategy by enunciating in his turn a further number of general concepts of defensive play aimed at achieving one's own goals by preventing realization of the opponent's plans. Notable in his \"system\" were concepts such as overprotection of pieces and pawns under attack, control of the center by pieces instead of pawns, blockading of opposing pieces (notably the passed pawns) and prophylaxis. He was also a leading exponent of the fianchetto development of bishops. Perhaps most importantly, he formulated the terminology still in use for various complex chess strategies. Others had used these ideas in practice, but he was the first to present them systematically as a lexicon of themes accompanied by extensive taxonomical observations.\n\nGrandmaster (GM) Raymond Keene writes that Nimzowitsch \"was one of the world's leading grandmasters for a period extending over a quarter of a century, and for some of that time he was the obvious challenger for the world championship. ... [He was also] a great and profound chess thinker second only to Steinitz, and his works – \"Die Blockade\", \"My System\" and \"Chess Praxis\" – established his reputation as one of the father figures of modern chess.\" GM Robert Byrne called him \"perhaps the most brilliant theoretician and teacher in the history of the game.\" GM Jan Hein Donner called Nimzowitsch \"a man who was too much of an artist to be able to prove he was right and who was regarded as something of a madman in his time. He would be understood only long after his death.\"\n\nMany chess openings and variations are named after Nimzowitsch, the most famous being the Nimzo-Indian Defence (1.d4 Nf6 2.c4 e6 3.Nc3 Bb4) and the less often played Nimzowitsch Defence (1.e4 Nc6). Nimzowitsch biographer GM Raymond Keene and others have referred to 1.Nf3 followed by 2.b3 as the Nimzowitsch–Larsen Attack. Keene wrote a book about the opening with that title. These openings all exemplify Nimzowitsch's ideas about controlling the center with pieces instead of pawns. He was also vital in the development of two important systems in the French Defence, the (in some places called the Nimzowitsch Variation; its moves are 1.e4 e6 2.d4 d5 3.Nc3 Bb4) and the (1.e4 e6 2.d4 d5 3.e5). He also pioneered two provocative variations of the Sicilian Defence: the , 1.e4 c5 2.Nf3 Nf6, which invites 3.e5 Nd5 (similar to Alekhine's Defence) and 1.e4 c5 2.Nf3 Nc6 3.d4 cxd4 4.Nxd4 d5?! (the latter regarded as dubious today). International Master John L. Watson has dubbed the line 1.c4 Nf6 2.Nc3 e6 3.Nf3 Bb4 the \"Nimzo-English\", employing this designation in Chapter 11 of his recent book \"Mastering the Chess Openings, Volume 3\".\n\nThere are many entertaining anecdotes regarding Nimzowitsch—some less savory than others. An article by Hans Kmoch and Fred Reinfeld entitled \"Unconventional Surrender\" on page 55 of the February 1950 Chess Review tells of the \"... example of Nimzowitsch, who ... once missed first prize in a tournament in Berlin by losing to Sämisch, and when it became clear he was going to lose the game, Nimzowitsch stood up on the table and shouted, 'Gegen diesen Idioten muss ich verlieren!' ('That I should lose to this idiot!')\".\n\nNimzowitsch was annoyed by his opponents' smoking. A popular, but probably apocryphal, story is that once when an opponent laid an unlit cigar on the table, he complained to the tournament arbiters, \"He is threatening to smoke, and as an old player you must know that the threat is stronger than the execution.\"\n\nNimzowitsch had lengthy and somewhat bitter dogmatic conflicts with Tarrasch over whose ideas constituted 'proper' chess.\n\nNimzowitsch's vanity and faith in his ideas of overprotection provoked Hans Kmoch to write a parody about him in February 1928 in the \"Wiener Schachzeitung\". This consisted of a mock game against the fictional player \"Systemsson\", supposedly played and annotated by Nimzowitsch himself. The annotations gleefully exaggerate the idea of overprotection, as well as asserting the true genius of the wondrous idea. Kmoch was in fact a great admirer of Nimzowitsch, and the subject of the parody himself was amused at the effort.\n\nKmoch also wrote an article about his nine years with Nimzowitsch:\n\nNimzowitsch's colleague Tartakower observed of him, \"He pretends to be crazy in order to drive us all crazy.\"\n\nAlthough he had long suffered from heart trouble, his early death was unexpected; taken ill suddenly at the end of 1934, he lay bedridden for three months before dying of pneumonia. He is buried in Bispebjerg Cemetery in Copenhagen.\n\n\n\n\n", "id": "2812", "title": "Aron Nimzowitsch"}
{"url": "https://en.wikipedia.org/wiki?curid=2813", "text": "Aragonese language\n\nAragonese (; \"aragonés\" in Aragonese) is a Romance language spoken in several dialects by 10,000 to 30,000 people in the Pyrenees valleys of Aragon, Spain, primarily in the comarcas of Somontano de Barbastro, Jacetania, Alto Gállego, Sobrarbe, and Ribagorza/Ribagorça. It is the only modern language which survived from medieval Navarro-Aragonese in a form distinctly different from Spanish.\n\nInformally known as \"fabla\" (\"talk\" or \"speech\"), Aragonese is also commonly referred to by the names of its local dialects such as \"cheso\" (from Valle de Hecho) or \"patués\" (from the Benasque Valley).\n\nAragonese, which developed in portions of the Ebro basin, can be traced back to the High Middle Ages. It spread throughout the Pyrenees to areas where languages similar to Basque were previously spoken. The Kingdom of Aragon (formed by the counties of Aragon, Sobrarbe and Ribagorza) expanded southward from the mountains, pushing the Moors farther south in the \"Reconquista\" and spreading the Aragonese language.\n\nThe union of the Catalan counties and the Kingdom of Aragon which formed the 12th-century Crown of Aragon did not merge the languages of the two territories; Catalan continued to be spoken in the east and Navarro-Aragonese in the west, with boundaries blurred by dialectal continuity. The Aragonese \"Reconquista\" in the south ended with the cession of Murcia by James I of Aragon to the Kingdom of Castile as dowry for an Aragonese princess.\n\nThe best-known proponent of the Aragonese language was Johan Ferrandez d'Heredia, the Grand Master of the Knights Hospitaller in Rhodes at the end of the 14th century. He wrote an extensive catalog of works in Aragonese and translated several works from Greek into Aragonese (the first in medieval Europe).\n\nThe spread of Castilian (Spanish), the Castilian origin of the Trastámara dynasty, and the similarity between Castilian and Aragonese facilitated the recession of the latter. A turning point was the 15th-century coronation of the Castilian Ferdinand I of Aragon, also known as Ferdinand of Antequeraa.\n\nIn recent times, Aragonese was mostly regarded as a group of rural dialects of Spanish. Compulsory education undermined its already weak position; for example, pupils were punished for using it. However, the 1978 Spanish transition to democracy heralded literary works and studies of the language.\n\nAragonese is the native language of the Aragonese mountain ranges of the Pyrenees, in the \"comarcas\" of Somontano, Jacetania, Sobrarbe, and Ribagorza. Cities and towns in which Aragonese is spoken are Huesca, Graus, Monzón, Barbastro, Bielsa, Chistén, Fonz, Echo, Estadilla, Benasque, Campo, Sabiñánigo, Jaca, Plan, Ansó, Ayerbe, Broto, and El Grado.\n\nIt is spoken as a second language by inhabitants of Huesca, Zaragoza, Ejea de los Caballeros, and Teruel. According to recent polls, there are about 10,000 active speakers and 30,000 passive speakers.\n\nIn 2009, the Languages Act of Aragon recognized the \"native language, original and historic\" of Aragon. The language received several linguistic rights, including its use in public administration.\n\n\nAragonese has many historical traits in common with Catalan. Some are conservative features that are also shared with the Astur-Leonese languages and Galician-Portuguese, where Spanish innovated in ways that did not spread to nearby languages.\n\n\n\n\n\nIn 2010, the Academia de l'Aragonés (founded in 2006) established an orthographic standard to modernize medieval orthography and to make it more etymological. The new orthography is used by the .\n\nAragonese had two orthographic standards:\n\nDuring the 16th century, Aragonese Moriscos wrote aljamiado texts (Romance texts in Arabic writing), possibly because of their inability to write in Arabic. The language in these texts has a mixture of Aragonese and Castilian traits, and they are among the last known written examples of the Aragonese formerly spoken in central and southern Aragon.\n\nAragonese grammar is similar to that of other Iberian Romance languages, such as Spanish and Catalan.\n\nThe definite article in Aragonese has undergone dialect-related changes, with definite articles in Old Aragonese similar to their present Spanish equivalents. The most-widespread articles in Aragonese are similar to those in Galician and Portuguese, since they lack the initial \"l\":\n\nThe second (auxiliary) article, after a vowel, is used with an \"r\" (pronounced [ɾ]).\n\nNeighboring Romance languages have influenced Aragonese. Catalan and Occitan influenced Medieval Aragonese, and the Catalan influence continued under the Crown of Aragon in the Ribagorçan dialect. Since the 15th century, Spanish has most influenced Aragonese; it was adopted throughout Aragon as the first language, limiting Aragonese to the northern region surrounding the Pyrenees. French has also influenced Aragonese; Italian loanwords have entered through other languages (such as Catalan), and Portuguese words have entered through Spanish. Germanic words came with the conquest of the region by Germanic peoples during the fifth century, and English has introduced a number of new words into the language.\n\nWords that were part of the Latin second declension—as well as words that joined it later on—are usually masculine:\n\n\nWords that were part of the Latin first declension are usually feminine:\n\nSome Latin neuter plural nouns joined the first declension as singular feminine nouns: \n\nWords ending in \"-or\" are feminine:\n\nThe names of fruit trees usually end in \"-era\" (a suffix derived from Latin -ARIA) and are usually feminine:\n\nThe genders of river names vary:\n\n\nUnlike most other Ibero-Romance varieties, Aragonese has partitive and locative clitic pronouns derived from the Latin \"inde\" and \"ibi\": \"en\"/\"ne\" and \"bi\"/\"i\"/\"ie\".\n\nSuch pronouns are present in most major Romance languages (Catalan \"en\" and \"hi\", Occitan \"ne\" and \"i\", French \"en\" and \"y\", and Italian \"ne\" and \"ci\"/\"vi\").\n\n\"En/ne\" is used for:\n\n\"Bi/i/ie\" is used for:\n\nAragonese was not written until the 12th and 13th centuries; the history \"Liber Regum\", \"Razón feita d'amor\", \"Libre dels tres reys d'orient\", and \"Vida de Santa María Egipcíaca\" date from this period.\n\nSince 1500, Spanish was the cultural language of Aragon; many Aragonese wrote in Spanish, and during the 17th century the Argensola brothers went to Castile to teach Spanish.\nAragonese became a popular village language. During the 17th century, popular literature in the language began to appear. In a 1650 Huesca literary contest, Aragonese poems were submitted by Matías Pradas, Isabel de Rodas and \"Fileno, montañés\".\n\nThe 19th and 20th centuries have seen a renaissance of Aragonese literature in several dialects. In 1844, Braulio Foz' novel \"Vida de Pedro Saputo\" was published in the Almudévar (southern) dialect. The 20th century featured Domingo Miral's costumbrist comedies and Veremundo Méndez Coarasa's poetry, both in Hecho (western) Aragonese; Cleto Torrodellas' poetry and Tonón de Baldomera's popular writings in the Graus (eastern) dialect and Arnal Cavero's costumbrist stories and Juana Coscujuela' novel \"A Lueca, historia d'una moceta d'o Semontano\", also in the southern dialect.\n\n\n", "id": "2813", "title": "Aragonese language"}
{"url": "https://en.wikipedia.org/wiki?curid=2815", "text": "Advanced Mobile Phone System\n\nAdvanced Mobile Phone System (AMPS) is an analog mobile cell phone system standard developed by Bell Labs, and officially introduced in the Americas on October 13, 1983, Israel in 1986, Australia in 1987, Singapore in 1988, and Pakistan in 1990. It was the primary analog mobile phone system in North America (and other locales) through the 1980s and into the 2000s. As of February 18, 2008, carriers in the United States were no longer required to support AMPS and companies such as AT&T and Verizon have discontinued this service permanently. AMPS was discontinued in Australia in September 2000, in Pakistan by October 2004, and Brazil by 2010.\n\nThe first cellular network efforts began at Bell Labs (which first proposed the idea of a cellular system in 1947 and continued to petition the FCC for channels through the 1950s and 1960s) and with research conducted at Motorola. \nIn 1960, John F. Mitchell,\nan electrical engineer who had graduated from the Illinois Institute of Technology, became Motorola's chief engineer for its mobile-communication products. Mitchell oversaw the development and marketing of the first pager to use transistors.\n\nMotorola had long produced mobile telephones for automobiles, but these large and heavy models consumed too much power to allow their use without the automobile's engine running. Mitchell's team, which included the gifted Dr. Martin Cooper, developed portable cellular telephony, and Mitchell was among the Motorola employees granted a patent for this work in 1973; the first call on the prototype connected, reportedly, to a wrong number.\n\nWhile Motorola was developing a cellular phone, from 1968-1983 Bell Labs worked out a system called Advanced Mobile Phone System (AMPS), which became the first cellular network standard in the United States. The first system was successfully deployed in Chicago, Illinois, in 1979. Motorola and others designed and built the cellular phones for this and other cellular systems.\n\nMartin Cooper, a former general manager for the systems division at Motorola, led a team that produced the DynaTAC8000x, the first commercially available cellular phone small enough to be easily carried, and made the first phone call from it, and later introduced the so-called Bag Phone.\n\nIn 1992 the first smartphone, called IBM Simon, used AMPS. Frank Canova led its design at IBM and it was demonstrated that year at the COMDEX computer-industry trade-show. A refined version of the product was marketed to consumers in 1994 by BellSouth under the name Simon Personal Communicator. The Simon was the first device that can be properly referred to as a \"smartphone\", even though that term was not yet coined.\n\nAMPS is a first-generation cellular technology that uses separate frequencies, or \"channels\", for each conversation (see Frequency-division multiple access (FDMA)). It therefore required considerable bandwidth for a large number of users. In general terms, AMPS was very similar to the older \"0G\" Improved Mobile Telephone Service, but used considerably more computing power in order to select frequencies, hand off conversations to PSTN lines, and handle billing and call setup.\n\nWhat really separated AMPS from older systems is the \"back end\" call setup functionality. In AMPS, the cell centers could flexibly assign channels to handsets based on signal strength, allowing the same frequency to be re-used in various locations without interference. This allowed a larger number of phones to be supported over a geographical area. AMPS pioneers coined the term \"cellular\" because of its use of small hexagonal \"cells\" within a system.\n\nAMPS suffered from many weaknesses compared to today's digital technologies. As an analog standard, it was susceptible to static and noise, and there was no protection from 'eavesdropping' using a scanner.\n\nIn the 1990s an epidemic of \"cloning\" cost the cellular carriers millions of dollars. An eavesdropper with specialized equipment could intercept a handset's ESN (Electronic Serial Number) and MDN or CTN (Mobile Directory Number or Cellular Telephone Number). The Electronic Serial Number, a 12-digit number sent by the handset to the cellular system for billing purposes, uniquely identified that phone on the network. The system then allowed or disallowed calls and or features based on its customer file. A person intercepting an ESN/MDN pair could clone the combination onto a different phone and use it in other areas for making calls without paying.\n\nCellular phone cloning became possible with off-the-shelf technology in the 1990s. Would-be cloners required three key items :\n\n\nThe radio, when tuned to the proper frequency, would receive the signal transmitted by the cell phone to be cloned, containing the phone's ESN/MDN pair. This signal would feed into the sound-card audio-input of the PC, and Banpaia would decode the ESN/MDN pair from this signal and display it on the screen. The hacker could then copy that data into the Oki 900 phone and reboot it, after which the phone network could not distinguish the Oki from the original phone whose signal had been received. This gave the cloner, through the Oki phone, the ability to use the mobile-phone service of the legitimate subscriber whose phone was cloned - just as if that phone had been physically stolen, except that the subscriber retained his or her phone, unaware that the phone had been cloned—at least until that subscriber received his or her next bill.\n\nThe problem became so large that some carriers required the use of a PIN before making calls. Eventually, the cellular companies initiated a system called RF Fingerprinting, whereby it could determine subtle differences in the signal of one phone from another and shut down some cloned phones. Some legitimate customers had problems with this though if they made certain changes to their own phone, such as replacing the battery and/or antenna. The Oki 900, the ultimate tool of cell-phone hackers, could listen in to AMPS phone-calls right out-of-the-box with no hardware modifications.\n\nAMPS was originally standardized by American National Standards Institute (ANSI) as EIA/TIA/IS-3. EIA/TIA/IS-3 was superseded by EIA/TIA-553 and TIA interim standard with digital technologies, the cost of wireless service is so low that the problem of cloning has virtually disappeared.\n\nAMPS cellular service operated in the 850 MHz Cellular band. For each market area, the United States Federal Communications Commission (FCC) allowed two licensees (networks) known as \"A\" and \"B\" carriers. Each carrier within a market used a specified \"block\" of frequencies consisting of 21 control channels and 395 voice channels. Originally, the B (wireline) side license was usually owned by the local phone company, and the A (non-wireline) license was given to wireless telephone providers.\n\nAt the inception of cellular in 1983, the FCC had granted each carrier within a market 333 channel pairs (666 channels total). By the late 1980s, the cellular industry's subscriber base had grown into the millions across America and it became necessary to add channels for additional capacity. In 1989, the FCC granted carriers an expansion from the previous 666 channels to the final 832 (416 pairs per carrier). The additional frequencies were from the band held in reserve for future (inevitable) expansion. These frequencies were immediately adjacent to the existing cellular band. These bands had previously been allocated to UHF TV channels 70–83.\n\nEach duplex channel was composed of 2 frequencies. 416 of these were in the 824–849 MHz range for transmissions from mobile stations to the base stations, paired with 416 frequencies in the 869–894 MHz range for transmissions from base stations to the mobile stations. Each cell site used a different subset of these channels than its neighbors to avoid interference. This significantly reduced the number of channels available at each site in real-world systems. Each AMPS channel had a one way bandwidth of 30 kHz, for a total of 60 kHz for each duplex channel.\n\nLaws were passed in the US which prohibited the FCC type acceptance and sale of any receiver which could tune the frequency ranges occupied by analog AMPS cellular services. Though the service is no longer offered, these laws remain in force.\n\nLater, many AMPS networks were partially converted to D-AMPS, often referred to as TDMA (though TDMA is a generic term that applies to many 2G cellular systems). D-AMPS, commercial deployed since 1993, was a digital, 2G standard used mainly by AT&T Mobility and U.S. Cellular in the United States, Rogers Wireless in Canada, Telcel in Mexico, Telecom Italia Mobile (TIM) in Brazil, VimpelCom in Russia, Movilnet in Venezuela, and Cellcom in Israel. In most areas, D-AMPS is no longer offered and has been replaced by more advanced digital wireless networks.\n\nAMPS and D-AMPS have now been phased out in favor of either CDMA2000 or GSM, which allow for higher capacity data transfers for services such as WAP, Multimedia Messaging System (MMS), and wireless Internet access. There are some phones capable of supporting AMPS, D-AMPS and GSM all in one phone (using the GAIT standard).\n\nIn 2002, the FCC decided to no longer require A and B carriers to support AMPS service as of February 18, 2008. All AMPS carriers have converted to a digital standard such as CDMA2000 or GSM. Digital technologies such as GSM and CDMA2000 support multiple voice calls on the same channel and offer enhanced features such as two-way text messaging and data services.\n\nUnlike in the United States, the Canadian Radio-television and Telecommunications Commission (CRTC) and Industry Canada have not set any requirement for maintaining AMPS service in Canada. Rogers Wireless has dismantled their AMPS (along with IS-136) network; the networks were shut down May 31, 2007. Bell Mobility and Telus Mobility, who operated AMPS networks in Canada, announced that they would observe the same timetable as outlined by the FCC in the United States, and as a result would not begin to dismantle their AMPS networks until after February 2008.\n\nOnStar relied heavily on North American AMPS service for its subscribers because, when the system was developed, AMPS offered the most comprehensive wireless coverage in the US. In 2006, ADT asked the FCC to extend the AMPS deadline due to many of their alarm systems still using analog technology to communicate with the control centers. Cellular companies who own an A or B license (such as Verizon and Alltel) were required to provide analog service until February 18, 2008. After that point, however, most cellular companies were eager to shut down AMPS and use the remaining channels for digital services. OnStar transitioned to digital service with the help of data transport technology developed by Airbiquity, but warned customers who could not be upgraded to digital service that their service would permanently expire on January 1, 2008.\n\n\n\n", "id": "2815", "title": "Advanced Mobile Phone System"}
{"url": "https://en.wikipedia.org/wiki?curid=2819", "text": "Aerodynamics\n\nAerodynamics, from Greek ἀήρ \"aer\" (air) + δυναμική (dynamics), the study of the motion of air, particularly its interaction with a solid object, such as an airplane wing. Aerodynamics is a sub-field of fluid dynamics and gas dynamics, and many aspects of aerodynamics theory are common to these fields. The term \"aerodynamics\" is often used synonymously with gas dynamics, the difference being that \"gas dynamics\" applies to the study of the motion of all gases, and is not limited to air. \nThe formal study of aerodynamics began in the modern sense in the eighteenth century, although observations of fundamental concepts such as aerodynamic drag were recorded much earlier. Most of the early efforts in aerodynamics were directed toward achieving heavier-than-air flight, which was first demonstrated by Wilbur and Orville Wright in 1903. Since then, the use of aerodynamics through mathematical analysis, empirical approximations, wind tunnel experimentation, and computer simulations has formed a rational basis for the development of heavier-than-air flight and a number of other technologies. Recent work in aerodynamics has focused on issues related to compressible flow, turbulence, and boundary layers and has become increasingly computational in nature.\n\nModern aerodynamics only dates back to the seventeenth century, but aerodynamic forces have been harnessed by humans for thousands of years in sailboats and windmills, and images and stories of flight appear throughout recorded history, such as the Ancient Greek legend of Icarus and Daedalus. Fundamental concepts of continuum, drag, and pressure gradients appear in the work of Aristotle and Archimedes.\n\nIn 1726, Sir Isaac Newton became the first person to develop a theory of air resistance, making him one of the first aerodynamicists. Dutch-Swiss mathematician Daniel Bernoulli followed in 1738 with \"Hydrodynamica\" in which he described a fundamental relationship between pressure, density, and flow velocity for incompressible flow known today as Bernoulli's principle, which provides one method for calculating aerodynamic lift. In 1757, Leonhard Euler published the more general Euler equations which could be applied to both compressible and incompressible flows. The Euler equations were extended to incorporate the effects of viscosity in the first half of the 1800s, resulting in the Navier-Stokes equations. The Navier-Stokes equations are the most general governing equations of fluid flow and but are difficult to solve for the flow around all but the simplest of shapes.\n\nIn 1799, Sir George Cayley became the first person to identify the four aerodynamic forces of flight (weight, lift, drag, and thrust), as well as the relationships between them, and in doing so outlined the path toward achieving heavier-than-air flight for the next century. In 1871, Francis Herbert Wenham constructed the first wind tunnel, allowing precise measurements of aerodynamic forces. Drag theories were developed by Jean le Rond d'Alembert, Gustav Kirchhoff, and Lord Rayleigh. In 1889, Charles Renard, a French aeronautical engineer, became the first person to reasonably predict the power needed for sustained flight. Otto Lilienthal, the first person to become highly successful with glider flights, was also the first to propose thin, curved airfoils that would produce high lift and low drag. Building on these developments as well as research carried out in their own wind tunnel, the Wright brothers flew the first powered airplane on December 17, 1903.\n\nDuring the time of the first flights, Frederick W. Lanchester, Martin Wilhelm Kutta, and Nikolai Zhukovsky independently created theories that connected circulation of a fluid flow to lift. Kutta and Zhukovsky went on to develop a two-dimensional wing theory. Expanding upon the work of Lanchester, Ludwig Prandtl is credited with developing the mathematics behind thin-airfoil and lifting-line theories as well as work with boundary layers.\n\nAs aircraft speed increased, designers began to encounter challenges associated with air compressibility at speeds near or greater than the speed of sound. The differences in air flows under such conditions leds to problems in aircraft control, increased drag due to shock waves, and the threat of structural failure due to aeroelastic flutter. The ratio of the flow speed to the speed of sound was named the Mach number after Ernst Mach who was one of the first to investigate the properties of supersonic flow. William John Macquorn Rankine and Pierre Henri Hugoniot independently developed the theory for flow properties before and after a shock wave, while Jakob Ackeret led the initial work of calculating the lift and drag of supersonic airfoils. Theodore von Kármán and Hugh Latimer Dryden introduced the term transonic to describe flow speeds around Mach 1 where drag increases rapidly. This rapid increase in drag led aerodynamicists and aviators to disagree on whether supersonic flight was achievable until the sound barrier was broken for the first time in 1947 using the Bell X-1 aircraft.\n\nBy the time the sound barrier was broken, aerodynamicists' understanding of the subsonic and low supersonic flow had matured. The Cold War prompted the design of an ever-evolving line of high performance aircraft. Computational fluid dynamics began as an effort to solve for flow properties around complex objects and has rapidly grown to the point where entire aircraft can be designed using computer software, with wind-tunnel tests followed by flight tests to confirm the computer predictions. Understanding of supersonic and hypersonic aerodynamics has matured since the 1960s, and the goals of aerodynamicists have shifted from the behavior of fluid flow the engineering of a vehicle such that it interacts pedictably with the fluid flow. Designing aircraft for supersonic and hypersonic conditions, as well as the desire to improve the aerodynamic efficiency of current aircraft and propulsion systems, continues to motivate new research in aerodynamics, while work continues to be done on important problems in basic aerodynamic theory related to flow turbulence and the existence and uniqueness of analytical solutions to the Navier-Stokes equations.\n\nUnderstanding the motion of air around an object (often called a flow field) enables the calculation of forces and moments acting on the object. In many aerodynamics problems, the forces of interest are the fundamental forces of flight: lift, drag, thrust, and weight. Of these, lift and drag are aerodynamic forces, i.e. forces due to air flow over a solid body. Calculation of these quantities is often founded upon the assumption that the flow field behaves as a continuum. Continuum flow fields are characterized by properties such as flow velocity, pressure, density, and temperature, which may be functions of position and time. These properties may be directly or indirectly measured in aerodynamics experiments or calculated starting with the equations for conservation of mass, momentum, and energy in air flows. Density, flow velocity, and an additional property, viscosity, are used to classify flow fields.\n\nFlow velocity is used to classify flows according to speed regime. Subsonic flows are flow fields in which the air speed field is always below the local speed of sound. Transonic flows include both regions of subsonic flow and regions in which the local flow speed is greater than the local speed of sound. Supersonic flows are defined to be flows in which the flow speed is greater than the speed of sound everywhere. A fourth classification, hypersonic flow, refers to flows where the flow speed is much greater than the speed of sound. Aerodynamicists disagree on the precise definition of hypersonic flow.\n\nCompressible flow accounts for varying density within the flow. Subsonic flows are often idealized as incompressible, i.e. the density is assumed to be constant. Transonic and supersonic flows are compressible, and calculations that neglect the changes of density in these flow fields will yield inaccurate results.\n\nViscosity is associated with the frictional forces in a flow. In some flow fields, viscous effects are very small, and approximate solutions may safely neglect viscous effects. These approximations are called inviscid flows. Flows for which viscosity is not neglected are called viscous flows. Finally, aerodynamic problems may also be classified by the flow environment. External aerodynamics is the study of flow around solid objects of various shapes (e.g. around an airplane wing), while internal aerodynamics is the study of flow through passages inside solid objects (e.g. through a jet engine).\n\nUnlike liquids and solids, gases are composed of discrete molecules which occupy only a small fraction of the volume filled by the gas. On a molecular level, flow fields are made up of many individual collisions between gas molecules and between gas molecules and solid surfaces. However, in most aerodynamics applications, the discrete molecular nature of gases is ignored, and the flow field is assumed to behave as a continuum. This assumption allows fluid properties such as density and flow velocity to be defined everywhere within the flow.\n\nThe validity of the continuum assumption is dependent on the density of the gas and the application in question. For the continuum assumption to be valid, the mean free path length must be much smaller than the length scale of the application in question. For example, many aerodynamics applications deal with aircraft flying in atmospheric conditions, where the mean free path length is on the order of micrometers and where the body is orders of magnitude larger. In these cases, the length scale of the aircraft ranges from a few meters to a few tens of meters, which is much larger than the mean free path length. For such applications, the continuum assumption is reasonable. The continuum assumption is less valid for extremely low-density flows, such as those encountered by vehicles at very high altitudes (e.g. 300,000 ft/90 km) or satellites in Low Earth orbit. In those cases, statistical mechanics is a more accurate method of solving the problem than is continuum aerodynamics. The Knudsen number can be used to guide the choice between statistical mechanics and the continuous formulation of aerodynamics.\n\nThe assumption of a fluid continuum allows problems in aerodynamics to be solved using fluid dynamics conservation laws. Three conservation principles are used: \n\nThe ideal gas law or another such equation of state is often used in conjunction with these equations to form a determined system that allows the solution for the unknown variables.\n\nAerodynamic problems are classified by the flow environment or properties of the flow, including flow speed, compressibility, and viscosity. \"External\" aerodynamics is the study of flow around solid objects of various shapes. Evaluating the lift and drag on an airplane or the shock waves that form in front of the nose of a rocket are examples of external aerodynamics. \"Internal\" aerodynamics is the study of flow through passages in solid objects. For instance, internal aerodynamics encompasses the study of the airflow through a jet engine or through an air conditioning pipe.\n\nAerodynamic problems can also be classified according to whether the flow speed is below, near or above the speed of sound. A problem is called subsonic if all the speeds in the problem are less than the speed of sound, transonic if speeds both below and above the speed of sound are present (normally when the characteristic speed is approximately the speed of sound), supersonic when the characteristic flow speed is greater than the speed of sound, and hypersonic when the flow speed is much greater than the speed of sound. Aerodynamicists disagree over the precise definition of hypersonic flow; a rough definition considers flows with Mach numbers above 5 to be hypersonic.\n\nThe influence of viscosity on the flow dictates a third classification. Some problems may encounter only very small viscous effects, in which case viscosity can be considered to be negligible. The approximations to these problems are called inviscid flows. Flows for which viscosity cannot be neglected are called viscous flows.\n\nAn incompressible flow is a flow in which density is constant in both time and space. Although all real fluids are compressible, a flow is often approximated as incompressible if the effect of the density changes cause only small changes to the calculated results. This is more likely to be true when the flow speeds are significantly lower than the speed of sound. Effects of compressibility are more significant at speeds close to or above the speed of sound. The Mach number is used to evaluate whether the incompressibility can be assumed, otherwise the effects of compressibility must be included.\n\nSubsonic (or low-speed) aerodynamics describes fluid motion in flows which are much lower than the speed of sound everywhere in the flow. There are several branches of subsonic flow but one special case arises when the flow is inviscid, incompressible and irrotational. This case is called potential flow and allows the differential equations that describe the flow to be a simplified version of the equations of fluid dynamics, thus making available to the aerodynamicist a range of quick and easy solutions.\n\nIn solving a subsonic problem, one decision to be made by the aerodynamicist is whether to incorporate the effects of compressibility. Compressibility is a description of the amount of change of density in the flow. When the effects of compressibility on the solution are small, the assumption that density is constant may be made. The problem is then an incompressible low-speed aerodynamics problem. When the density is allowed to vary, the flow is called compressible. In air, compressibility effects are usually ignored when the Mach number in the flow does not exceed 0.3 (about 335 feet (102 m) per second or 228 miles (366 km) per hour at 60 °F (16 °C)). Above Mach 0.3, the problem flow should be described using compressible aerodynamics.\n\nAccording to the theory of aerodynamics, a flow is considered to be compressible if the density changes along a streamline. This means that – unlike incompressible flow – changes in density are considered. In general, this is the case where the Mach number in part or all of the flow exceeds 0.3. The Mach 0.3 value is rather arbitrary, but it is used because gas flows with a Mach number below that value demonstrate changes in density of less than 5%. Furthermore, that maximum 5% density change occurs at the stagnation point (the point on the object where flow speed is zero), while the density changes around the rest of the object will be significantly lower. Transonic, supersonic, and hypersonic flows are all compressible flows.\n\nThe term Transonic refers to a range of flow velocities just below and above the local speed of sound (generally taken as Mach 0.8–1.2). It is defined as the range of speeds between the critical Mach number, when some parts of the airflow over an aircraft become supersonic, and a higher speed, typically near Mach 1.2, when all of the airflow is supersonic. Between these speeds, some of the airflow is supersonic, while some of the airflow is not supersonic.\n\nSupersonic aerodynamic problems are those involving flow speeds greater than the speed of sound. Calculating the lift on the Concorde during cruise can be an example of a supersonic aerodynamic problem.\n\nSupersonic flow behaves very differently from subsonic flow. Fluids react to differences in pressure; pressure changes are how a fluid is \"told\" to respond to its environment. Therefore, since sound is in fact an infinitesimal pressure difference propagating through a fluid, the speed of sound in that fluid can be considered the fastest speed that \"information\" can travel in the flow. This difference most obviously manifests itself in the case of a fluid striking an object. In front of that object, the fluid builds up a stagnation pressure as impact with the object brings the moving fluid to rest. In fluid traveling at subsonic speed, this pressure disturbance can propagate upstream, changing the flow pattern ahead of the object and giving the impression that the fluid \"knows\" the object is there by seemingly adjusting its movement and is flowing around it. In a supersonic flow however, the pressure disturbance cannot propagate upstream. Thus, when the fluid finally reaches the object it strikes it and the fluid is forced to change its properties – temperature, density, pressure, and Mach number—in an extremely violent and irreversible fashion called a shock wave. The presence of shock waves, along with the compressibility effects of high-flow velocity (see Reynolds number) fluids, is the central difference between the supersonic and subsonic aerodynamics regimes.\n\nIn aerodynamics, hypersonic speeds are speeds that are highly supersonic. In the 1970s, the term generally came to refer to speeds of Mach 5 (5 times the speed of sound) and above. The hypersonic regime is a subset of the supersonic regime. Hypersonic flow is characterized by high temperature flow behind a shock wave, viscous interaction, and chemical dissociation of gas.\n\nThe incompressible and compressible flow regimes produce many associated phenomena, such as boundary layers and turbulence.\n\nThe concept of a boundary layer is important in many problems in aerodynamics. The viscosity and fluid friction in the air is approximated as being significant only in this thin layer. This assumption makes the description of such aerodynamics much more tractable mathematically.\n\nIn aerodynamics, turbulence is characterized by chaotic property changes in the flow. These include low momentum diffusion, high momentum convection, and rapid variation of pressure and flow velocity in space and time. Flow that is not turbulent is called laminar flow.\n\nAerodynamics is important in a number of applications other than aerospace engineering. It is a significant factor in any type of vehicle design, including automobiles. It is important in the prediction of forces and moments acting on sailing vessels. It is used in the design of mechanical components such as hard drive heads. Structural engineers also use aerodynamics, and particularly aeroelasticity, to calculate wind loads in the design of large buildings and bridges. Urban aerodynamics seeks to help town planners and designers improve comfort in outdoor spaces, create urban microclimates and reduce the effects of urban pollution. The field of environmental aerodynamics describes the ways atmospheric circulation and flight mechanics affect ecosystems. The aerodynamics of internal passages is important in heating/ventilation, gas piping, and in automotive engines where detailed flow patterns strongly affect the performance of the engine.\nPeople who do wind turbine design use aerodynamics.\nA few aerodynamic equations are used as part of numerical weather prediction.\n\nGeneral aerodynamics\n\nSubsonic aerodynamics\n\nTransonic aerodynamics\n\nSupersonic aerodynamics\n\nHypersonic aerodynamics\n\nHistory of aerodynamics\n\nAerodynamics related to engineering\n\n\"Ground vehicles\"\n\n\"Fixed-wing aircraft\"\n\n\"Helicopters\"\n\n\"Missiles\"\n\n\"Model aircraft\"\n\nRelated branches of aerodynamics\n\n\"Aerothermodynamics\"\n\n\"Aeroelasticity\"\n\n\"Boundary layers\"\n\n\"Turbulence\"\n\n", "id": "2819", "title": "Aerodynamics"}
{"url": "https://en.wikipedia.org/wiki?curid=2820", "text": "Andreas Schlüter\n\nAndreas Schlüter (1659 or 1660; May 1714) was a German baroque sculptor and architect, active in Poland, Berlin and Saint Petersburg.\n\nAndreas Schlüter was born probably in Hamburg His early life is obscure as at least three different persons of that name are documented. The records of St. Michaelis Church, Hamburg show that an Andreas Schlüter, son of sculptor Gerhart Schlüter, had been baptized there on 22 May 1664. Documents from Danzig (Gdańsk) reported that an Andreas Schlüter \"(senior)\" had worked 1640-1652 in Danzig's Jopengasse lane (today's ulica Piwna). Possibly born in 1640, an \"Andres Schliter\" is recorded as apprentice on 9 May 1656 by the mason's guild. Other sources state 1659 as year of birth.\n\nHe probably did spend several years abroad as Journeyman. His first work, in 1675, may have been epitaphs of the Dukes Sambor and Mestwin in the dome of Pelplin monastery.\n\nSchlüter's first known work was the decoration of the facade of the Danzig Royal Chapel, in 1681. He later created statues for King John III Sobieski's Wilanów Palace in Warsaw and sepulchral sculptures in Żółkiew (Zhovkva). In 1689, he moved to Warsaw and made the pediment reliefs and sculptural work of Krasiński Palace.\n\nSchlüter was invited to Berlin in 1694 by Eberhard von Danckelmann to work as court sculptor at the armory (\"Zeughaus\") for Elector Frederick III. His sculpted decorations are a masterpiece of baroque expression and pathos. While the more visible reliefs on the outside had to praise fighting, the statues of dying warriors in the interior denounced war and gave an indication of his pacifist religious beliefs (he is said to have been a Mennonite). Travelling through Italy in 1696, he studied the work of masters like Michelangelo Buonarroti and Gian Lorenzo Bernini.\n\nSchlüter also worked as an architect and built many state buildings in Berlin in his role as \"Hofbaumeister\" (Court Architect), which he lost when one tower showed signs of a weak fundament. He also served as director of the Prussian Academy of Arts from 1702 to 1704, after which he began concentrating on sculpting again, as \"Hofbildhauer\" (Court Sculptor). His most important equestrian sculpture is that of the \"Great Elector\", Frederick William of Brandenburg, cast in 1708 and placed at \"Lange Brücke\" near the Berlin City Palace, now situated in the honor court before Charlottenburg Palace.\n\nThe Berlin City Palace, and many of his works, were partially destroyed by bombing in World War II and by the subsequent Communist regime. A similar fate probably befell the Amber Room, made between 1701 and 1709, Schlüter's most famous work of architecture.\n\nIn 1713 Schlüter's fame brought him to work for Tsar Peter the Great in Saint Petersburg, where he died of an illness after creating several designs. Together with Johann Friedrich Braunstein, he designed the Grand Palace and Monplaisir Palace in Peterhof Palace Complex. Also the city's oldest building, Kikin's Palace, and the reliefs at the Summer Palace are attributed to him. This way he became an important figure of Petrine Baroque.\n\n\n", "id": "2820", "title": "Andreas Schlüter"}
{"url": "https://en.wikipedia.org/wiki?curid=2822", "text": "Ash\n\nAsh or ashes are the solid remains of fires. Specifically, it refers to all non-aqueous, non-gaseous residues that remain after something is burned. In analytical chemistry, in order to analyse the mineral and metal content of chemical samples, ash is the non-gaseous, non-liquid residue after a complete combustion.\n\nAshes as the end product of incomplete combustion will be mostly mineral, but usually still contain an amount of combustible organic or other oxidizable residues. The best-known type of ash is wood ash, as a product of wood combustion in campfires, fireplaces, etc. The darker the wood ashes, the higher the content of remaining charcoal will be due to incomplete combustion.\n\nLike soap, ash is also a disinfecting agent (alkaline). The World Health Organization recommended ash or sand as alternative to soap when soap is not available.\n\n\n", "id": "2822", "title": "Ash"}
{"url": "https://en.wikipedia.org/wiki?curid=2823", "text": "Antiderivative\n\nIn calculus, an antiderivative, primitive function, primitive integral or indefinite integral of a function is a differentiable function whose derivative is equal to the original function . This can be stated symbolically as ′ . The process of solving for antiderivatives is called antidifferentiation (or indefinite integration) and its opposite operation is called differentiation, which is the process of finding a derivative.\n\nAntiderivatives are related to definite integrals through the fundamental theorem of calculus: the definite integral of a function over an interval is equal to the difference between the values of an antiderivative evaluated at the endpoints of the interval.\n\nThe discrete equivalent of the notion of antiderivative is antidifference.\n\nThe function \"F\"(\"x\") = \"x\"/3 is an antiderivative of \"f\"(\"x\") = \"x\", as the derivative of \"x\"/3 is \"x\". As the derivative of a constant is zero, \"x\" will have an infinite number of antiderivatives, such as \"x\"/3, \"x\"/3 + 1, \"x\"/3 - 2, etc. Thus, all the antiderivatives of \"x\" can be obtained by changing the value of C in \"F\"(\"x\") = \"x\"/3 + \"C\"; where \"C\" is an arbitrary constant known as the constant of integration. Essentially, the graphs of antiderivatives of a given function are vertical translations of each other; each graph's vertical location depending upon the value of \"C\".\n\nIn physics, the integration of acceleration yields velocity plus a constant. The constant is the initial velocity term that would be lost upon taking the derivative of velocity because the derivative of a constant term is zero. This same pattern applies to further integrations and derivatives of motion (position, velocity, acceleration, and so on).\n\nAntiderivatives are important because they can be used to compute definite integrals, using the fundamental theorem of calculus: if \"F\" is an antiderivative of the integrable function \"f\" over the interval then:\n\nBecause of this, each of the infinitely many antiderivatives of a given function \"f\" is sometimes called the \"general integral\" or \"indefinite integral\" of \"f\" and is written using the integral symbol with no bounds:\n\nIf \"F\" is an antiderivative of \"f\", and the function \"f\" is defined on some interval, then every other antiderivative \"G\" of \"f\" differs from \"F\" by a constant: there exists a number \"C\" such that \"G\"(\"x\") = \"F\"(\"x\") + \"C\" for all \"x\". \"C\" is called the arbitrary constant of integration. If the domain of \"F\" is a disjoint union of two or more intervals, then a different constant of integration may be chosen for each of the intervals. For instance\n\nis the most general antiderivative of formula_4 on its natural domain formula_5\n\nEvery continuous function \"f\" has an antiderivative, and one antiderivative \"F\" is given by the definite integral of \"f\" with variable upper boundary:\nVarying the lower boundary produces other antiderivatives (but not necessarily all possible antiderivatives). This is another formulation of the fundamental theorem of calculus.\n\nThere are many functions whose antiderivatives, even though they exist, cannot be expressed in terms of elementary functions (like polynomials, exponential functions, logarithms, trigonometric functions, inverse trigonometric functions and their combinations). Examples of these are\n\"From left to right, the first four are the error function, the Fresnel function, the trigonometric integral, and the logarithmic integral function.\"\n\nSee also Differential Galois theory for a more detailed discussion.\n\nFinding antiderivatives of elementary functions is often considerably harder than finding their derivatives. For some elementary functions, it is impossible to find an antiderivative in terms of other elementary functions. See the articles on elementary functions and nonelementary integral for further information.\n\nThere are various methods available:\n\n\nComputer algebra systems can be used to automate some or all of the work involved in the symbolic techniques above, which is particularly useful when the algebraic manipulations involved are very complex or lengthy. Integrals which have already been derived can be looked up in a table of integrals.\n\nNon-continuous functions can have antiderivatives. While there are still open questions in this area, it is known that:\n\nAssuming that the domains of the functions are open intervals:\n\n\n\n", "id": "2823", "title": "Antiderivative"}
{"url": "https://en.wikipedia.org/wiki?curid=2824", "text": "Alphabet song\n\nAn alphabet song is any of various songs used to teach children the alphabet. Alphabet songs typically follow the alphabetic principle (though the phonics method offers variants). In languages such as English with morphophonemic variation (e.g. \"cake\" is , not ), an alphabet song usually chooses a particular pronunciation for each letter in the alphabet and also typically for some words in the song.\n\n\"The A.B.C.\" or \"A.B.Cs\" is one of the best-known English language alphabet songs, and perhaps the one most frequently referred to as \"the alphabet song\", especially in the United States.\nThe song was first copyrighted in 1835 by the Boston-based music publisher Charles Bradlee, and given the title \"The A.B.C., a German air with variations for the flute with an easy accompaniment for the piano forte\". The musical arrangement was attributed to Louis Le Maire (sometimes Lemaire), an 18th-century composer. This was \"Entered according to act of Congress, in the year 1835, by C. Bradlee, in the clerk's office of the District Court of Massachusetts\", according to the Newberry Library, which also says, \"The theme is that used by Mozart for his piano variations, Ah, vous dirai-je, maman.\" This tune is the same as the tune for \"Twinkle, Twinkle, Little Star\" and \"Baa, Baa, Black Sheep\".\n\nLyrics: \"(each line represents two measures, or eight beats)\"\n\nIn the United States, Z is pronounced \"zee\"; in most other English-speaking countries (such as Canada, the UK and Australia) it is pronounced \"zed\". Generally, the absent \"zee\"-rhyme is not missed, although some children use a \"zee\" pronunciation in the rhyme which they would not use elsewhere. Variants of the song exist to accommodate the \"zed\" pronunciation. One variation shortens the second line and lengthens the last, to form a near-rhyme between N and zed:\n\nAlternate Zed Version:\n\nAnother alternate Zed version:\n\nNote that the third line is lengthened and the fourth line is shortened, to compensate for the Dutch pronunciations.\n\nA French-language version of the song is also taught in Canada, with generally no alterations to the melody except in the final line that requires adjustment to accommodate the two-syllable pronunciation of the French \"y\".\n\nBecause the English language has 40 sounds and only 26 letters, children and beginning readers also need to learn the different sounds (phonemes) associated with each letter. Many songs have been written to teach phonemic awareness and they are usually referred to as alphabet songs.\n\nThere are also songs that go through the alphabet, making some of the letters stand for something in the process. An example was recorded in 1948, by Buddy Kaye, Fred Wise, Sidney Lippman, and later Perry Como, called \"A, You're Adorable\" (also known as \"The Alphabet Love Song\"):\n\nA newer example of this is from the musical \"Matilda\". 'School Song' is an acrostic that spells out the alphabet phonetically.\n\nThe group Wee Sing released an alphabet song with the letters in reverse order. It is called ZYXs.\n\nThe Canadian children's TV series \"The Big Comfy Couch\" used a version of the song in the episode \"Backwards\" (Season 4, episode 1.) \n\nComedian Soupy Sales released a song in 1966 called \"Backwards Alphabet\" which contained the reverse alphabet in lyrical style. The original version of the song was performed by actress Judi Rolin with The Smothers Brothers in the 1966 teleplay adaptation of \"Alice Through the Looking Glass\".\n\nIn the opening scene of the 1992 episode of \"Martin\", Martin sings the song in the dark radio station in season 1's \"Dead Men Don't Flush\".\n\n\n", "id": "2824", "title": "Alphabet song"}
{"url": "https://en.wikipedia.org/wiki?curid=2826", "text": "Antigonid dynasty\n\nThe Antigonid dynasty (; ) was a dynasty of Hellenistic kings descended from Alexander the Great's general Antigonus I Monophthalmus (\"the One-eyed\").\n\nSucceeding the Antipatrid dynasty in much of Macedonia, Antigonus ruled mostly over Asia Minor and northern Syria. His attempts to take control of the whole of Alexander's empire led to his defeat and death at the Battle of Ipsus in 301 BC. Antigonus's son Demetrius I Poliorcetes survived the battle, and managed to seize control of Macedon itself a few years later, but eventually lost his throne, dying as a prisoner of Seleucus I Nicator. After a period of confusion, Demetrius's son Antigonus II Gonatas was able to establish the family's control over the old Kingdom of Macedon, as well as over most of the Greek city-states, by 276 BC.\n\nIt was one of four dynasties established by Alexander's successors, the others being the Seleucid dynasty, Ptolemaic dynasty and Attalid dynasty. The last scion of the dynasty, Perseus of Macedon, who reigned between 179-168 BC, proved unable to stop the advancing Roman legions and Macedon's defeat at the Battle of Pydna signaled the end of the dynasty.\n\nThe ruling members of the Antigonid dynasty were:\n\nThe Greek rebel against Rome and last King of Macedonia, Andriscus, claimed to be the son of Perseus.\n\n", "id": "2826", "title": "Antigonid dynasty"}
{"url": "https://en.wikipedia.org/wiki?curid=2827", "text": "Abingdon\n\nAbingdon may refer to:\n\nIn Australia :\n\nIn Britain:\n\nIn Canada:\n\nIn the United States:\n\nIn the Galapagos Islands:\n\n\n", "id": "2827", "title": "Abingdon"}
{"url": "https://en.wikipedia.org/wiki?curid=2830", "text": "Abjuration\n\nAbjuration is the solemn repudiation, abandonment, or renunciation by or upon oath, often the renunciation of citizenship or some other right or privilege. The term comes from the Latin \"abjurare\", \"to forswear\".\n\nAbjuration of the realm was a type of abjuration in ancient English law. The person taking the oath swore to leave the country directly and promptly, never to return to the kingdom unless by permission of the sovereign. This was often taken by fugitives who had taken sanctuary:\n\nNear the start of the English Civil War, on 18 August 1643 Parliament passed \"An Ordinance for Explanation of a former Ordinance for Sequestration of Delinquents Estates with some Enlargements.\" The enlargements included an oath which became known as the \"Oath of Abjuration\":\nIn 1656-7, it was reissued in what was for Catholics an even more objectionable form. Everyone was to be \"adjudged a Papist\" who refused this oath, and the consequent penalties began with the confiscation of two thirds of the recusant's goods, and went on to deprive him of almost every civic right.\n\nThe Catholic Encyclopaedia make the point that the oath and the penalties were so severe that it stopped the efforts of the Gallicanizing party among the English Catholics, who had been ready to offer forms of submission similar to the old oath of Allegiance, which was condemned anew about this time by Pope Innocent X.\n\nIn England (and after 1707 Great Britain) the Oath of Abjuration denied the royal title of James II's heirs (i.e. the direct Catholic descendent of the House of Stuart exiled after the Glorious Revolution in 1688). In England, an Oath of Abjuration was taken by Members of Parliament, clergy, and laymen, pledging to support the current British monarch and repudiated the right of the Stuarts and other claimants to the throne. This oath was imposed under William III, George I and George III. It was superseded by the oath of allegiance. In Ireland the oath was imposed of state office holders, teachers and lawyers, and on clergy of the established church in from 1703, the following year it was on all Irish voters and from 1709 it could be demanded of any adult male by a magistrate.\n\nAnother famous abjuration was brought about by the Plakkaat van Verlatinghe of July 26, 1581, the formal declaration of independence of the Low Countries from the Spanish king, Philip II. This oath was the climax of the Eighty Years' War (Dutch Revolt).\n", "id": "2830", "title": "Abjuration"}
{"url": "https://en.wikipedia.org/wiki?curid=2833", "text": "Abitibi\n\nAbitibi may refer to:\n\n", "id": "2833", "title": "Abitibi"}
{"url": "https://en.wikipedia.org/wiki?curid=2834", "text": "A Vindication of the Rights of Woman\n\nA Vindication of the Rights of Woman: with Strictures on Political and Moral Subjects (1792), written by the 18th-century British proto-feminist Mary Wollstonecraft, is one of the earliest works of feminist philosophy. In it, Wollstonecraft responds to those educational and political theorists of the 18th century who did not believe women should have an education. She argues that women ought to have an education commensurate with their position in society, claiming that women are essential to the nation because they educate its children and because they could be \"companions\" to their husbands, rather than mere wives. Instead of viewing women as ornaments to society or property to be traded in marriage, Wollstonecraft maintains that they are human beings deserving of the same fundamental rights as men.\n\nWollstonecraft was prompted to write the \"Rights of Woman\" after reading Charles Maurice de Talleyrand-Périgord's 1791 report to the French National Assembly, which stated that women should only receive a domestic education; she used her commentary on this specific event to launch a broad attack against sexual double standards and to indict men for encouraging women to indulge in excessive emotion. Wollstonecraft wrote the \"Rights of Woman\" hurriedly to respond directly to ongoing events; she intended to write a more thoughtful second volume but died before completing it.\n\nWhile Wollstonecraft does call for equality between the sexes in particular areas of life, such as morality, she does not explicitly state that men and women are equal. Her ambiguous statements regarding the equality of the sexes have since made it difficult to classify Wollstonecraft as a modern feminist, particularly since the word and the concept were unavailable to her. Although it is commonly assumed now that the \"Rights of Woman\" was unfavourably received, this is a modern misconception based on the belief that Wollstonecraft was as reviled during her lifetime as she became after the publication of William Godwin's \"Memoirs of the Author of A Vindication of the Rights of Woman\" (1798). The \"Rights of Woman\" was actually well received when it was first published in 1792. One biographer has called it \"perhaps the most original book of [Wollstonecraft's] century\".\n\n\"A Vindication of the Rights of Woman\" was written against the tumultuous background of the French Revolution and the debates that it spawned in Britain. In a lively and sometimes vicious pamphlet war, now referred to as the \"Revolution Controversy\", British political commentators addressed topics ranging from representative government to human rights to the separation of church and state, many of these issues having been raised in France first. Wollstonecraft first entered this fray in 1790 with \"A Vindication of the Rights of Men\", a response to Edmund Burke's \"Reflections on the Revolution in France\" (1790). In his \"Reflections\", Burke criticised the view of many British thinkers and writers who had welcomed the early stages of the French revolution. While they saw the revolution as analogous to Britain's own Glorious Revolution in 1688, which had restricted the powers of the monarchy, Burke argued that the appropriate historical analogy was the English Civil War (1642–1651) in which Charles I had been executed in 1649. He viewed the French revolution as the violent overthrow of a legitimate government. In \"Reflections\" he argues that citizens do not have the right to revolt against their government because civilisation is the result of social and political consensus; its traditions cannot be continually challenged—the result would be anarchy. One of the key arguments of Wollstonecraft's \"Rights of Men\", published just six weeks after Burke's \"Reflections\", is that rights cannot be based on tradition; rights, she argues, should be conferred because they are reasonable and just, regardless of their basis in tradition.\n\nWhen Charles Maurice de Talleyrand-Périgord presented his \"Rapport sur l'instruction publique\" (1791) to the National Assembly in France, Wollstonecraft was galvanised to respond. In his recommendations for a national system of education, Talleyrand had written:\n\nLet us bring up women, not to aspire to advantages which the Constitution denies them, but to know and appreciate those which it guarantees them . . . Men are destined to live on the stage of the world. A public education suits them: it early places before their eyes all the scenes of life: only the proportions are different. The paternal home is better for the education of women; they have less need to learn to deal with the interests of others, than to accustom themselves to a calm and secluded life.\nWollstonecraft dedicated the \"Rights of Woman\" to Talleyrand: \"Having read with great pleasure a pamphlet which you have lately published, I dedicate this volume to you; to induce you to reconsider the subject, and maturely weigh what I have advanced respecting the rights of woman and national education.\" At the end of 1791, French feminist Olympe de Gouges had published her \"Declaration of the Rights of Woman and the Female Citizen\", and the question of women's rights became central to political debates in both France and Britain.\n\nThe \"Rights of Woman\" is an extension of Wollstonecraft's arguments in the \"Rights of Men\". In the \"Rights of Men\", as the title suggests, she is concerned with the rights of particular men (18th-century British men) while in the \"Rights of Woman\", she is concerned with the rights afforded to \"woman\", an abstract category. She does not isolate her argument to 18th-century women or British women. The first chapter of the \"Rights of Woman\" addresses the issue of natural rights and asks who has those inalienable rights and on what grounds. She answers that since natural rights are given by God, for one segment of society to deny them to another segment is a sin. \"The Rights of Woman\" thus engages not only specific events in France and in Britain but also larger questions being raised by political philosophers such as John Locke and Jean-Jacques Rousseau.\n\nWollstonecraft did not employ the formal argumentation or logical prose style common to 18th-century philosophical writing when composing her own works. The \"Rights of Woman\" is a long essay that introduces all of its major topics in the opening chapters and then repeatedly returns to them, each time from a different point of view. It also adopts a hybrid tone that combines rational argument with the fervent rhetoric of sensibility.\n\nIn the 18th century, \"sensibility\" was a physical phenomenon that came to be attached to a specific set of moral beliefs. Physicians and anatomists believed that the more sensitive people's nerves, the more emotionally affected they would be by their surroundings. Since women were thought to have keener nerves than men, it was also believed that women were more emotional than men. The emotional excess associated with sensibility also theoretically produced an ethic of compassion: those with sensibility could easily sympathise with people in pain. Thus historians have credited the discourse of sensibility and those who promoted it with the increased humanitarian efforts, such as the movement to abolish the slave trade. But sensibility also paralysed those who had too much of it; as scholar G. J. Barker-Benfield explains, \"an innate refinement of nerves was also identifiable with greater suffering, with weakness, and a susceptibility to disorder\".\n\nBy the time Wollstonecraft was writing the \"Rights of Woman\", sensibility had already been under sustained attack for a number of years. Sensibility, which had initially promised to draw individuals together through sympathy, was now viewed as \"profoundly separatist\"; novels, plays, and poems that employed the language of sensibility asserted individual rights, sexual freedom, and unconventional familial relationships based only upon feeling. Furthermore, as Janet Todd, another scholar of sensibility, argues, \"to many in Britain the cult of sensibility seemed to have feminized the nation, given women undue prominence, and emasculated men.\"\n\nOne of Wollstonecraft's central arguments in the \"Rights of Woman\" is that women should be educated rationally to give them the opportunity to contribute to society. In the 18th century, it was often assumed by both educational philosophers and conduct book writers, who wrote what one might think of as early self-help books, that women were incapable of rational or abstract thought. Women, it was believed, were too susceptible to sensibility and too fragile to be able to think clearly. Wollstonecraft, along with other female reformers such as Catharine Macaulay and Hester Chapone, maintained that women were indeed capable of rational thought and deserved to be educated. She argued this point in her own conduct book, \"Thoughts on the Education of Daughters\" (1787), in her children's book, \"Original Stories from Real Life\" (1788), as well as in the \"Rights of Woman\".\n\nStating in her preface that \"my main argument is built on this simple principle, that if [woman] be not prepared by education to become the companion of man, she will stop the progress of knowledge and virtue; for truth must be common to all\", Wollstonecraft contends that society will degenerate without educated women, particularly because mothers are the primary educators of young children. She attributes the problem of uneducated women to men and \"a false system of education, gathered from the books written on this subject by men who [consider] females rather as women than human creatures\". Women are capable of rationality; it only appears that they are not, because men have refused to educate them and encouraged them to be frivolous (Wollstonecraft describes silly women as \"spaniels\" and \"toys\"). While stressing it is of the same kind, she entertains the notion that women might not be able to attain the same degree of knowledge that men do.\n\nWollstonecraft attacks conduct book writers such as James Fordyce and John Gregory as well as educational philosophers such as Jean-Jacques Rousseau who argue that a woman does not need a rational education. (Rousseau famously argues in \"\" (1762) that women should be educated for the pleasure of men; Wollstonecraft, infuriated by this argument, attacks not only it but also Rousseau himself.) Intent on illustrating the limitations that contemporary educational theory placed upon women, Wollstonecraft writes, \"taught from their infancy that beauty is woman's sceptre, the mind shapes itself to the body, and, roaming round its gilt cage, only seeks to adorn its prison\", implying that without this damaging ideology, which encourages young women to focus their attention on beauty and outward accomplishments, they could achieve much more. Wives could be the rational \"companions\" of their husbands and even pursue careers should they so choose: \"women might certainly study the art of healing, and be physicians as well as nurses. And midwifery, decency seems to allot to them . . . they might, also, study politics . . . Business of various kinds, they might likewise pursue.\"\n\nFor Wollstonecraft, \"the most perfect education\" is \"an exercise of the understanding as is best calculated to strengthen the body and form the heart. Or, in other words, to enable the individual to attach such habits of virtue as will render it independent.\" In addition to her broad philosophical arguments, Wollstonecraft lays out a specific plan for national education to counter Talleyrand's. In Chapter 12, \"On National Education,\" she proposes that children be sent to day schools as well as given some education at home \"to inspire a love of home and domestic pleasures,\" and that such schools be free for children \"five to nine years of age.\" She also maintains that schooling should be co-educational, contending that men and women, whose marriages are \"the cement of society,\" should be \"educated after the same model.\"\n\nIt is debatable to what extent the \"Rights of Woman\" is a feminist text; because the definitions of \"feminist\" vary, different scholars have come to different conclusions. Wollstonecraft would never have referred to her text as feminist because the words \"feminist\" and \"feminism\" were not coined until the 1890s. Moreover, there was no feminist movement to speak of during Wollstonecraft's lifetime. In the introduction to her seminal work on Wollstonecraft's thought, Barbara Taylor writes:\n\nDescribing [Wollstonecraft's philosophy] as feminist is problematic, and I do it only after much consideration. The label is of course anachronistic . . . Treating Wollstonecraft's thought as an anticipation of nineteenth and twentieth-century feminist argument has meant sacrificing or distorting some of its key elements. Leading examples of this . . . have been the widespread neglect of her religious beliefs, and the misrepresentation of her as a bourgeois liberal, which together have resulted in the displacement of a religiously inspired utopian radicalism by a secular, class-partisan reformism as alien to Wollstonecraft's political project as her dream of a divinely promised age of universal happiness is to our own. Even more important however has been the imposition on Wollstonecraft of a heroic-individualist brand of politics utterly at odds with her own ethically driven case for women's emancipation. Wollstonecraft's leading ambition for women was that they should attain virtue, and it was to this end that she sought their liberation.\n\nIn the \"Rights of Woman\", Wollstonecraft does not make the claim for gender equality using the same arguments or the same language that late 19th- and 20th century feminists later would. For instance, rather than unequivocally stating that men and women are equal, Wollstonecraft contends that men and women are equal in the eyes of God, which means that they are both subject to the same moral law. For Wollstonecraft, men and women are equal in the most important areas of life. While such an idea may not seem revolutionary to 21st-century readers, its implications were revolutionary during the 18th century. For example, it implied that both men and women—not just women—should be modest and respect the sanctity of marriage. Wollstonecraft's argument exposed the sexual double standard of the late 18th century and demanded that men adhere to the same virtues demanded of women.\n\nHowever, Wollstonecraft's arguments for equality stand in contrast to her statements respecting the superiority of masculine strength and valour. Wollstonecraft famously and ambiguously states:\n\nLet it not be concluded, that I wish to invert the order of things; I have already granted, that, from the constitution of their bodies, men seem to be designed by Providence to attain a greater degree of virtue. I speak collectively of the whole sex; but I see not the shadow of a reason to conclude that their virtues should differ in respect to their nature. In fact, how can they, if virtue has only one eternal standard? I must therefore, if I reason consequentially, as strenuously maintain that they have the same simple direction, as that there is a God.\nMoreover, Wollstonecraft calls on men, rather than women, to initiate the social and political changes she outlines in the \"Rights of Woman\". Because women are uneducated, they cannot alter their own situation—men must come to their aid. Wollstonecraft writes at the end of her chapter \"Of the Pernicious Effects Which Arise from the Unnatural Distinctions Established in Society\":\n\nI then would fain convince reasonable men of the importance of some of my remarks; and prevail on them to weigh dispassionately the whole tenor of my observations. – I appeal to their understandings; and, as a fellow-creature, claim, in the name of my sex, some interest in their hearts. I entreat them to assist to emancipate their companion, to make her a help meet for them! Would men but generously snap our chains, and be content with rational fellowship instead of slavish obedience, they would find us more observant daughters, more affectionate sisters, more faithful wives, more reasonable mothers – in a word, better citizens.\n\nIt is Wollstonecraft's last novel, \"\" (1798), the fictionalised sequel to the \"Rights of Woman\", that is usually considered her most radical feminist work.\n\nOne of Wollstonecraft's most scathing criticisms in the \"Rights of Woman\" is against false and excessive sensibility, particularly in women. She argues that women who succumb to sensibility are \"blown about by every momentary gust of feeling\"; because these women are \"the prey of their senses\", they cannot think rationally. In fact, not only do they do harm to themselves but they also do harm to all of civilisation: these are not women who can refine civilisation – these are women who will destroy it. But reason and feeling are not independent for Wollstonecraft; rather, she believes that they should inform each other. For Wollstonecraft, as for the important 18th-century philosopher David Hume, the passions underpin all reason. This was a theme that she would return to throughout her career, but particularly in her novels \"\" (1788) and \"\".\n\nAs part of her argument that women should not be overly influenced by their feelings, Wollstonecraft emphasises that they should not be constrained by or made slaves to their bodies or their sexual feelings. This particular argument has led many modern feminists to suggest that Wollstonecraft intentionally avoids granting women any sexual desire. Cora Kaplan argues that the \"negative and prescriptive assault on female sexuality\" is a \"\"leitmotif\"\" of the \"Rights of Woman\". For example, Wollstonecraft advises her readers to \"calmly let passion subside into friendship\" in the ideal companionate marriage (that is, in the ideal of a love-based marriage that was developing at the time). It would be better, she writes, when \"two virtuous young people marry . . . if some circumstances checked their passion\". According to Wollstonecraft, \"love and friendship cannot subsist in the same bosom\". As Mary Poovey explains, \"Wollstonecraft betrays her fear that female desire might in fact court man's lascivious and degrading attentions, that the subordinate position women have been given might even be deserved. Until women can transcend their fleshly desires and fleshly forms, they will be hostage to the body.\" If women are not interested in sexuality, they cannot be dominated by men. Wollstonecraft worries that women are consumed with \"romantic wavering\", that is, they are interested only in satisfying their lusts. Because the \"Rights of Woman\" eliminates sexuality from a woman's life, Kaplan contends, it \"expresses a violent antagonism to the sexual\" while at the same time \"exaggerat[ing] the importance of the sensual in the everyday life of women\". Wollstonecraft was so determined to wipe sexuality from her picture of the ideal woman that she ended up foregrounding it by insisting upon its absence. But as Kaplan and others have remarked, Wollstonecraft may have been forced to make this sacrifice: \"it is important to remember that the notion of woman as politically enabled and independent [was] fatally linked [during the eighteenth century] to the unrestrained and vicious exercise of her sexuality.\"\n\nClaudia Johnson, a prominent Wollstonecraft scholar, has called the \"Rights of Woman\" \"a republican manifesto\". Johnson contends that Wollstonecraft is hearkening back to the Commonwealth tradition of the 17th century and attempting to reestablish a republican ethos. In Wollstonecraft's version, there would be strong, but separate, masculine and feminine roles for citizens. According to Johnson, Wollstonecraft \"denounces the collapse of proper sexual distinction as the leading feature of her age, and as the grievous consequence of sentimentality itself. The problem undermining society in her view is feminized men\". If men feel free to adopt both the masculine position and the sentimental feminine position, she argues, women have no position open to them in society. Johnson therefore sees Wollstonecraft as a critic, in both the \"Rights of Men\" and the \"Rights of Woman\", of the \"masculinization of sensitivity\" in such works as Edmund Burke's \"Reflections on the Revolution in France\".\n\nIn the \"Rights of Woman\" Wollstonecraft adheres to a version of republicanism that includes a belief in the eventual overthrow of all titles, including the monarchy. She also briefly suggests that all men and women should be represented in government. But the bulk of her \"political criticism,\" as Chris Jones, a Wollstonecraft scholar, explains, \"is couched predominantly in terms of morality\". Her definition of virtue focuses on the individual's happiness rather than, for example, the good of the entire society. This is reflected in her explanation of natural rights. Because rights ultimately proceed from God, Wollstonecraft maintains that there are duties, tied to those rights, incumbent upon each and every person. For Wollstonecraft, the individual is taught republicanism and benevolence within the family; domestic relations and familial ties are crucial to her understanding of social cohesion and patriotism.\n\nIn many ways the \"Rights of Woman\" is inflected by a bourgeois view of the world, as is its direct predecessor the \"Rights of Men\". Wollstonecraft addresses her text to the middle class, which she calls the \"most natural state\". She also frequently praises modesty and industry, virtues which, at the time, were associated with the middle class. From her position as a middle-class writer arguing for a middle-class ethos, Wollstonecraft also attacks the wealthy, criticising them using the same arguments she employs against women. She points out the \"false-refinement, immorality, and vanity\" of the rich, calling them \"weak, artificial beings, raised above the common wants and affections of their race, in a premature unnatural manner [who] undermine the very foundation of virtue, and spread corruption through the whole mass of society\".\n\nBut Wollstonecraft's criticisms of the wealthy do not necessarily reflect a concomitant sympathy for the poor. For her, the poor are fortunate because they will never be trapped by the snares of wealth: \"Happy is it when people have the cares of life to struggle with; for these struggles prevent their becoming a prey to enervating vices, merely from idleness!\" Moreover, she contends that charity has only negative consequences because, as Jones puts it, she \"sees it as sustaining an unequal society while giving the appearance of virtue to the rich\".\n\nIn her national plan for education, she retains class distinctions (with an exception for the intelligent), suggesting that: \"After the age of nine, girls and boys, intended for domestic employments, or mechanical trades, ought to be removed to other schools, and receive instruction, in some measure appropriated to the destination of each individual . . . The young people of superior abilities, or fortune, might now be taught, in another school, the dead and living languages, the elements of science, and continue the study of history and politics, on a more extensive scale, which would not exclude polite literature.\"\n\nIn attempting to navigate the cultural expectations of female writers and the generic conventions of political and philosophical discourse, Wollstonecraft, as she does throughout her \"oeuvre\", constructs a unique blend of masculine and feminine styles in the \"Rights of Woman\". She utilises the language of philosophy, referring to her work as a \"treatise\" with \"arguments\" and \"principles\". However, Wollstonecraft also uses a personal tone, employing \"I\" and \"you\", dashes and exclamation marks, and autobiographical references to create a distinctly feminine voice in the text. The \"Rights of Woman\" further hybridizes its genre by weaving together elements of the conduct book, the short essay, and the novel, genres often associated with women, while at the same time claiming that these genres could be used to discuss philosophical topics such as rights.\n\nAlthough Wollstonecraft argues against excessive sensibility, the rhetoric of the \"Rights of Woman\" is at times heated and attempts to provoke the reader. Many of the most emotional comments in the book are directed at Rousseau. For example, after excerpting a long passage from \"\" (1762), Wollstonecraft pithily states, \"I shall make no other comments on this ingenious passage, than just to observe, that it is the philosophy of lasciviousness.\" A mere page later, after indicting Rousseau's plan for female education, she writes \"I must relieve myself by drawing another picture.\" These terse exclamations are meant to draw the reader to her side of the argument (it is assumed that the reader will agree with them). While she claims to write in a plain style so that her ideas will reach the broadest possible audience, she actually combines the plain, rational language of the political treatise with the poetic, passionate language of sensibility to demonstrate that one can combine rationality and sensibility in the same self. Wollstonecraft defends her positions not only with reasoned argument but also with ardent rhetoric.\n\nIn her efforts to vividly describe the condition of women within society, Wollstonecraft employs several different analogies. She often compares women to slaves, arguing that their ignorance and powerlessness places them in that position. But at the same time, she also compares them to \"capricious tyrants\" who use cunning and deceit to manipulate the men around them. At one point, she reasons that a woman can become either a slave or tyrant, which she describes as two sides of the same coin. Wollstonecraft also compares women to soldiers; like military men, they are valued only for their appearance. And like the rich, women's \"softness\" has \"debased mankind\".\n\nWollstonecraft was forced to write the \"Rights of Woman\" hurriedly to respond to Talleyrand and ongoing events. Upon completing the work, she wrote to her friend William Roscoe: \"I am dissatisfied with myself for not having done justice to the subject. – Do not suspect me of false modesty – I mean to say that had I allowed myself more time I could have written a better book, in every sense of the word . . . I intend to finish the next volume before I begin to print, for it is not pleasant to have the Devil coming for the conclusion of a sheet fore it is written.\" When Wollstonecraft revised the \"Rights of Woman\" for the second edition, she took the opportunity not only to fix small spelling and grammar mistakes but also to bolster the feminist claims of her argument. She changed some of her statements regarding female and male difference to reflect a greater equality between the sexes.\n\nWollstonecraft never wrote the second part to the \"Rights of Woman,\" although William Godwin published her \"Hints\", which were \"chiefly designed to have been incorporated in the second part of the \"Vindication of the Rights of Woman\"\", in the posthumous collection of her works. However, she did begin writing the novel \"\", which most scholars consider a fictionalised sequel to the \"Rights of Woman\". It was unfinished at her death and also included in the \"Posthumous Works\" published by Godwin.\n\nWhen it was first published in 1792, the \"Rights of Woman\" was reviewed favourably by the \"Analytical Review\", the \"General Magazine\", the \"Literary Magazine\", \"New York Magazine\", and the \"Monthly Review\", although the assumption persists even today that \"Rights of Woman\" received hostile reviews. It was almost immediately released in a second edition in 1792, several American editions appeared, and it was translated into French. Taylor writes that \"it was an immediate success\". Moreover, other writers such as Mary Hays and Mary Robinson specifically alluded to Wollstonecraft's text in their own works. Hays cited the \"Rights of Woman\" in her novel \"Memoirs of Emma Courtney\" (1796) and modelled her female characters after Wollstonecraft's ideal woman. Although female conservatives such as Hannah More excoriated Wollstonecraft personally, they actually shared many of the same values. As the scholar Anne Mellor has shown, both More and Wollstonecraft wanted a society founded on \"Christian virtues of rational benevolence, honesty, personal virtue, the fulfillment of social duty, thrift, sobriety, and hard work\". During the early 1790s, many writers within British society were engaged in an intense debate regarding the position of women in society. For example, the respected poet and essayist Anna Laetitia Barbauld and Wollstonecraft sparred back and forth; Barbauld published several poems responding to Wollstonecraft's work and Wollstonecraft commented on them in footnotes to the \"Rights of Woman\". The work also provoked outright hostility. The bluestocking Elizabeth Carter was unimpressed with the work. Thomas Taylor, the Neoplatonist translator who had been a landlord to the Wollstonecraft family in the late 1770s, swiftly wrote a satire called \"A Vindication of the Rights of Brutes\": if women have rights, why not animals too?\n\nAfter Wollstonecraft died in 1797, her husband William Godwin published his \"Memoirs of the Author of A Vindication of the Rights of Woman\" (1798). He revealed much about her private life that had previously not been known to the public: her illegitimate child, her love affairs, and her attempts at suicide. While Godwin believed he was portraying his wife with love, sincerity, and compassion, contemporary readers were shocked by Wollstonecraft's unorthodox lifestyle and she became a reviled figure. Richard Polwhele targeted her in particular in his anonymous long poem \"The Unsex'd Females\" (1798), a defensive reaction to women's literary self-assertion: Hannah More is Christ to Wollstonecraft's Satan. His poem was \"well known\" among the responses \"A Vindication\". One reviewer comments this \"ingenious poem\" with its \"playful sallies of sarcastic wit\" against \"our modern ladies,\" though others found it \"a tedious, lifeless piece of writing.\" Critical responses largely fell along clear-cut political lines.\n\nWollstonecraft's ideas became associated with her life story and women writers felt that it was dangerous to mention her in their texts. Hays, who had previously been a close friend and an outspoken advocate for Wollstonecraft and her \"Rights of Woman\", for example, did not include her in the collection of \"Illustrious and Celebrated Women\" she published in 1803. Maria Edgeworth specifically distances herself from Wollstonecraft in her novel \"Belinda\" (1802); she caricatures Wollstonecraft as a radical feminist in the character of Harriet Freke. But, like Jane Austen, she does not reject Wollstonecraft's ideas. Both Edgeworth and Austen argue that women are crucial to the development of the nation; moreover, they portray women as rational beings who should choose companionate marriage.\n\nThe negative views towards Wollstonecraft persisted for over a century. The \"Rights of Woman\" was not reprinted until the middle of the 19th century and it still retained an aura of ill-repute. George Eliot wrote \"there is in some quarters a vague prejudice against the \"Rights of Woman\" as in some way or other a reprehensible book, but readers who go to it with this impression will be surprised to find it eminently serious, severely moral, and withal rather heavy\".\nThe suffragist (i.e. moderate reformer, as opposed to suffragette) Millicent Garrett Fawcett wrote the introduction to the centenary edition of the \"Rights of Woman\", cleansing the memory of Wollstonecraft and claiming her as the foremother of the struggle for the vote. While the \"Rights of Woman\" may have paved the way for feminist arguments, 20th century feminists have tended to use Wollstonecraft's life story, rather than her texts, for inspiration; her unorthodox lifestyle convinced them to try new \"experiments in living\", as Virginia Woolf termed it in her famous essay on Wollstonecraft. However, there is some evidence that the \"Rights of Woman\" may be influencing current feminists. Ayaan Hirsi Ali, a feminist who is critical of Islam's dictates regarding women, cites the \"Rights of Woman\" in her autobiography \"Infidel\", writing that she was \"inspired by Mary Wollstonecraft, the pioneering feminist thinker who told women they had the same ability to reason as men did and deserved the same rights\".\n\n\n\n\n", "id": "2834", "title": "A Vindication of the Rights of Woman"}
{"url": "https://en.wikipedia.org/wiki?curid=2835", "text": "Afghan Hound\n\nThe Afghan Hound is a hound that is distinguished by its thick, fine, silky coat and its tail with a ring curl at the end. The breed was selectively bred for its unique features in the cold mountains of Afghanistan. Its local name is Tāžī Spay () or Sag-e Tāzī (Dari Persian: سگ تازی). Other names for this breed are \"Kuchi Hound\", \"Tāzī\", \"Balkh Hound\", \"Baluchi Hound\", \"Barakzai Hound\", \"Shalgar Hound\", \"Kabul Hound\", \"Galanday Hound\" or sometimes incorrectly \"African Hound\".\n\nThe Afghan Hound has been identified as a basal breed that predates the emergence of the modern breeds in the 19th Century. It is most closely related to the Saluki.\n\nToday's modern purebred breed of Afghan Hound descends from dogs brought to Great Britain in the 1920s which King Amanullah of the Afghan Royal Family gave away as gifts. Some had been kept as hunting dogs, others as guardians.\n\nAlthough the breed is demonstrably ancient, verifiable written or visual records that tie today's Afghan Hound breed to specific Afghan owners or places are absent. There is much speculation about the breeds origin and possible connections with the ancient world among fanciers and in non-scientific breed books and breed websites. Connections with other types and breeds from the same area may provide clues to the history. A name for a desert coursing Afghan hound, Tazi (sag-e-tazi), suggests a shared ancestry with the very similar Tasy breed from the Caspian Sea area of Russia and Turkmenistan. Other types or breeds of similar appearance are the Taigan from the mountainous Tian Shan region on the Chinese border of Afghanistan, and the Barakzay, or Kurram Valley Hound.\n\nThere are at least 13 types known in Afghanistan, and some are being developed (through breeding and record keeping) into modern purebred breeds. As the lives of the peoples with whom these dogs developed change in the modern world, often these landrace types of dogs lose their use and disappear; there may have been many more types of longhaired sighthound in the past.\n\nOnce out of Afghanistan, the history of the Afghan Hound breed becomes an important part of the history of the very earliest dog shows and The Kennel Club (UK). Various sighthounds were brought to England in the 1800s by army officers returning from British India (which at the time included), Afghanistan, and Persia, and were exhibited at dog shows, which were then just becoming popular, under various names, such as Barukzy hounds. They were also called \"Persian Greyhounds\" by the English, in reference to their own indigenous sighthound.\n\nOne dog in particular, \"Zardin\", was brought in 1907 from India by Captain Bariff, and became the early ideal of breed type for what was still called the Persian Greyhound. Zardin was the basis of the writing of the first breed standard in 1912, but breeding of the dogs was stopped by World War I.\n\nOut of the longhaired sighthound types known in Afghanistan, two main strains make up the modern Afghan Hound breed. The first were a group of hounds brought to Scotland from Baluchistan by Major and Mrs. G. Bell-Murray and Miss Jean C. Manson in 1920, and are called the \"Bell-Murray strain\".\n\nThese dogs were of the lowland or steppe type, also called kalagh, and are less heavily coated. The second strain was a group of dogs from a kennel in Kabul owned by Mrs. Mary Amps, which she shipped to England in 1925. She and her husband came to Kabul after the Afghan war in 1919, and the foundation sire of her kennel (named Ghazni) in Kabul was a dog that closely resembled Zardin. Her \"Ghazni strain\" were the more heavily coated mountain type. Most of the Afghans in the United States were developed from the Ghazni strain from England. The first Afghans in Australia were imported from the United States in 1934, also of the Ghazni strain. The French breed club was formed in 1939 (FALAPA). The mountain and steppe strains became mixed into the modern Afghan Hound breed, and a new standard was written in 1948, which is still used today.\n\nThe spectacular beauty of Afghan Hound dogs caused them to become highly desirable showdogs and pets, and they are recognised by all of the major kennel clubs in the English-speaking world. One of the Amps Ghazni, \"Sirdar\", won BIS at Crufts in 1928 and 1930. An Afghan hound was featured on the cover of Life Magazine, November 26, 1945. \"Afghan Hounds were the most popular in Australia in the 1970s…and won most of the major shows\". An Afghan Hound won BIS (Best in Show) at the 1996 World Dog Show in Budapest. Afghan hounds were BIS at the Westminster Kennel Club Dog Show in 1957 and again in 1983. That win also marked the most recent win at Westminster for breeder-owner-handler, Chris Terrell.\n\nThe Afghan Hound breed is no longer used for hunting, although it can be seen in the sport of lure coursing.\n\nThe Afghan Hound is tall, standing in height and weighing . The coat may be any colour, but white markings, particularly on the head, are discouraged; many individuals have a black facial mask. A specimen may have facial hair that looks like a Fu Manchu mustache. The mustache is called \"mandarins.\" Some Afghan Hounds are almost white, but parti-color hounds (white with islands of red or black) are not acceptable and may indicate impure breeding. The long, fine-textured coat requires considerable care and grooming. The long topknot and the shorter-haired saddle on the back of the dog are distinctive features of the Afghan Hound coat. The high hipbones and unique small ring on the end of the tail are also characteristics of the breed.\n\nThe temperament of the typical Afghan Hound can be aloof and dignified, but happy and clownish when it's playing. This breed, as is the case with many sighthounds, has a high prey drive and may not get along with small animals. The Afghan Hound can be a successful competitor in dog agility trials as well as an intuitive therapy dog and companion. Genomic studies have pointed to the Afghan Hound as one of the oldest of dog breeds.\n\nThe breed has a reputation among some dog trainers of having a relatively slow \"obedience intelligence\" as defined by author Stanley Coren in \"The Intelligence of Dogs\".\n\nAlthough seldom used today for hunting in Europe and America where they are popular, Afghan hounds are frequent participants in lure coursing events and are also popular in the sport of conformation showing.\n\nThe Khalag Tazi is a variety of the Afghan. It was introduced to Europe in 1920 when an Indian Army officer, Major G Bell-Murray, brought some animals back from Afghanistan. \"Tazi\" is a current and ancient name for hunting dogs of the sighthound type in the Middle East. It has been used to denote the Saluki, Afghan, Taigan, Persian Greyhound, greyhound types of hound.\n\nAfghan Hounds in UK surveys had an average lifespan of about 12 years. which is similar to other breeds of their size. In the 2004 UK Kennel Club survey, the most common causes of death were cancer (31%), old age (20%), cardiac (10.5%), and urologic (5%). Those that die of old age had a median lifespan of 12 years, with 12% living to at least 14.\n\nMajor health issues are allergies, cancer, and hip dysplasia. Sensitivity to anesthesia is an issue the Afghan hound shares with the rest of the sighthound group, as sighthounds have relatively low levels of body fat. Afghan hounds are also among the dog breeds most likely to develop chylothorax, a rare condition which causes the thoracic ducts to leak, allowing large quantities of chyle fluid to enter the dog's chest cavity. This condition commonly results in a lung torsion (in which the dog's lung twists within the chest cavity, requiring emergency surgery), due to the breed's typically deep, \"barrel\"-shaped chest. If not corrected through surgery, chylothorax can ultimately cause fibrosing pleuritis, or a hardening of the organs, due to scar tissue forming around the organs to protect them from the chyle fluid. Chylothorax is not necessarily, but often, fatal.\n\nBecause of its distinctive appearance, the Afghan hound has been represented in animated feature films and TV shows, including Universal Pictures' \"Balto\" (Sylvie), Disney's \"\" (Ruby) and \"Oliver & Company\" (Rita), an Afghan hound also appeared on \"101 Dalmatians\" as well as in \"102 Dalmatians\" as one of the dogs in Cruella De Vil's party and the television series What-a-Mess (Prince Amir of Kinjan; based on children's books by Frank Muir) and, as Prissy in the 1961 Disney animated film \"One Hundred and One Dalmatians\" and \"\". Brainy Barker from \"Krypto the Superdog\" claims to be an Afghan Hound in the episode \"Meet the Dog Stars\", although her design actually resembles that of a Saluki instead of an Afghan.\n\nAfghan hounds have also been featured in television advertisements and in fashion magazines. The Afghan hound is represented in books as well, including being featured in a series of mystery novels by Nina Wright (Abra), and a talking Afghan Hound in David Rothman's \"The Solomon Scandals\" (2008, Twilight Times Books). In the novel \"Between the Acts\", Virginia Woolf uses an Afghan hound (named Sohrab) to represent aspects of one of the book's human characters.\n\nOn August 3, 2005, Korean scientist Hwang Woo-Suk announced that his team of researchers had become the first team to successfully clone a dog, an Afghan Hound named Snuppy. In 2006 Hwang Woo-Suk was dismissed from his university position for fabricating data in his research. Snuppy, nonetheless, was a genuine clone, and thus the first cloned dog in history.\n\nThe Afghan Hound features prominently in the avant-garde music video of popular French band M83's, \"Set in Stone (M83 Remix)\".\n\n\n", "id": "2835", "title": "Afghan Hound"}
{"url": "https://en.wikipedia.org/wiki?curid=2836", "text": "Azawakh\n\nThe Azawakh is a sighthound livestock guardian breed of dog from West Africa. It is also used as a hunting dog, though relegated to a secondary function due to the lack of game in the region. With ancient origins, it is raised throughout the Sahelian zone of Mali, Niger, and Burkina Faso. This region includes the Azawagh Valley for which the breed is named. While commonly associated with the nomadic Tuareg people, they are also bred and owned by other ethnic groups such as the Peulh, Bella, and Hausa. The Azawakh is more related to the Sloughi than it is to the Saluki.\n\nMorphology is very similar to that of the Middle Eastern and South Indian sight hounds, all swift, high-bred coursing hounds, although there are several obvious differences. For example, a short, flat back combined with long legs place the hips higher than the withers. The Azawakh is almond eyed and thin. It moves with a distinctly feline gait and can be found in a variety of colors as well as varying degrees of refinement, though format is basically constant.\n\nThe standards call for a hound from ; its height is . The coat is very short and almost absent on the belly. Its bone structure shows clearly through the skin and musculature. Its muscles are \"dry\", meaning that they are quite flat, unlike the Greyhound and Whippet. In this respect it is similar in type to the Saluki.\n\nIn Africa, Azawakh are found in a variety of colors such as red, blue fawn (that is, with a lilac cast), grizzle, and, rarely, blue and black. The Azawakh in its native land also comes with various white markings including Irish marked (white collar) and particolor (mostly white). Because of this wide color variation in the native population, the American standard used by the AKC and UKC allows any color combination found in Africa. In the United States, the FCI standard is modified to have no color restrictions at a minimum and there is a strong sentiment that the FCI standard should be heavily edited or replaced.\n\nColors permitted by the FCI breed standard are clear sand to dark fawn/brown, red and brindle (with or without a dark mask), with white bib, tail tip, and white on all feet (which can be tips of toes to high stockings). Currently, white stockings that go above the elbow joint are considered disqualifying features in France, as is a white collar or half collar (Irish marked).\n\nThe Azawakh's light, supple, lissome gait is a notable breed characteristic, as is an upright double suspension gallop.\n\nAzawakhs are an incredibly sound coursing hound. Serious coursing injuries are rare. The dogs heal very quickly from injury.\n\nAzawakh have no known incidence of hip dysplasia. There is a small occurrence of adult-onset idiopathic epilepsy in the breed. Wobbler disease, or cervical vertebral instability, does rarely occur. Some breeders believe this is largely a developmental problem where puppies grow too quickly due to a high-protein Western diet.\n\nLike the Basenji and Tibetan Mastiff, the Azawakh often has a single annual estrus. Unassisted birth of healthy puppies is normal. Litter sizes are usually from four to six puppies, but litters as small as one and as large as ten occur.\n\nAzawakh need a fairly high level of exercise and should have regular runs off lead in large enclosed areas to run off steam. The dogs are very social and emotional. They need a master that provides firm but fair leadership. Azawakh thrive on companionship of other Azawakh.\n\nUnlike other sighthounds, the primary function of the Azawakh in its native land is that of protector. It develops an intense bond with its owner, yet can perform independently from its master. With those they accept, Azawakh are gentle and extremely affectionate. With strangers many are reserved and prefer not to be touched, but are not inherently aggressive. Although raised to protect livestock, they do not have innate aggression toward canines or humans unless they are threatened.\n\nAzawakh have high energy and tremendous endurance. They are excellent training companions for runners and are nearly impervious to heat. They will happily run in weather over 100 degrees Fahrenheit that would kill a Greyhound.\n\nMany Azawakh dislike rain and cold weather.\n\nAzawakh are pack oriented and form complex social hierarchies. They have tremendous memories and are able to recognize each other after long periods of separation. They can often be found sleeping on top of each other for warmth and companionship.\n\nAlberto Rossi: \"To raise an Azawakh is like building a very fragile construction, which takes a lot of sensibility and can be destroyed from one minute to the next. But every minute it lasts, it fills you with great happiness.\" Every time I´m sitting in a chair or sofa at least one of my dogs tries to take a seat on my lap. The same happens to those of my guests which they love. In these moments they seem to be the image of calmness, gentleness, and trust. But one should not be deceived about this. In the deepest place of their soul resides something wild and native, and they will remind us about it with the first occasion and we should not forget, even for a moment, not to treat them like a normal dog.\"\n\nBred by the Tuareg, Fula and various other nomads of the Sahara and sub-Saharan Sahel in the countries of Mali, Niger, Burkina Faso, and southern Algeria, the breed is used there as a guard dog and to hunt gazelle and hare at speeds up to 40 miles per hour. The austerity of the Sahel environment has ensured that only the most fit dogs survive and has accentuated the breed's ruggedness and independence. Unlike some other sighthounds, the Azawakh is more of a pack hunter and they bump down the quarry with hindquarters when it has been tired out. In role of a guard dog, if an Azawakh senses danger it will bark to alert the other members of the pack, and they will gather together as a pack under the lead of the alpha dog, then chase off or attack the predator. The Sloughi, by comparison, is more of an independent lone hunter and has a high hunting instinct.\n\nThey are relatively uncommon in Europe and North America but there is a growing band of devotees. Azawakhs have a range of temperaments from lap dog to quite fierce. Lifelong socialization and firm but gentle handling are critical. Well socialised and trained, they can be good with other dogs, cats, children, and strangers. Azawakh may be registered with the FCI in the USA via the Federación Canófila de Puerto Rico (FCPR). European FCI clubs and the AKC recognize the FCPR as an acceptable registry. The AKC currently recognizes Azawakh as a Foundation Stock Service breed and they are eligible to participate in AKC-sanctioned Companion & Performance events. The breed will enter the AKC Miscellaneous Class on June 30, 2011. The American Azawakh Association (AAA). is the AKC Parent Club for the Azawakh. Azawakh may be registered with the UKC and ARBA. The breed is not yet registered by CKC. Azawakh are eligible for ASFA and AKC lure coursing and NOFCA open field coursing events.\nGenetic, blood protein and archaeological studies, as well as direct observation in the field, offer a glimpse into the origin of the contemporary Azawakh breed. It originated from the pariah dogs of sub-Saharan Africa—also called \"bush dogs\" or \"basenji\"—and is also closely related to the Sloughi of the Maghreb. Despite morphological similarities, mitochondrial DNA evidence shows that it is only very distantly related to other sight hounds. Azawakh have a rare glucose isomerase allele (GPI) that occurs only in foxes, jackals, Italian wolves, Sloughi dogs and a handful of other quite unrelated rare dogs found mostly in Japan. The presence of the GPI suggests an ancient differentiation of the Azawakh from other dog populations near the base of the dog family tree divergence from wolves or perhaps a uniquely African cross-breeding with local African canids such as jackals. Petroglyph rock art dating from 8,000 to 10,000 years ago during the Green Sahara (also known as the Holocene and Neolithic Subpluvial) shows cursorial dogs in conjunction with hunters. Archaeologists have found dog bones buried in Holocene settlements in the Sahara. At the close of the Holocene Wet Phase in the 4th millennium BCE, the Sahara returned to desert and created a formidable physical barrier to travel. Together, this evidence suggests that the Azawakh population has a unique genetic heritage that has been largely isolated from other dog populations for millennia.\n\nIn the common era the Sahel dogs are almost totally isolated from northern dogs by the Sahara, but the ties to the pariah dogs to the south are extremely close. Azawakh are virtually indistinguishable from the Sahel pariah dog population from which they are drawn. In addition to a basic physical structure, the Azawakh share a number of unique traits with the pariah dogs:\n\n\nThroughout the Sahel, very elegant puppies can be found among rustic siblings. The Sahel nomads do not have the same breed concepts as in the West and, unlike the Bedouin of the North, do not recognize a strict separation of \"al hor\" (noble) from \"kelb\" (mongrel) dogs. The nomads act as an extra level of selection on top of the intense natural selection pressure of the Sahel environment. The approach to selection is diametrically opposed to Western breeding, and presents the advantage of maintaining a large reservoir of genetic variability and resilience.\n\nThe peoples of the Sahel control dam lines and cull puppies heavily at birth according to locally held aesthetic criteria that are not yet fully understood. In the Sahel, color is not a selection criterion. The alpha male dog from the local population is usually the sire. Females are usually culled unless the family projects a need for more dogs in the future.\n\n\n", "id": "2836", "title": "Azawakh"}
{"url": "https://en.wikipedia.org/wiki?curid=2838", "text": "Acrylic paint\n\nAcrylic paint is a fast-drying paint made of pigment suspended in acrylic polymer emulsion. Acrylic paints are water-soluble, but become water-resistant when dry. Depending on how much the paint is diluted with water, or modified with acrylic gels, media, or pastes, the finished acrylic painting can resemble a watercolor or an oil painting, or have its own unique characteristics not attainable with other media. Acrylic paint is typically used for crafting, or in art classes in schools because it does not require any chemicals, and rinses away with just water. It also is less likely to leave a stain on clothes than oil paint.\n\nAs early as 1934, the first usable acrylic resin dispersion was developed by German chemical company BASF, which was patented by Rohm and Haas. The synthetic paint was first used in the 1940s, combining some of the properties of oil and watercolor. Between 1946 and 1949, Leonard Bocour and Sam Golden invented a solution acrylic paint under the brand Magna paint. These were mineral spirit-based paints. Acrylics were made commercially available in the 1950s.\n\nFollowing that development, Golden came up with a waterborne acrylic paint called \"Aquatec\". Otto Röhm invented acrylic resin, which was quickly transformed into acrylic paint. In 1953, the year that Rohm and Haas developed the first acrylic emulsions, Jose L. Gutierrez produced \"Politec Acrylic Artists' Colors\" in Mexico, and Henry Levinson of Cincinnati-based Permanent Pigments Co. produced Liquitex colors. These two product lines were the very first acrylic emulsion artists' paints.\n\nWater-based acrylic paints were subsequently sold as latex house paints, as latex is the technical term for a suspension of polymer microparticles in water. Interior latex house paints tend to be a combination of binder (sometimes acrylic, vinyl, pva, and others), filler, pigment, and water. Exterior latex house paints may also be a co-polymer blend, but the best exterior water-based paints are 100% acrylic, due to elasticity and other factors. Vinyl, however, costs half of what 100% acrylic resins cost, and PVA (polyvinyl acetate) is even cheaper, so paint companies make many different combinations of them to match the market.\n\nSoon after the water-based acrylic binders were introduced as house paints, artists and companies alike began to explore the potential of the new binders. Water-soluble artists' acrylic paints were sold commercially by Liquitex beginning in the 1950s, with modern high-viscosity paints becoming available in the early '60s. In 1963, Rowney (now part of Daler-Rowney since 1983) was the first manufacturer to introduce artist’s acrylic paints in Europe, under the brand name \"Cryla\".\n\nBefore the 19th century, artists mixed their own paints, which allowed them to achieve the desired color and thickness, and to control the use of fillers, if any. While suitable media and raw pigments are available for the individual production of acrylic paint, hand mixing may not be practical because of the fast drying time and other technical issues.\n\nAcrylic painters can modify the appearance, hardness, flexibility, texture, and other characteristics of the paint surface by using acrylic media or simply by adding water. Watercolor and oil painters also use various media, but the range of acrylic media is much greater. Acrylics have the ability to bond to many different surfaces, and media can be used to modify their binding characteristics. Acrylics can be used on paper, canvas and a range of other materials, however their use on engineered woods such as medium-density fiberboard can be problematic because of the porous nature of those surfaces. In these cases it is recommended that the surface first be sealed with an appropriate sealer. Acrylics can be applied in thin layers or washes to create effects that resemble watercolors and other water-based media. They can also be used to build thick layers of paint—gel and molding paste media are sometimes used to create paintings with relief features that are, quite literally, sculptural. Acrylic paints are also used in hobbies such as train, car, house, and human models. People who make such models use acrylic paint to build facial features on dolls, or raised details on other types of models. Wet acrylic paint is easily removed from paint brushes and skin with water, whereas oil paints require the use of a hydrocarbon.\n\nAcrylic paints are the most common paints used in grattage, a surrealist technique that became popular with the advent of acrylic paint. Acrylics are used for this purpose because they easily scrape or peel from a surface.\n\nAcrylic artists' paints may be thinned with water and used as washes in the manner of watercolor paints, but unlike watercolor the washes are not rehydratable once dry. For this reason, acrylics do not lend themselves to the color lifting techniques of gum arabic-based watercolor paints.\n\nAcrylic paints with gloss or matte finishes are common, although a satin (semi-matte) sheen is most common. Some brands exhibit a range of finishes (e.g. heavy-body paints from Golden, Liquitex, Winsor & Newton and Daler-Rowney); Politec acrylics are fully matte. As with oils, pigment amounts and particle size or shape can affect the paint sheen. Matting agents can also be added during manufacture to dull the finish. If desired, the artist can mix different media with their paints and use topcoats or varnishes to alter or unify sheen.\n\nWhen dry, acrylic paint is generally non-removable from a solid surface if it adheres to the surface. Water or mild solvents do not re-solubilize it, although isopropyl alcohol can lift some fresh paint films off. Toluene and acetone can remove paint films, but they do not lift paint stains very well and are not selective. The use of a solvent to remove paint may result in removal of all of the paint layers (acrylic gesso, et cetera). Oils and warm, soapy water can remove acrylic paint from skin.\n\nOnly a proper acrylic gesso should be used to prime canvas in preparation for painting with acrylic paints. However, acrylic paint can be applied to a raw canvas if so desired without any negative effect or chemical reaction (the case with oil paint). It is important to avoid adding non-stable or non-archival elements to the gesso upon application. However, the viscosity of acrylic can be successfully reduced by using suitable extenders that maintain the integrity of the paint film. There are retarders to slow drying and extend \"workability\" time, and \"flow releases\" to increase color-blending ability.\n\nCommercial acrylic paints come in two grades:\n\n\nThe vehicle and binder of oil paints is linseed oil (or another drying oil), whereas acrylic paint has water as the vehicle for an emulsion (suspension) of acrylic polymer, which serves as the binder. Thus, oil paint is said to be \"oil-based\", whereas acrylic paint is \"water-based\" (or sometimes \"water-borne\").\nThe main practical difference between most acrylics and oil paints is the inherent drying time. Oils allow for more time to blend colors and apply even glazes over underpaintings. This slow-drying aspect of oil can be seen as an advantage for certain techniques, but it impedes an artist trying to work quickly. The fast evaporation of water from regular acrylic paint films can be slowed with the use of acrylic retarders. Retarders are generally glycol or glycerin-based additives. The addition of a retarder slows the evaporation rate of the water.\n\nOil paints may require the use of solvents such as mineral spirits or turpentine to thin the paint and clean up. These solvents generally have some level of toxicity and are often found objectionable. Relatively recently, water-miscible oil paints have been developed for artists' use. Oil paint films can become increasingly yellow and brittle with time; they lose much of their flexibility in a few decades. Additionally, the rules of \"fat over lean\" must be employed to ensure the paint films are durable.\n\nOil paint has a higher pigment load than acrylic paint. As linseed oil contains a smaller molecule than acrylic paint, oil paint is able to absorb substantially more pigment. Oil provides a refractive index that is less clear than acrylic dispersions, which imparts a unique \"look and feel\" to the resultant paint film. Not all the pigments of oil paints are available in acrylics.\n\nDue to acrylic paint's more flexible nature and more consistent drying time between layers, an artist does not have to follow the same rules of oil painting, where more medium must be applied to each layer to avoid cracking. It usually takes 15–20 minutes for one to two layers of acrylic paint to dry. Although canvas needs to be properly primed before painting with oil to prevent it from eventually rotting the canvas, acrylic can be safely applied straight to the canvas. The rapid drying of acrylic paint tends to discourage blending of color and use of wet-in-wet technique as in oil painting. Even though acrylic retarders can slow drying time to several hours, it remains a relatively fast-drying medium and adding too much acrylic retarder can prevent the paint from ever drying properly.\n\nMeanwhile, acrylic paint is very elastic, which prevents cracking from occurring. Acrylic paint's binder is acrylic polymer emulsion – as this binder dries, the paint remains flexible.\n\nAnother difference between oil and acrylic paints is the versatility offered by acrylic paints. Acrylics are very useful in mixed media, allowing the use of pastel (oil & chalk), charcoal and pen (among others) on top of the dried acrylic painted surface. Mixing other bodies into the acrylic is possible—sand, rice, and even pasta may be incorporated in the artwork. Mixing artist or student grade acrylic paint with household acrylic emulsions is possible, allowing the use of premixed tints straight from the tube or tin, and thereby presenting the painter with a vast color range at their disposal. This versatility is also illustrated by the variety of additional artistic uses for acrylics. Specialized acrylics have been manufactured and used for linoblock printing (acrylic block printing ink has been produced by Derivan since the early 1980s), face painting, airbrushing, watercolor-like techniques, and fabric screen printing.\n\nAnother difference between oil and acrylic paint is the cleanup. Acrylic paint can be cleaned out of a brush with any soap, while oil paint needs a specific type to be sure to get all the oil out of the brushes. Also, it is easier to let a pallet with oil paint dry and then scrape the paint off, whereas one can easily clean wet acrylic paint with water.\n\n", "id": "2838", "title": "Acrylic paint"}
{"url": "https://en.wikipedia.org/wiki?curid=2839", "text": "Angular momentum\n\nIn physics, angular momentum (rarely, moment of momentum or rotational momentum) is the rotational analog of linear momentum. It is an important quantity in physics because it is a conserved quantity – the angular momentum of a system remains constant unless acted on by an external torque.\n\nThe definition of angular momentum for a point particle is a pseudovector r×p, the cross product of the particle's position vector r (relative to some origin) and its momentum vector p = \"m\"v. This definition can be applied to each point in continua like solids or fluids, or physical fields. Unlike momentum, angular momentum does depend on where the origin is chosen, since the particle's position is measured from it. The angular momentum of an object can also be connected to the angular velocity ω of the object (how fast it rotates about an axis) via the moment of inertia \"I\" (which depends on the shape and distribution of mass about the axis of rotation). However, while ω always points in the direction of the rotation axis, the angular momentum L may point in a \"different\" direction depending on how the mass is distributed.\n\nAngular momentum is additive; the total angular momentum of a system is the (pseudo)vector sum of the angular momenta. For continua or fields one uses integration. The total angular momentum of anything can always be split into the sum of two main components: \"orbital\" angular momentum about an axis outside the object, plus \"spin\" angular momentum through the centre of mass of the object.\n\nTorque can be defined as the rate of change of angular momentum, analogous to force. The conservation of angular momentum helps explain many observed phenomena, for example the increase in rotational speed of a spinning figure skater as the skater's arms are contracted, the high rotational rates of neutron stars, the falling cat problem, and precession of tops and gyros. Applications include the gyrocompass, control moment gyroscope, inertial guidance systems, reaction wheels, flying discs or Frisbees and Earth's rotation to name a few. In general, conservation does limit the possible motion of a system, but does not uniquely determine what the exact motion is.\n\nIn quantum mechanics, angular momentum is an operator with quantized eigenvalues. Angular momentum is subject to the Heisenberg uncertainty principle, meaning only one component can be measured with definite precision, the other two cannot. Also, the \"spin\" of elementary particles does not correspond to literal spinning motion.\n\nAngular momentum is a vector quantity (more precisely, a pseudovector) that represents the product of a body's rotational inertia and rotational velocity about a particular axis. In the simple case of revolution of a particle in a circle about a center of rotation, the particle remaining always in the same plane and having always the same distance from the center, it is sufficient to discard the vector nature of angular momentum, and treat it as a scalar. Angular momentum can be considered a rotational analog of linear momentum. Thus, where linear momentum is proportional to mass formula_1 and linear speed formula_2,\nangular momentum is proportional to moment of inertia formula_4 and angular speed formula_5,\nUnlike mass, which depends only on amount of matter, moment of inertia is also dependent on the position of the axis of rotation and the shape of the matter. Unlike linear speed, which occurs in a straight line, angular speed occurs about a center of rotation. Therefore, strictly speaking, formula_7 should be referred to as the angular momentum \"relative to that center\".\n\nBecause formula_8 for a single particle and formula_9 for circular motion, angular momentum can be expanded, formula_10 and reduced to,\nthe product of the radius of rotation formula_12 and the linear momentum of the particle formula_13, where formula_2 in this case is the equivalent linear (tangential) speed at the radius (formula_15).\n\nThis simple analysis can also apply to non-circular motion if only the component of the motion which is perpendicular to the radius vector is considered. In that case,\n\nwhere formula_17 is the perpendicular component of the motion. Expanding, formula_18 rearranging, formula_19 and reducing, angular momentum can also be expressed,\nwhere formula_21 is the length of the \"moment arm\", a line dropped perpendicularly from the origin onto the path of the particle. It is this definition, to which the term \"moment of momentum\" refers.\n\nAnother approach is to define angular momentum as the conjugate momentum of the angular coordinate formula_22 expressed in the Lagrangian of the mechanical system. Consider a mechanical system with a mass formula_1 constrained to move in a circle of radius formula_24 in the absence of any external force field. The kinetic energy of the system is\n\nAnd the potential energy is\n\nThen the Lagrangian is\n\nThe \"generalized momentum\" \"canonically conjugate to\" the coordinate formula_22 is defined by\n\nTo completely define angular momentum in three dimensions, it is required to know the angle swept out in unit time, the direction of the axis of rotation, and the sense (right- or left-handed) of the rotation, as well as the mass involved. By retaining this vector nature of angular momentum, the general nature of the equations is also retained, and can describe any sort of three-dimensional motion about the center of rotation – circular, linear, or otherwise. In vector notation, the angular momentum of a particle in motion about the origin of coordinates is defined as:\n\nThis can be expanded, formula_37 reduced, formula_38\nand by the rules of vector algebra rearranged to the form,\nwhich is the cross product of the position vector formula_33 and the linear momentum formula_41 of the particle. By the definition of the cross product, the formula_42 vector is perpendicular to both formula_33 and formula_44. It is directed along the axis of rotation as indicated by the right-hand rule – so that the rotation is seen as counter-clockwise from the head of the vector. Conversely, the formula_42 vector defines the plane in which formula_33 and formula_44 lie.\n\nBy defining a unit vector formula_48 in the direction of the axis of rotation, a scalar angular speed formula_5 results, where\nThe two-dimensional scalar equations of the previous section can thus be given direction:\nand formula_54 for circular motion, where all of the motion is perpendicular to the radius formula_12.\n\nAngular momentum can be described as the rotational analog of linear momentum. Like linear momentum it involves elements of mass and displacement. Unlike linear momentum it also involves elements of position and shape.\n\nMany problems in physics involve matter in motion about some certain point in space, be it in actual rotation about it, or simply moving past it, where it is desired to know what effect the moving matter has on the point — can it exert energy upon it or perform work about it? Energy, the ability to do work, can be stored in matter by setting it in motion — a combination of its inertia and its displacement. Inertia is measured by its mass, and displacement by its velocity. Their product,\n\nis the matter's momentum. Referring this momentum to a central point introduces a complication: the momentum is not applied to the point directly. For instance, a particle of matter at the outer edge of a wheel is, in effect, at the end of a lever of the same length as the wheel's radius, its momentum turning the lever about the center point. This imaginary lever is known as the \"moment arm\". It has the effect of multiplying the momentum's effort in proportion to its length, an effect known as a \"moment\". Hence, the particle's momentum referred to a particular point,\n\nis the \"angular momentum\", sometimes called, as here, the \"moment of momentum\" of the particle versus that particular center point. The equation formula_58 combines a moment (a mass formula_1 turning moment arm formula_12) with a linear (straight-line equivalent) speed formula_2. Linear speed referred to the central point is simply the product of the distance formula_12 and the angular speed formula_5 versus the point: formula_64 another moment. Hence, angular momentum contains a double moment: formula_65 Simplifying slightly, formula_66 the quantity formula_67 is the particle's moment of inertia, sometimes called the second moment of mass. It is a measure of rotational inertia.\n\nBecause rotational inertia is a part of angular momentum, it necessarily includes all of the complications of moment of inertia, which is calculated by multiplying elementary bits of the mass by the squares of their distances from the center of rotation. Therefore, the total moment of inertia, and the angular momentum, is a complex function of the configuration of the matter about the center of rotation and the orientation of the rotation for the various bits.\n\nFor a rigid body, for instance a wheel or an asteroid, the orientation of rotation is simply the position of the rotation axis versus the matter of the body. It may or may not pass through the center of mass, or it may lie completely outside of the body. For the same body, angular momentum may take a different value for every possible axis about which rotation may take place. It reaches a minimum when the axis passes through the center of mass.\n\nFor a collection of objects revolving about a center, for instance all of the bodies of the Solar System, the orientations may be somewhat organized, as is the Solar System, with most of the bodies' axes lying close to the system's axis. Their orientations may also be completely random.\n\nIn brief, the more mass and the farther it is from the center of rotation (the longer the moment arm), the greater the moment of inertia, and therefore the greater the angular momentum for a given angular velocity. In many cases the moment of inertia, and hence the angular momentum, can be simplified by,\nSimilarly, for a point mass formula_1 the moment of inertia is defined as,\nand for any collection of particles formula_74 as the sum,\n\nAngular momentum's dependence on position and shape is reflected in its units versus linear momentum: kg·m/s, N·m·s or J·s for angular momentum versus kg·m/s or N·s for linear momentum. Angular momentum's units can be interpreted as torque·seconds, work·seconds, or energy·seconds. An object with angular momentum of can be reduced to zero rotation (all of the energy can be transferred out of it) by an angular impulse of or equivalently, by torque or work of for one second, or energy of for one second.\n\nThe plane perpendicular to the axis of angular momentum and passing through the center of mass is sometimes called the \"invariable plane\", because the direction of the axis remains fixed if only the interactions of the bodies within the system, free from outside influences, are considered. One such plane is the invariable plane of the Solar System.\n\nNewton's Second Law of Motion can be expressed mathematically,\nor force = mass × acceleration. The rotational equivalent is\nor torque = moment of inertia × angular acceleration. Because angular acceleration is the time derivative of angular velocity, this is equivalent to formula_78 Rearranging into a form suitable for integration, formula_79 and formula_80 and integrating with respect to time,\nTherefore, a torque acting over time is equivalent to a change in angular momentum, known as \"angular impulse\", by analogy with impulse, which is defined as the change in translational momentum. The constant can be interpreted as the initial angular momentum of the body, before the torque began to act. In particular, if torque formula_82 then angular momentum formula_83 That is, if no torque acts upon a body, then its angular momentum remains constant. Conversely,\nor Angular momentum = moment of inertia × angular velocity, and its time derivative is\n\nBecause moment of inertia is constant, formula_86 is zero, and formula_87 which, as above, reduces to\n\nTherefore, the time rate of change of angular momentum about a particular center of rotation is equivalent to applied torque about that center. If angular momentum is constant, formula_89 and no torque is applied.\n\nA rotational analog of Newton's Third Law of Motion might be written, \"In a closed system, no torque can be exerted on any matter without the exertion on some other matter of an equal and opposite torque.\" Hence, \"angular momentum can be exchanged between objects in a closed system, but total angular momentum before and after an exchange remains constant (is conserved).\"\n\nSimilarly, a rotational analogy of Newton's Second law of Motion might be, \"A change in angular momentum is proportional to the applied torque and occurs about the same axis as that torque.\" Since a torque applied over time is equivalent to a change in angular momentum, then if torque is zero, angular momentum is constant. As above, a system with constant angular momentum is a closed system. Therefore, \"requiring the system to be closed is equivalent to requiring that no external influence, in the form of a torque, acts upon it.\"\n\nA rotational analog of Newton's First Law of Motion might be written, \"A body continues in a state of rest or of uniform rotation unless acted by an external torque.\" Thus \"with no external influence to act upon it, the original angular momentum of the system is conserved\".\n\nThe conservation of angular momentum is used in analyzing \"central force motion\". If the net force on some body is directed always toward some point, the \"center\", then there is no torque on the body with respect to the center, as all of the force is directed along the radius vector, and none is perpendicular to the radius. Mathematically, torque formula_90 because in this case formula_33 and formula_92 are parallel vectors. Therefore, the angular momentum of the body about the center is constant. This is the case with gravitational attraction in the orbits of planets and satellites, where the gravitational force is always directed toward the primary body and orbiting bodies conserve angular momentum by exchanging distance and velocity as they move about the primary. Central force motion is also used in the analysis of the Bohr model of the atom.\n\nFor a planet, angular momentum is distributed between the spin of the planet and its revolution in its orbit, and these are often exchanged by various mechanisms. The conservation of angular momentum in the Earth–Moon system results in the transfer of angular momentum from Earth to Moon, due to tidal torque the Moon exerts on the Earth. This in turn results in the slowing down of the rotation rate of Earth, at about 65.7 nanoseconds per day, and in gradual increase of the radius of Moon's orbit, at about 3.82 centimeters per year.\n\nThe conservation of angular momentum explains the angular acceleration of an ice skater as she brings her arms and legs close to the vertical axis of rotation. By bringing part of the mass of her body closer to the axis she decreases her body's moment of inertia. Because angular momentum is the product of moment of inertia and angular velocity, if the angular momentum remains constant (is conserved), then the angular velocity (rotational speed) of the skater must increase.\n\nThe same phenomenon results in extremely fast spin of compact stars (like white dwarfs, neutron stars and black holes) when they are formed out of much larger and slower rotating stars. Decrease in the size of an object \"n\" times results in increase of its angular velocity by the factor of \"n\".\n\nConservation is not always full explanation for the dynamics of a system but a key constraint. For example, a spinning top is subject to a gravitational torque making it lean over and change the angular momentum about the nutation axis, but neglecting friction at the point of spinning contact, it has a conserved angular momentum about its spinning axis, and another about its precession axis. Also, in any planetary system, the planets, star(s), comets, and asteroids can all move in numerous complicated ways, but only so that the angular momentum of the system is conserved.\n\nNoether's theorem states that every conservation law is associated with a symmetry (invariant) of the underlying physics. The symmetry associated with conservation of angular momentum is rotational invariance. The fact that the physics of a system is unchanged if it is rotated by any angle about an axis implies that angular momentum is conserved.\n\nIn astrodynamics and celestial mechanics, a \"massless\" (or \"per unit mass\") angular momentum is defined\ncalled \"specific angular momentum\". Note that formula_94 Mass is often unimportant in orbital mechanics calculations, because motion is defined by gravity. The primary body of the system is often so much larger than any bodies in motion about it that the smaller bodies have a negligible gravitational effect on it; it is, in effect, stationary. All bodies are apparently attracted by its gravity in the same way, regardless of mass, and therefore all move approximately the same way under the same conditions.\n\nFor a continuous mass distribution with density function \"ρ\"(r), a differential volume element \"dV\" with position vector r within the mass has a mass element \"dm\" = \"ρ\"(r)\"dV\". Therefore, the infinitesimal angular momentum of this element is:\n\nand integrating this differential over the volume of the entire mass gives its total angular momentum:\n\nIn the derivation which follows, integrals similar to this can replace the sums for the case of continuous mass.\n\nFor a collection of particles in motion about an arbitrary origin, it is informative to develop the equation of angular momentum by resolving their motion into components about their own center of mass and about the origin. Given,\n\nThe total mass of the particles is simply their sum,\n\nThe position vector of the center of mass is defined by,\n\nBy inspection,\n\nThe total angular momentum of the collection of particles is the sum of the angular momentum of each particle,\nExpanding formula_99,\n\nExpanding formula_101,\n\nIt can be shown that (see sidebar),\ntherefore the second and third terms vanish,\n\nThe first term can be rearranged,\nand total angular momentum for the collection of particles is finally,\nThe first term is the angular momentum of the center of mass relative to the origin. Similar to Single particle, below, it is the angular momentum of one particle of mass \"M\" at the center of mass moving with velocity V. The second term is the angular momentum of the particles moving relative to the center of mass, similar to Fixed center of mass, below. The result is general — the motion of the particles is not restricted to rotation or revolution about the origin or center of mass. The particles need not be individual masses, but can be elements of a continuous distribution, such as a solid body.\n\nRearranging equation () by vector identities, multiplying both terms by \"one\", and grouping appropriately,\n\ngives the total angular momentum of the system of particles in terms of moment of inertia formula_4 and angular velocity formula_123,\n\nIn the case of a single particle moving about the arbitrary origin,\n\nFor the case of the center of mass fixed in space with respect to the origin,\n\nIn modern (20th century) theoretical physics, angular momentum (not including any intrinsic angular momentum – see below) is described using a different formalism, instead of a classical pseudovector. In this formalism, angular momentum is the 2-form Noether charge associated with rotational invariance. As a result, angular momentum is not conserved for general curved spacetimes, unless it happens to be asymptotically rotationally invariant.\n\nIn classical mechanics, the angular momentum of a particle can be reinterpreted as a plane element:\n\nin which the exterior product ∧ replaces the cross product × (these products have similar characteristics but are nonequivalent). This has the advantage of a clearer geometric interpretation as a plane element, defined from the x and p vectors, and the expression is true in any number of dimensions (two or higher). In Cartesian coordinates:\n\nor more compactly in index notation:\n\nThe angular velocity can also be defined as an antisymmetric second order tensor, with components \"ω\". The relation between the two antisymmetric tensors is given by the moment of inertia which must now be a fourth order tensor:\n\nAgain, this equation in L and ω as tensors is true in any number of dimensions. This equation also appears in the geometric algebra formalism, in which L and ω are bivectors, and the moment of inertia is a mapping between them.\n\nIn relativistic mechanics, the relativistic angular momentum of a particle is expressed as an antisymmetric tensor of second order:\n\nin the language of four-vectors, namely the four position \"X\" and the four momentum \"P\", and absorbs the above L together with the motion of the centre of mass of the particle.\n\nIn each of the above cases, for a system of particles, the total angular momentum is just the sum of the individual particle angular momenta, and the centre of mass is for the system.\n\nAngular momentum in quantum mechanics differs in many profound respects from angular momentum in classical mechanics. In relativistic quantum mechanics, it differs even more, in which the above relativistic definition becomes a tensorial operator.\n\nThe classical definition of angular momentum as formula_140 can be carried over to quantum mechanics, by reinterpreting r as the quantum position operator and p as the quantum momentum operator. L is then an operator, specifically called the \"orbital angular momentum operator\".\n\nHowever, in quantum physics, there is another type of angular momentum, called \"spin angular momentum\", represented by the spin operator S. Almost all elementary particles have spin. Spin is often depicted as a particle literally spinning around an axis, but this is a misleading and inaccurate picture: spin is an intrinsic property of a particle, unrelated to any sort of motion in space and fundamentally different from orbital angular momentum. All elementary particles have a characteristic spin, for example electrons have \"spin 1/2\" (this actually means \"spin ħ/2\") while photons have \"spin 1\" (this actually means \"spin ħ\").\n\nFinally, there is total angular momentum J, which combines both the spin and orbital angular momentum of all particles and fields. (For one particle, J = L + S.) Conservation of angular momentum applies to J, but not to L or S; for example, the spin–orbit interaction allows angular momentum to transfer back and forth between L and S, with the total remaining constant. Electrons and photons need not have integer-based values for total angular momentum, but can also have fractional values.\n\nIn quantum mechanics, angular momentum is quantized – that is, it cannot vary continuously, but only in \"quantum leaps\" between certain allowed values. For any system, the following restrictions on measurement results apply, where formula_141 is the reduced Planck constant and formula_142 is any direction vector such as x, y, or z:\n\nThe reduced Planck constant formula_141 is tiny by everyday standards, about 10 J s, and therefore this quantization does not noticeably affect the angular momentum of macroscopic objects. However, it is very important in the microscopic world. For example, the structure of electron shells and subshells in chemistry is significantly affected by the quantization of angular momentum.\n\nQuantization of angular momentum was first postulated by Niels Bohr in his Bohr model of the atom and was later predicted by Erwin Schrödinger in his Schrödinger equation.\n\nIn the definition formula_140, six operators are involved: The position operators formula_145, formula_146, formula_147, and the momentum operators formula_148, formula_149, formula_150. However, the Heisenberg uncertainty principle tells us that it is not possible for all six of these quantities to be known simultaneously with arbitrary precision. Therefore, there are limits to what can be known or measured about a particle's angular momentum. It turns out that the best that one can do is to simultaneously measure both the angular momentum vector's magnitude and its component along one axis.\n\nThe uncertainty is closely related to the fact that different components of an angular momentum operator do not commute, for example formula_151. (For the precise commutation relations, see angular momentum operator.)\n\nAs mentioned above, orbital angular momentum L is defined as in classical mechanics: formula_140, but \"total\" angular momentum J is defined in a different, more basic way: J is defined as the \"generator of rotations\". More specifically, J is defined so that the operator\nis the rotation operator that takes any system and rotates it by angle formula_22 about the axis formula_155. (The \"exp\" in the formula refers to operator exponential)\n\nThe relationship between the angular momentum operator and the rotation operators is the same as the relationship between lie algebras and lie groups in mathematics. The close relationship between angular momentum and rotations is reflected in Noether's theorem that proves that angular momentum is conserved whenever the laws of physics are rotationally invariant.\n\nWhen describing the motion of a charged particle in an electromagnetic field, the canonical momentum P (derived from the Lagrangian for this system) is not gauge invariant. As a consequence, the canonical angular momentum L = r × P is not gauge invariant either. Instead, the momentum that is physical, the so-called \"kinetic momentum\" (used throughout this article), is (in SI units)\n\nwhere \"e\" is the electric charge of the particle and A the magnetic vector potential of the electromagnetic field. The gauge-invariant angular momentum, that is \"kinetic angular momentum\", is given by\n\nThe interplay with quantum mechanics is discussed further in the article on canonical commutation relations.\n\nIn \"classical Maxwell electrodynamics\" the Pointing vector\nis a linear momentum density of electromagnetic field\n\nThe angular momentum density vector formula_159 is given by a vector product\nas in classical mechanics:\n\nThe above identities are valid \" locally \", i.e. in each space point formula_161 in a given moment formula_162.\n\nNewton, in the \"Principia\", hinted at angular momentum in his examples of the First Law of Motion,\n\nHe did not further investigate angular momentum directly in the \"Principia\",\nHowever, his geometric proof of the Law of Areas is an outstanding example of Newton's genius, and indirectly proves angular momentum conservation in the case of a central force.\n\nAs a planet orbits the Sun, the line between the Sun and the planet sweeps out equal areas in equal intervals of time. This had been known since Kepler expounded his Second Law of Planetary Motion. Newton derived a unique geometric proof, and went on to show that the attractive force of the Sun's gravity was the cause of all of Kepler's laws.\n\nDuring the first interval of time, an object is in motion from point A to point B. Undisturbed, it would continue to point c during the second interval. When the object arrives at B, it receives an impulse directed toward point S. The impulse gives it a small added velocity toward S, such that if this were its only velocity, it would move from B to V during the second interval. By the rules of velocity composition, these two velocities add, and point C is found by construction of parallelogram BcCV. Thus the object's path is deflected by the impulse so that it arrives at point C at the end of the second interval. Because the triangles SBc and SBC have the same base SB and the same height Bc or VC, they have the same area. By symmetry, triangle SBc also has the same area as triangle SAB, therefore the object has swept out equal areas SAB and SBC in equal times.\n\nAt point C, the object receives another impulse toward S, again deflecting its path during the third interval from d to D. Thus it continues to E and beyond, the triangles SAB, SBc, SBC, SCd, SCD, SDe, SDE all having the same area. Allowing the time intervals to become ever smaller, the path ABCDE approaches indefinitely close to a continuous curve.\n\nNote that because this derivation is geometric, and no specific force is applied, it proves a more general law than Kepler's Second Law of Planetary Motion. It shows that the Law of Areas applies to any central force, attractive or repulsive, continuous or non-continuous, or zero.\n\nThe proportionality of angular momentum to the area swept out by a moving object can be understood by realizing that the bases of the triangles, that is, the lines from S to the object, are equivalent to the radius, and that the heights of the triangles are proportional to the perpendicular component of velocity. Hence, if the area swept per unit time is constant, then by the triangular area formula , the product and therefore the product are constant: if and the base length are decreased, and height must increase proportionally. Mass is constant, therefore angular momentum is conserved by this exchange of distance and velocity.\n\nIn the case of triangle SBC, area is equal to (SB)(VC). Wherever C is eventually located due to the impulse applied at B, the product (SB)(VC), and therefore remain constant. Similarly so for each of the triangles.\n\nLeonhard Euler, Daniel Bernoulli, and Patrick d'Arcy all understood angular momentum in terms of conservation of areal velocity, a result of their analysis of Kepler's Second Law of planetary motion. It is unlikely that they realized the implications for ordinary rotating matter.\n\nIn 1736 Euler, like Newton, touched on some of the equations of angular momentum in his \"Mechanica\" without further developing them.\n\nBernoulli wrote in a 1744 letter of a \"moment of rotational motion\", possibly the first conception of angular momentum as we now understand it.\n\nIn 1799, Pierre-Simon Laplace first realized that a fixed plane was associated with rotation — his \"invariable plane\".\n\nLouis Poinsot in 1803 began representing rotations as a line segment perpendicular to the rotation, and elaborated on the \"conservation of moments\".\n\nIn 1852 Léon Foucault used a gyroscope in an experiment to display the Earth's rotation.\n\nWilliam J. M. Rankine's 1858 \"Manual of Applied Mechanics\" defined angular momentum in the modern sense for the first time:\n\nIn an 1872 edition of the same book, Rankine stated that \"The term \"angular momentum\" was introduced by Mr. Hayward,\" probably referring to R.B. Hayward's article \"On a Direct Method of estimating Velocities, Accelerations, and all similar Quantities with respect to Axes moveable in any manner in Space with Applications,\" which was introduced in 1856, and published in 1864. Rankine was mistaken, as numerous publications feature the term starting in the late 18th to early 19th centuries. However, Hayward's article apparently was the first use of the term and the concept seen by much of the English-speaking world. Before this, angular momentum was typically referred to as \"momentum of rotation\" in English.\n\n\n", "id": "2839", "title": "Angular momentum"}
{"url": "https://en.wikipedia.org/wiki?curid=2840", "text": "Plum pudding model\n\nThe plum pudding model is one of several scientific models of the atom. First proposed by J. J. Thomson in 1904 soon after the discovery of the electron, but before the discovery of the atomic nucleus, the model represented an attempt to consolidate the known properties of atoms at the time: 1) electrons are negatively-charged particles and 2) atoms are neutrally-charged.\n\nIn this model, atoms were known to consist of negatively charged electrons. Though Thomson called them \"corpuscles\", they were more commonly called \"electrons\" as G. J. Stoney proposed in 1894. At the time, atoms were known to be neutrally charged. To account for this, Thomson knew atoms must also have a source of positive charge to balance the negative charge of the electrons. He considered three plausible models that would satisfy the known properties of atoms at the time:\n\n\nThomson chose the third possibility as the most likely structure of atoms. Thomson published his proposed model in the March 1904 edition of the \"Philosophical Magazine\", the leading British science journal of the day. In Thomson's view:\n... the atoms of the elements consist of a number of negatively electrified corpuscles enclosed in a sphere of uniform positive electrification, ...\n\nWith this model, Thomson abandoned his earlier \"nebular atom\" hypothesis in which atoms were composed of immaterial vortices. Being an astute and practical scientist, Thomson based his atomic model on known experimental evidence of the day. His proposal of a positive volume charge reflects the nature of his scientific approach to discovery which was to propose ideas to guide future experiments.\n\nThe orbits of electrons within the model were stabilized by the fact that when an electron moved away from the centre of the positively-charged sphere, it was subjected to a greater net positive inward force, because there was more positive charge inside its orbit (see Gauss's law). Electrons were free to rotate in rings which were further stabilized by interactions among the electrons, and spectroscopic measurements were meant to account for energy differences associated with different electron rings. Thomson attempted unsuccessfully to reshape his model to account for some of the major spectral lines experimentally known for several elements.\n\nThe plum pudding model usefully guided his student, Ernest Rutherford, to devise experiments to further explore the composition of atoms. As well, Thomson's model (along with a similar Saturnian ring model for atomic electrons put forward in 1904 by Nagaoka after James Clerk Maxwell's model of Saturn's rings), were useful predecessors of the more correct solar-system-like Bohr model of the atom.\n\nThe colloquial nickname \"plum pudding\" was soon attributed to Thomson's model as the distribution of electrons within its positively-charged region of space reminded many scientists of \"plums\" in the common English dessert, plum pudding.\n\nIn 1909, Hans Geiger and Ernest Marsden conducted experiments with thin sheets of gold. Their professor, Ernest Rutherford, expected to find results consistent with Thomson's atomic model. It wasn't until 1911 that Rutherford correctly interpreted the experiment's results which implied the presence of a very small nucleus of positive charge at the center of gold atoms. This led to the development of the Rutherford model of the atom. Immediately after Rutherford published his results, Antonius Van den Broek made the intuitive proposal that the atomic number of an atom is the total number of units of charge present in its nucleus. Henry Moseley's 1913 experiments (see Moseley's law) provided the necessary evidence to support Van den Broek's proposal. The effective nuclear charge was found to be consistent with the atomic number (Moseley found only one unit of charge difference). This work culminated in the solar-system-like (but quantum-limited) Bohr model of the atom in the same year, in which a nucleus containing an atomic number of positive charges is surrounded by an equal number of electrons in orbital shells. As Thomson's model guided Rutherford's experiments, Bohr's model guided Moseley's research.\n\nThe plum pudding model with a single electron was used in part by the physicist Arthur Erich Haas in 1910 to estimate the numerical value of Planck's constant and the Bohr radius of hydrogen atoms. Haas' work estimated these values to within an order of magnitude and preceded the work of Niels Bohr by three years. Of note, the Bohr model itself only provides substantially-reasonable predictions for atomic and ionic systems having a single effective electron.\n\nA particularly useful mathematics problem related to the plum pudding model is the optimal distribution of equal point charges on a unit sphere called the Thomson problem. The Thomson problem is a natural consequence of the plum pudding model in the absence of its uniform positive background charge.\n\nThe classical electrostatic treatment of electrons confined to spherical quantum dots is also similar to their treatment in the plum pudding model. In this classical problem, the quantum dot is modeled as a simple dielectric sphere (in place of a uniform, positively-charged sphere as in the plum pudding model) in which free, or excess, electrons reside. The electrostatic N-electron configurations are found to be exceptionally close to solutions found in the Thomson problem with electrons residing at the same radius within the dielectric sphere. Notably, the plotted distribution of geometry-dependent energetics has been shown to bear a remarkable resemblance to the distribution of anticipated electron orbitals in natural atoms as arranged on the periodic table of elements. Of great interest, solutions of the Thomson problem exhibit this corresponding energy distribution by comparing the energy of each N-electron solution with the energy of its neighbouring (N-1)-electron solution with one charge at the origin. However, when treated within a dielectric sphere model, the features of the distribution are much more pronounced and provide greater fidelity with respect to electron orbital arrangements in real atoms.\n", "id": "2840", "title": "Plum pudding model"}
{"url": "https://en.wikipedia.org/wiki?curid=2844", "text": "Atomic theory\n\nIn chemistry and physics, atomic theory is a scientific theory of the nature of matter, which states that matter is composed of discrete units called atoms. It began as a philosophical concept in ancient Greece and entered the scientific mainstream in the early 19th century when discoveries in the field of chemistry showed that matter did indeed behave as if it were made up of atoms.\n\nThe word \"atom\" comes from the Ancient Greek adjective \"atomos\", meaning \"indivisible\". 19th century chemists began using the term in connection with the growing number of irreducible chemical elements. While seemingly apropos, around the turn of the 20th century, through various experiments with electromagnetism and radioactivity, physicists discovered that the so-called \"uncuttable atom\" was actually a conglomerate of various subatomic particles (chiefly, electrons, protons and neutrons) which can exist separately from each other. In fact, in certain extreme environments, such as neutron stars, extreme temperature and pressure prevents atoms from existing at all. Since atoms were found to be divisible, physicists later invented the term \"elementary particles\" to describe the \"uncuttable\", though not indestructible, parts of an atom. The field of science which studies subatomic particles is particle physics, and it is in this field that physicists hope to discover the true fundamental nature of matter.\n\nThe idea that matter is made up of discrete units is a very old one, appearing in many ancient cultures such as Greece and India. However, these ideas were founded in philosophical and theological reasoning rather than evidence and experimentation. Because of this, they could not convince everybody, so atomism was but one of a number of competing theories on the nature of matter. It was not until the 19th century that the idea was embraced and refined by scientists, as the blossoming science of chemistry produced discoveries that could easily be explained using the concept of atoms.\n\nNear the end of the 18th century, two laws about chemical reactions emerged without referring to the notion of an atomic theory. The first was the law of conservation of mass, formulated by Antoine Lavoisier in 1789, which states that the total mass in a chemical reaction remains constant (that is, the reactants have the same mass as the products). The second was the law of definite proportions. First proven by the French chemist Joseph Louis Proust in 1799, this law states that if a compound is broken down into its constituent elements, then the masses of the constituents will always have the same proportions, regardless of the quantity or source of the original substance.\n\nJohn Dalton studied and expanded upon this previous work and developed the law of multiple proportions: if two elements can be combined to form a number of possible compounds, then the ratios of the masses of the second element which combine with a fixed mass of the first element will be ratios of small whole numbers. For example: Proust had studied tin oxides and found that their masses were either 88.1% tin and 11.9% oxygen or 78.7% tin and 21.3% oxygen (these were tin(II) oxide and tin dioxide respectively). Dalton noted from these percentages that 100g of tin will combine either with 13.5g or 27g of oxygen; 13.5 and 27 form a ratio of 1:2. Dalton found that an atomic theory of matter could elegantly explain this common pattern in chemistry. In the case of Proust's tin oxides, one tin atom will combine with either one or two oxygen atoms.\n\nDalton believed atomic theory could explain why water absorbed different gases in different proportions - for example, he found that water absorbed carbon dioxide far better than it absorbed nitrogen. Dalton hypothesized this was due to the differences in mass and complexity of the gases' respective particles. Indeed, carbon dioxide molecules (CO) are heavier and larger than nitrogen molecules (N).\n\nDalton proposed that each chemical element is composed of atoms of a single, unique type, and though they cannot be altered or destroyed by chemical means, they can combine to form more complex structures (chemical compounds). This marked the first truly scientific theory of the atom, since Dalton reached his conclusions by experimentation and examination of the results in an empirical fashion.\nIn 1803 Dalton orally presented his first list of relative atomic weights for a number of substances. This paper was published in 1805, but he did not discuss there exactly how he obtained these figures. The method was first revealed in 1807 by his acquaintance Thomas Thomson, in the third edition of Thomson's textbook, \"A System of Chemistry\". Finally, Dalton published a full account in his own textbook, \"A New System of Chemical Philosophy\", 1808 and 1810.\n\nDalton estimated the atomic weights according to the mass ratios in which they combined, with the hydrogen atom taken as unity. However, Dalton did not conceive that with some elements atoms exist in molecules—e.g. pure oxygen exists as O. He also mistakenly believed that the simplest compound between any two elements is always one atom of each (so he thought water was HO, not HO). This, in addition to the crudity of his equipment, flawed his results. For instance, in 1803 he believed that oxygen atoms were 5.5 times heavier than hydrogen atoms, because in water he measured 5.5 grams of oxygen for every 1 gram of hydrogen and believed the formula for water was HO. Adopting better data, in 1806 he concluded that the atomic weight of oxygen must actually be 7 rather than 5.5, and he retained this weight for the rest of his life. Others at this time had already concluded that the oxygen atom must weigh 8 relative to hydrogen equals 1, if one assumes Dalton's formula for the water molecule (HO), or 16 if one assumes the modern water formula (HO).\n\nThe flaw in Dalton's theory was corrected in principle in 1811 by Amedeo Avogadro. Avogadro had proposed that equal volumes of any two gases, at equal temperature and pressure, contain equal numbers of molecules (in other words, the mass of a gas's particles does not affect the volume that it occupies). Avogadro's law allowed him to deduce the diatomic nature of numerous gases by studying the volumes at which they reacted. For instance: since two liters of hydrogen will react with just one liter of oxygen to produce two liters of water vapor (at constant pressure and temperature), it meant a single oxygen molecule splits in two in order to form two particles of water. Thus, Avogadro was able to offer more accurate estimates of the atomic mass of oxygen and various other elements, and made a clear distinction between molecules and atoms.\n\nIn 1827, the British botanist Robert Brown observed that dust particles inside pollen grains floating in water constantly jiggled about for no apparent reason. In 1905, Albert Einstein theorized that this Brownian motion was caused by the water molecules continuously knocking the grains about, and developed a hypothetical mathematical model to describe it. This model was validated experimentally in 1908 by French physicist Jean Perrin, thus providing additional validation for particle theory (and by extension atomic theory).\n\nAtoms were thought to be the smallest possible division of matter until 1897 when J.J. Thomson discovered the electron through his work on cathode rays.\n\nA Crookes tube is a sealed glass container in which two electrodes are separated by a vacuum. When a voltage is applied across the electrodes, cathode rays are generated, creating a glowing patch where they strike the glass at the opposite end of the tube. Through experimentation, Thomson discovered that the rays could be deflected by an electric field (in addition to magnetic fields, which was already known). He concluded that these rays, rather than being a form of light, were composed of very light negatively charged particles he called \"corpuscles\" (they would later be renamed electrons by other scientists). He measured the mass-to-charge ratio and discovered it was 1800 times smaller than that of hydrogen, the smallest atom. These corpuscles were a particle unlike any other previously known.\n\nThomson suggested that atoms were divisible, and that the corpuscles were their building blocks. To explain the overall neutral charge of the atom, he proposed that the corpuscles were distributed in a uniform sea of positive charge; this was the plum pudding model as the electrons were embedded in the positive charge like plums in a plum pudding (although in Thomson's model they were not stationary).\n\nThomson's plum pudding model was disproved in 1909 by one of his former students, Ernest Rutherford, who discovered that most of the mass and positive charge of an atom is concentrated in a very small fraction of its volume, which he assumed to be at the very center.\n\nIn the Geiger–Marsden experiment, Hans Geiger and Ernest Marsden (colleagues of Rutherford working at his behest) shot alpha particles at thin sheets of metal and measured their deflection through the use of a fluorescent screen. Given the very small mass of the electrons, the high momentum of the alpha particles, and the low concentration of the positive charge of the plum pudding model, the experimenters expected all the alpha particles to pass through the metal foil without significant deflection. To their astonishment, a small fraction of the alpha particles experienced heavy deflection. Rutherford concluded that the positive charge of the atom must be concentrated in a very tiny volume to produce an electric field sufficiently intense to deflect the alpha particles so strongly.\n\nThis led Rutherford to propose a planetary model in which a cloud of electrons surrounded a small, compact nucleus of positive charge. Only such a concentration of charge could produce the electric field strong enough to cause the heavy deflection.\n\nThe planetary model of the atom had two significant shortcomings. The first is that, unlike planets orbiting a sun, electrons are charged particles. An accelerating electric charge is known to emit electromagnetic waves according to the Larmor formula in classical electromagnetism. An orbiting charge should steadily lose energy and spiral toward the nucleus, colliding with it in a small fraction of a second. The second problem was that the planetary model could not explain the highly peaked emission and absorption spectra of atoms that were observed.\nQuantum theory revolutionized physics at the beginning of the 20th century, when Max Planck and Albert Einstein postulated that light energy is emitted or absorbed in discrete amounts known as quanta (singular, \"quantum\"). In 1913, Niels Bohr incorporated this idea into his Bohr model of the atom, in which an electron could only orbit the nucleus in particular circular orbits with fixed angular momentum and energy, its distance from the nucleus (i.e., their radii) being proportional to its energy. Under this model an electron could not spiral into the nucleus because it could not lose energy in a continuous manner; instead, it could only make instantaneous \"quantum leaps\" between the fixed energy levels. When this occurred, light was emitted or absorbed at a frequency proportional to the change in energy (hence the absorption and emission of light in discrete spectra).\n\nBohr's model was not perfect. It could only predict the spectral lines of hydrogen; it couldn't predict those of multielectron atoms. Worse still, as spectrographic technology improved, additional spectral lines in hydrogen were observed which Bohr's model couldn't explain. In 1916, Arnold Sommerfeld added elliptical orbits to the Bohr model to explain the extra emission lines, but this made the model very difficult to use, and it still couldn't explain more complex atoms.\n\nWhile experimenting with the products of radioactive decay, in 1913 radiochemist Frederick Soddy discovered that there appeared to be more than one element at each position on the periodic table. The term isotope was coined by Margaret Todd as a suitable name for these elements.\n\nThat same year, J.J. Thomson conducted an experiment in which he channeled a stream of neon ions through magnetic and electric fields, striking a photographic plate at the other end. He observed two glowing patches on the plate, which suggested two different deflection trajectories. Thomson concluded this was because some of the neon ions had a different mass. The nature of this differing mass would later be explained by the discovery of neutrons in 1932.\n\nIn 1917 Rutherford bombarded nitrogen gas with alpha particles and observed hydrogen nuclei being emitted from the gas (Rutherford recognized these, because he had previously obtained them bombarding hydrogen with alpha particles, and observing hydrogen nuclei in the products). Rutherford concluded that the hydrogen nuclei emerged from the nuclei of the nitrogen atoms themselves (in effect, he had split a nitrogen).\n\nFrom his own work and the work of his students Bohr and Henry Moseley, Rutherford knew that the positive charge of any atom could always be equated to that of an integer number of hydrogen nuclei. This, coupled with the atomic mass of many elements being roughly equivalent to an integer number of hydrogen atoms - then assumed to be the lightest particles - led him to conclude that hydrogen nuclei were singular particles and a basic constituent of all atomic nuclei. He named such particles protons. Further experimentation by Rutherford found that the nuclear mass of most atoms exceeded that of the protons it possessed; he speculated that this surplus mass was composed of hitherto unknown neutrally charged particles, which were tentatively dubbed \"neutrons\".\n\nIn 1928, Walter Bothe observed that beryllium emitted a highly penetrating, electrically neutral radiation when bombarded with alpha particles. It was later discovered that this radiation could knock hydrogen atoms out of paraffin wax. Initially it was thought to be high-energy gamma radiation, since gamma radiation had a similar effect on electrons in metals, but James Chadwick found that the ionization effect was too strong for it to be due to electromagnetic radiation, so long as energy and momentum were conserved in the interaction. In 1932, Chadwick exposed various elements, such as hydrogen and nitrogen, to the mysterious \"beryllium radiation\", and by measuring the energies of the recoiling charged particles, he deduced that the radiation was actually composed of electrically neutral particles which could not be massless like the gamma ray, but instead were required to have a mass similar to that of a proton. Chadwick now claimed these particles as Rutherford's neutrons. For his discovery of the neutron, Chadwick received the Nobel Prize in 1935.\n\nIn 1924, Louis de Broglie proposed that all moving particles—particularly subatomic particles such as electrons—exhibit a degree of wave-like behavior. Erwin Schrödinger, fascinated by this idea, explored whether or not the movement of an electron in an atom could be better explained as a wave rather than as a particle. Schrödinger's equation, published in 1926, describes an electron as a wavefunction instead of as a point particle. This approach elegantly predicted many of the spectral phenomena that Bohr's model failed to explain. Although this concept was mathematically convenient, it was difficult to visualize, and faced opposition. One of its critics, Max Born, proposed instead that Schrödinger's wavefunction described not the electron but rather all its possible states, and thus could be used to calculate the probability of finding an electron at any given location around the nucleus. This reconciled the two opposing theories of particle versus wave electrons and the idea of wave–particle duality was introduced. This theory stated that the electron may exhibit the properties of both a wave and a particle. For example, it can be refracted like a wave, and has mass like a particle.\n\nA consequence of describing electrons as waveforms is that it is mathematically impossible to simultaneously derive the position and momentum of an electron. This became known as the Heisenberg uncertainty principle after the theoretical physicist Werner Heisenberg, who first described it and published it in 1927. This invalidated Bohr's model, with its neat, clearly defined circular orbits. The modern model of the atom describes the positions of electrons in an atom in terms of probabilities. An electron can potentially be found at any distance from the nucleus, but, depending on its energy level, exists more frequently in certain regions around the nucleus than others; this pattern is referred to as its atomic orbital. The orbitals come in a variety of shapes-sphere, dumbbell, torus, etc.-with the nucleus in the middle.\n\n\n", "id": "2844", "title": "Atomic theory"}
{"url": "https://en.wikipedia.org/wiki?curid=2846", "text": "Ai\n\nAI, A.I., Ai, or ai may refer to:\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "2846", "title": "Ai"}
{"url": "https://en.wikipedia.org/wiki?curid=2847", "text": "Aung San Suu Kyi\n\nAung San Suu Kyi (, , ; born 19 June 1945) is a Burmese politician, diplomat, and author who is the First and incumbent State Counsellor and Leader of the National League for Democracy. She is also the first woman to serve as Minister of Foreign Affairs of Myanmar, the Minister of the President's Office, the Minister of Electric Power and Energy, and the Minister of Education in President Htin Kyaw's Cabinet, and from 2012 to 2016 was a Pyithu Hluttaw MP for Kawhmu Township.\n\nThe youngest daughter of Aung San, Father of the Nation of modern-day Myanmar, and Khin Kyi, Aung San Suu Kyi was born in Rangoon, British Burma. After graduating from the University of Delhi in 1964 and the University of Oxford in 1968, she worked at the United Nations for three years. She married Michael Aris in 1972, and gave birth to two children. Aung San Suu Kyi rose to prominence in the 1988 Uprisings, and became the General Secretary of the newly formed National League for Democracy (NLD). In the 1990 elections, NLD won 81% of the seats in Parliament, but the results were nullified, as the military refused to hand over power, resulting in an international outcry. She had, however, already been detained under house arrest before the elections. She remained under house arrest for almost 15 of the 21 years from 1989 to 2010, becoming one of the world's most prominent political prisoners.\n\nHer party boycotted the 2010 elections, resulting in a decisive victory for the military-backed Union Solidarity and Development Party. Aung San Suu Kyi became a Pyithu Hluttaw MP while her party won 43 of the 45 vacant seats in the 2012 by-elections. In the 2015 elections, her party won a landslide victory, taking 86% of the seats in the Assembly of the Union – well more than the 67 percent supermajority needed to ensure that its preferred candidates were elected President and Second Vice President in the Presidential Electoral College. Although she was prohibited from becoming the President due to a clause in the constitution – her late husband and children are foreign citizens – she assumed the newly created role of State Counsellor, a role akin to a Prime Minister or a head of government.\n\nAung San Suu Kyi has gained international acclaim, having received many honours, including the Rafto Prize, Sakharov Prize, Nobel Peace Prize, Jawaharlal Nehru Award, Order of Australia, US Congressional Gold Medal, and Presidential Medal of Freedom. She is an honorary citizen of many countries, including Canada, and was an honorary member of Nelson Mandela's Elders.\n\n\"Aung San Suu Kyi\", like other Burmese names, includes no family name, but is only a personal name, in her case derived from three relatives: \"Aung San\" from her father, \"Suu\" from her paternal grandmother, and \"Kyi\" from her mother Khin Kyi.\n\nThe Burmese refer to her as Daw Aung San Suu Kyi. \"Daw\", literally meaning \"aunt\", is not part of her name but is a Burmese honorific for any older and revered woman, akin to \"Madame\". Burmese sometimes address her as Daw Suu or Amay Suu (\"Mother Suu\").\n\nAung San Suu Kyi was born on 19 June 1945 in Rangoon (now Yangon), British Burma. According to Peter Popham, she was born in a small village outside Rangoon called Hmway Saung. Her father, Aung San, founded the modern Burmese army and negotiated Burma's independence from the British Empire in 1947; he was assassinated by his rivals in the same year. She grew up with her mother, Khin Kyi, and two brothers, Aung San Lin and Aung San Oo, in Rangoon. Aung San Lin died at the age of eight, when he drowned in an ornamental lake on the grounds of the house. Her elder brother emigrated to San Diego, California, becoming a United States citizen. After Aung San Lin's death, the family moved to a house by Inya Lake where Aung San Suu Kyi met people of various backgrounds, political views and religions. She was educated in Methodist English High School (now Basic Education High School No. 1 Dagon) for much of her childhood in Burma, where she was noted as having a talent for learning languages. She speaks four languages: Burmese, English, French and Japanese. She is a Theravada Buddhist.\nSuu Kyi's mother, Khin Kyi, gained prominence as a political figure in the newly formed Burmese government. She was appointed Burmese ambassador to India and Nepal in 1960, and Aung San Suu Kyi followed her there. She studied in the Convent of Jesus and Mary School in New Delhi, and graduated from Lady Shri Ram College in New Delhi with a degree in politics in 1964. Suu Kyi continued her education at St Hugh's College, Oxford, obtaining a B.A degree in Philosophy, Politics and Economics in 1967, graduating with a third and M.A degree in politics in 1968. After graduating, she lived in New York City with family friend Ma Than E, who was once a popular Burmese pop singer. She worked at the United Nations for three years, primarily on budget matters, writing daily to her future husband, Dr. Michael Aris. On 1 January 1972, Aung San Suu Kyi and Aris, a scholar of Tibetan culture, living abroad in Bhutan, were married. The following year she gave birth to their first son, Alexander Aris, in London; their second son, Kim, was born in 1977. Between 1985 and 1987, Suu Kyi was working toward an M.Phil degree in Burmese literature as a research student at SOAS, the School of Oriental and African Studies, University of London. She was elected as an Honorary Fellow of SOAS in 1990. For two years, she was a Fellow at the Indian Institute of Advanced Studies (IIAS) in Shimla, India. She also worked for the government of the Union of Burma.\n\nIn 1988, Suu Kyi returned to Burma, at first to tend for her ailing mother but later to lead the pro-democracy movement. Aris' visit in Christmas 1995 turned out to be the last time that he and Suu Kyi met, as Suu Kyi remained in Burma and the Burmese dictatorship denied him any further entry visas. Aris was diagnosed with prostate cancer in 1997 which was later found to be terminal. Despite appeals from prominent figures and organizations, including the United States, UN Secretary General Kofi Annan and Pope John Paul II, the Burmese government would not grant Aris a visa, saying that they did not have the facilities to care for him, and instead urged Aung San Suu Kyi to leave the country to visit him. She was at that time temporarily free from house arrest but was unwilling to depart, fearing that she would be refused re-entry if she left, as she did not trust the military junta's assurance that she could return.\n\nAris died on his 53rd birthday on 27 March 1999. Since 1989, when his wife was first placed under house arrest, he had seen her only five times, the last of which was for Christmas in 1995. She was also separated from her children, who live in the United Kingdom, but starting in 2011, they have visited her in Burma.\n\nOn 2 May 2008, after Cyclone Nargis hit Burma, Suu Kyi lost the roof of her house and lived in virtual darkness after losing electricity in her dilapidated lakeside residence. She used candles at night as she was not provided any generator set. Plans to renovate and repair the house were announced in August 2009. Suu Kyi was released from house arrest on 13 November 2010.\n\nCoincidentally, when Aung San Suu Kyi returned to Burma in 1988, the long-time military leader of Burma and head of the ruling party, General Ne Win, stepped down. Mass demonstrations for democracy followed that event on 8 August 1988 (8–8–88, a day seen as auspicious), which were violently suppressed in what came to be known as the 8888 Uprising. On 26 August 1988, she addressed half a million people at a mass rally in front of the Shwedagon Pagoda in the capital, calling for a democratic government. However, in September, a new military junta took power.\n\nInfluenced by both Mahatma Gandhi's philosophy of non-violence and more specifically by Buddhist concepts, Aung San Suu Kyi entered politics to work for democratization, helped found the National League for Democracy on 27 September 1988, but was put under house arrest on 20 July 1989. Offered freedom if she left the country, she refused. Despite her philosophy of non-violence, a group of ex-military commanders and senior politicians who joined NLD during the crisis believed that she was too confrontational and left NLD. However, she retained enormous popularity and support among NLD youths with whom she spent most of her time.\n\nDuring her time under house arrest, Suu Kyi devoted herself to Buddhist meditation practices and to studying Buddhist thought. This deeper interest in Buddhism is reflected in her writings as more emphasis is put on love and compassion. There also emerged more discussion on the compatibility of democracy and Buddhism and the ability of gaining freedom from an authoritarian government through Buddhism.\n\nDuring the crisis, the previous democratically elected Prime Minister of Burma, U Nu initiated to form an interim government and invited opposition leaders to join him. Indian Prime Minister Rajiv Gandhi had signaled his readiness to recognize the interim government. However, Aung San Suu Kyi categorically rejected U Nu's plan by saying \"the future of the opposition would be decided by masses of the people\". Ex-Brigadier General Aung Gyi, another influential politician at the time of the 8888 crisis, followed the suit and rejected the plan after Suu Kyi's refusal. Aung Gyi later accused several NLD members of being communists and resigned from the party.\nIn 1990, the military junta called a general election, in which the National League for Democracy (NLD) received 59% of the votes, guaranteeing NLD 80% of the parliament seats. Some claim that Aung San Suu Kyi would have assumed the office of Prime Minister; in fact, however, as she was not permitted, she did not stand as a candidate in the elections (although being a MP is not a strict prerequisite for becoming PM in most parliamentary systems). Instead, the results were nullified and the military refused to hand over power, resulting in an international outcry. Aung San Suu Kyi was placed under house arrest at her home on University Avenue () in Rangoon, during which time she was awarded the Sakharov Prize for Freedom of Thought in 1990, and the Nobel Peace Prize the year after. Her sons Alexander and Kim accepted the Nobel Peace Prize on her behalf. Aung San Suu Kyi used the Nobel Peace Prize's 1.3 million USD prize money to establish a health and education trust for the Burmese people. Around this time, Suu Kyi chose non-violence as an expedient political tactic, stating in 2007, \"I do not hold to non-violence for moral reasons, but for political and practical reasons.\"\n\nOn 9 November 1996, the motorcade that Aung San Suu Kyi was traveling in with other National League for Democracy leaders Tin Oo and Kyi Maung, was attacked in Yangon. About 200 men swooped down on the motorcade, wielding metal chains, metal batons, stones and other weapons. The car that Aung San Suu Kyi was in had its rear window smashed, and the car with Tin Oo and Kyi Maung had its rear window and two backdoor windows shattered. It is believed the offenders were members of the Union Solidarity and Development Association (USDA) who were allegedly paid 500 kyats (@ USD $0.50) each to participate. The NLD lodged an official complaint with the police, and according to reports the government launched an investigation, but no action was taken. (Amnesty International 120297)\n\nAung San Suu Kyi was placed under house arrest for a total of 15 years over a 21-year period, on numerous occasions, since she began her political career, during which time she was prevented from meeting her party supporters and international visitors. In an interview, Suu Kyi said that while under house arrest she spent her time reading philosophy, politics and biographies that her husband had sent her. She also passed the time playing the piano, and was occasionally allowed visits from foreign diplomats as well as from her personal physician.\n\nAlthough under house arrest, Suu Kyi was granted permission to leave Burma under the condition that she never return. Rather than abandon her people, Suu Kyi submitted to house arrest and decided to sacrifice a life with her husband and her two young sons, in order to stand by her people: \"As a mother, the greater sacrifice was giving up my sons, but I was always aware of the fact that others had given up more than me. I never forget that my colleagues who are in prison suffer not only physically, but mentally for their families who have no security outside- in the larger prison of Burma under authoritarian rule.\" Her loyalty to the people of Burma and her solidarity with those imprisoned for their pro-democratic acts have earned her deep respect among the Burmese people.\n\nThe media were also prevented from visiting Suu Kyi, as occurred in 1998 when journalist Maurizio Giuliano, after photographing her, was stopped by customs officials who then confiscated all his films, tapes and some notes. In contrast, Suu Kyi did have visits from government representatives, such as during her autumn 1994 house arrest when she met the leader of Burma, General Than Shwe and General Khin Nyunt on 20 September in the first meeting since she had been placed in detention. On several occasions during Suu Kyi's house arrest, she had periods of poor health and as a result was hospitalized.\n\nThe Burmese government detained and kept Suu Kyi imprisoned because it viewed her as someone \"likely to undermine the community peace and stability\" of the country, and used both Article 10(a) and 10(b) of the 1975 State Protection Act (granting the government the power to imprison people for up to five years without a trial), and Section 22 of the \"Law to Safeguard the State Against the Dangers of Those Desiring to Cause Subversive Acts\" as legal tools against her. She continuously appealed her detention, and many nations and figures continued to call for her release and that of 2,100 other political prisoners in the country. On 12 November 2010, days after the junta-backed Union Solidarity and Development Party (USDP) won elections conducted after a gap of 20 years, the junta finally agreed to sign orders allowing Suu Kyi's release, and Suu Kyi's house arrest term came to an end on 13 November 2010.\n\nThe United Nations (UN) has attempted to facilitate dialogue between the junta and Suu Kyi. On 6 May 2002, following secret confidence-building negotiations led by the UN, the government released her; a government spokesman said that she was free to move \"because we are confident that we can trust each other\". Aung San Suu Kyi proclaimed \"a new dawn for the country\". However, on 30 May 2003 in an incident similar to the 1996 attack on her, a government-sponsored mob attacked her caravan in the northern village of Depayin, murdering and wounding many of her supporters. Aung San Suu Kyi fled the scene with the help of her driver, Kyaw Soe Lin, but was arrested upon reaching Ye-U. The government imprisoned her at Insein Prison in Rangoon. After she underwent a hysterectomy in September 2003, the government again placed her under house arrest in Rangoon.\n\nThe results from the UN facilitation have been mixed; Razali Ismail, UN special envoy to Burma, met with Aung San Suu Kyi. Ismail resigned from his post the following year, partly because he was denied re-entry to Burma on several occasions. Several years later in 2006, Ibrahim Gambari, UN Undersecretary-General (USG) of Department of Political Affairs, met with Aung San Suu Kyi, the first visit by a foreign official since 2004. He also met with Suu Kyi later the same year. On 2 October 2007 Gambari returned to talk to her again after seeing Than Shwe and other members of the senior leadership in Naypyidaw. State television broadcast Suu Kyi with Gambari, stating that they had met twice. This was Suu Kyi's first appearance in state media in the four years since her current detention began.\n\nThe United Nations Working Group for Arbitrary Detention published an Opinion that Aung San Suu Kyi's deprivation of liberty was arbitrary and in contravention of Article 9 of the Universal Declaration of Human Rights 1948, and requested that the authorities in Burma set her free, but the authorities ignored the request at that time. The U.N. report said that according to the Burmese Government's reply, \"Daw Aung San Suu Kyi has not been arrested, but has only been taken into protective custody, for her own safety\", and while \"it could have instituted legal action against her under the country's domestic legislation ... it has preferred to adopt a magnanimous attitude, and is providing her with protection in her own interests.\"\n\nSuch claims were rejected by Brig-General Khin Yi, Chief of Myanmar Police Force (MPF). On 18 January 2007, the state-run paper \"New Light of Myanmar\" accused Suu Kyi of tax evasion for spending her Nobel Prize money outside the country. The accusation followed the defeat of a US-sponsored United Nations Security Council resolution condemning Burma as a threat to international security; the resolution was defeated because of strong opposition from China, which has strong ties with the military junta (China later voted against the resolution, along with Russia and South Africa).\n\nIn November 2007, it was reported that Suu Kyi would meet her political allies National League for Democracy along with a government minister. The ruling junta made the official announcement on state TV and radio just hours after UN special envoy Ibrahim Gambari ended his second visit to Burma. The NLD confirmed that it had received the invitation to hold talks with Suu Kyi. However, the process delivered few concrete results.\n\nOn 3 July 2009, UN Secretary-General Ban Ki-moon went to Burma to pressure the junta into releasing Suu Kyi and to institute democratic reform. However, on departing from Burma, Ban Ki-moon said he was \"disappointed\" with the visit after junta leader Than Shwe refused permission for him to visit Suu Kyi, citing her ongoing trial. Ban said he was \"deeply disappointed that they have missed a very important opportunity.\"\n\n\nProtests led by Buddhist monks began on 19 August 2007 following steep fuel price increases, and continued each day, despite the threat of a crackdown by the military.\n\nOn 22 September 2007, although still under house arrest, Suu Kyi made a brief public appearance at the gate of her residence in Yangon to accept the blessings of Buddhist monks who were marching in support of human rights. It was reported that she had been moved the following day to Insein Prison (where she had been detained in 2003), but meetings with UN envoy Ibrahim Gambari near her Rangoon home on 30 September and 2 October established that she remained under house arrest.\n\nOn 3 May 2009, an American man, identified as John Yettaw, swam across Inya Lake to her house uninvited and was arrested when he made his return trip three days later. He had attempted to make a similar trip two years earlier, but for unknown reasons was turned away. He later claimed at trial that he was motivated by a divine vision requiring him to notify her of an impending terrorist assassination attempt. On 13 May, Suu Kyi was arrested for violating the terms of her house arrest because the swimmer, who pleaded exhaustion, was allowed to stay in her house for two days before he attempted the swim back. Suu Kyi was later taken to Insein Prison, where she could have faced up to five years confinement for the intrusion. The trial of Suu Kyi and her two maids began on 18 May and a small number of protesters gathered outside. Diplomats and journalists were barred from attending the trial; however, on one occasion, several diplomats from Russia, Thailand and Singapore and journalists were allowed to meet Suu Kyi. The prosecution had originally planned to call 22 witnesses. It also accused John Yettaw of embarrassing the country. During the ongoing defence case, Suu Kyi said she was innocent. The defence was allowed to call only one witness (out of four), while the prosecution was permitted to call 14 witnesses. The court rejected two character witnesses, NLD members Tin Oo and Win Tin, and permitted the defence to call only a legal expert. According to one unconfirmed report, the junta was planning to, once again, place her in detention, this time in a military base outside the city. In a separate trial, Yettaw said he swam to Suu Kyi's house to warn her that her life was \"in danger\". The national police chief later confirmed that Yettaw was the \"main culprit\" in the case filed against Suu Kyi. According to aides, Suu Kyi spent her 64th birthday in jail sharing biryani rice and chocolate cake with her guards.\n\nHer arrest and subsequent trial received worldwide condemnation by the UN Secretary General Ban Ki-moon, the United Nations Security Council, Western governments, South Africa, Japan and the Association of Southeast Asian Nations, of which Burma is a member. The Burmese government strongly condemned the statement, as it created an \"unsound tradition\" and criticised Thailand for meddling in its internal affairs. The Burmese Foreign Minister Nyan Win was quoted in the state-run newspaper \"New Light of Myanmar\" as saying that the incident \"was trumped up to intensify international pressure on Burma by internal and external anti-government elements who do not wish to see the positive changes in those countries' policies toward Burma\". Ban responded to an international campaign by flying to Burma to negotiate, but Than Shwe rejected all of his requests.\n\nOn 11 August 2009 the trial concluded with Suu Kyi being sentenced to imprisonment for three years with hard labour. This sentence was commuted by the military rulers to further house arrest of 18 months. On 14 August, U.S. Senator Jim Webb visited Burma, visiting with junta leader Gen. Than Shwe and later with Suu Kyi. During the visit, Webb negotiated Yettaw's release and deportation from Burma. Following the verdict of the trial, lawyers of Suu Kyi said they would appeal against the 18-month sentence. On 18 August, United States President Barack Obama asked the country's military leadership to set free all political prisoners, including Aung San Suu Kyi. In her appeal, Aung San Suu Kyi had argued that the conviction was unwarranted. However, her appeal against the August sentence was rejected by a Burmese court on 2 October 2009. Although the court accepted the argument that the 1974 constitution, under which she had been charged, was null and void, it also said the provisions of the 1975 security law, under which she has been kept under house arrest, remained in force. The verdict effectively meant that she would be unable to participate in the elections scheduled to take place in 2010 – the first in Burma in two decades. Her lawyer stated that her legal team would pursue a new appeal within 60 days.\n\nIt was announced prior to the Burmese general election that Aung San Suu Kyi may be released \"so she can organize her party,\" However, Suu Kyi was not allowed to run. On 1 October 2010 the government announced that she would be released on 13 November 2010.\n\nU.S. President Barack Obama personally advocated the release of all political prisoners, especially Aung San Suu Kyi, during the US-ASEAN Summit of 2009.\n\nThe U.S. Government hoped that successful general elections would be an optimistic indicator of the Burmese government's sincerity towards eventual democracy. The Hatoyama government which spent 2.82 billion yen in 2008, has promised more Japanese foreign aid to encourage Burma to release Aung San Suu Kyi in time for the elections; and to continue moving towards democracy and the rule of law.\n\nIn a personal letter to Suu Kyi, UK Prime Minister Gordon Brown cautioned the Burmese government of the potential consequences of rigging elections as \"condemning Burma to more years of diplomatic isolation and economic stagnation\".\n\nSuu Kyi has met with many heads of state, and opened a dialog with the Minister of Labor Aung Kyi (not to be confused with Aung San Suu Kyi). She was allowed to meet with senior members of her NLD party at the State House, however these meetings took place under close supervision.\n\nOn the evening of 13 November 2010, Suu Kyi was released from house arrest. This was the date her detention had been set to expire according to a court ruling in August 2009 and came six days after a widely criticised general election. She appeared in front of a crowd of her supporters, who rushed to her house in Rangoon when nearby barricades were removed by the security forces. Suu Kyi had been detained for 15 of the past 21 years. The government newspaper \"New Light of Myanmar\" reported the release positively, saying she had been granted a pardon after serving her sentence \"in good conduct\". The New York Times suggested that the military government may have released Suu Kyi because it felt it was in a confident position to control her supporters after the election. The role that Suu Kyi will play in the future of democracy in Burma remains a subject of much debate.\n\nHer son Kim Aris was granted a visa in November 2010 to see his mother shortly after her release, for the first time in 10 years. He visited again on 5 July 2011, to accompany her on a trip to Bagan, her first trip outside Yangon since 2003. Her son visited again on 8 August 2011, to accompany her on a trip to Pegu, her second trip.\n\nDiscussions were held between Suu Kyi and the Burmese government during 2011, which led to a number of official gestures to meet her demands. In October, around a tenth of Burma's political prisoners were freed in an amnesty and trade unions were legalised.\n\nIn November 2011, following a meeting of its leaders, the NLD announced its intention to re-register as a political party in order to contend 48 by-elections necessitated by the promotion of parliamentarians to ministerial rank. Following the decision, Suu Kyi held a telephone conference with U.S. President Barack Obama, in which it was agreed that Secretary of State Hillary Clinton would make a visit to Burma, a move received with caution by Burma's ally China. On 1 December 2011, Suu Kyi met with Hillary Clinton at the residence of the top-ranking US diplomat in Yangon.\n\nOn 21 December 2011, Thai Prime Minister Yingluck Shinawatra met Suu Kyi in Yangoon, marking Suu Kyi's \"first-ever meeting with the leader of a foreign country\".\n\nOn 5 January 2012, British Foreign Minister William Hague met Aung San Suu Kyi and his Burmese counterpart. This represented a significant visit for Suu Kyi and Burma. Suu Kyi studied in the UK and maintains many ties there, whilst Britain is Burma's largest bilateral donor.\nDuring Aung San Suu Kyi's visit to Europe, she visited the Swiss parliament, collected her 1991 Nobel Prize in Oslo and her honorary degree from Oxford University.\n\nIn December 2011, there was speculation that Suu Kyi would run in the 2012 national by-elections to fill vacant seats. On 18 January 2012, Suu Kyi formally registered to contest a Pyithu Hluttaw (lower house) seat in the Kawhmu Township constituency in special parliamentary elections to be held on 1 April 2012. The seat was previously held by Soe Tint, who vacated it after being appointed Construction Deputy Minister, in the 2010 election. She ran against Union Solidarity and Development Party candidate Soe Min, a retired army physician and native of Twante Township.\n\nOn 3 March 2012, at a large campaign rally in Mandalay, Suu Kyi unexpectedly left after 15 minutes, because of exhaustion and airsickness.\n\nIn an official campaign speech broadcast on Burmese state television's MRTV on 14 March 2012, Suu Kyi publicly campaigned for reform of the 2008 Constitution, removal of restrictive laws, more adequate protections for people's democratic rights, and establishment of an independent judiciary. The speech was leaked online a day before it was broadcast. A paragraph in the speech, focusing on the Tatmadaw's repression by means of law, was censored by authorities.\n\nSuu Kyi has also called for international media to monitor the upcoming by-elections, while publicly pointing out irregularities in official voter lists, which include deceased individuals and exclude other eligible voters in the contested constituencies. On 21 March 2012, Aung San Suu Kyi was quoted as saying \"Fraud and rule violations are continuing and we can even say they are increasing.\"\n\nWhen asked whether she would assume a ministerial post if given the opportunity, she said the following:\n\nOn 26 March 2012, Suu Kyi suspended her nationwide campaign tour early, after a campaign rally in Myeik (Mergui), a coastal town in the south, citing health problems due to exhaustion and hot weather.\nOn 1 April 2012, the NLD announced that Suu Kyi had won the vote for a seat in Parliament. A news broadcast on state-run MRTV, reading the announcements of the Union Election Commission, confirmed her victory, as well as her party's victory in 43 of the 45 contested seats, officially making Suu Kyi the Leader of the Opposition in the Pyidaungsu Hluttaw.\n\nAlthough she and other MP-elects were expected to take office on 23 April when the Hluttaws resume session, National League for Democracy MP-elects, including Suu Kyi, said they might not take their oaths because of its wording; in its present form, parliamentarians must vow to \"safeguard\" the constitution. In an address on Radio Free Asia, she said \"We don't mean we will not attend the parliament, we mean we will attend only after taking the oath... Changing that wording in the oath is also in conformity with the Constitution. I don't expect there will be any difficulty in doing it.\"\n\nOn 2 May 2012, National League for Democracy MP-elects, including Aung San Suu Kyi, took their oaths and took office, though the wording of the oath was not changed. According to the Los Angeles Times, \"Suu Kyi and her colleagues decided they could do more by joining as lawmakers than maintaining their boycott on principle.\"\nOn 9 July 2012, she attended the Parliament for the first time as a lawmaker.\nSome activists criticised Aung San Suu Kyi for her silence on the 2012 Rakhine State riots (later repeated during the 2015 Rohingya refugee crisis), and her perceived indifference to the plight of the Rohingya, Myanmar's persecuted Muslim minority. After receiving a peace prize, she told reporters she did not know if the Rohingya could be regarded as Burmese citizens. In an interview with the BBC's Mishal Husain, Suu Kyi refused to condemn violence against the Rohingya and denied that Muslims in Myanmar have been subject to ethnic cleansing, insisting that the tensions were due to a \"climate of fear\" caused by \"a worldwide perception that global Muslim power is very great.\" According to Peter Popham, in the aftermath of the interview, she expressed anger at being interviewed by a Muslim. Husain had challenged Suu Kyi that almost all of the impact of violence was against the Rohingya, in response to Suu Kyi's claim that was violence was happening on both sides, and Peter Popham described her position on the issue as one of purposeful ambiguity for political gain.\n\nHowever, she said that she wanted to work towards reconciliation and she cannot take sides as violence has been committed by both sides. According to \"The Economist\", her \"halo has even slipped among foreign human-rights lobbyists, disappointed at her failure to make a clear stand on behalf of the Rohingya minority.\" However, she has spoken out \"against a ban on Rohingya families near the Bangladeshi border having more than two children.\"\n\nIn a 2015 BBC News article, reporter Jonah Fisher suggested that Aung San Suu Kyi's silence over the Rohingya issue is due to a need to obtain support from the majority Bamar ethnicity as she is in \"the middle of a general election campaign\"; In May 2015, the 14th Dalai Lama publicly called upon her to do more to help the Rohingya in Myanmar, claiming that he had previously urged her to address the plight of the Rohingya in private during two separate meetings and that she had resisted his urging. In May 2016, Suu Kyi asked the newly appointed United States Ambassador to Myanmar, Scot Marciel, not to refer to the Rohingya by their name. This followed Bamar protests at Marciel's use of the word 'Rohingya'.\n\nIn 2016, Suu Kyi was accused of failing to protect Myanmar's Rohingya Muslims during the 2016–17 persecution. State crime experts from Queen Mary University of London warned that Suu Kyi is \"legitimising genocide\" in Myanmar.\n\nOn 6 July 2012, Suu Kyi announced on the World Economic Forum's website that she wanted to run for the presidency in Myanmar's 2015 elections. The current Constitution, which came into effect in 2008, bars her from the presidency because she is the widow and mother of foreigners – provisions that appeared to be written specifically to prevent her from being eligible.\nThe NLD won a sweeping victory in those elections, winning at least 255 seats in the House of Representatives and 135 seats in the House of Nationalities. In addition, Suu Kyi won re-election to the House of Representatives. Under the 2008 constitution, the NLD needed to win at least a two-thirds majority in both houses to ensure that its candidate would become president. Before the elections, Suu Kyi announced that even though she is constitutionally barred from the presidency, she would hold the real power in any NLD-led government. On the 30 March 2016 she took over the roles of Foreign Affairs Minister, President's Office Minister, Education Minister and Electric Power and Energy Minister in the President Htin Kyaw government and later relinquished Ministries of Education and Electric Power and Energy. Moreover, President Htin Kyaw created a position called State Counsellor (de facto Prime Minister) for her.\n\nAs soon as she became foreign minister, she invited Chinese Foreign Minister Wang Yi, Canadian Foreign Minister Stephane Dion and Italian Foreign Minister Paolo Gentiloni in April and Japanese Foreign Minister Fumio Kishida in May and discussed to have good diplomatic relationships with these countries.\n\nInitially, upon accepting the State Counsellor position, she granted amnesty to the students who were arrested for opposing the National Education Bill, and announced a creation of the commission on Rakhine state, which had a long record of persecution of Muslim Rohingya minority. However, soon Aung San Suu Kyi's government did not manage with the ethnic conflicts in Shan and Kachin states, where thousands of refugees fled to China, and eventually the persecution of the Rohingya by the government fources escalated to the point that it is not uncommonly called a genocide. Aung San Suu Kyi, when interviewed, has denied the allegations of ethnic cleansing.She has also refused to grant citenzenship to the Rohingya, instead taking steps to issue ID cards for residency but no guarantess of citizenship. \n\nAsked what democratic models Myanmar could look to, she said: \"We have many, many lessons to learn from various places, not just the Asian countries like South Korea, Taiwan, Mongolia, and Indonesia.\" She also cited \"the eastern European countries, which made the transition from communist autocracy to democracy in the 1980s and 1990s, and the Latin American countries, which made the transition from military governments. \"And we cannot of course forget South Africa, because although it wasn't a military regime, it was certainly an authoritarian regime.\" She added: \"We wish to learn from everybody who has achieved a transition to democracy, and also ... our great strong point is that, because we are so far behind everybody else, we can also learn which mistakes we should avoid.\"\n\nIn a nod to the deep US political divide between Republicans led by Mitt Romney and the Democrats of Obama—then battling to win the 2012 Presidential election—she stressed with a smile, \"Those of you who are familiar with American politics I'm sure understand the need for negotiated compromise.\"\n\nAung San Suu Kyi has received vocal support from Western nations in Europe, Australia and North and South America, as well as India, Israel, Japan the Philippines and South Korea. In December 2007, the US House of Representatives voted unanimously 400–0 to award Aung San Suu Kyi the Congressional Gold Medal; the Senate concurred on 25 April 2008. On 6 May 2008, President George W. Bush signed legislation awarding Suu Kyi the Congressional Gold Medal. She is the first recipient in American history to receive the prize while imprisoned. More recently, there has been growing criticism of her detention by Burma's neighbours in the Association of Southeast Asian Nations, particularly from Indonesia, Thailand, the Philippines and Singapore. At one point Malaysia warned Burma that it faced expulsion from ASEAN as a result of the detention of Suu Kyi. Other nations including South Africa, Bangladesh and the Maldives also called for her release. The United Nations has urged the country to move towards inclusive national reconciliation, the restoration of democracy, and full respect for human rights. In December 2008, the United Nations General Assembly passed a resolution condemning the human rights situation in Burma and calling for Suu Kyi's release—80 countries voting for the resolution, 25 against and 45 abstentions. Other nations, such as China and Russia, are less critical of the regime and prefer to cooperate only on economic matters. Indonesia has urged China to push Burma for reforms. However, Samak Sundaravej, former Prime Minister of Thailand, criticised the amount of support for Suu Kyi, saying that \"Europe uses Aung San Suu Kyi as a tool. If it's not related to Aung San Suu Kyi, you can have deeper discussions with Myanmar.\"\n\nVietnam, however, did not support calls by other ASEAN member states for Myanmar to free Aung San Suu Kyi, state media reported Friday, 14 August 2009. The state-run Việt Nam News said Vietnam had no criticism of Myanmar's decision 11 August 2009 to place Suu Kyi under house arrest for the next 18 months, effectively barring her from elections scheduled for 2010. \"It is our view that the Aung San Suu Kyi trial is an internal affair of Myanmar\", Vietnamese government spokesman Le Dung stated on the website of the Ministry of Foreign Affairs. In contrast with other ASEAN member states, Dung said Vietnam has always supported Myanmar and hopes it will continue to implement the \"roadmap to democracy\" outlined by its government.\n\nAung San Suu Kyi was awarded the Nobel Peace Prize in 1991. The decision of the Nobel Committee mentions:\nIn 1995 Aung San Suu Kyi delivered the keynote address at the Fourth World Conference on Women in Beijing.\n\nNobel Peace Prize winners (Archbishop Desmond Tutu, the Dalai Lama, Shirin Ebadi, Adolfo Pérez Esquivel, Mairead Corrigan, Rigoberta Menchú, Prof. Elie Wiesel, U.S. President Barack Obama, Betty Williams, Jody Williams and former U.S. President Jimmy Carter) called for the rulers of Burma to release Suu Kyi in order to \"create the necessary conditions for a genuine dialogue with Daw Aung San Suu Kyi and all concerned parties and ethnic groups in order to achieve an inclusive national reconciliation with the direct support of the United Nations.\" Some of the money she received as part of the award helps fund London-based charity Prospect Burma, which provides higher education grants to Burmese students.\n\nOn 16 June 2012, Aung San Suu Kyi was finally able to deliver her Nobel acceptance speech (Nobel lecture) at Oslo's City Hall, two decades after being awarded the peace prize.\n\nIn September 2012, Aung San Suu Kyi received in person the United States Congressional Gold Medal, which is the highest Congressional award. Although she was awarded this medal in 2008, at the time she was under house arrest, and was unable to receive the medal. Aung San Suu Kyi was greeted with bipartisan support at Congress, as part of a coast-to-coast tour in the United States. In addition, Aung San Suu Kyi met President Barack Obama at the White House. The experience was described by Aung San Suu Kyi as \"one of the most moving days of my life.\"\n\nAs of 2014, she is listed as the 61st most powerful woman in the world by \"Forbes\".\n\n\n\nU2's Bono wrote the song \"Walk On\" in tribute to Suu Kyi, and publicized her plight during the U2 360° Tour, 2009-2011.\n\nSaxophonist Wayne Shorter composed a song titled \"Aung San Suu Kyi\". It appears on his albums 1 + 1 (with pianist Herbie Hancock) and Footprints Live!\n\nShe had surgery for a gynecological condition in September 2003 at Asia Royal Hospital during her house arrest. She underwent minor foot surgery in December 2013 and eye surgery in April 2016. Her doctor said that she had no serious health problems but weighed only 48 kg, had low blood pressure and could become weak easily.\n\nThe life of Suu Kyi and her husband Michael Aris is portrayed in Luc Besson's 2011 film \"The Lady\", in which they are played by Michelle Yeoh and David Thewlis. Yeoh visited Suu Kyi in 2011 before the film's release in November.\n\nIn the John Boorman's 1995 film \"Beyond Rangoon\", Suu Kyi was played by Adelle Lutz.\n\nSince 2009, Indian actress and Bharathanatyam dancer, Rukmini Vijayakumar has been portraying as Suu Kyi in an one-act play titled \"\"The Lady of Burma\"\" directed by Prakash Belawadi, which also happens to be an eponymous play written by Richard Shannon.\n\n\n\n", "id": "2847", "title": "Aung San Suu Kyi"}
{"url": "https://en.wikipedia.org/wiki?curid=2851", "text": "Abraham Joshua Heschel\n\nAbraham Joshua Heschel (January 11, 1907 – December 23, 1972) was a Polish-born American rabbi and one of the leading Jewish theologians and Jewish philosophers of the 20th century. Heschel, a professor of Jewish mysticism at the Jewish Theological Seminary of America, authored a number of widely read books on Jewish philosophy and was active in the Civil Rights Movement.\n\nAbraham Joshua Heschel was born in 1907 as the youngest of six children of Moshe Mordechai and Reizel Perlow. He was descended from preeminent European rabbis on both sides of his family. His paternal great-great-grandfather and namesake was Rebbe Avraham Yehoshua Heshel of Apt in present-day Poland. His mother was also a descendant of Avraham Yehoshua Heshel and other Hasidic dynasties. His siblings were Sarah, Dvora Miriam, Esther Sima, Gittel, and Jacob. Their father Moshe died of influenza in 1916 when Abraham was nine.\n\nAfter a traditional yeshiva education and studying for Orthodox rabbinical ordination semicha, Heschel pursued his doctorate at the University of Berlin and a liberal rabbinic ordination at the Hochschule für die Wissenschaft des Judentums. There he studied under some of the finest Jewish educators of the time: Chanoch Albeck, Ismar Elbogen, Julius Guttmann, and Leo Baeck. His mentor in Berlin was David Koigen. Heschel later taught Talmud at the Hochschule. He joined a Yiddish poetry group, Jung Vilna, and in 1933, published a volume of Yiddish poems, \"Der Shem Hamefoyrosh: Mentsch,\" dedicated to his father.\n\nIn late October 1938, when Heschel was living in a rented room in the home of a Jewish family in Frankfurt, he was arrested by the Gestapo and deported to Poland. He spent ten months lecturing on Jewish philosophy and Torah at Warsaw's Institute for Jewish Studies. Six weeks before the German invasion of Poland, Heschel left Warsaw for London with the help of Julian Morgenstern, president of Hebrew Union College, who had been working to obtain visas for Jewish scholars in Europe.\n\nHeschel's sister Esther was killed in a German bombing. His mother was murdered by the Nazis, and two other sisters, Gittel and Devorah, died in Nazi concentration camps. He never returned to Germany, Austria or Poland. He once wrote, \"If I should go to Poland or Germany, every stone, every tree would remind me of contempt, hatred, murder, of children killed, of mothers burned alive, of human beings asphyxiated.\"\n\nHeschel arrived in New York City in March 1940. He served on the faculty of Hebrew Union College (HUC), the main seminary of Reform Judaism, in Cincinnati for five years. In 1946, he took a position at the Jewish Theological Seminary of America (JTS) in New York City, the main seminary of Conservative Judaism. He served as professor of Jewish ethics and Mysticism until his death in 1972.\n\nHeschel married Sylvia Straus, a concert pianist, on December 10, 1946, in Los Angeles. Their daughter, Susannah Heschel, became a Jewish scholar in her own right. Heschel's papers are held in the Rubenstein Rare Book & Manuscript Library at Duke University.\n\nHeschel explicated many facets of Jewish thought, including studies on medieval Jewish philosophy, Kabbalah, and Hasidism. According to some scholars, he was more interested in spirituality than in critical text study; the latter was a specialty of many scholars at JTS. He was not given a graduate assistant for many years and was relegated to teach mainly in the education school or Rabbinical school, not in the academic graduate program. Heschel became friendly with his colleague Mordecai Kaplan. Though they differed in their approach to Judaism, they had a very cordial relationship and visited each other's homes from time to time.\n\nHeschel believed the teachings of the Hebrew prophets were a clarion call for social action in the United States and worked for African Americans' civil rights and against the Vietnam War.\n\nHe also specifically criticized what he called \"pan-halakhism\", or an exclusive focus upon religiously compatible behavior to the neglect of the non-legalistic dimension of rabbinic tradition.\n\nHeschel is a widely read Jewish theologian whose most influential works include \"Man Is Not Alone\", \"God in Search of Man\", \"The Sabbath,\" and \"The Prophets\". At the Vatican Council II, as representative of American Jews, Heschel persuaded the Roman Catholic Church to eliminate or modify passages in its liturgy that demeaned the Jews, or referred to an expected conversion to Christianity. His theological works argued that religious experience is a fundamentally human impulse, not just a Jewish one. He believed that no religious community could claim a monopoly on religious truth.\n\n\"The Sabbath: Its Meaning for Modern Man\" is a work on the nature and celebration of Shabbat, the Jewish Sabbath. This work is rooted in the thesis that Judaism is a religion of time, not space, and that the Sabbath symbolizes the sanctification of time.\n\n\"Man Is Not Alone: A Philosophy of Religion\" offers Heschel's views on how people can comprehend God. Judaism views God as being radically different from humans, so Heschel explores the ways that Judaism teaches that a person may have an encounter with the ineffable. A recurring theme in this work is the radical amazement that people feel when experiencing the presence of the Divine. Heschel then goes on to explore the problems of doubts and faith; what Judaism means by teaching that God is one; the essence of humanity and the problem of human needs; the definition of religion in general and of Judaism in particular; and human yearning for spirituality. He offers his views as to Judaism being a pattern for life.\n\n\"God in Search of Man: A Philosophy of Judaism\" is a companion volume to \"Man Is Not Alone\". In this book Heschel discusses the nature of religious thought, how thought becomes faith, and how faith creates responses in the believer. He discusses ways that people can seek God's presence, and the radical amazement that we receive in return. He offers a criticism of nature worship; a study of humanity's metaphysical loneliness, and his view that we can consider God to be in search of humanity. The first section concludes with a study of Jews as a chosen people. Section two deals with the idea of revelation, and what it means for one to be a prophet. This section gives us his idea of revelation as an event, as opposed to a process. This relates to Israel's commitment to God. Section three discusses his views of how a Jew should understand the nature of Judaism as a religion. He discusses and rejects the idea that mere faith (without law) alone is enough, but then cautions against rabbis he sees as adding too many restrictions to Jewish law. He discusses the need to correlate ritual observance with spirituality and love, the importance of Kavanah (intention) when performing mitzvot. He engages in a discussion of religious behaviorism—when people strive for external compliance with the law, yet disregard the importance of inner devotion.\n\nThis work started out as his PhD thesis in German, which he later expanded and translated into English. Originally published in a two-volume edition, this work studies the books of the Hebrew prophets. It covers their lives and the historical context that their missions were set in, summarizes their work, and discusses their psychological state. In it Heschel puts forward what would become a central idea in his theology: that the prophetic (and, ultimately, Jewish) view of God is best understood not as anthropomorphic (that God takes human form) but rather as anthropopathic—that God has human feelings.\n\nIn his book \"The Prophets\", Abraham Joshua Heschel describes the unique aspect of the Jewish prophets as compared to other similar figures. Whereas other nations have soothsayers and diviners who attempt to discover the will of their gods, according to Heschel the Hebrew prophets are characterized by their experience of what he calls theotropism—God turning towards humanity. Heschel argues for the view of Hebrew prophets as receivers of the \"Divine Pathos\", of the wrath and sorrow of God over his nation that has forsaken him. In this view, prophets do not speak for God so much as they remind their audience of God's voice for the voiceless, the poor and oppressed.\n\nHe writes:\nMany consider Heschel's \"Torah min HaShamayim BeAspaklariya shel HaDorot\", (\"Torah from Heaven in the mirror of the generations\") to be his masterwork. The three volumes of this work are a study of classical rabbinic theology and aggadah, as opposed to halakha (Jewish law.) It explores the views of the rabbis in the Mishnah, Talmud and Midrash about the nature of Torah, the revelation of God to mankind, prophecy, and the ways that Jews have used scriptural exegesis to expand and understand these core Jewish texts. In this work, Heschel views the 2nd century sages Rabbi Akiva and Ishmael ben Elisha as paradigms for the two dominant world-views in Jewish theology\n\nTwo Hebrew volumes were published during his lifetime by Soncino Press, and the third Hebrew volume was published posthumously by JTS Press in the 1990s. An English translation of all three volumes, with notes, essays and appendices, was translated and edited by Rabbi Gordon Tucker, entitled \"Heavenly Torah: As Refracted Through the Generations\". In its own right it can be the subject of intense study and analysis, and provides insight into the relationship between God and Man beyond the world of Judaism and for all Monotheism.\n\nHeschel wrote a series of articles, originally in Hebrew, on the existence of prophecy in Judaism after the destruction of the Holy Temple in Jerusalem in 70 CE. These essays were translated into English and published as \"Prophetic Inspiration After the Prophets: Maimonides and Others\" by the American Judaica publisher Ktav.\n\nThe publisher of this book states, \"The standard Jewish view is that prophecy ended with the ancient prophets, somewhere early in the Second Temple era. Heschel demonstrated that this view is not altogether accurate. Belief in the possibility of continued prophetic inspiration, and in its actual occurrence appear throughout much of the medieval period, and even in modern times. Heschel's work on prophetic inspiration in the Middle Ages originally appeared in two long Hebrew articles. In them he concentrated on the idea that prophetic inspiration was possible even in post-Talmudic times, and, indeed, had taken place at various times and in various schools, from the Geonim to Maimonides and beyond.\"\n\nFour schools have been named for Heschel, in the Upper West Side of New York City, Northridge, California, Agoura Hills, California, and Toronto, Ontario, Canada. In 2009, a highway in Missouri was named \"Dr. Abraham Joshua Heschel Highway\" after a Springfield, Missouri area Neo-Nazi group cleaned the stretch of highway as part of an \"Adopt-A-Highway\" plan. Heschel's daughter, Susannah, has objected to the adoption of her father's name in this context.\n\n\n\n", "id": "2851", "title": "Abraham Joshua Heschel"}
{"url": "https://en.wikipedia.org/wiki?curid=2853", "text": "Aberdeen Bestiary\n\nThe Aberdeen Bestiary (Aberdeen University Library, Univ Lib. MS 24) is a 12th-century English illuminated manuscript bestiary that was first listed in 1542 in the inventory of the Old Royal Library at the Palace of Westminster.\n\nInformation about its origins and patron are circumstantial. It probably comes from the 12th century and was owned by a wealthy ecclesiastical patron of the north or south province. The \"Aberdeen Bestiary\" is related to other bestiaries of the Middle Ages such as the \"Ashmole Bestiary\".\n\n\n\nAfter folio 9 verso some leaves are missing which should have contained antelope (\"Antalops\"), unicorn (\"Unicornis\"), lynx (\"Lynx\"), griffin (\"Gryps\") and part of elephant (\"Elephans\").\n\n\nAfter folio 15 verso some leaves are missing which should have contained crocodile (\"Crocodilus\"), manticore (\"Mantichora\") and part of parandrus (\"Parandrus\").\n\n\n\nAfter folio 21 verso two leaves are missing which should have contained ox (\"Bos\"), camel (\"Camelus\"), dromedary (\"Dromedarius\"), ass (\"Asinus\"), onager (\"Onager\") and part of horse (\"Equus\").\n\n\n\n\n\n\n\n\n\n\n\n", "id": "2853", "title": "Aberdeen Bestiary"}
{"url": "https://en.wikipedia.org/wiki?curid=2856", "text": "Latin American Integration Association\n\nThe Latin American Integration Association / Asociación Latinoamericana de Integración / Associação Latino-Americana de Integração (LAIA / ALADI) is an international and regional scope organization. It was created on 12 August 1980 by the 1980 Montevideo Treaty, replacing the Latin American Free Trade Association (LAFTA / ALALC). Currently, it has 13 member countries, and any of the Latin American States may apply for accession.\n\nThe development of the integration process developed within the framework of the ALADI aims at promoting the harmonious and balanced socio-economic development of the region, and its long-term objective is the gradual and progressive establishment of a Latin-American Common Market.\n\n\n\nThe ALADI promotes the establishment of an area of economic preferences within the region, in order to create a Latin-American common market, through three mechanisms:\n\nThe Relatively Less Economically Developed Countries of the region (Bolivia, Ecuador and Paraguay) benefit from a preferential system, through the lists of markets opening offered by the countries in favor of the Relatively Less Economically Developed Countries; special programs of cooperation (business rounds, pre-investment, financing, technological support); and countervailing measures in favor of the land-locked countries, the full participation of such countries in the integration process is sought.\nThe ALADI includes in its legal structure the strongest sub-regional, plurilateral and bilateral integration agreements arising in growing numbers in the continent. As a result, the ALADI – as an institutional and legal framework or “umbrella” of the regional integration- develops actions in order to support and foster these efforts for the progressive establishment of a common economic space.\n\nThe 1980 Montevideo Treaty is open to the accession of any Latin-American country. \nOn 26 August 1999, the first accession to the 1980 Montevideo Treaty was executed, with the incorporation of the Republic of Cuba as a member country of the ALADI. \nOn 10 May 2012, the Republic of Panama became the thirteenth member country of the ALADI. \nLikewise, the accession of the Republic of Nicaragua was accepted in the Sixteenth Meeting of the Council of Ministers (Resolution 75 (XVI)), held on 11 August 2011. Currently, Nicaragua moves towards the fulfillment of conditions for becoming a member country of the ALADI.\nThe ALADI opens its field of actions for the rest of Latin America through multilateral links or partial agreements with other countries and integration areas of the continent (Article 25).\nThe Latin-American Integration Association also contemplates the horizontal cooperation with other integration movements in the world and partial actions with third developing countries or their respective integration areas (Article 27).\n\nThe Council of Ministers is the supreme body of the ALADI, and adopts the decisions for the superior political management of the integration process. \nIt is constituted by the Ministers of Foreign Affairs of the member countries. Notwithstanding, when one of such member countries assigns the competence of the integration affairs to a different Minister or Secretary of State, the member countries may be represented, with full powers, by the respective Minister or Secretary. It is convened by the Committee of Representatives, meets and makes decisions with the presence of all the member countries.\n\nIt is in charge, among others, of analyzing the functioning of the integration process in all its aspects, promoting the convergence of the partial scope agreements seeking their progressive multilateralization, and promoting greater scope actions as regards economic integration. It is made up of Plenipotentiaries of the member countries.\n\nIt is the permanent political body and negotiating forum of the ALADI, where all the initiatives for the fulfillment of the objectives established by the 1980 Montevideo Treaty are analyzed and agreed on. It is composed of a Permanent Representative of each member country with right to one vote and an Alternate Representative. It meets regularly every 15 days and its Resolutions are adopted by the affirmative vote of two thirds of the member countries.\n\nIt is the technical body of the ALADI, and it may propose, evaluate, study and manage for the fulfillment of the objectives of the ALADI. It is composed of technical and administrative personnel, and directed by a Secretary-General, who has the support of two Undersecretaries, elected for a three-year period, renewable for the same term.\n\n", "id": "2856", "title": "Latin American Integration Association"}
{"url": "https://en.wikipedia.org/wiki?curid=2858", "text": "Aircraft spotting\n\nAircraft spotting or plane spotting is a hobby of tracking the movement of aircraft, which is often accomplished by photography. Besides monitoring aircraft, aircraft spotting enthusiasts (whom are usually called plane spotters) also record informations of airports, air traffic control communications and airline routes.\n\nAviation enthusiasts have been watching airplanes and other aircraft ever since they were invented. However, plane spotting was not considered a distinct hobby until the second half of the 20th century.\n\nThe development of technology and global resources enabled a revolution in spotting. Point and shoot cameras, DSLRs & walkie talkies significantly changed the hobby. With the help of the internet, websites such as FlightAware and Flightradar24 have made it possible for spotters to track and locate specific aircraft from all across the world. Websites specifically for aircraft, such as airliners.net, and social networking websites, such as Twitter and Instagram, allow spotters to record their sightings and upload their shots or see pictures of aircraft spotted by other people from all over the world.\n\nWhen spotting aircraft, observers generally notice the key attributes of an aircraft, such as a distinctive noise from its engine or the number of vapour trails it is leaving. Observers assess the size of the aircraft and the number, type and position of its engines. Another distinctive attribute is the position of wings relative to the fuselage and the degree to which they are swept rearwards. The wings may be above the fuselage, below it, or fixed at midpoint. The number of wings indicate whether it is a monoplane, biplane or triplane. The position of the tailplane relative to the fin(s) and the shape of the fin are other attributes. The configuration of the landing gear can be distinctive, as well.\n\nOther features include the speed, cockpit placement, colour scheme or special equipment that changes the silhouette of the aircraft. Taken together these traits will enable the identification of an aircraft. If the observer is familiar with the airfield being used by the aircraft and its normal traffic patterns, he or she is more likely to leap quickly to a decision about the aircraft's identity – they may have seen the same type of aircraft from the same angle many times. This is particularly prevalent if the aircraft spotter is spotting commercial aircraft, operated by airlines that have a limited fleet. \nSpotters use equipment such as ADS-B decoders to track the movements of aircraft. The two most famous devices used are the AirNav Systems RadarBox and Kinetic Avionics SBS series. Both of them read and process the radar data and show the movements on a computer screen. Most of the decoders also allow the exporting of logs from a certain route or airport.\n\nSome spotters will note and compile the markings, a national insignia or airline livery or logo, a squadron badge or code letters in the case of a military aircraft. Published manuals allow more information to be deduced, such as the delivery date or the manufacturer's construction number. Camouflage markings differ, depending on the surroundings in which that aircraft is expected to operate.\n\nIn general, most spotters attempt to see as many aircraft of a given type, a particular airline, or a particular subset of aircraft such as business jets, commercial airliners, military and/or general aviation aircraft. Some spotters attempt to see every airframe and are known as \"frame spotters.\" Others are keen to see every registration worn by each aircraft. \nAncillary activities might include listening-in to air traffic control transmissions (using radio scanners, where that is legal), liaising with other \"spotters\" to clear up uncertainties as to what aircraft have been seen at specific times or in particular places. Several internet mailing list groups have been formed to help communicate aircraft seen at airports, queries and anomalies. These groups can cater to certain regions, certain aircraft types, or may appeal to a wider audience. Many of these groups originated from the original Oxford.vax group which pioneered this type of communication. The result is that information on aircraft movements can be delivered worldwide in a real-time fashion to spotters.\n\nThe hobbyist might travel long distances to visit different airports, to see an unusual aircraft, or to view the remains of aircraft withdrawn from use. Some aircraft may be placed in the care of museums (see Aviation archaeology) – or perhaps be cannibalized in order to repair a similar aircraft already preserved.\n\nAircraft registrations can be found in books, with online resources, or in monthly magazines from enthusiast groups. Most spotters maintained books of different aircraft fleets and would underline or check each aircraft seen. Each year, a revised version of the books would be published and the spotter would need to re-underline every aircraft seen. With the development of commercial aircraft databases spotters were finally able to record their sightings in an electronic database and produce reports that emulated the underlined books.\n\nDuring World War II and the subsequent Cold War some countries encouraged their citizens to become \"plane spotters\" in an \"observation corps\" or similar public body for reasons of public security. Britain had the Royal Observer Corps which operated between 1925 and 1995. A journal called \"The Aeroplane Spotter\" was published in January 1940. The publication included a glossary that was refined in 2010 and published online.\n\nAir shows usually draw large numbers of spotters as it is a chance to enter airfields and air bases worldwide that are usually closed to the public and to see displayed aircraft at close range.\n\nThe legal repercussions of the hobby were dramatically shown in November 2001 when fourteen aircraft spotters (twelve British, two Dutch) were arrested by Greek police after being observed at an open day at the Greek Air Force base at Kalamata. They were charged with espionage, and faced a possible 20-year prison sentence if found guilty. After being held for six weeks, they were eventually released on £9,000 bail, and the charges reduced to the misdemeanor charge of illegal information collection. Confident of their innocence they returned for their trial in April 2002 and were stunned to be found guilty, with eight of the group sentenced to three years, the rest for one year. At their appeal a year later all were acquitted.\n\nIn the wake of the targeting of airports by terrorists, enthusiasts' organisations and police in the UK have cooperated in creating a code of conduct for plane spotters. By asking enthusiasts to contact police if spotters believe they see or hear something suspicious, this is an attempt to allow enthusiasts to continue their hobby while increasing security around airports. Birmingham and Stansted pioneered this approach in Britain and prior to the 2012 London Olympics, RAF Northolt introduced a \"Flightwatch\" scheme based on the same cooperative principles. These changes are also being made abroad in countries like Australia, where aviation enthusiasts are reporting suspicious or malice actions to police.\n\nThe organisation of such groups has now been echoed in parts of North America. For example, the Bensenville Illinois Police Department have sponsored an \"Airport Watch\" group at the Chicago O'Hare Airport. Members are issued identification cards and given training to accurately record and report unusual activities around the airport perimeter (members are not permitted airside). Meetings are attended and supported by the FBI, Chicago Department of Aviation and the TSA who also provide regular training to group members. The Bensenville program was modeled on similar programs in Toronto, Ottawa and Minneapolis.\n\nIn 2009, a similar airport watch group was organized between airport security and local aircraft spotters at Montreal-Pierre Trudeau International Airport. As of 2016, the group has 46 members and a special phone number to use to contact police if suspicious activity is seen around the airport area.\n\nFollowing the events of 9/11, information collected by planespotters helped uncover what is known as \"extraordinary rendition\" by the CIA. Information on unusual movements of rendition aircraft provided data which led first to news reports and then to a number of governmental and inter-governmental investigations.\n\n\n", "id": "2858", "title": "Aircraft spotting"}
